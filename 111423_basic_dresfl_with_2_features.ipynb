{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DReS-FL Experiment \n",
    "\n",
    "- K = 1\n",
    "- T = 1\n",
    "- input dimension = 2 -> scalar\n",
    "- linear regression\n",
    "- w = [1 1]\n",
    "- finite field size = 5\n",
    "- inputs are selected from {0, 1}\n",
    "- no relationship between x and y\n",
    "- the gradient is supposed to be revealed at the end of each training round\n",
    "\n",
    "Basically, our objective function is $l = (y - xw)^2$ and our gradient is $g = -2(xy - x^2w)$ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b3c4298b0e65eb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lcc.polynomials import LCCPoly, InterpolatedPoly, Poly\n",
    "from mutual_information.estimators.neural.benchmark import neural_estimator_benchmark\n",
    "from lcc.domain import create_lcc_gradient_domain_basic_setup_no_relationship\n",
    "from mutual_information.exhaustive_search_mutual_information import calculate_mutual_information_domain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T23:49:41.716431646Z",
     "start_time": "2023-11-14T23:49:40.720356223Z"
    }
   },
   "id": "5ecd3014be47b957"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "prime = 5\n",
    "data_range = 2\n",
    "para_param = 1 # K\n",
    "priv_param = 1 # T\n",
    "\n",
    "num_of_samples = 10\n",
    "beta_arr = [0, 1]\n",
    "alpha_arr = [2, 3, 4] # number of clients = 3\n",
    "weight = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T23:49:41.757026519Z",
     "start_time": "2023-11-14T23:49:41.756565908Z"
    }
   },
   "id": "cea634fe6a81f53"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_encoded_dataset(encoded_data_pol, data_size, encoded_label_pol, alpha):\n",
    "    encoded_data = np.empty((len(encoded_data_pol), *data_size)) \n",
    "    encoded_label = np.empty((len(encoded_label_pol), 1))\n",
    "    for idx, (data_pol, label_pol) in enumerate(zip(encoded_data_pol, encoded_label_pol)):\n",
    "        encoded_data[idx] = data_pol(alpha)\n",
    "        encoded_label[idx][1] = label_pol(alpha)\n",
    "    return encoded_data, encoded_label\n",
    "\n",
    "def calculate_gradient(encoded_data, encoded_label, curr_weight, p):\n",
    "    encoded_data = encoded_dataset[:, 0].reshape(-1, 1)\n",
    "    encoded_label = encoded_dataset[:, 1].reshape(-1, 1)\n",
    "    \n",
    "    gradient = (encoded_label - encoded_data @ curr_weight) % p\n",
    "    gradient = (encoded_data.T @ gradient) % p\n",
    "    gradient = (-2 * gradient) % p\n",
    "    return gradient\n",
    "\n",
    "def calculate_gradient_samplewise(encoded_dataset, curr_weight, p):\n",
    "    # g = -2(xy - x^2w)\n",
    "    gradient = np.empty(encoded_dataset.shape[0])\n",
    "    for idx, encoded_sample in enumerate(encoded_dataset):\n",
    "        data, label = encoded_sample[0], encoded_sample[1]\n",
    "        gradient[idx] = (label - data * curr_weight) % p\n",
    "        gradient[idx] = (data * gradient[idx]) % p\n",
    "        gradient[idx] = (-2 * gradient[idx]) % p\n",
    "    gradient = gradient.astype(int)\n",
    "    return gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T23:49:42.470039293Z",
     "start_time": "2023-11-14T23:49:42.464384921Z"
    }
   },
   "id": "2d6a184396caa636"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "secret_data = np.random.randint(low=0, high=2, size=(num_of_samples, 2, 1))\n",
    "secret_label = np.random.randint(low=0, high=2, size=(num_of_samples, 1))\n",
    "encoded_secret_data_pol = [LCCPoly(beta_arr, [x], para_param, priv_param, prime, size=(2, 1)) for x in secret_data]\n",
    "encoded_secret_label_pol = [LCCPoly(beta_arr, [x[0]], para_param, priv_param, prime) for x in secret_label]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T23:49:45.823847399Z",
     "start_time": "2023-11-14T23:49:45.134165203Z"
    }
   },
   "id": "705f968c5d9b62fc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# client 0\n",
    "client_0_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[0])\n",
    "client_0_encoded_gradient = calculate_gradient_samplewise(client_0_encoded_data, weight, prime)\n",
    "\n",
    "# client 1\n",
    "client_1_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[1])\n",
    "client_1_encoded_gradient = calculate_gradient_samplewise(client_1_encoded_data, weight, prime)\n",
    "\n",
    "# client 2\n",
    "client_2_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[2])\n",
    "client_2_encoded_gradient = calculate_gradient_samplewise(client_2_encoded_data, weight, prime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:24:05.674280432Z",
     "start_time": "2023-11-14T02:24:05.537062175Z"
    }
   },
   "id": "ac2d268532e1f34a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "revealed_poly_arr = [] \n",
    "revealed_gradients = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_random = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_poly_constructed_coeff = np.empty((client_0_encoded_gradient.shape[0], 2 * para_param + 1))\n",
    "for gradient_idx in range(client_0_encoded_gradient.shape[0]):\n",
    "    revealed_poly = InterpolatedPoly([int(client_0_encoded_gradient[gradient_idx]), int(client_1_encoded_gradient[gradient_idx]), int(client_2_encoded_gradient[gradient_idx])], alpha_arr, prime)\n",
    "    revealed_gradients[gradient_idx][0] = revealed_poly(beta_arr[0])\n",
    "    revealed_random[gradient_idx][0] = revealed_poly(beta_arr[1])\n",
    "    revealed_poly_constructed_coeff[gradient_idx] = revealed_poly.coefficients\n",
    "    revealed_poly_arr.append(revealed_poly)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:24:10.391145594Z",
     "start_time": "2023-11-14T02:24:06.537828687Z"
    }
   },
   "id": "a77a29cfacc3050a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# create dataset\n",
    "resulting_dataset = np.concatenate([secret_data, secret_label, revealed_gradients, revealed_random, revealed_poly_constructed_coeff], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:24:11.626905631Z",
     "start_time": "2023-11-14T02:24:11.623034023Z"
    }
   },
   "id": "4566e622a38e75c5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████▉                                         | 2250/10000 [03:43<12:50, 10.06step/s, test=1.29, train=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▉                                                 | 750/10000 [00:03<00:38, 238.42step/s, test=1.29, train=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████▎                                           | 1750/10000 [02:54<13:44, 10.00step/s, test=1.29, train=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▉                                             | 1500/10000 [02:29<14:08, 10.02step/s, test=1.29, train=1.30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_all, results_all = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 2:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:33:39.951606623Z",
     "start_time": "2023-11-14T02:24:27.161264533Z"
    }
   },
   "id": "4e4d497917e37ba1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▉                                             | 1500/10000 [03:26<19:29,  7.27step/s, test=1.04, train=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▏                                              | 1000/10000 [00:03<00:34, 261.57step/s, test=1.03, train=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                                  | 750/10000 [01:41<20:54,  7.38step/s, test=1.04, train=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▉                                             | 1500/10000 [03:33<20:07,  7.04step/s, test=1.04, train=1.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_revealed_gradient, results_revealed_gradient = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 2].reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:47:02.457463572Z",
     "start_time": "2023-11-14T02:38:17.239213363Z"
    }
   },
   "id": "f4987aa6326c8320"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100/12500\n",
      "iteration 200/12500\n",
      "iteration 300/12500\n",
      "iteration 400/12500\n",
      "iteration 500/12500\n",
      "iteration 600/12500\n",
      "iteration 700/12500\n",
      "iteration 800/12500\n",
      "iteration 900/12500\n",
      "iteration 1000/12500\n",
      "iteration 1100/12500\n",
      "iteration 1200/12500\n",
      "iteration 1300/12500\n",
      "iteration 1400/12500\n",
      "iteration 1500/12500\n",
      "iteration 1600/12500\n",
      "iteration 1700/12500\n",
      "iteration 1800/12500\n",
      "iteration 1900/12500\n",
      "iteration 2000/12500\n",
      "iteration 2100/12500\n",
      "iteration 2200/12500\n",
      "iteration 2300/12500\n",
      "iteration 2400/12500\n",
      "iteration 2500/12500\n",
      "iteration 2600/12500\n",
      "iteration 2700/12500\n",
      "iteration 2800/12500\n",
      "iteration 2900/12500\n",
      "iteration 3000/12500\n",
      "iteration 3100/12500\n",
      "iteration 3200/12500\n",
      "iteration 3300/12500\n",
      "iteration 3400/12500\n",
      "iteration 3500/12500\n",
      "iteration 3600/12500\n",
      "iteration 3700/12500\n",
      "iteration 3800/12500\n",
      "iteration 3900/12500\n",
      "iteration 4000/12500\n",
      "iteration 4100/12500\n",
      "iteration 4200/12500\n",
      "iteration 4300/12500\n",
      "iteration 4400/12500\n",
      "iteration 4500/12500\n",
      "iteration 4600/12500\n",
      "iteration 4700/12500\n",
      "iteration 4800/12500\n",
      "iteration 4900/12500\n",
      "iteration 5000/12500\n",
      "iteration 5100/12500\n",
      "iteration 5200/12500\n",
      "iteration 5300/12500\n",
      "iteration 5400/12500\n",
      "iteration 5500/12500\n",
      "iteration 5600/12500\n",
      "iteration 5700/12500\n",
      "iteration 5800/12500\n",
      "iteration 5900/12500\n",
      "iteration 6000/12500\n",
      "iteration 6100/12500\n",
      "iteration 6200/12500\n",
      "iteration 6300/12500\n",
      "iteration 6400/12500\n",
      "iteration 6500/12500\n",
      "iteration 6600/12500\n",
      "iteration 6700/12500\n",
      "iteration 6800/12500\n",
      "iteration 6900/12500\n",
      "iteration 7000/12500\n",
      "iteration 7100/12500\n",
      "iteration 7200/12500\n",
      "iteration 7300/12500\n",
      "iteration 7400/12500\n",
      "iteration 7500/12500\n",
      "iteration 7600/12500\n",
      "iteration 7700/12500\n",
      "iteration 7800/12500\n",
      "iteration 7900/12500\n",
      "iteration 8000/12500\n",
      "iteration 8100/12500\n",
      "iteration 8200/12500\n",
      "iteration 8300/12500\n",
      "iteration 8400/12500\n",
      "iteration 8500/12500\n",
      "iteration 8600/12500\n",
      "iteration 8700/12500\n",
      "iteration 8800/12500\n",
      "iteration 8900/12500\n",
      "iteration 9000/12500\n",
      "iteration 9100/12500\n",
      "iteration 9200/12500\n",
      "iteration 9300/12500\n",
      "iteration 9400/12500\n",
      "iteration 9500/12500\n",
      "iteration 9600/12500\n",
      "iteration 9700/12500\n",
      "iteration 9800/12500\n",
      "iteration 9900/12500\n",
      "iteration 10000/12500\n",
      "iteration 10100/12500\n",
      "iteration 10200/12500\n",
      "iteration 10300/12500\n",
      "iteration 10400/12500\n",
      "iteration 10500/12500\n",
      "iteration 10600/12500\n",
      "iteration 10700/12500\n",
      "iteration 10800/12500\n",
      "iteration 10900/12500\n",
      "iteration 11000/12500\n",
      "iteration 11100/12500\n",
      "iteration 11200/12500\n",
      "iteration 11300/12500\n",
      "iteration 11400/12500\n",
      "iteration 11500/12500\n",
      "iteration 11600/12500\n",
      "iteration 11700/12500\n",
      "iteration 11800/12500\n",
      "iteration 11900/12500\n",
      "iteration 12000/12500\n",
      "iteration 12100/12500\n",
      "iteration 12200/12500\n",
      "iteration 12300/12500\n",
      "iteration 12400/12500\n",
      "iteration 12500/12500\n",
      "1.2950484425557183 1.0397207708399179\n"
     ]
    }
   ],
   "source": [
    "basic_experiment_domain = create_lcc_gradient_domain_basic_setup_no_relationship(data_range, beta_arr, alpha_arr, weight, prime)\n",
    "all_coeff_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4, 5, 6, 7, 8], [data_range, data_range], [prime, prime, prime, prime, prime])\n",
    "revealed_gradient_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4], [data_range, data_range], [prime])\n",
    "print(all_coeff_mi, revealed_gradient_mi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T02:47:19.987313187Z",
     "start_time": "2023-11-14T02:47:12.671482754Z"
    }
   },
   "id": "e5c2fec600e08573"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
