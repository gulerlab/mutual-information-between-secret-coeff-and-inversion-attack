{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:30:46.368855896Z",
     "start_time": "2023-11-21T09:30:45.295579809Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulerlab/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lcc.dataset import create_lcc_dataset_k1_t1_scalar\n",
    "\n",
    "from probabilistic_classifier.dataset import create_knn_sampling_joint_cond_marginal_dataset\n",
    "from probabilistic_classifier.estimate import estimate_mi_for_binary_classification\n",
    "from probabilistic_classifier.train import train_binary_classifier_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52797b0247350ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:31:55.822497776Z",
     "start_time": "2023-11-21T09:30:46.370006564Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pols created\n",
      "dataset is created\n"
     ]
    }
   ],
   "source": [
    "# create the basis dataset\n",
    "prime = 5\n",
    "data_range = 2\n",
    "num_of_samples = 800000\n",
    "weight = np.asarray([[1]])\n",
    "dataset = create_lcc_dataset_k1_t1_scalar(prime, data_range, num_of_samples, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62da61c8fc32e6fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:55.812331907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "num_of_neighbors = 4\n",
    "x_idx, y_idx, z_idx = [0, 1], [3, 4, 5], [2]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_knn_sampling_joint_cond_marginal_dataset(dataset, num_of_neighbors, x_idx, y_idx, z_idx)\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb99642d6db7215",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:55.812488300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(y_idx) + len(z_idx)\n",
    "hidden_size_arr = [256, 256, 256]\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146b880bcd657c43",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:55.812572342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, epoch, 1, iter: 1, curr loss: 0.69249427318573, avg loss: 0.69249427318573\n",
      "trial: 1, epoch, 1, iter: 200, curr loss: 0.18395623564720154, avg loss: 0.22718291208148003\n",
      "trial: 1, epoch, 2, iter: 1, curr loss: 0.1888899952173233, avg loss: 0.1888899952173233\n",
      "trial: 1, epoch, 2, iter: 200, curr loss: 0.18508991599082947, avg loss: 0.18578461721539496\n",
      "trial: 1, epoch, 3, iter: 1, curr loss: 0.17851215600967407, avg loss: 0.17851215600967407\n",
      "trial: 1, epoch, 3, iter: 200, curr loss: 0.1835688054561615, avg loss: 0.1864711120724678\n",
      "trial: 1, epoch, 4, iter: 1, curr loss: 0.18146224319934845, avg loss: 0.18146224319934845\n",
      "trial: 1, epoch, 4, iter: 200, curr loss: 0.18273651599884033, avg loss: 0.18548314779996872\n",
      "trial: 1, epoch, 5, iter: 1, curr loss: 0.18506398797035217, avg loss: 0.18506398797035217\n",
      "trial: 1, epoch, 5, iter: 200, curr loss: 0.1846223622560501, avg loss: 0.1849384944140911\n",
      "trial: 1, epoch, 6, iter: 1, curr loss: 0.18651655316352844, avg loss: 0.18651655316352844\n",
      "trial: 1, epoch, 6, iter: 200, curr loss: 0.18714657425880432, avg loss: 0.18501827344298363\n",
      "trial: 1, epoch, 7, iter: 1, curr loss: 0.18298029899597168, avg loss: 0.18298029899597168\n",
      "trial: 1, epoch, 7, iter: 200, curr loss: 0.1829649806022644, avg loss: 0.18442340172827243\n",
      "trial: 1, epoch, 8, iter: 1, curr loss: 0.1866564303636551, avg loss: 0.1866564303636551\n",
      "trial: 1, epoch, 8, iter: 200, curr loss: 0.18049678206443787, avg loss: 0.18463007390499114\n",
      "trial: 1, epoch, 9, iter: 1, curr loss: 0.18548375368118286, avg loss: 0.18548375368118286\n",
      "trial: 1, epoch, 9, iter: 200, curr loss: 0.1919703483581543, avg loss: 0.1847775548696518\n",
      "trial: 1, epoch, 10, iter: 1, curr loss: 0.18035517632961273, avg loss: 0.18035517632961273\n",
      "trial: 1, epoch, 10, iter: 200, curr loss: 0.18037909269332886, avg loss: 0.18460461355745791\n",
      "trial: 1, epoch, 11, iter: 1, curr loss: 0.1879711002111435, avg loss: 0.1879711002111435\n",
      "trial: 1, epoch, 11, iter: 200, curr loss: 0.18899911642074585, avg loss: 0.184845954477787\n",
      "trial: 1, epoch, 12, iter: 1, curr loss: 0.18057620525360107, avg loss: 0.18057620525360107\n",
      "trial: 1, epoch, 12, iter: 200, curr loss: 0.18437209725379944, avg loss: 0.18441828116774558\n",
      "trial: 1, epoch, 13, iter: 1, curr loss: 0.18964481353759766, avg loss: 0.18964481353759766\n",
      "trial: 1, epoch, 13, iter: 200, curr loss: 0.17883214354515076, avg loss: 0.18471239812672138\n",
      "trial: 1, epoch, 14, iter: 1, curr loss: 0.19068410992622375, avg loss: 0.19068410992622375\n",
      "trial: 1, epoch, 14, iter: 200, curr loss: 0.18311291933059692, avg loss: 0.18472604356706143\n",
      "trial: 1, epoch, 15, iter: 1, curr loss: 0.18913881480693817, avg loss: 0.18913881480693817\n",
      "trial: 1, epoch, 15, iter: 200, curr loss: 0.19136837124824524, avg loss: 0.18448168724775316\n",
      "trial: 1, epoch, 16, iter: 1, curr loss: 0.1882290542125702, avg loss: 0.1882290542125702\n",
      "trial: 1, epoch, 16, iter: 200, curr loss: 0.1790342926979065, avg loss: 0.1844343825429678\n",
      "trial: 1, epoch, 17, iter: 1, curr loss: 0.191654235124588, avg loss: 0.191654235124588\n",
      "trial: 1, epoch, 17, iter: 200, curr loss: 0.19541385769844055, avg loss: 0.1845731855928898\n",
      "trial: 1, epoch, 18, iter: 1, curr loss: 0.17574921250343323, avg loss: 0.17574921250343323\n",
      "trial: 1, epoch, 18, iter: 200, curr loss: 0.18639224767684937, avg loss: 0.18462912753224373\n",
      "trial: 1, epoch, 19, iter: 1, curr loss: 0.1817186176776886, avg loss: 0.1817186176776886\n",
      "trial: 1, epoch, 19, iter: 200, curr loss: 0.18815843760967255, avg loss: 0.18438994750380516\n",
      "trial: 1, epoch, 20, iter: 1, curr loss: 0.1838567554950714, avg loss: 0.1838567554950714\n",
      "trial: 1, epoch, 20, iter: 200, curr loss: 0.1802610456943512, avg loss: 0.18494428716599942\n",
      "trial: 1, epoch, 21, iter: 1, curr loss: 0.19596578180789948, avg loss: 0.19596578180789948\n",
      "trial: 1, epoch, 21, iter: 200, curr loss: 0.18354234099388123, avg loss: 0.18457160666584968\n",
      "trial: 1, epoch, 22, iter: 1, curr loss: 0.18998003005981445, avg loss: 0.18998003005981445\n",
      "trial: 1, epoch, 22, iter: 200, curr loss: 0.18833330273628235, avg loss: 0.18430545285344124\n",
      "trial: 1, epoch, 23, iter: 1, curr loss: 0.18493980169296265, avg loss: 0.18493980169296265\n",
      "trial: 1, epoch, 23, iter: 200, curr loss: 0.1866174042224884, avg loss: 0.18434642396867276\n",
      "trial: 1, epoch, 24, iter: 1, curr loss: 0.19115963578224182, avg loss: 0.19115963578224182\n",
      "trial: 1, epoch, 24, iter: 200, curr loss: 0.18952743709087372, avg loss: 0.18382923878729343\n",
      "trial: 1, epoch, 25, iter: 1, curr loss: 0.18980342149734497, avg loss: 0.18980342149734497\n",
      "trial: 1, epoch, 25, iter: 200, curr loss: 0.18989863991737366, avg loss: 0.18479999013245105\n",
      "trial: 1, epoch, 26, iter: 1, curr loss: 0.18905380368232727, avg loss: 0.18905380368232727\n",
      "trial: 1, epoch, 26, iter: 200, curr loss: 0.19187414646148682, avg loss: 0.18437379956245423\n",
      "trial: 1, epoch, 27, iter: 1, curr loss: 0.18187911808490753, avg loss: 0.18187911808490753\n",
      "trial: 1, epoch, 27, iter: 200, curr loss: 0.18758776783943176, avg loss: 0.18419906705617906\n",
      "trial: 1, epoch, 28, iter: 1, curr loss: 0.18673482537269592, avg loss: 0.18673482537269592\n",
      "trial: 1, epoch, 28, iter: 200, curr loss: 0.19029012322425842, avg loss: 0.18459821350872516\n",
      "trial: 1, epoch, 29, iter: 1, curr loss: 0.1799359917640686, avg loss: 0.1799359917640686\n",
      "trial: 1, epoch, 29, iter: 200, curr loss: 0.18172328174114227, avg loss: 0.1846009325236082\n",
      "trial: 1, epoch, 30, iter: 1, curr loss: 0.1818065345287323, avg loss: 0.1818065345287323\n",
      "trial: 1, epoch, 30, iter: 200, curr loss: 0.17949023842811584, avg loss: 0.18486807405948638\n",
      "trial: 1, epoch, 31, iter: 1, curr loss: 0.17934812605381012, avg loss: 0.17934812605381012\n",
      "trial: 1, epoch, 31, iter: 200, curr loss: 0.18765896558761597, avg loss: 0.18469674043357373\n",
      "trial: 1, epoch, 32, iter: 1, curr loss: 0.18605320155620575, avg loss: 0.18605320155620575\n",
      "trial: 1, epoch, 32, iter: 200, curr loss: 0.18820589780807495, avg loss: 0.18489187709987165\n",
      "trial: 1, epoch, 33, iter: 1, curr loss: 0.18737256526947021, avg loss: 0.18737256526947021\n",
      "trial: 1, epoch, 33, iter: 200, curr loss: 0.1863955557346344, avg loss: 0.1848921471834183\n",
      "trial: 1, epoch, 34, iter: 1, curr loss: 0.18877577781677246, avg loss: 0.18877577781677246\n",
      "trial: 1, epoch, 34, iter: 200, curr loss: 0.18897773325443268, avg loss: 0.18450442373752593\n",
      "trial: 1, epoch, 35, iter: 1, curr loss: 0.19202035665512085, avg loss: 0.19202035665512085\n",
      "trial: 1, epoch, 35, iter: 200, curr loss: 0.18371805548667908, avg loss: 0.18462568663060666\n",
      "trial: 1, epoch, 36, iter: 1, curr loss: 0.18642961978912354, avg loss: 0.18642961978912354\n",
      "trial: 1, epoch, 36, iter: 200, curr loss: 0.19194594025611877, avg loss: 0.18443463794887066\n",
      "trial: 1, epoch, 37, iter: 1, curr loss: 0.18676777184009552, avg loss: 0.18676777184009552\n",
      "trial: 1, epoch, 37, iter: 200, curr loss: 0.18213516473770142, avg loss: 0.1842332748323679\n",
      "trial: 1, epoch, 38, iter: 1, curr loss: 0.18804700672626495, avg loss: 0.18804700672626495\n",
      "trial: 1, epoch, 38, iter: 200, curr loss: 0.18867707252502441, avg loss: 0.18469192519783972\n",
      "trial: 1, epoch, 39, iter: 1, curr loss: 0.18329444527626038, avg loss: 0.18329444527626038\n",
      "trial: 1, epoch, 39, iter: 200, curr loss: 0.19105994701385498, avg loss: 0.18481407813727857\n",
      "trial: 1, epoch, 40, iter: 1, curr loss: 0.18740907311439514, avg loss: 0.18740907311439514\n",
      "trial: 1, epoch, 40, iter: 200, curr loss: 0.18494029343128204, avg loss: 0.1845352378487587\n",
      "trial: 1, epoch, 41, iter: 1, curr loss: 0.19164645671844482, avg loss: 0.19164645671844482\n",
      "trial: 1, epoch, 41, iter: 200, curr loss: 0.1839473396539688, avg loss: 0.18463427148759365\n",
      "trial: 1, epoch, 42, iter: 1, curr loss: 0.18046128749847412, avg loss: 0.18046128749847412\n",
      "trial: 1, epoch, 42, iter: 200, curr loss: 0.18397901952266693, avg loss: 0.18403336346149446\n",
      "trial: 1, epoch, 43, iter: 1, curr loss: 0.18354392051696777, avg loss: 0.18354392051696777\n",
      "trial: 1, epoch, 43, iter: 200, curr loss: 0.1764189600944519, avg loss: 0.18414759904146194\n",
      "trial: 1, epoch, 44, iter: 1, curr loss: 0.18303059041500092, avg loss: 0.18303059041500092\n",
      "trial: 1, epoch, 44, iter: 200, curr loss: 0.18394342064857483, avg loss: 0.1842028308659792\n",
      "trial: 1, epoch, 45, iter: 1, curr loss: 0.18505170941352844, avg loss: 0.18505170941352844\n",
      "trial: 1, epoch, 45, iter: 200, curr loss: 0.19501304626464844, avg loss: 0.18527330689132213\n",
      "trial: 1, epoch, 46, iter: 1, curr loss: 0.18843892216682434, avg loss: 0.18843892216682434\n",
      "trial: 1, epoch, 46, iter: 200, curr loss: 0.18194109201431274, avg loss: 0.1847079649567604\n",
      "trial: 1, epoch, 47, iter: 1, curr loss: 0.18567118048667908, avg loss: 0.18567118048667908\n",
      "trial: 1, epoch, 47, iter: 200, curr loss: 0.18680104613304138, avg loss: 0.1845335803925991\n",
      "trial: 1, epoch, 48, iter: 1, curr loss: 0.1796865463256836, avg loss: 0.1796865463256836\n",
      "trial: 1, epoch, 48, iter: 200, curr loss: 0.18859276175498962, avg loss: 0.1847388394922018\n",
      "trial: 1, epoch, 49, iter: 1, curr loss: 0.19489827752113342, avg loss: 0.19489827752113342\n",
      "trial: 1, epoch, 49, iter: 200, curr loss: 0.18196134269237518, avg loss: 0.1848037675023079\n",
      "trial: 1, epoch, 50, iter: 1, curr loss: 0.1870305836200714, avg loss: 0.1870305836200714\n",
      "trial: 1, epoch, 50, iter: 200, curr loss: 0.1884974092245102, avg loss: 0.1844100809842348\n",
      "trial: 1, ldr: 18.38945198059082, dv: 19.783626556396484, nwj: 19.141414642333984\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, epoch, 1, iter: 1, curr loss: 0.6940871477127075, avg loss: 0.6940871477127075\n",
      "trial: 2, epoch, 1, iter: 200, curr loss: 0.1918410062789917, avg loss: 0.2267565581202507\n",
      "trial: 2, epoch, 2, iter: 1, curr loss: 0.19374918937683105, avg loss: 0.19374918937683105\n",
      "trial: 2, epoch, 2, iter: 200, curr loss: 0.18985262513160706, avg loss: 0.186379878744483\n",
      "trial: 2, epoch, 3, iter: 1, curr loss: 0.18679049611091614, avg loss: 0.18679049611091614\n",
      "trial: 2, epoch, 3, iter: 200, curr loss: 0.1894238144159317, avg loss: 0.18612088538706303\n",
      "trial: 2, epoch, 4, iter: 1, curr loss: 0.18658889830112457, avg loss: 0.18658889830112457\n",
      "trial: 2, epoch, 4, iter: 200, curr loss: 0.1826649010181427, avg loss: 0.18489498056471348\n",
      "trial: 2, epoch, 5, iter: 1, curr loss: 0.18975484371185303, avg loss: 0.18975484371185303\n",
      "trial: 2, epoch, 5, iter: 200, curr loss: 0.1828443855047226, avg loss: 0.18465477660298346\n",
      "trial: 2, epoch, 6, iter: 1, curr loss: 0.18725153803825378, avg loss: 0.18725153803825378\n",
      "trial: 2, epoch, 6, iter: 200, curr loss: 0.18467998504638672, avg loss: 0.1848293485492468\n",
      "trial: 2, epoch, 7, iter: 1, curr loss: 0.18860435485839844, avg loss: 0.18860435485839844\n",
      "trial: 2, epoch, 7, iter: 200, curr loss: 0.18944776058197021, avg loss: 0.18408266678452492\n",
      "trial: 2, epoch, 8, iter: 1, curr loss: 0.18748623132705688, avg loss: 0.18748623132705688\n",
      "trial: 2, epoch, 8, iter: 200, curr loss: 0.18048515915870667, avg loss: 0.18444514878094195\n",
      "trial: 2, epoch, 9, iter: 1, curr loss: 0.1867981255054474, avg loss: 0.1867981255054474\n",
      "trial: 2, epoch, 9, iter: 200, curr loss: 0.18694783747196198, avg loss: 0.18468955911695958\n",
      "trial: 2, epoch, 10, iter: 1, curr loss: 0.18711815774440765, avg loss: 0.18711815774440765\n",
      "trial: 2, epoch, 10, iter: 200, curr loss: 0.1874867081642151, avg loss: 0.18471230417490006\n",
      "trial: 2, epoch, 11, iter: 1, curr loss: 0.17647776007652283, avg loss: 0.17647776007652283\n",
      "trial: 2, epoch, 11, iter: 200, curr loss: 0.1886843591928482, avg loss: 0.1845150397717953\n",
      "trial: 2, epoch, 12, iter: 1, curr loss: 0.17787085473537445, avg loss: 0.17787085473537445\n",
      "trial: 2, epoch, 12, iter: 200, curr loss: 0.18856287002563477, avg loss: 0.18406008638441562\n",
      "trial: 2, epoch, 13, iter: 1, curr loss: 0.18335068225860596, avg loss: 0.18335068225860596\n",
      "trial: 2, epoch, 13, iter: 200, curr loss: 0.19172251224517822, avg loss: 0.18430199317634105\n",
      "trial: 2, epoch, 14, iter: 1, curr loss: 0.18963134288787842, avg loss: 0.18963134288787842\n",
      "trial: 2, epoch, 14, iter: 200, curr loss: 0.18296466767787933, avg loss: 0.18461018234491347\n",
      "trial: 2, epoch, 15, iter: 1, curr loss: 0.18310867249965668, avg loss: 0.18310867249965668\n",
      "trial: 2, epoch, 15, iter: 200, curr loss: 0.1887463927268982, avg loss: 0.18449069239199162\n",
      "trial: 2, epoch, 16, iter: 1, curr loss: 0.1750382035970688, avg loss: 0.1750382035970688\n",
      "trial: 2, epoch, 16, iter: 200, curr loss: 0.17983029782772064, avg loss: 0.1845312451571226\n",
      "trial: 2, epoch, 17, iter: 1, curr loss: 0.18044513463974, avg loss: 0.18044513463974\n",
      "trial: 2, epoch, 17, iter: 200, curr loss: 0.18059664964675903, avg loss: 0.1850384657084942\n",
      "trial: 2, epoch, 18, iter: 1, curr loss: 0.18652714788913727, avg loss: 0.18652714788913727\n",
      "trial: 2, epoch, 18, iter: 200, curr loss: 0.18584394454956055, avg loss: 0.18458372235298157\n",
      "trial: 2, epoch, 19, iter: 1, curr loss: 0.1748075634241104, avg loss: 0.1748075634241104\n",
      "trial: 2, epoch, 19, iter: 200, curr loss: 0.1890082061290741, avg loss: 0.18421045683324336\n",
      "trial: 2, epoch, 20, iter: 1, curr loss: 0.18567831814289093, avg loss: 0.18567831814289093\n",
      "trial: 2, epoch, 20, iter: 200, curr loss: 0.18398058414459229, avg loss: 0.18450068674981593\n",
      "trial: 2, epoch, 21, iter: 1, curr loss: 0.1932542622089386, avg loss: 0.1932542622089386\n",
      "trial: 2, epoch, 21, iter: 200, curr loss: 0.19004198908805847, avg loss: 0.18468376949429513\n",
      "trial: 2, epoch, 22, iter: 1, curr loss: 0.19384896755218506, avg loss: 0.19384896755218506\n",
      "trial: 2, epoch, 22, iter: 200, curr loss: 0.18056076765060425, avg loss: 0.18473694302141666\n",
      "trial: 2, epoch, 23, iter: 1, curr loss: 0.18360047042369843, avg loss: 0.18360047042369843\n",
      "trial: 2, epoch, 23, iter: 200, curr loss: 0.18391475081443787, avg loss: 0.1843561802059412\n",
      "trial: 2, epoch, 24, iter: 1, curr loss: 0.19122785329818726, avg loss: 0.19122785329818726\n",
      "trial: 2, epoch, 24, iter: 200, curr loss: 0.18501229584217072, avg loss: 0.18470752872526647\n",
      "trial: 2, epoch, 25, iter: 1, curr loss: 0.19175714254379272, avg loss: 0.19175714254379272\n",
      "trial: 2, epoch, 25, iter: 200, curr loss: 0.1831739991903305, avg loss: 0.18468535132706165\n",
      "trial: 2, epoch, 26, iter: 1, curr loss: 0.1906309425830841, avg loss: 0.1906309425830841\n",
      "trial: 2, epoch, 26, iter: 200, curr loss: 0.18946054577827454, avg loss: 0.18459992498159408\n",
      "trial: 2, epoch, 27, iter: 1, curr loss: 0.17806215584278107, avg loss: 0.17806215584278107\n",
      "trial: 2, epoch, 27, iter: 200, curr loss: 0.1856861412525177, avg loss: 0.184656448289752\n",
      "trial: 2, epoch, 28, iter: 1, curr loss: 0.18576866388320923, avg loss: 0.18576866388320923\n",
      "trial: 2, epoch, 28, iter: 200, curr loss: 0.1861175149679184, avg loss: 0.18495186433196067\n",
      "trial: 2, epoch, 29, iter: 1, curr loss: 0.1773703396320343, avg loss: 0.1773703396320343\n",
      "trial: 2, epoch, 29, iter: 200, curr loss: 0.1753120720386505, avg loss: 0.18444968670606612\n",
      "trial: 2, epoch, 30, iter: 1, curr loss: 0.18573841452598572, avg loss: 0.18573841452598572\n",
      "trial: 2, epoch, 30, iter: 200, curr loss: 0.179521843791008, avg loss: 0.18453975729644298\n",
      "trial: 2, epoch, 31, iter: 1, curr loss: 0.18426059186458588, avg loss: 0.18426059186458588\n",
      "trial: 2, epoch, 31, iter: 200, curr loss: 0.17957782745361328, avg loss: 0.1845762611180544\n",
      "trial: 2, epoch, 32, iter: 1, curr loss: 0.19071970880031586, avg loss: 0.19071970880031586\n",
      "trial: 2, epoch, 32, iter: 200, curr loss: 0.18895122408866882, avg loss: 0.18457083106040956\n",
      "trial: 2, epoch, 33, iter: 1, curr loss: 0.19123312830924988, avg loss: 0.19123312830924988\n",
      "trial: 2, epoch, 33, iter: 200, curr loss: 0.17929613590240479, avg loss: 0.18453647524118424\n",
      "trial: 2, epoch, 34, iter: 1, curr loss: 0.18670713901519775, avg loss: 0.18670713901519775\n",
      "trial: 2, epoch, 34, iter: 200, curr loss: 0.1820807307958603, avg loss: 0.18994664333760738\n",
      "trial: 2, epoch, 35, iter: 1, curr loss: 0.1804257035255432, avg loss: 0.1804257035255432\n",
      "trial: 2, epoch, 35, iter: 200, curr loss: 0.1761469542980194, avg loss: 0.1841145434230566\n",
      "trial: 2, epoch, 36, iter: 1, curr loss: 0.17999424040317535, avg loss: 0.17999424040317535\n",
      "trial: 2, epoch, 36, iter: 200, curr loss: 0.19315332174301147, avg loss: 0.18442421913146972\n",
      "trial: 2, epoch, 37, iter: 1, curr loss: 0.18474793434143066, avg loss: 0.18474793434143066\n",
      "trial: 2, epoch, 37, iter: 200, curr loss: 0.1758042722940445, avg loss: 0.18464339539408683\n",
      "trial: 2, epoch, 38, iter: 1, curr loss: 0.1908736675977707, avg loss: 0.1908736675977707\n",
      "trial: 2, epoch, 38, iter: 200, curr loss: 0.17981389164924622, avg loss: 0.18424501977860927\n",
      "trial: 2, epoch, 39, iter: 1, curr loss: 0.1875605434179306, avg loss: 0.1875605434179306\n",
      "trial: 2, epoch, 39, iter: 200, curr loss: 0.18289433419704437, avg loss: 0.18475743420422078\n",
      "trial: 2, epoch, 40, iter: 1, curr loss: 0.18618105351924896, avg loss: 0.18618105351924896\n",
      "trial: 2, epoch, 40, iter: 200, curr loss: 0.1894274353981018, avg loss: 0.18434172585606576\n",
      "trial: 2, epoch, 41, iter: 1, curr loss: 0.1874685287475586, avg loss: 0.1874685287475586\n",
      "trial: 2, epoch, 41, iter: 200, curr loss: 0.19159436225891113, avg loss: 0.1843798293918371\n",
      "trial: 2, epoch, 42, iter: 1, curr loss: 0.18600164353847504, avg loss: 0.18600164353847504\n",
      "trial: 2, epoch, 42, iter: 200, curr loss: 0.1862800419330597, avg loss: 0.18459839284420013\n",
      "trial: 2, epoch, 43, iter: 1, curr loss: 0.1905592381954193, avg loss: 0.1905592381954193\n",
      "trial: 2, epoch, 43, iter: 200, curr loss: 0.1915900856256485, avg loss: 0.1848951952904463\n",
      "trial: 2, epoch, 44, iter: 1, curr loss: 0.19001302123069763, avg loss: 0.19001302123069763\n",
      "trial: 2, epoch, 44, iter: 200, curr loss: 0.1834440380334854, avg loss: 0.18424361057579516\n",
      "trial: 2, epoch, 45, iter: 1, curr loss: 0.18896132707595825, avg loss: 0.18896132707595825\n",
      "trial: 2, epoch, 45, iter: 200, curr loss: 0.18058061599731445, avg loss: 0.1838417835533619\n",
      "trial: 2, epoch, 46, iter: 1, curr loss: 0.1881093978881836, avg loss: 0.1881093978881836\n",
      "trial: 2, epoch, 46, iter: 200, curr loss: 0.19641247391700745, avg loss: 0.18404102511703968\n",
      "trial: 2, epoch, 47, iter: 1, curr loss: 0.18913182616233826, avg loss: 0.18913182616233826\n",
      "trial: 2, epoch, 47, iter: 200, curr loss: 0.18186479806900024, avg loss: 0.18419895105063916\n",
      "trial: 2, epoch, 48, iter: 1, curr loss: 0.17614160478115082, avg loss: 0.17614160478115082\n",
      "trial: 2, epoch, 48, iter: 200, curr loss: 0.18433257937431335, avg loss: 0.18461780555546284\n",
      "trial: 2, epoch, 49, iter: 1, curr loss: 0.18201453983783722, avg loss: 0.18201453983783722\n",
      "trial: 2, epoch, 49, iter: 200, curr loss: 0.1847560703754425, avg loss: 0.1847719093412161\n",
      "trial: 2, epoch, 50, iter: 1, curr loss: 0.18659895658493042, avg loss: 0.18659895658493042\n",
      "trial: 2, epoch, 50, iter: 200, curr loss: 0.185244619846344, avg loss: 0.18447791472077368\n",
      "trial: 2, ldr: 16.666339874267578, dv: 18.045425415039062, nwj: 17.414531707763672\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, epoch, 1, iter: 1, curr loss: 0.6945739388465881, avg loss: 0.6945739388465881\n",
      "trial: 3, epoch, 1, iter: 200, curr loss: 0.18499109148979187, avg loss: 0.2290821824967861\n",
      "trial: 3, epoch, 2, iter: 1, curr loss: 0.18877387046813965, avg loss: 0.18877387046813965\n",
      "trial: 3, epoch, 2, iter: 200, curr loss: 0.18784363567829132, avg loss: 0.18618912644684316\n",
      "trial: 3, epoch, 3, iter: 1, curr loss: 0.1855546534061432, avg loss: 0.1855546534061432\n",
      "trial: 3, epoch, 3, iter: 200, curr loss: 0.1824541836977005, avg loss: 0.18544907666742802\n",
      "trial: 3, epoch, 4, iter: 1, curr loss: 0.1904883086681366, avg loss: 0.1904883086681366\n",
      "trial: 3, epoch, 4, iter: 200, curr loss: 0.18990741670131683, avg loss: 0.185238805860281\n",
      "trial: 3, epoch, 5, iter: 1, curr loss: 0.19701075553894043, avg loss: 0.19701075553894043\n",
      "trial: 3, epoch, 5, iter: 200, curr loss: 0.18133369088172913, avg loss: 0.184841321259737\n",
      "trial: 3, epoch, 6, iter: 1, curr loss: 0.18675261735916138, avg loss: 0.18675261735916138\n",
      "trial: 3, epoch, 6, iter: 200, curr loss: 0.18290939927101135, avg loss: 0.1843789705634117\n",
      "trial: 3, epoch, 7, iter: 1, curr loss: 0.18467217683792114, avg loss: 0.18467217683792114\n",
      "trial: 3, epoch, 7, iter: 200, curr loss: 0.1825941950082779, avg loss: 0.18460968688130378\n",
      "trial: 3, epoch, 8, iter: 1, curr loss: 0.18872040510177612, avg loss: 0.18872040510177612\n",
      "trial: 3, epoch, 8, iter: 200, curr loss: 0.19164124131202698, avg loss: 0.18467378303408621\n",
      "trial: 3, epoch, 9, iter: 1, curr loss: 0.18634581565856934, avg loss: 0.18634581565856934\n",
      "trial: 3, epoch, 9, iter: 200, curr loss: 0.18003304302692413, avg loss: 0.18478439137339592\n",
      "trial: 3, epoch, 10, iter: 1, curr loss: 0.19181162118911743, avg loss: 0.19181162118911743\n",
      "trial: 3, epoch, 10, iter: 200, curr loss: 0.18166661262512207, avg loss: 0.18484832234680654\n",
      "trial: 3, epoch, 11, iter: 1, curr loss: 0.18896658718585968, avg loss: 0.18896658718585968\n",
      "trial: 3, epoch, 11, iter: 200, curr loss: 0.19389143586158752, avg loss: 0.18464288100600243\n",
      "trial: 3, epoch, 12, iter: 1, curr loss: 0.18400543928146362, avg loss: 0.18400543928146362\n",
      "trial: 3, epoch, 12, iter: 200, curr loss: 0.1944282203912735, avg loss: 0.18399604812264442\n",
      "trial: 3, epoch, 13, iter: 1, curr loss: 0.187008798122406, avg loss: 0.187008798122406\n",
      "trial: 3, epoch, 13, iter: 200, curr loss: 0.17799405753612518, avg loss: 0.1843557161092758\n",
      "trial: 3, epoch, 14, iter: 1, curr loss: 0.18412089347839355, avg loss: 0.18412089347839355\n",
      "trial: 3, epoch, 14, iter: 200, curr loss: 0.19535520672798157, avg loss: 0.18407293781638145\n",
      "trial: 3, epoch, 15, iter: 1, curr loss: 0.18440796434879303, avg loss: 0.18440796434879303\n",
      "trial: 3, epoch, 15, iter: 200, curr loss: 0.18578845262527466, avg loss: 0.18467933773994447\n",
      "trial: 3, epoch, 16, iter: 1, curr loss: 0.17951884865760803, avg loss: 0.17951884865760803\n",
      "trial: 3, epoch, 16, iter: 200, curr loss: 0.18706627190113068, avg loss: 0.18456421218812466\n",
      "trial: 3, epoch, 17, iter: 1, curr loss: 0.18489506840705872, avg loss: 0.18489506840705872\n",
      "trial: 3, epoch, 17, iter: 200, curr loss: 0.17020206153392792, avg loss: 0.18430584765970706\n",
      "trial: 3, epoch, 18, iter: 1, curr loss: 0.18383300304412842, avg loss: 0.18383300304412842\n",
      "trial: 3, epoch, 18, iter: 200, curr loss: 0.18215472996234894, avg loss: 0.1845789311081171\n",
      "trial: 3, epoch, 19, iter: 1, curr loss: 0.18370625376701355, avg loss: 0.18370625376701355\n",
      "trial: 3, epoch, 19, iter: 200, curr loss: 0.18012386560440063, avg loss: 0.18413186125457287\n",
      "trial: 3, epoch, 20, iter: 1, curr loss: 0.192001610994339, avg loss: 0.192001610994339\n",
      "trial: 3, epoch, 20, iter: 200, curr loss: 0.19256806373596191, avg loss: 0.1848943092674017\n",
      "trial: 3, epoch, 21, iter: 1, curr loss: 0.1883099228143692, avg loss: 0.1883099228143692\n",
      "trial: 3, epoch, 21, iter: 200, curr loss: 0.19374528527259827, avg loss: 0.1844701486080885\n",
      "trial: 3, epoch, 22, iter: 1, curr loss: 0.1823800802230835, avg loss: 0.1823800802230835\n",
      "trial: 3, epoch, 22, iter: 200, curr loss: 0.18728551268577576, avg loss: 0.1841603695601225\n",
      "trial: 3, epoch, 23, iter: 1, curr loss: 0.18218423426151276, avg loss: 0.18218423426151276\n",
      "trial: 3, epoch, 23, iter: 200, curr loss: 0.18105155229568481, avg loss: 0.18459683939814567\n",
      "trial: 3, epoch, 24, iter: 1, curr loss: 0.1924969106912613, avg loss: 0.1924969106912613\n",
      "trial: 3, epoch, 24, iter: 200, curr loss: 0.1908634603023529, avg loss: 0.18427811823785306\n",
      "trial: 3, epoch, 25, iter: 1, curr loss: 0.19348347187042236, avg loss: 0.19348347187042236\n",
      "trial: 3, epoch, 25, iter: 200, curr loss: 0.1884058117866516, avg loss: 0.18482337683439254\n",
      "trial: 3, epoch, 26, iter: 1, curr loss: 0.19236555695533752, avg loss: 0.19236555695533752\n",
      "trial: 3, epoch, 26, iter: 200, curr loss: 0.1866045594215393, avg loss: 0.18435181878507137\n",
      "trial: 3, epoch, 27, iter: 1, curr loss: 0.18409664928913116, avg loss: 0.18409664928913116\n",
      "trial: 3, epoch, 27, iter: 200, curr loss: 0.1799415647983551, avg loss: 0.18450693920254707\n",
      "trial: 3, epoch, 28, iter: 1, curr loss: 0.1808864176273346, avg loss: 0.1808864176273346\n",
      "trial: 3, epoch, 28, iter: 200, curr loss: 0.1825902760028839, avg loss: 0.1842636524140835\n",
      "trial: 3, epoch, 29, iter: 1, curr loss: 0.18430334329605103, avg loss: 0.18430334329605103\n",
      "trial: 3, epoch, 29, iter: 200, curr loss: 0.18763548135757446, avg loss: 0.18459321215748786\n",
      "trial: 3, epoch, 30, iter: 1, curr loss: 0.1753551959991455, avg loss: 0.1753551959991455\n",
      "trial: 3, epoch, 30, iter: 200, curr loss: 0.18243096768856049, avg loss: 0.18431435965001583\n",
      "trial: 3, epoch, 31, iter: 1, curr loss: 0.18336710333824158, avg loss: 0.18336710333824158\n",
      "trial: 3, epoch, 31, iter: 200, curr loss: 0.18761104345321655, avg loss: 0.18456646643579006\n",
      "trial: 3, epoch, 32, iter: 1, curr loss: 0.18816035985946655, avg loss: 0.18816035985946655\n",
      "trial: 3, epoch, 32, iter: 200, curr loss: 0.18549039959907532, avg loss: 0.18437842689454556\n",
      "trial: 3, epoch, 33, iter: 1, curr loss: 0.18425270915031433, avg loss: 0.18425270915031433\n",
      "trial: 3, epoch, 33, iter: 200, curr loss: 0.1941256821155548, avg loss: 0.18418902434408665\n",
      "trial: 3, epoch, 34, iter: 1, curr loss: 0.19142723083496094, avg loss: 0.19142723083496094\n",
      "trial: 3, epoch, 34, iter: 200, curr loss: 0.18524500727653503, avg loss: 0.18444351620972158\n",
      "trial: 3, epoch, 35, iter: 1, curr loss: 0.18627601861953735, avg loss: 0.18627601861953735\n",
      "trial: 3, epoch, 35, iter: 200, curr loss: 0.1883762925863266, avg loss: 0.18498351722955703\n",
      "trial: 3, epoch, 36, iter: 1, curr loss: 0.18880003690719604, avg loss: 0.18880003690719604\n",
      "trial: 3, epoch, 36, iter: 200, curr loss: 0.18336430191993713, avg loss: 0.18453245013952255\n",
      "trial: 3, epoch, 37, iter: 1, curr loss: 0.19181954860687256, avg loss: 0.19181954860687256\n",
      "trial: 3, epoch, 37, iter: 200, curr loss: 0.18887758255004883, avg loss: 0.18418172679841519\n",
      "trial: 3, epoch, 38, iter: 1, curr loss: 0.18778571486473083, avg loss: 0.18778571486473083\n",
      "trial: 3, epoch, 38, iter: 200, curr loss: 0.17550916969776154, avg loss: 0.18456536136567592\n",
      "trial: 3, epoch, 39, iter: 1, curr loss: 0.18471866846084595, avg loss: 0.18471866846084595\n",
      "trial: 3, epoch, 39, iter: 200, curr loss: 0.1914491057395935, avg loss: 0.1844796035438776\n",
      "trial: 3, epoch, 40, iter: 1, curr loss: 0.18663504719734192, avg loss: 0.18663504719734192\n",
      "trial: 3, epoch, 40, iter: 200, curr loss: 0.19113126397132874, avg loss: 0.18426965311169624\n",
      "trial: 3, epoch, 41, iter: 1, curr loss: 0.18675628304481506, avg loss: 0.18675628304481506\n",
      "trial: 3, epoch, 41, iter: 200, curr loss: 0.18440860509872437, avg loss: 0.1840893279761076\n",
      "trial: 3, epoch, 42, iter: 1, curr loss: 0.174997940659523, avg loss: 0.174997940659523\n",
      "trial: 3, epoch, 42, iter: 200, curr loss: 0.18056915700435638, avg loss: 0.18463009774684905\n",
      "trial: 3, epoch, 43, iter: 1, curr loss: 0.18101300299167633, avg loss: 0.18101300299167633\n",
      "trial: 3, epoch, 43, iter: 200, curr loss: 0.19041825830936432, avg loss: 0.18416986718773842\n",
      "trial: 3, epoch, 44, iter: 1, curr loss: 0.18327069282531738, avg loss: 0.18327069282531738\n",
      "trial: 3, epoch, 44, iter: 200, curr loss: 0.18712462484836578, avg loss: 0.18403531476855278\n",
      "trial: 3, epoch, 45, iter: 1, curr loss: 0.18514978885650635, avg loss: 0.18514978885650635\n",
      "trial: 3, epoch, 45, iter: 200, curr loss: 0.17968182265758514, avg loss: 0.18446860045194627\n",
      "trial: 3, epoch, 46, iter: 1, curr loss: 0.1939006745815277, avg loss: 0.1939006745815277\n",
      "trial: 3, epoch, 46, iter: 200, curr loss: 0.1841360628604889, avg loss: 0.18410193242132664\n",
      "trial: 3, epoch, 47, iter: 1, curr loss: 0.1924147605895996, avg loss: 0.1924147605895996\n",
      "trial: 3, epoch, 47, iter: 200, curr loss: 0.18433398008346558, avg loss: 0.18454841583967208\n",
      "trial: 3, epoch, 48, iter: 1, curr loss: 0.18738138675689697, avg loss: 0.18738138675689697\n",
      "trial: 3, epoch, 48, iter: 200, curr loss: 0.18143945932388306, avg loss: 0.18438369974493982\n",
      "trial: 3, epoch, 49, iter: 1, curr loss: 0.18473580479621887, avg loss: 0.18473580479621887\n",
      "trial: 3, epoch, 49, iter: 200, curr loss: 0.17657339572906494, avg loss: 0.18467050574719907\n",
      "trial: 3, epoch, 50, iter: 1, curr loss: 0.18636246025562286, avg loss: 0.18636246025562286\n",
      "trial: 3, epoch, 50, iter: 200, curr loss: 0.18377336859703064, avg loss: 0.18460986502468585\n",
      "trial: 3, ldr: 20.915019989013672, dv: 22.296405792236328, nwj: 21.663789749145508\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, epoch, 1, iter: 1, curr loss: 0.6932898163795471, avg loss: 0.6932898163795471\n",
      "trial: 4, epoch, 1, iter: 200, curr loss: 0.18809549510478973, avg loss: 0.22778871707618237\n",
      "trial: 4, epoch, 2, iter: 1, curr loss: 0.18406939506530762, avg loss: 0.18406939506530762\n",
      "trial: 4, epoch, 2, iter: 200, curr loss: 0.19118106365203857, avg loss: 0.18701803244650364\n",
      "trial: 4, epoch, 3, iter: 1, curr loss: 0.19921815395355225, avg loss: 0.19921815395355225\n",
      "trial: 4, epoch, 3, iter: 200, curr loss: 0.18007512390613556, avg loss: 0.1858223583549261\n",
      "trial: 4, epoch, 4, iter: 1, curr loss: 0.18868234753608704, avg loss: 0.18868234753608704\n",
      "trial: 4, epoch, 4, iter: 200, curr loss: 0.1943640261888504, avg loss: 0.18530362524092198\n",
      "trial: 4, epoch, 5, iter: 1, curr loss: 0.1822527050971985, avg loss: 0.1822527050971985\n",
      "trial: 4, epoch, 5, iter: 200, curr loss: 0.18579931557178497, avg loss: 0.18489943869411946\n",
      "trial: 4, epoch, 6, iter: 1, curr loss: 0.1836082637310028, avg loss: 0.1836082637310028\n",
      "trial: 4, epoch, 6, iter: 200, curr loss: 0.19050194323062897, avg loss: 0.18485238455235958\n",
      "trial: 4, epoch, 7, iter: 1, curr loss: 0.17840832471847534, avg loss: 0.17840832471847534\n",
      "trial: 4, epoch, 7, iter: 200, curr loss: 0.18271422386169434, avg loss: 0.1846336444467306\n",
      "trial: 4, epoch, 8, iter: 1, curr loss: 0.17919450998306274, avg loss: 0.17919450998306274\n",
      "trial: 4, epoch, 8, iter: 200, curr loss: 0.18351271748542786, avg loss: 0.1842827917635441\n",
      "trial: 4, epoch, 9, iter: 1, curr loss: 0.18412497639656067, avg loss: 0.18412497639656067\n",
      "trial: 4, epoch, 9, iter: 200, curr loss: 0.191427081823349, avg loss: 0.1843708349764347\n",
      "trial: 4, epoch, 10, iter: 1, curr loss: 0.18877148628234863, avg loss: 0.18877148628234863\n",
      "trial: 4, epoch, 10, iter: 200, curr loss: 0.19064483046531677, avg loss: 0.18464791767299174\n",
      "trial: 4, epoch, 11, iter: 1, curr loss: 0.18677754700183868, avg loss: 0.18677754700183868\n",
      "trial: 4, epoch, 11, iter: 200, curr loss: 0.1839432716369629, avg loss: 0.18491851940751075\n",
      "trial: 4, epoch, 12, iter: 1, curr loss: 0.184556245803833, avg loss: 0.184556245803833\n",
      "trial: 4, epoch, 12, iter: 200, curr loss: 0.1892997920513153, avg loss: 0.18446346193552018\n",
      "trial: 4, epoch, 13, iter: 1, curr loss: 0.1725231409072876, avg loss: 0.1725231409072876\n",
      "trial: 4, epoch, 13, iter: 200, curr loss: 0.18630462884902954, avg loss: 0.18484290361404418\n",
      "trial: 4, epoch, 14, iter: 1, curr loss: 0.18972831964492798, avg loss: 0.18972831964492798\n",
      "trial: 4, epoch, 14, iter: 200, curr loss: 0.1915280520915985, avg loss: 0.1847626792639494\n",
      "trial: 4, epoch, 15, iter: 1, curr loss: 0.18283504247665405, avg loss: 0.18283504247665405\n",
      "trial: 4, epoch, 15, iter: 200, curr loss: 0.18116778135299683, avg loss: 0.18439762122929096\n",
      "trial: 4, epoch, 16, iter: 1, curr loss: 0.18434232473373413, avg loss: 0.18434232473373413\n",
      "trial: 4, epoch, 16, iter: 200, curr loss: 0.1944390833377838, avg loss: 0.18459069527685643\n",
      "trial: 4, epoch, 17, iter: 1, curr loss: 0.197581946849823, avg loss: 0.197581946849823\n",
      "trial: 4, epoch, 17, iter: 200, curr loss: 0.18462252616882324, avg loss: 0.18445323161780836\n",
      "trial: 4, epoch, 18, iter: 1, curr loss: 0.18661105632781982, avg loss: 0.18661105632781982\n",
      "trial: 4, epoch, 18, iter: 200, curr loss: 0.19447822868824005, avg loss: 0.18423699639737606\n",
      "trial: 4, epoch, 19, iter: 1, curr loss: 0.17447856068611145, avg loss: 0.17447856068611145\n",
      "trial: 4, epoch, 19, iter: 200, curr loss: 0.1804952472448349, avg loss: 0.18444877207279206\n",
      "trial: 4, epoch, 20, iter: 1, curr loss: 0.19173264503479004, avg loss: 0.19173264503479004\n",
      "trial: 4, epoch, 20, iter: 200, curr loss: 0.192124605178833, avg loss: 0.18440165646374226\n",
      "trial: 4, epoch, 21, iter: 1, curr loss: 0.18410177528858185, avg loss: 0.18410177528858185\n",
      "trial: 4, epoch, 21, iter: 200, curr loss: 0.18273049592971802, avg loss: 0.18428991608321665\n",
      "trial: 4, epoch, 22, iter: 1, curr loss: 0.18633651733398438, avg loss: 0.18633651733398438\n",
      "trial: 4, epoch, 22, iter: 200, curr loss: 0.1954362541437149, avg loss: 0.18477034226059913\n",
      "trial: 4, epoch, 23, iter: 1, curr loss: 0.19183588027954102, avg loss: 0.19183588027954102\n",
      "trial: 4, epoch, 23, iter: 200, curr loss: 0.18477694690227509, avg loss: 0.1843039768189192\n",
      "trial: 4, epoch, 24, iter: 1, curr loss: 0.1869937777519226, avg loss: 0.1869937777519226\n",
      "trial: 4, epoch, 24, iter: 200, curr loss: 0.1820540726184845, avg loss: 0.18452026590704917\n",
      "trial: 4, epoch, 25, iter: 1, curr loss: 0.1922597438097, avg loss: 0.1922597438097\n",
      "trial: 4, epoch, 25, iter: 200, curr loss: 0.19233186542987823, avg loss: 0.18496212430298328\n",
      "trial: 4, epoch, 26, iter: 1, curr loss: 0.18474146723747253, avg loss: 0.18474146723747253\n",
      "trial: 4, epoch, 26, iter: 200, curr loss: 0.18731921911239624, avg loss: 0.18436173982918264\n",
      "trial: 4, epoch, 27, iter: 1, curr loss: 0.18979933857917786, avg loss: 0.18979933857917786\n",
      "trial: 4, epoch, 27, iter: 200, curr loss: 0.1861361712217331, avg loss: 0.18447974510490894\n",
      "trial: 4, epoch, 28, iter: 1, curr loss: 0.18618838489055634, avg loss: 0.18618838489055634\n",
      "trial: 4, epoch, 28, iter: 200, curr loss: 0.19300609827041626, avg loss: 0.18481027588248253\n",
      "trial: 4, epoch, 29, iter: 1, curr loss: 0.18351037800312042, avg loss: 0.18351037800312042\n",
      "trial: 4, epoch, 29, iter: 200, curr loss: 0.18461337685585022, avg loss: 0.18410556241869927\n",
      "trial: 4, epoch, 30, iter: 1, curr loss: 0.19061873853206635, avg loss: 0.19061873853206635\n",
      "trial: 4, epoch, 30, iter: 200, curr loss: 0.19186973571777344, avg loss: 0.1849367420375347\n",
      "trial: 4, epoch, 31, iter: 1, curr loss: 0.18997564911842346, avg loss: 0.18997564911842346\n",
      "trial: 4, epoch, 31, iter: 200, curr loss: 0.18830406665802002, avg loss: 0.18462563179433344\n",
      "trial: 4, epoch, 32, iter: 1, curr loss: 0.18487697839736938, avg loss: 0.18487697839736938\n",
      "trial: 4, epoch, 32, iter: 200, curr loss: 0.18371623754501343, avg loss: 0.18477413058280945\n",
      "trial: 4, epoch, 33, iter: 1, curr loss: 0.17842909693717957, avg loss: 0.17842909693717957\n",
      "trial: 4, epoch, 33, iter: 200, curr loss: 0.18387365341186523, avg loss: 0.18480185560882093\n",
      "trial: 4, epoch, 34, iter: 1, curr loss: 0.18287861347198486, avg loss: 0.18287861347198486\n",
      "trial: 4, epoch, 34, iter: 200, curr loss: 0.1852598339319229, avg loss: 0.18445099376142024\n",
      "trial: 4, epoch, 35, iter: 1, curr loss: 0.18892979621887207, avg loss: 0.18892979621887207\n",
      "trial: 4, epoch, 35, iter: 200, curr loss: 0.18709048628807068, avg loss: 0.18470824033021926\n",
      "trial: 4, epoch, 36, iter: 1, curr loss: 0.18711331486701965, avg loss: 0.18711331486701965\n",
      "trial: 4, epoch, 36, iter: 200, curr loss: 0.18192028999328613, avg loss: 0.18466198891401292\n",
      "trial: 4, epoch, 37, iter: 1, curr loss: 0.1896192580461502, avg loss: 0.1896192580461502\n",
      "trial: 4, epoch, 37, iter: 200, curr loss: 0.18143747746944427, avg loss: 0.1842868359386921\n",
      "trial: 4, epoch, 38, iter: 1, curr loss: 0.18013347685337067, avg loss: 0.18013347685337067\n",
      "trial: 4, epoch, 38, iter: 200, curr loss: 0.18331097066402435, avg loss: 0.18494184881448747\n",
      "trial: 4, epoch, 39, iter: 1, curr loss: 0.18486568331718445, avg loss: 0.18486568331718445\n",
      "trial: 4, epoch, 39, iter: 200, curr loss: 0.19222217798233032, avg loss: 0.18518051087856294\n",
      "trial: 4, epoch, 40, iter: 1, curr loss: 0.18299809098243713, avg loss: 0.18299809098243713\n",
      "trial: 4, epoch, 40, iter: 200, curr loss: 0.18828368186950684, avg loss: 0.18455297410488128\n",
      "trial: 4, epoch, 41, iter: 1, curr loss: 0.18115967512130737, avg loss: 0.18115967512130737\n",
      "trial: 4, epoch, 41, iter: 200, curr loss: 0.1905137151479721, avg loss: 0.18452457904815675\n",
      "trial: 4, epoch, 42, iter: 1, curr loss: 0.18272244930267334, avg loss: 0.18272244930267334\n",
      "trial: 4, epoch, 42, iter: 200, curr loss: 0.19170445203781128, avg loss: 0.18462457060813903\n",
      "trial: 4, epoch, 43, iter: 1, curr loss: 0.18623867630958557, avg loss: 0.18623867630958557\n",
      "trial: 4, epoch, 43, iter: 200, curr loss: 0.1771099716424942, avg loss: 0.1900390523672104\n",
      "trial: 4, epoch, 44, iter: 1, curr loss: 0.18020431697368622, avg loss: 0.18020431697368622\n",
      "trial: 4, epoch, 44, iter: 200, curr loss: 0.18611235916614532, avg loss: 0.1841439837217331\n",
      "trial: 4, epoch, 45, iter: 1, curr loss: 0.18584215641021729, avg loss: 0.18584215641021729\n",
      "trial: 4, epoch, 45, iter: 200, curr loss: 0.18569529056549072, avg loss: 0.18469677083194255\n",
      "trial: 4, epoch, 46, iter: 1, curr loss: 0.1856016367673874, avg loss: 0.1856016367673874\n",
      "trial: 4, epoch, 46, iter: 200, curr loss: 0.18989746272563934, avg loss: 0.18475672252476216\n",
      "trial: 4, epoch, 47, iter: 1, curr loss: 0.17407943308353424, avg loss: 0.17407943308353424\n",
      "trial: 4, epoch, 47, iter: 200, curr loss: 0.18160787224769592, avg loss: 0.1848430497199297\n",
      "trial: 4, epoch, 48, iter: 1, curr loss: 0.18946683406829834, avg loss: 0.18946683406829834\n",
      "trial: 4, epoch, 48, iter: 200, curr loss: 0.1929396390914917, avg loss: 0.1841053868830204\n",
      "trial: 4, epoch, 49, iter: 1, curr loss: 0.19036319851875305, avg loss: 0.19036319851875305\n",
      "trial: 4, epoch, 49, iter: 200, curr loss: 0.181697279214859, avg loss: 0.18427104279398918\n",
      "trial: 4, epoch, 50, iter: 1, curr loss: 0.18299053609371185, avg loss: 0.18299053609371185\n",
      "trial: 4, epoch, 50, iter: 200, curr loss: 0.17680507898330688, avg loss: 0.18487617529928685\n",
      "trial: 4, ldr: 21.20156478881836, dv: 22.596416473388672, nwj: 21.95369529724121\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, epoch, 1, iter: 1, curr loss: 0.6951937079429626, avg loss: 0.6951937079429626\n",
      "trial: 5, epoch, 1, iter: 200, curr loss: 0.18954315781593323, avg loss: 0.2273633761703968\n",
      "trial: 5, epoch, 2, iter: 1, curr loss: 0.18896624445915222, avg loss: 0.18896624445915222\n",
      "trial: 5, epoch, 2, iter: 200, curr loss: 0.18928398191928864, avg loss: 0.18627853587269783\n",
      "trial: 5, epoch, 3, iter: 1, curr loss: 0.1838519275188446, avg loss: 0.1838519275188446\n",
      "trial: 5, epoch, 3, iter: 200, curr loss: 0.18461841344833374, avg loss: 0.1858252565562725\n",
      "trial: 5, epoch, 4, iter: 1, curr loss: 0.17599225044250488, avg loss: 0.17599225044250488\n",
      "trial: 5, epoch, 4, iter: 200, curr loss: 0.1912078708410263, avg loss: 0.18527335219085217\n",
      "trial: 5, epoch, 5, iter: 1, curr loss: 0.19242674112319946, avg loss: 0.19242674112319946\n",
      "trial: 5, epoch, 5, iter: 200, curr loss: 0.1692284345626831, avg loss: 0.1850518859177828\n",
      "trial: 5, epoch, 6, iter: 1, curr loss: 0.187791109085083, avg loss: 0.187791109085083\n",
      "trial: 5, epoch, 6, iter: 200, curr loss: 0.18788506090641022, avg loss: 0.18522273935377598\n",
      "trial: 5, epoch, 7, iter: 1, curr loss: 0.1858736276626587, avg loss: 0.1858736276626587\n",
      "trial: 5, epoch, 7, iter: 200, curr loss: 0.18231424689292908, avg loss: 0.1848300402611494\n",
      "trial: 5, epoch, 8, iter: 1, curr loss: 0.1882682740688324, avg loss: 0.1882682740688324\n",
      "trial: 5, epoch, 8, iter: 200, curr loss: 0.18673697113990784, avg loss: 0.18475465141236783\n",
      "trial: 5, epoch, 9, iter: 1, curr loss: 0.18796350061893463, avg loss: 0.18796350061893463\n",
      "trial: 5, epoch, 9, iter: 200, curr loss: 0.19005557894706726, avg loss: 0.18461557246744634\n",
      "trial: 5, epoch, 10, iter: 1, curr loss: 0.19422884285449982, avg loss: 0.19422884285449982\n",
      "trial: 5, epoch, 10, iter: 200, curr loss: 0.18364524841308594, avg loss: 0.1842421094328165\n",
      "trial: 5, epoch, 11, iter: 1, curr loss: 0.17725896835327148, avg loss: 0.17725896835327148\n",
      "trial: 5, epoch, 11, iter: 200, curr loss: 0.1822974979877472, avg loss: 0.18448535293340684\n",
      "trial: 5, epoch, 12, iter: 1, curr loss: 0.1910908818244934, avg loss: 0.1910908818244934\n",
      "trial: 5, epoch, 12, iter: 200, curr loss: 0.1926816701889038, avg loss: 0.1842094974964857\n",
      "trial: 5, epoch, 13, iter: 1, curr loss: 0.18919184803962708, avg loss: 0.18919184803962708\n",
      "trial: 5, epoch, 13, iter: 200, curr loss: 0.18765071034431458, avg loss: 0.18439991131424904\n",
      "trial: 5, epoch, 14, iter: 1, curr loss: 0.182715505361557, avg loss: 0.182715505361557\n",
      "trial: 5, epoch, 14, iter: 200, curr loss: 0.18560263514518738, avg loss: 0.1843934256583452\n",
      "trial: 5, epoch, 15, iter: 1, curr loss: 0.18963322043418884, avg loss: 0.18963322043418884\n",
      "trial: 5, epoch, 15, iter: 200, curr loss: 0.1857646107673645, avg loss: 0.18423056438565255\n",
      "trial: 5, epoch, 16, iter: 1, curr loss: 0.18624693155288696, avg loss: 0.18624693155288696\n",
      "trial: 5, epoch, 16, iter: 200, curr loss: 0.18350553512573242, avg loss: 0.18466811276972295\n",
      "trial: 5, epoch, 17, iter: 1, curr loss: 0.18633978068828583, avg loss: 0.18633978068828583\n",
      "trial: 5, epoch, 17, iter: 200, curr loss: 0.18009252846240997, avg loss: 0.1842912220209837\n",
      "trial: 5, epoch, 18, iter: 1, curr loss: 0.18480974435806274, avg loss: 0.18480974435806274\n",
      "trial: 5, epoch, 18, iter: 200, curr loss: 0.18436262011528015, avg loss: 0.18465659834444523\n",
      "trial: 5, epoch, 19, iter: 1, curr loss: 0.1839848905801773, avg loss: 0.1839848905801773\n",
      "trial: 5, epoch, 19, iter: 200, curr loss: 0.18559372425079346, avg loss: 0.18447984471917153\n",
      "trial: 5, epoch, 20, iter: 1, curr loss: 0.18578976392745972, avg loss: 0.18578976392745972\n",
      "trial: 5, epoch, 20, iter: 200, curr loss: 0.1821223497390747, avg loss: 0.18474217012524605\n",
      "trial: 5, epoch, 21, iter: 1, curr loss: 0.18422792851924896, avg loss: 0.18422792851924896\n",
      "trial: 5, epoch, 21, iter: 200, curr loss: 0.18007442355155945, avg loss: 0.18450701124966146\n",
      "trial: 5, epoch, 22, iter: 1, curr loss: 0.1923939436674118, avg loss: 0.1923939436674118\n",
      "trial: 5, epoch, 22, iter: 200, curr loss: 0.18983492255210876, avg loss: 0.18415849663317205\n",
      "trial: 5, epoch, 23, iter: 1, curr loss: 0.18353933095932007, avg loss: 0.18353933095932007\n",
      "trial: 5, epoch, 23, iter: 200, curr loss: 0.17919446527957916, avg loss: 0.18435181804001333\n",
      "trial: 5, epoch, 24, iter: 1, curr loss: 0.18097896873950958, avg loss: 0.18097896873950958\n",
      "trial: 5, epoch, 24, iter: 200, curr loss: 0.19530439376831055, avg loss: 0.18457645513117313\n",
      "trial: 5, epoch, 25, iter: 1, curr loss: 0.19446533918380737, avg loss: 0.19446533918380737\n",
      "trial: 5, epoch, 25, iter: 200, curr loss: 0.1861914098262787, avg loss: 0.18794055953621863\n",
      "trial: 5, epoch, 26, iter: 1, curr loss: 0.19018122553825378, avg loss: 0.19018122553825378\n",
      "trial: 5, epoch, 26, iter: 200, curr loss: 0.17820051312446594, avg loss: 0.18442609548568725\n",
      "trial: 5, epoch, 27, iter: 1, curr loss: 0.1825668215751648, avg loss: 0.1825668215751648\n",
      "trial: 5, epoch, 27, iter: 200, curr loss: 0.18682971596717834, avg loss: 0.18449121363461018\n",
      "trial: 5, epoch, 28, iter: 1, curr loss: 0.18022453784942627, avg loss: 0.18022453784942627\n",
      "trial: 5, epoch, 28, iter: 200, curr loss: 0.1836177110671997, avg loss: 0.1847025176882744\n",
      "trial: 5, epoch, 29, iter: 1, curr loss: 0.19619682431221008, avg loss: 0.19619682431221008\n",
      "trial: 5, epoch, 29, iter: 200, curr loss: 0.18221084773540497, avg loss: 0.18411851555109024\n",
      "trial: 5, epoch, 30, iter: 1, curr loss: 0.19285421073436737, avg loss: 0.19285421073436737\n",
      "trial: 5, epoch, 30, iter: 200, curr loss: 0.18276867270469666, avg loss: 0.18426531791687012\n",
      "trial: 5, epoch, 31, iter: 1, curr loss: 0.18884389102458954, avg loss: 0.18884389102458954\n",
      "trial: 5, epoch, 31, iter: 200, curr loss: 0.18529294431209564, avg loss: 0.1842756459861994\n",
      "trial: 5, epoch, 32, iter: 1, curr loss: 0.18733224272727966, avg loss: 0.18733224272727966\n",
      "trial: 5, epoch, 32, iter: 200, curr loss: 0.17655852437019348, avg loss: 0.18446495831012727\n",
      "trial: 5, epoch, 33, iter: 1, curr loss: 0.18867871165275574, avg loss: 0.18867871165275574\n",
      "trial: 5, epoch, 33, iter: 200, curr loss: 0.18372347950935364, avg loss: 0.18471158012747765\n",
      "trial: 5, epoch, 34, iter: 1, curr loss: 0.19015789031982422, avg loss: 0.19015789031982422\n",
      "trial: 5, epoch, 34, iter: 200, curr loss: 0.18987318873405457, avg loss: 0.18468060582876206\n",
      "trial: 5, epoch, 35, iter: 1, curr loss: 0.18566012382507324, avg loss: 0.18566012382507324\n",
      "trial: 5, epoch, 35, iter: 200, curr loss: 0.1908377856016159, avg loss: 0.18428414449095726\n",
      "trial: 5, epoch, 36, iter: 1, curr loss: 0.17823117971420288, avg loss: 0.17823117971420288\n",
      "trial: 5, epoch, 36, iter: 200, curr loss: 0.18938839435577393, avg loss: 0.18451215401291848\n",
      "trial: 5, epoch, 37, iter: 1, curr loss: 0.19049914181232452, avg loss: 0.19049914181232452\n",
      "trial: 5, epoch, 37, iter: 200, curr loss: 0.18080756068229675, avg loss: 0.18438847333192826\n",
      "trial: 5, epoch, 38, iter: 1, curr loss: 0.1768757551908493, avg loss: 0.1768757551908493\n",
      "trial: 5, epoch, 38, iter: 200, curr loss: 0.18099336326122284, avg loss: 0.18449076101183892\n",
      "trial: 5, epoch, 39, iter: 1, curr loss: 0.1847730129957199, avg loss: 0.1847730129957199\n",
      "trial: 5, epoch, 39, iter: 200, curr loss: 0.19067157804965973, avg loss: 0.184658772200346\n",
      "trial: 5, epoch, 40, iter: 1, curr loss: 0.18875476717948914, avg loss: 0.18875476717948914\n",
      "trial: 5, epoch, 40, iter: 200, curr loss: 0.18888722360134125, avg loss: 0.18456312090158464\n",
      "trial: 5, epoch, 41, iter: 1, curr loss: 0.18834690749645233, avg loss: 0.18834690749645233\n",
      "trial: 5, epoch, 41, iter: 200, curr loss: 0.19066908955574036, avg loss: 0.1844650040566921\n",
      "trial: 5, epoch, 42, iter: 1, curr loss: 0.18371281027793884, avg loss: 0.18371281027793884\n",
      "trial: 5, epoch, 42, iter: 200, curr loss: 0.17973434925079346, avg loss: 0.18441615268588066\n",
      "trial: 5, epoch, 43, iter: 1, curr loss: 0.18510812520980835, avg loss: 0.18510812520980835\n",
      "trial: 5, epoch, 43, iter: 200, curr loss: 0.1809070110321045, avg loss: 0.18467956878244876\n",
      "trial: 5, epoch, 44, iter: 1, curr loss: 0.1865900754928589, avg loss: 0.1865900754928589\n",
      "trial: 5, epoch, 44, iter: 200, curr loss: 0.18376889824867249, avg loss: 0.18453542597591877\n",
      "trial: 5, epoch, 45, iter: 1, curr loss: 0.18449616432189941, avg loss: 0.18449616432189941\n",
      "trial: 5, epoch, 45, iter: 200, curr loss: 0.18811428546905518, avg loss: 0.1843922820687294\n",
      "trial: 5, epoch, 46, iter: 1, curr loss: 0.18529599905014038, avg loss: 0.18529599905014038\n",
      "trial: 5, epoch, 46, iter: 200, curr loss: 0.18652623891830444, avg loss: 0.1846624218672514\n",
      "trial: 5, epoch, 47, iter: 1, curr loss: 0.19005386531352997, avg loss: 0.19005386531352997\n",
      "trial: 5, epoch, 47, iter: 200, curr loss: 0.1883966624736786, avg loss: 0.184451497271657\n",
      "trial: 5, epoch, 48, iter: 1, curr loss: 0.18332014977931976, avg loss: 0.18332014977931976\n",
      "trial: 5, epoch, 48, iter: 200, curr loss: 0.1894114464521408, avg loss: 0.1843365816771984\n",
      "trial: 5, epoch, 49, iter: 1, curr loss: 0.17753615975379944, avg loss: 0.17753615975379944\n",
      "trial: 5, epoch, 49, iter: 200, curr loss: 0.1917390525341034, avg loss: 0.18482104979455471\n",
      "trial: 5, epoch, 50, iter: 1, curr loss: 0.18705910444259644, avg loss: 0.18705910444259644\n",
      "trial: 5, epoch, 50, iter: 200, curr loss: 0.18605300784111023, avg loss: 0.18478091925382614\n",
      "trial: 5, ldr: 22.631450653076172, dv: 24.030017852783203, nwj: 23.38450050354004\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 6, epoch, 1, iter: 1, curr loss: 0.694749116897583, avg loss: 0.694749116897583\n",
      "trial: 6, epoch, 1, iter: 200, curr loss: 0.1918506622314453, avg loss: 0.22643494568765163\n",
      "trial: 6, epoch, 2, iter: 1, curr loss: 0.1878441721200943, avg loss: 0.1878441721200943\n",
      "trial: 6, epoch, 2, iter: 200, curr loss: 0.18187251687049866, avg loss: 0.18592645928263665\n",
      "trial: 6, epoch, 3, iter: 1, curr loss: 0.17421187460422516, avg loss: 0.17421187460422516\n",
      "trial: 6, epoch, 3, iter: 200, curr loss: 0.19970789551734924, avg loss: 0.18581996701657771\n",
      "trial: 6, epoch, 4, iter: 1, curr loss: 0.17810742557048798, avg loss: 0.17810742557048798\n",
      "trial: 6, epoch, 4, iter: 200, curr loss: 0.1786518096923828, avg loss: 0.18557684674859046\n",
      "trial: 6, epoch, 5, iter: 1, curr loss: 0.18053165078163147, avg loss: 0.18053165078163147\n",
      "trial: 6, epoch, 5, iter: 200, curr loss: 0.18001583218574524, avg loss: 0.18482658989727496\n",
      "trial: 6, epoch, 6, iter: 1, curr loss: 0.19359293580055237, avg loss: 0.19359293580055237\n",
      "trial: 6, epoch, 6, iter: 200, curr loss: 0.1886143833398819, avg loss: 0.18479834079742433\n",
      "trial: 6, epoch, 7, iter: 1, curr loss: 0.18518386781215668, avg loss: 0.18518386781215668\n",
      "trial: 6, epoch, 7, iter: 200, curr loss: 0.1853410005569458, avg loss: 0.1845974700152874\n",
      "trial: 6, epoch, 8, iter: 1, curr loss: 0.19422973692417145, avg loss: 0.19422973692417145\n",
      "trial: 6, epoch, 8, iter: 200, curr loss: 0.193409264087677, avg loss: 0.18486838690936566\n",
      "trial: 6, epoch, 9, iter: 1, curr loss: 0.17937901616096497, avg loss: 0.17937901616096497\n",
      "trial: 6, epoch, 9, iter: 200, curr loss: 0.1851743757724762, avg loss: 0.18444698132574558\n",
      "trial: 6, epoch, 10, iter: 1, curr loss: 0.1892072558403015, avg loss: 0.1892072558403015\n",
      "trial: 6, epoch, 10, iter: 200, curr loss: 0.18970558047294617, avg loss: 0.18434143520891666\n",
      "trial: 6, epoch, 11, iter: 1, curr loss: 0.18492528796195984, avg loss: 0.18492528796195984\n",
      "trial: 6, epoch, 11, iter: 200, curr loss: 0.18842104077339172, avg loss: 0.18472992219030857\n",
      "trial: 6, epoch, 12, iter: 1, curr loss: 0.18256275355815887, avg loss: 0.18256275355815887\n",
      "trial: 6, epoch, 12, iter: 200, curr loss: 0.18236559629440308, avg loss: 0.1844904876500368\n",
      "trial: 6, epoch, 13, iter: 1, curr loss: 0.18142595887184143, avg loss: 0.18142595887184143\n",
      "trial: 6, epoch, 13, iter: 200, curr loss: 0.18616142868995667, avg loss: 0.18437463492155076\n",
      "trial: 6, epoch, 14, iter: 1, curr loss: 0.18283696472644806, avg loss: 0.18283696472644806\n",
      "trial: 6, epoch, 14, iter: 200, curr loss: 0.18201524019241333, avg loss: 0.1847789304703474\n",
      "trial: 6, epoch, 15, iter: 1, curr loss: 0.1837770640850067, avg loss: 0.1837770640850067\n",
      "trial: 6, epoch, 15, iter: 200, curr loss: 0.18795323371887207, avg loss: 0.18478063620626928\n",
      "trial: 6, epoch, 16, iter: 1, curr loss: 0.17815348505973816, avg loss: 0.17815348505973816\n",
      "trial: 6, epoch, 16, iter: 200, curr loss: 0.1839466542005539, avg loss: 0.1842426484078169\n",
      "trial: 6, epoch, 17, iter: 1, curr loss: 0.18659012019634247, avg loss: 0.18659012019634247\n",
      "trial: 6, epoch, 17, iter: 200, curr loss: 0.18136171996593475, avg loss: 0.18490318357944488\n",
      "trial: 6, epoch, 18, iter: 1, curr loss: 0.18073417246341705, avg loss: 0.18073417246341705\n",
      "trial: 6, epoch, 18, iter: 200, curr loss: 0.1807895451784134, avg loss: 0.18475051321089267\n",
      "trial: 6, epoch, 19, iter: 1, curr loss: 0.19278952479362488, avg loss: 0.19278952479362488\n",
      "trial: 6, epoch, 19, iter: 200, curr loss: 0.1951587200164795, avg loss: 0.18456582859158516\n",
      "trial: 6, epoch, 20, iter: 1, curr loss: 0.18238504230976105, avg loss: 0.18238504230976105\n",
      "trial: 6, epoch, 20, iter: 200, curr loss: 0.1814812421798706, avg loss: 0.18494004726409913\n",
      "trial: 6, epoch, 21, iter: 1, curr loss: 0.18577703833580017, avg loss: 0.18577703833580017\n",
      "trial: 6, epoch, 21, iter: 200, curr loss: 0.1859438568353653, avg loss: 0.18437863148748876\n",
      "trial: 6, epoch, 22, iter: 1, curr loss: 0.1856701672077179, avg loss: 0.1856701672077179\n",
      "trial: 6, epoch, 22, iter: 200, curr loss: 0.17948994040489197, avg loss: 0.1845880498737097\n",
      "trial: 6, epoch, 23, iter: 1, curr loss: 0.18350204825401306, avg loss: 0.18350204825401306\n",
      "trial: 6, epoch, 23, iter: 200, curr loss: 0.18469935655593872, avg loss: 0.18423534631729127\n",
      "trial: 6, epoch, 24, iter: 1, curr loss: 0.184065043926239, avg loss: 0.184065043926239\n",
      "trial: 6, epoch, 24, iter: 200, curr loss: 0.18532270193099976, avg loss: 0.18491398468613623\n",
      "trial: 6, epoch, 25, iter: 1, curr loss: 0.18270567059516907, avg loss: 0.18270567059516907\n",
      "trial: 6, epoch, 25, iter: 200, curr loss: 0.18449965119361877, avg loss: 0.18439152292907238\n",
      "trial: 6, epoch, 26, iter: 1, curr loss: 0.1837475448846817, avg loss: 0.1837475448846817\n",
      "trial: 6, epoch, 26, iter: 200, curr loss: 0.19308936595916748, avg loss: 0.18471191979944707\n",
      "trial: 6, epoch, 27, iter: 1, curr loss: 0.18587273359298706, avg loss: 0.18587273359298706\n",
      "trial: 6, epoch, 27, iter: 200, curr loss: 0.18293055891990662, avg loss: 0.1846499364823103\n",
      "trial: 6, epoch, 28, iter: 1, curr loss: 0.18842923641204834, avg loss: 0.18842923641204834\n",
      "trial: 6, epoch, 28, iter: 200, curr loss: 0.18851803243160248, avg loss: 0.18488716535270214\n",
      "trial: 6, epoch, 29, iter: 1, curr loss: 0.17654667794704437, avg loss: 0.17654667794704437\n",
      "trial: 6, epoch, 29, iter: 200, curr loss: 0.19038423895835876, avg loss: 0.18516327165067195\n",
      "trial: 6, epoch, 30, iter: 1, curr loss: 0.1828828752040863, avg loss: 0.1828828752040863\n",
      "trial: 6, epoch, 30, iter: 200, curr loss: 0.1972123384475708, avg loss: 0.18423309326171874\n",
      "trial: 6, epoch, 31, iter: 1, curr loss: 0.1885818988084793, avg loss: 0.1885818988084793\n",
      "trial: 6, epoch, 31, iter: 200, curr loss: 0.17681987583637238, avg loss: 0.18455927848815917\n",
      "trial: 6, epoch, 32, iter: 1, curr loss: 0.18780532479286194, avg loss: 0.18780532479286194\n",
      "trial: 6, epoch, 32, iter: 200, curr loss: 0.19584007561206818, avg loss: 0.18493277713656425\n",
      "trial: 6, epoch, 33, iter: 1, curr loss: 0.17838478088378906, avg loss: 0.17838478088378906\n",
      "trial: 6, epoch, 33, iter: 200, curr loss: 0.18234360218048096, avg loss: 0.18448039673268796\n",
      "trial: 6, epoch, 34, iter: 1, curr loss: 0.1840120404958725, avg loss: 0.1840120404958725\n",
      "trial: 6, epoch, 34, iter: 200, curr loss: 0.18486152589321136, avg loss: 0.18469529278576374\n",
      "trial: 6, epoch, 35, iter: 1, curr loss: 0.19640634953975677, avg loss: 0.19640634953975677\n",
      "trial: 6, epoch, 35, iter: 200, curr loss: 0.1878480166196823, avg loss: 0.18427919566631318\n",
      "trial: 6, epoch, 36, iter: 1, curr loss: 0.18263939023017883, avg loss: 0.18263939023017883\n",
      "trial: 6, epoch, 36, iter: 200, curr loss: 0.1838681995868683, avg loss: 0.1842817758023739\n",
      "trial: 6, epoch, 37, iter: 1, curr loss: 0.18790720403194427, avg loss: 0.18790720403194427\n",
      "trial: 6, epoch, 37, iter: 200, curr loss: 0.1896800696849823, avg loss: 0.18500674828886987\n",
      "trial: 6, epoch, 38, iter: 1, curr loss: 0.1843036711215973, avg loss: 0.1843036711215973\n",
      "trial: 6, epoch, 38, iter: 200, curr loss: 0.17903324961662292, avg loss: 0.18490350261330604\n",
      "trial: 6, epoch, 39, iter: 1, curr loss: 0.18796488642692566, avg loss: 0.18796488642692566\n",
      "trial: 6, epoch, 39, iter: 200, curr loss: 0.17827431857585907, avg loss: 0.1840438190102577\n",
      "trial: 6, epoch, 40, iter: 1, curr loss: 0.18413199484348297, avg loss: 0.18413199484348297\n",
      "trial: 6, epoch, 40, iter: 200, curr loss: 0.1864631026983261, avg loss: 0.1844506063312292\n",
      "trial: 6, epoch, 41, iter: 1, curr loss: 0.18300387263298035, avg loss: 0.18300387263298035\n",
      "trial: 6, epoch, 41, iter: 200, curr loss: 0.18204590678215027, avg loss: 0.18458210080862045\n",
      "trial: 6, epoch, 42, iter: 1, curr loss: 0.1860499382019043, avg loss: 0.1860499382019043\n",
      "trial: 6, epoch, 42, iter: 200, curr loss: 0.19322526454925537, avg loss: 0.1842546332627535\n",
      "trial: 6, epoch, 43, iter: 1, curr loss: 0.17398397624492645, avg loss: 0.17398397624492645\n",
      "trial: 6, epoch, 43, iter: 200, curr loss: 0.1784878373146057, avg loss: 0.18472326308488846\n",
      "trial: 6, epoch, 44, iter: 1, curr loss: 0.18575163185596466, avg loss: 0.18575163185596466\n",
      "trial: 6, epoch, 44, iter: 200, curr loss: 0.1819629669189453, avg loss: 0.18471022218465805\n",
      "trial: 6, epoch, 45, iter: 1, curr loss: 0.1947634220123291, avg loss: 0.1947634220123291\n",
      "trial: 6, epoch, 45, iter: 200, curr loss: 0.1859360635280609, avg loss: 0.18463245525956154\n",
      "trial: 6, epoch, 46, iter: 1, curr loss: 0.18568195402622223, avg loss: 0.18568195402622223\n",
      "trial: 6, epoch, 46, iter: 200, curr loss: 0.18842965364456177, avg loss: 0.1843433042615652\n",
      "trial: 6, epoch, 47, iter: 1, curr loss: 0.18479023873806, avg loss: 0.18479023873806\n",
      "trial: 6, epoch, 47, iter: 200, curr loss: 0.18601223826408386, avg loss: 0.18501897029578684\n",
      "trial: 6, epoch, 48, iter: 1, curr loss: 0.18904051184654236, avg loss: 0.18904051184654236\n",
      "trial: 6, epoch, 48, iter: 200, curr loss: 0.18188239634037018, avg loss: 0.18475850619375705\n",
      "trial: 6, epoch, 49, iter: 1, curr loss: 0.18432262539863586, avg loss: 0.18432262539863586\n",
      "trial: 6, epoch, 49, iter: 200, curr loss: 0.19028812646865845, avg loss: 0.18474863424897195\n",
      "trial: 6, epoch, 50, iter: 1, curr loss: 0.18117722868919373, avg loss: 0.18117722868919373\n",
      "trial: 6, epoch, 50, iter: 200, curr loss: 0.17744934558868408, avg loss: 0.1850281086564064\n",
      "trial: 6, ldr: 22.12836456298828, dv: 23.50621795654297, nwj: 22.876245498657227\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 7, epoch, 1, iter: 1, curr loss: 0.6935458183288574, avg loss: 0.6935458183288574\n",
      "trial: 7, epoch, 1, iter: 200, curr loss: 0.18248599767684937, avg loss: 0.2267493049800396\n",
      "trial: 7, epoch, 2, iter: 1, curr loss: 0.18002305924892426, avg loss: 0.18002305924892426\n",
      "trial: 7, epoch, 2, iter: 200, curr loss: 0.17808252573013306, avg loss: 0.18658769369125366\n",
      "trial: 7, epoch, 3, iter: 1, curr loss: 0.187795490026474, avg loss: 0.187795490026474\n",
      "trial: 7, epoch, 3, iter: 200, curr loss: 0.1942692995071411, avg loss: 0.1857157590985298\n",
      "trial: 7, epoch, 4, iter: 1, curr loss: 0.19160646200180054, avg loss: 0.19160646200180054\n",
      "trial: 7, epoch, 4, iter: 200, curr loss: 0.19556424021720886, avg loss: 0.18523564420640468\n",
      "trial: 7, epoch, 5, iter: 1, curr loss: 0.1838127076625824, avg loss: 0.1838127076625824\n",
      "trial: 7, epoch, 5, iter: 200, curr loss: 0.18309402465820312, avg loss: 0.18532702811062335\n",
      "trial: 7, epoch, 6, iter: 1, curr loss: 0.1857472062110901, avg loss: 0.1857472062110901\n",
      "trial: 7, epoch, 6, iter: 200, curr loss: 0.1849116086959839, avg loss: 0.18509662486612796\n",
      "trial: 7, epoch, 7, iter: 1, curr loss: 0.19001001119613647, avg loss: 0.19001001119613647\n",
      "trial: 7, epoch, 7, iter: 200, curr loss: 0.1870163381099701, avg loss: 0.18422628089785575\n",
      "trial: 7, epoch, 8, iter: 1, curr loss: 0.1854664385318756, avg loss: 0.1854664385318756\n",
      "trial: 7, epoch, 8, iter: 200, curr loss: 0.18836265802383423, avg loss: 0.18439421012997628\n",
      "trial: 7, epoch, 9, iter: 1, curr loss: 0.19087302684783936, avg loss: 0.19087302684783936\n",
      "trial: 7, epoch, 9, iter: 200, curr loss: 0.19216881692409515, avg loss: 0.18468351989984513\n",
      "trial: 7, epoch, 10, iter: 1, curr loss: 0.18823139369487762, avg loss: 0.18823139369487762\n",
      "trial: 7, epoch, 10, iter: 200, curr loss: 0.19076381623744965, avg loss: 0.18422720722854138\n",
      "trial: 7, epoch, 11, iter: 1, curr loss: 0.19098004698753357, avg loss: 0.19098004698753357\n",
      "trial: 7, epoch, 11, iter: 200, curr loss: 0.1801716685295105, avg loss: 0.18446276634931563\n",
      "trial: 7, epoch, 12, iter: 1, curr loss: 0.19034364819526672, avg loss: 0.19034364819526672\n",
      "trial: 7, epoch, 12, iter: 200, curr loss: 0.18130797147750854, avg loss: 0.1844550881534815\n",
      "trial: 7, epoch, 13, iter: 1, curr loss: 0.1904650628566742, avg loss: 0.1904650628566742\n",
      "trial: 7, epoch, 13, iter: 200, curr loss: 0.18582339584827423, avg loss: 0.18404955595731734\n",
      "trial: 7, epoch, 14, iter: 1, curr loss: 0.18808090686798096, avg loss: 0.18808090686798096\n",
      "trial: 7, epoch, 14, iter: 200, curr loss: 0.18435388803482056, avg loss: 0.1847349428385496\n",
      "trial: 7, epoch, 15, iter: 1, curr loss: 0.19064471125602722, avg loss: 0.19064471125602722\n",
      "trial: 7, epoch, 15, iter: 200, curr loss: 0.17975910007953644, avg loss: 0.1847025950998068\n",
      "trial: 7, epoch, 16, iter: 1, curr loss: 0.1879422664642334, avg loss: 0.1879422664642334\n",
      "trial: 7, epoch, 16, iter: 200, curr loss: 0.18056271970272064, avg loss: 0.18412049882113934\n",
      "trial: 7, epoch, 17, iter: 1, curr loss: 0.182839497923851, avg loss: 0.182839497923851\n",
      "trial: 7, epoch, 17, iter: 200, curr loss: 0.1877809762954712, avg loss: 0.18441522493958473\n",
      "trial: 7, epoch, 18, iter: 1, curr loss: 0.18787318468093872, avg loss: 0.18787318468093872\n",
      "trial: 7, epoch, 18, iter: 200, curr loss: 0.18581657111644745, avg loss: 0.18476115807890892\n",
      "trial: 7, epoch, 19, iter: 1, curr loss: 0.1905086785554886, avg loss: 0.1905086785554886\n",
      "trial: 7, epoch, 19, iter: 200, curr loss: 0.18503974378108978, avg loss: 0.18433077573776246\n",
      "trial: 7, epoch, 20, iter: 1, curr loss: 0.18778002262115479, avg loss: 0.18778002262115479\n",
      "trial: 7, epoch, 20, iter: 200, curr loss: 0.18347904086112976, avg loss: 0.18443811193108559\n",
      "trial: 7, epoch, 21, iter: 1, curr loss: 0.18446694314479828, avg loss: 0.18446694314479828\n",
      "trial: 7, epoch, 21, iter: 200, curr loss: 0.18262888491153717, avg loss: 0.18492873795330525\n",
      "trial: 7, epoch, 22, iter: 1, curr loss: 0.18912936747074127, avg loss: 0.18912936747074127\n",
      "trial: 7, epoch, 22, iter: 200, curr loss: 0.18948456645011902, avg loss: 0.18458662994205952\n",
      "trial: 7, epoch, 23, iter: 1, curr loss: 0.1819426268339157, avg loss: 0.1819426268339157\n",
      "trial: 7, epoch, 23, iter: 200, curr loss: 0.18377861380577087, avg loss: 0.18413414552807808\n",
      "trial: 7, epoch, 24, iter: 1, curr loss: 0.18270625174045563, avg loss: 0.18270625174045563\n",
      "trial: 7, epoch, 24, iter: 200, curr loss: 0.18500518798828125, avg loss: 0.1851664886623621\n",
      "trial: 7, epoch, 25, iter: 1, curr loss: 0.1812112033367157, avg loss: 0.1812112033367157\n",
      "trial: 7, epoch, 25, iter: 200, curr loss: 0.1837366372346878, avg loss: 0.18480107322335243\n",
      "trial: 7, epoch, 26, iter: 1, curr loss: 0.18264831602573395, avg loss: 0.18264831602573395\n",
      "trial: 7, epoch, 26, iter: 200, curr loss: 0.1899610459804535, avg loss: 0.18413772329688072\n",
      "trial: 7, epoch, 27, iter: 1, curr loss: 0.186845064163208, avg loss: 0.186845064163208\n",
      "trial: 7, epoch, 27, iter: 200, curr loss: 0.19498074054718018, avg loss: 0.18475757747888566\n",
      "trial: 7, epoch, 28, iter: 1, curr loss: 0.19349804520606995, avg loss: 0.19349804520606995\n",
      "trial: 7, epoch, 28, iter: 200, curr loss: 0.18474596738815308, avg loss: 0.18430533595383167\n",
      "trial: 7, epoch, 29, iter: 1, curr loss: 0.18630509078502655, avg loss: 0.18630509078502655\n",
      "trial: 7, epoch, 29, iter: 200, curr loss: 0.17185547947883606, avg loss: 0.18446394316852094\n",
      "trial: 7, epoch, 30, iter: 1, curr loss: 0.1915946751832962, avg loss: 0.1915946751832962\n",
      "trial: 7, epoch, 30, iter: 200, curr loss: 0.19003334641456604, avg loss: 0.1844217536598444\n",
      "trial: 7, epoch, 31, iter: 1, curr loss: 0.19623792171478271, avg loss: 0.19623792171478271\n",
      "trial: 7, epoch, 31, iter: 200, curr loss: 0.185601606965065, avg loss: 0.18417582273483277\n",
      "trial: 7, epoch, 32, iter: 1, curr loss: 0.1840893030166626, avg loss: 0.1840893030166626\n",
      "trial: 7, epoch, 32, iter: 200, curr loss: 0.18289527297019958, avg loss: 0.18478231854736804\n",
      "trial: 7, epoch, 33, iter: 1, curr loss: 0.1939316689968109, avg loss: 0.1939316689968109\n",
      "trial: 7, epoch, 33, iter: 200, curr loss: 0.17961858212947845, avg loss: 0.18427384927868842\n",
      "trial: 7, epoch, 34, iter: 1, curr loss: 0.18473803997039795, avg loss: 0.18473803997039795\n",
      "trial: 7, epoch, 34, iter: 200, curr loss: 0.19174346327781677, avg loss: 0.184354457706213\n",
      "trial: 7, epoch, 35, iter: 1, curr loss: 0.1874307096004486, avg loss: 0.1874307096004486\n",
      "trial: 7, epoch, 35, iter: 200, curr loss: 0.18483781814575195, avg loss: 0.18470752030611037\n",
      "trial: 7, epoch, 36, iter: 1, curr loss: 0.19054439663887024, avg loss: 0.19054439663887024\n",
      "trial: 7, epoch, 36, iter: 200, curr loss: 0.18809063732624054, avg loss: 0.18479217261075973\n",
      "trial: 7, epoch, 37, iter: 1, curr loss: 0.1868823766708374, avg loss: 0.1868823766708374\n",
      "trial: 7, epoch, 37, iter: 200, curr loss: 0.18738870322704315, avg loss: 0.18439737729728223\n",
      "trial: 7, epoch, 38, iter: 1, curr loss: 0.18531449139118195, avg loss: 0.18531449139118195\n",
      "trial: 7, epoch, 38, iter: 200, curr loss: 0.1815250813961029, avg loss: 0.18435386076569557\n",
      "trial: 7, epoch, 39, iter: 1, curr loss: 0.18979698419570923, avg loss: 0.18979698419570923\n",
      "trial: 7, epoch, 39, iter: 200, curr loss: 0.18883107602596283, avg loss: 0.18516034983098506\n",
      "trial: 7, epoch, 40, iter: 1, curr loss: 0.18460208177566528, avg loss: 0.18460208177566528\n",
      "trial: 7, epoch, 40, iter: 200, curr loss: 0.18304064869880676, avg loss: 0.18434638470411302\n",
      "trial: 7, epoch, 41, iter: 1, curr loss: 0.1845369040966034, avg loss: 0.1845369040966034\n",
      "trial: 7, epoch, 41, iter: 200, curr loss: 0.1902463436126709, avg loss: 0.18466167405247688\n",
      "trial: 7, epoch, 42, iter: 1, curr loss: 0.18312054872512817, avg loss: 0.18312054872512817\n",
      "trial: 7, epoch, 42, iter: 200, curr loss: 0.19867414236068726, avg loss: 0.18461770534515382\n",
      "trial: 7, epoch, 43, iter: 1, curr loss: 0.1854678988456726, avg loss: 0.1854678988456726\n",
      "trial: 7, epoch, 43, iter: 200, curr loss: 0.1875106692314148, avg loss: 0.1843842763453722\n",
      "trial: 7, epoch, 44, iter: 1, curr loss: 0.1785782277584076, avg loss: 0.1785782277584076\n",
      "trial: 7, epoch, 44, iter: 200, curr loss: 0.1897929310798645, avg loss: 0.18455633871257304\n",
      "trial: 7, epoch, 45, iter: 1, curr loss: 0.18420355021953583, avg loss: 0.18420355021953583\n",
      "trial: 7, epoch, 45, iter: 200, curr loss: 0.18636652827262878, avg loss: 0.1844025642424822\n",
      "trial: 7, epoch, 46, iter: 1, curr loss: 0.1883775293827057, avg loss: 0.1883775293827057\n",
      "trial: 7, epoch, 46, iter: 200, curr loss: 0.18493251502513885, avg loss: 0.18424137130379678\n",
      "trial: 7, epoch, 47, iter: 1, curr loss: 0.19039477407932281, avg loss: 0.19039477407932281\n",
      "trial: 7, epoch, 47, iter: 200, curr loss: 0.18775907158851624, avg loss: 0.18429637789726258\n",
      "trial: 7, epoch, 48, iter: 1, curr loss: 0.17931653559207916, avg loss: 0.17931653559207916\n",
      "trial: 7, epoch, 48, iter: 200, curr loss: 0.18931898474693298, avg loss: 0.18472836002707482\n",
      "trial: 7, epoch, 49, iter: 1, curr loss: 0.1886773258447647, avg loss: 0.1886773258447647\n",
      "trial: 7, epoch, 49, iter: 200, curr loss: 0.1775534451007843, avg loss: 0.1844337210059166\n",
      "trial: 7, epoch, 50, iter: 1, curr loss: 0.18588435649871826, avg loss: 0.18588435649871826\n",
      "trial: 7, epoch, 50, iter: 200, curr loss: 0.18554800748825073, avg loss: 0.18449717484414577\n",
      "trial: 7, ldr: 18.57225227355957, dv: 19.961950302124023, nwj: 19.323101043701172\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 8, epoch, 1, iter: 1, curr loss: 0.692916750907898, avg loss: 0.692916750907898\n",
      "trial: 8, epoch, 1, iter: 200, curr loss: 0.1833423376083374, avg loss: 0.2284871570020914\n",
      "trial: 8, epoch, 2, iter: 1, curr loss: 0.19125822186470032, avg loss: 0.19125822186470032\n",
      "trial: 8, epoch, 2, iter: 200, curr loss: 0.18513058125972748, avg loss: 0.18612098135054111\n",
      "trial: 8, epoch, 3, iter: 1, curr loss: 0.1832972913980484, avg loss: 0.1832972913980484\n",
      "trial: 8, epoch, 3, iter: 200, curr loss: 0.18382596969604492, avg loss: 0.1857316107302904\n",
      "trial: 8, epoch, 4, iter: 1, curr loss: 0.18553340435028076, avg loss: 0.18553340435028076\n",
      "trial: 8, epoch, 4, iter: 200, curr loss: 0.19022390246391296, avg loss: 0.18515354096889497\n",
      "trial: 8, epoch, 5, iter: 1, curr loss: 0.19567936658859253, avg loss: 0.19567936658859253\n",
      "trial: 8, epoch, 5, iter: 200, curr loss: 0.18590837717056274, avg loss: 0.18503380119800567\n",
      "trial: 8, epoch, 6, iter: 1, curr loss: 0.18315109610557556, avg loss: 0.18315109610557556\n",
      "trial: 8, epoch, 6, iter: 200, curr loss: 0.18719275295734406, avg loss: 0.184916954934597\n",
      "trial: 8, epoch, 7, iter: 1, curr loss: 0.19624702632427216, avg loss: 0.19624702632427216\n",
      "trial: 8, epoch, 7, iter: 200, curr loss: 0.1837005913257599, avg loss: 0.18450803995132448\n",
      "trial: 8, epoch, 8, iter: 1, curr loss: 0.19033652544021606, avg loss: 0.19033652544021606\n",
      "trial: 8, epoch, 8, iter: 200, curr loss: 0.19206033647060394, avg loss: 0.1844647289812565\n",
      "trial: 8, epoch, 9, iter: 1, curr loss: 0.1914692521095276, avg loss: 0.1914692521095276\n",
      "trial: 8, epoch, 9, iter: 200, curr loss: 0.19160911440849304, avg loss: 0.18439025677740573\n",
      "trial: 8, epoch, 10, iter: 1, curr loss: 0.19684310257434845, avg loss: 0.19684310257434845\n",
      "trial: 8, epoch, 10, iter: 200, curr loss: 0.17823100090026855, avg loss: 0.1843249575793743\n",
      "trial: 8, epoch, 11, iter: 1, curr loss: 0.18220850825309753, avg loss: 0.18220850825309753\n",
      "trial: 8, epoch, 11, iter: 200, curr loss: 0.18542417883872986, avg loss: 0.18475744739174843\n",
      "trial: 8, epoch, 12, iter: 1, curr loss: 0.18742527067661285, avg loss: 0.18742527067661285\n",
      "trial: 8, epoch, 12, iter: 200, curr loss: 0.17283165454864502, avg loss: 0.1845902756601572\n",
      "trial: 8, epoch, 13, iter: 1, curr loss: 0.19234691560268402, avg loss: 0.19234691560268402\n",
      "trial: 8, epoch, 13, iter: 200, curr loss: 0.17575930058956146, avg loss: 0.18446377351880072\n",
      "trial: 8, epoch, 14, iter: 1, curr loss: 0.18180380761623383, avg loss: 0.18180380761623383\n",
      "trial: 8, epoch, 14, iter: 200, curr loss: 0.18452070653438568, avg loss: 0.18473365791141988\n",
      "trial: 8, epoch, 15, iter: 1, curr loss: 0.18755683302879333, avg loss: 0.18755683302879333\n",
      "trial: 8, epoch, 15, iter: 200, curr loss: 0.1901591271162033, avg loss: 0.1844707214832306\n",
      "trial: 8, epoch, 16, iter: 1, curr loss: 0.1879500448703766, avg loss: 0.1879500448703766\n",
      "trial: 8, epoch, 16, iter: 200, curr loss: 0.18966373801231384, avg loss: 0.18438595302402974\n",
      "trial: 8, epoch, 17, iter: 1, curr loss: 0.18560677766799927, avg loss: 0.18560677766799927\n",
      "trial: 8, epoch, 17, iter: 200, curr loss: 0.18169695138931274, avg loss: 0.18499020986258985\n",
      "trial: 8, epoch, 18, iter: 1, curr loss: 0.18216821551322937, avg loss: 0.18216821551322937\n",
      "trial: 8, epoch, 18, iter: 200, curr loss: 0.19166822731494904, avg loss: 0.1848416355997324\n",
      "trial: 8, epoch, 19, iter: 1, curr loss: 0.17745476961135864, avg loss: 0.17745476961135864\n",
      "trial: 8, epoch, 19, iter: 200, curr loss: 0.19166216254234314, avg loss: 0.1844874404370785\n",
      "trial: 8, epoch, 20, iter: 1, curr loss: 0.18212632834911346, avg loss: 0.18212632834911346\n",
      "trial: 8, epoch, 20, iter: 200, curr loss: 0.18488043546676636, avg loss: 0.18481248684227466\n",
      "trial: 8, epoch, 21, iter: 1, curr loss: 0.18963739275932312, avg loss: 0.18963739275932312\n",
      "trial: 8, epoch, 21, iter: 200, curr loss: 0.18647567927837372, avg loss: 0.18422510243952275\n",
      "trial: 8, epoch, 22, iter: 1, curr loss: 0.18731077015399933, avg loss: 0.18731077015399933\n",
      "trial: 8, epoch, 22, iter: 200, curr loss: 0.17749488353729248, avg loss: 0.18431794144213198\n",
      "trial: 8, epoch, 23, iter: 1, curr loss: 0.18482953310012817, avg loss: 0.18482953310012817\n",
      "trial: 8, epoch, 23, iter: 200, curr loss: 0.18004471063613892, avg loss: 0.1848588403314352\n",
      "trial: 8, epoch, 24, iter: 1, curr loss: 0.19072163105010986, avg loss: 0.19072163105010986\n",
      "trial: 8, epoch, 24, iter: 200, curr loss: 0.18598049879074097, avg loss: 0.1846067550033331\n",
      "trial: 8, epoch, 25, iter: 1, curr loss: 0.18328076601028442, avg loss: 0.18328076601028442\n",
      "trial: 8, epoch, 25, iter: 200, curr loss: 0.18512983620166779, avg loss: 0.1845712687075138\n",
      "trial: 8, epoch, 26, iter: 1, curr loss: 0.18808981776237488, avg loss: 0.18808981776237488\n",
      "trial: 8, epoch, 26, iter: 200, curr loss: 0.18649597465991974, avg loss: 0.18470372408628463\n",
      "trial: 8, epoch, 27, iter: 1, curr loss: 0.18418735265731812, avg loss: 0.18418735265731812\n",
      "trial: 8, epoch, 27, iter: 200, curr loss: 0.18435539305210114, avg loss: 0.1849773509055376\n",
      "trial: 8, epoch, 28, iter: 1, curr loss: 0.19023378193378448, avg loss: 0.19023378193378448\n",
      "trial: 8, epoch, 28, iter: 200, curr loss: 0.1849084198474884, avg loss: 0.18418374553322792\n",
      "trial: 8, epoch, 29, iter: 1, curr loss: 0.19284692406654358, avg loss: 0.19284692406654358\n",
      "trial: 8, epoch, 29, iter: 200, curr loss: 0.1782659888267517, avg loss: 0.18444566167891024\n",
      "trial: 8, epoch, 30, iter: 1, curr loss: 0.18098711967468262, avg loss: 0.18098711967468262\n",
      "trial: 8, epoch, 30, iter: 200, curr loss: 0.18649783730506897, avg loss: 0.18490458376705646\n",
      "trial: 8, epoch, 31, iter: 1, curr loss: 0.1956166923046112, avg loss: 0.1956166923046112\n",
      "trial: 8, epoch, 31, iter: 200, curr loss: 0.1796867549419403, avg loss: 0.1847104859352112\n",
      "trial: 8, epoch, 32, iter: 1, curr loss: 0.1927548497915268, avg loss: 0.1927548497915268\n",
      "trial: 8, epoch, 32, iter: 200, curr loss: 0.18710216879844666, avg loss: 0.18483845956623554\n",
      "trial: 8, epoch, 33, iter: 1, curr loss: 0.18363302946090698, avg loss: 0.18363302946090698\n",
      "trial: 8, epoch, 33, iter: 200, curr loss: 0.18815076351165771, avg loss: 0.1848014221340418\n",
      "trial: 8, epoch, 34, iter: 1, curr loss: 0.1834646761417389, avg loss: 0.1834646761417389\n",
      "trial: 8, epoch, 34, iter: 200, curr loss: 0.1878165304660797, avg loss: 0.1844182822853327\n",
      "trial: 8, epoch, 35, iter: 1, curr loss: 0.19326543807983398, avg loss: 0.19326543807983398\n",
      "trial: 8, epoch, 35, iter: 200, curr loss: 0.18492206931114197, avg loss: 0.1847732125222683\n",
      "trial: 8, epoch, 36, iter: 1, curr loss: 0.18390506505966187, avg loss: 0.18390506505966187\n",
      "trial: 8, epoch, 36, iter: 200, curr loss: 0.18426981568336487, avg loss: 0.1846630173176527\n",
      "trial: 8, epoch, 37, iter: 1, curr loss: 0.17184963822364807, avg loss: 0.17184963822364807\n",
      "trial: 8, epoch, 37, iter: 200, curr loss: 0.18615368008613586, avg loss: 0.18483009420335292\n",
      "trial: 8, epoch, 38, iter: 1, curr loss: 0.1857120394706726, avg loss: 0.1857120394706726\n",
      "trial: 8, epoch, 38, iter: 200, curr loss: 0.19261281192302704, avg loss: 0.1839695405215025\n",
      "trial: 8, epoch, 39, iter: 1, curr loss: 0.19075796008110046, avg loss: 0.19075796008110046\n",
      "trial: 8, epoch, 39, iter: 200, curr loss: 0.1815813183784485, avg loss: 0.18429630279541015\n",
      "trial: 8, epoch, 40, iter: 1, curr loss: 0.18785586953163147, avg loss: 0.18785586953163147\n",
      "trial: 8, epoch, 40, iter: 200, curr loss: 0.19806815683841705, avg loss: 0.18436430841684343\n",
      "trial: 8, epoch, 41, iter: 1, curr loss: 0.1798190474510193, avg loss: 0.1798190474510193\n",
      "trial: 8, epoch, 41, iter: 200, curr loss: 0.17984315752983093, avg loss: 0.18455274000763894\n",
      "trial: 8, epoch, 42, iter: 1, curr loss: 0.18825051188468933, avg loss: 0.18825051188468933\n",
      "trial: 8, epoch, 42, iter: 200, curr loss: 0.18729105591773987, avg loss: 0.1846557555347681\n",
      "trial: 8, epoch, 43, iter: 1, curr loss: 0.18658581376075745, avg loss: 0.18658581376075745\n",
      "trial: 8, epoch, 43, iter: 200, curr loss: 0.18909522891044617, avg loss: 0.18502455905079843\n",
      "trial: 8, epoch, 44, iter: 1, curr loss: 0.18431119620800018, avg loss: 0.18431119620800018\n",
      "trial: 8, epoch, 44, iter: 200, curr loss: 0.18166466057300568, avg loss: 0.18516452133655548\n",
      "trial: 8, epoch, 45, iter: 1, curr loss: 0.18768705427646637, avg loss: 0.18768705427646637\n",
      "trial: 8, epoch, 45, iter: 200, curr loss: 0.18247750401496887, avg loss: 0.18471457563340665\n",
      "trial: 8, epoch, 46, iter: 1, curr loss: 0.18270349502563477, avg loss: 0.18270349502563477\n",
      "trial: 8, epoch, 46, iter: 200, curr loss: 0.18737807869911194, avg loss: 0.18473586201667785\n",
      "trial: 8, epoch, 47, iter: 1, curr loss: 0.18689870834350586, avg loss: 0.18689870834350586\n",
      "trial: 8, epoch, 47, iter: 200, curr loss: 0.1920381486415863, avg loss: 0.18434861436486244\n",
      "trial: 8, epoch, 48, iter: 1, curr loss: 0.18581485748291016, avg loss: 0.18581485748291016\n",
      "trial: 8, epoch, 48, iter: 200, curr loss: 0.18704883754253387, avg loss: 0.1843326872587204\n",
      "trial: 8, epoch, 49, iter: 1, curr loss: 0.18113955855369568, avg loss: 0.18113955855369568\n",
      "trial: 8, epoch, 49, iter: 200, curr loss: 0.18217113614082336, avg loss: 0.1845219910889864\n",
      "trial: 8, epoch, 50, iter: 1, curr loss: 0.185157909989357, avg loss: 0.185157909989357\n",
      "trial: 8, epoch, 50, iter: 200, curr loss: 0.18404173851013184, avg loss: 0.18420778892934322\n",
      "trial: 8, ldr: 18.427757263183594, dv: 19.792280197143555, nwj: 19.17225456237793\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 9, epoch, 1, iter: 1, curr loss: 0.6942089796066284, avg loss: 0.6942089796066284\n",
      "trial: 9, epoch, 1, iter: 200, curr loss: 0.1825266182422638, avg loss: 0.22652869783341884\n",
      "trial: 9, epoch, 2, iter: 1, curr loss: 0.18435871601104736, avg loss: 0.18435871601104736\n",
      "trial: 9, epoch, 2, iter: 200, curr loss: 0.18742866814136505, avg loss: 0.1863919635862112\n",
      "trial: 9, epoch, 3, iter: 1, curr loss: 0.1940649002790451, avg loss: 0.1940649002790451\n",
      "trial: 9, epoch, 3, iter: 200, curr loss: 0.17622771859169006, avg loss: 0.18570237614214422\n",
      "trial: 9, epoch, 4, iter: 1, curr loss: 0.19441743195056915, avg loss: 0.19441743195056915\n",
      "trial: 9, epoch, 4, iter: 200, curr loss: 0.18730410933494568, avg loss: 0.18567779242992402\n",
      "trial: 9, epoch, 5, iter: 1, curr loss: 0.1900305151939392, avg loss: 0.1900305151939392\n",
      "trial: 9, epoch, 5, iter: 200, curr loss: 0.19153133034706116, avg loss: 0.18466211713850497\n",
      "trial: 9, epoch, 6, iter: 1, curr loss: 0.1828155368566513, avg loss: 0.1828155368566513\n",
      "trial: 9, epoch, 6, iter: 200, curr loss: 0.18550562858581543, avg loss: 0.18427720978856088\n",
      "trial: 9, epoch, 7, iter: 1, curr loss: 0.18865859508514404, avg loss: 0.18865859508514404\n",
      "trial: 9, epoch, 7, iter: 200, curr loss: 0.18313848972320557, avg loss: 0.1849988829344511\n",
      "trial: 9, epoch, 8, iter: 1, curr loss: 0.17767059803009033, avg loss: 0.17767059803009033\n",
      "trial: 9, epoch, 8, iter: 200, curr loss: 0.19026470184326172, avg loss: 0.1843459339439869\n",
      "trial: 9, epoch, 9, iter: 1, curr loss: 0.18527087569236755, avg loss: 0.18527087569236755\n",
      "trial: 9, epoch, 9, iter: 200, curr loss: 0.18495646119117737, avg loss: 0.18467206962406635\n",
      "trial: 9, epoch, 10, iter: 1, curr loss: 0.1927730143070221, avg loss: 0.1927730143070221\n",
      "trial: 9, epoch, 10, iter: 200, curr loss: 0.17636528611183167, avg loss: 0.18511721007525922\n",
      "trial: 9, epoch, 11, iter: 1, curr loss: 0.19535261392593384, avg loss: 0.19535261392593384\n",
      "trial: 9, epoch, 11, iter: 200, curr loss: 0.19181214272975922, avg loss: 0.18500114895403386\n",
      "trial: 9, epoch, 12, iter: 1, curr loss: 0.1847345530986786, avg loss: 0.1847345530986786\n",
      "trial: 9, epoch, 12, iter: 200, curr loss: 0.1864553987979889, avg loss: 0.18456529401242733\n",
      "trial: 9, epoch, 13, iter: 1, curr loss: 0.18638484179973602, avg loss: 0.18638484179973602\n",
      "trial: 9, epoch, 13, iter: 200, curr loss: 0.19145897030830383, avg loss: 0.1846513906121254\n",
      "trial: 9, epoch, 14, iter: 1, curr loss: 0.17884908616542816, avg loss: 0.17884908616542816\n",
      "trial: 9, epoch, 14, iter: 200, curr loss: 0.18753769993782043, avg loss: 0.18470676816999912\n",
      "trial: 9, epoch, 15, iter: 1, curr loss: 0.17526212334632874, avg loss: 0.17526212334632874\n",
      "trial: 9, epoch, 15, iter: 200, curr loss: 0.17681407928466797, avg loss: 0.18493576362729072\n",
      "trial: 9, epoch, 16, iter: 1, curr loss: 0.18554289638996124, avg loss: 0.18554289638996124\n",
      "trial: 9, epoch, 16, iter: 200, curr loss: 0.18603765964508057, avg loss: 0.18476978071033956\n",
      "trial: 9, epoch, 17, iter: 1, curr loss: 0.19746007025241852, avg loss: 0.19746007025241852\n",
      "trial: 9, epoch, 17, iter: 200, curr loss: 0.19258499145507812, avg loss: 0.18450269304215908\n",
      "trial: 9, epoch, 18, iter: 1, curr loss: 0.18046681582927704, avg loss: 0.18046681582927704\n",
      "trial: 9, epoch, 18, iter: 200, curr loss: 0.18653661012649536, avg loss: 0.18451058730483055\n",
      "trial: 9, epoch, 19, iter: 1, curr loss: 0.18418647348880768, avg loss: 0.18418647348880768\n",
      "trial: 9, epoch, 19, iter: 200, curr loss: 0.1820237636566162, avg loss: 0.18463094919919967\n",
      "trial: 9, epoch, 20, iter: 1, curr loss: 0.18250331282615662, avg loss: 0.18250331282615662\n",
      "trial: 9, epoch, 20, iter: 200, curr loss: 0.18506476283073425, avg loss: 0.18394669212400913\n",
      "trial: 9, epoch, 21, iter: 1, curr loss: 0.18712210655212402, avg loss: 0.18712210655212402\n",
      "trial: 9, epoch, 21, iter: 200, curr loss: 0.1823205053806305, avg loss: 0.18491492815315724\n",
      "trial: 9, epoch, 22, iter: 1, curr loss: 0.17677152156829834, avg loss: 0.17677152156829834\n",
      "trial: 9, epoch, 22, iter: 200, curr loss: 0.19266165792942047, avg loss: 0.18475101448595524\n",
      "trial: 9, epoch, 23, iter: 1, curr loss: 0.1859225183725357, avg loss: 0.1859225183725357\n",
      "trial: 9, epoch, 23, iter: 200, curr loss: 0.19282981753349304, avg loss: 0.1849294688552618\n",
      "trial: 9, epoch, 24, iter: 1, curr loss: 0.18202859163284302, avg loss: 0.18202859163284302\n",
      "trial: 9, epoch, 24, iter: 200, curr loss: 0.18487122654914856, avg loss: 0.1843236466497183\n",
      "trial: 9, epoch, 25, iter: 1, curr loss: 0.19508904218673706, avg loss: 0.19508904218673706\n",
      "trial: 9, epoch, 25, iter: 200, curr loss: 0.179290309548378, avg loss: 0.18416324712336063\n",
      "trial: 9, epoch, 26, iter: 1, curr loss: 0.1870725154876709, avg loss: 0.1870725154876709\n",
      "trial: 9, epoch, 26, iter: 200, curr loss: 0.18587782979011536, avg loss: 0.18460237450897693\n",
      "trial: 9, epoch, 27, iter: 1, curr loss: 0.1979304850101471, avg loss: 0.1979304850101471\n",
      "trial: 9, epoch, 27, iter: 200, curr loss: 0.18407988548278809, avg loss: 0.18449487701058387\n",
      "trial: 9, epoch, 28, iter: 1, curr loss: 0.18586954474449158, avg loss: 0.18586954474449158\n",
      "trial: 9, epoch, 28, iter: 200, curr loss: 0.18965886533260345, avg loss: 0.18477056093513966\n",
      "trial: 9, epoch, 29, iter: 1, curr loss: 0.17941290140151978, avg loss: 0.17941290140151978\n",
      "trial: 9, epoch, 29, iter: 200, curr loss: 0.18805727362632751, avg loss: 0.1843081632256508\n",
      "trial: 9, epoch, 30, iter: 1, curr loss: 0.1815599799156189, avg loss: 0.1815599799156189\n",
      "trial: 9, epoch, 30, iter: 200, curr loss: 0.17844894528388977, avg loss: 0.1846068149805069\n",
      "trial: 9, epoch, 31, iter: 1, curr loss: 0.1895846426486969, avg loss: 0.1895846426486969\n",
      "trial: 9, epoch, 31, iter: 200, curr loss: 0.18714496493339539, avg loss: 0.1846619039773941\n",
      "trial: 9, epoch, 32, iter: 1, curr loss: 0.19272807240486145, avg loss: 0.19272807240486145\n",
      "trial: 9, epoch, 32, iter: 200, curr loss: 0.1830461025238037, avg loss: 0.18464826315641403\n",
      "trial: 9, epoch, 33, iter: 1, curr loss: 0.1900216042995453, avg loss: 0.1900216042995453\n",
      "trial: 9, epoch, 33, iter: 200, curr loss: 0.1845516860485077, avg loss: 0.1843266685307026\n",
      "trial: 9, epoch, 34, iter: 1, curr loss: 0.1896294504404068, avg loss: 0.1896294504404068\n",
      "trial: 9, epoch, 34, iter: 200, curr loss: 0.1914592683315277, avg loss: 0.1853845250606537\n",
      "trial: 9, epoch, 35, iter: 1, curr loss: 0.19075876474380493, avg loss: 0.19075876474380493\n",
      "trial: 9, epoch, 35, iter: 200, curr loss: 0.18473657965660095, avg loss: 0.1847394571453333\n",
      "trial: 9, epoch, 36, iter: 1, curr loss: 0.17619957029819489, avg loss: 0.17619957029819489\n",
      "trial: 9, epoch, 36, iter: 200, curr loss: 0.1852518916130066, avg loss: 0.1846607669442892\n",
      "trial: 9, epoch, 37, iter: 1, curr loss: 0.18577063083648682, avg loss: 0.18577063083648682\n",
      "trial: 9, epoch, 37, iter: 200, curr loss: 0.189090296626091, avg loss: 0.18480365067720414\n",
      "trial: 9, epoch, 38, iter: 1, curr loss: 0.17832526564598083, avg loss: 0.17832526564598083\n",
      "trial: 9, epoch, 38, iter: 200, curr loss: 0.1904820203781128, avg loss: 0.18467536963522435\n",
      "trial: 9, epoch, 39, iter: 1, curr loss: 0.18941578269004822, avg loss: 0.18941578269004822\n",
      "trial: 9, epoch, 39, iter: 200, curr loss: 0.1799948513507843, avg loss: 0.18458857096731662\n",
      "trial: 9, epoch, 40, iter: 1, curr loss: 0.1770579069852829, avg loss: 0.1770579069852829\n",
      "trial: 9, epoch, 40, iter: 200, curr loss: 0.18505463004112244, avg loss: 0.18457296818494798\n",
      "trial: 9, epoch, 41, iter: 1, curr loss: 0.1851758062839508, avg loss: 0.1851758062839508\n",
      "trial: 9, epoch, 41, iter: 200, curr loss: 0.18569085001945496, avg loss: 0.18455824576318264\n",
      "trial: 9, epoch, 42, iter: 1, curr loss: 0.18558280169963837, avg loss: 0.18558280169963837\n",
      "trial: 9, epoch, 42, iter: 200, curr loss: 0.19041307270526886, avg loss: 0.18508952498435974\n",
      "trial: 9, epoch, 43, iter: 1, curr loss: 0.19137319922447205, avg loss: 0.19137319922447205\n",
      "trial: 9, epoch, 43, iter: 200, curr loss: 0.1828969269990921, avg loss: 0.18469239622354508\n",
      "trial: 9, epoch, 44, iter: 1, curr loss: 0.17906178534030914, avg loss: 0.17906178534030914\n",
      "trial: 9, epoch, 44, iter: 200, curr loss: 0.18487808108329773, avg loss: 0.18497227638959884\n",
      "trial: 9, epoch, 45, iter: 1, curr loss: 0.1922127902507782, avg loss: 0.1922127902507782\n",
      "trial: 9, epoch, 45, iter: 200, curr loss: 0.17551454901695251, avg loss: 0.18460060983896256\n",
      "trial: 9, epoch, 46, iter: 1, curr loss: 0.17964211106300354, avg loss: 0.17964211106300354\n",
      "trial: 9, epoch, 46, iter: 200, curr loss: 0.18649323284626007, avg loss: 0.1847831253707409\n",
      "trial: 9, epoch, 47, iter: 1, curr loss: 0.18436449766159058, avg loss: 0.18436449766159058\n",
      "trial: 9, epoch, 47, iter: 200, curr loss: 0.18012645840644836, avg loss: 0.1843176259845495\n",
      "trial: 9, epoch, 48, iter: 1, curr loss: 0.18738210201263428, avg loss: 0.18738210201263428\n",
      "trial: 9, epoch, 48, iter: 200, curr loss: 0.18783734738826752, avg loss: 0.18454476132988928\n",
      "trial: 9, epoch, 49, iter: 1, curr loss: 0.17801305651664734, avg loss: 0.17801305651664734\n",
      "trial: 9, epoch, 49, iter: 200, curr loss: 0.1829092800617218, avg loss: 0.1846334721893072\n",
      "trial: 9, epoch, 50, iter: 1, curr loss: 0.18377457559108734, avg loss: 0.18377457559108734\n",
      "trial: 9, epoch, 50, iter: 200, curr loss: 0.1914089024066925, avg loss: 0.18429254926741123\n",
      "trial: 9, ldr: 16.053394317626953, dv: 17.449321746826172, nwj: 16.805789947509766\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 10, epoch, 1, iter: 1, curr loss: 0.6989918351173401, avg loss: 0.6989918351173401\n",
      "trial: 10, epoch, 1, iter: 200, curr loss: 0.19124647974967957, avg loss: 0.23152790553867816\n",
      "trial: 10, epoch, 2, iter: 1, curr loss: 0.18157453835010529, avg loss: 0.18157453835010529\n",
      "trial: 10, epoch, 2, iter: 200, curr loss: 0.18412025272846222, avg loss: 0.187683620005846\n",
      "trial: 10, epoch, 3, iter: 1, curr loss: 0.18487420678138733, avg loss: 0.18487420678138733\n",
      "trial: 10, epoch, 3, iter: 200, curr loss: 0.17304609715938568, avg loss: 0.18501222632825376\n",
      "trial: 10, epoch, 4, iter: 1, curr loss: 0.18150334060192108, avg loss: 0.18150334060192108\n",
      "trial: 10, epoch, 4, iter: 200, curr loss: 0.1885731816291809, avg loss: 0.18558856964111328\n",
      "trial: 10, epoch, 5, iter: 1, curr loss: 0.18529236316680908, avg loss: 0.18529236316680908\n",
      "trial: 10, epoch, 5, iter: 200, curr loss: 0.18365855515003204, avg loss: 0.18504154935479164\n",
      "trial: 10, epoch, 6, iter: 1, curr loss: 0.18119610846042633, avg loss: 0.18119610846042633\n",
      "trial: 10, epoch, 6, iter: 200, curr loss: 0.17727616429328918, avg loss: 0.18498599641025065\n",
      "trial: 10, epoch, 7, iter: 1, curr loss: 0.17829471826553345, avg loss: 0.17829471826553345\n",
      "trial: 10, epoch, 7, iter: 200, curr loss: 0.17511999607086182, avg loss: 0.18476930662989616\n",
      "trial: 10, epoch, 8, iter: 1, curr loss: 0.18335707485675812, avg loss: 0.18335707485675812\n",
      "trial: 10, epoch, 8, iter: 200, curr loss: 0.17920173704624176, avg loss: 0.18436136178672313\n",
      "trial: 10, epoch, 9, iter: 1, curr loss: 0.19647133350372314, avg loss: 0.19647133350372314\n",
      "trial: 10, epoch, 9, iter: 200, curr loss: 0.18152430653572083, avg loss: 0.18429513707756995\n",
      "trial: 10, epoch, 10, iter: 1, curr loss: 0.18803302943706512, avg loss: 0.18803302943706512\n",
      "trial: 10, epoch, 10, iter: 200, curr loss: 0.18710386753082275, avg loss: 0.1846818160265684\n",
      "trial: 10, epoch, 11, iter: 1, curr loss: 0.19474539160728455, avg loss: 0.19474539160728455\n",
      "trial: 10, epoch, 11, iter: 200, curr loss: 0.180152028799057, avg loss: 0.18444732435047625\n",
      "trial: 10, epoch, 12, iter: 1, curr loss: 0.18521881103515625, avg loss: 0.18521881103515625\n",
      "trial: 10, epoch, 12, iter: 200, curr loss: 0.18009254336357117, avg loss: 0.18461582489311695\n",
      "trial: 10, epoch, 13, iter: 1, curr loss: 0.17853394150733948, avg loss: 0.17853394150733948\n",
      "trial: 10, epoch, 13, iter: 200, curr loss: 0.18302978575229645, avg loss: 0.18463952623307706\n",
      "trial: 10, epoch, 14, iter: 1, curr loss: 0.1878127157688141, avg loss: 0.1878127157688141\n",
      "trial: 10, epoch, 14, iter: 200, curr loss: 0.18278372287750244, avg loss: 0.18460237145423888\n",
      "trial: 10, epoch, 15, iter: 1, curr loss: 0.19095700979232788, avg loss: 0.19095700979232788\n",
      "trial: 10, epoch, 15, iter: 200, curr loss: 0.18615521490573883, avg loss: 0.18465503051877022\n",
      "trial: 10, epoch, 16, iter: 1, curr loss: 0.18465164303779602, avg loss: 0.18465164303779602\n",
      "trial: 10, epoch, 16, iter: 200, curr loss: 0.19374516606330872, avg loss: 0.18435685843229294\n",
      "trial: 10, epoch, 17, iter: 1, curr loss: 0.17988447844982147, avg loss: 0.17988447844982147\n",
      "trial: 10, epoch, 17, iter: 200, curr loss: 0.18705499172210693, avg loss: 0.184551709741354\n",
      "trial: 10, epoch, 18, iter: 1, curr loss: 0.18184839189052582, avg loss: 0.18184839189052582\n",
      "trial: 10, epoch, 18, iter: 200, curr loss: 0.18827326595783234, avg loss: 0.18434281334280966\n",
      "trial: 10, epoch, 19, iter: 1, curr loss: 0.18697494268417358, avg loss: 0.18697494268417358\n",
      "trial: 10, epoch, 19, iter: 200, curr loss: 0.1800529956817627, avg loss: 0.18478026248514653\n",
      "trial: 10, epoch, 20, iter: 1, curr loss: 0.17695672810077667, avg loss: 0.17695672810077667\n",
      "trial: 10, epoch, 20, iter: 200, curr loss: 0.18925800919532776, avg loss: 0.18456688299775123\n",
      "trial: 10, epoch, 21, iter: 1, curr loss: 0.1872391253709793, avg loss: 0.1872391253709793\n",
      "trial: 10, epoch, 21, iter: 200, curr loss: 0.18206879496574402, avg loss: 0.1847157669812441\n",
      "trial: 10, epoch, 22, iter: 1, curr loss: 0.18325898051261902, avg loss: 0.18325898051261902\n",
      "trial: 10, epoch, 22, iter: 200, curr loss: 0.1830059289932251, avg loss: 0.1846177288889885\n",
      "trial: 10, epoch, 23, iter: 1, curr loss: 0.19104140996932983, avg loss: 0.19104140996932983\n",
      "trial: 10, epoch, 23, iter: 200, curr loss: 0.1784643679857254, avg loss: 0.1842199195921421\n",
      "trial: 10, epoch, 24, iter: 1, curr loss: 0.1794968694448471, avg loss: 0.1794968694448471\n",
      "trial: 10, epoch, 24, iter: 200, curr loss: 0.1851319670677185, avg loss: 0.18448930874466896\n",
      "trial: 10, epoch, 25, iter: 1, curr loss: 0.19229677319526672, avg loss: 0.19229677319526672\n",
      "trial: 10, epoch, 25, iter: 200, curr loss: 0.17788025736808777, avg loss: 0.18412828370928763\n",
      "trial: 10, epoch, 26, iter: 1, curr loss: 0.19964371621608734, avg loss: 0.19964371621608734\n",
      "trial: 10, epoch, 26, iter: 200, curr loss: 0.18461854755878448, avg loss: 0.18484626464545728\n",
      "trial: 10, epoch, 27, iter: 1, curr loss: 0.1907765120267868, avg loss: 0.1907765120267868\n",
      "trial: 10, epoch, 27, iter: 200, curr loss: 0.1896604597568512, avg loss: 0.18430797934532164\n",
      "trial: 10, epoch, 28, iter: 1, curr loss: 0.18347951769828796, avg loss: 0.18347951769828796\n",
      "trial: 10, epoch, 28, iter: 200, curr loss: 0.19135096669197083, avg loss: 0.18444238230586052\n",
      "trial: 10, epoch, 29, iter: 1, curr loss: 0.18175220489501953, avg loss: 0.18175220489501953\n",
      "trial: 10, epoch, 29, iter: 200, curr loss: 0.18684551119804382, avg loss: 0.1845435180515051\n",
      "trial: 10, epoch, 30, iter: 1, curr loss: 0.18270792067050934, avg loss: 0.18270792067050934\n",
      "trial: 10, epoch, 30, iter: 200, curr loss: 0.17826436460018158, avg loss: 0.1841686461865902\n",
      "trial: 10, epoch, 31, iter: 1, curr loss: 0.18076205253601074, avg loss: 0.18076205253601074\n",
      "trial: 10, epoch, 31, iter: 200, curr loss: 0.18958966434001923, avg loss: 0.1845990052819252\n",
      "trial: 10, epoch, 32, iter: 1, curr loss: 0.179521381855011, avg loss: 0.179521381855011\n",
      "trial: 10, epoch, 32, iter: 200, curr loss: 0.18873274326324463, avg loss: 0.18456885702908038\n",
      "trial: 10, epoch, 33, iter: 1, curr loss: 0.18492412567138672, avg loss: 0.18492412567138672\n",
      "trial: 10, epoch, 33, iter: 200, curr loss: 0.185311958193779, avg loss: 0.1845137059688568\n",
      "trial: 10, epoch, 34, iter: 1, curr loss: 0.1850387156009674, avg loss: 0.1850387156009674\n",
      "trial: 10, epoch, 34, iter: 200, curr loss: 0.1810796558856964, avg loss: 0.18476601138710977\n",
      "trial: 10, epoch, 35, iter: 1, curr loss: 0.18311822414398193, avg loss: 0.18311822414398193\n",
      "trial: 10, epoch, 35, iter: 200, curr loss: 0.1881343126296997, avg loss: 0.18475348457694055\n",
      "trial: 10, epoch, 36, iter: 1, curr loss: 0.1895621120929718, avg loss: 0.1895621120929718\n",
      "trial: 10, epoch, 36, iter: 200, curr loss: 0.18421706557273865, avg loss: 0.18490874215960504\n",
      "trial: 10, epoch, 37, iter: 1, curr loss: 0.18570542335510254, avg loss: 0.18570542335510254\n",
      "trial: 10, epoch, 37, iter: 200, curr loss: 0.18616771697998047, avg loss: 0.1840884353965521\n",
      "trial: 10, epoch, 38, iter: 1, curr loss: 0.18751086294651031, avg loss: 0.18751086294651031\n",
      "trial: 10, epoch, 38, iter: 200, curr loss: 0.18022561073303223, avg loss: 0.1844893541187048\n",
      "trial: 10, epoch, 39, iter: 1, curr loss: 0.1852596253156662, avg loss: 0.1852596253156662\n",
      "trial: 10, epoch, 39, iter: 200, curr loss: 0.19002683460712433, avg loss: 0.1849196296185255\n",
      "trial: 10, epoch, 40, iter: 1, curr loss: 0.17981180548667908, avg loss: 0.17981180548667908\n",
      "trial: 10, epoch, 40, iter: 200, curr loss: 0.1868053674697876, avg loss: 0.1842997905611992\n",
      "trial: 10, epoch, 41, iter: 1, curr loss: 0.18719550967216492, avg loss: 0.18719550967216492\n",
      "trial: 10, epoch, 41, iter: 200, curr loss: 0.18618115782737732, avg loss: 0.18442763589322567\n",
      "trial: 10, epoch, 42, iter: 1, curr loss: 0.19425863027572632, avg loss: 0.19425863027572632\n",
      "trial: 10, epoch, 42, iter: 200, curr loss: 0.18234501779079437, avg loss: 0.18467871144413947\n",
      "trial: 10, epoch, 43, iter: 1, curr loss: 0.18425212800502777, avg loss: 0.18425212800502777\n",
      "trial: 10, epoch, 43, iter: 200, curr loss: 0.19163480401039124, avg loss: 0.18457622736692428\n",
      "trial: 10, epoch, 44, iter: 1, curr loss: 0.18858329951763153, avg loss: 0.18858329951763153\n",
      "trial: 10, epoch, 44, iter: 200, curr loss: 0.1921570599079132, avg loss: 0.18524268969893457\n",
      "trial: 10, epoch, 45, iter: 1, curr loss: 0.17736658453941345, avg loss: 0.17736658453941345\n",
      "trial: 10, epoch, 45, iter: 200, curr loss: 0.19147607684135437, avg loss: 0.18403368420898913\n",
      "trial: 10, epoch, 46, iter: 1, curr loss: 0.1834079623222351, avg loss: 0.1834079623222351\n",
      "trial: 10, epoch, 46, iter: 200, curr loss: 0.17634105682373047, avg loss: 0.1847645454108715\n",
      "trial: 10, epoch, 47, iter: 1, curr loss: 0.1963273584842682, avg loss: 0.1963273584842682\n",
      "trial: 10, epoch, 47, iter: 200, curr loss: 0.18775683641433716, avg loss: 0.18464463137090206\n",
      "trial: 10, epoch, 48, iter: 1, curr loss: 0.18083733320236206, avg loss: 0.18083733320236206\n",
      "trial: 10, epoch, 48, iter: 200, curr loss: 0.18452833592891693, avg loss: 0.18459982387721538\n",
      "trial: 10, epoch, 49, iter: 1, curr loss: 0.18449831008911133, avg loss: 0.18449831008911133\n",
      "trial: 10, epoch, 49, iter: 200, curr loss: 0.18071331083774567, avg loss: 0.1847132094204426\n",
      "trial: 10, epoch, 50, iter: 1, curr loss: 0.18192094564437866, avg loss: 0.18192094564437866\n",
      "trial: 10, epoch, 50, iter: 200, curr loss: 0.18521730601787567, avg loss: 0.18460246607661246\n",
      "trial: 10, ldr: 16.98639678955078, dv: 18.374452590942383, nwj: 17.73683738708496\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 11, epoch, 1, iter: 1, curr loss: 0.6926959753036499, avg loss: 0.6926959753036499\n",
      "trial: 11, epoch, 1, iter: 200, curr loss: 0.18909677863121033, avg loss: 0.22566043004393577\n",
      "trial: 11, epoch, 2, iter: 1, curr loss: 0.1790473908185959, avg loss: 0.1790473908185959\n",
      "trial: 11, epoch, 2, iter: 200, curr loss: 0.19403278827667236, avg loss: 0.1862779338657856\n",
      "trial: 11, epoch, 3, iter: 1, curr loss: 0.18754856288433075, avg loss: 0.18754856288433075\n",
      "trial: 11, epoch, 3, iter: 200, curr loss: 0.18253584206104279, avg loss: 0.1851741425693035\n",
      "trial: 11, epoch, 4, iter: 1, curr loss: 0.18590682744979858, avg loss: 0.18590682744979858\n",
      "trial: 11, epoch, 4, iter: 200, curr loss: 0.18359608948230743, avg loss: 0.18478582061827184\n",
      "trial: 11, epoch, 5, iter: 1, curr loss: 0.1813296377658844, avg loss: 0.1813296377658844\n",
      "trial: 11, epoch, 5, iter: 200, curr loss: 0.18794018030166626, avg loss: 0.1845617165416479\n",
      "trial: 11, epoch, 6, iter: 1, curr loss: 0.1872381567955017, avg loss: 0.1872381567955017\n",
      "trial: 11, epoch, 6, iter: 200, curr loss: 0.19012100994586945, avg loss: 0.18465157434344293\n",
      "trial: 11, epoch, 7, iter: 1, curr loss: 0.1816764622926712, avg loss: 0.1816764622926712\n",
      "trial: 11, epoch, 7, iter: 200, curr loss: 0.18074773252010345, avg loss: 0.18450916476547718\n",
      "trial: 11, epoch, 8, iter: 1, curr loss: 0.18872550129890442, avg loss: 0.18872550129890442\n",
      "trial: 11, epoch, 8, iter: 200, curr loss: 0.18569034337997437, avg loss: 0.18425765804946423\n",
      "trial: 11, epoch, 9, iter: 1, curr loss: 0.18246519565582275, avg loss: 0.18246519565582275\n",
      "trial: 11, epoch, 9, iter: 200, curr loss: 0.18254104256629944, avg loss: 0.18388366892933847\n",
      "trial: 11, epoch, 10, iter: 1, curr loss: 0.1842678338289261, avg loss: 0.1842678338289261\n",
      "trial: 11, epoch, 10, iter: 200, curr loss: 0.1777404546737671, avg loss: 0.18460347414016723\n",
      "trial: 11, epoch, 11, iter: 1, curr loss: 0.18404845893383026, avg loss: 0.18404845893383026\n",
      "trial: 11, epoch, 11, iter: 200, curr loss: 0.17973774671554565, avg loss: 0.18444140627980232\n",
      "trial: 11, epoch, 12, iter: 1, curr loss: 0.18684527277946472, avg loss: 0.18684527277946472\n",
      "trial: 11, epoch, 12, iter: 200, curr loss: 0.19243255257606506, avg loss: 0.18516089744865893\n",
      "trial: 11, epoch, 13, iter: 1, curr loss: 0.19455766677856445, avg loss: 0.19455766677856445\n",
      "trial: 11, epoch, 13, iter: 200, curr loss: 0.18654870986938477, avg loss: 0.18483570776879787\n",
      "trial: 11, epoch, 14, iter: 1, curr loss: 0.1894342452287674, avg loss: 0.1894342452287674\n",
      "trial: 11, epoch, 14, iter: 200, curr loss: 0.19204369187355042, avg loss: 0.18459643244743348\n",
      "trial: 11, epoch, 15, iter: 1, curr loss: 0.19020012021064758, avg loss: 0.19020012021064758\n",
      "trial: 11, epoch, 15, iter: 200, curr loss: 0.1919625997543335, avg loss: 0.18454782098531722\n",
      "trial: 11, epoch, 16, iter: 1, curr loss: 0.18719081580638885, avg loss: 0.18719081580638885\n",
      "trial: 11, epoch, 16, iter: 200, curr loss: 0.180232971906662, avg loss: 0.1844119067490101\n",
      "trial: 11, epoch, 17, iter: 1, curr loss: 0.18516573309898376, avg loss: 0.18516573309898376\n",
      "trial: 11, epoch, 17, iter: 200, curr loss: 0.18939058482646942, avg loss: 0.18459135428071022\n",
      "trial: 11, epoch, 18, iter: 1, curr loss: 0.1909656524658203, avg loss: 0.1909656524658203\n",
      "trial: 11, epoch, 18, iter: 200, curr loss: 0.18718349933624268, avg loss: 0.18438053376972674\n",
      "trial: 11, epoch, 19, iter: 1, curr loss: 0.1883888840675354, avg loss: 0.1883888840675354\n",
      "trial: 11, epoch, 19, iter: 200, curr loss: 0.18851958215236664, avg loss: 0.18457905247807502\n",
      "trial: 11, epoch, 20, iter: 1, curr loss: 0.1832830011844635, avg loss: 0.1832830011844635\n",
      "trial: 11, epoch, 20, iter: 200, curr loss: 0.19183513522148132, avg loss: 0.1847600806504488\n",
      "trial: 11, epoch, 21, iter: 1, curr loss: 0.18796434998512268, avg loss: 0.18796434998512268\n",
      "trial: 11, epoch, 21, iter: 200, curr loss: 0.17954523861408234, avg loss: 0.18504323527216912\n",
      "trial: 11, epoch, 22, iter: 1, curr loss: 0.18890133500099182, avg loss: 0.18890133500099182\n",
      "trial: 11, epoch, 22, iter: 200, curr loss: 0.191687673330307, avg loss: 0.18477815546095372\n",
      "trial: 11, epoch, 23, iter: 1, curr loss: 0.18889766931533813, avg loss: 0.18889766931533813\n",
      "trial: 11, epoch, 23, iter: 200, curr loss: 0.18416166305541992, avg loss: 0.18463022455573083\n",
      "trial: 11, epoch, 24, iter: 1, curr loss: 0.19032958149909973, avg loss: 0.19032958149909973\n",
      "trial: 11, epoch, 24, iter: 200, curr loss: 0.1888083517551422, avg loss: 0.1843946861475706\n",
      "trial: 11, epoch, 25, iter: 1, curr loss: 0.18301859498023987, avg loss: 0.18301859498023987\n",
      "trial: 11, epoch, 25, iter: 200, curr loss: 0.19651228189468384, avg loss: 0.1843966606259346\n",
      "trial: 11, epoch, 26, iter: 1, curr loss: 0.19124451279640198, avg loss: 0.19124451279640198\n",
      "trial: 11, epoch, 26, iter: 200, curr loss: 0.18824000656604767, avg loss: 0.18498342752456665\n",
      "trial: 11, epoch, 27, iter: 1, curr loss: 0.20122689008712769, avg loss: 0.20122689008712769\n",
      "trial: 11, epoch, 27, iter: 200, curr loss: 0.1881617158651352, avg loss: 0.18467303484678269\n",
      "trial: 11, epoch, 28, iter: 1, curr loss: 0.18806609511375427, avg loss: 0.18806609511375427\n",
      "trial: 11, epoch, 28, iter: 200, curr loss: 0.19068916141986847, avg loss: 0.18485200688242912\n",
      "trial: 11, epoch, 29, iter: 1, curr loss: 0.18740242719650269, avg loss: 0.18740242719650269\n",
      "trial: 11, epoch, 29, iter: 200, curr loss: 0.19724616408348083, avg loss: 0.18444361977279186\n",
      "trial: 11, epoch, 30, iter: 1, curr loss: 0.18768423795700073, avg loss: 0.18768423795700073\n",
      "trial: 11, epoch, 30, iter: 200, curr loss: 0.1865762174129486, avg loss: 0.18449156694114208\n",
      "trial: 11, epoch, 31, iter: 1, curr loss: 0.18568155169487, avg loss: 0.18568155169487\n",
      "trial: 11, epoch, 31, iter: 200, curr loss: 0.18160882592201233, avg loss: 0.1851745667308569\n",
      "trial: 11, epoch, 32, iter: 1, curr loss: 0.18688134849071503, avg loss: 0.18688134849071503\n",
      "trial: 11, epoch, 32, iter: 200, curr loss: 0.18211185932159424, avg loss: 0.18455369733273982\n",
      "trial: 11, epoch, 33, iter: 1, curr loss: 0.19062629342079163, avg loss: 0.19062629342079163\n",
      "trial: 11, epoch, 33, iter: 200, curr loss: 0.18926629424095154, avg loss: 0.18451484695076942\n",
      "trial: 11, epoch, 34, iter: 1, curr loss: 0.18592645227909088, avg loss: 0.18592645227909088\n",
      "trial: 11, epoch, 34, iter: 200, curr loss: 0.18917909264564514, avg loss: 0.18490926273167133\n",
      "trial: 11, epoch, 35, iter: 1, curr loss: 0.19372770190238953, avg loss: 0.19372770190238953\n",
      "trial: 11, epoch, 35, iter: 200, curr loss: 0.19249868392944336, avg loss: 0.18438644960522652\n",
      "trial: 11, epoch, 36, iter: 1, curr loss: 0.1815507560968399, avg loss: 0.1815507560968399\n",
      "trial: 11, epoch, 36, iter: 200, curr loss: 0.19284257292747498, avg loss: 0.1846464468538761\n",
      "trial: 11, epoch, 37, iter: 1, curr loss: 0.18473462760448456, avg loss: 0.18473462760448456\n",
      "trial: 11, epoch, 37, iter: 200, curr loss: 0.19381898641586304, avg loss: 0.18462106324732303\n",
      "trial: 11, epoch, 38, iter: 1, curr loss: 0.18216350674629211, avg loss: 0.18216350674629211\n",
      "trial: 11, epoch, 38, iter: 200, curr loss: 0.18682172894477844, avg loss: 0.18448829978704454\n",
      "trial: 11, epoch, 39, iter: 1, curr loss: 0.18860499560832977, avg loss: 0.18860499560832977\n",
      "trial: 11, epoch, 39, iter: 200, curr loss: 0.19181805849075317, avg loss: 0.18497700229287148\n",
      "trial: 11, epoch, 40, iter: 1, curr loss: 0.18350844085216522, avg loss: 0.18350844085216522\n",
      "trial: 11, epoch, 40, iter: 200, curr loss: 0.18428713083267212, avg loss: 0.18445197604596614\n",
      "trial: 11, epoch, 41, iter: 1, curr loss: 0.17253899574279785, avg loss: 0.17253899574279785\n",
      "trial: 11, epoch, 41, iter: 200, curr loss: 0.19203177094459534, avg loss: 0.18455747507512568\n",
      "trial: 11, epoch, 42, iter: 1, curr loss: 0.17633308470249176, avg loss: 0.17633308470249176\n",
      "trial: 11, epoch, 42, iter: 200, curr loss: 0.18673476576805115, avg loss: 0.18450365647673606\n",
      "trial: 11, epoch, 43, iter: 1, curr loss: 0.18762855231761932, avg loss: 0.18762855231761932\n",
      "trial: 11, epoch, 43, iter: 200, curr loss: 0.18683770298957825, avg loss: 0.18440100446343421\n",
      "trial: 11, epoch, 44, iter: 1, curr loss: 0.18881523609161377, avg loss: 0.18881523609161377\n",
      "trial: 11, epoch, 44, iter: 200, curr loss: 0.1905507743358612, avg loss: 0.18467121608555317\n",
      "trial: 11, epoch, 45, iter: 1, curr loss: 0.19270318746566772, avg loss: 0.19270318746566772\n",
      "trial: 11, epoch, 45, iter: 200, curr loss: 0.18073594570159912, avg loss: 0.18411852322518826\n",
      "trial: 11, epoch, 46, iter: 1, curr loss: 0.18621128797531128, avg loss: 0.18621128797531128\n",
      "trial: 11, epoch, 46, iter: 200, curr loss: 0.18791991472244263, avg loss: 0.18439642354846\n",
      "trial: 11, epoch, 47, iter: 1, curr loss: 0.18921568989753723, avg loss: 0.18921568989753723\n",
      "trial: 11, epoch, 47, iter: 200, curr loss: 0.18670448660850525, avg loss: 0.18424831584095955\n",
      "trial: 11, epoch, 48, iter: 1, curr loss: 0.18452246487140656, avg loss: 0.18452246487140656\n",
      "trial: 11, epoch, 48, iter: 200, curr loss: 0.17607994377613068, avg loss: 0.18477981120347978\n",
      "trial: 11, epoch, 49, iter: 1, curr loss: 0.18757322430610657, avg loss: 0.18757322430610657\n",
      "trial: 11, epoch, 49, iter: 200, curr loss: 0.18693876266479492, avg loss: 0.18443856425583363\n",
      "trial: 11, epoch, 50, iter: 1, curr loss: 0.18754246830940247, avg loss: 0.18754246830940247\n",
      "trial: 11, epoch, 50, iter: 200, curr loss: 0.18429425358772278, avg loss: 0.18505678117275237\n",
      "trial: 11, ldr: 19.140932083129883, dv: 20.529115676879883, nwj: 19.891403198242188\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 12, epoch, 1, iter: 1, curr loss: 0.6926453113555908, avg loss: 0.6926453113555908\n",
      "trial: 12, epoch, 1, iter: 200, curr loss: 0.1853492707014084, avg loss: 0.22563894875347615\n",
      "trial: 12, epoch, 2, iter: 1, curr loss: 0.19117815792560577, avg loss: 0.19117815792560577\n",
      "trial: 12, epoch, 2, iter: 200, curr loss: 0.18495479226112366, avg loss: 0.1863354416191578\n",
      "trial: 12, epoch, 3, iter: 1, curr loss: 0.1910851001739502, avg loss: 0.1910851001739502\n",
      "trial: 12, epoch, 3, iter: 200, curr loss: 0.19670742750167847, avg loss: 0.18570270508527756\n",
      "trial: 12, epoch, 4, iter: 1, curr loss: 0.1734892725944519, avg loss: 0.1734892725944519\n",
      "trial: 12, epoch, 4, iter: 200, curr loss: 0.19169054925441742, avg loss: 0.18541804671287537\n",
      "trial: 12, epoch, 5, iter: 1, curr loss: 0.1896498203277588, avg loss: 0.1896498203277588\n",
      "trial: 12, epoch, 5, iter: 200, curr loss: 0.1786029189825058, avg loss: 0.1852269384264946\n",
      "trial: 12, epoch, 6, iter: 1, curr loss: 0.1871887892484665, avg loss: 0.1871887892484665\n",
      "trial: 12, epoch, 6, iter: 200, curr loss: 0.1863112598657608, avg loss: 0.18457692861557007\n",
      "trial: 12, epoch, 7, iter: 1, curr loss: 0.18895408511161804, avg loss: 0.18895408511161804\n",
      "trial: 12, epoch, 7, iter: 200, curr loss: 0.1922917366027832, avg loss: 0.1850265134125948\n",
      "trial: 12, epoch, 8, iter: 1, curr loss: 0.18741926550865173, avg loss: 0.18741926550865173\n",
      "trial: 12, epoch, 8, iter: 200, curr loss: 0.184607595205307, avg loss: 0.18486161313951016\n",
      "trial: 12, epoch, 9, iter: 1, curr loss: 0.18684282898902893, avg loss: 0.18684282898902893\n",
      "trial: 12, epoch, 9, iter: 200, curr loss: 0.1855459362268448, avg loss: 0.18465007364749908\n",
      "trial: 12, epoch, 10, iter: 1, curr loss: 0.18914595246315002, avg loss: 0.18914595246315002\n",
      "trial: 12, epoch, 10, iter: 200, curr loss: 0.18763867020606995, avg loss: 0.18421117432415485\n",
      "trial: 12, epoch, 11, iter: 1, curr loss: 0.18171675503253937, avg loss: 0.18171675503253937\n",
      "trial: 12, epoch, 11, iter: 200, curr loss: 0.18158413469791412, avg loss: 0.18470933847129345\n",
      "trial: 12, epoch, 12, iter: 1, curr loss: 0.1794358789920807, avg loss: 0.1794358789920807\n",
      "trial: 12, epoch, 12, iter: 200, curr loss: 0.18825265765190125, avg loss: 0.18461785092949867\n",
      "trial: 12, epoch, 13, iter: 1, curr loss: 0.19241869449615479, avg loss: 0.19241869449615479\n",
      "trial: 12, epoch, 13, iter: 200, curr loss: 0.18327486515045166, avg loss: 0.18439408004283905\n",
      "trial: 12, epoch, 14, iter: 1, curr loss: 0.1830899864435196, avg loss: 0.1830899864435196\n",
      "trial: 12, epoch, 14, iter: 200, curr loss: 0.18543493747711182, avg loss: 0.18392969124019146\n",
      "trial: 12, epoch, 15, iter: 1, curr loss: 0.1921364665031433, avg loss: 0.1921364665031433\n",
      "trial: 12, epoch, 15, iter: 200, curr loss: 0.1857682466506958, avg loss: 0.18489943712949752\n",
      "trial: 12, epoch, 16, iter: 1, curr loss: 0.18486768007278442, avg loss: 0.18486768007278442\n",
      "trial: 12, epoch, 16, iter: 200, curr loss: 0.18911351263523102, avg loss: 0.18454970449209213\n",
      "trial: 12, epoch, 17, iter: 1, curr loss: 0.18776580691337585, avg loss: 0.18776580691337585\n",
      "trial: 12, epoch, 17, iter: 200, curr loss: 0.1800912767648697, avg loss: 0.18443005077540875\n",
      "trial: 12, epoch, 18, iter: 1, curr loss: 0.1834811419248581, avg loss: 0.1834811419248581\n",
      "trial: 12, epoch, 18, iter: 200, curr loss: 0.1792806088924408, avg loss: 0.1846851423382759\n",
      "trial: 12, epoch, 19, iter: 1, curr loss: 0.1832677721977234, avg loss: 0.1832677721977234\n",
      "trial: 12, epoch, 19, iter: 200, curr loss: 0.1971467137336731, avg loss: 0.18523688569664956\n",
      "trial: 12, epoch, 20, iter: 1, curr loss: 0.17774125933647156, avg loss: 0.17774125933647156\n",
      "trial: 12, epoch, 20, iter: 200, curr loss: 0.17846864461898804, avg loss: 0.18442343845963477\n",
      "trial: 12, epoch, 21, iter: 1, curr loss: 0.18248093128204346, avg loss: 0.18248093128204346\n",
      "trial: 12, epoch, 21, iter: 200, curr loss: 0.18704944849014282, avg loss: 0.1843899257481098\n",
      "trial: 12, epoch, 22, iter: 1, curr loss: 0.1930190622806549, avg loss: 0.1930190622806549\n",
      "trial: 12, epoch, 22, iter: 200, curr loss: 0.1888435184955597, avg loss: 0.1848898757249117\n",
      "trial: 12, epoch, 23, iter: 1, curr loss: 0.181188702583313, avg loss: 0.181188702583313\n",
      "trial: 12, epoch, 23, iter: 200, curr loss: 0.19076092541217804, avg loss: 0.1845697622746229\n",
      "trial: 12, epoch, 24, iter: 1, curr loss: 0.18184055387973785, avg loss: 0.18184055387973785\n",
      "trial: 12, epoch, 24, iter: 200, curr loss: 0.18031904101371765, avg loss: 0.1847816951572895\n",
      "trial: 12, epoch, 25, iter: 1, curr loss: 0.18055742979049683, avg loss: 0.18055742979049683\n",
      "trial: 12, epoch, 25, iter: 200, curr loss: 0.1857568323612213, avg loss: 0.18422845661640166\n",
      "trial: 12, epoch, 26, iter: 1, curr loss: 0.18449124693870544, avg loss: 0.18449124693870544\n",
      "trial: 12, epoch, 26, iter: 200, curr loss: 0.19022057950496674, avg loss: 0.1847175035625696\n",
      "trial: 12, epoch, 27, iter: 1, curr loss: 0.18223993480205536, avg loss: 0.18223993480205536\n",
      "trial: 12, epoch, 27, iter: 200, curr loss: 0.1820528507232666, avg loss: 0.1844107324630022\n",
      "trial: 12, epoch, 28, iter: 1, curr loss: 0.18082845211029053, avg loss: 0.18082845211029053\n",
      "trial: 12, epoch, 28, iter: 200, curr loss: 0.1885049194097519, avg loss: 0.18428898975253105\n",
      "trial: 12, epoch, 29, iter: 1, curr loss: 0.18910694122314453, avg loss: 0.18910694122314453\n",
      "trial: 12, epoch, 29, iter: 200, curr loss: 0.17468954622745514, avg loss: 0.18444847017526628\n",
      "trial: 12, epoch, 30, iter: 1, curr loss: 0.18217143416404724, avg loss: 0.18217143416404724\n",
      "trial: 12, epoch, 30, iter: 200, curr loss: 0.18300801515579224, avg loss: 0.18474068239331246\n",
      "trial: 12, epoch, 31, iter: 1, curr loss: 0.19314955174922943, avg loss: 0.19314955174922943\n",
      "trial: 12, epoch, 31, iter: 200, curr loss: 0.1780470907688141, avg loss: 0.18470982871949673\n",
      "trial: 12, epoch, 32, iter: 1, curr loss: 0.18566226959228516, avg loss: 0.18566226959228516\n",
      "trial: 12, epoch, 32, iter: 200, curr loss: 0.184044748544693, avg loss: 0.1843259946256876\n",
      "trial: 12, epoch, 33, iter: 1, curr loss: 0.18000289797782898, avg loss: 0.18000289797782898\n",
      "trial: 12, epoch, 33, iter: 200, curr loss: 0.18520842492580414, avg loss: 0.18474156267940997\n",
      "trial: 12, epoch, 34, iter: 1, curr loss: 0.1815262734889984, avg loss: 0.1815262734889984\n",
      "trial: 12, epoch, 34, iter: 200, curr loss: 0.17821578681468964, avg loss: 0.18453855536878108\n",
      "trial: 12, epoch, 35, iter: 1, curr loss: 0.18491671979427338, avg loss: 0.18491671979427338\n",
      "trial: 12, epoch, 35, iter: 200, curr loss: 0.1747521013021469, avg loss: 0.18479603990912438\n",
      "trial: 12, epoch, 36, iter: 1, curr loss: 0.17838546633720398, avg loss: 0.17838546633720398\n",
      "trial: 12, epoch, 36, iter: 200, curr loss: 0.18933458626270294, avg loss: 0.18453879989683628\n",
      "trial: 12, epoch, 37, iter: 1, curr loss: 0.19066645205020905, avg loss: 0.19066645205020905\n",
      "trial: 12, epoch, 37, iter: 200, curr loss: 0.184475377202034, avg loss: 0.184437995031476\n",
      "trial: 12, epoch, 38, iter: 1, curr loss: 0.17503134906291962, avg loss: 0.17503134906291962\n",
      "trial: 12, epoch, 38, iter: 200, curr loss: 0.1829262226819992, avg loss: 0.18461454406380653\n",
      "trial: 12, epoch, 39, iter: 1, curr loss: 0.18933090567588806, avg loss: 0.18933090567588806\n",
      "trial: 12, epoch, 39, iter: 200, curr loss: 0.18227243423461914, avg loss: 0.18427159629762171\n",
      "trial: 12, epoch, 40, iter: 1, curr loss: 0.18925222754478455, avg loss: 0.18925222754478455\n",
      "trial: 12, epoch, 40, iter: 200, curr loss: 0.18649068474769592, avg loss: 0.18433614797890185\n",
      "trial: 12, epoch, 41, iter: 1, curr loss: 0.17445805668830872, avg loss: 0.17445805668830872\n",
      "trial: 12, epoch, 41, iter: 200, curr loss: 0.1966579407453537, avg loss: 0.1847048255056143\n",
      "trial: 12, epoch, 42, iter: 1, curr loss: 0.18837429583072662, avg loss: 0.18837429583072662\n",
      "trial: 12, epoch, 42, iter: 200, curr loss: 0.1725793033838272, avg loss: 0.18433858312666415\n",
      "trial: 12, epoch, 43, iter: 1, curr loss: 0.19354495406150818, avg loss: 0.19354495406150818\n",
      "trial: 12, epoch, 43, iter: 200, curr loss: 0.1790805160999298, avg loss: 0.1846464540809393\n",
      "trial: 12, epoch, 44, iter: 1, curr loss: 0.18292218446731567, avg loss: 0.18292218446731567\n",
      "trial: 12, epoch, 44, iter: 200, curr loss: 0.18442577123641968, avg loss: 0.18441797964274884\n",
      "trial: 12, epoch, 45, iter: 1, curr loss: 0.1831609159708023, avg loss: 0.1831609159708023\n",
      "trial: 12, epoch, 45, iter: 200, curr loss: 0.19027093052864075, avg loss: 0.18427673369646072\n",
      "trial: 12, epoch, 46, iter: 1, curr loss: 0.18141897022724152, avg loss: 0.18141897022724152\n",
      "trial: 12, epoch, 46, iter: 200, curr loss: 0.19274643063545227, avg loss: 0.18441989555954932\n",
      "trial: 12, epoch, 47, iter: 1, curr loss: 0.18575716018676758, avg loss: 0.18575716018676758\n",
      "trial: 12, epoch, 47, iter: 200, curr loss: 0.18573403358459473, avg loss: 0.18429968789219855\n",
      "trial: 12, epoch, 48, iter: 1, curr loss: 0.18403947353363037, avg loss: 0.18403947353363037\n",
      "trial: 12, epoch, 48, iter: 200, curr loss: 0.17698359489440918, avg loss: 0.18374596089124678\n",
      "trial: 12, epoch, 49, iter: 1, curr loss: 0.18424993753433228, avg loss: 0.18424993753433228\n",
      "trial: 12, epoch, 49, iter: 200, curr loss: 0.18848156929016113, avg loss: 0.18476841889321804\n",
      "trial: 12, epoch, 50, iter: 1, curr loss: 0.18175986409187317, avg loss: 0.18175986409187317\n",
      "trial: 12, epoch, 50, iter: 200, curr loss: 0.18046247959136963, avg loss: 0.18408271580934524\n",
      "trial: 12, ldr: 17.18524169921875, dv: 18.56825828552246, nwj: 17.93442153930664\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 13, epoch, 1, iter: 1, curr loss: 0.6932027339935303, avg loss: 0.6932027339935303\n",
      "trial: 13, epoch, 1, iter: 200, curr loss: 0.19002795219421387, avg loss: 0.22762348271906377\n",
      "trial: 13, epoch, 2, iter: 1, curr loss: 0.19402998685836792, avg loss: 0.19402998685836792\n",
      "trial: 13, epoch, 2, iter: 200, curr loss: 0.1914348602294922, avg loss: 0.186975931301713\n",
      "trial: 13, epoch, 3, iter: 1, curr loss: 0.19118943810462952, avg loss: 0.19118943810462952\n",
      "trial: 13, epoch, 3, iter: 200, curr loss: 0.1781674027442932, avg loss: 0.18635596990585326\n",
      "trial: 13, epoch, 4, iter: 1, curr loss: 0.18292897939682007, avg loss: 0.18292897939682007\n",
      "trial: 13, epoch, 4, iter: 200, curr loss: 0.19389033317565918, avg loss: 0.18519382804632187\n",
      "trial: 13, epoch, 5, iter: 1, curr loss: 0.18497097492218018, avg loss: 0.18497097492218018\n",
      "trial: 13, epoch, 5, iter: 200, curr loss: 0.1975901871919632, avg loss: 0.18475004695355893\n",
      "trial: 13, epoch, 6, iter: 1, curr loss: 0.1897454857826233, avg loss: 0.1897454857826233\n",
      "trial: 13, epoch, 6, iter: 200, curr loss: 0.1756836622953415, avg loss: 0.18496836021542548\n",
      "trial: 13, epoch, 7, iter: 1, curr loss: 0.19070865213871002, avg loss: 0.19070865213871002\n",
      "trial: 13, epoch, 7, iter: 200, curr loss: 0.1868896782398224, avg loss: 0.18459311477839946\n",
      "trial: 13, epoch, 8, iter: 1, curr loss: 0.1948981136083603, avg loss: 0.1948981136083603\n",
      "trial: 13, epoch, 8, iter: 200, curr loss: 0.18600869178771973, avg loss: 0.1847723203897476\n",
      "trial: 13, epoch, 9, iter: 1, curr loss: 0.18159633874893188, avg loss: 0.18159633874893188\n",
      "trial: 13, epoch, 9, iter: 200, curr loss: 0.1937824785709381, avg loss: 0.18442704536020757\n",
      "trial: 13, epoch, 10, iter: 1, curr loss: 0.18785032629966736, avg loss: 0.18785032629966736\n",
      "trial: 13, epoch, 10, iter: 200, curr loss: 0.17924365401268005, avg loss: 0.18415663436055182\n",
      "trial: 13, epoch, 11, iter: 1, curr loss: 0.18003246188163757, avg loss: 0.18003246188163757\n",
      "trial: 13, epoch, 11, iter: 200, curr loss: 0.1773953139781952, avg loss: 0.18465733267366885\n",
      "trial: 13, epoch, 12, iter: 1, curr loss: 0.18539012968540192, avg loss: 0.18539012968540192\n",
      "trial: 13, epoch, 12, iter: 200, curr loss: 0.1888488233089447, avg loss: 0.18453914523124695\n",
      "trial: 13, epoch, 13, iter: 1, curr loss: 0.18264761567115784, avg loss: 0.18264761567115784\n",
      "trial: 13, epoch, 13, iter: 200, curr loss: 0.18728940188884735, avg loss: 0.18449210301041602\n",
      "trial: 13, epoch, 14, iter: 1, curr loss: 0.1758752167224884, avg loss: 0.1758752167224884\n",
      "trial: 13, epoch, 14, iter: 200, curr loss: 0.17788058519363403, avg loss: 0.18480700440704823\n",
      "trial: 13, epoch, 15, iter: 1, curr loss: 0.18814398348331451, avg loss: 0.18814398348331451\n",
      "trial: 13, epoch, 15, iter: 200, curr loss: 0.19439822435379028, avg loss: 0.18504356645047665\n",
      "trial: 13, epoch, 16, iter: 1, curr loss: 0.18136191368103027, avg loss: 0.18136191368103027\n",
      "trial: 13, epoch, 16, iter: 200, curr loss: 0.1862478107213974, avg loss: 0.1844286547601223\n",
      "trial: 13, epoch, 17, iter: 1, curr loss: 0.18715974688529968, avg loss: 0.18715974688529968\n",
      "trial: 13, epoch, 17, iter: 200, curr loss: 0.1815403550863266, avg loss: 0.1843798527866602\n",
      "trial: 13, epoch, 18, iter: 1, curr loss: 0.18437235057353973, avg loss: 0.18437235057353973\n",
      "trial: 13, epoch, 18, iter: 200, curr loss: 0.18130888044834137, avg loss: 0.18445752635598184\n",
      "trial: 13, epoch, 19, iter: 1, curr loss: 0.18862807750701904, avg loss: 0.18862807750701904\n",
      "trial: 13, epoch, 19, iter: 200, curr loss: 0.1867905706167221, avg loss: 0.1848502241820097\n",
      "trial: 13, epoch, 20, iter: 1, curr loss: 0.1827416568994522, avg loss: 0.1827416568994522\n",
      "trial: 13, epoch, 20, iter: 200, curr loss: 0.18599024415016174, avg loss: 0.18435597158968448\n",
      "trial: 13, epoch, 21, iter: 1, curr loss: 0.1801377832889557, avg loss: 0.1801377832889557\n",
      "trial: 13, epoch, 21, iter: 200, curr loss: 0.17787936329841614, avg loss: 0.1843333975225687\n",
      "trial: 13, epoch, 22, iter: 1, curr loss: 0.1830984354019165, avg loss: 0.1830984354019165\n",
      "trial: 13, epoch, 22, iter: 200, curr loss: 0.18639115989208221, avg loss: 0.18452513299882412\n",
      "trial: 13, epoch, 23, iter: 1, curr loss: 0.1923152655363083, avg loss: 0.1923152655363083\n",
      "trial: 13, epoch, 23, iter: 200, curr loss: 0.18894094228744507, avg loss: 0.1845057289302349\n",
      "trial: 13, epoch, 24, iter: 1, curr loss: 0.18732912838459015, avg loss: 0.18732912838459015\n",
      "trial: 13, epoch, 24, iter: 200, curr loss: 0.19252589344978333, avg loss: 0.18461918994784354\n",
      "trial: 13, epoch, 25, iter: 1, curr loss: 0.18132780492305756, avg loss: 0.18132780492305756\n",
      "trial: 13, epoch, 25, iter: 200, curr loss: 0.18820282816886902, avg loss: 0.18481766372919084\n",
      "trial: 13, epoch, 26, iter: 1, curr loss: 0.18616938591003418, avg loss: 0.18616938591003418\n",
      "trial: 13, epoch, 26, iter: 200, curr loss: 0.1744334101676941, avg loss: 0.18452382549643517\n",
      "trial: 13, epoch, 27, iter: 1, curr loss: 0.18995800614356995, avg loss: 0.18995800614356995\n",
      "trial: 13, epoch, 27, iter: 200, curr loss: 0.18662700057029724, avg loss: 0.18474838346242906\n",
      "trial: 13, epoch, 28, iter: 1, curr loss: 0.18584594130516052, avg loss: 0.18584594130516052\n",
      "trial: 13, epoch, 28, iter: 200, curr loss: 0.18402299284934998, avg loss: 0.18452963292598723\n",
      "trial: 13, epoch, 29, iter: 1, curr loss: 0.193171888589859, avg loss: 0.193171888589859\n",
      "trial: 13, epoch, 29, iter: 200, curr loss: 0.18508073687553406, avg loss: 0.18436203218996525\n",
      "trial: 13, epoch, 30, iter: 1, curr loss: 0.1823083609342575, avg loss: 0.1823083609342575\n",
      "trial: 13, epoch, 30, iter: 200, curr loss: 0.18442630767822266, avg loss: 0.18483310781419277\n",
      "trial: 13, epoch, 31, iter: 1, curr loss: 0.1852502077817917, avg loss: 0.1852502077817917\n",
      "trial: 13, epoch, 31, iter: 200, curr loss: 0.17957362532615662, avg loss: 0.1847596900910139\n",
      "trial: 13, epoch, 32, iter: 1, curr loss: 0.19437411427497864, avg loss: 0.19437411427497864\n",
      "trial: 13, epoch, 32, iter: 200, curr loss: 0.19331520795822144, avg loss: 0.18485263496637344\n",
      "trial: 13, epoch, 33, iter: 1, curr loss: 0.18760302662849426, avg loss: 0.18760302662849426\n",
      "trial: 13, epoch, 33, iter: 200, curr loss: 0.186666339635849, avg loss: 0.18504785612225533\n",
      "trial: 13, epoch, 34, iter: 1, curr loss: 0.1845194399356842, avg loss: 0.1845194399356842\n",
      "trial: 13, epoch, 34, iter: 200, curr loss: 0.18785250186920166, avg loss: 0.1846427232027054\n",
      "trial: 13, epoch, 35, iter: 1, curr loss: 0.18303489685058594, avg loss: 0.18303489685058594\n",
      "trial: 13, epoch, 35, iter: 200, curr loss: 0.1870109736919403, avg loss: 0.18428182326257228\n",
      "trial: 13, epoch, 36, iter: 1, curr loss: 0.18001411855220795, avg loss: 0.18001411855220795\n",
      "trial: 13, epoch, 36, iter: 200, curr loss: 0.18633446097373962, avg loss: 0.184441197514534\n",
      "trial: 13, epoch, 37, iter: 1, curr loss: 0.19033676385879517, avg loss: 0.19033676385879517\n",
      "trial: 13, epoch, 37, iter: 200, curr loss: 0.18683242797851562, avg loss: 0.18481423005461692\n",
      "trial: 13, epoch, 38, iter: 1, curr loss: 0.18777525424957275, avg loss: 0.18777525424957275\n",
      "trial: 13, epoch, 38, iter: 200, curr loss: 0.18333251774311066, avg loss: 0.18455695159733296\n",
      "trial: 13, epoch, 39, iter: 1, curr loss: 0.18452100455760956, avg loss: 0.18452100455760956\n",
      "trial: 13, epoch, 39, iter: 200, curr loss: 0.19352799654006958, avg loss: 0.1843639287352562\n",
      "trial: 13, epoch, 40, iter: 1, curr loss: 0.1889941394329071, avg loss: 0.1889941394329071\n",
      "trial: 13, epoch, 40, iter: 200, curr loss: 0.18840134143829346, avg loss: 0.18432903230190278\n",
      "trial: 13, epoch, 41, iter: 1, curr loss: 0.18123313784599304, avg loss: 0.18123313784599304\n",
      "trial: 13, epoch, 41, iter: 200, curr loss: 0.18873995542526245, avg loss: 0.18433183021843433\n",
      "trial: 13, epoch, 42, iter: 1, curr loss: 0.184685617685318, avg loss: 0.184685617685318\n",
      "trial: 13, epoch, 42, iter: 200, curr loss: 0.1912500262260437, avg loss: 0.1844051644206047\n",
      "trial: 13, epoch, 43, iter: 1, curr loss: 0.18938256800174713, avg loss: 0.18938256800174713\n",
      "trial: 13, epoch, 43, iter: 200, curr loss: 0.18716073036193848, avg loss: 0.18446310363709928\n",
      "trial: 13, epoch, 44, iter: 1, curr loss: 0.18893492221832275, avg loss: 0.18893492221832275\n",
      "trial: 13, epoch, 44, iter: 200, curr loss: 0.18355128169059753, avg loss: 0.18424246355891227\n",
      "trial: 13, epoch, 45, iter: 1, curr loss: 0.18997372686862946, avg loss: 0.18997372686862946\n",
      "trial: 13, epoch, 45, iter: 200, curr loss: 0.18404686450958252, avg loss: 0.1846934936195612\n",
      "trial: 13, epoch, 46, iter: 1, curr loss: 0.18766741454601288, avg loss: 0.18766741454601288\n",
      "trial: 13, epoch, 46, iter: 200, curr loss: 0.18676406145095825, avg loss: 0.18473069481551646\n",
      "trial: 13, epoch, 47, iter: 1, curr loss: 0.190023735165596, avg loss: 0.190023735165596\n",
      "trial: 13, epoch, 47, iter: 200, curr loss: 0.18722006678581238, avg loss: 0.18445670634508132\n",
      "trial: 13, epoch, 48, iter: 1, curr loss: 0.1753525733947754, avg loss: 0.1753525733947754\n",
      "trial: 13, epoch, 48, iter: 200, curr loss: 0.18145576119422913, avg loss: 0.18478688769042492\n",
      "trial: 13, epoch, 49, iter: 1, curr loss: 0.18197937309741974, avg loss: 0.18197937309741974\n",
      "trial: 13, epoch, 49, iter: 200, curr loss: 0.1896260678768158, avg loss: 0.1849988493323326\n",
      "trial: 13, epoch, 50, iter: 1, curr loss: 0.1878381073474884, avg loss: 0.1878381073474884\n",
      "trial: 13, epoch, 50, iter: 200, curr loss: 0.1852721869945526, avg loss: 0.18436494462192057\n",
      "trial: 13, ldr: 20.72020149230957, dv: 22.109376907348633, nwj: 21.47092056274414\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 14, epoch, 1, iter: 1, curr loss: 0.693641185760498, avg loss: 0.693641185760498\n",
      "trial: 14, epoch, 1, iter: 200, curr loss: 0.1805495023727417, avg loss: 0.22924016900360583\n",
      "trial: 14, epoch, 2, iter: 1, curr loss: 0.1833893358707428, avg loss: 0.1833893358707428\n",
      "trial: 14, epoch, 2, iter: 200, curr loss: 0.19269201159477234, avg loss: 0.18612729057669639\n",
      "trial: 14, epoch, 3, iter: 1, curr loss: 0.18833360075950623, avg loss: 0.18833360075950623\n",
      "trial: 14, epoch, 3, iter: 200, curr loss: 0.18763309717178345, avg loss: 0.18608063831925392\n",
      "trial: 14, epoch, 4, iter: 1, curr loss: 0.1749686449766159, avg loss: 0.1749686449766159\n",
      "trial: 14, epoch, 4, iter: 200, curr loss: 0.18816864490509033, avg loss: 0.18563556402921677\n",
      "trial: 14, epoch, 5, iter: 1, curr loss: 0.18866682052612305, avg loss: 0.18866682052612305\n",
      "trial: 14, epoch, 5, iter: 200, curr loss: 0.19195179641246796, avg loss: 0.1847498258203268\n",
      "trial: 14, epoch, 6, iter: 1, curr loss: 0.19075030088424683, avg loss: 0.19075030088424683\n",
      "trial: 14, epoch, 6, iter: 200, curr loss: 0.1873684823513031, avg loss: 0.18503786921501159\n",
      "trial: 14, epoch, 7, iter: 1, curr loss: 0.18837004899978638, avg loss: 0.18837004899978638\n",
      "trial: 14, epoch, 7, iter: 200, curr loss: 0.18124738335609436, avg loss: 0.18521634705364703\n",
      "trial: 14, epoch, 8, iter: 1, curr loss: 0.18464380502700806, avg loss: 0.18464380502700806\n",
      "trial: 14, epoch, 8, iter: 200, curr loss: 0.18839427828788757, avg loss: 0.1845108637958765\n",
      "trial: 14, epoch, 9, iter: 1, curr loss: 0.18672874569892883, avg loss: 0.18672874569892883\n",
      "trial: 14, epoch, 9, iter: 200, curr loss: 0.18523095548152924, avg loss: 0.18484768711030483\n",
      "trial: 14, epoch, 10, iter: 1, curr loss: 0.1924460530281067, avg loss: 0.1924460530281067\n",
      "trial: 14, epoch, 10, iter: 200, curr loss: 0.17973966896533966, avg loss: 0.18469436928629876\n",
      "trial: 14, epoch, 11, iter: 1, curr loss: 0.18364961445331573, avg loss: 0.18364961445331573\n",
      "trial: 14, epoch, 11, iter: 200, curr loss: 0.18381479382514954, avg loss: 0.18457787327468395\n",
      "trial: 14, epoch, 12, iter: 1, curr loss: 0.1930921971797943, avg loss: 0.1930921971797943\n",
      "trial: 14, epoch, 12, iter: 200, curr loss: 0.18237420916557312, avg loss: 0.18480008617043495\n",
      "trial: 14, epoch, 13, iter: 1, curr loss: 0.1820591688156128, avg loss: 0.1820591688156128\n",
      "trial: 14, epoch, 13, iter: 200, curr loss: 0.1896391212940216, avg loss: 0.1846319182217121\n",
      "trial: 14, epoch, 14, iter: 1, curr loss: 0.18744322657585144, avg loss: 0.18744322657585144\n",
      "trial: 14, epoch, 14, iter: 200, curr loss: 0.1907486766576767, avg loss: 0.1845607552677393\n",
      "trial: 14, epoch, 15, iter: 1, curr loss: 0.18190786242485046, avg loss: 0.18190786242485046\n",
      "trial: 14, epoch, 15, iter: 200, curr loss: 0.1856851875782013, avg loss: 0.18484402135014533\n",
      "trial: 14, epoch, 16, iter: 1, curr loss: 0.1862974762916565, avg loss: 0.1862974762916565\n",
      "trial: 14, epoch, 16, iter: 200, curr loss: 0.1976841688156128, avg loss: 0.18469250805675982\n",
      "trial: 14, epoch, 17, iter: 1, curr loss: 0.18865373730659485, avg loss: 0.18865373730659485\n",
      "trial: 14, epoch, 17, iter: 200, curr loss: 0.1869317591190338, avg loss: 0.18424158781766892\n",
      "trial: 14, epoch, 18, iter: 1, curr loss: 0.19866564869880676, avg loss: 0.19866564869880676\n",
      "trial: 14, epoch, 18, iter: 200, curr loss: 0.18602225184440613, avg loss: 0.18451496355235578\n",
      "trial: 14, epoch, 19, iter: 1, curr loss: 0.17565801739692688, avg loss: 0.17565801739692688\n",
      "trial: 14, epoch, 19, iter: 200, curr loss: 0.18024376034736633, avg loss: 0.18490979753434658\n",
      "trial: 14, epoch, 20, iter: 1, curr loss: 0.19114519655704498, avg loss: 0.19114519655704498\n",
      "trial: 14, epoch, 20, iter: 200, curr loss: 0.1895686686038971, avg loss: 0.18470106810331344\n",
      "trial: 14, epoch, 21, iter: 1, curr loss: 0.1826377809047699, avg loss: 0.1826377809047699\n",
      "trial: 14, epoch, 21, iter: 200, curr loss: 0.1865796595811844, avg loss: 0.18464288592338562\n",
      "trial: 14, epoch, 22, iter: 1, curr loss: 0.18614435195922852, avg loss: 0.18614435195922852\n",
      "trial: 14, epoch, 22, iter: 200, curr loss: 0.1769975870847702, avg loss: 0.18471223525702954\n",
      "trial: 14, epoch, 23, iter: 1, curr loss: 0.18509288132190704, avg loss: 0.18509288132190704\n",
      "trial: 14, epoch, 23, iter: 200, curr loss: 0.18036247789859772, avg loss: 0.18428236417472363\n",
      "trial: 14, epoch, 24, iter: 1, curr loss: 0.18319430947303772, avg loss: 0.18319430947303772\n",
      "trial: 14, epoch, 24, iter: 200, curr loss: 0.17754384875297546, avg loss: 0.18450547873973847\n",
      "trial: 14, epoch, 25, iter: 1, curr loss: 0.18449293076992035, avg loss: 0.18449293076992035\n",
      "trial: 14, epoch, 25, iter: 200, curr loss: 0.19203568994998932, avg loss: 0.1844120515137911\n",
      "trial: 14, epoch, 26, iter: 1, curr loss: 0.17914777994155884, avg loss: 0.17914777994155884\n",
      "trial: 14, epoch, 26, iter: 200, curr loss: 0.1868177056312561, avg loss: 0.1847908014804125\n",
      "trial: 14, epoch, 27, iter: 1, curr loss: 0.17902937531471252, avg loss: 0.17902937531471252\n",
      "trial: 14, epoch, 27, iter: 200, curr loss: 0.17606911063194275, avg loss: 0.18421991370618343\n",
      "trial: 14, epoch, 28, iter: 1, curr loss: 0.18563608825206757, avg loss: 0.18563608825206757\n",
      "trial: 14, epoch, 28, iter: 200, curr loss: 0.19040758907794952, avg loss: 0.18453069627285004\n",
      "trial: 14, epoch, 29, iter: 1, curr loss: 0.18731042742729187, avg loss: 0.18731042742729187\n",
      "trial: 14, epoch, 29, iter: 200, curr loss: 0.1865401715040207, avg loss: 0.18469321556389331\n",
      "trial: 14, epoch, 30, iter: 1, curr loss: 0.17763033509254456, avg loss: 0.17763033509254456\n",
      "trial: 14, epoch, 30, iter: 200, curr loss: 0.18873444199562073, avg loss: 0.18417874455451966\n",
      "trial: 14, epoch, 31, iter: 1, curr loss: 0.19098424911499023, avg loss: 0.19098424911499023\n",
      "trial: 14, epoch, 31, iter: 200, curr loss: 0.18099410831928253, avg loss: 0.18439469799399377\n",
      "trial: 14, epoch, 32, iter: 1, curr loss: 0.17227321863174438, avg loss: 0.17227321863174438\n",
      "trial: 14, epoch, 32, iter: 200, curr loss: 0.18835589289665222, avg loss: 0.18439794160425663\n",
      "trial: 14, epoch, 33, iter: 1, curr loss: 0.19021129608154297, avg loss: 0.19021129608154297\n",
      "trial: 14, epoch, 33, iter: 200, curr loss: 0.19014449417591095, avg loss: 0.18436203353106975\n",
      "trial: 14, epoch, 34, iter: 1, curr loss: 0.18705201148986816, avg loss: 0.18705201148986816\n",
      "trial: 14, epoch, 34, iter: 200, curr loss: 0.18439698219299316, avg loss: 0.18423343695700167\n",
      "trial: 14, epoch, 35, iter: 1, curr loss: 0.18655025959014893, avg loss: 0.18655025959014893\n",
      "trial: 14, epoch, 35, iter: 200, curr loss: 0.178645521402359, avg loss: 0.18494947589933872\n",
      "trial: 14, epoch, 36, iter: 1, curr loss: 0.18485671281814575, avg loss: 0.18485671281814575\n",
      "trial: 14, epoch, 36, iter: 200, curr loss: 0.18534527719020844, avg loss: 0.18454765319824218\n",
      "trial: 14, epoch, 37, iter: 1, curr loss: 0.1787799745798111, avg loss: 0.1787799745798111\n",
      "trial: 14, epoch, 37, iter: 200, curr loss: 0.19059321284294128, avg loss: 0.18453178972005843\n",
      "trial: 14, epoch, 38, iter: 1, curr loss: 0.18902620673179626, avg loss: 0.18902620673179626\n",
      "trial: 14, epoch, 38, iter: 200, curr loss: 0.18130165338516235, avg loss: 0.18470859929919242\n",
      "trial: 14, epoch, 39, iter: 1, curr loss: 0.1837788224220276, avg loss: 0.1837788224220276\n",
      "trial: 14, epoch, 39, iter: 200, curr loss: 0.18971872329711914, avg loss: 0.18425747156143188\n",
      "trial: 14, epoch, 40, iter: 1, curr loss: 0.19149750471115112, avg loss: 0.19149750471115112\n",
      "trial: 14, epoch, 40, iter: 200, curr loss: 0.18934296071529388, avg loss: 0.18500862441956997\n",
      "trial: 14, epoch, 41, iter: 1, curr loss: 0.1881890445947647, avg loss: 0.1881890445947647\n",
      "trial: 14, epoch, 41, iter: 200, curr loss: 0.183336541056633, avg loss: 0.184578360915184\n",
      "trial: 14, epoch, 42, iter: 1, curr loss: 0.18644611537456512, avg loss: 0.18644611537456512\n",
      "trial: 14, epoch, 42, iter: 200, curr loss: 0.18144403398036957, avg loss: 0.18443633206188678\n",
      "trial: 14, epoch, 43, iter: 1, curr loss: 0.1878509819507599, avg loss: 0.1878509819507599\n",
      "trial: 14, epoch, 43, iter: 200, curr loss: 0.18428345024585724, avg loss: 0.18463646486401558\n",
      "trial: 14, epoch, 44, iter: 1, curr loss: 0.18204905092716217, avg loss: 0.18204905092716217\n",
      "trial: 14, epoch, 44, iter: 200, curr loss: 0.18231049180030823, avg loss: 0.18436878710985183\n",
      "trial: 14, epoch, 45, iter: 1, curr loss: 0.1832476556301117, avg loss: 0.1832476556301117\n",
      "trial: 14, epoch, 45, iter: 200, curr loss: 0.17922168970108032, avg loss: 0.1845672481507063\n",
      "trial: 14, epoch, 46, iter: 1, curr loss: 0.18059894442558289, avg loss: 0.18059894442558289\n",
      "trial: 14, epoch, 46, iter: 200, curr loss: 0.1873251497745514, avg loss: 0.18437228381633758\n",
      "trial: 14, epoch, 47, iter: 1, curr loss: 0.18329668045043945, avg loss: 0.18329668045043945\n",
      "trial: 14, epoch, 47, iter: 200, curr loss: 0.1896056830883026, avg loss: 0.18431773155927658\n",
      "trial: 14, epoch, 48, iter: 1, curr loss: 0.1847047358751297, avg loss: 0.1847047358751297\n",
      "trial: 14, epoch, 48, iter: 200, curr loss: 0.18529267609119415, avg loss: 0.18444037929177284\n",
      "trial: 14, epoch, 49, iter: 1, curr loss: 0.1816832423210144, avg loss: 0.1816832423210144\n",
      "trial: 14, epoch, 49, iter: 200, curr loss: 0.19241051375865936, avg loss: 0.18486384816467763\n",
      "trial: 14, epoch, 50, iter: 1, curr loss: 0.19548237323760986, avg loss: 0.19548237323760986\n",
      "trial: 14, epoch, 50, iter: 200, curr loss: 0.17955169081687927, avg loss: 0.18453195989131926\n",
      "trial: 14, ldr: 18.759336471557617, dv: 20.140338897705078, nwj: 19.508010864257812\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 15, epoch, 1, iter: 1, curr loss: 0.6958765983581543, avg loss: 0.6958765983581543\n",
      "trial: 15, epoch, 1, iter: 200, curr loss: 0.1916711926460266, avg loss: 0.22978253841400145\n",
      "trial: 15, epoch, 2, iter: 1, curr loss: 0.17522911727428436, avg loss: 0.17522911727428436\n",
      "trial: 15, epoch, 2, iter: 200, curr loss: 0.18775850534439087, avg loss: 0.18626876711845397\n",
      "trial: 15, epoch, 3, iter: 1, curr loss: 0.18690520524978638, avg loss: 0.18690520524978638\n",
      "trial: 15, epoch, 3, iter: 200, curr loss: 0.18780989944934845, avg loss: 0.18558555103838445\n",
      "trial: 15, epoch, 4, iter: 1, curr loss: 0.18883101642131805, avg loss: 0.18883101642131805\n",
      "trial: 15, epoch, 4, iter: 200, curr loss: 0.19316533207893372, avg loss: 0.18532433167099951\n",
      "trial: 15, epoch, 5, iter: 1, curr loss: 0.18801671266555786, avg loss: 0.18801671266555786\n",
      "trial: 15, epoch, 5, iter: 200, curr loss: 0.18193319439888, avg loss: 0.18480320602655412\n",
      "trial: 15, epoch, 6, iter: 1, curr loss: 0.190168559551239, avg loss: 0.190168559551239\n",
      "trial: 15, epoch, 6, iter: 200, curr loss: 0.18969404697418213, avg loss: 0.18472509317100047\n",
      "trial: 15, epoch, 7, iter: 1, curr loss: 0.1749643087387085, avg loss: 0.1749643087387085\n",
      "trial: 15, epoch, 7, iter: 200, curr loss: 0.1857813000679016, avg loss: 0.18502243019640446\n",
      "trial: 15, epoch, 8, iter: 1, curr loss: 0.18936045467853546, avg loss: 0.18936045467853546\n",
      "trial: 15, epoch, 8, iter: 200, curr loss: 0.1759137064218521, avg loss: 0.18443993635475636\n",
      "trial: 15, epoch, 9, iter: 1, curr loss: 0.185745507478714, avg loss: 0.185745507478714\n",
      "trial: 15, epoch, 9, iter: 200, curr loss: 0.18525102734565735, avg loss: 0.18454549945890902\n",
      "trial: 15, epoch, 10, iter: 1, curr loss: 0.18883618712425232, avg loss: 0.18883618712425232\n",
      "trial: 15, epoch, 10, iter: 200, curr loss: 0.1800345778465271, avg loss: 0.18465874299407006\n",
      "trial: 15, epoch, 11, iter: 1, curr loss: 0.18725499510765076, avg loss: 0.18725499510765076\n",
      "trial: 15, epoch, 11, iter: 200, curr loss: 0.18438181281089783, avg loss: 0.18480393312871457\n",
      "trial: 15, epoch, 12, iter: 1, curr loss: 0.17204192280769348, avg loss: 0.17204192280769348\n",
      "trial: 15, epoch, 12, iter: 200, curr loss: 0.18675392866134644, avg loss: 0.1847975492477417\n",
      "trial: 15, epoch, 13, iter: 1, curr loss: 0.18526135385036469, avg loss: 0.18526135385036469\n",
      "trial: 15, epoch, 13, iter: 200, curr loss: 0.17936356365680695, avg loss: 0.18456529572606087\n",
      "trial: 15, epoch, 14, iter: 1, curr loss: 0.1815122812986374, avg loss: 0.1815122812986374\n",
      "trial: 15, epoch, 14, iter: 200, curr loss: 0.18454955518245697, avg loss: 0.18429706774652005\n",
      "trial: 15, epoch, 15, iter: 1, curr loss: 0.185470849275589, avg loss: 0.185470849275589\n",
      "trial: 15, epoch, 15, iter: 200, curr loss: 0.18429380655288696, avg loss: 0.18482135593891144\n",
      "trial: 15, epoch, 16, iter: 1, curr loss: 0.17809873819351196, avg loss: 0.17809873819351196\n",
      "trial: 15, epoch, 16, iter: 200, curr loss: 0.187610924243927, avg loss: 0.1843893714249134\n",
      "trial: 15, epoch, 17, iter: 1, curr loss: 0.18854767084121704, avg loss: 0.18854767084121704\n",
      "trial: 15, epoch, 17, iter: 200, curr loss: 0.1893455982208252, avg loss: 0.1843274363130331\n",
      "trial: 15, epoch, 18, iter: 1, curr loss: 0.18739035725593567, avg loss: 0.18739035725593567\n",
      "trial: 15, epoch, 18, iter: 200, curr loss: 0.18677431344985962, avg loss: 0.18456652231514453\n",
      "trial: 15, epoch, 19, iter: 1, curr loss: 0.17908088862895966, avg loss: 0.17908088862895966\n",
      "trial: 15, epoch, 19, iter: 200, curr loss: 0.1902257800102234, avg loss: 0.18449650302529336\n",
      "trial: 15, epoch, 20, iter: 1, curr loss: 0.19773590564727783, avg loss: 0.19773590564727783\n",
      "trial: 15, epoch, 20, iter: 200, curr loss: 0.1828090250492096, avg loss: 0.18459949076175688\n",
      "trial: 15, epoch, 21, iter: 1, curr loss: 0.18605585396289825, avg loss: 0.18605585396289825\n",
      "trial: 15, epoch, 21, iter: 200, curr loss: 0.1889043152332306, avg loss: 0.18424000672996044\n",
      "trial: 15, epoch, 22, iter: 1, curr loss: 0.18178880214691162, avg loss: 0.18178880214691162\n",
      "trial: 15, epoch, 22, iter: 200, curr loss: 0.18535751104354858, avg loss: 0.1843546838313341\n",
      "trial: 15, epoch, 23, iter: 1, curr loss: 0.18694351613521576, avg loss: 0.18694351613521576\n",
      "trial: 15, epoch, 23, iter: 200, curr loss: 0.1857965886592865, avg loss: 0.18462616868317128\n",
      "trial: 15, epoch, 24, iter: 1, curr loss: 0.18248561024665833, avg loss: 0.18248561024665833\n",
      "trial: 15, epoch, 24, iter: 200, curr loss: 0.19166040420532227, avg loss: 0.1848622414469719\n",
      "trial: 15, epoch, 25, iter: 1, curr loss: 0.18346872925758362, avg loss: 0.18346872925758362\n",
      "trial: 15, epoch, 25, iter: 200, curr loss: 0.1827532947063446, avg loss: 0.18496975742280483\n",
      "trial: 15, epoch, 26, iter: 1, curr loss: 0.18233659863471985, avg loss: 0.18233659863471985\n",
      "trial: 15, epoch, 26, iter: 200, curr loss: 0.17832250893115997, avg loss: 0.1843450516462326\n",
      "trial: 15, epoch, 27, iter: 1, curr loss: 0.18351373076438904, avg loss: 0.18351373076438904\n",
      "trial: 15, epoch, 27, iter: 200, curr loss: 0.1862131953239441, avg loss: 0.18441877014935015\n",
      "trial: 15, epoch, 28, iter: 1, curr loss: 0.17834287881851196, avg loss: 0.17834287881851196\n",
      "trial: 15, epoch, 28, iter: 200, curr loss: 0.17587827146053314, avg loss: 0.18495907835662365\n",
      "trial: 15, epoch, 29, iter: 1, curr loss: 0.18337887525558472, avg loss: 0.18337887525558472\n",
      "trial: 15, epoch, 29, iter: 200, curr loss: 0.18557491898536682, avg loss: 0.18459710076451302\n",
      "trial: 15, epoch, 30, iter: 1, curr loss: 0.18958434462547302, avg loss: 0.18958434462547302\n",
      "trial: 15, epoch, 30, iter: 200, curr loss: 0.18423691391944885, avg loss: 0.18458931088447572\n",
      "trial: 15, epoch, 31, iter: 1, curr loss: 0.18417245149612427, avg loss: 0.18417245149612427\n",
      "trial: 15, epoch, 31, iter: 200, curr loss: 0.1865454763174057, avg loss: 0.1839927151799202\n",
      "trial: 15, epoch, 32, iter: 1, curr loss: 0.1914084255695343, avg loss: 0.1914084255695343\n",
      "trial: 15, epoch, 32, iter: 200, curr loss: 0.181766539812088, avg loss: 0.1849144381284714\n",
      "trial: 15, epoch, 33, iter: 1, curr loss: 0.18535840511322021, avg loss: 0.18535840511322021\n",
      "trial: 15, epoch, 33, iter: 200, curr loss: 0.18922626972198486, avg loss: 0.18434497959911822\n",
      "trial: 15, epoch, 34, iter: 1, curr loss: 0.18212369084358215, avg loss: 0.18212369084358215\n",
      "trial: 15, epoch, 34, iter: 200, curr loss: 0.18880271911621094, avg loss: 0.1847770781069994\n",
      "trial: 15, epoch, 35, iter: 1, curr loss: 0.18429136276245117, avg loss: 0.18429136276245117\n",
      "trial: 15, epoch, 35, iter: 200, curr loss: 0.18340033292770386, avg loss: 0.1838849089294672\n",
      "trial: 15, epoch, 36, iter: 1, curr loss: 0.18501724302768707, avg loss: 0.18501724302768707\n",
      "trial: 15, epoch, 36, iter: 200, curr loss: 0.19644451141357422, avg loss: 0.18468810826539994\n",
      "trial: 15, epoch, 37, iter: 1, curr loss: 0.18847757577896118, avg loss: 0.18847757577896118\n",
      "trial: 15, epoch, 37, iter: 200, curr loss: 0.18226981163024902, avg loss: 0.18511648535728453\n",
      "trial: 15, epoch, 38, iter: 1, curr loss: 0.18745769560337067, avg loss: 0.18745769560337067\n",
      "trial: 15, epoch, 38, iter: 200, curr loss: 0.1823001503944397, avg loss: 0.184362203925848\n",
      "trial: 15, epoch, 39, iter: 1, curr loss: 0.1923581212759018, avg loss: 0.1923581212759018\n",
      "trial: 15, epoch, 39, iter: 200, curr loss: 0.19134138524532318, avg loss: 0.1847642744332552\n",
      "trial: 15, epoch, 40, iter: 1, curr loss: 0.18411242961883545, avg loss: 0.18411242961883545\n",
      "trial: 15, epoch, 40, iter: 200, curr loss: 0.18297575414180756, avg loss: 0.18461026974022388\n",
      "trial: 15, epoch, 41, iter: 1, curr loss: 0.18590004742145538, avg loss: 0.18590004742145538\n",
      "trial: 15, epoch, 41, iter: 200, curr loss: 0.19135871529579163, avg loss: 0.1845343229919672\n",
      "trial: 15, epoch, 42, iter: 1, curr loss: 0.17643335461616516, avg loss: 0.17643335461616516\n",
      "trial: 15, epoch, 42, iter: 200, curr loss: 0.1915256530046463, avg loss: 0.18452220357954502\n",
      "trial: 15, epoch, 43, iter: 1, curr loss: 0.1883380264043808, avg loss: 0.1883380264043808\n",
      "trial: 15, epoch, 43, iter: 200, curr loss: 0.18516626954078674, avg loss: 0.1846109191328287\n",
      "trial: 15, epoch, 44, iter: 1, curr loss: 0.18737713992595673, avg loss: 0.18737713992595673\n",
      "trial: 15, epoch, 44, iter: 200, curr loss: 0.18973222374916077, avg loss: 0.1845587631314993\n",
      "trial: 15, epoch, 45, iter: 1, curr loss: 0.1768789291381836, avg loss: 0.1768789291381836\n",
      "trial: 15, epoch, 45, iter: 200, curr loss: 0.19056205451488495, avg loss: 0.1849204594641924\n",
      "trial: 15, epoch, 46, iter: 1, curr loss: 0.18799293041229248, avg loss: 0.18799293041229248\n",
      "trial: 15, epoch, 46, iter: 200, curr loss: 0.18333673477172852, avg loss: 0.18471247002482413\n",
      "trial: 15, epoch, 47, iter: 1, curr loss: 0.18664111196994781, avg loss: 0.18664111196994781\n",
      "trial: 15, epoch, 47, iter: 200, curr loss: 0.18226471543312073, avg loss: 0.18464771047234535\n",
      "trial: 15, epoch, 48, iter: 1, curr loss: 0.18837258219718933, avg loss: 0.18837258219718933\n",
      "trial: 15, epoch, 48, iter: 200, curr loss: 0.1809336245059967, avg loss: 0.18503344617784023\n",
      "trial: 15, epoch, 49, iter: 1, curr loss: 0.1921352744102478, avg loss: 0.1921352744102478\n",
      "trial: 15, epoch, 49, iter: 200, curr loss: 0.1829243302345276, avg loss: 0.18459041588008404\n",
      "trial: 15, epoch, 50, iter: 1, curr loss: 0.18560639023780823, avg loss: 0.18560639023780823\n",
      "trial: 15, epoch, 50, iter: 200, curr loss: 0.1824086606502533, avg loss: 0.18450238443911077\n",
      "trial: 15, ldr: 17.53693962097168, dv: 18.92958641052246, nwj: 18.288522720336914\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 16, epoch, 1, iter: 1, curr loss: 0.6944275498390198, avg loss: 0.6944275498390198\n",
      "trial: 16, epoch, 1, iter: 200, curr loss: 0.1921955943107605, avg loss: 0.2262364546954632\n",
      "trial: 16, epoch, 2, iter: 1, curr loss: 0.19473767280578613, avg loss: 0.19473767280578613\n",
      "trial: 16, epoch, 2, iter: 200, curr loss: 0.1885775327682495, avg loss: 0.1869932346791029\n",
      "trial: 16, epoch, 3, iter: 1, curr loss: 0.18645647168159485, avg loss: 0.18645647168159485\n",
      "trial: 16, epoch, 3, iter: 200, curr loss: 0.17907389998435974, avg loss: 0.18543571598827838\n",
      "trial: 16, epoch, 4, iter: 1, curr loss: 0.18557129800319672, avg loss: 0.18557129800319672\n",
      "trial: 16, epoch, 4, iter: 200, curr loss: 0.1856173872947693, avg loss: 0.18538468159735202\n",
      "trial: 16, epoch, 5, iter: 1, curr loss: 0.18787497282028198, avg loss: 0.18787497282028198\n",
      "trial: 16, epoch, 5, iter: 200, curr loss: 0.18612079322338104, avg loss: 0.18473641000688076\n",
      "trial: 16, epoch, 6, iter: 1, curr loss: 0.18324363231658936, avg loss: 0.18324363231658936\n",
      "trial: 16, epoch, 6, iter: 200, curr loss: 0.18212921917438507, avg loss: 0.18453555651009082\n",
      "trial: 16, epoch, 7, iter: 1, curr loss: 0.18175171315670013, avg loss: 0.18175171315670013\n",
      "trial: 16, epoch, 7, iter: 200, curr loss: 0.18299005925655365, avg loss: 0.18449677534401418\n",
      "trial: 16, epoch, 8, iter: 1, curr loss: 0.19482043385505676, avg loss: 0.19482043385505676\n",
      "trial: 16, epoch, 8, iter: 200, curr loss: 0.19207623600959778, avg loss: 0.18446613408625126\n",
      "trial: 16, epoch, 9, iter: 1, curr loss: 0.18562406301498413, avg loss: 0.18562406301498413\n",
      "trial: 16, epoch, 9, iter: 200, curr loss: 0.1898491531610489, avg loss: 0.1844596630334854\n",
      "trial: 16, epoch, 10, iter: 1, curr loss: 0.1830926388502121, avg loss: 0.1830926388502121\n",
      "trial: 16, epoch, 10, iter: 200, curr loss: 0.17891836166381836, avg loss: 0.18472537010908127\n",
      "trial: 16, epoch, 11, iter: 1, curr loss: 0.1865990161895752, avg loss: 0.1865990161895752\n",
      "trial: 16, epoch, 11, iter: 200, curr loss: 0.1863151490688324, avg loss: 0.18424322277307512\n",
      "trial: 16, epoch, 12, iter: 1, curr loss: 0.18168774247169495, avg loss: 0.18168774247169495\n",
      "trial: 16, epoch, 12, iter: 200, curr loss: 0.1888158768415451, avg loss: 0.18455686770379542\n",
      "trial: 16, epoch, 13, iter: 1, curr loss: 0.1882958710193634, avg loss: 0.1882958710193634\n",
      "trial: 16, epoch, 13, iter: 200, curr loss: 0.18134060502052307, avg loss: 0.18430352710187436\n",
      "trial: 16, epoch, 14, iter: 1, curr loss: 0.19733837246894836, avg loss: 0.19733837246894836\n",
      "trial: 16, epoch, 14, iter: 200, curr loss: 0.1826261281967163, avg loss: 0.1842459239810705\n",
      "trial: 16, epoch, 15, iter: 1, curr loss: 0.19100548326969147, avg loss: 0.19100548326969147\n",
      "trial: 16, epoch, 15, iter: 200, curr loss: 0.18423745036125183, avg loss: 0.1841656245291233\n",
      "trial: 16, epoch, 16, iter: 1, curr loss: 0.18098491430282593, avg loss: 0.18098491430282593\n",
      "trial: 16, epoch, 16, iter: 200, curr loss: 0.18015654385089874, avg loss: 0.18408263936638833\n",
      "trial: 16, epoch, 17, iter: 1, curr loss: 0.18508625030517578, avg loss: 0.18508625030517578\n",
      "trial: 16, epoch, 17, iter: 200, curr loss: 0.18185681104660034, avg loss: 0.18452539026737214\n",
      "trial: 16, epoch, 18, iter: 1, curr loss: 0.18117594718933105, avg loss: 0.18117594718933105\n",
      "trial: 16, epoch, 18, iter: 200, curr loss: 0.1814228594303131, avg loss: 0.18458951719105243\n",
      "trial: 16, epoch, 19, iter: 1, curr loss: 0.18882420659065247, avg loss: 0.18882420659065247\n",
      "trial: 16, epoch, 19, iter: 200, curr loss: 0.1837504506111145, avg loss: 0.1844611258804798\n",
      "trial: 16, epoch, 20, iter: 1, curr loss: 0.1743999868631363, avg loss: 0.1743999868631363\n",
      "trial: 16, epoch, 20, iter: 200, curr loss: 0.18819889426231384, avg loss: 0.18463686637580395\n",
      "trial: 16, epoch, 21, iter: 1, curr loss: 0.18478763103485107, avg loss: 0.18478763103485107\n",
      "trial: 16, epoch, 21, iter: 200, curr loss: 0.18871080875396729, avg loss: 0.18457907810807228\n",
      "trial: 16, epoch, 22, iter: 1, curr loss: 0.1828177571296692, avg loss: 0.1828177571296692\n",
      "trial: 16, epoch, 22, iter: 200, curr loss: 0.19044166803359985, avg loss: 0.18445382632315158\n",
      "trial: 16, epoch, 23, iter: 1, curr loss: 0.183204784989357, avg loss: 0.183204784989357\n",
      "trial: 16, epoch, 23, iter: 200, curr loss: 0.18339475989341736, avg loss: 0.18480788573622703\n",
      "trial: 16, epoch, 24, iter: 1, curr loss: 0.17901039123535156, avg loss: 0.17901039123535156\n",
      "trial: 16, epoch, 24, iter: 200, curr loss: 0.19071544706821442, avg loss: 0.18488192901015282\n",
      "trial: 16, epoch, 25, iter: 1, curr loss: 0.18226593732833862, avg loss: 0.18226593732833862\n",
      "trial: 16, epoch, 25, iter: 200, curr loss: 0.17533275485038757, avg loss: 0.18450768537819384\n",
      "trial: 16, epoch, 26, iter: 1, curr loss: 0.19192388653755188, avg loss: 0.19192388653755188\n",
      "trial: 16, epoch, 26, iter: 200, curr loss: 0.19117134809494019, avg loss: 0.18448820412158967\n",
      "trial: 16, epoch, 27, iter: 1, curr loss: 0.1897108554840088, avg loss: 0.1897108554840088\n",
      "trial: 16, epoch, 27, iter: 200, curr loss: 0.18710017204284668, avg loss: 0.18478123016655446\n",
      "trial: 16, epoch, 28, iter: 1, curr loss: 0.1901787370443344, avg loss: 0.1901787370443344\n",
      "trial: 16, epoch, 28, iter: 200, curr loss: 0.1851368546485901, avg loss: 0.18466995149850846\n",
      "trial: 16, epoch, 29, iter: 1, curr loss: 0.18543872237205505, avg loss: 0.18543872237205505\n",
      "trial: 16, epoch, 29, iter: 200, curr loss: 0.18101048469543457, avg loss: 0.18484125919640065\n",
      "trial: 16, epoch, 30, iter: 1, curr loss: 0.19027072191238403, avg loss: 0.19027072191238403\n",
      "trial: 16, epoch, 30, iter: 200, curr loss: 0.18307450413703918, avg loss: 0.1846265234053135\n",
      "trial: 16, epoch, 31, iter: 1, curr loss: 0.17842930555343628, avg loss: 0.17842930555343628\n",
      "trial: 16, epoch, 31, iter: 200, curr loss: 0.19433823227882385, avg loss: 0.18411136098206043\n",
      "trial: 16, epoch, 32, iter: 1, curr loss: 0.18678069114685059, avg loss: 0.18678069114685059\n",
      "trial: 16, epoch, 32, iter: 200, curr loss: 0.18695597350597382, avg loss: 0.18447953179478646\n",
      "trial: 16, epoch, 33, iter: 1, curr loss: 0.1840081661939621, avg loss: 0.1840081661939621\n",
      "trial: 16, epoch, 33, iter: 200, curr loss: 0.18733486533164978, avg loss: 0.1849692501872778\n",
      "trial: 16, epoch, 34, iter: 1, curr loss: 0.19295145571231842, avg loss: 0.19295145571231842\n",
      "trial: 16, epoch, 34, iter: 200, curr loss: 0.18035808205604553, avg loss: 0.1847405341267586\n",
      "trial: 16, epoch, 35, iter: 1, curr loss: 0.1858297884464264, avg loss: 0.1858297884464264\n",
      "trial: 16, epoch, 35, iter: 200, curr loss: 0.1773557811975479, avg loss: 0.1844320258498192\n",
      "trial: 16, epoch, 36, iter: 1, curr loss: 0.1853904277086258, avg loss: 0.1853904277086258\n",
      "trial: 16, epoch, 36, iter: 200, curr loss: 0.18696162104606628, avg loss: 0.1845610300451517\n",
      "trial: 16, epoch, 37, iter: 1, curr loss: 0.19571907818317413, avg loss: 0.19571907818317413\n",
      "trial: 16, epoch, 37, iter: 200, curr loss: 0.18428224325180054, avg loss: 0.18465706162154674\n",
      "trial: 16, epoch, 38, iter: 1, curr loss: 0.1809818148612976, avg loss: 0.1809818148612976\n",
      "trial: 16, epoch, 38, iter: 200, curr loss: 0.18224520981311798, avg loss: 0.18467251591384412\n",
      "trial: 16, epoch, 39, iter: 1, curr loss: 0.18046064674854279, avg loss: 0.18046064674854279\n",
      "trial: 16, epoch, 39, iter: 200, curr loss: 0.19252508878707886, avg loss: 0.18393882118165494\n",
      "trial: 16, epoch, 40, iter: 1, curr loss: 0.17978185415267944, avg loss: 0.17978185415267944\n",
      "trial: 16, epoch, 40, iter: 200, curr loss: 0.18703822791576385, avg loss: 0.18408764213323592\n",
      "trial: 16, epoch, 41, iter: 1, curr loss: 0.1909131109714508, avg loss: 0.1909131109714508\n",
      "trial: 16, epoch, 41, iter: 200, curr loss: 0.18938356637954712, avg loss: 0.18477128699421883\n",
      "trial: 16, epoch, 42, iter: 1, curr loss: 0.1899719536304474, avg loss: 0.1899719536304474\n",
      "trial: 16, epoch, 42, iter: 200, curr loss: 0.1822003871202469, avg loss: 0.18463770151138306\n",
      "trial: 16, epoch, 43, iter: 1, curr loss: 0.18686622381210327, avg loss: 0.18686622381210327\n",
      "trial: 16, epoch, 43, iter: 200, curr loss: 0.18480607867240906, avg loss: 0.18476264707744122\n",
      "trial: 16, epoch, 44, iter: 1, curr loss: 0.1855204552412033, avg loss: 0.1855204552412033\n",
      "trial: 16, epoch, 44, iter: 200, curr loss: 0.18233348429203033, avg loss: 0.18487073950469493\n",
      "trial: 16, epoch, 45, iter: 1, curr loss: 0.1835058629512787, avg loss: 0.1835058629512787\n",
      "trial: 16, epoch, 45, iter: 200, curr loss: 0.19644320011138916, avg loss: 0.18448028467595579\n",
      "trial: 16, epoch, 46, iter: 1, curr loss: 0.18576985597610474, avg loss: 0.18576985597610474\n",
      "trial: 16, epoch, 46, iter: 200, curr loss: 0.1881963163614273, avg loss: 0.18431775949895382\n",
      "trial: 16, epoch, 47, iter: 1, curr loss: 0.18821769952774048, avg loss: 0.18821769952774048\n",
      "trial: 16, epoch, 47, iter: 200, curr loss: 0.18985848128795624, avg loss: 0.18432073399424553\n",
      "trial: 16, epoch, 48, iter: 1, curr loss: 0.18228623270988464, avg loss: 0.18228623270988464\n",
      "trial: 16, epoch, 48, iter: 200, curr loss: 0.1824338138103485, avg loss: 0.1842321678996086\n",
      "trial: 16, epoch, 49, iter: 1, curr loss: 0.1829225718975067, avg loss: 0.1829225718975067\n",
      "trial: 16, epoch, 49, iter: 200, curr loss: 0.1915147304534912, avg loss: 0.18460206121206282\n",
      "trial: 16, epoch, 50, iter: 1, curr loss: 0.18440406024456024, avg loss: 0.18440406024456024\n",
      "trial: 16, epoch, 50, iter: 200, curr loss: 0.19045034050941467, avg loss: 0.18452157489955426\n",
      "trial: 16, ldr: 21.189367294311523, dv: 22.57005500793457, nwj: 21.93796157836914\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 17, epoch, 1, iter: 1, curr loss: 0.6949762105941772, avg loss: 0.6949762105941772\n",
      "trial: 17, epoch, 1, iter: 200, curr loss: 0.18820756673812866, avg loss: 0.22702055916190148\n",
      "trial: 17, epoch, 2, iter: 1, curr loss: 0.2066495716571808, avg loss: 0.2066495716571808\n",
      "trial: 17, epoch, 2, iter: 200, curr loss: 0.17941954731941223, avg loss: 0.18601566210389137\n",
      "trial: 17, epoch, 3, iter: 1, curr loss: 0.18388503789901733, avg loss: 0.18388503789901733\n",
      "trial: 17, epoch, 3, iter: 200, curr loss: 0.1835317611694336, avg loss: 0.18527320794761182\n",
      "trial: 17, epoch, 4, iter: 1, curr loss: 0.1732625961303711, avg loss: 0.1732625961303711\n",
      "trial: 17, epoch, 4, iter: 200, curr loss: 0.18172961473464966, avg loss: 0.1851235467940569\n",
      "trial: 17, epoch, 5, iter: 1, curr loss: 0.18970081210136414, avg loss: 0.18970081210136414\n",
      "trial: 17, epoch, 5, iter: 200, curr loss: 0.18289029598236084, avg loss: 0.18512698106467723\n",
      "trial: 17, epoch, 6, iter: 1, curr loss: 0.18152391910552979, avg loss: 0.18152391910552979\n",
      "trial: 17, epoch, 6, iter: 200, curr loss: 0.1924709677696228, avg loss: 0.18496156483888626\n",
      "trial: 17, epoch, 7, iter: 1, curr loss: 0.19237616658210754, avg loss: 0.19237616658210754\n",
      "trial: 17, epoch, 7, iter: 200, curr loss: 0.17559677362442017, avg loss: 0.1845255171507597\n",
      "trial: 17, epoch, 8, iter: 1, curr loss: 0.18751218914985657, avg loss: 0.18751218914985657\n",
      "trial: 17, epoch, 8, iter: 200, curr loss: 0.18006420135498047, avg loss: 0.18497639894485474\n",
      "trial: 17, epoch, 9, iter: 1, curr loss: 0.1868005245923996, avg loss: 0.1868005245923996\n",
      "trial: 17, epoch, 9, iter: 200, curr loss: 0.18224173784255981, avg loss: 0.18437766626477242\n",
      "trial: 17, epoch, 10, iter: 1, curr loss: 0.19297677278518677, avg loss: 0.19297677278518677\n",
      "trial: 17, epoch, 10, iter: 200, curr loss: 0.17655903100967407, avg loss: 0.18481169477105142\n",
      "trial: 17, epoch, 11, iter: 1, curr loss: 0.18572980165481567, avg loss: 0.18572980165481567\n",
      "trial: 17, epoch, 11, iter: 200, curr loss: 0.18936151266098022, avg loss: 0.18438268393278123\n",
      "trial: 17, epoch, 12, iter: 1, curr loss: 0.18504980206489563, avg loss: 0.18504980206489563\n",
      "trial: 17, epoch, 12, iter: 200, curr loss: 0.17850099503993988, avg loss: 0.18471238598227502\n",
      "trial: 17, epoch, 13, iter: 1, curr loss: 0.18884527683258057, avg loss: 0.18884527683258057\n",
      "trial: 17, epoch, 13, iter: 200, curr loss: 0.18851733207702637, avg loss: 0.1848868837952614\n",
      "trial: 17, epoch, 14, iter: 1, curr loss: 0.18490853905677795, avg loss: 0.18490853905677795\n",
      "trial: 17, epoch, 14, iter: 200, curr loss: 0.1890944391489029, avg loss: 0.18441469751298428\n",
      "trial: 17, epoch, 15, iter: 1, curr loss: 0.1835700422525406, avg loss: 0.1835700422525406\n",
      "trial: 17, epoch, 15, iter: 200, curr loss: 0.186722069978714, avg loss: 0.18447083689272403\n",
      "trial: 17, epoch, 16, iter: 1, curr loss: 0.18984779715538025, avg loss: 0.18984779715538025\n",
      "trial: 17, epoch, 16, iter: 200, curr loss: 0.18230359256267548, avg loss: 0.18424183882772924\n",
      "trial: 17, epoch, 17, iter: 1, curr loss: 0.17995020747184753, avg loss: 0.17995020747184753\n",
      "trial: 17, epoch, 17, iter: 200, curr loss: 0.18480387330055237, avg loss: 0.18457811377942562\n",
      "trial: 17, epoch, 18, iter: 1, curr loss: 0.18979930877685547, avg loss: 0.18979930877685547\n",
      "trial: 17, epoch, 18, iter: 200, curr loss: 0.1855449676513672, avg loss: 0.1843220204114914\n",
      "trial: 17, epoch, 19, iter: 1, curr loss: 0.19171252846717834, avg loss: 0.19171252846717834\n",
      "trial: 17, epoch, 19, iter: 200, curr loss: 0.18645113706588745, avg loss: 0.18470330238342286\n",
      "trial: 17, epoch, 20, iter: 1, curr loss: 0.18974606692790985, avg loss: 0.18974606692790985\n",
      "trial: 17, epoch, 20, iter: 200, curr loss: 0.18245261907577515, avg loss: 0.18471322886645794\n",
      "trial: 17, epoch, 21, iter: 1, curr loss: 0.18216465413570404, avg loss: 0.18216465413570404\n",
      "trial: 17, epoch, 21, iter: 200, curr loss: 0.19323235750198364, avg loss: 0.18456676125526428\n",
      "trial: 17, epoch, 22, iter: 1, curr loss: 0.1857595592737198, avg loss: 0.1857595592737198\n",
      "trial: 17, epoch, 22, iter: 200, curr loss: 0.18484753370285034, avg loss: 0.18438155017793179\n",
      "trial: 17, epoch, 23, iter: 1, curr loss: 0.1818164438009262, avg loss: 0.1818164438009262\n",
      "trial: 17, epoch, 23, iter: 200, curr loss: 0.17864835262298584, avg loss: 0.1843879008293152\n",
      "trial: 17, epoch, 24, iter: 1, curr loss: 0.17859899997711182, avg loss: 0.17859899997711182\n",
      "trial: 17, epoch, 24, iter: 200, curr loss: 0.18723595142364502, avg loss: 0.1847946086525917\n",
      "trial: 17, epoch, 25, iter: 1, curr loss: 0.1815538853406906, avg loss: 0.1815538853406906\n",
      "trial: 17, epoch, 25, iter: 200, curr loss: 0.18465492129325867, avg loss: 0.1843271189928055\n",
      "trial: 17, epoch, 26, iter: 1, curr loss: 0.1964397430419922, avg loss: 0.1964397430419922\n",
      "trial: 17, epoch, 26, iter: 200, curr loss: 0.1758100539445877, avg loss: 0.18448892526328564\n",
      "trial: 17, epoch, 27, iter: 1, curr loss: 0.1910506784915924, avg loss: 0.1910506784915924\n",
      "trial: 17, epoch, 27, iter: 200, curr loss: 0.18633845448493958, avg loss: 0.18429430887103082\n",
      "trial: 17, epoch, 28, iter: 1, curr loss: 0.18654370307922363, avg loss: 0.18654370307922363\n",
      "trial: 17, epoch, 28, iter: 200, curr loss: 0.19403007626533508, avg loss: 0.18432038851082325\n",
      "trial: 17, epoch, 29, iter: 1, curr loss: 0.19050177931785583, avg loss: 0.19050177931785583\n",
      "trial: 17, epoch, 29, iter: 200, curr loss: 0.1799657940864563, avg loss: 0.18400364011526107\n",
      "trial: 17, epoch, 30, iter: 1, curr loss: 0.1801317036151886, avg loss: 0.1801317036151886\n",
      "trial: 17, epoch, 30, iter: 200, curr loss: 0.18005532026290894, avg loss: 0.1838258522748947\n",
      "trial: 17, epoch, 31, iter: 1, curr loss: 0.18275508284568787, avg loss: 0.18275508284568787\n",
      "trial: 17, epoch, 31, iter: 200, curr loss: 0.1884952187538147, avg loss: 0.184488230869174\n",
      "trial: 17, epoch, 32, iter: 1, curr loss: 0.18937814235687256, avg loss: 0.18937814235687256\n",
      "trial: 17, epoch, 32, iter: 200, curr loss: 0.18179750442504883, avg loss: 0.18412966698408126\n",
      "trial: 17, epoch, 33, iter: 1, curr loss: 0.1840667724609375, avg loss: 0.1840667724609375\n",
      "trial: 17, epoch, 33, iter: 200, curr loss: 0.18271854519844055, avg loss: 0.1846666034311056\n",
      "trial: 17, epoch, 34, iter: 1, curr loss: 0.18271943926811218, avg loss: 0.18271943926811218\n",
      "trial: 17, epoch, 34, iter: 200, curr loss: 0.17943879961967468, avg loss: 0.18452247105538844\n",
      "trial: 17, epoch, 35, iter: 1, curr loss: 0.19724878668785095, avg loss: 0.19724878668785095\n",
      "trial: 17, epoch, 35, iter: 200, curr loss: 0.1915966272354126, avg loss: 0.18392154894769192\n",
      "trial: 17, epoch, 36, iter: 1, curr loss: 0.19123968482017517, avg loss: 0.19123968482017517\n",
      "trial: 17, epoch, 36, iter: 200, curr loss: 0.18952533602714539, avg loss: 0.18462235793471338\n",
      "trial: 17, epoch, 37, iter: 1, curr loss: 0.18528512120246887, avg loss: 0.18528512120246887\n",
      "trial: 17, epoch, 37, iter: 200, curr loss: 0.18914514780044556, avg loss: 0.18478272259235382\n",
      "trial: 17, epoch, 38, iter: 1, curr loss: 0.19154421985149384, avg loss: 0.19154421985149384\n",
      "trial: 17, epoch, 38, iter: 200, curr loss: 0.19264933466911316, avg loss: 0.1846242956072092\n",
      "trial: 17, epoch, 39, iter: 1, curr loss: 0.18763424456119537, avg loss: 0.18763424456119537\n",
      "trial: 17, epoch, 39, iter: 200, curr loss: 0.18555429577827454, avg loss: 0.18402105771005153\n",
      "trial: 17, epoch, 40, iter: 1, curr loss: 0.18524688482284546, avg loss: 0.18524688482284546\n",
      "trial: 17, epoch, 40, iter: 200, curr loss: 0.1861138641834259, avg loss: 0.1846396191418171\n",
      "trial: 17, epoch, 41, iter: 1, curr loss: 0.1904309093952179, avg loss: 0.1904309093952179\n",
      "trial: 17, epoch, 41, iter: 200, curr loss: 0.19172604382038116, avg loss: 0.18440793447196482\n",
      "trial: 17, epoch, 42, iter: 1, curr loss: 0.19412881135940552, avg loss: 0.19412881135940552\n",
      "trial: 17, epoch, 42, iter: 200, curr loss: 0.1847091019153595, avg loss: 0.184735552072525\n",
      "trial: 17, epoch, 43, iter: 1, curr loss: 0.18435078859329224, avg loss: 0.18435078859329224\n",
      "trial: 17, epoch, 43, iter: 200, curr loss: 0.19519636034965515, avg loss: 0.18450448475778103\n",
      "trial: 17, epoch, 44, iter: 1, curr loss: 0.1759880632162094, avg loss: 0.1759880632162094\n",
      "trial: 17, epoch, 44, iter: 200, curr loss: 0.19068647921085358, avg loss: 0.1843656077235937\n",
      "trial: 17, epoch, 45, iter: 1, curr loss: 0.18625029921531677, avg loss: 0.18625029921531677\n",
      "trial: 17, epoch, 45, iter: 200, curr loss: 0.18642836809158325, avg loss: 0.1846693318337202\n",
      "trial: 17, epoch, 46, iter: 1, curr loss: 0.18258509039878845, avg loss: 0.18258509039878845\n",
      "trial: 17, epoch, 46, iter: 200, curr loss: 0.1808709055185318, avg loss: 0.18462871186435223\n",
      "trial: 17, epoch, 47, iter: 1, curr loss: 0.17839586734771729, avg loss: 0.17839586734771729\n",
      "trial: 17, epoch, 47, iter: 200, curr loss: 0.18988224864006042, avg loss: 0.18479903168976308\n",
      "trial: 17, epoch, 48, iter: 1, curr loss: 0.19036054611206055, avg loss: 0.19036054611206055\n",
      "trial: 17, epoch, 48, iter: 200, curr loss: 0.18741264939308167, avg loss: 0.18475572057068348\n",
      "trial: 17, epoch, 49, iter: 1, curr loss: 0.18868017196655273, avg loss: 0.18868017196655273\n",
      "trial: 17, epoch, 49, iter: 200, curr loss: 0.18280522525310516, avg loss: 0.18384188808500768\n",
      "trial: 17, epoch, 50, iter: 1, curr loss: 0.1896231770515442, avg loss: 0.1896231770515442\n",
      "trial: 17, epoch, 50, iter: 200, curr loss: 0.187942236661911, avg loss: 0.1838635714352131\n",
      "trial: 17, ldr: 19.83841323852539, dv: 21.21076774597168, nwj: 20.584903717041016\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 18, epoch, 1, iter: 1, curr loss: 0.6919839382171631, avg loss: 0.6919839382171631\n",
      "trial: 18, epoch, 1, iter: 200, curr loss: 0.19137920439243317, avg loss: 0.22580352045595645\n",
      "trial: 18, epoch, 2, iter: 1, curr loss: 0.18945100903511047, avg loss: 0.18945100903511047\n",
      "trial: 18, epoch, 2, iter: 200, curr loss: 0.19366449117660522, avg loss: 0.18679821603000163\n",
      "trial: 18, epoch, 3, iter: 1, curr loss: 0.18879900872707367, avg loss: 0.18879900872707367\n",
      "trial: 18, epoch, 3, iter: 200, curr loss: 0.18076205253601074, avg loss: 0.18501024194061755\n",
      "trial: 18, epoch, 4, iter: 1, curr loss: 0.17832879722118378, avg loss: 0.17832879722118378\n",
      "trial: 18, epoch, 4, iter: 200, curr loss: 0.18288543820381165, avg loss: 0.18539126239717008\n",
      "trial: 18, epoch, 5, iter: 1, curr loss: 0.18154072761535645, avg loss: 0.18154072761535645\n",
      "trial: 18, epoch, 5, iter: 200, curr loss: 0.1911710947751999, avg loss: 0.1851051504909992\n",
      "trial: 18, epoch, 6, iter: 1, curr loss: 0.1885848343372345, avg loss: 0.1885848343372345\n",
      "trial: 18, epoch, 6, iter: 200, curr loss: 0.18937057256698608, avg loss: 0.1848221553862095\n",
      "trial: 18, epoch, 7, iter: 1, curr loss: 0.18534860014915466, avg loss: 0.18534860014915466\n",
      "trial: 18, epoch, 7, iter: 200, curr loss: 0.18354597687721252, avg loss: 0.18455519668757916\n",
      "trial: 18, epoch, 8, iter: 1, curr loss: 0.18474486470222473, avg loss: 0.18474486470222473\n",
      "trial: 18, epoch, 8, iter: 200, curr loss: 0.1891973614692688, avg loss: 0.18443268544971944\n",
      "trial: 18, epoch, 9, iter: 1, curr loss: 0.18709902465343475, avg loss: 0.18709902465343475\n",
      "trial: 18, epoch, 9, iter: 200, curr loss: 0.19228142499923706, avg loss: 0.18415720328688623\n",
      "trial: 18, epoch, 10, iter: 1, curr loss: 0.1805245578289032, avg loss: 0.1805245578289032\n",
      "trial: 18, epoch, 10, iter: 200, curr loss: 0.1855587363243103, avg loss: 0.18459959708154203\n",
      "trial: 18, epoch, 11, iter: 1, curr loss: 0.18451634049415588, avg loss: 0.18451634049415588\n",
      "trial: 18, epoch, 11, iter: 200, curr loss: 0.1888340711593628, avg loss: 0.18472455836832524\n",
      "trial: 18, epoch, 12, iter: 1, curr loss: 0.189395010471344, avg loss: 0.189395010471344\n",
      "trial: 18, epoch, 12, iter: 200, curr loss: 0.18238024413585663, avg loss: 0.18472962990403174\n",
      "trial: 18, epoch, 13, iter: 1, curr loss: 0.1865992248058319, avg loss: 0.1865992248058319\n",
      "trial: 18, epoch, 13, iter: 200, curr loss: 0.18919622898101807, avg loss: 0.18420123904943467\n",
      "trial: 18, epoch, 14, iter: 1, curr loss: 0.18912002444267273, avg loss: 0.18912002444267273\n",
      "trial: 18, epoch, 14, iter: 200, curr loss: 0.18366053700447083, avg loss: 0.1846530155092478\n",
      "trial: 18, epoch, 15, iter: 1, curr loss: 0.18853063881397247, avg loss: 0.18853063881397247\n",
      "trial: 18, epoch, 15, iter: 200, curr loss: 0.1947678178548813, avg loss: 0.18446871407330037\n",
      "trial: 18, epoch, 16, iter: 1, curr loss: 0.18774765729904175, avg loss: 0.18774765729904175\n",
      "trial: 18, epoch, 16, iter: 200, curr loss: 0.19185970723628998, avg loss: 0.1842577926069498\n",
      "trial: 18, epoch, 17, iter: 1, curr loss: 0.19309885799884796, avg loss: 0.19309885799884796\n",
      "trial: 18, epoch, 17, iter: 200, curr loss: 0.18980705738067627, avg loss: 0.18458133213222028\n",
      "trial: 18, epoch, 18, iter: 1, curr loss: 0.17819438874721527, avg loss: 0.17819438874721527\n",
      "trial: 18, epoch, 18, iter: 200, curr loss: 0.1896553933620453, avg loss: 0.18485644064843654\n",
      "trial: 18, epoch, 19, iter: 1, curr loss: 0.1944744884967804, avg loss: 0.1944744884967804\n",
      "trial: 18, epoch, 19, iter: 200, curr loss: 0.18379159271717072, avg loss: 0.1845473513007164\n",
      "trial: 18, epoch, 20, iter: 1, curr loss: 0.18797266483306885, avg loss: 0.18797266483306885\n",
      "trial: 18, epoch, 20, iter: 200, curr loss: 0.1776582896709442, avg loss: 0.1845145046710968\n",
      "trial: 18, epoch, 21, iter: 1, curr loss: 0.1934303343296051, avg loss: 0.1934303343296051\n",
      "trial: 18, epoch, 21, iter: 200, curr loss: 0.19089961051940918, avg loss: 0.1848026890307665\n",
      "trial: 18, epoch, 22, iter: 1, curr loss: 0.18858179450035095, avg loss: 0.18858179450035095\n",
      "trial: 18, epoch, 22, iter: 200, curr loss: 0.18609023094177246, avg loss: 0.18473753310739993\n",
      "trial: 18, epoch, 23, iter: 1, curr loss: 0.18383538722991943, avg loss: 0.18383538722991943\n",
      "trial: 18, epoch, 23, iter: 200, curr loss: 0.1685713231563568, avg loss: 0.18472858428955077\n",
      "trial: 18, epoch, 24, iter: 1, curr loss: 0.18775451183319092, avg loss: 0.18775451183319092\n",
      "trial: 18, epoch, 24, iter: 200, curr loss: 0.18550267815589905, avg loss: 0.18436222784221173\n",
      "trial: 18, epoch, 25, iter: 1, curr loss: 0.1890491247177124, avg loss: 0.1890491247177124\n",
      "trial: 18, epoch, 25, iter: 200, curr loss: 0.18007779121398926, avg loss: 0.18435328878462315\n",
      "trial: 18, epoch, 26, iter: 1, curr loss: 0.18352295458316803, avg loss: 0.18352295458316803\n",
      "trial: 18, epoch, 26, iter: 200, curr loss: 0.18365886807441711, avg loss: 0.18459901869297027\n",
      "trial: 18, epoch, 27, iter: 1, curr loss: 0.19790317118167877, avg loss: 0.19790317118167877\n",
      "trial: 18, epoch, 27, iter: 200, curr loss: 0.17836065590381622, avg loss: 0.18459366783499717\n",
      "trial: 18, epoch, 28, iter: 1, curr loss: 0.18812410533428192, avg loss: 0.18812410533428192\n",
      "trial: 18, epoch, 28, iter: 200, curr loss: 0.1864205002784729, avg loss: 0.18455044277012347\n",
      "trial: 18, epoch, 29, iter: 1, curr loss: 0.18707463145256042, avg loss: 0.18707463145256042\n",
      "trial: 18, epoch, 29, iter: 200, curr loss: 0.1896437406539917, avg loss: 0.1842089554667473\n",
      "trial: 18, epoch, 30, iter: 1, curr loss: 0.18231478333473206, avg loss: 0.18231478333473206\n",
      "trial: 18, epoch, 30, iter: 200, curr loss: 0.18917065858840942, avg loss: 0.18476201213896273\n",
      "trial: 18, epoch, 31, iter: 1, curr loss: 0.1867416948080063, avg loss: 0.1867416948080063\n",
      "trial: 18, epoch, 31, iter: 200, curr loss: 0.183466836810112, avg loss: 0.1847504150122404\n",
      "trial: 18, epoch, 32, iter: 1, curr loss: 0.1915629655122757, avg loss: 0.1915629655122757\n",
      "trial: 18, epoch, 32, iter: 200, curr loss: 0.1783425360918045, avg loss: 0.18428647086024286\n",
      "trial: 18, epoch, 33, iter: 1, curr loss: 0.19002105295658112, avg loss: 0.19002105295658112\n",
      "trial: 18, epoch, 33, iter: 200, curr loss: 0.1827324777841568, avg loss: 0.18415178440511226\n",
      "trial: 18, epoch, 34, iter: 1, curr loss: 0.18498684465885162, avg loss: 0.18498684465885162\n",
      "trial: 18, epoch, 34, iter: 200, curr loss: 0.1844761222600937, avg loss: 0.1848108594864607\n",
      "trial: 18, epoch, 35, iter: 1, curr loss: 0.18749789893627167, avg loss: 0.18749789893627167\n",
      "trial: 18, epoch, 35, iter: 200, curr loss: 0.19886010885238647, avg loss: 0.18457564331591128\n",
      "trial: 18, epoch, 36, iter: 1, curr loss: 0.18581242859363556, avg loss: 0.18581242859363556\n",
      "trial: 18, epoch, 36, iter: 200, curr loss: 0.18613235652446747, avg loss: 0.1847214625775814\n",
      "trial: 18, epoch, 37, iter: 1, curr loss: 0.17428064346313477, avg loss: 0.17428064346313477\n",
      "trial: 18, epoch, 37, iter: 200, curr loss: 0.18464338779449463, avg loss: 0.18484257221221922\n",
      "trial: 18, epoch, 38, iter: 1, curr loss: 0.19582726061344147, avg loss: 0.19582726061344147\n",
      "trial: 18, epoch, 38, iter: 200, curr loss: 0.18591856956481934, avg loss: 0.1847859701514244\n",
      "trial: 18, epoch, 39, iter: 1, curr loss: 0.18845336139202118, avg loss: 0.18845336139202118\n",
      "trial: 18, epoch, 39, iter: 200, curr loss: 0.1805737167596817, avg loss: 0.1843299700319767\n",
      "trial: 18, epoch, 40, iter: 1, curr loss: 0.18647906184196472, avg loss: 0.18647906184196472\n",
      "trial: 18, epoch, 40, iter: 200, curr loss: 0.1960151344537735, avg loss: 0.1849661248922348\n",
      "trial: 18, epoch, 41, iter: 1, curr loss: 0.1823805719614029, avg loss: 0.1823805719614029\n",
      "trial: 18, epoch, 41, iter: 200, curr loss: 0.19173091650009155, avg loss: 0.18461222268640995\n",
      "trial: 18, epoch, 42, iter: 1, curr loss: 0.18152979016304016, avg loss: 0.18152979016304016\n",
      "trial: 18, epoch, 42, iter: 200, curr loss: 0.19212830066680908, avg loss: 0.18514316894114016\n",
      "trial: 18, epoch, 43, iter: 1, curr loss: 0.19110645353794098, avg loss: 0.19110645353794098\n",
      "trial: 18, epoch, 43, iter: 200, curr loss: 0.18860633671283722, avg loss: 0.18478432193398475\n",
      "trial: 18, epoch, 44, iter: 1, curr loss: 0.1834138184785843, avg loss: 0.1834138184785843\n",
      "trial: 18, epoch, 44, iter: 200, curr loss: 0.17990811169147491, avg loss: 0.18444461725652217\n",
      "trial: 18, epoch, 45, iter: 1, curr loss: 0.17759910225868225, avg loss: 0.17759910225868225\n",
      "trial: 18, epoch, 45, iter: 200, curr loss: 0.1898868829011917, avg loss: 0.1847604913264513\n",
      "trial: 18, epoch, 46, iter: 1, curr loss: 0.18933093547821045, avg loss: 0.18933093547821045\n",
      "trial: 18, epoch, 46, iter: 200, curr loss: 0.18928910791873932, avg loss: 0.18494256615638732\n",
      "trial: 18, epoch, 47, iter: 1, curr loss: 0.18444553017616272, avg loss: 0.18444553017616272\n",
      "trial: 18, epoch, 47, iter: 200, curr loss: 0.18478991091251373, avg loss: 0.18449077844619752\n",
      "trial: 18, epoch, 48, iter: 1, curr loss: 0.18908752501010895, avg loss: 0.18908752501010895\n",
      "trial: 18, epoch, 48, iter: 200, curr loss: 0.1830451339483261, avg loss: 0.18447054035961627\n",
      "trial: 18, epoch, 49, iter: 1, curr loss: 0.1877904236316681, avg loss: 0.1877904236316681\n",
      "trial: 18, epoch, 49, iter: 200, curr loss: 0.19130204617977142, avg loss: 0.184508446007967\n",
      "trial: 18, epoch, 50, iter: 1, curr loss: 0.180789977312088, avg loss: 0.180789977312088\n",
      "trial: 18, epoch, 50, iter: 200, curr loss: 0.19438999891281128, avg loss: 0.1844640489667654\n",
      "trial: 18, ldr: 18.138975143432617, dv: 19.537273406982422, nwj: 18.891958236694336\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 19, epoch, 1, iter: 1, curr loss: 0.6927983164787292, avg loss: 0.6927983164787292\n",
      "trial: 19, epoch, 1, iter: 200, curr loss: 0.17985105514526367, avg loss: 0.2280726344883442\n",
      "trial: 19, epoch, 2, iter: 1, curr loss: 0.1846122145652771, avg loss: 0.1846122145652771\n",
      "trial: 19, epoch, 2, iter: 200, curr loss: 0.19720005989074707, avg loss: 0.18702388525009156\n",
      "trial: 19, epoch, 3, iter: 1, curr loss: 0.1801222711801529, avg loss: 0.1801222711801529\n",
      "trial: 19, epoch, 3, iter: 200, curr loss: 0.19038841128349304, avg loss: 0.1859189161658287\n",
      "trial: 19, epoch, 4, iter: 1, curr loss: 0.18193469941616058, avg loss: 0.18193469941616058\n",
      "trial: 19, epoch, 4, iter: 200, curr loss: 0.19819089770317078, avg loss: 0.18519691355526446\n",
      "trial: 19, epoch, 5, iter: 1, curr loss: 0.1807613968849182, avg loss: 0.1807613968849182\n",
      "trial: 19, epoch, 5, iter: 200, curr loss: 0.18178458511829376, avg loss: 0.1848957137018442\n",
      "trial: 19, epoch, 6, iter: 1, curr loss: 0.18494950234889984, avg loss: 0.18494950234889984\n",
      "trial: 19, epoch, 6, iter: 200, curr loss: 0.18813815712928772, avg loss: 0.18519608102738858\n",
      "trial: 19, epoch, 7, iter: 1, curr loss: 0.18732240796089172, avg loss: 0.18732240796089172\n",
      "trial: 19, epoch, 7, iter: 200, curr loss: 0.18383187055587769, avg loss: 0.1846275932341814\n",
      "trial: 19, epoch, 8, iter: 1, curr loss: 0.18792754411697388, avg loss: 0.18792754411697388\n",
      "trial: 19, epoch, 8, iter: 200, curr loss: 0.18565522134304047, avg loss: 0.18466914288699626\n",
      "trial: 19, epoch, 9, iter: 1, curr loss: 0.1842709183692932, avg loss: 0.1842709183692932\n",
      "trial: 19, epoch, 9, iter: 200, curr loss: 0.18946929275989532, avg loss: 0.18465464025735856\n",
      "trial: 19, epoch, 10, iter: 1, curr loss: 0.1770683377981186, avg loss: 0.1770683377981186\n",
      "trial: 19, epoch, 10, iter: 200, curr loss: 0.18574179708957672, avg loss: 0.18435291938483714\n",
      "trial: 19, epoch, 11, iter: 1, curr loss: 0.17995256185531616, avg loss: 0.17995256185531616\n",
      "trial: 19, epoch, 11, iter: 200, curr loss: 0.18468372523784637, avg loss: 0.18433723993599416\n",
      "trial: 19, epoch, 12, iter: 1, curr loss: 0.17515599727630615, avg loss: 0.17515599727630615\n",
      "trial: 19, epoch, 12, iter: 200, curr loss: 0.18121260404586792, avg loss: 0.1842661389708519\n",
      "trial: 19, epoch, 13, iter: 1, curr loss: 0.1933521032333374, avg loss: 0.1933521032333374\n",
      "trial: 19, epoch, 13, iter: 200, curr loss: 0.18145987391471863, avg loss: 0.18457677975296974\n",
      "trial: 19, epoch, 14, iter: 1, curr loss: 0.18589037656784058, avg loss: 0.18589037656784058\n",
      "trial: 19, epoch, 14, iter: 200, curr loss: 0.18456491827964783, avg loss: 0.18494979724287985\n",
      "trial: 19, epoch, 15, iter: 1, curr loss: 0.1801805943250656, avg loss: 0.1801805943250656\n",
      "trial: 19, epoch, 15, iter: 200, curr loss: 0.1825944185256958, avg loss: 0.18428250454366207\n",
      "trial: 19, epoch, 16, iter: 1, curr loss: 0.184381365776062, avg loss: 0.184381365776062\n",
      "trial: 19, epoch, 16, iter: 200, curr loss: 0.18060661852359772, avg loss: 0.18427993193268777\n",
      "trial: 19, epoch, 17, iter: 1, curr loss: 0.18382209539413452, avg loss: 0.18382209539413452\n",
      "trial: 19, epoch, 17, iter: 200, curr loss: 0.19156940281391144, avg loss: 0.18479457072913646\n",
      "trial: 19, epoch, 18, iter: 1, curr loss: 0.18140184879302979, avg loss: 0.18140184879302979\n",
      "trial: 19, epoch, 18, iter: 200, curr loss: 0.17484790086746216, avg loss: 0.18469519816339017\n",
      "trial: 19, epoch, 19, iter: 1, curr loss: 0.18485967814922333, avg loss: 0.18485967814922333\n",
      "trial: 19, epoch, 19, iter: 200, curr loss: 0.1922917664051056, avg loss: 0.18455616630613803\n",
      "trial: 19, epoch, 20, iter: 1, curr loss: 0.18969601392745972, avg loss: 0.18969601392745972\n",
      "trial: 19, epoch, 20, iter: 200, curr loss: 0.18853601813316345, avg loss: 0.18449946656823157\n",
      "trial: 19, epoch, 21, iter: 1, curr loss: 0.18975520133972168, avg loss: 0.18975520133972168\n",
      "trial: 19, epoch, 21, iter: 200, curr loss: 0.19092941284179688, avg loss: 0.18420557528734208\n",
      "trial: 19, epoch, 22, iter: 1, curr loss: 0.17839950323104858, avg loss: 0.17839950323104858\n",
      "trial: 19, epoch, 22, iter: 200, curr loss: 0.18517208099365234, avg loss: 0.19566230356693268\n",
      "trial: 19, epoch, 23, iter: 1, curr loss: 0.1816140115261078, avg loss: 0.1816140115261078\n",
      "trial: 19, epoch, 23, iter: 200, curr loss: 0.18985533714294434, avg loss: 0.1845790947973728\n",
      "trial: 19, epoch, 24, iter: 1, curr loss: 0.18972650170326233, avg loss: 0.18972650170326233\n",
      "trial: 19, epoch, 24, iter: 200, curr loss: 0.17371535301208496, avg loss: 0.18470552377402782\n",
      "trial: 19, epoch, 25, iter: 1, curr loss: 0.17876528203487396, avg loss: 0.17876528203487396\n",
      "trial: 19, epoch, 25, iter: 200, curr loss: 0.17549043893814087, avg loss: 0.1844557663798332\n",
      "trial: 19, epoch, 26, iter: 1, curr loss: 0.177308589220047, avg loss: 0.177308589220047\n",
      "trial: 19, epoch, 26, iter: 200, curr loss: 0.18459883332252502, avg loss: 0.1845016784965992\n",
      "trial: 19, epoch, 27, iter: 1, curr loss: 0.18264856934547424, avg loss: 0.18264856934547424\n",
      "trial: 19, epoch, 27, iter: 200, curr loss: 0.1874879002571106, avg loss: 0.18426722645759583\n",
      "trial: 19, epoch, 28, iter: 1, curr loss: 0.18543994426727295, avg loss: 0.18543994426727295\n",
      "trial: 19, epoch, 28, iter: 200, curr loss: 0.17978085577487946, avg loss: 0.18442071937024593\n",
      "trial: 19, epoch, 29, iter: 1, curr loss: 0.19559229910373688, avg loss: 0.19559229910373688\n",
      "trial: 19, epoch, 29, iter: 200, curr loss: 0.18685030937194824, avg loss: 0.18409139595925808\n",
      "trial: 19, epoch, 30, iter: 1, curr loss: 0.1769041270017624, avg loss: 0.1769041270017624\n",
      "trial: 19, epoch, 30, iter: 200, curr loss: 0.17959854006767273, avg loss: 0.184544096365571\n",
      "trial: 19, epoch, 31, iter: 1, curr loss: 0.18299752473831177, avg loss: 0.18299752473831177\n",
      "trial: 19, epoch, 31, iter: 200, curr loss: 0.18547481298446655, avg loss: 0.184486039057374\n",
      "trial: 19, epoch, 32, iter: 1, curr loss: 0.18750153481960297, avg loss: 0.18750153481960297\n",
      "trial: 19, epoch, 32, iter: 200, curr loss: 0.18014180660247803, avg loss: 0.1845260454714298\n",
      "trial: 19, epoch, 33, iter: 1, curr loss: 0.18526726961135864, avg loss: 0.18526726961135864\n",
      "trial: 19, epoch, 33, iter: 200, curr loss: 0.18311023712158203, avg loss: 0.18460973352193832\n",
      "trial: 19, epoch, 34, iter: 1, curr loss: 0.18765434622764587, avg loss: 0.18765434622764587\n",
      "trial: 19, epoch, 34, iter: 200, curr loss: 0.1793939173221588, avg loss: 0.18446611545979977\n",
      "trial: 19, epoch, 35, iter: 1, curr loss: 0.18018345534801483, avg loss: 0.18018345534801483\n",
      "trial: 19, epoch, 35, iter: 200, curr loss: 0.17993661761283875, avg loss: 0.1842604825645685\n",
      "trial: 19, epoch, 36, iter: 1, curr loss: 0.1852910816669464, avg loss: 0.1852910816669464\n",
      "trial: 19, epoch, 36, iter: 200, curr loss: 0.19383586943149567, avg loss: 0.1843650358170271\n",
      "trial: 19, epoch, 37, iter: 1, curr loss: 0.18266943097114563, avg loss: 0.18266943097114563\n",
      "trial: 19, epoch, 37, iter: 200, curr loss: 0.18118295073509216, avg loss: 0.18453943572938442\n",
      "trial: 19, epoch, 38, iter: 1, curr loss: 0.19237159192562103, avg loss: 0.19237159192562103\n",
      "trial: 19, epoch, 38, iter: 200, curr loss: 0.1815057247877121, avg loss: 0.18463840551674365\n",
      "trial: 19, epoch, 39, iter: 1, curr loss: 0.18779657781124115, avg loss: 0.18779657781124115\n",
      "trial: 19, epoch, 39, iter: 200, curr loss: 0.18628166615962982, avg loss: 0.1846727927774191\n",
      "trial: 19, epoch, 40, iter: 1, curr loss: 0.1750287115573883, avg loss: 0.1750287115573883\n",
      "trial: 19, epoch, 40, iter: 200, curr loss: 0.1880832314491272, avg loss: 0.1845721886307001\n",
      "trial: 19, epoch, 41, iter: 1, curr loss: 0.18445847928524017, avg loss: 0.18445847928524017\n",
      "trial: 19, epoch, 41, iter: 200, curr loss: 0.1877952516078949, avg loss: 0.18479864969849585\n",
      "trial: 19, epoch, 42, iter: 1, curr loss: 0.18202972412109375, avg loss: 0.18202972412109375\n",
      "trial: 19, epoch, 42, iter: 200, curr loss: 0.18656931817531586, avg loss: 0.1843935426324606\n",
      "trial: 19, epoch, 43, iter: 1, curr loss: 0.19539788365364075, avg loss: 0.19539788365364075\n",
      "trial: 19, epoch, 43, iter: 200, curr loss: 0.1903662532567978, avg loss: 0.1845689968019724\n",
      "trial: 19, epoch, 44, iter: 1, curr loss: 0.1828245371580124, avg loss: 0.1828245371580124\n",
      "trial: 19, epoch, 44, iter: 200, curr loss: 0.18512113392353058, avg loss: 0.18449643187224865\n",
      "trial: 19, epoch, 45, iter: 1, curr loss: 0.17684108018875122, avg loss: 0.17684108018875122\n",
      "trial: 19, epoch, 45, iter: 200, curr loss: 0.1842590570449829, avg loss: 0.18482823811471463\n",
      "trial: 19, epoch, 46, iter: 1, curr loss: 0.17657627165317535, avg loss: 0.17657627165317535\n",
      "trial: 19, epoch, 46, iter: 200, curr loss: 0.18375235795974731, avg loss: 0.18480113834142686\n",
      "trial: 19, epoch, 47, iter: 1, curr loss: 0.1841242015361786, avg loss: 0.1841242015361786\n",
      "trial: 19, epoch, 47, iter: 200, curr loss: 0.18823572993278503, avg loss: 0.18454248197376727\n",
      "trial: 19, epoch, 48, iter: 1, curr loss: 0.18030968308448792, avg loss: 0.18030968308448792\n",
      "trial: 19, epoch, 48, iter: 200, curr loss: 0.18776008486747742, avg loss: 0.18495642699301243\n",
      "trial: 19, epoch, 49, iter: 1, curr loss: 0.18285083770751953, avg loss: 0.18285083770751953\n",
      "trial: 19, epoch, 49, iter: 200, curr loss: 0.1882798969745636, avg loss: 0.18454694725573062\n",
      "trial: 19, epoch, 50, iter: 1, curr loss: 0.18742334842681885, avg loss: 0.18742334842681885\n",
      "trial: 19, epoch, 50, iter: 200, curr loss: 0.17921559512615204, avg loss: 0.18389135278761387\n",
      "trial: 19, ldr: 18.144798278808594, dv: 19.551584243774414, nwj: 18.899869918823242\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 20, epoch, 1, iter: 1, curr loss: 0.6939077973365784, avg loss: 0.6939077973365784\n",
      "trial: 20, epoch, 1, iter: 200, curr loss: 0.19022026658058167, avg loss: 0.22468266740441323\n",
      "trial: 20, epoch, 2, iter: 1, curr loss: 0.196395605802536, avg loss: 0.196395605802536\n",
      "trial: 20, epoch, 2, iter: 200, curr loss: 0.18601757287979126, avg loss: 0.1867635064572096\n",
      "trial: 20, epoch, 3, iter: 1, curr loss: 0.18332649767398834, avg loss: 0.18332649767398834\n",
      "trial: 20, epoch, 3, iter: 200, curr loss: 0.18134653568267822, avg loss: 0.18628623127937316\n",
      "trial: 20, epoch, 4, iter: 1, curr loss: 0.19370415806770325, avg loss: 0.19370415806770325\n",
      "trial: 20, epoch, 4, iter: 200, curr loss: 0.17595013976097107, avg loss: 0.1851853559166193\n",
      "trial: 20, epoch, 5, iter: 1, curr loss: 0.18945366144180298, avg loss: 0.18945366144180298\n",
      "trial: 20, epoch, 5, iter: 200, curr loss: 0.1834174543619156, avg loss: 0.18506654046475887\n",
      "trial: 20, epoch, 6, iter: 1, curr loss: 0.18857961893081665, avg loss: 0.18857961893081665\n",
      "trial: 20, epoch, 6, iter: 200, curr loss: 0.18855997920036316, avg loss: 0.18520752064883708\n",
      "trial: 20, epoch, 7, iter: 1, curr loss: 0.18947884440422058, avg loss: 0.18947884440422058\n",
      "trial: 20, epoch, 7, iter: 200, curr loss: 0.18883663415908813, avg loss: 0.18483699053525926\n",
      "trial: 20, epoch, 8, iter: 1, curr loss: 0.17705503106117249, avg loss: 0.17705503106117249\n",
      "trial: 20, epoch, 8, iter: 200, curr loss: 0.19284379482269287, avg loss: 0.18449038453400135\n",
      "trial: 20, epoch, 9, iter: 1, curr loss: 0.18059177696704865, avg loss: 0.18059177696704865\n",
      "trial: 20, epoch, 9, iter: 200, curr loss: 0.17843297123908997, avg loss: 0.1844396512955427\n",
      "trial: 20, epoch, 10, iter: 1, curr loss: 0.18933457136154175, avg loss: 0.18933457136154175\n",
      "trial: 20, epoch, 10, iter: 200, curr loss: 0.17964771389961243, avg loss: 0.18451500572264196\n",
      "trial: 20, epoch, 11, iter: 1, curr loss: 0.1874849498271942, avg loss: 0.1874849498271942\n",
      "trial: 20, epoch, 11, iter: 200, curr loss: 0.18819084763526917, avg loss: 0.18466995514929294\n",
      "trial: 20, epoch, 12, iter: 1, curr loss: 0.18163052201271057, avg loss: 0.18163052201271057\n",
      "trial: 20, epoch, 12, iter: 200, curr loss: 0.1858552098274231, avg loss: 0.18460534445941448\n",
      "trial: 20, epoch, 13, iter: 1, curr loss: 0.1906479001045227, avg loss: 0.1906479001045227\n",
      "trial: 20, epoch, 13, iter: 200, curr loss: 0.18802210688591003, avg loss: 0.18436963692307473\n",
      "trial: 20, epoch, 14, iter: 1, curr loss: 0.18035002052783966, avg loss: 0.18035002052783966\n",
      "trial: 20, epoch, 14, iter: 200, curr loss: 0.19030316174030304, avg loss: 0.18472458258271218\n",
      "trial: 20, epoch, 15, iter: 1, curr loss: 0.19255220890045166, avg loss: 0.19255220890045166\n",
      "trial: 20, epoch, 15, iter: 200, curr loss: 0.18922030925750732, avg loss: 0.1843915382027626\n",
      "trial: 20, epoch, 16, iter: 1, curr loss: 0.1863861232995987, avg loss: 0.1863861232995987\n",
      "trial: 20, epoch, 16, iter: 200, curr loss: 0.18550975620746613, avg loss: 0.1848373844474554\n",
      "trial: 20, epoch, 17, iter: 1, curr loss: 0.18391570448875427, avg loss: 0.18391570448875427\n",
      "trial: 20, epoch, 17, iter: 200, curr loss: 0.18013115227222443, avg loss: 0.18489059910178185\n",
      "trial: 20, epoch, 18, iter: 1, curr loss: 0.18279433250427246, avg loss: 0.18279433250427246\n",
      "trial: 20, epoch, 18, iter: 200, curr loss: 0.1813548505306244, avg loss: 0.18477158829569817\n",
      "trial: 20, epoch, 19, iter: 1, curr loss: 0.18501102924346924, avg loss: 0.18501102924346924\n",
      "trial: 20, epoch, 19, iter: 200, curr loss: 0.18882371485233307, avg loss: 0.18446765035390855\n",
      "trial: 20, epoch, 20, iter: 1, curr loss: 0.18416158854961395, avg loss: 0.18416158854961395\n",
      "trial: 20, epoch, 20, iter: 200, curr loss: 0.18486288189888, avg loss: 0.18438309334218503\n",
      "trial: 20, epoch, 21, iter: 1, curr loss: 0.19214487075805664, avg loss: 0.19214487075805664\n",
      "trial: 20, epoch, 21, iter: 200, curr loss: 0.18888992071151733, avg loss: 0.18439967468380927\n",
      "trial: 20, epoch, 22, iter: 1, curr loss: 0.18534955382347107, avg loss: 0.18534955382347107\n",
      "trial: 20, epoch, 22, iter: 200, curr loss: 0.17619243264198303, avg loss: 0.1844590651243925\n",
      "trial: 20, epoch, 23, iter: 1, curr loss: 0.18556790053844452, avg loss: 0.18556790053844452\n",
      "trial: 20, epoch, 23, iter: 200, curr loss: 0.1825762540102005, avg loss: 0.18458797425031662\n",
      "trial: 20, epoch, 24, iter: 1, curr loss: 0.17468245327472687, avg loss: 0.17468245327472687\n",
      "trial: 20, epoch, 24, iter: 200, curr loss: 0.18288147449493408, avg loss: 0.18458837017416954\n",
      "trial: 20, epoch, 25, iter: 1, curr loss: 0.18598230183124542, avg loss: 0.18598230183124542\n",
      "trial: 20, epoch, 25, iter: 200, curr loss: 0.17831319570541382, avg loss: 0.18419670172035693\n",
      "trial: 20, epoch, 26, iter: 1, curr loss: 0.18021917343139648, avg loss: 0.18021917343139648\n",
      "trial: 20, epoch, 26, iter: 200, curr loss: 0.1860751360654831, avg loss: 0.18480474971234798\n",
      "trial: 20, epoch, 27, iter: 1, curr loss: 0.17755350470542908, avg loss: 0.17755350470542908\n",
      "trial: 20, epoch, 27, iter: 200, curr loss: 0.18037615716457367, avg loss: 0.1844482108950615\n",
      "trial: 20, epoch, 28, iter: 1, curr loss: 0.17816407978534698, avg loss: 0.17816407978534698\n",
      "trial: 20, epoch, 28, iter: 200, curr loss: 0.18872880935668945, avg loss: 0.1842359098047018\n",
      "trial: 20, epoch, 29, iter: 1, curr loss: 0.1812392771244049, avg loss: 0.1812392771244049\n",
      "trial: 20, epoch, 29, iter: 200, curr loss: 0.19203153252601624, avg loss: 0.18453094467520714\n",
      "trial: 20, epoch, 30, iter: 1, curr loss: 0.18461453914642334, avg loss: 0.18461453914642334\n",
      "trial: 20, epoch, 30, iter: 200, curr loss: 0.19098463654518127, avg loss: 0.18472592413425445\n",
      "trial: 20, epoch, 31, iter: 1, curr loss: 0.1831134557723999, avg loss: 0.1831134557723999\n",
      "trial: 20, epoch, 31, iter: 200, curr loss: 0.18667827546596527, avg loss: 0.18477625824511051\n",
      "trial: 20, epoch, 32, iter: 1, curr loss: 0.18669354915618896, avg loss: 0.18669354915618896\n",
      "trial: 20, epoch, 32, iter: 200, curr loss: 0.18330934643745422, avg loss: 0.18452954344451428\n",
      "trial: 20, epoch, 33, iter: 1, curr loss: 0.1954556703567505, avg loss: 0.1954556703567505\n",
      "trial: 20, epoch, 33, iter: 200, curr loss: 0.182966947555542, avg loss: 0.1846293918043375\n",
      "trial: 20, epoch, 34, iter: 1, curr loss: 0.18459223210811615, avg loss: 0.18459223210811615\n",
      "trial: 20, epoch, 34, iter: 200, curr loss: 0.17885346710681915, avg loss: 0.18444045186042785\n",
      "trial: 20, epoch, 35, iter: 1, curr loss: 0.19206005334854126, avg loss: 0.19206005334854126\n",
      "trial: 20, epoch, 35, iter: 200, curr loss: 0.19472071528434753, avg loss: 0.18430132955312728\n",
      "trial: 20, epoch, 36, iter: 1, curr loss: 0.1790280044078827, avg loss: 0.1790280044078827\n",
      "trial: 20, epoch, 36, iter: 200, curr loss: 0.1844693422317505, avg loss: 0.184352403357625\n",
      "trial: 20, epoch, 37, iter: 1, curr loss: 0.18905287981033325, avg loss: 0.18905287981033325\n",
      "trial: 20, epoch, 37, iter: 200, curr loss: 0.18961676955223083, avg loss: 0.18432742327451707\n",
      "trial: 20, epoch, 38, iter: 1, curr loss: 0.1829489916563034, avg loss: 0.1829489916563034\n",
      "trial: 20, epoch, 38, iter: 200, curr loss: 0.18927904963493347, avg loss: 0.18430248901247978\n",
      "trial: 20, epoch, 39, iter: 1, curr loss: 0.18968744575977325, avg loss: 0.18968744575977325\n",
      "trial: 20, epoch, 39, iter: 200, curr loss: 0.1892026662826538, avg loss: 0.18477443471550942\n",
      "trial: 20, epoch, 40, iter: 1, curr loss: 0.18526172637939453, avg loss: 0.18526172637939453\n",
      "trial: 20, epoch, 40, iter: 200, curr loss: 0.18587471544742584, avg loss: 0.1843623375147581\n",
      "trial: 20, epoch, 41, iter: 1, curr loss: 0.18860852718353271, avg loss: 0.18860852718353271\n",
      "trial: 20, epoch, 41, iter: 200, curr loss: 0.1830601841211319, avg loss: 0.1842215885221958\n",
      "trial: 20, epoch, 42, iter: 1, curr loss: 0.189944326877594, avg loss: 0.189944326877594\n",
      "trial: 20, epoch, 42, iter: 200, curr loss: 0.18973809480667114, avg loss: 0.18447852313518523\n",
      "trial: 20, epoch, 43, iter: 1, curr loss: 0.18420182168483734, avg loss: 0.18420182168483734\n",
      "trial: 20, epoch, 43, iter: 200, curr loss: 0.17775371670722961, avg loss: 0.184514612108469\n",
      "trial: 20, epoch, 44, iter: 1, curr loss: 0.18020057678222656, avg loss: 0.18020057678222656\n",
      "trial: 20, epoch, 44, iter: 200, curr loss: 0.18559950590133667, avg loss: 0.1846562172472477\n",
      "trial: 20, epoch, 45, iter: 1, curr loss: 0.18637260794639587, avg loss: 0.18637260794639587\n",
      "trial: 20, epoch, 45, iter: 200, curr loss: 0.19052986800670624, avg loss: 0.18455173432826996\n",
      "trial: 20, epoch, 46, iter: 1, curr loss: 0.18208536505699158, avg loss: 0.18208536505699158\n",
      "trial: 20, epoch, 46, iter: 200, curr loss: 0.18889886140823364, avg loss: 0.1848281344026327\n",
      "trial: 20, epoch, 47, iter: 1, curr loss: 0.1871076226234436, avg loss: 0.1871076226234436\n",
      "trial: 20, epoch, 47, iter: 200, curr loss: 0.18156251311302185, avg loss: 0.18461436189711095\n",
      "trial: 20, epoch, 48, iter: 1, curr loss: 0.18872234225273132, avg loss: 0.18872234225273132\n",
      "trial: 20, epoch, 48, iter: 200, curr loss: 0.18651166558265686, avg loss: 0.1847298776358366\n",
      "trial: 20, epoch, 49, iter: 1, curr loss: 0.18733352422714233, avg loss: 0.18733352422714233\n",
      "trial: 20, epoch, 49, iter: 200, curr loss: 0.1883041113615036, avg loss: 0.18465378500521182\n",
      "trial: 20, epoch, 50, iter: 1, curr loss: 0.17813724279403687, avg loss: 0.17813724279403687\n",
      "trial: 20, epoch, 50, iter: 200, curr loss: 0.18563738465309143, avg loss: 0.1847966056317091\n",
      "trial: 20, ldr: 15.186388969421387, dv: 16.571842193603516, nwj: 15.936179161071777\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 18.89062933921814\n",
      "\tdv: 20.2777156829834\n",
      "\tnwj: 19.640815591812135\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 20\n",
    "num_of_inner_iteration = 50\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    print('################################################################')\n",
    "    model, inner_running_loss, inner_running_loss_avg, num_of_joint, num_of_marginal = train_binary_classifier_v2(data, label, num_input_features, hidden_size_arr, lr, num_of_inner_iteration, batch_size, outer_iter, save_avg=200, print_progress=True)\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    curr_ldr, curr_dv, curr_nwj = estimate_mi_for_binary_classification(model, joint_data, num_of_joint, marginal_data, num_of_marginal)\n",
    "    print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "    print('################################################################\\n')\n",
    "    ldr_estimations.append(curr_ldr.item())\n",
    "    dv_estimations.append(curr_dv.item())\n",
    "    nwj_estimations.append(curr_nwj.item())\n",
    "    \n",
    "print('final estimations:\\n\\tldr: {}\\n\\tdv: {}\\n\\tnwj: {}'.format(np.mean(ldr_estimations), np.mean(dv_estimations), np.mean(nwj_estimations)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
