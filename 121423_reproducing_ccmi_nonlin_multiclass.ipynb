{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:24:57.748280337Z",
     "start_time": "2023-12-15T05:24:55.934908534Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulerlab/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from probabilistic_classifier.experiment import multiclass_probabilistic_classifier_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bb10f2344d44d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prime = None\n",
    "data_range = None\n",
    "\n",
    "hidden_size_arr = [64, 64]\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "num_of_outer_iteration = 10\n",
    "num_of_mid_iteration = 5\n",
    "\n",
    "para_param, priv_param = None, None\n",
    "beta_arr, alpha_arr = None, None\n",
    "\n",
    "feature_size = None\n",
    "weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a561a79b0a0ccde",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment start with data path: ./data/catNon-lin-NI_9/data.5k.dz50.seed0.npy\n",
      "################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulerlab/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1, iter: 200, curr loss: 1.3871631622314453, avg loss: 1.3874283480644225\n",
      "trial: 1, iter: 400, curr loss: 1.385521650314331, avg loss: 1.3865346264839173\n",
      "trial: 1, iter: 600, curr loss: 1.3866130113601685, avg loss: 1.3868610858917236\n",
      "trial: 1, iter: 800, curr loss: 1.386618971824646, avg loss: 1.3863496178388595\n",
      "trial: 1, iter: 1000, curr loss: 1.3875161409378052, avg loss: 1.3864269775152207\n",
      "trial: 1, iter: 1200, curr loss: 1.3856182098388672, avg loss: 1.3864713889360427\n",
      "trial: 1, iter: 1400, curr loss: 1.386499047279358, avg loss: 1.3863810783624648\n",
      "trial: 1, ldr: 0.008611053228378296\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3844290971755981, avg loss: 1.3878224718570709\n",
      "trial: 2, iter: 400, curr loss: 1.3871135711669922, avg loss: 1.3866890668869019\n",
      "trial: 2, iter: 600, curr loss: 1.3873201608657837, avg loss: 1.3866635996103287\n",
      "trial: 2, iter: 800, curr loss: 1.388466238975525, avg loss: 1.3866302525997163\n",
      "trial: 2, iter: 1000, curr loss: 1.3872557878494263, avg loss: 1.3864558088779448\n",
      "trial: 2, iter: 1200, curr loss: 1.3868482112884521, avg loss: 1.3864895850419998\n",
      "trial: 2, iter: 1400, curr loss: 1.3851518630981445, avg loss: 1.386322780251503\n",
      "trial: 2, ldr: -0.008129117079079151\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.383743405342102, avg loss: 1.3872661590576172\n",
      "trial: 3, iter: 400, curr loss: 1.3872064352035522, avg loss: 1.3867314118146896\n",
      "trial: 3, iter: 600, curr loss: 1.3839672803878784, avg loss: 1.3864537996053696\n",
      "trial: 3, iter: 800, curr loss: 1.3863935470581055, avg loss: 1.3865287983417511\n",
      "trial: 3, iter: 1000, curr loss: 1.385587215423584, avg loss: 1.3865212219953538\n",
      "trial: 3, iter: 1200, curr loss: 1.3853769302368164, avg loss: 1.3863122004270554\n",
      "trial: 3, iter: 1400, curr loss: 1.38645339012146, avg loss: 1.386502110362053\n",
      "trial: 3, ldr: -0.002878432860597968\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3848997354507446, avg loss: 1.38731285572052\n",
      "trial: 4, iter: 400, curr loss: 1.38614821434021, avg loss: 1.3866787129640579\n",
      "trial: 4, iter: 600, curr loss: 1.3860284090042114, avg loss: 1.3864903724193574\n",
      "trial: 4, iter: 800, curr loss: 1.3857640027999878, avg loss: 1.3864878916740417\n",
      "trial: 4, iter: 1000, curr loss: 1.3864630460739136, avg loss: 1.3864632958173753\n",
      "trial: 4, iter: 1200, curr loss: 1.386378288269043, avg loss: 1.386571277976036\n",
      "trial: 4, iter: 1400, curr loss: 1.3861790895462036, avg loss: 1.3864490592479706\n",
      "trial: 4, ldr: 0.0019424138590693474\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3874738216400146, avg loss: 1.387099967598915\n",
      "trial: 5, iter: 400, curr loss: 1.3854496479034424, avg loss: 1.3866958326101304\n",
      "trial: 5, iter: 600, curr loss: 1.3859072923660278, avg loss: 1.3867449551820754\n",
      "trial: 5, iter: 800, curr loss: 1.3860208988189697, avg loss: 1.3865916031599044\n",
      "trial: 5, iter: 1000, curr loss: 1.3865948915481567, avg loss: 1.3863401573896408\n",
      "trial: 5, iter: 1200, curr loss: 1.3856967687606812, avg loss: 1.3865226471424104\n",
      "trial: 5, iter: 1400, curr loss: 1.3876811265945435, avg loss: 1.386396290063858\n",
      "trial: 5, ldr: 0.001426394795998931\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00019446238875389099\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3880268335342407, avg loss: 1.3873805165290833\n",
      "trial: 1, iter: 400, curr loss: 1.3838684558868408, avg loss: 1.3865098249912262\n",
      "trial: 1, iter: 600, curr loss: 1.3847732543945312, avg loss: 1.3865640956163405\n",
      "trial: 1, iter: 800, curr loss: 1.3869394063949585, avg loss: 1.3865589851140976\n",
      "trial: 1, iter: 1000, curr loss: 1.3875147104263306, avg loss: 1.3866138762235642\n",
      "trial: 1, iter: 1200, curr loss: 1.387259840965271, avg loss: 1.3864336705207825\n",
      "trial: 1, iter: 1400, curr loss: 1.3871209621429443, avg loss: 1.3864405357837677\n",
      "trial: 1, ldr: 0.0006909703370183706\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.385869026184082, avg loss: 1.3873740243911743\n",
      "trial: 2, iter: 400, curr loss: 1.3847767114639282, avg loss: 1.3867856246232986\n",
      "trial: 2, iter: 600, curr loss: 1.3872058391571045, avg loss: 1.3865359842777252\n",
      "trial: 2, iter: 800, curr loss: 1.383863925933838, avg loss: 1.3865251791477204\n",
      "trial: 2, iter: 1000, curr loss: 1.387895941734314, avg loss: 1.386393751502037\n",
      "trial: 2, iter: 1200, curr loss: 1.3869149684906006, avg loss: 1.3863206362724305\n",
      "trial: 2, iter: 1400, curr loss: 1.38755464553833, avg loss: 1.386516388654709\n",
      "trial: 2, ldr: 0.0001491097209509462\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3872429132461548, avg loss: 1.3872292762994767\n",
      "trial: 3, iter: 400, curr loss: 1.3864498138427734, avg loss: 1.3868638932704926\n",
      "trial: 3, iter: 600, curr loss: 1.3854413032531738, avg loss: 1.386599349975586\n",
      "trial: 3, iter: 800, curr loss: 1.3865631818771362, avg loss: 1.386554913520813\n",
      "trial: 3, iter: 1000, curr loss: 1.3880616426467896, avg loss: 1.3864231115579606\n",
      "trial: 3, iter: 1200, curr loss: 1.38837730884552, avg loss: 1.3863152819871902\n",
      "trial: 3, iter: 1400, curr loss: 1.3864407539367676, avg loss: 1.386411071419716\n",
      "trial: 3, ldr: 0.0012842820724472404\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3900068998336792, avg loss: 1.3872939413785934\n",
      "trial: 4, iter: 400, curr loss: 1.3859812021255493, avg loss: 1.3871252310276032\n",
      "trial: 4, iter: 600, curr loss: 1.384783148765564, avg loss: 1.3866252493858338\n",
      "trial: 4, iter: 800, curr loss: 1.3855600357055664, avg loss: 1.386467535495758\n",
      "trial: 4, iter: 1000, curr loss: 1.3860018253326416, avg loss: 1.3864244359731674\n",
      "trial: 4, iter: 1200, curr loss: 1.386467695236206, avg loss: 1.3864115571975708\n",
      "trial: 4, iter: 1400, curr loss: 1.3864476680755615, avg loss: 1.3864027220010757\n",
      "trial: 4, ldr: 0.008329393342137337\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3847874402999878, avg loss: 1.3873692810535432\n",
      "trial: 5, iter: 400, curr loss: 1.385151743888855, avg loss: 1.3868221700191499\n",
      "trial: 5, iter: 600, curr loss: 1.3873205184936523, avg loss: 1.3865600943565368\n",
      "trial: 5, iter: 800, curr loss: 1.3871604204177856, avg loss: 1.3865743637084962\n",
      "trial: 5, iter: 1000, curr loss: 1.3870742321014404, avg loss: 1.3863762015104293\n",
      "trial: 5, iter: 1200, curr loss: 1.3839752674102783, avg loss: 1.3863113564252854\n",
      "trial: 5, iter: 1400, curr loss: 1.3852781057357788, avg loss: 1.3864180767536163\n",
      "trial: 5, ldr: 0.01613994687795639\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.005318740470102057\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3853839635849, avg loss: 1.387236258983612\n",
      "trial: 1, iter: 400, curr loss: 1.3866915702819824, avg loss: 1.3867566460371017\n",
      "trial: 1, iter: 600, curr loss: 1.3862019777297974, avg loss: 1.3865817099809647\n",
      "trial: 1, iter: 800, curr loss: 1.3891924619674683, avg loss: 1.3865330868959427\n",
      "trial: 1, iter: 1000, curr loss: 1.3874707221984863, avg loss: 1.3864976733922958\n",
      "trial: 1, iter: 1200, curr loss: 1.386853814125061, avg loss: 1.3864184832572937\n",
      "trial: 1, iter: 1400, curr loss: 1.3868428468704224, avg loss: 1.386367883682251\n",
      "trial: 1, ldr: -0.006121940910816193\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863921165466309, avg loss: 1.3871838492155075\n",
      "trial: 2, iter: 400, curr loss: 1.3880728483200073, avg loss: 1.3867323893308638\n",
      "trial: 2, iter: 600, curr loss: 1.3876433372497559, avg loss: 1.3865731012821199\n",
      "trial: 2, iter: 800, curr loss: 1.3849550485610962, avg loss: 1.3865335911512375\n",
      "trial: 2, iter: 1000, curr loss: 1.3863803148269653, avg loss: 1.386450030207634\n",
      "trial: 2, iter: 1200, curr loss: 1.3869155645370483, avg loss: 1.3864388179779052\n",
      "trial: 2, iter: 1400, curr loss: 1.387057900428772, avg loss: 1.3863440191745757\n",
      "trial: 2, ldr: -0.0015559208113700151\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3916999101638794, avg loss: 1.3876561254262925\n",
      "trial: 3, iter: 400, curr loss: 1.3892024755477905, avg loss: 1.3868615120649337\n",
      "trial: 3, iter: 600, curr loss: 1.3874125480651855, avg loss: 1.3865889716148376\n",
      "trial: 3, iter: 800, curr loss: 1.3885598182678223, avg loss: 1.386503688097\n",
      "trial: 3, iter: 1000, curr loss: 1.386080026626587, avg loss: 1.386459349989891\n",
      "trial: 3, iter: 1200, curr loss: 1.3855665922164917, avg loss: 1.3863666200637816\n",
      "trial: 3, iter: 1400, curr loss: 1.385614275932312, avg loss: 1.386443293094635\n",
      "trial: 3, ldr: -0.002620798535645008\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3867956399917603, avg loss: 1.387168197631836\n",
      "trial: 4, iter: 400, curr loss: 1.3879081010818481, avg loss: 1.3868330591917037\n",
      "trial: 4, iter: 600, curr loss: 1.388077735900879, avg loss: 1.38668201982975\n",
      "trial: 4, iter: 800, curr loss: 1.3879549503326416, avg loss: 1.3865985667705536\n",
      "trial: 4, iter: 1000, curr loss: 1.3855783939361572, avg loss: 1.386407197713852\n",
      "trial: 4, iter: 1200, curr loss: 1.3867384195327759, avg loss: 1.3864096105098724\n",
      "trial: 4, iter: 1400, curr loss: 1.3870577812194824, avg loss: 1.386480906009674\n",
      "trial: 4, ldr: 0.003228666028007865\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3863943815231323, avg loss: 1.3871043705940247\n",
      "trial: 5, iter: 400, curr loss: 1.3869303464889526, avg loss: 1.3866837865114212\n",
      "trial: 5, iter: 600, curr loss: 1.3846088647842407, avg loss: 1.386481635570526\n",
      "trial: 5, iter: 800, curr loss: 1.3867992162704468, avg loss: 1.3865578424930574\n",
      "trial: 5, iter: 1000, curr loss: 1.3865599632263184, avg loss: 1.3864229571819306\n",
      "trial: 5, iter: 1200, curr loss: 1.3853816986083984, avg loss: 1.3864581096172333\n",
      "trial: 5, iter: 1400, curr loss: 1.3853342533111572, avg loss: 1.3864159506559373\n",
      "trial: 5, ldr: 0.009170841425657272\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0004201694391667843\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3852461576461792, avg loss: 1.3870598238706588\n",
      "trial: 1, iter: 400, curr loss: 1.3851220607757568, avg loss: 1.3867902201414108\n",
      "trial: 1, iter: 600, curr loss: 1.3885949850082397, avg loss: 1.386632798910141\n",
      "trial: 1, iter: 800, curr loss: 1.3873580694198608, avg loss: 1.3865452951192856\n",
      "trial: 1, iter: 1000, curr loss: 1.386276364326477, avg loss: 1.3865085971355438\n",
      "trial: 1, iter: 1200, curr loss: 1.3851484060287476, avg loss: 1.3863688540458678\n",
      "trial: 1, iter: 1400, curr loss: 1.3874893188476562, avg loss: 1.3863892984390258\n",
      "trial: 1, ldr: -0.002793860388919711\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875104188919067, avg loss: 1.3875166350603103\n",
      "trial: 2, iter: 400, curr loss: 1.384171724319458, avg loss: 1.3865900373458862\n",
      "trial: 2, iter: 600, curr loss: 1.3867771625518799, avg loss: 1.3865287798643111\n",
      "trial: 2, iter: 800, curr loss: 1.387150764465332, avg loss: 1.3865821141004562\n",
      "trial: 2, iter: 1000, curr loss: 1.386596441268921, avg loss: 1.386480969786644\n",
      "trial: 2, iter: 1200, curr loss: 1.3876903057098389, avg loss: 1.3864841592311858\n",
      "trial: 2, iter: 1400, curr loss: 1.3846511840820312, avg loss: 1.3864047598838807\n",
      "trial: 2, ldr: -0.00614068191498518\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.384584665298462, avg loss: 1.3874006688594818\n",
      "trial: 3, iter: 400, curr loss: 1.3872551918029785, avg loss: 1.3865319347381593\n",
      "trial: 3, iter: 600, curr loss: 1.387088418006897, avg loss: 1.386867036819458\n",
      "trial: 3, iter: 800, curr loss: 1.3872401714324951, avg loss: 1.3865648341178893\n",
      "trial: 3, iter: 1000, curr loss: 1.3863160610198975, avg loss: 1.3864091688394546\n",
      "trial: 3, iter: 1200, curr loss: 1.385503888130188, avg loss: 1.3864017468690872\n",
      "trial: 3, iter: 1400, curr loss: 1.3863991498947144, avg loss: 1.386358476281166\n",
      "trial: 3, ldr: -0.00258432375267148\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860398530960083, avg loss: 1.3875887346267701\n",
      "trial: 4, iter: 400, curr loss: 1.3855386972427368, avg loss: 1.3867298835515975\n",
      "trial: 4, iter: 600, curr loss: 1.388024926185608, avg loss: 1.3865179759263992\n",
      "trial: 4, iter: 800, curr loss: 1.3894579410552979, avg loss: 1.386594327688217\n",
      "trial: 4, iter: 1000, curr loss: 1.3875278234481812, avg loss: 1.3865769737958908\n",
      "trial: 4, iter: 1200, curr loss: 1.3855171203613281, avg loss: 1.386430000066757\n",
      "trial: 4, iter: 1400, curr loss: 1.3865461349487305, avg loss: 1.3864110273122787\n",
      "trial: 4, ldr: -0.010516648180782795\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3912104368209839, avg loss: 1.3870992547273635\n",
      "trial: 5, iter: 400, curr loss: 1.3849152326583862, avg loss: 1.3866945278644562\n",
      "trial: 5, iter: 600, curr loss: 1.391023874282837, avg loss: 1.386589549779892\n",
      "trial: 5, iter: 800, curr loss: 1.3862956762313843, avg loss: 1.3864954727888108\n",
      "trial: 5, iter: 1000, curr loss: 1.3866897821426392, avg loss: 1.3864490687847137\n",
      "trial: 5, iter: 1200, curr loss: 1.3863571882247925, avg loss: 1.3864159673452376\n",
      "trial: 5, iter: 1400, curr loss: 1.3866444826126099, avg loss: 1.3864224225282669\n",
      "trial: 5, ldr: 0.0018781292019411922\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0040314770070835945\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3845200538635254, avg loss: 1.3872905850410462\n",
      "trial: 1, iter: 400, curr loss: 1.3861910104751587, avg loss: 1.3867879104614258\n",
      "trial: 1, iter: 600, curr loss: 1.389745831489563, avg loss: 1.3865664213895799\n",
      "trial: 1, iter: 800, curr loss: 1.3842473030090332, avg loss: 1.386532108783722\n",
      "trial: 1, iter: 1000, curr loss: 1.386345624923706, avg loss: 1.3865076303482056\n",
      "trial: 1, iter: 1200, curr loss: 1.3870354890823364, avg loss: 1.3864322769641877\n",
      "trial: 1, iter: 1400, curr loss: 1.3870092630386353, avg loss: 1.3863652700185776\n",
      "trial: 1, ldr: 0.002128586871549487\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3848665952682495, avg loss: 1.387236220240593\n",
      "trial: 2, iter: 400, curr loss: 1.3847479820251465, avg loss: 1.3867688351869583\n",
      "trial: 2, iter: 600, curr loss: 1.3858609199523926, avg loss: 1.38653695166111\n",
      "trial: 2, iter: 800, curr loss: 1.385462999343872, avg loss: 1.3865084052085876\n",
      "trial: 2, iter: 1000, curr loss: 1.3850114345550537, avg loss: 1.386338987350464\n",
      "trial: 2, iter: 1200, curr loss: 1.386919379234314, avg loss: 1.3863936322927475\n",
      "trial: 2, iter: 1400, curr loss: 1.386620283126831, avg loss: 1.3863507908582688\n",
      "trial: 2, ldr: -0.00989978015422821\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.383670687675476, avg loss: 1.3872743940353394\n",
      "trial: 3, iter: 400, curr loss: 1.384164571762085, avg loss: 1.3868670332431794\n",
      "trial: 3, iter: 600, curr loss: 1.3862055540084839, avg loss: 1.3865268236398698\n",
      "trial: 3, iter: 800, curr loss: 1.3857827186584473, avg loss: 1.3865618270635605\n",
      "trial: 3, iter: 1000, curr loss: 1.3882086277008057, avg loss: 1.386490722298622\n",
      "trial: 3, iter: 1200, curr loss: 1.3861517906188965, avg loss: 1.3863985913991927\n",
      "trial: 3, iter: 1400, curr loss: 1.3884302377700806, avg loss: 1.3863958704471588\n",
      "trial: 3, ldr: 0.0007609659223817289\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.390754222869873, avg loss: 1.3875754296779632\n",
      "trial: 4, iter: 400, curr loss: 1.385970950126648, avg loss: 1.3866645354032516\n",
      "trial: 4, iter: 600, curr loss: 1.3849058151245117, avg loss: 1.3867170876264572\n",
      "trial: 4, iter: 800, curr loss: 1.3896088600158691, avg loss: 1.386670359969139\n",
      "trial: 4, iter: 1000, curr loss: 1.38690984249115, avg loss: 1.3865051978826524\n",
      "trial: 4, iter: 1200, curr loss: 1.386749267578125, avg loss: 1.3862495654821396\n",
      "trial: 4, iter: 1400, curr loss: 1.3850809335708618, avg loss: 1.386528373360634\n",
      "trial: 4, ldr: -0.005816835910081863\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3875693082809448, avg loss: 1.3874026000499726\n",
      "trial: 5, iter: 400, curr loss: 1.3856441974639893, avg loss: 1.3868851673603058\n",
      "trial: 5, iter: 600, curr loss: 1.3852473497390747, avg loss: 1.386609063744545\n",
      "trial: 5, iter: 800, curr loss: 1.3864059448242188, avg loss: 1.386539298892021\n",
      "trial: 5, iter: 1000, curr loss: 1.3876591920852661, avg loss: 1.3864482599496841\n",
      "trial: 5, iter: 1200, curr loss: 1.3870383501052856, avg loss: 1.3864787274599075\n",
      "trial: 5, iter: 1400, curr loss: 1.3860602378845215, avg loss: 1.386385954618454\n",
      "trial: 5, ldr: -0.018083207309246063\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.006182054115924984\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3893678188323975, avg loss: 1.3875096541643144\n",
      "trial: 1, iter: 400, curr loss: 1.3866835832595825, avg loss: 1.3868997186422347\n",
      "trial: 1, iter: 600, curr loss: 1.3844552040100098, avg loss: 1.3864014732837677\n",
      "trial: 1, iter: 800, curr loss: 1.3860368728637695, avg loss: 1.386562201976776\n",
      "trial: 1, iter: 1000, curr loss: 1.387671947479248, avg loss: 1.3863040310144426\n",
      "trial: 1, iter: 1200, curr loss: 1.3861514329910278, avg loss: 1.3864983558654784\n",
      "trial: 1, iter: 1400, curr loss: 1.3869223594665527, avg loss: 1.3863732558488846\n",
      "trial: 1, ldr: -0.004072884563356638\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386941909790039, avg loss: 1.387566232085228\n",
      "trial: 2, iter: 400, curr loss: 1.3848223686218262, avg loss: 1.3867795813083648\n",
      "trial: 2, iter: 600, curr loss: 1.386736273765564, avg loss: 1.3865024864673614\n",
      "trial: 2, iter: 800, curr loss: 1.3849769830703735, avg loss: 1.386483106613159\n",
      "trial: 2, iter: 1000, curr loss: 1.3873255252838135, avg loss: 1.3864725095033645\n",
      "trial: 2, iter: 1200, curr loss: 1.386468768119812, avg loss: 1.3864018577337265\n",
      "trial: 2, iter: 1400, curr loss: 1.386539340019226, avg loss: 1.3863428431749343\n",
      "trial: 2, ldr: 0.009579810313880444\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3826645612716675, avg loss: 1.387108182311058\n",
      "trial: 3, iter: 400, curr loss: 1.385843276977539, avg loss: 1.3867790013551713\n",
      "trial: 3, iter: 600, curr loss: 1.3871878385543823, avg loss: 1.3865154653787612\n",
      "trial: 3, iter: 800, curr loss: 1.3872615098953247, avg loss: 1.3866427224874496\n",
      "trial: 3, iter: 1000, curr loss: 1.3859531879425049, avg loss: 1.38638791680336\n",
      "trial: 3, iter: 1200, curr loss: 1.3858921527862549, avg loss: 1.386444661617279\n",
      "trial: 3, iter: 1400, curr loss: 1.387534737586975, avg loss: 1.3863982206583023\n",
      "trial: 3, ldr: -0.0031399165745824575\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3880516290664673, avg loss: 1.387301332950592\n",
      "trial: 4, iter: 400, curr loss: 1.3860160112380981, avg loss: 1.3870057308673858\n",
      "trial: 4, iter: 600, curr loss: 1.3871347904205322, avg loss: 1.3865050321817398\n",
      "trial: 4, iter: 800, curr loss: 1.3854235410690308, avg loss: 1.3865381270647048\n",
      "trial: 4, iter: 1000, curr loss: 1.3873951435089111, avg loss: 1.3864544397592544\n",
      "trial: 4, iter: 1200, curr loss: 1.3876768350601196, avg loss: 1.3864694267511368\n",
      "trial: 4, iter: 1400, curr loss: 1.3857710361480713, avg loss: 1.3864077907800674\n",
      "trial: 4, ldr: -0.00796524528414011\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.388169288635254, avg loss: 1.387641778588295\n",
      "trial: 5, iter: 400, curr loss: 1.384884238243103, avg loss: 1.3865036499500274\n",
      "trial: 5, iter: 600, curr loss: 1.3847553730010986, avg loss: 1.3869405210018158\n",
      "trial: 5, iter: 800, curr loss: 1.386506199836731, avg loss: 1.386597563624382\n",
      "trial: 5, iter: 1000, curr loss: 1.3854480981826782, avg loss: 1.3865238058567046\n",
      "trial: 5, iter: 1200, curr loss: 1.386556625366211, avg loss: 1.386489417552948\n",
      "trial: 5, iter: 1400, curr loss: 1.3857790231704712, avg loss: 1.3864138388633729\n",
      "trial: 5, ldr: -0.00953313522040844\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0030262742657214403\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873727321624756, avg loss: 1.3874256360530852\n",
      "trial: 1, iter: 400, curr loss: 1.3890507221221924, avg loss: 1.3867411601543427\n",
      "trial: 1, iter: 600, curr loss: 1.3858283758163452, avg loss: 1.3865556055307389\n",
      "trial: 1, iter: 800, curr loss: 1.3856624364852905, avg loss: 1.3864743596315383\n",
      "trial: 1, iter: 1000, curr loss: 1.3869622945785522, avg loss: 1.3864820152521133\n",
      "trial: 1, iter: 1200, curr loss: 1.3873894214630127, avg loss: 1.3864173793792725\n",
      "trial: 1, iter: 1400, curr loss: 1.386842966079712, avg loss: 1.3863451409339904\n",
      "trial: 1, ldr: -0.0023746169172227383\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3899132013320923, avg loss: 1.387438838481903\n",
      "trial: 2, iter: 400, curr loss: 1.3873008489608765, avg loss: 1.386724406480789\n",
      "trial: 2, iter: 600, curr loss: 1.3847235441207886, avg loss: 1.3865325593948363\n",
      "trial: 2, iter: 800, curr loss: 1.3844983577728271, avg loss: 1.3864111590385437\n",
      "trial: 2, iter: 1000, curr loss: 1.3861546516418457, avg loss: 1.3864901161193848\n",
      "trial: 2, iter: 1200, curr loss: 1.385512113571167, avg loss: 1.3864281338453293\n",
      "trial: 2, iter: 1400, curr loss: 1.3866628408432007, avg loss: 1.3864059072732926\n",
      "trial: 2, ldr: -0.005819249898195267\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3846328258514404, avg loss: 1.38750821352005\n",
      "trial: 3, iter: 400, curr loss: 1.3890557289123535, avg loss: 1.3867227470874786\n",
      "trial: 3, iter: 600, curr loss: 1.3865643739700317, avg loss: 1.3865814489126205\n",
      "trial: 3, iter: 800, curr loss: 1.3854156732559204, avg loss: 1.3864503872394562\n",
      "trial: 3, iter: 1000, curr loss: 1.3883610963821411, avg loss: 1.3865320765972138\n",
      "trial: 3, iter: 1200, curr loss: 1.3876451253890991, avg loss: 1.386490159034729\n",
      "trial: 3, iter: 1400, curr loss: 1.3865056037902832, avg loss: 1.3862004321813584\n",
      "trial: 3, ldr: 0.0011729731922969222\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3868557214736938, avg loss: 1.3876883059740066\n",
      "trial: 4, iter: 400, curr loss: 1.385035514831543, avg loss: 1.3868316572904587\n",
      "trial: 4, iter: 600, curr loss: 1.3878482580184937, avg loss: 1.3864897400140763\n",
      "trial: 4, iter: 800, curr loss: 1.3856066465377808, avg loss: 1.3865156704187394\n",
      "trial: 4, iter: 1000, curr loss: 1.3872078657150269, avg loss: 1.386449363231659\n",
      "trial: 4, iter: 1200, curr loss: 1.3881003856658936, avg loss: 1.3862011814117432\n",
      "trial: 4, iter: 1400, curr loss: 1.3866606950759888, avg loss: 1.3863876926898957\n",
      "trial: 4, ldr: -0.0010750270448625088\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3844387531280518, avg loss: 1.387185179591179\n",
      "trial: 5, iter: 400, curr loss: 1.3865094184875488, avg loss: 1.3866191524267197\n",
      "trial: 5, iter: 600, curr loss: 1.3865737915039062, avg loss: 1.3866497945785523\n",
      "trial: 5, iter: 800, curr loss: 1.3872917890548706, avg loss: 1.3864949011802674\n",
      "trial: 5, iter: 1000, curr loss: 1.3859562873840332, avg loss: 1.386397010087967\n",
      "trial: 5, iter: 1200, curr loss: 1.3864505290985107, avg loss: 1.386403706073761\n",
      "trial: 5, iter: 1400, curr loss: 1.387024998664856, avg loss: 1.386386244893074\n",
      "trial: 5, ldr: -0.003662719391286373\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.002351728011853993\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3900059461593628, avg loss: 1.3871381109952927\n",
      "trial: 1, iter: 400, curr loss: 1.3871513605117798, avg loss: 1.3867833960056304\n",
      "trial: 1, iter: 600, curr loss: 1.3891912698745728, avg loss: 1.3865734595060348\n",
      "trial: 1, iter: 800, curr loss: 1.38887357711792, avg loss: 1.386594454050064\n",
      "trial: 1, iter: 1000, curr loss: 1.3873708248138428, avg loss: 1.3863384854793548\n",
      "trial: 1, iter: 1200, curr loss: 1.387997031211853, avg loss: 1.386538080573082\n",
      "trial: 1, iter: 1400, curr loss: 1.3858145475387573, avg loss: 1.3864369958639144\n",
      "trial: 1, ldr: -0.00079143833136186\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3856693506240845, avg loss: 1.3873210495710373\n",
      "trial: 2, iter: 400, curr loss: 1.3866883516311646, avg loss: 1.3866311287879944\n",
      "trial: 2, iter: 600, curr loss: 1.383800983428955, avg loss: 1.386617156267166\n",
      "trial: 2, iter: 800, curr loss: 1.3858866691589355, avg loss: 1.3866698670387267\n",
      "trial: 2, iter: 1000, curr loss: 1.3867987394332886, avg loss: 1.3864642190933227\n",
      "trial: 2, iter: 1200, curr loss: 1.3850386142730713, avg loss: 1.3864125436544419\n",
      "trial: 2, iter: 1400, curr loss: 1.3833856582641602, avg loss: 1.3863265854120255\n",
      "trial: 2, ldr: -0.01536472886800766\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3888975381851196, avg loss: 1.3872912859916686\n",
      "trial: 3, iter: 400, curr loss: 1.383923888206482, avg loss: 1.386620241999626\n",
      "trial: 3, iter: 600, curr loss: 1.3840956687927246, avg loss: 1.3865154248476028\n",
      "trial: 3, iter: 800, curr loss: 1.3866792917251587, avg loss: 1.3865088385343551\n",
      "trial: 3, iter: 1000, curr loss: 1.3854726552963257, avg loss: 1.386430846452713\n",
      "trial: 3, iter: 1200, curr loss: 1.3849329948425293, avg loss: 1.3863770657777785\n",
      "trial: 3, iter: 1400, curr loss: 1.3855074644088745, avg loss: 1.3864359551668166\n",
      "trial: 3, ldr: 0.0109047070145607\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3843111991882324, avg loss: 1.387528009414673\n",
      "trial: 4, iter: 400, curr loss: 1.3883999586105347, avg loss: 1.386897909641266\n",
      "trial: 4, iter: 600, curr loss: 1.3846265077590942, avg loss: 1.3866392946243287\n",
      "trial: 4, iter: 800, curr loss: 1.3871650695800781, avg loss: 1.386488071680069\n",
      "trial: 4, iter: 1000, curr loss: 1.3854525089263916, avg loss: 1.3863988602161408\n",
      "trial: 4, iter: 1200, curr loss: 1.3856393098831177, avg loss: 1.3863760882616043\n",
      "trial: 4, iter: 1400, curr loss: 1.3874444961547852, avg loss: 1.386400484442711\n",
      "trial: 4, ldr: -0.00035086082061752677\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3883458375930786, avg loss: 1.3872356414794922\n",
      "trial: 5, iter: 400, curr loss: 1.385961651802063, avg loss: 1.3869763112068176\n",
      "trial: 5, iter: 600, curr loss: 1.3867816925048828, avg loss: 1.3865242063999177\n",
      "trial: 5, iter: 800, curr loss: 1.3865506649017334, avg loss: 1.3864815419912337\n",
      "trial: 5, iter: 1000, curr loss: 1.3852423429489136, avg loss: 1.3865132820606232\n",
      "trial: 5, iter: 1200, curr loss: 1.3858367204666138, avg loss: 1.3864251041412354\n",
      "trial: 5, iter: 1400, curr loss: 1.3858269453048706, avg loss: 1.386335386633873\n",
      "trial: 5, ldr: -0.0026092552579939365\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0016423152526840567\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3884766101837158, avg loss: 1.3872473472356797\n",
      "trial: 1, iter: 400, curr loss: 1.3859589099884033, avg loss: 1.3866603112220763\n",
      "trial: 1, iter: 600, curr loss: 1.3859912157058716, avg loss: 1.3866167837381362\n",
      "trial: 1, iter: 800, curr loss: 1.386858582496643, avg loss: 1.3866013062000275\n",
      "trial: 1, iter: 1000, curr loss: 1.386580467224121, avg loss: 1.386621989607811\n",
      "trial: 1, iter: 1200, curr loss: 1.3873276710510254, avg loss: 1.3863140398263931\n",
      "trial: 1, iter: 1400, curr loss: 1.3881698846817017, avg loss: 1.3864449220895767\n",
      "trial: 1, ldr: 0.005388238001614809\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3873642683029175, avg loss: 1.3874609637260438\n",
      "trial: 2, iter: 400, curr loss: 1.3864657878875732, avg loss: 1.3867173272371291\n",
      "trial: 2, iter: 600, curr loss: 1.3888342380523682, avg loss: 1.3866174447536468\n",
      "trial: 2, iter: 800, curr loss: 1.3865646123886108, avg loss: 1.3865120309591292\n",
      "trial: 2, iter: 1000, curr loss: 1.3856534957885742, avg loss: 1.3865557992458344\n",
      "trial: 2, iter: 1200, curr loss: 1.3870749473571777, avg loss: 1.3864136636257172\n",
      "trial: 2, iter: 1400, curr loss: 1.3877134323120117, avg loss: 1.386359177827835\n",
      "trial: 2, ldr: 0.003404897404834628\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3910295963287354, avg loss: 1.3872746056318284\n",
      "trial: 3, iter: 400, curr loss: 1.3902621269226074, avg loss: 1.3868077540397643\n",
      "trial: 3, iter: 600, curr loss: 1.3868330717086792, avg loss: 1.3865937983989716\n",
      "trial: 3, iter: 800, curr loss: 1.3859535455703735, avg loss: 1.386462107896805\n",
      "trial: 3, iter: 1000, curr loss: 1.386299729347229, avg loss: 1.386336355805397\n",
      "trial: 3, iter: 1200, curr loss: 1.388668179512024, avg loss: 1.3864311492443084\n",
      "trial: 3, iter: 1400, curr loss: 1.3853963613510132, avg loss: 1.386308017373085\n",
      "trial: 3, ldr: -0.004782042000442743\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3858284950256348, avg loss: 1.3876568007469177\n",
      "trial: 4, iter: 400, curr loss: 1.3870415687561035, avg loss: 1.3868080818653106\n",
      "trial: 4, iter: 600, curr loss: 1.3868459463119507, avg loss: 1.386801277399063\n",
      "trial: 4, iter: 800, curr loss: 1.3869932889938354, avg loss: 1.386536442041397\n",
      "trial: 4, iter: 1000, curr loss: 1.3871984481811523, avg loss: 1.3863735896348954\n",
      "trial: 4, iter: 1200, curr loss: 1.3865373134613037, avg loss: 1.3864204186201095\n",
      "trial: 4, iter: 1400, curr loss: 1.3868927955627441, avg loss: 1.3865639662742615\n",
      "trial: 4, ldr: -0.007427990902215242\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3840895891189575, avg loss: 1.387185861468315\n",
      "trial: 5, iter: 400, curr loss: 1.3871790170669556, avg loss: 1.3868350613117217\n",
      "trial: 5, iter: 600, curr loss: 1.385107159614563, avg loss: 1.3864414584636688\n",
      "trial: 5, iter: 800, curr loss: 1.386034369468689, avg loss: 1.3864318633079529\n",
      "trial: 5, iter: 1000, curr loss: 1.3875278234481812, avg loss: 1.3864713525772094\n",
      "trial: 5, iter: 1200, curr loss: 1.386527419090271, avg loss: 1.3865026760101318\n",
      "trial: 5, iter: 1400, curr loss: 1.385284662246704, avg loss: 1.3863957566022873\n",
      "trial: 5, ldr: 0.0059476085007190704\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0005061422009021044\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3827362060546875, avg loss: 1.3875379061698914\n",
      "trial: 1, iter: 400, curr loss: 1.3879797458648682, avg loss: 1.3867623865604402\n",
      "trial: 1, iter: 600, curr loss: 1.3889586925506592, avg loss: 1.3866028904914856\n",
      "trial: 1, iter: 800, curr loss: 1.3870371580123901, avg loss: 1.3866424095630645\n",
      "trial: 1, iter: 1000, curr loss: 1.3871753215789795, avg loss: 1.3864180326461792\n",
      "trial: 1, iter: 1200, curr loss: 1.3873165845870972, avg loss: 1.3864513075351714\n",
      "trial: 1, iter: 1400, curr loss: 1.3857951164245605, avg loss: 1.38636336684227\n",
      "trial: 1, ldr: 0.0006495943525806069\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849503993988037, avg loss: 1.3874699252843856\n",
      "trial: 2, iter: 400, curr loss: 1.3846383094787598, avg loss: 1.3865837794542313\n",
      "trial: 2, iter: 600, curr loss: 1.3852494955062866, avg loss: 1.3866634595394134\n",
      "trial: 2, iter: 800, curr loss: 1.3866260051727295, avg loss: 1.3866114598512649\n",
      "trial: 2, iter: 1000, curr loss: 1.3867805004119873, avg loss: 1.3864328932762147\n",
      "trial: 2, iter: 1200, curr loss: 1.3872010707855225, avg loss: 1.3864400207996368\n",
      "trial: 2, iter: 1400, curr loss: 1.385864496231079, avg loss: 1.3864157074689865\n",
      "trial: 2, ldr: 0.008650059811770916\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3896193504333496, avg loss: 1.3873566108942033\n",
      "trial: 3, iter: 400, curr loss: 1.3837145566940308, avg loss: 1.386622004508972\n",
      "trial: 3, iter: 600, curr loss: 1.3856464624404907, avg loss: 1.386527557373047\n",
      "trial: 3, iter: 800, curr loss: 1.3857461214065552, avg loss: 1.3863957649469376\n",
      "trial: 3, iter: 1000, curr loss: 1.3874998092651367, avg loss: 1.3864387780427934\n",
      "trial: 3, iter: 1200, curr loss: 1.3870683908462524, avg loss: 1.3863078409433365\n",
      "trial: 3, iter: 1400, curr loss: 1.3865727186203003, avg loss: 1.3864270102977754\n",
      "trial: 3, ldr: -0.005814644508063793\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3840203285217285, avg loss: 1.3871186941862106\n",
      "trial: 4, iter: 400, curr loss: 1.3880188465118408, avg loss: 1.3867684310674668\n",
      "trial: 4, iter: 600, curr loss: 1.3851237297058105, avg loss: 1.3868058604001998\n",
      "trial: 4, iter: 800, curr loss: 1.3880013227462769, avg loss: 1.3865099352598191\n",
      "trial: 4, iter: 1000, curr loss: 1.3857680559158325, avg loss: 1.3865358650684356\n",
      "trial: 4, iter: 1200, curr loss: 1.386777639389038, avg loss: 1.386467032432556\n",
      "trial: 4, iter: 1400, curr loss: 1.386924147605896, avg loss: 1.3862953680753707\n",
      "trial: 4, ldr: -0.004350930918008089\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3840047121047974, avg loss: 1.3871345043182373\n",
      "trial: 5, iter: 400, curr loss: 1.3858526945114136, avg loss: 1.3866555082798004\n",
      "trial: 5, iter: 600, curr loss: 1.38689386844635, avg loss: 1.3865870314836501\n",
      "trial: 5, iter: 800, curr loss: 1.3860561847686768, avg loss: 1.386457160115242\n",
      "trial: 5, iter: 1000, curr loss: 1.3861407041549683, avg loss: 1.386415768265724\n",
      "trial: 5, iter: 1200, curr loss: 1.386714220046997, avg loss: 1.3863657522201538\n",
      "trial: 5, iter: 1400, curr loss: 1.3865172863006592, avg loss: 1.3863535386323929\n",
      "trial: 5, ldr: -0.005097514484077692\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0011926871491596102\n",
      "Experiment done with data path: ./data/catNon-lin-NI_9/data.5k.dz50.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_13/data.5k.dz100.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.383122205734253, avg loss: 1.3871858328580857\n",
      "trial: 1, iter: 400, curr loss: 1.3883951902389526, avg loss: 1.3868215000629425\n",
      "trial: 1, iter: 600, curr loss: 1.3841090202331543, avg loss: 1.386495286822319\n",
      "trial: 1, iter: 800, curr loss: 1.3879154920578003, avg loss: 1.3866294330358506\n",
      "trial: 1, iter: 1000, curr loss: 1.3870724439620972, avg loss: 1.3864235579967499\n",
      "trial: 1, iter: 1200, curr loss: 1.3881374597549438, avg loss: 1.386330509185791\n",
      "trial: 1, iter: 1400, curr loss: 1.3864506483078003, avg loss: 1.3864182740449906\n",
      "trial: 1, ldr: -0.007914385758340359\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3892987966537476, avg loss: 1.387449614405632\n",
      "trial: 2, iter: 400, curr loss: 1.3858163356781006, avg loss: 1.3866223287582398\n",
      "trial: 2, iter: 600, curr loss: 1.3881736993789673, avg loss: 1.3865993362665177\n",
      "trial: 2, iter: 800, curr loss: 1.3868939876556396, avg loss: 1.3864998942613602\n",
      "trial: 2, iter: 1000, curr loss: 1.3863980770111084, avg loss: 1.3864011019468307\n",
      "trial: 2, iter: 1200, curr loss: 1.3874565362930298, avg loss: 1.3863269740343094\n",
      "trial: 2, iter: 1400, curr loss: 1.3854228258132935, avg loss: 1.3865373355150223\n",
      "trial: 2, ldr: -0.010310499928891659\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3871272802352905, avg loss: 1.3871515828371048\n",
      "trial: 3, iter: 400, curr loss: 1.3878127336502075, avg loss: 1.386677766442299\n",
      "trial: 3, iter: 600, curr loss: 1.3851909637451172, avg loss: 1.3866220378875733\n",
      "trial: 3, iter: 800, curr loss: 1.3857744932174683, avg loss: 1.38655768096447\n",
      "trial: 3, iter: 1000, curr loss: 1.3873286247253418, avg loss: 1.386358557343483\n",
      "trial: 3, iter: 1200, curr loss: 1.3859963417053223, avg loss: 1.3863619983196258\n",
      "trial: 3, iter: 1400, curr loss: 1.3836991786956787, avg loss: 1.3855325716733933\n",
      "trial: 3, ldr: -0.009834926575422287\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3866461515426636, avg loss: 1.387204270362854\n",
      "trial: 4, iter: 400, curr loss: 1.3859034776687622, avg loss: 1.3867409473657608\n",
      "trial: 4, iter: 600, curr loss: 1.3884367942810059, avg loss: 1.3866380590200424\n",
      "trial: 4, iter: 800, curr loss: 1.3869343996047974, avg loss: 1.3864443093538283\n",
      "trial: 4, iter: 1000, curr loss: 1.3854633569717407, avg loss: 1.3865262931585312\n",
      "trial: 4, iter: 1200, curr loss: 1.3868188858032227, avg loss: 1.3864189612865447\n",
      "trial: 4, iter: 1400, curr loss: 1.3864425420761108, avg loss: 1.3864105534553528\n",
      "trial: 4, ldr: -0.005146046634763479\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3884799480438232, avg loss: 1.3872570580244064\n",
      "trial: 5, iter: 400, curr loss: 1.386962652206421, avg loss: 1.386656322479248\n",
      "trial: 5, iter: 600, curr loss: 1.3851054906845093, avg loss: 1.3866238886117934\n",
      "trial: 5, iter: 800, curr loss: 1.3859398365020752, avg loss: 1.3864221197366715\n",
      "trial: 5, iter: 1000, curr loss: 1.38496994972229, avg loss: 1.3864803010225295\n",
      "trial: 5, iter: 1200, curr loss: 1.3883652687072754, avg loss: 1.3864910113811493\n",
      "trial: 5, iter: 1400, curr loss: 1.3876430988311768, avg loss: 1.3863674986362458\n",
      "trial: 5, ldr: -0.008148174732923508\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.008270806726068258\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3853451013565063, avg loss: 1.3872238034009934\n",
      "trial: 1, iter: 400, curr loss: 1.3859665393829346, avg loss: 1.386636525988579\n",
      "trial: 1, iter: 600, curr loss: 1.388439416885376, avg loss: 1.3866071784496308\n",
      "trial: 1, iter: 800, curr loss: 1.3859894275665283, avg loss: 1.3865620690584182\n",
      "trial: 1, iter: 1000, curr loss: 1.38774573802948, avg loss: 1.3865539598464967\n",
      "trial: 1, iter: 1200, curr loss: 1.386007308959961, avg loss: 1.3863283812999725\n",
      "trial: 1, iter: 1400, curr loss: 1.385213851928711, avg loss: 1.386349692940712\n",
      "trial: 1, ldr: -0.010588335804641247\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3844910860061646, avg loss: 1.3871288585662842\n",
      "trial: 2, iter: 400, curr loss: 1.3872613906860352, avg loss: 1.3866188943386077\n",
      "trial: 2, iter: 600, curr loss: 1.3871172666549683, avg loss: 1.386595618724823\n",
      "trial: 2, iter: 800, curr loss: 1.384277582168579, avg loss: 1.386477279663086\n",
      "trial: 2, iter: 1000, curr loss: 1.3865147829055786, avg loss: 1.3864848440885544\n",
      "trial: 2, iter: 1200, curr loss: 1.3857321739196777, avg loss: 1.3864448899030686\n",
      "trial: 2, iter: 1400, curr loss: 1.3849666118621826, avg loss: 1.386371794939041\n",
      "trial: 2, ldr: -0.0018079791916534305\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3847182989120483, avg loss: 1.3872217971086502\n",
      "trial: 3, iter: 400, curr loss: 1.3858829736709595, avg loss: 1.386696171760559\n",
      "trial: 3, iter: 600, curr loss: 1.3858988285064697, avg loss: 1.3866322565078735\n",
      "trial: 3, iter: 800, curr loss: 1.3834187984466553, avg loss: 1.3865119487047195\n",
      "trial: 3, iter: 1000, curr loss: 1.3873924016952515, avg loss: 1.3865092343091965\n",
      "trial: 3, iter: 1200, curr loss: 1.386319637298584, avg loss: 1.3865788471698761\n",
      "trial: 3, iter: 1400, curr loss: 1.386763334274292, avg loss: 1.3863349431753158\n",
      "trial: 3, ldr: -0.010980242863297462\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3858591318130493, avg loss: 1.3873965281248093\n",
      "trial: 4, iter: 400, curr loss: 1.3870080709457397, avg loss: 1.3867206716537475\n",
      "trial: 4, iter: 600, curr loss: 1.3874969482421875, avg loss: 1.3865456533432008\n",
      "trial: 4, iter: 800, curr loss: 1.3870738744735718, avg loss: 1.3864292269945144\n",
      "trial: 4, iter: 1000, curr loss: 1.3868688344955444, avg loss: 1.3865099865198136\n",
      "trial: 4, iter: 1200, curr loss: 1.3863561153411865, avg loss: 1.3864871299266814\n",
      "trial: 4, iter: 1400, curr loss: 1.3873193264007568, avg loss: 1.3864063012599945\n",
      "trial: 4, ldr: 0.004746789578348398\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.388892650604248, avg loss: 1.387290723323822\n",
      "trial: 5, iter: 400, curr loss: 1.3871439695358276, avg loss: 1.386575875878334\n",
      "trial: 5, iter: 600, curr loss: 1.3865522146224976, avg loss: 1.386541067957878\n",
      "trial: 5, iter: 800, curr loss: 1.3870116472244263, avg loss: 1.3863910275697708\n",
      "trial: 5, iter: 1000, curr loss: 1.3853763341903687, avg loss: 1.38638277053833\n",
      "trial: 5, iter: 1200, curr loss: 1.3853801488876343, avg loss: 1.3862658315896987\n",
      "trial: 5, iter: 1400, curr loss: 1.3868297338485718, avg loss: 1.3863505268096923\n",
      "trial: 5, ldr: -0.004228848498314619\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.004571723355911672\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3864072561264038, avg loss: 1.3872399878501893\n",
      "trial: 1, iter: 400, curr loss: 1.3873002529144287, avg loss: 1.3866532909870148\n",
      "trial: 1, iter: 600, curr loss: 1.3856838941574097, avg loss: 1.3865828704833985\n",
      "trial: 1, iter: 800, curr loss: 1.3860312700271606, avg loss: 1.3864403009414672\n",
      "trial: 1, iter: 1000, curr loss: 1.387657642364502, avg loss: 1.3864436107873916\n",
      "trial: 1, iter: 1200, curr loss: 1.3857569694519043, avg loss: 1.3864906531572343\n",
      "trial: 1, iter: 1400, curr loss: 1.3861228227615356, avg loss: 1.3863241291046142\n",
      "trial: 1, ldr: 0.002353670774027705\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3870429992675781, avg loss: 1.3873496609926224\n",
      "trial: 2, iter: 400, curr loss: 1.3870242834091187, avg loss: 1.3867152613401412\n",
      "trial: 2, iter: 600, curr loss: 1.3855124711990356, avg loss: 1.3865797859430313\n",
      "trial: 2, iter: 800, curr loss: 1.3870978355407715, avg loss: 1.3865275919437408\n",
      "trial: 2, iter: 1000, curr loss: 1.3869515657424927, avg loss: 1.3865042161941528\n",
      "trial: 2, iter: 1200, curr loss: 1.386417031288147, avg loss: 1.3864134258031846\n",
      "trial: 2, iter: 1400, curr loss: 1.3860002756118774, avg loss: 1.3863182616233827\n",
      "trial: 2, ldr: -0.001946905511431396\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387125015258789, avg loss: 1.3873527139425277\n",
      "trial: 3, iter: 400, curr loss: 1.386289119720459, avg loss: 1.386800064444542\n",
      "trial: 3, iter: 600, curr loss: 1.3876183032989502, avg loss: 1.3866083055734635\n",
      "trial: 3, iter: 800, curr loss: 1.3885096311569214, avg loss: 1.3865539336204529\n",
      "trial: 3, iter: 1000, curr loss: 1.3903870582580566, avg loss: 1.3865125977993011\n",
      "trial: 3, iter: 1200, curr loss: 1.3864387273788452, avg loss: 1.3864380276203156\n",
      "trial: 3, iter: 1400, curr loss: 1.3853724002838135, avg loss: 1.3863854521512986\n",
      "trial: 3, ldr: -0.002975982613861561\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3836286067962646, avg loss: 1.387366018295288\n",
      "trial: 4, iter: 400, curr loss: 1.3847891092300415, avg loss: 1.386691501736641\n",
      "trial: 4, iter: 600, curr loss: 1.386606216430664, avg loss: 1.3863757288455962\n",
      "trial: 4, iter: 800, curr loss: 1.3862425088882446, avg loss: 1.3865040355920792\n",
      "trial: 4, iter: 1000, curr loss: 1.3851763010025024, avg loss: 1.3863904911279679\n",
      "trial: 4, iter: 1200, curr loss: 1.3872060775756836, avg loss: 1.3864078551530838\n",
      "trial: 4, iter: 1400, curr loss: 1.3852381706237793, avg loss: 1.3864670795202256\n",
      "trial: 4, ldr: 0.00886283814907074\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3847557306289673, avg loss: 1.3873935562372208\n",
      "trial: 5, iter: 400, curr loss: 1.386375904083252, avg loss: 1.3868605732917785\n",
      "trial: 5, iter: 600, curr loss: 1.387844204902649, avg loss: 1.3865383303165435\n",
      "trial: 5, iter: 800, curr loss: 1.3887134790420532, avg loss: 1.3864892327785492\n",
      "trial: 5, iter: 1000, curr loss: 1.3859326839447021, avg loss: 1.386373353600502\n",
      "trial: 5, iter: 1200, curr loss: 1.3867974281311035, avg loss: 1.3863858294487\n",
      "trial: 5, iter: 1400, curr loss: 1.385608434677124, avg loss: 1.3862376260757445\n",
      "trial: 5, ldr: -0.00969219021499157\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0006797138834372163\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3849830627441406, avg loss: 1.3872282046079636\n",
      "trial: 1, iter: 400, curr loss: 1.3868883848190308, avg loss: 1.3867317312955856\n",
      "trial: 1, iter: 600, curr loss: 1.3887302875518799, avg loss: 1.3864871174097062\n",
      "trial: 1, iter: 800, curr loss: 1.386602520942688, avg loss: 1.3864496558904649\n",
      "trial: 1, iter: 1000, curr loss: 1.387232780456543, avg loss: 1.386443703174591\n",
      "trial: 1, iter: 1200, curr loss: 1.3871960639953613, avg loss: 1.3864614123106003\n",
      "trial: 1, iter: 1400, curr loss: 1.386775255203247, avg loss: 1.3863958609104157\n",
      "trial: 1, ldr: -0.0004742644669022411\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387075424194336, avg loss: 1.3873879623413086\n",
      "trial: 2, iter: 400, curr loss: 1.3890175819396973, avg loss: 1.3867913687229156\n",
      "trial: 2, iter: 600, curr loss: 1.388525366783142, avg loss: 1.38673723757267\n",
      "trial: 2, iter: 800, curr loss: 1.385777235031128, avg loss: 1.386588990688324\n",
      "trial: 2, iter: 1000, curr loss: 1.3867157697677612, avg loss: 1.3864928495883941\n",
      "trial: 2, iter: 1200, curr loss: 1.3871536254882812, avg loss: 1.3863263785839082\n",
      "trial: 2, iter: 1400, curr loss: 1.3876982927322388, avg loss: 1.3863566678762436\n",
      "trial: 2, ldr: 0.012826267629861832\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3878703117370605, avg loss: 1.3871412247419357\n",
      "trial: 3, iter: 400, curr loss: 1.3878428936004639, avg loss: 1.3865541541576385\n",
      "trial: 3, iter: 600, curr loss: 1.3861819505691528, avg loss: 1.3866778242588043\n",
      "trial: 3, iter: 800, curr loss: 1.3878273963928223, avg loss: 1.3865385746955872\n",
      "trial: 3, iter: 1000, curr loss: 1.3872162103652954, avg loss: 1.386487322449684\n",
      "trial: 3, iter: 1200, curr loss: 1.388134479522705, avg loss: 1.3864819025993347\n",
      "trial: 3, iter: 1400, curr loss: 1.3867980241775513, avg loss: 1.3864338463544845\n",
      "trial: 3, ldr: 0.006202101241797209\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386906385421753, avg loss: 1.387446471452713\n",
      "trial: 4, iter: 400, curr loss: 1.385805368423462, avg loss: 1.3868051254749298\n",
      "trial: 4, iter: 600, curr loss: 1.3863569498062134, avg loss: 1.3865655022859573\n",
      "trial: 4, iter: 800, curr loss: 1.387194275856018, avg loss: 1.3866601830720902\n",
      "trial: 4, iter: 1000, curr loss: 1.3874092102050781, avg loss: 1.386490620970726\n",
      "trial: 4, iter: 1200, curr loss: 1.38618803024292, avg loss: 1.3865574103593827\n",
      "trial: 4, iter: 1400, curr loss: 1.3872536420822144, avg loss: 1.3863609516620636\n",
      "trial: 4, ldr: -0.0020333556458353996\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.386200189590454, avg loss: 1.3873782873153686\n",
      "trial: 5, iter: 400, curr loss: 1.3855371475219727, avg loss: 1.3865697103738786\n",
      "trial: 5, iter: 600, curr loss: 1.3870234489440918, avg loss: 1.3863295859098435\n",
      "trial: 5, iter: 800, curr loss: 1.3842533826828003, avg loss: 1.386438336968422\n",
      "trial: 5, iter: 1000, curr loss: 1.3849865198135376, avg loss: 1.3861816507577895\n",
      "trial: 5, iter: 1200, curr loss: 1.3841842412948608, avg loss: 1.386132001876831\n",
      "trial: 5, iter: 1400, curr loss: 1.385735034942627, avg loss: 1.3857220262289047\n",
      "trial: 5, ldr: 0.01605021022260189\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.006514191796304658\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3841315507888794, avg loss: 1.3873153775930405\n",
      "trial: 1, iter: 400, curr loss: 1.3871490955352783, avg loss: 1.3866018736362458\n",
      "trial: 1, iter: 600, curr loss: 1.3875757455825806, avg loss: 1.3865845161676407\n",
      "trial: 1, iter: 800, curr loss: 1.3854819536209106, avg loss: 1.3863636934757233\n",
      "trial: 1, iter: 1000, curr loss: 1.3868428468704224, avg loss: 1.3865100479125976\n",
      "trial: 1, iter: 1200, curr loss: 1.3859163522720337, avg loss: 1.3863772869110107\n",
      "trial: 1, iter: 1400, curr loss: 1.3860771656036377, avg loss: 1.3863085132837296\n",
      "trial: 1, ldr: 0.0026868933346122503\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3847010135650635, avg loss: 1.3873748260736465\n",
      "trial: 2, iter: 400, curr loss: 1.386352777481079, avg loss: 1.3867206692695617\n",
      "trial: 2, iter: 600, curr loss: 1.3871639966964722, avg loss: 1.386569816470146\n",
      "trial: 2, iter: 800, curr loss: 1.3857299089431763, avg loss: 1.3864338356256485\n",
      "trial: 2, iter: 1000, curr loss: 1.386391520500183, avg loss: 1.3864309698343278\n",
      "trial: 2, iter: 1200, curr loss: 1.3855993747711182, avg loss: 1.386438812017441\n",
      "trial: 2, iter: 1400, curr loss: 1.3864493370056152, avg loss: 1.3862854146957397\n",
      "trial: 2, ldr: -0.010344656184315681\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.386513352394104, avg loss: 1.3872887009382249\n",
      "trial: 3, iter: 400, curr loss: 1.3830418586730957, avg loss: 1.386809972524643\n",
      "trial: 3, iter: 600, curr loss: 1.3866398334503174, avg loss: 1.3866075879335404\n",
      "trial: 3, iter: 800, curr loss: 1.3867011070251465, avg loss: 1.386595043540001\n",
      "trial: 3, iter: 1000, curr loss: 1.3861185312271118, avg loss: 1.386488420367241\n",
      "trial: 3, iter: 1200, curr loss: 1.3878965377807617, avg loss: 1.386382031440735\n",
      "trial: 3, iter: 1400, curr loss: 1.3866796493530273, avg loss: 1.3864296066761017\n",
      "trial: 3, ldr: -0.016345376148819923\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.38290536403656, avg loss: 1.3872442662715911\n",
      "trial: 4, iter: 400, curr loss: 1.3845666646957397, avg loss: 1.3869272708892821\n",
      "trial: 4, iter: 600, curr loss: 1.3864376544952393, avg loss: 1.3865650868415833\n",
      "trial: 4, iter: 800, curr loss: 1.3876307010650635, avg loss: 1.3866289454698562\n",
      "trial: 4, iter: 1000, curr loss: 1.3870755434036255, avg loss: 1.3864434748888015\n",
      "trial: 4, iter: 1200, curr loss: 1.3874680995941162, avg loss: 1.3864573061466217\n",
      "trial: 4, iter: 1400, curr loss: 1.3871042728424072, avg loss: 1.3865033572912215\n",
      "trial: 4, ldr: 0.01287563145160675\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3855267763137817, avg loss: 1.38761483669281\n",
      "trial: 5, iter: 400, curr loss: 1.3839889764785767, avg loss: 1.3867933112382889\n",
      "trial: 5, iter: 600, curr loss: 1.3855218887329102, avg loss: 1.3867211455106736\n",
      "trial: 5, iter: 800, curr loss: 1.3859755992889404, avg loss: 1.386467981338501\n",
      "trial: 5, iter: 1000, curr loss: 1.3877651691436768, avg loss: 1.3866371911764146\n",
      "trial: 5, iter: 1200, curr loss: 1.384867787361145, avg loss: 1.3864732795953751\n",
      "trial: 5, iter: 1400, curr loss: 1.3886327743530273, avg loss: 1.386346925497055\n",
      "trial: 5, ldr: -0.0032718994189053774\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0028798813931643964\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3863587379455566, avg loss: 1.387577873468399\n",
      "trial: 1, iter: 400, curr loss: 1.3894782066345215, avg loss: 1.3868730956315993\n",
      "trial: 1, iter: 600, curr loss: 1.3885594606399536, avg loss: 1.3865402603149415\n",
      "trial: 1, iter: 800, curr loss: 1.3858436346054077, avg loss: 1.3865579694509507\n",
      "trial: 1, iter: 1000, curr loss: 1.3879923820495605, avg loss: 1.386414583325386\n",
      "trial: 1, iter: 1200, curr loss: 1.3859059810638428, avg loss: 1.386349513530731\n",
      "trial: 1, iter: 1400, curr loss: 1.3860574960708618, avg loss: 1.3864104270935058\n",
      "trial: 1, ldr: -0.0006526398938149214\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3898934125900269, avg loss: 1.3873728841543198\n",
      "trial: 2, iter: 400, curr loss: 1.3875226974487305, avg loss: 1.3867984288930892\n",
      "trial: 2, iter: 600, curr loss: 1.3871039152145386, avg loss: 1.3865836673974992\n",
      "trial: 2, iter: 800, curr loss: 1.3859163522720337, avg loss: 1.386470866203308\n",
      "trial: 2, iter: 1000, curr loss: 1.3863123655319214, avg loss: 1.3864497792720796\n",
      "trial: 2, iter: 1200, curr loss: 1.386396050453186, avg loss: 1.386322961449623\n",
      "trial: 2, iter: 1400, curr loss: 1.387555480003357, avg loss: 1.3859397280216217\n",
      "trial: 2, ldr: 0.0019609597511589527\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3871023654937744, avg loss: 1.3871151566505433\n",
      "trial: 3, iter: 400, curr loss: 1.3876290321350098, avg loss: 1.386821129322052\n",
      "trial: 3, iter: 600, curr loss: 1.3871204853057861, avg loss: 1.386480523943901\n",
      "trial: 3, iter: 800, curr loss: 1.3864903450012207, avg loss: 1.3864747929573058\n",
      "trial: 3, iter: 1000, curr loss: 1.3862152099609375, avg loss: 1.3863403248786925\n",
      "trial: 3, iter: 1200, curr loss: 1.3872510194778442, avg loss: 1.3863928771018983\n",
      "trial: 3, iter: 1400, curr loss: 1.385979413986206, avg loss: 1.3864246624708176\n",
      "trial: 3, ldr: 0.010445380583405495\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3869456052780151, avg loss: 1.3870563417673112\n",
      "trial: 4, iter: 400, curr loss: 1.3886449337005615, avg loss: 1.3867367190122604\n",
      "trial: 4, iter: 600, curr loss: 1.3855489492416382, avg loss: 1.386486274600029\n",
      "trial: 4, iter: 800, curr loss: 1.3871725797653198, avg loss: 1.3866587471961975\n",
      "trial: 4, iter: 1000, curr loss: 1.388216257095337, avg loss: 1.386476182937622\n",
      "trial: 4, iter: 1200, curr loss: 1.3868672847747803, avg loss: 1.3865393579006196\n",
      "trial: 4, iter: 1400, curr loss: 1.3863873481750488, avg loss: 1.3864758545160294\n",
      "trial: 4, ldr: -0.007115618325769901\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3867734670639038, avg loss: 1.3872917062044143\n",
      "trial: 5, iter: 400, curr loss: 1.3851553201675415, avg loss: 1.3867843812704086\n",
      "trial: 5, iter: 600, curr loss: 1.385459542274475, avg loss: 1.3864066863059998\n",
      "trial: 5, iter: 800, curr loss: 1.384500503540039, avg loss: 1.3864141082763672\n",
      "trial: 5, iter: 1000, curr loss: 1.386494517326355, avg loss: 1.3864607226848602\n",
      "trial: 5, iter: 1200, curr loss: 1.385962724685669, avg loss: 1.3864315223693848\n",
      "trial: 5, iter: 1400, curr loss: 1.3853431940078735, avg loss: 1.386318797469139\n",
      "trial: 5, ldr: -0.008226918056607246\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0007177671883255244\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3856559991836548, avg loss: 1.3872775894403457\n",
      "trial: 1, iter: 400, curr loss: 1.3882009983062744, avg loss: 1.38690702855587\n",
      "trial: 1, iter: 600, curr loss: 1.3872500658035278, avg loss: 1.3866314762830734\n",
      "trial: 1, iter: 800, curr loss: 1.38666570186615, avg loss: 1.3864845836162567\n",
      "trial: 1, iter: 1000, curr loss: 1.3866546154022217, avg loss: 1.3865278911590577\n",
      "trial: 1, iter: 1200, curr loss: 1.386558175086975, avg loss: 1.386436843276024\n",
      "trial: 1, iter: 1400, curr loss: 1.3869640827178955, avg loss: 1.386375722885132\n",
      "trial: 1, ldr: -0.007108367048203945\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3843441009521484, avg loss: 1.3872194981575012\n",
      "trial: 2, iter: 400, curr loss: 1.3838770389556885, avg loss: 1.3869909518957138\n",
      "trial: 2, iter: 600, curr loss: 1.3871060609817505, avg loss: 1.3865328586101533\n",
      "trial: 2, iter: 800, curr loss: 1.385521411895752, avg loss: 1.386578331589699\n",
      "trial: 2, iter: 1000, curr loss: 1.3883516788482666, avg loss: 1.38650554895401\n",
      "trial: 2, iter: 1200, curr loss: 1.3863636255264282, avg loss: 1.386410604119301\n",
      "trial: 2, iter: 1400, curr loss: 1.386833667755127, avg loss: 1.3864606356620788\n",
      "trial: 2, ldr: -0.022671017795801163\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3854960203170776, avg loss: 1.3871363711357116\n",
      "trial: 3, iter: 400, curr loss: 1.383975863456726, avg loss: 1.3866681545972823\n",
      "trial: 3, iter: 600, curr loss: 1.386985182762146, avg loss: 1.3866513752937317\n",
      "trial: 3, iter: 800, curr loss: 1.3854930400848389, avg loss: 1.3864234632253647\n",
      "trial: 3, iter: 1000, curr loss: 1.3849563598632812, avg loss: 1.3863392275571824\n",
      "trial: 3, iter: 1200, curr loss: 1.3845775127410889, avg loss: 1.3862902289628982\n",
      "trial: 3, iter: 1400, curr loss: 1.3854514360427856, avg loss: 1.3863115614652635\n",
      "trial: 3, ldr: -0.001538892975077033\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3853260278701782, avg loss: 1.3871509099006654\n",
      "trial: 4, iter: 400, curr loss: 1.3861042261123657, avg loss: 1.386606588959694\n",
      "trial: 4, iter: 600, curr loss: 1.386884331703186, avg loss: 1.3865549957752228\n",
      "trial: 4, iter: 800, curr loss: 1.387307047843933, avg loss: 1.3864088189601897\n",
      "trial: 4, iter: 1000, curr loss: 1.3876020908355713, avg loss: 1.3865131705999374\n",
      "trial: 4, iter: 1200, curr loss: 1.3857601881027222, avg loss: 1.3863194489479065\n",
      "trial: 4, iter: 1400, curr loss: 1.3857653141021729, avg loss: 1.3863722050189973\n",
      "trial: 4, ldr: 0.007908676750957966\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3896740674972534, avg loss: 1.387518482208252\n",
      "trial: 5, iter: 400, curr loss: 1.3889210224151611, avg loss: 1.3868027800321578\n",
      "trial: 5, iter: 600, curr loss: 1.3873211145401, avg loss: 1.3865572607517243\n",
      "trial: 5, iter: 800, curr loss: 1.3870819807052612, avg loss: 1.3864751303195952\n",
      "trial: 5, iter: 1000, curr loss: 1.3858656883239746, avg loss: 1.3865021592378617\n",
      "trial: 5, iter: 1200, curr loss: 1.386214017868042, avg loss: 1.3864421862363816\n",
      "trial: 5, iter: 1400, curr loss: 1.3858526945114136, avg loss: 1.386387412548065\n",
      "trial: 5, ldr: 0.012229622341692448\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0022359957452863454\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3871575593948364, avg loss: 1.3874364823102951\n",
      "trial: 1, iter: 400, curr loss: 1.3875969648361206, avg loss: 1.3865527284145356\n",
      "trial: 1, iter: 600, curr loss: 1.3884433507919312, avg loss: 1.3865421104431153\n",
      "trial: 1, iter: 800, curr loss: 1.3860269784927368, avg loss: 1.3865288323163987\n",
      "trial: 1, iter: 1000, curr loss: 1.3880218267440796, avg loss: 1.3863939601182937\n",
      "trial: 1, iter: 1200, curr loss: 1.3864140510559082, avg loss: 1.3865096431970596\n",
      "trial: 1, iter: 1400, curr loss: 1.3853446245193481, avg loss: 1.3863508754968643\n",
      "trial: 1, ldr: -0.010010565631091595\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3858822584152222, avg loss: 1.387122768163681\n",
      "trial: 2, iter: 400, curr loss: 1.3853657245635986, avg loss: 1.3866419929265976\n",
      "trial: 2, iter: 600, curr loss: 1.3844802379608154, avg loss: 1.3867065274715424\n",
      "trial: 2, iter: 800, curr loss: 1.3857182264328003, avg loss: 1.3863982731103897\n",
      "trial: 2, iter: 1000, curr loss: 1.3863385915756226, avg loss: 1.386366531252861\n",
      "trial: 2, iter: 1200, curr loss: 1.387388825416565, avg loss: 1.3861280518770218\n",
      "trial: 2, iter: 1400, curr loss: 1.3813490867614746, avg loss: 1.3850707656145096\n",
      "trial: 2, ldr: 0.021152600646018982\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387273907661438, avg loss: 1.387184453010559\n",
      "trial: 3, iter: 400, curr loss: 1.3868985176086426, avg loss: 1.3867960608005523\n",
      "trial: 3, iter: 600, curr loss: 1.3856850862503052, avg loss: 1.3866931718587876\n",
      "trial: 3, iter: 800, curr loss: 1.3865234851837158, avg loss: 1.3865609633922578\n",
      "trial: 3, iter: 1000, curr loss: 1.3864080905914307, avg loss: 1.3865209519863129\n",
      "trial: 3, iter: 1200, curr loss: 1.3867206573486328, avg loss: 1.3864632254838944\n",
      "trial: 3, iter: 1400, curr loss: 1.3862576484680176, avg loss: 1.3863527762889862\n",
      "trial: 3, ldr: 0.015061790123581886\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838251829147339, avg loss: 1.3873350417613983\n",
      "trial: 4, iter: 400, curr loss: 1.3866206407546997, avg loss: 1.3869100069999696\n",
      "trial: 4, iter: 600, curr loss: 1.3850624561309814, avg loss: 1.386707083582878\n",
      "trial: 4, iter: 800, curr loss: 1.3857228755950928, avg loss: 1.3864714723825455\n",
      "trial: 4, iter: 1000, curr loss: 1.3865675926208496, avg loss: 1.3864520782232284\n",
      "trial: 4, iter: 1200, curr loss: 1.3864574432373047, avg loss: 1.3864344090223313\n",
      "trial: 4, iter: 1400, curr loss: 1.3844040632247925, avg loss: 1.3863549065589904\n",
      "trial: 4, ldr: -0.009748779237270355\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3842434883117676, avg loss: 1.387346167564392\n",
      "trial: 5, iter: 400, curr loss: 1.3856356143951416, avg loss: 1.386807508468628\n",
      "trial: 5, iter: 600, curr loss: 1.3849503993988037, avg loss: 1.386484941840172\n",
      "trial: 5, iter: 800, curr loss: 1.3878353834152222, avg loss: 1.3865029209852218\n",
      "trial: 5, iter: 1000, curr loss: 1.3867824077606201, avg loss: 1.3864290344715118\n",
      "trial: 5, iter: 1200, curr loss: 1.3867610692977905, avg loss: 1.3864412146806717\n",
      "trial: 5, iter: 1400, curr loss: 1.3858957290649414, avg loss: 1.3863721621036529\n",
      "trial: 5, ldr: 0.012328820303082466\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.005756773240864277\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3886545896530151, avg loss: 1.3875311535596848\n",
      "trial: 1, iter: 400, curr loss: 1.3856267929077148, avg loss: 1.3867819434404374\n",
      "trial: 1, iter: 600, curr loss: 1.3857684135437012, avg loss: 1.386565568447113\n",
      "trial: 1, iter: 800, curr loss: 1.386010766029358, avg loss: 1.3865125268697738\n",
      "trial: 1, iter: 1000, curr loss: 1.3864638805389404, avg loss: 1.3864358496665954\n",
      "trial: 1, iter: 1200, curr loss: 1.38522469997406, avg loss: 1.3862246888875962\n",
      "trial: 1, iter: 1400, curr loss: 1.3864585161209106, avg loss: 1.38635693192482\n",
      "trial: 1, ldr: -0.0011442251270636916\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863015174865723, avg loss: 1.3870687013864518\n",
      "trial: 2, iter: 400, curr loss: 1.3872861862182617, avg loss: 1.3867175269126892\n",
      "trial: 2, iter: 600, curr loss: 1.3856773376464844, avg loss: 1.3866004824638367\n",
      "trial: 2, iter: 800, curr loss: 1.388873815536499, avg loss: 1.3865849775075914\n",
      "trial: 2, iter: 1000, curr loss: 1.3858405351638794, avg loss: 1.3863985049724579\n",
      "trial: 2, iter: 1200, curr loss: 1.3835694789886475, avg loss: 1.3860398066043853\n",
      "trial: 2, iter: 1400, curr loss: 1.383044719696045, avg loss: 1.383016840815544\n",
      "trial: 2, ldr: -0.013915527611970901\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389709234237671, avg loss: 1.3872068214416504\n",
      "trial: 3, iter: 400, curr loss: 1.3850014209747314, avg loss: 1.3869031637907028\n",
      "trial: 3, iter: 600, curr loss: 1.385161280632019, avg loss: 1.386491478085518\n",
      "trial: 3, iter: 800, curr loss: 1.3865163326263428, avg loss: 1.386449666619301\n",
      "trial: 3, iter: 1000, curr loss: 1.3865700960159302, avg loss: 1.386358603835106\n",
      "trial: 3, iter: 1200, curr loss: 1.386699914932251, avg loss: 1.3863176268339157\n",
      "trial: 3, iter: 1400, curr loss: 1.3868476152420044, avg loss: 1.3864389908313752\n",
      "trial: 3, ldr: -0.01616797409951687\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838188648223877, avg loss: 1.3872860831022262\n",
      "trial: 4, iter: 400, curr loss: 1.386228322982788, avg loss: 1.3867174577713013\n",
      "trial: 4, iter: 600, curr loss: 1.3895165920257568, avg loss: 1.386458483338356\n",
      "trial: 4, iter: 800, curr loss: 1.3881723880767822, avg loss: 1.3863938188552856\n",
      "trial: 4, iter: 1000, curr loss: 1.386462926864624, avg loss: 1.3863521218299866\n",
      "trial: 4, iter: 1200, curr loss: 1.3867145776748657, avg loss: 1.3861541879177093\n",
      "trial: 4, iter: 1400, curr loss: 1.3823221921920776, avg loss: 1.384227734208107\n",
      "trial: 4, ldr: 0.012450764887034893\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3864282369613647, avg loss: 1.3872866481542587\n",
      "trial: 5, iter: 400, curr loss: 1.3884155750274658, avg loss: 1.3866147869825363\n",
      "trial: 5, iter: 600, curr loss: 1.3857595920562744, avg loss: 1.386605743765831\n",
      "trial: 5, iter: 800, curr loss: 1.3861218690872192, avg loss: 1.3865826731920243\n",
      "trial: 5, iter: 1000, curr loss: 1.3886356353759766, avg loss: 1.386536026597023\n",
      "trial: 5, iter: 1200, curr loss: 1.3864061832427979, avg loss: 1.3863876092433929\n",
      "trial: 5, iter: 1400, curr loss: 1.384592890739441, avg loss: 1.386428900361061\n",
      "trial: 5, ldr: -0.0157551821321249\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0069064288167282935\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3869876861572266, avg loss: 1.3874000030755997\n",
      "trial: 1, iter: 400, curr loss: 1.388719081878662, avg loss: 1.3868213599920274\n",
      "trial: 1, iter: 600, curr loss: 1.3865406513214111, avg loss: 1.3864481836557387\n",
      "trial: 1, iter: 800, curr loss: 1.386322259902954, avg loss: 1.386484561562538\n",
      "trial: 1, iter: 1000, curr loss: 1.3868950605392456, avg loss: 1.3863825780153274\n",
      "trial: 1, iter: 1200, curr loss: 1.3861947059631348, avg loss: 1.386442534327507\n",
      "trial: 1, iter: 1400, curr loss: 1.386764407157898, avg loss: 1.3863808941841125\n",
      "trial: 1, ldr: 0.0058189695701003075\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3872628211975098, avg loss: 1.3873721390962601\n",
      "trial: 2, iter: 400, curr loss: 1.3885153532028198, avg loss: 1.3867992079257965\n",
      "trial: 2, iter: 600, curr loss: 1.3869974613189697, avg loss: 1.3865659886598587\n",
      "trial: 2, iter: 800, curr loss: 1.3887242078781128, avg loss: 1.3865182882547378\n",
      "trial: 2, iter: 1000, curr loss: 1.3856433629989624, avg loss: 1.3863088005781175\n",
      "trial: 2, iter: 1200, curr loss: 1.3850224018096924, avg loss: 1.386249166727066\n",
      "trial: 2, iter: 1400, curr loss: 1.3835382461547852, avg loss: 1.3855974918603897\n",
      "trial: 2, ldr: 0.010064274072647095\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3882273435592651, avg loss: 1.387454087138176\n",
      "trial: 3, iter: 400, curr loss: 1.3852893114089966, avg loss: 1.3866346681118011\n",
      "trial: 3, iter: 600, curr loss: 1.3870800733566284, avg loss: 1.3863427114486695\n",
      "trial: 3, iter: 800, curr loss: 1.3860647678375244, avg loss: 1.3864299070835113\n",
      "trial: 3, iter: 1000, curr loss: 1.3862277269363403, avg loss: 1.386534233689308\n",
      "trial: 3, iter: 1200, curr loss: 1.3875155448913574, avg loss: 1.3863927698135377\n",
      "trial: 3, iter: 1400, curr loss: 1.3861643075942993, avg loss: 1.3862827026844025\n",
      "trial: 3, ldr: -0.012274784967303276\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3834878206253052, avg loss: 1.387429929971695\n",
      "trial: 4, iter: 400, curr loss: 1.386189341545105, avg loss: 1.3869836473464965\n",
      "trial: 4, iter: 600, curr loss: 1.3865547180175781, avg loss: 1.3866112685203553\n",
      "trial: 4, iter: 800, curr loss: 1.386582612991333, avg loss: 1.3866217583417892\n",
      "trial: 4, iter: 1000, curr loss: 1.3850518465042114, avg loss: 1.386472613811493\n",
      "trial: 4, iter: 1200, curr loss: 1.3863593339920044, avg loss: 1.3864570504426956\n",
      "trial: 4, iter: 1400, curr loss: 1.386712670326233, avg loss: 1.3863632315397263\n",
      "trial: 4, ldr: 0.007814038544893265\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3855048418045044, avg loss: 1.3874151504039764\n",
      "trial: 5, iter: 400, curr loss: 1.383435606956482, avg loss: 1.3866261702775955\n",
      "trial: 5, iter: 600, curr loss: 1.3861973285675049, avg loss: 1.3865371090173721\n",
      "trial: 5, iter: 800, curr loss: 1.3866633176803589, avg loss: 1.3864771407842635\n",
      "trial: 5, iter: 1000, curr loss: 1.386449933052063, avg loss: 1.3864414250850678\n",
      "trial: 5, iter: 1200, curr loss: 1.3869925737380981, avg loss: 1.3863508212566376\n",
      "trial: 5, iter: 1400, curr loss: 1.3852726221084595, avg loss: 1.3864135211706161\n",
      "trial: 5, ldr: 9.572198177920654e-05\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0023036438404233197\n",
      "Experiment done with data path: ./data/catNon-lin-NI_13/data.5k.dz100.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_4/data.50k.dz10.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3887889385223389, avg loss: 1.3869376039505006\n",
      "trial: 1, iter: 400, curr loss: 1.384505271911621, avg loss: 1.3861226457357407\n",
      "trial: 1, iter: 600, curr loss: 1.3739782571792603, avg loss: 1.3753651666641236\n",
      "trial: 1, iter: 800, curr loss: 1.2995890378952026, avg loss: 1.3354473114013672\n",
      "trial: 1, iter: 1000, curr loss: 1.3171665668487549, avg loss: 1.315322580933571\n",
      "trial: 1, iter: 1200, curr loss: 1.329577088356018, avg loss: 1.3106070894002915\n",
      "trial: 1, iter: 1400, curr loss: 1.2885105609893799, avg loss: 1.3030582189559936\n",
      "trial: 1, iter: 1600, curr loss: 1.2549880743026733, avg loss: 1.2971942985057832\n",
      "trial: 1, iter: 1800, curr loss: 1.3108532428741455, avg loss: 1.291230936050415\n",
      "trial: 1, iter: 2000, curr loss: 1.2732561826705933, avg loss: 1.2897549587488175\n",
      "trial: 1, iter: 2200, curr loss: 1.2399675846099854, avg loss: 1.2792774057388305\n",
      "trial: 1, iter: 2400, curr loss: 1.2538371086120605, avg loss: 1.281877067089081\n",
      "trial: 1, iter: 2600, curr loss: 1.303419589996338, avg loss: 1.278064985871315\n",
      "trial: 1, iter: 2800, curr loss: 1.239136815071106, avg loss: 1.275805492401123\n",
      "trial: 1, iter: 3000, curr loss: 1.279218077659607, avg loss: 1.2716231274604797\n",
      "trial: 1, iter: 3200, curr loss: 1.2793668508529663, avg loss: 1.272228379845619\n",
      "trial: 1, iter: 3400, curr loss: 1.2911080121994019, avg loss: 1.2702454048395158\n",
      "trial: 1, iter: 3600, curr loss: 1.2504132986068726, avg loss: 1.2715680062770844\n",
      "trial: 1, iter: 3800, curr loss: 1.263736605644226, avg loss: 1.270404536128044\n",
      "trial: 1, iter: 4000, curr loss: 1.2294104099273682, avg loss: 1.2669034868478775\n",
      "trial: 1, iter: 4200, curr loss: 1.2643202543258667, avg loss: 1.267428045272827\n",
      "trial: 1, iter: 4400, curr loss: 1.2964787483215332, avg loss: 1.2657611751556397\n",
      "trial: 1, iter: 4600, curr loss: 1.2998472452163696, avg loss: 1.2656855738162995\n",
      "trial: 1, iter: 4800, curr loss: 1.2871949672698975, avg loss: 1.2689532393217087\n",
      "trial: 1, iter: 5000, curr loss: 1.240158200263977, avg loss: 1.2666679000854493\n",
      "trial: 1, iter: 5200, curr loss: 1.2521096467971802, avg loss: 1.2667967838048935\n",
      "trial: 1, iter: 5400, curr loss: 1.2970188856124878, avg loss: 1.2688810992240906\n",
      "trial: 1, iter: 5600, curr loss: 1.3066868782043457, avg loss: 1.26611071228981\n",
      "trial: 1, iter: 5800, curr loss: 1.2993406057357788, avg loss: 1.2678546208143233\n",
      "trial: 1, iter: 6000, curr loss: 1.277482509613037, avg loss: 1.266354843378067\n",
      "trial: 1, iter: 6200, curr loss: 1.2326083183288574, avg loss: 1.2642917305231094\n",
      "trial: 1, iter: 6400, curr loss: 1.2565057277679443, avg loss: 1.2649264687299728\n",
      "trial: 1, iter: 6600, curr loss: 1.329817771911621, avg loss: 1.2650474363565445\n",
      "trial: 1, iter: 6800, curr loss: 1.2788329124450684, avg loss: 1.2660585784912108\n",
      "trial: 1, iter: 7000, curr loss: 1.2384897470474243, avg loss: 1.263637936115265\n",
      "trial: 1, iter: 7200, curr loss: 1.2849066257476807, avg loss: 1.2676517295837402\n",
      "trial: 1, iter: 7400, curr loss: 1.2695826292037964, avg loss: 1.2659098607301713\n",
      "trial: 1, iter: 7600, curr loss: 1.2155905961990356, avg loss: 1.26611993432045\n",
      "trial: 1, iter: 7800, curr loss: 1.2838659286499023, avg loss: 1.2681139343976975\n",
      "trial: 1, iter: 8000, curr loss: 1.2909495830535889, avg loss: 1.26268243432045\n",
      "trial: 1, iter: 8200, curr loss: 1.2524373531341553, avg loss: 1.2665082812309265\n",
      "trial: 1, iter: 8400, curr loss: 1.2091741561889648, avg loss: 1.2631173706054688\n",
      "trial: 1, iter: 8600, curr loss: 1.2805640697479248, avg loss: 1.2641913145780563\n",
      "trial: 1, iter: 8800, curr loss: 1.247762680053711, avg loss: 1.2669141352176667\n",
      "trial: 1, iter: 9000, curr loss: 1.2726458311080933, avg loss: 1.2644618940353394\n",
      "trial: 1, iter: 9200, curr loss: 1.2389016151428223, avg loss: 1.2651794427633285\n",
      "trial: 1, iter: 9400, curr loss: 1.2826334238052368, avg loss: 1.2620365530252458\n",
      "trial: 1, iter: 9600, curr loss: 1.2923163175582886, avg loss: 1.2596997565031052\n",
      "trial: 1, iter: 9800, curr loss: 1.3307815790176392, avg loss: 1.2651030719280243\n",
      "trial: 1, iter: 10000, curr loss: 1.2511847019195557, avg loss: 1.264849054813385\n",
      "trial: 1, iter: 10200, curr loss: 1.2769849300384521, avg loss: 1.2637110298871994\n",
      "trial: 1, iter: 10400, curr loss: 1.2416455745697021, avg loss: 1.266539715528488\n",
      "trial: 1, iter: 10600, curr loss: 1.2367955446243286, avg loss: 1.2633873736858368\n",
      "trial: 1, iter: 10800, curr loss: 1.3122918605804443, avg loss: 1.2655303609371185\n",
      "trial: 1, iter: 11000, curr loss: 1.2666051387786865, avg loss: 1.2651569849252702\n",
      "trial: 1, iter: 11200, curr loss: 1.247463583946228, avg loss: 1.2628758066892625\n",
      "trial: 1, iter: 11400, curr loss: 1.2922908067703247, avg loss: 1.2635763078927993\n",
      "trial: 1, iter: 11600, curr loss: 1.2839020490646362, avg loss: 1.2632762801647186\n",
      "trial: 1, iter: 11800, curr loss: 1.2723884582519531, avg loss: 1.2633976131677627\n",
      "trial: 1, iter: 12000, curr loss: 1.3051575422286987, avg loss: 1.265278097987175\n",
      "trial: 1, iter: 12200, curr loss: 1.266131043434143, avg loss: 1.2643350321054458\n",
      "trial: 1, iter: 12400, curr loss: 1.284009337425232, avg loss: 1.264786588549614\n",
      "trial: 1, iter: 12600, curr loss: 1.3002033233642578, avg loss: 1.2649532729387283\n",
      "trial: 1, iter: 12800, curr loss: 1.2741944789886475, avg loss: 1.2653404241800308\n",
      "trial: 1, iter: 13000, curr loss: 1.278532862663269, avg loss: 1.2624490940570832\n",
      "trial: 1, iter: 13200, curr loss: 1.2216931581497192, avg loss: 1.2622853934764862\n",
      "trial: 1, iter: 13400, curr loss: 1.21808660030365, avg loss: 1.262625615000725\n",
      "trial: 1, iter: 13600, curr loss: 1.261985182762146, avg loss: 1.2616883021593095\n",
      "trial: 1, iter: 13800, curr loss: 1.3003171682357788, avg loss: 1.2629235869646072\n",
      "trial: 1, iter: 14000, curr loss: 1.26388418674469, avg loss: 1.2627394592761993\n",
      "trial: 1, iter: 14200, curr loss: 1.3190834522247314, avg loss: 1.2620164155960083\n",
      "trial: 1, iter: 14400, curr loss: 1.2096753120422363, avg loss: 1.2596195060014725\n",
      "trial: 1, iter: 14600, curr loss: 1.264084815979004, avg loss: 1.261828569173813\n",
      "trial: 1, iter: 14800, curr loss: 1.257732629776001, avg loss: 1.2610842341184616\n",
      "trial: 1, iter: 15000, curr loss: 1.2130115032196045, avg loss: 1.2634660041332244\n",
      "trial: 1, iter: 15200, curr loss: 1.260080337524414, avg loss: 1.2620680421590804\n",
      "trial: 1, iter: 15400, curr loss: 1.2185547351837158, avg loss: 1.2626906269788742\n",
      "trial: 1, iter: 15600, curr loss: 1.2641432285308838, avg loss: 1.2639407688379287\n",
      "trial: 1, ldr: 0.27183061838150024\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3871718645095825, avg loss: 1.3867077577114104\n",
      "trial: 2, iter: 400, curr loss: 1.3775560855865479, avg loss: 1.381130383014679\n",
      "trial: 2, iter: 600, curr loss: 1.358245611190796, avg loss: 1.3429299795627594\n",
      "trial: 2, iter: 800, curr loss: 1.3324320316314697, avg loss: 1.3201096498966216\n",
      "trial: 2, iter: 1000, curr loss: 1.3130545616149902, avg loss: 1.3125952756404877\n",
      "trial: 2, iter: 1200, curr loss: 1.310900092124939, avg loss: 1.3083706068992615\n",
      "trial: 2, iter: 1400, curr loss: 1.3036465644836426, avg loss: 1.3021429646015168\n",
      "trial: 2, iter: 1600, curr loss: 1.2387758493423462, avg loss: 1.2971062326431275\n",
      "trial: 2, iter: 1800, curr loss: 1.3031089305877686, avg loss: 1.2913738292455674\n",
      "trial: 2, iter: 2000, curr loss: 1.330053448677063, avg loss: 1.2861518383026123\n",
      "trial: 2, iter: 2200, curr loss: 1.2252116203308105, avg loss: 1.2779855221509933\n",
      "trial: 2, iter: 2400, curr loss: 1.2808173894882202, avg loss: 1.2769959765672683\n",
      "trial: 2, iter: 2600, curr loss: 1.267673134803772, avg loss: 1.2718839317560195\n",
      "trial: 2, iter: 2800, curr loss: 1.2719902992248535, avg loss: 1.2719115275144577\n",
      "trial: 2, iter: 3000, curr loss: 1.2856172323226929, avg loss: 1.2682901459932328\n",
      "trial: 2, iter: 3200, curr loss: 1.2620153427124023, avg loss: 1.2731072223186493\n",
      "trial: 2, iter: 3400, curr loss: 1.2923706769943237, avg loss: 1.2688178324699402\n",
      "trial: 2, iter: 3600, curr loss: 1.244737148284912, avg loss: 1.2696257680654526\n",
      "trial: 2, iter: 3800, curr loss: 1.2613341808319092, avg loss: 1.2686756175756455\n",
      "trial: 2, iter: 4000, curr loss: 1.2816250324249268, avg loss: 1.2680372285842896\n",
      "trial: 2, iter: 4200, curr loss: 1.2725276947021484, avg loss: 1.2661015337705612\n",
      "trial: 2, iter: 4400, curr loss: 1.2710975408554077, avg loss: 1.2685871464014054\n",
      "trial: 2, iter: 4600, curr loss: 1.2925629615783691, avg loss: 1.2649457567930222\n",
      "trial: 2, iter: 4800, curr loss: 1.2693544626235962, avg loss: 1.2638164925575257\n",
      "trial: 2, iter: 5000, curr loss: 1.256269931793213, avg loss: 1.2646338963508605\n",
      "trial: 2, iter: 5200, curr loss: 1.2809224128723145, avg loss: 1.2664572125673295\n",
      "trial: 2, iter: 5400, curr loss: 1.2410842180252075, avg loss: 1.2646967142820358\n",
      "trial: 2, iter: 5600, curr loss: 1.2586641311645508, avg loss: 1.263406396508217\n",
      "trial: 2, iter: 5800, curr loss: 1.284110426902771, avg loss: 1.2653610068559646\n",
      "trial: 2, iter: 6000, curr loss: 1.2971243858337402, avg loss: 1.269130405187607\n",
      "trial: 2, iter: 6200, curr loss: 1.2633968591690063, avg loss: 1.2645793271064758\n",
      "trial: 2, iter: 6400, curr loss: 1.2392568588256836, avg loss: 1.264070652127266\n",
      "trial: 2, iter: 6600, curr loss: 1.3200660943984985, avg loss: 1.2649767863750458\n",
      "trial: 2, iter: 6800, curr loss: 1.2300769090652466, avg loss: 1.2646007239818573\n",
      "trial: 2, iter: 7000, curr loss: 1.2317910194396973, avg loss: 1.2644491177797317\n",
      "trial: 2, iter: 7200, curr loss: 1.2689756155014038, avg loss: 1.262811798453331\n",
      "trial: 2, iter: 7400, curr loss: 1.2833521366119385, avg loss: 1.2617915308475494\n",
      "trial: 2, iter: 7600, curr loss: 1.2503124475479126, avg loss: 1.2605565559864045\n",
      "trial: 2, iter: 7800, curr loss: 1.2614203691482544, avg loss: 1.2626617795228958\n",
      "trial: 2, iter: 8000, curr loss: 1.2438485622406006, avg loss: 1.2606242269277572\n",
      "trial: 2, iter: 8200, curr loss: 1.2846298217773438, avg loss: 1.2646076595783233\n",
      "trial: 2, iter: 8400, curr loss: 1.2577108144760132, avg loss: 1.2660214763879776\n",
      "trial: 2, iter: 8600, curr loss: 1.2098087072372437, avg loss: 1.2683097314834595\n",
      "trial: 2, iter: 8800, curr loss: 1.2954707145690918, avg loss: 1.2627793151140212\n",
      "trial: 2, iter: 9000, curr loss: 1.208742380142212, avg loss: 1.2650714200735091\n",
      "trial: 2, iter: 9200, curr loss: 1.2825921773910522, avg loss: 1.2664263278245926\n",
      "trial: 2, iter: 9400, curr loss: 1.2868181467056274, avg loss: 1.2655153894424438\n",
      "trial: 2, iter: 9600, curr loss: 1.2704869508743286, avg loss: 1.2608477467298507\n",
      "trial: 2, iter: 9800, curr loss: 1.2979121208190918, avg loss: 1.264408523440361\n",
      "trial: 2, iter: 10000, curr loss: 1.261474609375, avg loss: 1.2605695056915283\n",
      "trial: 2, iter: 10200, curr loss: 1.2413192987442017, avg loss: 1.2601396042108535\n",
      "trial: 2, iter: 10400, curr loss: 1.25912344455719, avg loss: 1.2689902400970459\n",
      "trial: 2, iter: 10600, curr loss: 1.2936075925827026, avg loss: 1.264152037501335\n",
      "trial: 2, iter: 10800, curr loss: 1.245214581489563, avg loss: 1.2627720409631729\n",
      "trial: 2, iter: 11000, curr loss: 1.2496227025985718, avg loss: 1.2622289282083512\n",
      "trial: 2, iter: 11200, curr loss: 1.2875144481658936, avg loss: 1.2662112879753114\n",
      "trial: 2, iter: 11400, curr loss: 1.2460435628890991, avg loss: 1.2654494065046311\n",
      "trial: 2, iter: 11600, curr loss: 1.257280945777893, avg loss: 1.2632371562719344\n",
      "trial: 2, iter: 11800, curr loss: 1.3092812299728394, avg loss: 1.260884668827057\n",
      "trial: 2, iter: 12000, curr loss: 1.280717134475708, avg loss: 1.261862666606903\n",
      "trial: 2, iter: 12200, curr loss: 1.2944263219833374, avg loss: 1.2659663718938827\n",
      "trial: 2, iter: 12400, curr loss: 1.2956039905548096, avg loss: 1.2600282138586045\n",
      "trial: 2, iter: 12600, curr loss: 1.2691535949707031, avg loss: 1.2615142005681992\n",
      "trial: 2, iter: 12800, curr loss: 1.2685861587524414, avg loss: 1.2633183377981185\n",
      "trial: 2, iter: 13000, curr loss: 1.2523688077926636, avg loss: 1.261512433886528\n",
      "trial: 2, iter: 13200, curr loss: 1.243011713027954, avg loss: 1.261890971660614\n",
      "trial: 2, iter: 13400, curr loss: 1.2303546667099, avg loss: 1.2606626975536346\n",
      "trial: 2, iter: 13600, curr loss: 1.2785210609436035, avg loss: 1.26073523581028\n",
      "trial: 2, iter: 13800, curr loss: 1.2274740934371948, avg loss: 1.2614225631952285\n",
      "trial: 2, iter: 14000, curr loss: 1.2879306077957153, avg loss: 1.2631506252288818\n",
      "trial: 2, iter: 14200, curr loss: 1.2818793058395386, avg loss: 1.2633542889356613\n",
      "trial: 2, iter: 14400, curr loss: 1.2557883262634277, avg loss: 1.2667459350824357\n",
      "trial: 2, iter: 14600, curr loss: 1.281231164932251, avg loss: 1.2600611054897308\n",
      "trial: 2, iter: 14800, curr loss: 1.2218222618103027, avg loss: 1.263577554821968\n",
      "trial: 2, iter: 15000, curr loss: 1.2367823123931885, avg loss: 1.2613034003973007\n",
      "trial: 2, iter: 15200, curr loss: 1.2291150093078613, avg loss: 1.2642705303430557\n",
      "trial: 2, iter: 15400, curr loss: 1.2488842010498047, avg loss: 1.259540992975235\n",
      "trial: 2, iter: 15600, curr loss: 1.254892349243164, avg loss: 1.2605213350057602\n",
      "trial: 2, ldr: 0.3382686376571655\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3895013332366943, avg loss: 1.3871773159503937\n",
      "trial: 3, iter: 400, curr loss: 1.3802552223205566, avg loss: 1.3855545485019685\n",
      "trial: 3, iter: 600, curr loss: 1.3435096740722656, avg loss: 1.3651069205999375\n",
      "trial: 3, iter: 800, curr loss: 1.3305069208145142, avg loss: 1.328557716012001\n",
      "trial: 3, iter: 1000, curr loss: 1.3147739171981812, avg loss: 1.32073572576046\n",
      "trial: 3, iter: 1200, curr loss: 1.2938497066497803, avg loss: 1.3103606218099595\n",
      "trial: 3, iter: 1400, curr loss: 1.3095898628234863, avg loss: 1.3066127836704253\n",
      "trial: 3, iter: 1600, curr loss: 1.3020657300949097, avg loss: 1.3001200652122498\n",
      "trial: 3, iter: 1800, curr loss: 1.3079338073730469, avg loss: 1.2933469742536545\n",
      "trial: 3, iter: 2000, curr loss: 1.252111792564392, avg loss: 1.2857964032888411\n",
      "trial: 3, iter: 2200, curr loss: 1.2715377807617188, avg loss: 1.2781059515476227\n",
      "trial: 3, iter: 2400, curr loss: 1.2730909585952759, avg loss: 1.2743091422319412\n",
      "trial: 3, iter: 2600, curr loss: 1.2669440507888794, avg loss: 1.272489659190178\n",
      "trial: 3, iter: 2800, curr loss: 1.271002173423767, avg loss: 1.272557146549225\n",
      "trial: 3, iter: 3000, curr loss: 1.275615930557251, avg loss: 1.2675651317834855\n",
      "trial: 3, iter: 3200, curr loss: 1.2555627822875977, avg loss: 1.270194900035858\n",
      "trial: 3, iter: 3400, curr loss: 1.287422776222229, avg loss: 1.2708910846710204\n",
      "trial: 3, iter: 3600, curr loss: 1.241280436515808, avg loss: 1.2711264890432359\n",
      "trial: 3, iter: 3800, curr loss: 1.2645336389541626, avg loss: 1.2710018455982208\n",
      "trial: 3, iter: 4000, curr loss: 1.2628368139266968, avg loss: 1.2661014980077743\n",
      "trial: 3, iter: 4200, curr loss: 1.317040205001831, avg loss: 1.2705074125528335\n",
      "trial: 3, iter: 4400, curr loss: 1.2372188568115234, avg loss: 1.2671566700935364\n",
      "trial: 3, iter: 4600, curr loss: 1.2751822471618652, avg loss: 1.2689423644542694\n",
      "trial: 3, iter: 4800, curr loss: 1.2482738494873047, avg loss: 1.2631554311513902\n",
      "trial: 3, iter: 5000, curr loss: 1.2923556566238403, avg loss: 1.2667597913742066\n",
      "trial: 3, iter: 5200, curr loss: 1.3135954141616821, avg loss: 1.267206866145134\n",
      "trial: 3, iter: 5400, curr loss: 1.3026788234710693, avg loss: 1.2645684772729873\n",
      "trial: 3, iter: 5600, curr loss: 1.3181926012039185, avg loss: 1.2616151851415633\n",
      "trial: 3, iter: 5800, curr loss: 1.2555797100067139, avg loss: 1.2663903111219406\n",
      "trial: 3, iter: 6000, curr loss: 1.267329216003418, avg loss: 1.2682933831214904\n",
      "trial: 3, iter: 6200, curr loss: 1.2579470872879028, avg loss: 1.2692347538471223\n",
      "trial: 3, iter: 6400, curr loss: 1.2571274042129517, avg loss: 1.2630501669645309\n",
      "trial: 3, iter: 6600, curr loss: 1.2760215997695923, avg loss: 1.2683494484424591\n",
      "trial: 3, iter: 6800, curr loss: 1.245822548866272, avg loss: 1.2632900816202164\n",
      "trial: 3, iter: 7000, curr loss: 1.2484742403030396, avg loss: 1.2656749814748764\n",
      "trial: 3, iter: 7200, curr loss: 1.237504005432129, avg loss: 1.2610019534826278\n",
      "trial: 3, iter: 7400, curr loss: 1.26992666721344, avg loss: 1.2658726489543914\n",
      "trial: 3, iter: 7600, curr loss: 1.2660473585128784, avg loss: 1.2625207966566085\n",
      "trial: 3, iter: 7800, curr loss: 1.3326289653778076, avg loss: 1.2672634375095368\n",
      "trial: 3, iter: 8000, curr loss: 1.232277512550354, avg loss: 1.2630066603422165\n",
      "trial: 3, iter: 8200, curr loss: 1.2432633638381958, avg loss: 1.2630474776029588\n",
      "trial: 3, iter: 8400, curr loss: 1.3215711116790771, avg loss: 1.2677681040763855\n",
      "trial: 3, iter: 8600, curr loss: 1.2921265363693237, avg loss: 1.2646349501609802\n",
      "trial: 3, iter: 8800, curr loss: 1.2528444528579712, avg loss: 1.265203070640564\n",
      "trial: 3, iter: 9000, curr loss: 1.2560101747512817, avg loss: 1.2654811501502992\n",
      "trial: 3, iter: 9200, curr loss: 1.261622667312622, avg loss: 1.2613123881816863\n",
      "trial: 3, iter: 9400, curr loss: 1.2175110578536987, avg loss: 1.2613079839944839\n",
      "trial: 3, iter: 9600, curr loss: 1.2620856761932373, avg loss: 1.2638774758577347\n",
      "trial: 3, iter: 9800, curr loss: 1.243331789970398, avg loss: 1.2624577730894089\n",
      "trial: 3, iter: 10000, curr loss: 1.2134425640106201, avg loss: 1.2626519203186035\n",
      "trial: 3, iter: 10200, curr loss: 1.2639615535736084, avg loss: 1.2628184992074967\n",
      "trial: 3, iter: 10400, curr loss: 1.2389822006225586, avg loss: 1.2637491446733475\n",
      "trial: 3, iter: 10600, curr loss: 1.2502597570419312, avg loss: 1.2616819530725478\n",
      "trial: 3, iter: 10800, curr loss: 1.318079948425293, avg loss: 1.2644999527931213\n",
      "trial: 3, iter: 11000, curr loss: 1.238434910774231, avg loss: 1.2624285465478897\n",
      "trial: 3, iter: 11200, curr loss: 1.2513116598129272, avg loss: 1.2650709092617034\n",
      "trial: 3, iter: 11400, curr loss: 1.2668009996414185, avg loss: 1.2646583396196365\n",
      "trial: 3, iter: 11600, curr loss: 1.2858824729919434, avg loss: 1.2584589701890945\n",
      "trial: 3, iter: 11800, curr loss: 1.2881931066513062, avg loss: 1.2634494763612747\n",
      "trial: 3, iter: 12000, curr loss: 1.3336840867996216, avg loss: 1.2651516091823578\n",
      "trial: 3, iter: 12200, curr loss: 1.241163730621338, avg loss: 1.264526298046112\n",
      "trial: 3, iter: 12400, curr loss: 1.2818512916564941, avg loss: 1.2640959548950195\n",
      "trial: 3, iter: 12600, curr loss: 1.291200041770935, avg loss: 1.2625079905986787\n",
      "trial: 3, iter: 12800, curr loss: 1.2649554014205933, avg loss: 1.2649831175804138\n",
      "trial: 3, iter: 13000, curr loss: 1.2695014476776123, avg loss: 1.2658399122953414\n",
      "trial: 3, iter: 13200, curr loss: 1.2689521312713623, avg loss: 1.267443032860756\n",
      "trial: 3, iter: 13400, curr loss: 1.2201354503631592, avg loss: 1.2639689087867736\n",
      "trial: 3, iter: 13600, curr loss: 1.2671676874160767, avg loss: 1.2605931293964385\n",
      "trial: 3, iter: 13800, curr loss: 1.2754524946212769, avg loss: 1.2625759607553482\n",
      "trial: 3, iter: 14000, curr loss: 1.2752772569656372, avg loss: 1.2604276871681213\n",
      "trial: 3, iter: 14200, curr loss: 1.281432032585144, avg loss: 1.2617013865709306\n",
      "trial: 3, iter: 14400, curr loss: 1.2248575687408447, avg loss: 1.2641118985414506\n",
      "trial: 3, iter: 14600, curr loss: 1.3108471632003784, avg loss: 1.2630928474664689\n",
      "trial: 3, iter: 14800, curr loss: 1.2635442018508911, avg loss: 1.262062185406685\n",
      "trial: 3, iter: 15000, curr loss: 1.2999869585037231, avg loss: 1.2604212409257889\n",
      "trial: 3, iter: 15200, curr loss: 1.2769908905029297, avg loss: 1.2626412951946258\n",
      "trial: 3, iter: 15400, curr loss: 1.2474969625473022, avg loss: 1.2631469655036927\n",
      "trial: 3, iter: 15600, curr loss: 1.2671291828155518, avg loss: 1.263517554998398\n",
      "trial: 3, ldr: 0.2450421154499054\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3833054304122925, avg loss: 1.3869775182008743\n",
      "trial: 4, iter: 400, curr loss: 1.371921420097351, avg loss: 1.3810177171230316\n",
      "trial: 4, iter: 600, curr loss: 1.3348283767700195, avg loss: 1.3409832835197448\n",
      "trial: 4, iter: 800, curr loss: 1.3032647371292114, avg loss: 1.3200009697675705\n",
      "trial: 4, iter: 1000, curr loss: 1.3033455610275269, avg loss: 1.310904352068901\n",
      "trial: 4, iter: 1200, curr loss: 1.2855615615844727, avg loss: 1.3036012345552443\n",
      "trial: 4, iter: 1400, curr loss: 1.2835127115249634, avg loss: 1.2967925196886063\n",
      "trial: 4, iter: 1600, curr loss: 1.2845698595046997, avg loss: 1.2895510494709015\n",
      "trial: 4, iter: 1800, curr loss: 1.273659586906433, avg loss: 1.2810398948192596\n",
      "trial: 4, iter: 2000, curr loss: 1.2934138774871826, avg loss: 1.2790410274267197\n",
      "trial: 4, iter: 2200, curr loss: 1.302717924118042, avg loss: 1.2740781664848329\n",
      "trial: 4, iter: 2400, curr loss: 1.3080174922943115, avg loss: 1.2723928099870683\n",
      "trial: 4, iter: 2600, curr loss: 1.274256944656372, avg loss: 1.2703882229328156\n",
      "trial: 4, iter: 2800, curr loss: 1.2793793678283691, avg loss: 1.2724101269245147\n",
      "trial: 4, iter: 3000, curr loss: 1.2656681537628174, avg loss: 1.2704161781072616\n",
      "trial: 4, iter: 3200, curr loss: 1.2774455547332764, avg loss: 1.2732682359218597\n",
      "trial: 4, iter: 3400, curr loss: 1.276132345199585, avg loss: 1.2698175710439683\n",
      "trial: 4, iter: 3600, curr loss: 1.248165488243103, avg loss: 1.2685730570554734\n",
      "trial: 4, iter: 3800, curr loss: 1.3022935390472412, avg loss: 1.2693539506196976\n",
      "trial: 4, iter: 4000, curr loss: 1.2821351289749146, avg loss: 1.266930883526802\n",
      "trial: 4, iter: 4200, curr loss: 1.2243292331695557, avg loss: 1.266123748421669\n",
      "trial: 4, iter: 4400, curr loss: 1.270100474357605, avg loss: 1.2673946887254715\n",
      "trial: 4, iter: 4600, curr loss: 1.2919995784759521, avg loss: 1.2690804010629655\n",
      "trial: 4, iter: 4800, curr loss: 1.3233917951583862, avg loss: 1.2658963918685913\n",
      "trial: 4, iter: 5000, curr loss: 1.2408816814422607, avg loss: 1.2636843174695969\n",
      "trial: 4, iter: 5200, curr loss: 1.2378638982772827, avg loss: 1.2668195849657058\n",
      "trial: 4, iter: 5400, curr loss: 1.3042924404144287, avg loss: 1.2662688237428665\n",
      "trial: 4, iter: 5600, curr loss: 1.2427457571029663, avg loss: 1.2654758775234223\n",
      "trial: 4, iter: 5800, curr loss: 1.303508996963501, avg loss: 1.265092470049858\n",
      "trial: 4, iter: 6000, curr loss: 1.2606894969940186, avg loss: 1.2627585196495057\n",
      "trial: 4, iter: 6200, curr loss: 1.2921570539474487, avg loss: 1.2678144842386245\n",
      "trial: 4, iter: 6400, curr loss: 1.2817846536636353, avg loss: 1.267590109705925\n",
      "trial: 4, iter: 6600, curr loss: 1.2221112251281738, avg loss: 1.2663518208265305\n",
      "trial: 4, iter: 6800, curr loss: 1.2840667963027954, avg loss: 1.2671989953517915\n",
      "trial: 4, iter: 7000, curr loss: 1.2631604671478271, avg loss: 1.2651514506340027\n",
      "trial: 4, iter: 7200, curr loss: 1.2268882989883423, avg loss: 1.2649807864427567\n",
      "trial: 4, iter: 7400, curr loss: 1.268153190612793, avg loss: 1.2645250713825227\n",
      "trial: 4, iter: 7600, curr loss: 1.2337074279785156, avg loss: 1.2637556320428849\n",
      "trial: 4, iter: 7800, curr loss: 1.2885892391204834, avg loss: 1.2656477361917495\n",
      "trial: 4, iter: 8000, curr loss: 1.262444257736206, avg loss: 1.262886153459549\n",
      "trial: 4, iter: 8200, curr loss: 1.2195502519607544, avg loss: 1.2638538420200347\n",
      "trial: 4, iter: 8400, curr loss: 1.3316102027893066, avg loss: 1.2609688544273376\n",
      "trial: 4, iter: 8600, curr loss: 1.275194764137268, avg loss: 1.2617702037096024\n",
      "trial: 4, iter: 8800, curr loss: 1.3043994903564453, avg loss: 1.2629452383518218\n",
      "trial: 4, iter: 9000, curr loss: 1.2667691707611084, avg loss: 1.2663813716173171\n",
      "trial: 4, iter: 9200, curr loss: 1.254752278327942, avg loss: 1.262634003162384\n",
      "trial: 4, iter: 9400, curr loss: 1.2409186363220215, avg loss: 1.2662948828935623\n",
      "trial: 4, iter: 9600, curr loss: 1.2442710399627686, avg loss: 1.262893762588501\n",
      "trial: 4, iter: 9800, curr loss: 1.2653414011001587, avg loss: 1.262191635966301\n",
      "trial: 4, iter: 10000, curr loss: 1.2567023038864136, avg loss: 1.2641554653644562\n",
      "trial: 4, iter: 10200, curr loss: 1.2625560760498047, avg loss: 1.2653724187612534\n",
      "trial: 4, iter: 10400, curr loss: 1.2818641662597656, avg loss: 1.263225758075714\n",
      "trial: 4, iter: 10600, curr loss: 1.2755926847457886, avg loss: 1.2627106428146362\n",
      "trial: 4, iter: 10800, curr loss: 1.251013994216919, avg loss: 1.2620710015296936\n",
      "trial: 4, iter: 11000, curr loss: 1.2356990575790405, avg loss: 1.2646830010414123\n",
      "trial: 4, iter: 11200, curr loss: 1.3048324584960938, avg loss: 1.2645170110464097\n",
      "trial: 4, iter: 11400, curr loss: 1.2037943601608276, avg loss: 1.2637367171049119\n",
      "trial: 4, iter: 11600, curr loss: 1.2337839603424072, avg loss: 1.2634813117980956\n",
      "trial: 4, iter: 11800, curr loss: 1.2640372514724731, avg loss: 1.261573502421379\n",
      "trial: 4, iter: 12000, curr loss: 1.2390295267105103, avg loss: 1.2617758673429489\n",
      "trial: 4, iter: 12200, curr loss: 1.252132773399353, avg loss: 1.2621257323026658\n",
      "trial: 4, iter: 12400, curr loss: 1.2736940383911133, avg loss: 1.259280623793602\n",
      "trial: 4, iter: 12600, curr loss: 1.2397199869155884, avg loss: 1.2623688513040543\n",
      "trial: 4, iter: 12800, curr loss: 1.2239737510681152, avg loss: 1.2606447702646255\n",
      "trial: 4, iter: 13000, curr loss: 1.236378788948059, avg loss: 1.263269640803337\n",
      "trial: 4, iter: 13200, curr loss: 1.2499103546142578, avg loss: 1.262310989499092\n",
      "trial: 4, iter: 13400, curr loss: 1.2253828048706055, avg loss: 1.2615491223335267\n",
      "trial: 4, iter: 13600, curr loss: 1.2890002727508545, avg loss: 1.2624184584617615\n",
      "trial: 4, iter: 13800, curr loss: 1.2712604999542236, avg loss: 1.2624683499336242\n",
      "trial: 4, iter: 14000, curr loss: 1.244231104850769, avg loss: 1.2603798997402191\n",
      "trial: 4, iter: 14200, curr loss: 1.2734202146530151, avg loss: 1.2656536400318146\n",
      "trial: 4, iter: 14400, curr loss: 1.2760508060455322, avg loss: 1.2640072137117386\n",
      "trial: 4, iter: 14600, curr loss: 1.2692099809646606, avg loss: 1.2618478441238403\n",
      "trial: 4, iter: 14800, curr loss: 1.2182482481002808, avg loss: 1.2614042073488236\n",
      "trial: 4, iter: 15000, curr loss: 1.2799689769744873, avg loss: 1.2640254700183868\n",
      "trial: 4, iter: 15200, curr loss: 1.3187443017959595, avg loss: 1.262301223874092\n",
      "trial: 4, iter: 15400, curr loss: 1.2661683559417725, avg loss: 1.258650091290474\n",
      "trial: 4, iter: 15600, curr loss: 1.3437895774841309, avg loss: 1.263792930841446\n",
      "trial: 4, ldr: 0.21733810007572174\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3835108280181885, avg loss: 1.3871495312452315\n",
      "trial: 5, iter: 400, curr loss: 1.371669054031372, avg loss: 1.38016892015934\n",
      "trial: 5, iter: 600, curr loss: 1.3187741041183472, avg loss: 1.342285577058792\n",
      "trial: 5, iter: 800, curr loss: 1.3214040994644165, avg loss: 1.3214421385526658\n",
      "trial: 5, iter: 1000, curr loss: 1.3298068046569824, avg loss: 1.3139789998531342\n",
      "trial: 5, iter: 1200, curr loss: 1.339322566986084, avg loss: 1.304703739285469\n",
      "trial: 5, iter: 1400, curr loss: 1.273986577987671, avg loss: 1.2990062350034715\n",
      "trial: 5, iter: 1600, curr loss: 1.291730284690857, avg loss: 1.2925065356492995\n",
      "trial: 5, iter: 1800, curr loss: 1.2751880884170532, avg loss: 1.284903699159622\n",
      "trial: 5, iter: 2000, curr loss: 1.309436559677124, avg loss: 1.2758290868997575\n",
      "trial: 5, iter: 2200, curr loss: 1.2755494117736816, avg loss: 1.276488071680069\n",
      "trial: 5, iter: 2400, curr loss: 1.3013789653778076, avg loss: 1.2724129980802537\n",
      "trial: 5, iter: 2600, curr loss: 1.2440541982650757, avg loss: 1.2710143357515336\n",
      "trial: 5, iter: 2800, curr loss: 1.2341456413269043, avg loss: 1.2679682224988937\n",
      "trial: 5, iter: 3000, curr loss: 1.287305474281311, avg loss: 1.2699904400110245\n",
      "trial: 5, iter: 3200, curr loss: 1.3038337230682373, avg loss: 1.2678118121623994\n",
      "trial: 5, iter: 3400, curr loss: 1.2623413801193237, avg loss: 1.264224106669426\n",
      "trial: 5, iter: 3600, curr loss: 1.2739678621292114, avg loss: 1.26777741253376\n",
      "trial: 5, iter: 3800, curr loss: 1.3265587091445923, avg loss: 1.2665762293338776\n",
      "trial: 5, iter: 4000, curr loss: 1.2777986526489258, avg loss: 1.269919227361679\n",
      "trial: 5, iter: 4200, curr loss: 1.2067292928695679, avg loss: 1.2657918953895568\n",
      "trial: 5, iter: 4400, curr loss: 1.2273222208023071, avg loss: 1.2686595487594605\n",
      "trial: 5, iter: 4600, curr loss: 1.2795552015304565, avg loss: 1.2673866146802901\n",
      "trial: 5, iter: 4800, curr loss: 1.2777998447418213, avg loss: 1.2643985915184022\n",
      "trial: 5, iter: 5000, curr loss: 1.2488465309143066, avg loss: 1.2679226738214493\n",
      "trial: 5, iter: 5200, curr loss: 1.3242884874343872, avg loss: 1.2661651712656021\n",
      "trial: 5, iter: 5400, curr loss: 1.2897024154663086, avg loss: 1.267474141716957\n",
      "trial: 5, iter: 5600, curr loss: 1.2279363870620728, avg loss: 1.2623354691267012\n",
      "trial: 5, iter: 5800, curr loss: 1.2567498683929443, avg loss: 1.2657460570335388\n",
      "trial: 5, iter: 6000, curr loss: 1.2690563201904297, avg loss: 1.2657142901420593\n",
      "trial: 5, iter: 6200, curr loss: 1.2832821607589722, avg loss: 1.2668926745653153\n",
      "trial: 5, iter: 6400, curr loss: 1.2797189950942993, avg loss: 1.2640652757883073\n",
      "trial: 5, iter: 6600, curr loss: 1.2443065643310547, avg loss: 1.2631288784742356\n",
      "trial: 5, iter: 6800, curr loss: 1.2194113731384277, avg loss: 1.2642118167877197\n",
      "trial: 5, iter: 7000, curr loss: 1.275990605354309, avg loss: 1.2656127250194549\n",
      "trial: 5, iter: 7200, curr loss: 1.2602972984313965, avg loss: 1.2631557166576386\n",
      "trial: 5, iter: 7400, curr loss: 1.2714365720748901, avg loss: 1.2661385887861252\n",
      "trial: 5, iter: 7600, curr loss: 1.284869909286499, avg loss: 1.2646906977891923\n",
      "trial: 5, iter: 7800, curr loss: 1.2655706405639648, avg loss: 1.265919172167778\n",
      "trial: 5, iter: 8000, curr loss: 1.2439639568328857, avg loss: 1.2666458636522293\n",
      "trial: 5, iter: 8200, curr loss: 1.3053433895111084, avg loss: 1.2631799203157426\n",
      "trial: 5, iter: 8400, curr loss: 1.2818609476089478, avg loss: 1.2672787630558013\n",
      "trial: 5, iter: 8600, curr loss: 1.250410556793213, avg loss: 1.2624136847257614\n",
      "trial: 5, iter: 8800, curr loss: 1.2300183773040771, avg loss: 1.2629001933336257\n",
      "trial: 5, iter: 9000, curr loss: 1.285751461982727, avg loss: 1.262079421877861\n",
      "trial: 5, iter: 9200, curr loss: 1.2465057373046875, avg loss: 1.2617804217338562\n",
      "trial: 5, iter: 9400, curr loss: 1.2655433416366577, avg loss: 1.2645382034778594\n",
      "trial: 5, iter: 9600, curr loss: 1.3193082809448242, avg loss: 1.2616199892759323\n",
      "trial: 5, iter: 9800, curr loss: 1.262920618057251, avg loss: 1.2621108651161195\n",
      "trial: 5, iter: 10000, curr loss: 1.2476834058761597, avg loss: 1.266150995492935\n",
      "trial: 5, iter: 10200, curr loss: 1.3116357326507568, avg loss: 1.2626910918951035\n",
      "trial: 5, iter: 10400, curr loss: 1.2968220710754395, avg loss: 1.2625471585988999\n",
      "trial: 5, iter: 10600, curr loss: 1.2639334201812744, avg loss: 1.2638939720392228\n",
      "trial: 5, iter: 10800, curr loss: 1.2482311725616455, avg loss: 1.2616277760267258\n",
      "trial: 5, iter: 11000, curr loss: 1.2614933252334595, avg loss: 1.2635049259662627\n",
      "trial: 5, iter: 11200, curr loss: 1.2907289266586304, avg loss: 1.2685392373800277\n",
      "trial: 5, iter: 11400, curr loss: 1.2744183540344238, avg loss: 1.2616385859251023\n",
      "trial: 5, iter: 11600, curr loss: 1.273074746131897, avg loss: 1.2630589205026626\n",
      "trial: 5, iter: 11800, curr loss: 1.2437602281570435, avg loss: 1.2639709895849227\n",
      "trial: 5, iter: 12000, curr loss: 1.2802534103393555, avg loss: 1.2631099140644073\n",
      "trial: 5, iter: 12200, curr loss: 1.2198724746704102, avg loss: 1.2636157888174058\n",
      "trial: 5, iter: 12400, curr loss: 1.2608935832977295, avg loss: 1.260081850886345\n",
      "trial: 5, iter: 12600, curr loss: 1.2796883583068848, avg loss: 1.263712795972824\n",
      "trial: 5, iter: 12800, curr loss: 1.2384990453720093, avg loss: 1.2630466157197953\n",
      "trial: 5, iter: 13000, curr loss: 1.2742880582809448, avg loss: 1.2619439536333084\n",
      "trial: 5, iter: 13200, curr loss: 1.2659623622894287, avg loss: 1.2628677409887314\n",
      "trial: 5, iter: 13400, curr loss: 1.2738851308822632, avg loss: 1.2633114659786224\n",
      "trial: 5, iter: 13600, curr loss: 1.287266731262207, avg loss: 1.261889134645462\n",
      "trial: 5, iter: 13800, curr loss: 1.2559962272644043, avg loss: 1.2632472002506256\n",
      "trial: 5, iter: 14000, curr loss: 1.2639362812042236, avg loss: 1.2644422668218613\n",
      "trial: 5, iter: 14200, curr loss: 1.2671401500701904, avg loss: 1.2633949279785157\n",
      "trial: 5, iter: 14400, curr loss: 1.285634994506836, avg loss: 1.2613932597637176\n",
      "trial: 5, iter: 14600, curr loss: 1.2545243501663208, avg loss: 1.2619360953569412\n",
      "trial: 5, iter: 14800, curr loss: 1.2511250972747803, avg loss: 1.2616238325834275\n",
      "trial: 5, iter: 15000, curr loss: 1.270201325416565, avg loss: 1.265374110341072\n",
      "trial: 5, iter: 15200, curr loss: 1.255851149559021, avg loss: 1.2611864006519318\n",
      "trial: 5, iter: 15400, curr loss: 1.2374669313430786, avg loss: 1.263354480266571\n",
      "trial: 5, iter: 15600, curr loss: 1.2691473960876465, avg loss: 1.264925087094307\n",
      "trial: 5, ldr: 0.24927569925785065\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26435103416442873\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3865810632705688, avg loss: 1.387138239145279\n",
      "trial: 1, iter: 400, curr loss: 1.3806936740875244, avg loss: 1.3846352100372314\n",
      "trial: 1, iter: 600, curr loss: 1.3471784591674805, avg loss: 1.3588310283422471\n",
      "trial: 1, iter: 800, curr loss: 1.30199134349823, avg loss: 1.3288270872831345\n",
      "trial: 1, iter: 1000, curr loss: 1.2716704607009888, avg loss: 1.3156768107414245\n",
      "trial: 1, iter: 1200, curr loss: 1.2919710874557495, avg loss: 1.3082148015499115\n",
      "trial: 1, iter: 1400, curr loss: 1.3301727771759033, avg loss: 1.3053311014175415\n",
      "trial: 1, iter: 1600, curr loss: 1.2853498458862305, avg loss: 1.3010462129116058\n",
      "trial: 1, iter: 1800, curr loss: 1.3001389503479004, avg loss: 1.2920550513267517\n",
      "trial: 1, iter: 2000, curr loss: 1.297922134399414, avg loss: 1.2838875132799148\n",
      "trial: 1, iter: 2200, curr loss: 1.3069672584533691, avg loss: 1.2784526640176772\n",
      "trial: 1, iter: 2400, curr loss: 1.2935417890548706, avg loss: 1.2755638629198074\n",
      "trial: 1, iter: 2600, curr loss: 1.2876325845718384, avg loss: 1.2749265265464782\n",
      "trial: 1, iter: 2800, curr loss: 1.2759486436843872, avg loss: 1.2727178305387497\n",
      "trial: 1, iter: 3000, curr loss: 1.2813069820404053, avg loss: 1.2684117835760116\n",
      "trial: 1, iter: 3200, curr loss: 1.254940390586853, avg loss: 1.2727181297540664\n",
      "trial: 1, iter: 3400, curr loss: 1.2321326732635498, avg loss: 1.26657761156559\n",
      "trial: 1, iter: 3600, curr loss: 1.279368281364441, avg loss: 1.2657364696264266\n",
      "trial: 1, iter: 3800, curr loss: 1.2803823947906494, avg loss: 1.2699526393413543\n",
      "trial: 1, iter: 4000, curr loss: 1.2712730169296265, avg loss: 1.2713567590713502\n",
      "trial: 1, iter: 4200, curr loss: 1.2396432161331177, avg loss: 1.266982159614563\n",
      "trial: 1, iter: 4400, curr loss: 1.2549293041229248, avg loss: 1.2642042309045791\n",
      "trial: 1, iter: 4600, curr loss: 1.2785992622375488, avg loss: 1.2695723104476928\n",
      "trial: 1, iter: 4800, curr loss: 1.2969876527786255, avg loss: 1.2691147327423096\n",
      "trial: 1, iter: 5000, curr loss: 1.2696735858917236, avg loss: 1.265879229903221\n",
      "trial: 1, iter: 5200, curr loss: 1.2927719354629517, avg loss: 1.2660602450370788\n",
      "trial: 1, iter: 5400, curr loss: 1.2797534465789795, avg loss: 1.2635225033760071\n",
      "trial: 1, iter: 5600, curr loss: 1.2625035047531128, avg loss: 1.264858775138855\n",
      "trial: 1, iter: 5800, curr loss: 1.2389378547668457, avg loss: 1.2646228688955308\n",
      "trial: 1, iter: 6000, curr loss: 1.311489224433899, avg loss: 1.2665071350336075\n",
      "trial: 1, iter: 6200, curr loss: 1.2831155061721802, avg loss: 1.262811467051506\n",
      "trial: 1, iter: 6400, curr loss: 1.2512294054031372, avg loss: 1.2669132387638091\n",
      "trial: 1, iter: 6600, curr loss: 1.2590231895446777, avg loss: 1.2665749216079711\n",
      "trial: 1, iter: 6800, curr loss: 1.2745132446289062, avg loss: 1.2656494355201722\n",
      "trial: 1, iter: 7000, curr loss: 1.2787983417510986, avg loss: 1.2625411158800126\n",
      "trial: 1, iter: 7200, curr loss: 1.2915606498718262, avg loss: 1.2670487153530121\n",
      "trial: 1, iter: 7400, curr loss: 1.2365131378173828, avg loss: 1.2641625255346298\n",
      "trial: 1, iter: 7600, curr loss: 1.2111445665359497, avg loss: 1.2636333125829697\n",
      "trial: 1, iter: 7800, curr loss: 1.237302303314209, avg loss: 1.2630284112691879\n",
      "trial: 1, iter: 8000, curr loss: 1.2964028120040894, avg loss: 1.2640240800380707\n",
      "trial: 1, iter: 8200, curr loss: 1.270632028579712, avg loss: 1.2621905559301376\n",
      "trial: 1, iter: 8400, curr loss: 1.3056142330169678, avg loss: 1.2647485798597335\n",
      "trial: 1, iter: 8600, curr loss: 1.2442283630371094, avg loss: 1.2611337733268737\n",
      "trial: 1, iter: 8800, curr loss: 1.3419201374053955, avg loss: 1.262869508266449\n",
      "trial: 1, iter: 9000, curr loss: 1.2465384006500244, avg loss: 1.260196671485901\n",
      "trial: 1, iter: 9200, curr loss: 1.250154972076416, avg loss: 1.2639193159341813\n",
      "trial: 1, iter: 9400, curr loss: 1.2701271772384644, avg loss: 1.2616165924072265\n",
      "trial: 1, iter: 9600, curr loss: 1.2234266996383667, avg loss: 1.2649340879917146\n",
      "trial: 1, iter: 9800, curr loss: 1.2502816915512085, avg loss: 1.2577962481975555\n",
      "trial: 1, iter: 10000, curr loss: 1.2266604900360107, avg loss: 1.2652544277906417\n",
      "trial: 1, iter: 10200, curr loss: 1.250012993812561, avg loss: 1.2614562368392945\n",
      "trial: 1, iter: 10400, curr loss: 1.269121527671814, avg loss: 1.2659461116790771\n",
      "trial: 1, iter: 10600, curr loss: 1.2686097621917725, avg loss: 1.261436943411827\n",
      "trial: 1, iter: 10800, curr loss: 1.2551372051239014, avg loss: 1.2635407799482345\n",
      "trial: 1, iter: 11000, curr loss: 1.3253965377807617, avg loss: 1.26276012301445\n",
      "trial: 1, iter: 11200, curr loss: 1.272984504699707, avg loss: 1.2619809305667877\n",
      "trial: 1, iter: 11400, curr loss: 1.236045479774475, avg loss: 1.26006338596344\n",
      "trial: 1, iter: 11600, curr loss: 1.2304359674453735, avg loss: 1.2623816865682602\n",
      "trial: 1, iter: 11800, curr loss: 1.2820017337799072, avg loss: 1.2631832492351531\n",
      "trial: 1, iter: 12000, curr loss: 1.2440705299377441, avg loss: 1.2609686636924744\n",
      "trial: 1, iter: 12200, curr loss: 1.3147974014282227, avg loss: 1.261090202331543\n",
      "trial: 1, iter: 12400, curr loss: 1.2666068077087402, avg loss: 1.2621206122636794\n",
      "trial: 1, iter: 12600, curr loss: 1.2646503448486328, avg loss: 1.2611230432987213\n",
      "trial: 1, iter: 12800, curr loss: 1.2498353719711304, avg loss: 1.2645610862970351\n",
      "trial: 1, iter: 13000, curr loss: 1.2624614238739014, avg loss: 1.2652342677116395\n",
      "trial: 1, iter: 13200, curr loss: 1.287894606590271, avg loss: 1.2618887042999267\n",
      "trial: 1, iter: 13400, curr loss: 1.250781774520874, avg loss: 1.2615180176496505\n",
      "trial: 1, iter: 13600, curr loss: 1.2297762632369995, avg loss: 1.2621678107976912\n",
      "trial: 1, iter: 13800, curr loss: 1.2802612781524658, avg loss: 1.26251540184021\n",
      "trial: 1, iter: 14000, curr loss: 1.2454006671905518, avg loss: 1.2628289830684662\n",
      "trial: 1, iter: 14200, curr loss: 1.2614799737930298, avg loss: 1.2598369586467744\n",
      "trial: 1, iter: 14400, curr loss: 1.2614691257476807, avg loss: 1.260713324546814\n",
      "trial: 1, iter: 14600, curr loss: 1.2705469131469727, avg loss: 1.262641127705574\n",
      "trial: 1, iter: 14800, curr loss: 1.2601096630096436, avg loss: 1.2598138278722764\n",
      "trial: 1, iter: 15000, curr loss: 1.2591032981872559, avg loss: 1.2638212209939956\n",
      "trial: 1, iter: 15200, curr loss: 1.3121733665466309, avg loss: 1.2601061207056046\n",
      "trial: 1, iter: 15400, curr loss: 1.2502124309539795, avg loss: 1.2610019147396088\n",
      "trial: 1, iter: 15600, curr loss: 1.2542271614074707, avg loss: 1.2630208432674408\n",
      "trial: 1, ldr: 0.22059853374958038\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.38406240940094, avg loss: 1.3869325363636016\n",
      "trial: 2, iter: 400, curr loss: 1.3721437454223633, avg loss: 1.3805785566568374\n",
      "trial: 2, iter: 600, curr loss: 1.2927732467651367, avg loss: 1.3420791697502137\n",
      "trial: 2, iter: 800, curr loss: 1.3305373191833496, avg loss: 1.319270665049553\n",
      "trial: 2, iter: 1000, curr loss: 1.3189815282821655, avg loss: 1.3118942219018936\n",
      "trial: 2, iter: 1200, curr loss: 1.3645586967468262, avg loss: 1.3087961477041246\n",
      "trial: 2, iter: 1400, curr loss: 1.298983097076416, avg loss: 1.3044133824110031\n",
      "trial: 2, iter: 1600, curr loss: 1.2942379713058472, avg loss: 1.298733719587326\n",
      "trial: 2, iter: 1800, curr loss: 1.3078298568725586, avg loss: 1.2942783242464067\n",
      "trial: 2, iter: 2000, curr loss: 1.2708940505981445, avg loss: 1.2949665015935898\n",
      "trial: 2, iter: 2200, curr loss: 1.2858721017837524, avg loss: 1.2852111208438872\n",
      "trial: 2, iter: 2400, curr loss: 1.2620433568954468, avg loss: 1.2759546303749085\n",
      "trial: 2, iter: 2600, curr loss: 1.273451328277588, avg loss: 1.2756373769044875\n",
      "trial: 2, iter: 2800, curr loss: 1.301169991493225, avg loss: 1.2750120115280152\n",
      "trial: 2, iter: 3000, curr loss: 1.259615421295166, avg loss: 1.2732477033138274\n",
      "trial: 2, iter: 3200, curr loss: 1.2876698970794678, avg loss: 1.2701072776317597\n",
      "trial: 2, iter: 3400, curr loss: 1.267063856124878, avg loss: 1.2680131739377976\n",
      "trial: 2, iter: 3600, curr loss: 1.2787684202194214, avg loss: 1.2721079748868942\n",
      "trial: 2, iter: 3800, curr loss: 1.2763023376464844, avg loss: 1.2683171659708024\n",
      "trial: 2, iter: 4000, curr loss: 1.25743567943573, avg loss: 1.2663117998838425\n",
      "trial: 2, iter: 4200, curr loss: 1.2787240743637085, avg loss: 1.267657465338707\n",
      "trial: 2, iter: 4400, curr loss: 1.2850708961486816, avg loss: 1.2692975634336472\n",
      "trial: 2, iter: 4600, curr loss: 1.3017847537994385, avg loss: 1.2673971670866013\n",
      "trial: 2, iter: 4800, curr loss: 1.2312607765197754, avg loss: 1.2674208146333694\n",
      "trial: 2, iter: 5000, curr loss: 1.2457753419876099, avg loss: 1.2694391345977782\n",
      "trial: 2, iter: 5200, curr loss: 1.2799780368804932, avg loss: 1.2623423737287522\n",
      "trial: 2, iter: 5400, curr loss: 1.270994782447815, avg loss: 1.266515182852745\n",
      "trial: 2, iter: 5600, curr loss: 1.2575461864471436, avg loss: 1.2641636562347411\n",
      "trial: 2, iter: 5800, curr loss: 1.2492729425430298, avg loss: 1.262347964644432\n",
      "trial: 2, iter: 6000, curr loss: 1.2486205101013184, avg loss: 1.265015305876732\n",
      "trial: 2, iter: 6200, curr loss: 1.2937601804733276, avg loss: 1.264871405363083\n",
      "trial: 2, iter: 6400, curr loss: 1.2612465620040894, avg loss: 1.2638500797748566\n",
      "trial: 2, iter: 6600, curr loss: 1.2597167491912842, avg loss: 1.2684006810188293\n",
      "trial: 2, iter: 6800, curr loss: 1.2843303680419922, avg loss: 1.2636410576105117\n",
      "trial: 2, iter: 7000, curr loss: 1.2841850519180298, avg loss: 1.2620958149433137\n",
      "trial: 2, iter: 7200, curr loss: 1.2882236242294312, avg loss: 1.2627800637483597\n",
      "trial: 2, iter: 7400, curr loss: 1.222182035446167, avg loss: 1.2649166798591613\n",
      "trial: 2, iter: 7600, curr loss: 1.2709813117980957, avg loss: 1.2640199887752532\n",
      "trial: 2, iter: 7800, curr loss: 1.296216607093811, avg loss: 1.264390504360199\n",
      "trial: 2, iter: 8000, curr loss: 1.258905291557312, avg loss: 1.2608219701051713\n",
      "trial: 2, iter: 8200, curr loss: 1.2713062763214111, avg loss: 1.2636323249340058\n",
      "trial: 2, iter: 8400, curr loss: 1.2676215171813965, avg loss: 1.2617587065696716\n",
      "trial: 2, iter: 8600, curr loss: 1.2239595651626587, avg loss: 1.2632484304904938\n",
      "trial: 2, iter: 8800, curr loss: 1.2665990591049194, avg loss: 1.2606262069940568\n",
      "trial: 2, iter: 9000, curr loss: 1.2568601369857788, avg loss: 1.2621500009298325\n",
      "trial: 2, iter: 9200, curr loss: 1.2640228271484375, avg loss: 1.2628272950649262\n",
      "trial: 2, iter: 9400, curr loss: 1.2515085935592651, avg loss: 1.262603561282158\n",
      "trial: 2, iter: 9600, curr loss: 1.2846438884735107, avg loss: 1.2654385250806808\n",
      "trial: 2, iter: 9800, curr loss: 1.279624581336975, avg loss: 1.2646282613277435\n",
      "trial: 2, iter: 10000, curr loss: 1.2204725742340088, avg loss: 1.2619034790992736\n",
      "trial: 2, iter: 10200, curr loss: 1.2685198783874512, avg loss: 1.2640228700637817\n",
      "trial: 2, iter: 10400, curr loss: 1.2234737873077393, avg loss: 1.2605201309919358\n",
      "trial: 2, iter: 10600, curr loss: 1.2667598724365234, avg loss: 1.2631875997781754\n",
      "trial: 2, iter: 10800, curr loss: 1.2900359630584717, avg loss: 1.2646391880512238\n",
      "trial: 2, iter: 11000, curr loss: 1.248945713043213, avg loss: 1.2619481438398361\n",
      "trial: 2, iter: 11200, curr loss: 1.2529385089874268, avg loss: 1.2622402322292328\n",
      "trial: 2, iter: 11400, curr loss: 1.2505327463150024, avg loss: 1.2635414171218873\n",
      "trial: 2, iter: 11600, curr loss: 1.2979762554168701, avg loss: 1.2636196607351302\n",
      "trial: 2, iter: 11800, curr loss: 1.263968825340271, avg loss: 1.260504149198532\n",
      "trial: 2, iter: 12000, curr loss: 1.2684069871902466, avg loss: 1.261514043211937\n",
      "trial: 2, iter: 12200, curr loss: 1.263682246208191, avg loss: 1.2650268810987473\n",
      "trial: 2, iter: 12400, curr loss: 1.281660795211792, avg loss: 1.2591063052415847\n",
      "trial: 2, iter: 12600, curr loss: 1.3044297695159912, avg loss: 1.2607905346155166\n",
      "trial: 2, iter: 12800, curr loss: 1.2487246990203857, avg loss: 1.2637510019540787\n",
      "trial: 2, iter: 13000, curr loss: 1.2598254680633545, avg loss: 1.259092349410057\n",
      "trial: 2, iter: 13200, curr loss: 1.291043996810913, avg loss: 1.266491903066635\n",
      "trial: 2, iter: 13400, curr loss: 1.3119713068008423, avg loss: 1.2628284442424773\n",
      "trial: 2, iter: 13600, curr loss: 1.2424153089523315, avg loss: 1.2613851749897003\n",
      "trial: 2, iter: 13800, curr loss: 1.273438572883606, avg loss: 1.2589743077754973\n",
      "trial: 2, iter: 14000, curr loss: 1.2831287384033203, avg loss: 1.2630837208032608\n",
      "trial: 2, iter: 14200, curr loss: 1.2636332511901855, avg loss: 1.2625383013486862\n",
      "trial: 2, iter: 14400, curr loss: 1.2317242622375488, avg loss: 1.2601280337572098\n",
      "trial: 2, iter: 14600, curr loss: 1.2277121543884277, avg loss: 1.2621376597881317\n",
      "trial: 2, iter: 14800, curr loss: 1.2626621723175049, avg loss: 1.2639588034152984\n",
      "trial: 2, iter: 15000, curr loss: 1.2720789909362793, avg loss: 1.2592468351125716\n",
      "trial: 2, iter: 15200, curr loss: 1.2531228065490723, avg loss: 1.2622473675012589\n",
      "trial: 2, iter: 15400, curr loss: 1.234640121459961, avg loss: 1.2611818492412568\n",
      "trial: 2, iter: 15600, curr loss: 1.2843425273895264, avg loss: 1.2602069807052612\n",
      "trial: 2, ldr: 0.26858747005462646\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3895939588546753, avg loss: 1.3865893507003784\n",
      "trial: 3, iter: 400, curr loss: 1.3704979419708252, avg loss: 1.3822021168470382\n",
      "trial: 3, iter: 600, curr loss: 1.340817928314209, avg loss: 1.3447628545761108\n",
      "trial: 3, iter: 800, curr loss: 1.3188395500183105, avg loss: 1.3188796764612198\n",
      "trial: 3, iter: 1000, curr loss: 1.3075246810913086, avg loss: 1.3119551527500153\n",
      "trial: 3, iter: 1200, curr loss: 1.3047914505004883, avg loss: 1.3075546634197235\n",
      "trial: 3, iter: 1400, curr loss: 1.2962682247161865, avg loss: 1.2994751793146133\n",
      "trial: 3, iter: 1600, curr loss: 1.3252959251403809, avg loss: 1.291056958436966\n",
      "trial: 3, iter: 1800, curr loss: 1.2680824995040894, avg loss: 1.2819023042917252\n",
      "trial: 3, iter: 2000, curr loss: 1.3062201738357544, avg loss: 1.2767559987306596\n",
      "trial: 3, iter: 2200, curr loss: 1.2540020942687988, avg loss: 1.2755542474985122\n",
      "trial: 3, iter: 2400, curr loss: 1.267085313796997, avg loss: 1.2718599462509155\n",
      "trial: 3, iter: 2600, curr loss: 1.3001961708068848, avg loss: 1.2715678143501281\n",
      "trial: 3, iter: 2800, curr loss: 1.2754175662994385, avg loss: 1.2658788973093034\n",
      "trial: 3, iter: 3000, curr loss: 1.2999094724655151, avg loss: 1.268113415837288\n",
      "trial: 3, iter: 3200, curr loss: 1.2465506792068481, avg loss: 1.2683918356895447\n",
      "trial: 3, iter: 3400, curr loss: 1.244652271270752, avg loss: 1.2701446032524109\n",
      "trial: 3, iter: 3600, curr loss: 1.251654863357544, avg loss: 1.2668047946691514\n",
      "trial: 3, iter: 3800, curr loss: 1.3074407577514648, avg loss: 1.2657524412870407\n",
      "trial: 3, iter: 4000, curr loss: 1.2827033996582031, avg loss: 1.2659148055315017\n",
      "trial: 3, iter: 4200, curr loss: 1.2867313623428345, avg loss: 1.2655961155891418\n",
      "trial: 3, iter: 4400, curr loss: 1.2799183130264282, avg loss: 1.2641181015968324\n",
      "trial: 3, iter: 4600, curr loss: 1.262624740600586, avg loss: 1.2695591217279434\n",
      "trial: 3, iter: 4800, curr loss: 1.2699474096298218, avg loss: 1.2632557541131972\n",
      "trial: 3, iter: 5000, curr loss: 1.263231635093689, avg loss: 1.2629211407899856\n",
      "trial: 3, iter: 5200, curr loss: 1.3065578937530518, avg loss: 1.268102192878723\n",
      "trial: 3, iter: 5400, curr loss: 1.257642149925232, avg loss: 1.2643994426727294\n",
      "trial: 3, iter: 5600, curr loss: 1.2369335889816284, avg loss: 1.2613073754310609\n",
      "trial: 3, iter: 5800, curr loss: 1.3146800994873047, avg loss: 1.2613040107488631\n",
      "trial: 3, iter: 6000, curr loss: 1.300302505493164, avg loss: 1.2666813254356384\n",
      "trial: 3, iter: 6200, curr loss: 1.2435821294784546, avg loss: 1.2612336713075638\n",
      "trial: 3, iter: 6400, curr loss: 1.2497559785842896, avg loss: 1.263232770562172\n",
      "trial: 3, iter: 6600, curr loss: 1.2810717821121216, avg loss: 1.2618751794099807\n",
      "trial: 3, iter: 6800, curr loss: 1.308366298675537, avg loss: 1.2658780843019486\n",
      "trial: 3, iter: 7000, curr loss: 1.2458455562591553, avg loss: 1.2667903816699981\n",
      "trial: 3, iter: 7200, curr loss: 1.2386834621429443, avg loss: 1.261313821077347\n",
      "trial: 3, iter: 7400, curr loss: 1.2611494064331055, avg loss: 1.2636333495378493\n",
      "trial: 3, iter: 7600, curr loss: 1.2416795492172241, avg loss: 1.2633348625898362\n",
      "trial: 3, iter: 7800, curr loss: 1.2392594814300537, avg loss: 1.2607026880979537\n",
      "trial: 3, iter: 8000, curr loss: 1.2765166759490967, avg loss: 1.2626724684238433\n",
      "trial: 3, iter: 8200, curr loss: 1.2741210460662842, avg loss: 1.2636841797828675\n",
      "trial: 3, iter: 8400, curr loss: 1.280090570449829, avg loss: 1.2652510738372802\n",
      "trial: 3, iter: 8600, curr loss: 1.2769756317138672, avg loss: 1.2609919506311416\n",
      "trial: 3, iter: 8800, curr loss: 1.265311360359192, avg loss: 1.2619745117425918\n",
      "trial: 3, iter: 9000, curr loss: 1.2321197986602783, avg loss: 1.2608869528770448\n",
      "trial: 3, iter: 9200, curr loss: 1.3116755485534668, avg loss: 1.2614702022075652\n",
      "trial: 3, iter: 9400, curr loss: 1.2560288906097412, avg loss: 1.263750536441803\n",
      "trial: 3, iter: 9600, curr loss: 1.2536066770553589, avg loss: 1.2595172756910324\n",
      "trial: 3, iter: 9800, curr loss: 1.2876139879226685, avg loss: 1.262873175740242\n",
      "trial: 3, iter: 10000, curr loss: 1.259616494178772, avg loss: 1.2652032089233398\n",
      "trial: 3, iter: 10200, curr loss: 1.2122119665145874, avg loss: 1.2663818454742433\n",
      "trial: 3, iter: 10400, curr loss: 1.2355742454528809, avg loss: 1.2603549653291701\n",
      "trial: 3, iter: 10600, curr loss: 1.2611274719238281, avg loss: 1.2606821960210801\n",
      "trial: 3, iter: 10800, curr loss: 1.2176848649978638, avg loss: 1.2616268235445023\n",
      "trial: 3, iter: 11000, curr loss: 1.2476204633712769, avg loss: 1.2583068311214447\n",
      "trial: 3, iter: 11200, curr loss: 1.2280913591384888, avg loss: 1.262856141924858\n",
      "trial: 3, iter: 11400, curr loss: 1.2574676275253296, avg loss: 1.2629713058471679\n",
      "trial: 3, iter: 11600, curr loss: 1.2717945575714111, avg loss: 1.2639625829458236\n",
      "trial: 3, iter: 11800, curr loss: 1.3137730360031128, avg loss: 1.2617622810602187\n",
      "trial: 3, iter: 12000, curr loss: 1.2299128770828247, avg loss: 1.2579153698682786\n",
      "trial: 3, iter: 12200, curr loss: 1.2451297044754028, avg loss: 1.2630928856134416\n",
      "trial: 3, iter: 12400, curr loss: 1.23589289188385, avg loss: 1.261700627207756\n",
      "trial: 3, iter: 12600, curr loss: 1.3142764568328857, avg loss: 1.2611004108190536\n",
      "trial: 3, iter: 12800, curr loss: 1.2570220232009888, avg loss: 1.2626385581493378\n",
      "trial: 3, iter: 13000, curr loss: 1.2811130285263062, avg loss: 1.2622407537698745\n",
      "trial: 3, iter: 13200, curr loss: 1.2692127227783203, avg loss: 1.2589122015237808\n",
      "trial: 3, iter: 13400, curr loss: 1.2667319774627686, avg loss: 1.2589011466503144\n",
      "trial: 3, iter: 13600, curr loss: 1.3150455951690674, avg loss: 1.2629635494947433\n",
      "trial: 3, iter: 13800, curr loss: 1.2785000801086426, avg loss: 1.2619489872455596\n",
      "trial: 3, iter: 14000, curr loss: 1.2766708135604858, avg loss: 1.2600375360250473\n",
      "trial: 3, iter: 14200, curr loss: 1.2413122653961182, avg loss: 1.2635507971048354\n",
      "trial: 3, iter: 14400, curr loss: 1.2571132183074951, avg loss: 1.261727129817009\n",
      "trial: 3, iter: 14600, curr loss: 1.2524306774139404, avg loss: 1.2601133048534394\n",
      "trial: 3, iter: 14800, curr loss: 1.235750675201416, avg loss: 1.2595178031921386\n",
      "trial: 3, iter: 15000, curr loss: 1.2846872806549072, avg loss: 1.2606865632534028\n",
      "trial: 3, iter: 15200, curr loss: 1.2834819555282593, avg loss: 1.263170828819275\n",
      "trial: 3, iter: 15400, curr loss: 1.2960511445999146, avg loss: 1.2577880722284318\n",
      "trial: 3, iter: 15600, curr loss: 1.2660177946090698, avg loss: 1.2599807536602021\n",
      "trial: 3, ldr: 0.24119043350219727\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3882219791412354, avg loss: 1.3864717072248458\n",
      "trial: 4, iter: 400, curr loss: 1.369441270828247, avg loss: 1.3821441447734832\n",
      "trial: 4, iter: 600, curr loss: 1.3368030786514282, avg loss: 1.3459112030267715\n",
      "trial: 4, iter: 800, curr loss: 1.291337251663208, avg loss: 1.323163145184517\n",
      "trial: 4, iter: 1000, curr loss: 1.2869770526885986, avg loss: 1.314779207110405\n",
      "trial: 4, iter: 1200, curr loss: 1.3226845264434814, avg loss: 1.3057047206163406\n",
      "trial: 4, iter: 1400, curr loss: 1.3402791023254395, avg loss: 1.3048704713582993\n",
      "trial: 4, iter: 1600, curr loss: 1.2949857711791992, avg loss: 1.2966981971263885\n",
      "trial: 4, iter: 1800, curr loss: 1.305357813835144, avg loss: 1.293980486392975\n",
      "trial: 4, iter: 2000, curr loss: 1.259284257888794, avg loss: 1.285360289812088\n",
      "trial: 4, iter: 2200, curr loss: 1.281752109527588, avg loss: 1.2806384468078613\n",
      "trial: 4, iter: 2400, curr loss: 1.2706302404403687, avg loss: 1.2741270518302918\n",
      "trial: 4, iter: 2600, curr loss: 1.3255802392959595, avg loss: 1.2716238939762115\n",
      "trial: 4, iter: 2800, curr loss: 1.2508904933929443, avg loss: 1.270378503203392\n",
      "trial: 4, iter: 3000, curr loss: 1.3005497455596924, avg loss: 1.2726988863945008\n",
      "trial: 4, iter: 3200, curr loss: 1.2577800750732422, avg loss: 1.270234639644623\n",
      "trial: 4, iter: 3400, curr loss: 1.2955572605133057, avg loss: 1.2685396349430085\n",
      "trial: 4, iter: 3600, curr loss: 1.295533299446106, avg loss: 1.2656577944755554\n",
      "trial: 4, iter: 3800, curr loss: 1.2591041326522827, avg loss: 1.2671889412403106\n",
      "trial: 4, iter: 4000, curr loss: 1.26808762550354, avg loss: 1.2662103772163391\n",
      "trial: 4, iter: 4200, curr loss: 1.2370303869247437, avg loss: 1.2683578395843507\n",
      "trial: 4, iter: 4400, curr loss: 1.2861855030059814, avg loss: 1.2674216985702516\n",
      "trial: 4, iter: 4600, curr loss: 1.2632731199264526, avg loss: 1.2643045097589494\n",
      "trial: 4, iter: 4800, curr loss: 1.2637107372283936, avg loss: 1.2692261564731597\n",
      "trial: 4, iter: 5000, curr loss: 1.2587101459503174, avg loss: 1.2661253398656844\n",
      "trial: 4, iter: 5200, curr loss: 1.2635990381240845, avg loss: 1.2632915151119233\n",
      "trial: 4, iter: 5400, curr loss: 1.282629370689392, avg loss: 1.265095101594925\n",
      "trial: 4, iter: 5600, curr loss: 1.2948236465454102, avg loss: 1.2665232026576996\n",
      "trial: 4, iter: 5800, curr loss: 1.259955883026123, avg loss: 1.265581364631653\n",
      "trial: 4, iter: 6000, curr loss: 1.255428433418274, avg loss: 1.2651183623075486\n",
      "trial: 4, iter: 6200, curr loss: 1.254188060760498, avg loss: 1.2636496919393538\n",
      "trial: 4, iter: 6400, curr loss: 1.2458442449569702, avg loss: 1.2605406987667083\n",
      "trial: 4, iter: 6600, curr loss: 1.3008733987808228, avg loss: 1.2627504628896713\n",
      "trial: 4, iter: 6800, curr loss: 1.2495753765106201, avg loss: 1.2640121722221374\n",
      "trial: 4, iter: 7000, curr loss: 1.2764055728912354, avg loss: 1.2643603783845903\n",
      "trial: 4, iter: 7200, curr loss: 1.2766145467758179, avg loss: 1.2650817406177521\n",
      "trial: 4, iter: 7400, curr loss: 1.2708791494369507, avg loss: 1.2622938132286072\n",
      "trial: 4, iter: 7600, curr loss: 1.2209959030151367, avg loss: 1.2652923172712327\n",
      "trial: 4, iter: 7800, curr loss: 1.2631564140319824, avg loss: 1.2652871716022491\n",
      "trial: 4, iter: 8000, curr loss: 1.2385001182556152, avg loss: 1.2607870322465897\n",
      "trial: 4, iter: 8200, curr loss: 1.2569787502288818, avg loss: 1.2635253876447679\n",
      "trial: 4, iter: 8400, curr loss: 1.2749499082565308, avg loss: 1.262718022465706\n",
      "trial: 4, iter: 8600, curr loss: 1.2282027006149292, avg loss: 1.2613926362991332\n",
      "trial: 4, iter: 8800, curr loss: 1.2848358154296875, avg loss: 1.2654872769117356\n",
      "trial: 4, iter: 9000, curr loss: 1.2208280563354492, avg loss: 1.2627238649129868\n",
      "trial: 4, iter: 9200, curr loss: 1.2418845891952515, avg loss: 1.2607217472791672\n",
      "trial: 4, iter: 9400, curr loss: 1.2647908926010132, avg loss: 1.2612824660539628\n",
      "trial: 4, iter: 9600, curr loss: 1.2484997510910034, avg loss: 1.2634554016590118\n",
      "trial: 4, iter: 9800, curr loss: 1.2673135995864868, avg loss: 1.2604056799411774\n",
      "trial: 4, iter: 10000, curr loss: 1.2839148044586182, avg loss: 1.264128115773201\n",
      "trial: 4, iter: 10200, curr loss: 1.2356576919555664, avg loss: 1.2611676913499832\n",
      "trial: 4, iter: 10400, curr loss: 1.2500578165054321, avg loss: 1.2631160300970077\n",
      "trial: 4, iter: 10600, curr loss: 1.2535752058029175, avg loss: 1.261659144759178\n",
      "trial: 4, iter: 10800, curr loss: 1.255428671836853, avg loss: 1.261038866043091\n",
      "trial: 4, iter: 11000, curr loss: 1.2567356824874878, avg loss: 1.2604112094640731\n",
      "trial: 4, iter: 11200, curr loss: 1.2317910194396973, avg loss: 1.2647646725177766\n",
      "trial: 4, iter: 11400, curr loss: 1.2880505323410034, avg loss: 1.2614372211694718\n",
      "trial: 4, iter: 11600, curr loss: 1.2653868198394775, avg loss: 1.262134810090065\n",
      "trial: 4, iter: 11800, curr loss: 1.2565664052963257, avg loss: 1.2617620104551315\n",
      "trial: 4, iter: 12000, curr loss: 1.259072184562683, avg loss: 1.2641959220170975\n",
      "trial: 4, iter: 12200, curr loss: 1.2932724952697754, avg loss: 1.2632736951112746\n",
      "trial: 4, iter: 12400, curr loss: 1.2832682132720947, avg loss: 1.2642297637462616\n",
      "trial: 4, iter: 12600, curr loss: 1.2335765361785889, avg loss: 1.2631395804882048\n",
      "trial: 4, iter: 12800, curr loss: 1.284446358680725, avg loss: 1.2647225695848465\n",
      "trial: 4, iter: 13000, curr loss: 1.2541098594665527, avg loss: 1.2592432057857514\n",
      "trial: 4, iter: 13200, curr loss: 1.2518712282180786, avg loss: 1.2589827919006347\n",
      "trial: 4, iter: 13400, curr loss: 1.3087341785430908, avg loss: 1.260529438853264\n",
      "trial: 4, iter: 13600, curr loss: 1.2840995788574219, avg loss: 1.2604745787382126\n",
      "trial: 4, iter: 13800, curr loss: 1.2556946277618408, avg loss: 1.2617753714323043\n",
      "trial: 4, iter: 14000, curr loss: 1.278670072555542, avg loss: 1.263982339501381\n",
      "trial: 4, iter: 14200, curr loss: 1.2330677509307861, avg loss: 1.2616007035970689\n",
      "trial: 4, iter: 14400, curr loss: 1.356382966041565, avg loss: 1.264923356771469\n",
      "trial: 4, iter: 14600, curr loss: 1.2706313133239746, avg loss: 1.2618185698986053\n",
      "trial: 4, iter: 14800, curr loss: 1.2532354593276978, avg loss: 1.2621684020757675\n",
      "trial: 4, iter: 15000, curr loss: 1.2724883556365967, avg loss: 1.2589739990234374\n",
      "trial: 4, iter: 15200, curr loss: 1.2099432945251465, avg loss: 1.2636627745628357\n",
      "trial: 4, iter: 15400, curr loss: 1.2761318683624268, avg loss: 1.2596014189720153\n",
      "trial: 4, iter: 15600, curr loss: 1.2687803506851196, avg loss: 1.2637673443555832\n",
      "trial: 4, ldr: 0.22255267202854156\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387238621711731, avg loss: 1.3869336420297622\n",
      "trial: 5, iter: 400, curr loss: 1.3794234991073608, avg loss: 1.3829804074764251\n",
      "trial: 5, iter: 600, curr loss: 1.3177753686904907, avg loss: 1.3538041752576828\n",
      "trial: 5, iter: 800, curr loss: 1.3068071603775024, avg loss: 1.324068678021431\n",
      "trial: 5, iter: 1000, curr loss: 1.317743182182312, avg loss: 1.3142437988519668\n",
      "trial: 5, iter: 1200, curr loss: 1.2813798189163208, avg loss: 1.311871857047081\n",
      "trial: 5, iter: 1400, curr loss: 1.3406167030334473, avg loss: 1.306829594373703\n",
      "trial: 5, iter: 1600, curr loss: 1.3346506357192993, avg loss: 1.300253021121025\n",
      "trial: 5, iter: 1800, curr loss: 1.2908655405044556, avg loss: 1.2936261236667632\n",
      "trial: 5, iter: 2000, curr loss: 1.2844303846359253, avg loss: 1.2862336945533752\n",
      "trial: 5, iter: 2200, curr loss: 1.2855168581008911, avg loss: 1.2826862031221389\n",
      "trial: 5, iter: 2400, curr loss: 1.277948260307312, avg loss: 1.2779694664478303\n",
      "trial: 5, iter: 2600, curr loss: 1.2622865438461304, avg loss: 1.2762981677055358\n",
      "trial: 5, iter: 2800, curr loss: 1.259934425354004, avg loss: 1.2727495151758195\n",
      "trial: 5, iter: 3000, curr loss: 1.2553925514221191, avg loss: 1.2688527995347976\n",
      "trial: 5, iter: 3200, curr loss: 1.236708641052246, avg loss: 1.2696399092674255\n",
      "trial: 5, iter: 3400, curr loss: 1.2750879526138306, avg loss: 1.2699733525514603\n",
      "trial: 5, iter: 3600, curr loss: 1.2958019971847534, avg loss: 1.2665948873758317\n",
      "trial: 5, iter: 3800, curr loss: 1.2571614980697632, avg loss: 1.2682952374219894\n",
      "trial: 5, iter: 4000, curr loss: 1.278886079788208, avg loss: 1.2677765411138535\n",
      "trial: 5, iter: 4200, curr loss: 1.2626991271972656, avg loss: 1.2640357279777528\n",
      "trial: 5, iter: 4400, curr loss: 1.2499732971191406, avg loss: 1.2644534879922866\n",
      "trial: 5, iter: 4600, curr loss: 1.2594783306121826, avg loss: 1.2657966566085816\n",
      "trial: 5, iter: 4800, curr loss: 1.2766106128692627, avg loss: 1.2661977910995483\n",
      "trial: 5, iter: 5000, curr loss: 1.3484525680541992, avg loss: 1.2640100139379502\n",
      "trial: 5, iter: 5200, curr loss: 1.2863303422927856, avg loss: 1.264448236823082\n",
      "trial: 5, iter: 5400, curr loss: 1.2952378988265991, avg loss: 1.2653433138132095\n",
      "trial: 5, iter: 5600, curr loss: 1.2492308616638184, avg loss: 1.267238290309906\n",
      "trial: 5, iter: 5800, curr loss: 1.261818766593933, avg loss: 1.2657430696487426\n",
      "trial: 5, iter: 6000, curr loss: 1.3133171796798706, avg loss: 1.2622029715776444\n",
      "trial: 5, iter: 6200, curr loss: 1.2378411293029785, avg loss: 1.2625543183088304\n",
      "trial: 5, iter: 6400, curr loss: 1.2720149755477905, avg loss: 1.2668039780855178\n",
      "trial: 5, iter: 6600, curr loss: 1.2434967756271362, avg loss: 1.2624383932352066\n",
      "trial: 5, iter: 6800, curr loss: 1.278096318244934, avg loss: 1.262754716873169\n",
      "trial: 5, iter: 7000, curr loss: 1.2335741519927979, avg loss: 1.2626908528804779\n",
      "trial: 5, iter: 7200, curr loss: 1.2315523624420166, avg loss: 1.2651104217767715\n",
      "trial: 5, iter: 7400, curr loss: 1.3091036081314087, avg loss: 1.2621356219053268\n",
      "trial: 5, iter: 7600, curr loss: 1.2852634191513062, avg loss: 1.2656720668077468\n",
      "trial: 5, iter: 7800, curr loss: 1.2668448686599731, avg loss: 1.2602847141027451\n",
      "trial: 5, iter: 8000, curr loss: 1.2756892442703247, avg loss: 1.26529660820961\n",
      "trial: 5, iter: 8200, curr loss: 1.2604721784591675, avg loss: 1.2628824120759965\n",
      "trial: 5, iter: 8400, curr loss: 1.2784810066223145, avg loss: 1.2612728321552276\n",
      "trial: 5, iter: 8600, curr loss: 1.273026466369629, avg loss: 1.2636097192764282\n",
      "trial: 5, iter: 8800, curr loss: 1.2444988489151, avg loss: 1.261077075600624\n",
      "trial: 5, iter: 9000, curr loss: 1.2364349365234375, avg loss: 1.2665392929315566\n",
      "trial: 5, iter: 9200, curr loss: 1.2456073760986328, avg loss: 1.262224292755127\n",
      "trial: 5, iter: 9400, curr loss: 1.2203792333602905, avg loss: 1.2614170849323272\n",
      "trial: 5, iter: 9600, curr loss: 1.2848271131515503, avg loss: 1.2611389917135238\n",
      "trial: 5, iter: 9800, curr loss: 1.261608362197876, avg loss: 1.2617557501792909\n",
      "trial: 5, iter: 10000, curr loss: 1.2605479955673218, avg loss: 1.2621390396356582\n",
      "trial: 5, iter: 10200, curr loss: 1.3124771118164062, avg loss: 1.2663876748085021\n",
      "trial: 5, iter: 10400, curr loss: 1.2384743690490723, avg loss: 1.2623097026348113\n",
      "trial: 5, iter: 10600, curr loss: 1.2595820426940918, avg loss: 1.2606576460599899\n",
      "trial: 5, iter: 10800, curr loss: 1.2176663875579834, avg loss: 1.258117201924324\n",
      "trial: 5, iter: 11000, curr loss: 1.2540241479873657, avg loss: 1.2613184195756912\n",
      "trial: 5, iter: 11200, curr loss: 1.2450754642486572, avg loss: 1.2644209498167038\n",
      "trial: 5, iter: 11400, curr loss: 1.2390174865722656, avg loss: 1.2612646985054017\n",
      "trial: 5, iter: 11600, curr loss: 1.268277883529663, avg loss: 1.2625519329309463\n",
      "trial: 5, iter: 11800, curr loss: 1.2599906921386719, avg loss: 1.2632658183574677\n",
      "trial: 5, iter: 12000, curr loss: 1.2723039388656616, avg loss: 1.2619169771671295\n",
      "trial: 5, iter: 12200, curr loss: 1.2140769958496094, avg loss: 1.261811420917511\n",
      "trial: 5, iter: 12400, curr loss: 1.283064842224121, avg loss: 1.2617464864253998\n",
      "trial: 5, iter: 12600, curr loss: 1.2406480312347412, avg loss: 1.2643803799152373\n",
      "trial: 5, iter: 12800, curr loss: 1.2675268650054932, avg loss: 1.2585001736879349\n",
      "trial: 5, iter: 13000, curr loss: 1.2920899391174316, avg loss: 1.261490883231163\n",
      "trial: 5, iter: 13200, curr loss: 1.2323685884475708, avg loss: 1.2634757071733476\n",
      "trial: 5, iter: 13400, curr loss: 1.3104207515716553, avg loss: 1.2623475551605225\n",
      "trial: 5, iter: 13600, curr loss: 1.287753701210022, avg loss: 1.261432123184204\n",
      "trial: 5, iter: 13800, curr loss: 1.2317783832550049, avg loss: 1.2616523522138596\n",
      "trial: 5, iter: 14000, curr loss: 1.243326187133789, avg loss: 1.263860085606575\n",
      "trial: 5, iter: 14200, curr loss: 1.2692855596542358, avg loss: 1.2597752577066421\n",
      "trial: 5, iter: 14400, curr loss: 1.2797919511795044, avg loss: 1.2626050317287445\n",
      "trial: 5, iter: 14600, curr loss: 1.2656546831130981, avg loss: 1.2608580148220063\n",
      "trial: 5, iter: 14800, curr loss: 1.300429344177246, avg loss: 1.2621121019124986\n",
      "trial: 5, iter: 15000, curr loss: 1.2586618661880493, avg loss: 1.2617268151044845\n",
      "trial: 5, iter: 15200, curr loss: 1.267707347869873, avg loss: 1.258651652932167\n",
      "trial: 5, iter: 15400, curr loss: 1.2743083238601685, avg loss: 1.2613390678167342\n",
      "trial: 5, iter: 15600, curr loss: 1.248564600944519, avg loss: 1.2601635992527007\n",
      "trial: 5, ldr: 0.26034557819366455\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.24265493750572203\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3781172037124634, avg loss: 1.3868159979581833\n",
      "trial: 1, iter: 400, curr loss: 1.3801486492156982, avg loss: 1.3823709750175477\n",
      "trial: 1, iter: 600, curr loss: 1.328958511352539, avg loss: 1.348203734755516\n",
      "trial: 1, iter: 800, curr loss: 1.328852653503418, avg loss: 1.323536555171013\n",
      "trial: 1, iter: 1000, curr loss: 1.3502360582351685, avg loss: 1.3143027210235596\n",
      "trial: 1, iter: 1200, curr loss: 1.3103514909744263, avg loss: 1.3102631652355194\n",
      "trial: 1, iter: 1400, curr loss: 1.303809404373169, avg loss: 1.3035079473257065\n",
      "trial: 1, iter: 1600, curr loss: 1.3043241500854492, avg loss: 1.294950407743454\n",
      "trial: 1, iter: 1800, curr loss: 1.2567487955093384, avg loss: 1.2896480393409728\n",
      "trial: 1, iter: 2000, curr loss: 1.2373054027557373, avg loss: 1.2830288237333298\n",
      "trial: 1, iter: 2200, curr loss: 1.291273832321167, avg loss: 1.2805580979585647\n",
      "trial: 1, iter: 2400, curr loss: 1.3011302947998047, avg loss: 1.2717892956733703\n",
      "trial: 1, iter: 2600, curr loss: 1.3033305406570435, avg loss: 1.272145802974701\n",
      "trial: 1, iter: 2800, curr loss: 1.268244743347168, avg loss: 1.2725368624925613\n",
      "trial: 1, iter: 3000, curr loss: 1.2810231447219849, avg loss: 1.2726298081874847\n",
      "trial: 1, iter: 3200, curr loss: 1.2529116868972778, avg loss: 1.2692932677268982\n",
      "trial: 1, iter: 3400, curr loss: 1.2790361642837524, avg loss: 1.2692910861968993\n",
      "trial: 1, iter: 3600, curr loss: 1.2490501403808594, avg loss: 1.2679259198904038\n",
      "trial: 1, iter: 3800, curr loss: 1.2151519060134888, avg loss: 1.2681065058708192\n",
      "trial: 1, iter: 4000, curr loss: 1.252779483795166, avg loss: 1.2682789689302445\n",
      "trial: 1, iter: 4200, curr loss: 1.2339385747909546, avg loss: 1.268230726122856\n",
      "trial: 1, iter: 4400, curr loss: 1.271939754486084, avg loss: 1.2675357222557069\n",
      "trial: 1, iter: 4600, curr loss: 1.2702113389968872, avg loss: 1.268841985464096\n",
      "trial: 1, iter: 4800, curr loss: 1.269500970840454, avg loss: 1.261517726778984\n",
      "trial: 1, iter: 5000, curr loss: 1.2505995035171509, avg loss: 1.2671609425544739\n",
      "trial: 1, iter: 5200, curr loss: 1.232450008392334, avg loss: 1.2651094484329224\n",
      "trial: 1, iter: 5400, curr loss: 1.2708719968795776, avg loss: 1.2657202810049057\n",
      "trial: 1, iter: 5600, curr loss: 1.2592618465423584, avg loss: 1.265153939127922\n",
      "trial: 1, iter: 5800, curr loss: 1.2321562767028809, avg loss: 1.267681695818901\n",
      "trial: 1, iter: 6000, curr loss: 1.2521946430206299, avg loss: 1.2662708973884582\n",
      "trial: 1, iter: 6200, curr loss: 1.2540643215179443, avg loss: 1.2662976950407028\n",
      "trial: 1, iter: 6400, curr loss: 1.2653169631958008, avg loss: 1.266996926665306\n",
      "trial: 1, iter: 6600, curr loss: 1.2438461780548096, avg loss: 1.2647887295484543\n",
      "trial: 1, iter: 6800, curr loss: 1.2515214681625366, avg loss: 1.2672928440570832\n",
      "trial: 1, iter: 7000, curr loss: 1.2586851119995117, avg loss: 1.264214282631874\n",
      "trial: 1, iter: 7200, curr loss: 1.269538164138794, avg loss: 1.2660908699035645\n",
      "trial: 1, iter: 7400, curr loss: 1.3082407712936401, avg loss: 1.2646124136447907\n",
      "trial: 1, iter: 7600, curr loss: 1.262001633644104, avg loss: 1.266025750041008\n",
      "trial: 1, iter: 7800, curr loss: 1.2642027139663696, avg loss: 1.2644144243001938\n",
      "trial: 1, iter: 8000, curr loss: 1.2383689880371094, avg loss: 1.2614217841625213\n",
      "trial: 1, iter: 8200, curr loss: 1.2535408735275269, avg loss: 1.262568045258522\n",
      "trial: 1, iter: 8400, curr loss: 1.2843999862670898, avg loss: 1.2637627148628234\n",
      "trial: 1, iter: 8600, curr loss: 1.274882197380066, avg loss: 1.262349960207939\n",
      "trial: 1, iter: 8800, curr loss: 1.2816588878631592, avg loss: 1.2648140573501587\n",
      "trial: 1, iter: 9000, curr loss: 1.2525479793548584, avg loss: 1.2657054412364959\n",
      "trial: 1, iter: 9200, curr loss: 1.2884782552719116, avg loss: 1.264533684849739\n",
      "trial: 1, iter: 9400, curr loss: 1.2623987197875977, avg loss: 1.2649788808822633\n",
      "trial: 1, iter: 9600, curr loss: 1.2367554903030396, avg loss: 1.2609559941291808\n",
      "trial: 1, iter: 9800, curr loss: 1.2367104291915894, avg loss: 1.2648878914117814\n",
      "trial: 1, iter: 10000, curr loss: 1.2705639600753784, avg loss: 1.261004392504692\n",
      "trial: 1, iter: 10200, curr loss: 1.3039847612380981, avg loss: 1.264809671640396\n",
      "trial: 1, iter: 10400, curr loss: 1.2505346536636353, avg loss: 1.2616520923376084\n",
      "trial: 1, iter: 10600, curr loss: 1.2873172760009766, avg loss: 1.2637333351373672\n",
      "trial: 1, iter: 10800, curr loss: 1.2366762161254883, avg loss: 1.265293517112732\n",
      "trial: 1, iter: 11000, curr loss: 1.254900336265564, avg loss: 1.2644874852895738\n",
      "trial: 1, iter: 11200, curr loss: 1.2479010820388794, avg loss: 1.2627093875408173\n",
      "trial: 1, iter: 11400, curr loss: 1.269214153289795, avg loss: 1.2612866085767747\n",
      "trial: 1, iter: 11600, curr loss: 1.2559349536895752, avg loss: 1.2651163560152054\n",
      "trial: 1, iter: 11800, curr loss: 1.2691675424575806, avg loss: 1.260011746287346\n",
      "trial: 1, iter: 12000, curr loss: 1.2408173084259033, avg loss: 1.2607119643688203\n",
      "trial: 1, iter: 12200, curr loss: 1.2333537340164185, avg loss: 1.26071719288826\n",
      "trial: 1, iter: 12400, curr loss: 1.273169755935669, avg loss: 1.2656372439861299\n",
      "trial: 1, iter: 12600, curr loss: 1.259922981262207, avg loss: 1.2605330264568329\n",
      "trial: 1, iter: 12800, curr loss: 1.273047685623169, avg loss: 1.2620336854457854\n",
      "trial: 1, iter: 13000, curr loss: 1.2530673742294312, avg loss: 1.2615265601873398\n",
      "trial: 1, iter: 13200, curr loss: 1.2680972814559937, avg loss: 1.2623354750871658\n",
      "trial: 1, iter: 13400, curr loss: 1.2523821592330933, avg loss: 1.2605369526147843\n",
      "trial: 1, iter: 13600, curr loss: 1.270675778388977, avg loss: 1.2667195016145707\n",
      "trial: 1, iter: 13800, curr loss: 1.231750249862671, avg loss: 1.2650791054964066\n",
      "trial: 1, iter: 14000, curr loss: 1.2533290386199951, avg loss: 1.262255660891533\n",
      "trial: 1, iter: 14200, curr loss: 1.2605892419815063, avg loss: 1.267566995024681\n",
      "trial: 1, iter: 14400, curr loss: 1.2680134773254395, avg loss: 1.2613188886642457\n",
      "trial: 1, iter: 14600, curr loss: 1.2502104043960571, avg loss: 1.2619834804534913\n",
      "trial: 1, iter: 14800, curr loss: 1.2377864122390747, avg loss: 1.2640562641620636\n",
      "trial: 1, iter: 15000, curr loss: 1.2222431898117065, avg loss: 1.2645131021738052\n",
      "trial: 1, iter: 15200, curr loss: 1.2772173881530762, avg loss: 1.26303437769413\n",
      "trial: 1, iter: 15400, curr loss: 1.2609882354736328, avg loss: 1.2614217990636825\n",
      "trial: 1, iter: 15600, curr loss: 1.2422916889190674, avg loss: 1.2633029663562774\n",
      "trial: 1, ldr: 0.2912023961544037\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3807748556137085, avg loss: 1.386278012394905\n",
      "trial: 2, iter: 400, curr loss: 1.3418322801589966, avg loss: 1.3752123707532882\n",
      "trial: 2, iter: 600, curr loss: 1.3032306432724, avg loss: 1.3355789911746978\n",
      "trial: 2, iter: 800, curr loss: 1.3360815048217773, avg loss: 1.3215192914009095\n",
      "trial: 2, iter: 1000, curr loss: 1.273024320602417, avg loss: 1.3144611006975173\n",
      "trial: 2, iter: 1200, curr loss: 1.324950933456421, avg loss: 1.3098906534910202\n",
      "trial: 2, iter: 1400, curr loss: 1.2925857305526733, avg loss: 1.308984454870224\n",
      "trial: 2, iter: 1600, curr loss: 1.3192152976989746, avg loss: 1.3015081810951232\n",
      "trial: 2, iter: 1800, curr loss: 1.2878230810165405, avg loss: 1.297563841342926\n",
      "trial: 2, iter: 2000, curr loss: 1.2935458421707153, avg loss: 1.2868571412563323\n",
      "trial: 2, iter: 2200, curr loss: 1.3060098886489868, avg loss: 1.2858645915985107\n",
      "trial: 2, iter: 2400, curr loss: 1.248505711555481, avg loss: 1.2773286610841752\n",
      "trial: 2, iter: 2600, curr loss: 1.2862647771835327, avg loss: 1.2785327112674714\n",
      "trial: 2, iter: 2800, curr loss: 1.2169595956802368, avg loss: 1.2745079237222672\n",
      "trial: 2, iter: 3000, curr loss: 1.2796685695648193, avg loss: 1.272325599193573\n",
      "trial: 2, iter: 3200, curr loss: 1.2416348457336426, avg loss: 1.270038434267044\n",
      "trial: 2, iter: 3400, curr loss: 1.2598236799240112, avg loss: 1.2685602647066117\n",
      "trial: 2, iter: 3600, curr loss: 1.2687321901321411, avg loss: 1.268360396027565\n",
      "trial: 2, iter: 3800, curr loss: 1.213924527168274, avg loss: 1.2673168700933457\n",
      "trial: 2, iter: 4000, curr loss: 1.277503490447998, avg loss: 1.267889023423195\n",
      "trial: 2, iter: 4200, curr loss: 1.2774375677108765, avg loss: 1.2654302686452865\n",
      "trial: 2, iter: 4400, curr loss: 1.2450687885284424, avg loss: 1.2688783138990403\n",
      "trial: 2, iter: 4600, curr loss: 1.2967318296432495, avg loss: 1.265102646946907\n",
      "trial: 2, iter: 4800, curr loss: 1.244702696800232, avg loss: 1.2656100553274154\n",
      "trial: 2, iter: 5000, curr loss: 1.2765815258026123, avg loss: 1.2636201798915863\n",
      "trial: 2, iter: 5200, curr loss: 1.2927017211914062, avg loss: 1.2651729077100753\n",
      "trial: 2, iter: 5400, curr loss: 1.2106317281723022, avg loss: 1.266889488697052\n",
      "trial: 2, iter: 5600, curr loss: 1.2671780586242676, avg loss: 1.2655030077695846\n",
      "trial: 2, iter: 5800, curr loss: 1.2709327936172485, avg loss: 1.2673825752735137\n",
      "trial: 2, iter: 6000, curr loss: 1.244430422782898, avg loss: 1.262474370598793\n",
      "trial: 2, iter: 6200, curr loss: 1.2402502298355103, avg loss: 1.2671076756715776\n",
      "trial: 2, iter: 6400, curr loss: 1.2503808736801147, avg loss: 1.265097460746765\n",
      "trial: 2, iter: 6600, curr loss: 1.204131841659546, avg loss: 1.263984894156456\n",
      "trial: 2, iter: 6800, curr loss: 1.2231435775756836, avg loss: 1.2661224120855332\n",
      "trial: 2, iter: 7000, curr loss: 1.2851835489273071, avg loss: 1.263590271472931\n",
      "trial: 2, iter: 7200, curr loss: 1.2333744764328003, avg loss: 1.2651475936174392\n",
      "trial: 2, iter: 7400, curr loss: 1.2615875005722046, avg loss: 1.2656559002399446\n",
      "trial: 2, iter: 7600, curr loss: 1.2612336874008179, avg loss: 1.2612139940261842\n",
      "trial: 2, iter: 7800, curr loss: 1.2345532178878784, avg loss: 1.2607750910520554\n",
      "trial: 2, iter: 8000, curr loss: 1.2817888259887695, avg loss: 1.2674187570810318\n",
      "trial: 2, iter: 8200, curr loss: 1.2585402727127075, avg loss: 1.262403853535652\n",
      "trial: 2, iter: 8400, curr loss: 1.2580169439315796, avg loss: 1.2632818120718001\n",
      "trial: 2, iter: 8600, curr loss: 1.2297927141189575, avg loss: 1.265664018392563\n",
      "trial: 2, iter: 8800, curr loss: 1.202622652053833, avg loss: 1.2619929695129395\n",
      "trial: 2, iter: 9000, curr loss: 1.2210346460342407, avg loss: 1.2663993537425995\n",
      "trial: 2, iter: 9200, curr loss: 1.2781869173049927, avg loss: 1.2620946949720382\n",
      "trial: 2, iter: 9400, curr loss: 1.266425371170044, avg loss: 1.2617232090234756\n",
      "trial: 2, iter: 9600, curr loss: 1.3051296472549438, avg loss: 1.2631779485940933\n",
      "trial: 2, iter: 9800, curr loss: 1.2730573415756226, avg loss: 1.2622130990028382\n",
      "trial: 2, iter: 10000, curr loss: 1.2416480779647827, avg loss: 1.2588817405700683\n",
      "trial: 2, iter: 10200, curr loss: 1.245802402496338, avg loss: 1.2637653952836991\n",
      "trial: 2, iter: 10400, curr loss: 1.2702540159225464, avg loss: 1.2623406141996383\n",
      "trial: 2, iter: 10600, curr loss: 1.2418502569198608, avg loss: 1.2625470316410066\n",
      "trial: 2, iter: 10800, curr loss: 1.2683415412902832, avg loss: 1.2614355033636093\n",
      "trial: 2, iter: 11000, curr loss: 1.215282917022705, avg loss: 1.265158177614212\n",
      "trial: 2, iter: 11200, curr loss: 1.2816036939620972, avg loss: 1.2619226843118667\n",
      "trial: 2, iter: 11400, curr loss: 1.256211519241333, avg loss: 1.2619777727127075\n",
      "trial: 2, iter: 11600, curr loss: 1.2384908199310303, avg loss: 1.2620701152086258\n",
      "trial: 2, iter: 11800, curr loss: 1.2695050239562988, avg loss: 1.2581564104557037\n",
      "trial: 2, iter: 12000, curr loss: 1.2684006690979004, avg loss: 1.2630665689706801\n",
      "trial: 2, iter: 12200, curr loss: 1.245469570159912, avg loss: 1.2612024468183518\n",
      "trial: 2, iter: 12400, curr loss: 1.277082920074463, avg loss: 1.2604685926437378\n",
      "trial: 2, iter: 12600, curr loss: 1.2457462549209595, avg loss: 1.2630664640665055\n",
      "trial: 2, iter: 12800, curr loss: 1.2637044191360474, avg loss: 1.2624026489257814\n",
      "trial: 2, iter: 13000, curr loss: 1.2711578607559204, avg loss: 1.2607080030441284\n",
      "trial: 2, iter: 13200, curr loss: 1.263384222984314, avg loss: 1.2585799872875214\n",
      "trial: 2, iter: 13400, curr loss: 1.261257529258728, avg loss: 1.2626673936843873\n",
      "trial: 2, iter: 13600, curr loss: 1.2332879304885864, avg loss: 1.261559121608734\n",
      "trial: 2, iter: 13800, curr loss: 1.2695223093032837, avg loss: 1.2617074429988862\n",
      "trial: 2, iter: 14000, curr loss: 1.2806792259216309, avg loss: 1.2589987510442733\n",
      "trial: 2, iter: 14200, curr loss: 1.2599809169769287, avg loss: 1.2634589195251464\n",
      "trial: 2, iter: 14400, curr loss: 1.2598711252212524, avg loss: 1.26200390458107\n",
      "trial: 2, iter: 14600, curr loss: 1.239858865737915, avg loss: 1.264205015897751\n",
      "trial: 2, iter: 14800, curr loss: 1.2152864933013916, avg loss: 1.2619607692956925\n",
      "trial: 2, iter: 15000, curr loss: 1.2311429977416992, avg loss: 1.2635244613885879\n",
      "trial: 2, iter: 15200, curr loss: 1.3326748609542847, avg loss: 1.2625808519124986\n",
      "trial: 2, iter: 15400, curr loss: 1.2428579330444336, avg loss: 1.2626363801956177\n",
      "trial: 2, iter: 15600, curr loss: 1.2650055885314941, avg loss: 1.2617533230781555\n",
      "trial: 2, ldr: 0.25346916913986206\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3842343091964722, avg loss: 1.3873095524311065\n",
      "trial: 3, iter: 400, curr loss: 1.3708035945892334, avg loss: 1.3822253549098968\n",
      "trial: 3, iter: 600, curr loss: 1.318158745765686, avg loss: 1.349040384888649\n",
      "trial: 3, iter: 800, curr loss: 1.3255430459976196, avg loss: 1.3235918009281158\n",
      "trial: 3, iter: 1000, curr loss: 1.2985215187072754, avg loss: 1.3197517198324205\n",
      "trial: 3, iter: 1200, curr loss: 1.3261723518371582, avg loss: 1.310415305495262\n",
      "trial: 3, iter: 1400, curr loss: 1.2745429277420044, avg loss: 1.3075381463766098\n",
      "trial: 3, iter: 1600, curr loss: 1.2778502702713013, avg loss: 1.2999643796682359\n",
      "trial: 3, iter: 1800, curr loss: 1.3016732931137085, avg loss: 1.2995069020986556\n",
      "trial: 3, iter: 2000, curr loss: 1.2582181692123413, avg loss: 1.2828017562627791\n",
      "trial: 3, iter: 2200, curr loss: 1.2551418542861938, avg loss: 1.279654089808464\n",
      "trial: 3, iter: 2400, curr loss: 1.2702853679656982, avg loss: 1.2790532952547073\n",
      "trial: 3, iter: 2600, curr loss: 1.28003990650177, avg loss: 1.2754263693094254\n",
      "trial: 3, iter: 2800, curr loss: 1.2702018022537231, avg loss: 1.272745726108551\n",
      "trial: 3, iter: 3000, curr loss: 1.3006205558776855, avg loss: 1.2711586725711823\n",
      "trial: 3, iter: 3200, curr loss: 1.2127612829208374, avg loss: 1.269430819749832\n",
      "trial: 3, iter: 3400, curr loss: 1.3045903444290161, avg loss: 1.2687387669086456\n",
      "trial: 3, iter: 3600, curr loss: 1.2295764684677124, avg loss: 1.2676372247934342\n",
      "trial: 3, iter: 3800, curr loss: 1.2468414306640625, avg loss: 1.2695339357852935\n",
      "trial: 3, iter: 4000, curr loss: 1.273521065711975, avg loss: 1.2689685410261153\n",
      "trial: 3, iter: 4200, curr loss: 1.2923613786697388, avg loss: 1.269269033074379\n",
      "trial: 3, iter: 4400, curr loss: 1.2868351936340332, avg loss: 1.2660673105716704\n",
      "trial: 3, iter: 4600, curr loss: 1.24648916721344, avg loss: 1.2674769884347916\n",
      "trial: 3, iter: 4800, curr loss: 1.2467089891433716, avg loss: 1.2664196491241455\n",
      "trial: 3, iter: 5000, curr loss: 1.2898367643356323, avg loss: 1.2676958060264587\n",
      "trial: 3, iter: 5200, curr loss: 1.2487595081329346, avg loss: 1.267043150663376\n",
      "trial: 3, iter: 5400, curr loss: 1.2986961603164673, avg loss: 1.268226667046547\n",
      "trial: 3, iter: 5600, curr loss: 1.2588528394699097, avg loss: 1.2677060359716414\n",
      "trial: 3, iter: 5800, curr loss: 1.2014049291610718, avg loss: 1.2630293476581573\n",
      "trial: 3, iter: 6000, curr loss: 1.305320143699646, avg loss: 1.268470128774643\n",
      "trial: 3, iter: 6200, curr loss: 1.2967802286148071, avg loss: 1.263890261054039\n",
      "trial: 3, iter: 6400, curr loss: 1.3112390041351318, avg loss: 1.2655145394802094\n",
      "trial: 3, iter: 6600, curr loss: 1.3077958822250366, avg loss: 1.267035374045372\n",
      "trial: 3, iter: 6800, curr loss: 1.2653931379318237, avg loss: 1.265902870297432\n",
      "trial: 3, iter: 7000, curr loss: 1.233116626739502, avg loss: 1.2638151693344115\n",
      "trial: 3, iter: 7200, curr loss: 1.3066805601119995, avg loss: 1.2643672531843186\n",
      "trial: 3, iter: 7400, curr loss: 1.2565441131591797, avg loss: 1.2654680448770523\n",
      "trial: 3, iter: 7600, curr loss: 1.2641741037368774, avg loss: 1.268840321302414\n",
      "trial: 3, iter: 7800, curr loss: 1.2935104370117188, avg loss: 1.2676676309108734\n",
      "trial: 3, iter: 8000, curr loss: 1.3071149587631226, avg loss: 1.2688201493024827\n",
      "trial: 3, iter: 8200, curr loss: 1.2658931016921997, avg loss: 1.2657924300432206\n",
      "trial: 3, iter: 8400, curr loss: 1.2501869201660156, avg loss: 1.264122257232666\n",
      "trial: 3, iter: 8600, curr loss: 1.2974050045013428, avg loss: 1.2643821001052857\n",
      "trial: 3, iter: 8800, curr loss: 1.3021913766860962, avg loss: 1.265795999765396\n",
      "trial: 3, iter: 9000, curr loss: 1.2587707042694092, avg loss: 1.264047919511795\n",
      "trial: 3, iter: 9200, curr loss: 1.279834508895874, avg loss: 1.2633487451076508\n",
      "trial: 3, iter: 9400, curr loss: 1.2684028148651123, avg loss: 1.264430513381958\n",
      "trial: 3, iter: 9600, curr loss: 1.2585760354995728, avg loss: 1.2629988592863084\n",
      "trial: 3, iter: 9800, curr loss: 1.2321157455444336, avg loss: 1.2600668579339982\n",
      "trial: 3, iter: 10000, curr loss: 1.2759841680526733, avg loss: 1.2624581146240235\n",
      "trial: 3, iter: 10200, curr loss: 1.2632330656051636, avg loss: 1.2617345982789994\n",
      "trial: 3, iter: 10400, curr loss: 1.2528306245803833, avg loss: 1.2643983602523803\n",
      "trial: 3, iter: 10600, curr loss: 1.260288953781128, avg loss: 1.2635566848516464\n",
      "trial: 3, iter: 10800, curr loss: 1.256619930267334, avg loss: 1.2647881150245666\n",
      "trial: 3, iter: 11000, curr loss: 1.2856751680374146, avg loss: 1.2608661139011383\n",
      "trial: 3, iter: 11200, curr loss: 1.2712132930755615, avg loss: 1.2652363973855971\n",
      "trial: 3, iter: 11400, curr loss: 1.264815092086792, avg loss: 1.2654796880483627\n",
      "trial: 3, iter: 11600, curr loss: 1.2783746719360352, avg loss: 1.2641868215799332\n",
      "trial: 3, iter: 11800, curr loss: 1.290389895439148, avg loss: 1.2651977521181106\n",
      "trial: 3, iter: 12000, curr loss: 1.2801072597503662, avg loss: 1.2641676127910615\n",
      "trial: 3, iter: 12200, curr loss: 1.3021693229675293, avg loss: 1.2619850301742555\n",
      "trial: 3, iter: 12400, curr loss: 1.2360438108444214, avg loss: 1.265736991763115\n",
      "trial: 3, iter: 12600, curr loss: 1.2319155931472778, avg loss: 1.2636834275722504\n",
      "trial: 3, iter: 12800, curr loss: 1.2608147859573364, avg loss: 1.2609469139575957\n",
      "trial: 3, iter: 13000, curr loss: 1.3051730394363403, avg loss: 1.2630408358573915\n",
      "trial: 3, iter: 13200, curr loss: 1.3072715997695923, avg loss: 1.2617829233407973\n",
      "trial: 3, iter: 13400, curr loss: 1.290662169456482, avg loss: 1.2581246399879455\n",
      "trial: 3, iter: 13600, curr loss: 1.2423408031463623, avg loss: 1.25928484082222\n",
      "trial: 3, iter: 13800, curr loss: 1.2650854587554932, avg loss: 1.2631874930858613\n",
      "trial: 3, iter: 14000, curr loss: 1.1913598775863647, avg loss: 1.261954430937767\n",
      "trial: 3, iter: 14200, curr loss: 1.2092469930648804, avg loss: 1.2605855214595794\n",
      "trial: 3, iter: 14400, curr loss: 1.2533258199691772, avg loss: 1.2617960005998612\n",
      "trial: 3, iter: 14600, curr loss: 1.2936089038848877, avg loss: 1.2626403427124024\n",
      "trial: 3, iter: 14800, curr loss: 1.2412564754486084, avg loss: 1.2623606956005096\n",
      "trial: 3, iter: 15000, curr loss: 1.2036817073822021, avg loss: 1.260898683667183\n",
      "trial: 3, iter: 15200, curr loss: 1.231001853942871, avg loss: 1.2626839017868041\n",
      "trial: 3, iter: 15400, curr loss: 1.2669087648391724, avg loss: 1.2631766217947007\n",
      "trial: 3, iter: 15600, curr loss: 1.243077039718628, avg loss: 1.2611577254533768\n",
      "trial: 3, ldr: 0.2876432538032532\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3862723112106323, avg loss: 1.3871690887212753\n",
      "trial: 4, iter: 400, curr loss: 1.3780261278152466, avg loss: 1.3838428509235383\n",
      "trial: 4, iter: 600, curr loss: 1.3408067226409912, avg loss: 1.353794143795967\n",
      "trial: 4, iter: 800, curr loss: 1.274388313293457, avg loss: 1.3204543668031692\n",
      "trial: 4, iter: 1000, curr loss: 1.27993643283844, avg loss: 1.3160498601198196\n",
      "trial: 4, iter: 1200, curr loss: 1.2991032600402832, avg loss: 1.3091958826780319\n",
      "trial: 4, iter: 1400, curr loss: 1.2873749732971191, avg loss: 1.3040494740009307\n",
      "trial: 4, iter: 1600, curr loss: 1.3082730770111084, avg loss: 1.2979257053136826\n",
      "trial: 4, iter: 1800, curr loss: 1.3105356693267822, avg loss: 1.289374167919159\n",
      "trial: 4, iter: 2000, curr loss: 1.2695099115371704, avg loss: 1.2815370017290115\n",
      "trial: 4, iter: 2200, curr loss: 1.3313167095184326, avg loss: 1.2783330798149108\n",
      "trial: 4, iter: 2400, curr loss: 1.28453528881073, avg loss: 1.2767704290151596\n",
      "trial: 4, iter: 2600, curr loss: 1.2651833295822144, avg loss: 1.272723127603531\n",
      "trial: 4, iter: 2800, curr loss: 1.2855433225631714, avg loss: 1.2737039029598236\n",
      "trial: 4, iter: 3000, curr loss: 1.288540244102478, avg loss: 1.271329447031021\n",
      "trial: 4, iter: 3200, curr loss: 1.2654191255569458, avg loss: 1.269154622554779\n",
      "trial: 4, iter: 3400, curr loss: 1.2836573123931885, avg loss: 1.2699911558628083\n",
      "trial: 4, iter: 3600, curr loss: 1.2781622409820557, avg loss: 1.2675559204816818\n",
      "trial: 4, iter: 3800, curr loss: 1.3195903301239014, avg loss: 1.2678138893842696\n",
      "trial: 4, iter: 4000, curr loss: 1.2384850978851318, avg loss: 1.266604923605919\n",
      "trial: 4, iter: 4200, curr loss: 1.2680790424346924, avg loss: 1.2681857138872146\n",
      "trial: 4, iter: 4400, curr loss: 1.3066227436065674, avg loss: 1.266396501660347\n",
      "trial: 4, iter: 4600, curr loss: 1.2851635217666626, avg loss: 1.2624058401584626\n",
      "trial: 4, iter: 4800, curr loss: 1.257002592086792, avg loss: 1.2677856051921845\n",
      "trial: 4, iter: 5000, curr loss: 1.2449625730514526, avg loss: 1.2667726451158523\n",
      "trial: 4, iter: 5200, curr loss: 1.215567946434021, avg loss: 1.2638329392671586\n",
      "trial: 4, iter: 5400, curr loss: 1.2469779253005981, avg loss: 1.26532734811306\n",
      "trial: 4, iter: 5600, curr loss: 1.2439459562301636, avg loss: 1.2630644023418427\n",
      "trial: 4, iter: 5800, curr loss: 1.2848585844039917, avg loss: 1.264978066086769\n",
      "trial: 4, iter: 6000, curr loss: 1.2716606855392456, avg loss: 1.266187784075737\n",
      "trial: 4, iter: 6200, curr loss: 1.2464665174484253, avg loss: 1.2653232896327973\n",
      "trial: 4, iter: 6400, curr loss: 1.282356858253479, avg loss: 1.2645702975988389\n",
      "trial: 4, iter: 6600, curr loss: 1.2781944274902344, avg loss: 1.2641044414043427\n",
      "trial: 4, iter: 6800, curr loss: 1.2227002382278442, avg loss: 1.2669413524866104\n",
      "trial: 4, iter: 7000, curr loss: 1.2886184453964233, avg loss: 1.2662361800670623\n",
      "trial: 4, iter: 7200, curr loss: 1.276651382446289, avg loss: 1.2616958230733872\n",
      "trial: 4, iter: 7400, curr loss: 1.2553728818893433, avg loss: 1.2650710356235504\n",
      "trial: 4, iter: 7600, curr loss: 1.2486740350723267, avg loss: 1.2618072432279588\n",
      "trial: 4, iter: 7800, curr loss: 1.2469180822372437, avg loss: 1.2647151905298233\n",
      "trial: 4, iter: 8000, curr loss: 1.2424910068511963, avg loss: 1.2634949064254761\n",
      "trial: 4, iter: 8200, curr loss: 1.2232719659805298, avg loss: 1.2611196321249007\n",
      "trial: 4, iter: 8400, curr loss: 1.2290523052215576, avg loss: 1.264886843562126\n",
      "trial: 4, iter: 8600, curr loss: 1.2650763988494873, avg loss: 1.2669956386089325\n",
      "trial: 4, iter: 8800, curr loss: 1.2627432346343994, avg loss: 1.2642061603069306\n",
      "trial: 4, iter: 9000, curr loss: 1.2654566764831543, avg loss: 1.262740597128868\n",
      "trial: 4, iter: 9200, curr loss: 1.2656892538070679, avg loss: 1.2633865016698838\n",
      "trial: 4, iter: 9400, curr loss: 1.2644069194793701, avg loss: 1.2662656486034394\n",
      "trial: 4, iter: 9600, curr loss: 1.2774828672409058, avg loss: 1.2643211317062377\n",
      "trial: 4, iter: 9800, curr loss: 1.2757388353347778, avg loss: 1.2634689277410507\n",
      "trial: 4, iter: 10000, curr loss: 1.2756736278533936, avg loss: 1.2639460861682892\n",
      "trial: 4, iter: 10200, curr loss: 1.2771378755569458, avg loss: 1.2649382531642914\n",
      "trial: 4, iter: 10400, curr loss: 1.2857413291931152, avg loss: 1.2627730458974837\n",
      "trial: 4, iter: 10600, curr loss: 1.2464852333068848, avg loss: 1.2637520343065263\n",
      "trial: 4, iter: 10800, curr loss: 1.284546136856079, avg loss: 1.2605706322193146\n",
      "trial: 4, iter: 11000, curr loss: 1.2512627840042114, avg loss: 1.264299075603485\n",
      "trial: 4, iter: 11200, curr loss: 1.2572543621063232, avg loss: 1.26430304646492\n",
      "trial: 4, iter: 11400, curr loss: 1.238388180732727, avg loss: 1.2633241099119186\n",
      "trial: 4, iter: 11600, curr loss: 1.271977186203003, avg loss: 1.264429584145546\n",
      "trial: 4, iter: 11800, curr loss: 1.2230592966079712, avg loss: 1.263850073814392\n",
      "trial: 4, iter: 12000, curr loss: 1.284851312637329, avg loss: 1.261896589398384\n",
      "trial: 4, iter: 12200, curr loss: 1.269044041633606, avg loss: 1.2649201673269272\n",
      "trial: 4, iter: 12400, curr loss: 1.279847264289856, avg loss: 1.2623117727041244\n",
      "trial: 4, iter: 12600, curr loss: 1.2520564794540405, avg loss: 1.2648196214437484\n",
      "trial: 4, iter: 12800, curr loss: 1.3150382041931152, avg loss: 1.26263633787632\n",
      "trial: 4, iter: 13000, curr loss: 1.2325878143310547, avg loss: 1.2619783085584642\n",
      "trial: 4, iter: 13200, curr loss: 1.2852815389633179, avg loss: 1.2625576627254487\n",
      "trial: 4, iter: 13400, curr loss: 1.2868599891662598, avg loss: 1.2618049681186676\n",
      "trial: 4, iter: 13600, curr loss: 1.2726421356201172, avg loss: 1.2619939315319062\n",
      "trial: 4, iter: 13800, curr loss: 1.2786481380462646, avg loss: 1.259774796962738\n",
      "trial: 4, iter: 14000, curr loss: 1.2284306287765503, avg loss: 1.26317548930645\n",
      "trial: 4, iter: 14200, curr loss: 1.239741563796997, avg loss: 1.2599705809354782\n",
      "trial: 4, iter: 14400, curr loss: 1.2762808799743652, avg loss: 1.2631938827037812\n",
      "trial: 4, iter: 14600, curr loss: 1.2192133665084839, avg loss: 1.260738376379013\n",
      "trial: 4, iter: 14800, curr loss: 1.2777403593063354, avg loss: 1.2612470948696137\n",
      "trial: 4, iter: 15000, curr loss: 1.2519088983535767, avg loss: 1.2599237668514252\n",
      "trial: 4, iter: 15200, curr loss: 1.267585039138794, avg loss: 1.2629895794391632\n",
      "trial: 4, iter: 15400, curr loss: 1.2242255210876465, avg loss: 1.2608304238319397\n",
      "trial: 4, iter: 15600, curr loss: 1.278812289237976, avg loss: 1.2608023226261138\n",
      "trial: 4, ldr: 0.26112425327301025\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3875304460525513, avg loss: 1.3865717488527298\n",
      "trial: 5, iter: 400, curr loss: 1.358373761177063, avg loss: 1.3784818363189697\n",
      "trial: 5, iter: 600, curr loss: 1.3211991786956787, avg loss: 1.341285030245781\n",
      "trial: 5, iter: 800, curr loss: 1.3262591361999512, avg loss: 1.3235559695959092\n",
      "trial: 5, iter: 1000, curr loss: 1.327587604522705, avg loss: 1.313552240729332\n",
      "trial: 5, iter: 1200, curr loss: 1.2961033582687378, avg loss: 1.3113100928068162\n",
      "trial: 5, iter: 1400, curr loss: 1.2907330989837646, avg loss: 1.3034998273849487\n",
      "trial: 5, iter: 1600, curr loss: 1.2952662706375122, avg loss: 1.2938422018289566\n",
      "trial: 5, iter: 1800, curr loss: 1.2599608898162842, avg loss: 1.2860758131742478\n",
      "trial: 5, iter: 2000, curr loss: 1.2666537761688232, avg loss: 1.2830175536870956\n",
      "trial: 5, iter: 2200, curr loss: 1.2813458442687988, avg loss: 1.2792551499605178\n",
      "trial: 5, iter: 2400, curr loss: 1.2662112712860107, avg loss: 1.2727817672491073\n",
      "trial: 5, iter: 2600, curr loss: 1.2516648769378662, avg loss: 1.2684610718488694\n",
      "trial: 5, iter: 2800, curr loss: 1.252777338027954, avg loss: 1.2711425644159318\n",
      "trial: 5, iter: 3000, curr loss: 1.2568016052246094, avg loss: 1.2695776623487474\n",
      "trial: 5, iter: 3200, curr loss: 1.2822110652923584, avg loss: 1.2710650646686554\n",
      "trial: 5, iter: 3400, curr loss: 1.2516981363296509, avg loss: 1.2659615248441696\n",
      "trial: 5, iter: 3600, curr loss: 1.264356255531311, avg loss: 1.2670084249973297\n",
      "trial: 5, iter: 3800, curr loss: 1.2934659719467163, avg loss: 1.2683938980102538\n",
      "trial: 5, iter: 4000, curr loss: 1.25300931930542, avg loss: 1.267519189119339\n",
      "trial: 5, iter: 4200, curr loss: 1.2699261903762817, avg loss: 1.268054919242859\n",
      "trial: 5, iter: 4400, curr loss: 1.3320434093475342, avg loss: 1.265484842658043\n",
      "trial: 5, iter: 4600, curr loss: 1.2545827627182007, avg loss: 1.265398463010788\n",
      "trial: 5, iter: 4800, curr loss: 1.2927227020263672, avg loss: 1.2663883203268052\n",
      "trial: 5, iter: 5000, curr loss: 1.2666152715682983, avg loss: 1.2642714011669158\n",
      "trial: 5, iter: 5200, curr loss: 1.280940294265747, avg loss: 1.2662977296113969\n",
      "trial: 5, iter: 5400, curr loss: 1.2606486082077026, avg loss: 1.2644293665885926\n",
      "trial: 5, iter: 5600, curr loss: 1.2876551151275635, avg loss: 1.265687226653099\n",
      "trial: 5, iter: 5800, curr loss: 1.2641316652297974, avg loss: 1.2665014904737473\n",
      "trial: 5, iter: 6000, curr loss: 1.2887499332427979, avg loss: 1.2649102091789246\n",
      "trial: 5, iter: 6200, curr loss: 1.308900237083435, avg loss: 1.2637758630514144\n",
      "trial: 5, iter: 6400, curr loss: 1.3090375661849976, avg loss: 1.2662482064962388\n",
      "trial: 5, iter: 6600, curr loss: 1.255975365638733, avg loss: 1.2653789174556733\n",
      "trial: 5, iter: 6800, curr loss: 1.2982518672943115, avg loss: 1.26363605260849\n",
      "trial: 5, iter: 7000, curr loss: 1.2878214120864868, avg loss: 1.2657351464033126\n",
      "trial: 5, iter: 7200, curr loss: 1.283747673034668, avg loss: 1.2641096287965774\n",
      "trial: 5, iter: 7400, curr loss: 1.2847459316253662, avg loss: 1.2633762723207473\n",
      "trial: 5, iter: 7600, curr loss: 1.2955878973007202, avg loss: 1.2634292078018188\n",
      "trial: 5, iter: 7800, curr loss: 1.2937484979629517, avg loss: 1.2647160744667054\n",
      "trial: 5, iter: 8000, curr loss: 1.263119101524353, avg loss: 1.2641776657104493\n",
      "trial: 5, iter: 8200, curr loss: 1.2546515464782715, avg loss: 1.2631827688217163\n",
      "trial: 5, iter: 8400, curr loss: 1.2526910305023193, avg loss: 1.2598460364341735\n",
      "trial: 5, iter: 8600, curr loss: 1.2605414390563965, avg loss: 1.2604860961437225\n",
      "trial: 5, iter: 8800, curr loss: 1.2822626829147339, avg loss: 1.261506693959236\n",
      "trial: 5, iter: 9000, curr loss: 1.3131669759750366, avg loss: 1.2602610582113265\n",
      "trial: 5, iter: 9200, curr loss: 1.2451622486114502, avg loss: 1.2628209400177002\n",
      "trial: 5, iter: 9400, curr loss: 1.2834192514419556, avg loss: 1.2618646919727325\n",
      "trial: 5, iter: 9600, curr loss: 1.2273346185684204, avg loss: 1.262565250992775\n",
      "trial: 5, iter: 9800, curr loss: 1.227294683456421, avg loss: 1.2640475696325302\n",
      "trial: 5, iter: 10000, curr loss: 1.2687475681304932, avg loss: 1.2631238025426865\n",
      "trial: 5, iter: 10200, curr loss: 1.2932816743850708, avg loss: 1.2624712777137757\n",
      "trial: 5, iter: 10400, curr loss: 1.2533098459243774, avg loss: 1.2628980141878128\n",
      "trial: 5, iter: 10600, curr loss: 1.2824465036392212, avg loss: 1.2643599486351014\n",
      "trial: 5, iter: 10800, curr loss: 1.2725975513458252, avg loss: 1.2609872740507126\n",
      "trial: 5, iter: 11000, curr loss: 1.256768822669983, avg loss: 1.2601762706041335\n",
      "trial: 5, iter: 11200, curr loss: 1.2513350248336792, avg loss: 1.2622485959529877\n",
      "trial: 5, iter: 11400, curr loss: 1.303528904914856, avg loss: 1.2607962030172348\n",
      "trial: 5, iter: 11600, curr loss: 1.2588893175125122, avg loss: 1.2622665387392045\n",
      "trial: 5, iter: 11800, curr loss: 1.2615699768066406, avg loss: 1.2629627567529678\n",
      "trial: 5, iter: 12000, curr loss: 1.2706445455551147, avg loss: 1.2623641335964202\n",
      "trial: 5, iter: 12200, curr loss: 1.240808367729187, avg loss: 1.2615562731027603\n",
      "trial: 5, iter: 12400, curr loss: 1.2747342586517334, avg loss: 1.262589049935341\n",
      "trial: 5, iter: 12600, curr loss: 1.2880321741104126, avg loss: 1.2589306968450547\n",
      "trial: 5, iter: 12800, curr loss: 1.258460521697998, avg loss: 1.2617628121376037\n",
      "trial: 5, iter: 13000, curr loss: 1.2432751655578613, avg loss: 1.2637271255254745\n",
      "trial: 5, iter: 13200, curr loss: 1.2471201419830322, avg loss: 1.2590170753002168\n",
      "trial: 5, iter: 13400, curr loss: 1.244241714477539, avg loss: 1.2632437556982041\n",
      "trial: 5, iter: 13600, curr loss: 1.243463158607483, avg loss: 1.2633211570978164\n",
      "trial: 5, iter: 13800, curr loss: 1.2242194414138794, avg loss: 1.262866776585579\n",
      "trial: 5, iter: 14000, curr loss: 1.3175512552261353, avg loss: 1.262403439283371\n",
      "trial: 5, iter: 14200, curr loss: 1.2742993831634521, avg loss: 1.2622717052698136\n",
      "trial: 5, iter: 14400, curr loss: 1.236505389213562, avg loss: 1.262985230088234\n",
      "trial: 5, iter: 14600, curr loss: 1.254354476928711, avg loss: 1.2652537512779236\n",
      "trial: 5, iter: 14800, curr loss: 1.2561476230621338, avg loss: 1.2598649972677232\n",
      "trial: 5, iter: 15000, curr loss: 1.2867586612701416, avg loss: 1.261163199543953\n",
      "trial: 5, iter: 15200, curr loss: 1.2858079671859741, avg loss: 1.2605515521764756\n",
      "trial: 5, iter: 15400, curr loss: 1.2772332429885864, avg loss: 1.2575972062349319\n",
      "trial: 5, iter: 15600, curr loss: 1.250913143157959, avg loss: 1.2614188426733017\n",
      "trial: 5, ldr: 0.2362891584634781\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26594564616680144\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3863834142684937, avg loss: 1.3866299229860306\n",
      "trial: 1, iter: 400, curr loss: 1.3610649108886719, avg loss: 1.3783774650096894\n",
      "trial: 1, iter: 600, curr loss: 1.3206077814102173, avg loss: 1.3397081398963928\n",
      "trial: 1, iter: 800, curr loss: 1.2960327863693237, avg loss: 1.3219051748514175\n",
      "trial: 1, iter: 1000, curr loss: 1.2896028757095337, avg loss: 1.312328997850418\n",
      "trial: 1, iter: 1200, curr loss: 1.32187819480896, avg loss: 1.3096059727668763\n",
      "trial: 1, iter: 1400, curr loss: 1.301651120185852, avg loss: 1.299183605313301\n",
      "trial: 1, iter: 1600, curr loss: 1.3166357278823853, avg loss: 1.29492844581604\n",
      "trial: 1, iter: 1800, curr loss: 1.2801895141601562, avg loss: 1.2870738679170608\n",
      "trial: 1, iter: 2000, curr loss: 1.2640557289123535, avg loss: 1.2825974541902543\n",
      "trial: 1, iter: 2200, curr loss: 1.2555460929870605, avg loss: 1.2767582547664642\n",
      "trial: 1, iter: 2400, curr loss: 1.2854231595993042, avg loss: 1.2720694506168366\n",
      "trial: 1, iter: 2600, curr loss: 1.2737400531768799, avg loss: 1.270766664147377\n",
      "trial: 1, iter: 2800, curr loss: 1.2550201416015625, avg loss: 1.273107070326805\n",
      "trial: 1, iter: 3000, curr loss: 1.2832579612731934, avg loss: 1.2689282488822937\n",
      "trial: 1, iter: 3200, curr loss: 1.2931121587753296, avg loss: 1.2682672435045241\n",
      "trial: 1, iter: 3400, curr loss: 1.2525818347930908, avg loss: 1.27035400390625\n",
      "trial: 1, iter: 3600, curr loss: 1.2755303382873535, avg loss: 1.270953769683838\n",
      "trial: 1, iter: 3800, curr loss: 1.2307125329971313, avg loss: 1.2681258344650268\n",
      "trial: 1, iter: 4000, curr loss: 1.2816109657287598, avg loss: 1.269778596162796\n",
      "trial: 1, iter: 4200, curr loss: 1.2796863317489624, avg loss: 1.2689158809185028\n",
      "trial: 1, iter: 4400, curr loss: 1.262493371963501, avg loss: 1.2675952649116515\n",
      "trial: 1, iter: 4600, curr loss: 1.2826471328735352, avg loss: 1.2660812628269196\n",
      "trial: 1, iter: 4800, curr loss: 1.2787381410598755, avg loss: 1.2635061287879943\n",
      "trial: 1, iter: 5000, curr loss: 1.284970760345459, avg loss: 1.2644300198554992\n",
      "trial: 1, iter: 5200, curr loss: 1.260354995727539, avg loss: 1.268477558493614\n",
      "trial: 1, iter: 5400, curr loss: 1.2579156160354614, avg loss: 1.2648262256383895\n",
      "trial: 1, iter: 5600, curr loss: 1.2924078702926636, avg loss: 1.2675599676370621\n",
      "trial: 1, iter: 5800, curr loss: 1.284738540649414, avg loss: 1.2656826531887055\n",
      "trial: 1, iter: 6000, curr loss: 1.2305431365966797, avg loss: 1.265961412191391\n",
      "trial: 1, iter: 6200, curr loss: 1.2130151987075806, avg loss: 1.2649483501911163\n",
      "trial: 1, iter: 6400, curr loss: 1.2718710899353027, avg loss: 1.2643453800678253\n",
      "trial: 1, iter: 6600, curr loss: 1.249027967453003, avg loss: 1.265725198984146\n",
      "trial: 1, iter: 6800, curr loss: 1.2479701042175293, avg loss: 1.262900143265724\n",
      "trial: 1, iter: 7000, curr loss: 1.2394967079162598, avg loss: 1.262337023615837\n",
      "trial: 1, iter: 7200, curr loss: 1.2625597715377808, avg loss: 1.265816366672516\n",
      "trial: 1, iter: 7400, curr loss: 1.287257432937622, avg loss: 1.262627444267273\n",
      "trial: 1, iter: 7600, curr loss: 1.2535191774368286, avg loss: 1.265606449842453\n",
      "trial: 1, iter: 7800, curr loss: 1.2744171619415283, avg loss: 1.26157053232193\n",
      "trial: 1, iter: 8000, curr loss: 1.2676212787628174, avg loss: 1.2639436328411102\n",
      "trial: 1, iter: 8200, curr loss: 1.250391960144043, avg loss: 1.2627416849136353\n",
      "trial: 1, iter: 8400, curr loss: 1.2563496828079224, avg loss: 1.2638388276100159\n",
      "trial: 1, iter: 8600, curr loss: 1.2505601644515991, avg loss: 1.263388003706932\n",
      "trial: 1, iter: 8800, curr loss: 1.2366126775741577, avg loss: 1.260215426683426\n",
      "trial: 1, iter: 9000, curr loss: 1.2613399028778076, avg loss: 1.2625629580020905\n",
      "trial: 1, iter: 9200, curr loss: 1.2500579357147217, avg loss: 1.2646568363904953\n",
      "trial: 1, iter: 9400, curr loss: 1.2939786911010742, avg loss: 1.2657066696882249\n",
      "trial: 1, iter: 9600, curr loss: 1.2552988529205322, avg loss: 1.2633971321582793\n",
      "trial: 1, iter: 9800, curr loss: 1.3045363426208496, avg loss: 1.2604807138442993\n",
      "trial: 1, iter: 10000, curr loss: 1.256001353263855, avg loss: 1.2636303555965425\n",
      "trial: 1, iter: 10200, curr loss: 1.261472463607788, avg loss: 1.263806249499321\n",
      "trial: 1, iter: 10400, curr loss: 1.2775719165802002, avg loss: 1.264025321006775\n",
      "trial: 1, iter: 10600, curr loss: 1.253699541091919, avg loss: 1.259647090435028\n",
      "trial: 1, iter: 10800, curr loss: 1.2559747695922852, avg loss: 1.263336063027382\n",
      "trial: 1, iter: 11000, curr loss: 1.2399989366531372, avg loss: 1.2641226798295975\n",
      "trial: 1, iter: 11200, curr loss: 1.2691574096679688, avg loss: 1.26382840692997\n",
      "trial: 1, iter: 11400, curr loss: 1.2750333547592163, avg loss: 1.2627445870637894\n",
      "trial: 1, iter: 11600, curr loss: 1.2771856784820557, avg loss: 1.2629814517498017\n",
      "trial: 1, iter: 11800, curr loss: 1.288887619972229, avg loss: 1.2627749115228653\n",
      "trial: 1, iter: 12000, curr loss: 1.235788345336914, avg loss: 1.2583474838733673\n",
      "trial: 1, iter: 12200, curr loss: 1.2771320343017578, avg loss: 1.262736483812332\n",
      "trial: 1, iter: 12400, curr loss: 1.2588328123092651, avg loss: 1.2609589064121247\n",
      "trial: 1, iter: 12600, curr loss: 1.225242018699646, avg loss: 1.2630505508184433\n",
      "trial: 1, iter: 12800, curr loss: 1.2702363729476929, avg loss: 1.2630412900447845\n",
      "trial: 1, iter: 13000, curr loss: 1.2450610399246216, avg loss: 1.26486409842968\n",
      "trial: 1, iter: 13200, curr loss: 1.2744483947753906, avg loss: 1.2634404069185257\n",
      "trial: 1, iter: 13400, curr loss: 1.276593565940857, avg loss: 1.2615175306797028\n",
      "trial: 1, iter: 13600, curr loss: 1.2499237060546875, avg loss: 1.26025665640831\n",
      "trial: 1, iter: 13800, curr loss: 1.2610840797424316, avg loss: 1.260075448155403\n",
      "trial: 1, iter: 14000, curr loss: 1.2945919036865234, avg loss: 1.2616957956552506\n",
      "trial: 1, iter: 14200, curr loss: 1.3320980072021484, avg loss: 1.2623981869220733\n",
      "trial: 1, iter: 14400, curr loss: 1.3056851625442505, avg loss: 1.2630757063627243\n",
      "trial: 1, iter: 14600, curr loss: 1.2349858283996582, avg loss: 1.2618609845638276\n",
      "trial: 1, iter: 14800, curr loss: 1.2266236543655396, avg loss: 1.2611846840381622\n",
      "trial: 1, iter: 15000, curr loss: 1.264528751373291, avg loss: 1.2608371925354005\n",
      "trial: 1, iter: 15200, curr loss: 1.289272665977478, avg loss: 1.2642472469806671\n",
      "trial: 1, iter: 15400, curr loss: 1.2339450120925903, avg loss: 1.2588034534454347\n",
      "trial: 1, iter: 15600, curr loss: 1.2426211833953857, avg loss: 1.261500391960144\n",
      "trial: 1, ldr: 0.22277285158634186\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.38075852394104, avg loss: 1.3864400351047517\n",
      "trial: 2, iter: 400, curr loss: 1.3561832904815674, avg loss: 1.3726260131597519\n",
      "trial: 2, iter: 600, curr loss: 1.3336362838745117, avg loss: 1.3306816053390502\n",
      "trial: 2, iter: 800, curr loss: 1.3109056949615479, avg loss: 1.3194058740139007\n",
      "trial: 2, iter: 1000, curr loss: 1.307364821434021, avg loss: 1.315707596540451\n",
      "trial: 2, iter: 1200, curr loss: 1.317067265510559, avg loss: 1.3074104076623916\n",
      "trial: 2, iter: 1400, curr loss: 1.2996182441711426, avg loss: 1.3043270111083984\n",
      "trial: 2, iter: 1600, curr loss: 1.2611433267593384, avg loss: 1.2997653383016585\n",
      "trial: 2, iter: 1800, curr loss: 1.2910822629928589, avg loss: 1.2949145978689194\n",
      "trial: 2, iter: 2000, curr loss: 1.3024753332138062, avg loss: 1.2912947481870651\n",
      "trial: 2, iter: 2200, curr loss: 1.2750118970870972, avg loss: 1.2862113952636718\n",
      "trial: 2, iter: 2400, curr loss: 1.2949707508087158, avg loss: 1.2837706661224366\n",
      "trial: 2, iter: 2600, curr loss: 1.3058959245681763, avg loss: 1.280724851489067\n",
      "trial: 2, iter: 2800, curr loss: 1.2501641511917114, avg loss: 1.2724524682760239\n",
      "trial: 2, iter: 3000, curr loss: 1.294148564338684, avg loss: 1.2710072153806686\n",
      "trial: 2, iter: 3200, curr loss: 1.2798982858657837, avg loss: 1.2672885054349898\n",
      "trial: 2, iter: 3400, curr loss: 1.2544623613357544, avg loss: 1.271230245232582\n",
      "trial: 2, iter: 3600, curr loss: 1.2429832220077515, avg loss: 1.267060774564743\n",
      "trial: 2, iter: 3800, curr loss: 1.223075032234192, avg loss: 1.271753165125847\n",
      "trial: 2, iter: 4000, curr loss: 1.2417278289794922, avg loss: 1.2663523906469345\n",
      "trial: 2, iter: 4200, curr loss: 1.2647994756698608, avg loss: 1.2696938163042069\n",
      "trial: 2, iter: 4400, curr loss: 1.2788794040679932, avg loss: 1.266128802895546\n",
      "trial: 2, iter: 4600, curr loss: 1.2777258157730103, avg loss: 1.2645513117313385\n",
      "trial: 2, iter: 4800, curr loss: 1.3214300870895386, avg loss: 1.2644352561235428\n",
      "trial: 2, iter: 5000, curr loss: 1.2684372663497925, avg loss: 1.2629668951034545\n",
      "trial: 2, iter: 5200, curr loss: 1.258056879043579, avg loss: 1.2694777768850327\n",
      "trial: 2, iter: 5400, curr loss: 1.2621091604232788, avg loss: 1.2669958412647246\n",
      "trial: 2, iter: 5600, curr loss: 1.2289448976516724, avg loss: 1.2664130479097366\n",
      "trial: 2, iter: 5800, curr loss: 1.2774533033370972, avg loss: 1.2618663626909257\n",
      "trial: 2, iter: 6000, curr loss: 1.2495030164718628, avg loss: 1.264692204594612\n",
      "trial: 2, iter: 6200, curr loss: 1.3180325031280518, avg loss: 1.266100818514824\n",
      "trial: 2, iter: 6400, curr loss: 1.2658851146697998, avg loss: 1.263353641629219\n",
      "trial: 2, iter: 6600, curr loss: 1.2897359132766724, avg loss: 1.266847448348999\n",
      "trial: 2, iter: 6800, curr loss: 1.2460811138153076, avg loss: 1.2656347966194152\n",
      "trial: 2, iter: 7000, curr loss: 1.197669506072998, avg loss: 1.2644604527950287\n",
      "trial: 2, iter: 7200, curr loss: 1.217372179031372, avg loss: 1.2633018440008164\n",
      "trial: 2, iter: 7400, curr loss: 1.2744125127792358, avg loss: 1.2649180853366853\n",
      "trial: 2, iter: 7600, curr loss: 1.2854986190795898, avg loss: 1.2624618995189667\n",
      "trial: 2, iter: 7800, curr loss: 1.2572942972183228, avg loss: 1.2651171898841858\n",
      "trial: 2, iter: 8000, curr loss: 1.2462377548217773, avg loss: 1.2626258355379105\n",
      "trial: 2, iter: 8200, curr loss: 1.278069019317627, avg loss: 1.265558750629425\n",
      "trial: 2, iter: 8400, curr loss: 1.2706347703933716, avg loss: 1.2643121922016143\n",
      "trial: 2, iter: 8600, curr loss: 1.2818117141723633, avg loss: 1.2654272973537446\n",
      "trial: 2, iter: 8800, curr loss: 1.2637020349502563, avg loss: 1.262040194272995\n",
      "trial: 2, iter: 9000, curr loss: 1.3283268213272095, avg loss: 1.262882354259491\n",
      "trial: 2, iter: 9200, curr loss: 1.2767285108566284, avg loss: 1.2647177052497864\n",
      "trial: 2, iter: 9400, curr loss: 1.2785718441009521, avg loss: 1.2642826819419861\n",
      "trial: 2, iter: 9600, curr loss: 1.2484140396118164, avg loss: 1.2630340015888215\n",
      "trial: 2, iter: 9800, curr loss: 1.245847463607788, avg loss: 1.2655022621154786\n",
      "trial: 2, iter: 10000, curr loss: 1.26851487159729, avg loss: 1.2665845769643784\n",
      "trial: 2, iter: 10200, curr loss: 1.2513012886047363, avg loss: 1.2659598803520202\n",
      "trial: 2, iter: 10400, curr loss: 1.2688699960708618, avg loss: 1.26187068939209\n",
      "trial: 2, iter: 10600, curr loss: 1.2480388879776, avg loss: 1.262480339407921\n",
      "trial: 2, iter: 10800, curr loss: 1.2516347169876099, avg loss: 1.2635306441783904\n",
      "trial: 2, iter: 11000, curr loss: 1.3229128122329712, avg loss: 1.2635233974456788\n",
      "trial: 2, iter: 11200, curr loss: 1.2846465110778809, avg loss: 1.2647937726974487\n",
      "trial: 2, iter: 11400, curr loss: 1.237673044204712, avg loss: 1.2617799776792527\n",
      "trial: 2, iter: 11600, curr loss: 1.2746230363845825, avg loss: 1.2654019355773927\n",
      "trial: 2, iter: 11800, curr loss: 1.2348392009735107, avg loss: 1.2616786342859267\n",
      "trial: 2, iter: 12000, curr loss: 1.2953957319259644, avg loss: 1.2634086728096008\n",
      "trial: 2, iter: 12200, curr loss: 1.2539271116256714, avg loss: 1.262256491780281\n",
      "trial: 2, iter: 12400, curr loss: 1.261602759361267, avg loss: 1.2592981654405593\n",
      "trial: 2, iter: 12600, curr loss: 1.2462224960327148, avg loss: 1.2632621157169341\n",
      "trial: 2, iter: 12800, curr loss: 1.2573046684265137, avg loss: 1.2613648730516434\n",
      "trial: 2, iter: 13000, curr loss: 1.2646458148956299, avg loss: 1.2614458602666856\n",
      "trial: 2, iter: 13200, curr loss: 1.2794008255004883, avg loss: 1.2590490102767944\n",
      "trial: 2, iter: 13400, curr loss: 1.276761531829834, avg loss: 1.2646048092842102\n",
      "trial: 2, iter: 13600, curr loss: 1.2279728651046753, avg loss: 1.2621791106462479\n",
      "trial: 2, iter: 13800, curr loss: 1.2700302600860596, avg loss: 1.2657560640573502\n",
      "trial: 2, iter: 14000, curr loss: 1.2403318881988525, avg loss: 1.2627766972780228\n",
      "trial: 2, iter: 14200, curr loss: 1.247849702835083, avg loss: 1.264063213467598\n",
      "trial: 2, iter: 14400, curr loss: 1.2626904249191284, avg loss: 1.2643755036592483\n",
      "trial: 2, iter: 14600, curr loss: 1.2550462484359741, avg loss: 1.259300435781479\n",
      "trial: 2, iter: 14800, curr loss: 1.2579230070114136, avg loss: 1.2633323442935944\n",
      "trial: 2, iter: 15000, curr loss: 1.2384569644927979, avg loss: 1.2642044967412949\n",
      "trial: 2, iter: 15200, curr loss: 1.246038794517517, avg loss: 1.2628429853916168\n",
      "trial: 2, iter: 15400, curr loss: 1.2652491331100464, avg loss: 1.2628483498096466\n",
      "trial: 2, iter: 15600, curr loss: 1.2547420263290405, avg loss: 1.2616458225250244\n",
      "trial: 2, ldr: 0.28213217854499817\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389183521270752, avg loss: 1.386866756081581\n",
      "trial: 3, iter: 400, curr loss: 1.3756463527679443, avg loss: 1.3833003050088883\n",
      "trial: 3, iter: 600, curr loss: 1.315629005432129, avg loss: 1.3472647392749786\n",
      "trial: 3, iter: 800, curr loss: 1.2979172468185425, avg loss: 1.3176351404190063\n",
      "trial: 3, iter: 1000, curr loss: 1.2922168970108032, avg loss: 1.3101957023143769\n",
      "trial: 3, iter: 1200, curr loss: 1.2960476875305176, avg loss: 1.3017165786027909\n",
      "trial: 3, iter: 1400, curr loss: 1.253670573234558, avg loss: 1.2929326045513152\n",
      "trial: 3, iter: 1600, curr loss: 1.273579478263855, avg loss: 1.2852003115415573\n",
      "trial: 3, iter: 1800, curr loss: 1.2032305002212524, avg loss: 1.278688179254532\n",
      "trial: 3, iter: 2000, curr loss: 1.285796880722046, avg loss: 1.2704215878248215\n",
      "trial: 3, iter: 2200, curr loss: 1.2466812133789062, avg loss: 1.2723157924413682\n",
      "trial: 3, iter: 2400, curr loss: 1.2656803131103516, avg loss: 1.2725668692588805\n",
      "trial: 3, iter: 2600, curr loss: 1.2410115003585815, avg loss: 1.2693792879581451\n",
      "trial: 3, iter: 2800, curr loss: 1.272049903869629, avg loss: 1.2674664908647537\n",
      "trial: 3, iter: 3000, curr loss: 1.2657036781311035, avg loss: 1.2694516324996947\n",
      "trial: 3, iter: 3200, curr loss: 1.2895491123199463, avg loss: 1.269542899131775\n",
      "trial: 3, iter: 3400, curr loss: 1.2468012571334839, avg loss: 1.2680501317977906\n",
      "trial: 3, iter: 3600, curr loss: 1.2709118127822876, avg loss: 1.2703344172239304\n",
      "trial: 3, iter: 3800, curr loss: 1.202836275100708, avg loss: 1.2660949271917343\n",
      "trial: 3, iter: 4000, curr loss: 1.2463568449020386, avg loss: 1.2628764724731445\n",
      "trial: 3, iter: 4200, curr loss: 1.278262734413147, avg loss: 1.2671099519729614\n",
      "trial: 3, iter: 4400, curr loss: 1.2550537586212158, avg loss: 1.2668174308538438\n",
      "trial: 3, iter: 4600, curr loss: 1.275288462638855, avg loss: 1.2630456602573394\n",
      "trial: 3, iter: 4800, curr loss: 1.2686067819595337, avg loss: 1.2684704780578613\n",
      "trial: 3, iter: 5000, curr loss: 1.3028552532196045, avg loss: 1.2672621035575866\n",
      "trial: 3, iter: 5200, curr loss: 1.2392489910125732, avg loss: 1.2645497250556945\n",
      "trial: 3, iter: 5400, curr loss: 1.2770682573318481, avg loss: 1.2637578344345093\n",
      "trial: 3, iter: 5600, curr loss: 1.2836158275604248, avg loss: 1.2639651292562484\n",
      "trial: 3, iter: 5800, curr loss: 1.2203881740570068, avg loss: 1.2649800509214402\n",
      "trial: 3, iter: 6000, curr loss: 1.2552355527877808, avg loss: 1.261031523346901\n",
      "trial: 3, iter: 6200, curr loss: 1.2845746278762817, avg loss: 1.2647599804401397\n",
      "trial: 3, iter: 6400, curr loss: 1.2257499694824219, avg loss: 1.2647347980737687\n",
      "trial: 3, iter: 6600, curr loss: 1.2517964839935303, avg loss: 1.2644962573051453\n",
      "trial: 3, iter: 6800, curr loss: 1.3070101737976074, avg loss: 1.2667899549007415\n",
      "trial: 3, iter: 7000, curr loss: 1.2619013786315918, avg loss: 1.2618671649694442\n",
      "trial: 3, iter: 7200, curr loss: 1.2387893199920654, avg loss: 1.2622578984498978\n",
      "trial: 3, iter: 7400, curr loss: 1.2688665390014648, avg loss: 1.264045929312706\n",
      "trial: 3, iter: 7600, curr loss: 1.275815486907959, avg loss: 1.2660022336244583\n",
      "trial: 3, iter: 7800, curr loss: 1.252667784690857, avg loss: 1.2627747571468353\n",
      "trial: 3, iter: 8000, curr loss: 1.2810744047164917, avg loss: 1.265317514538765\n",
      "trial: 3, iter: 8200, curr loss: 1.2308545112609863, avg loss: 1.2631862103939056\n",
      "trial: 3, iter: 8400, curr loss: 1.2800184488296509, avg loss: 1.2609192025661469\n",
      "trial: 3, iter: 8600, curr loss: 1.2632367610931396, avg loss: 1.261839901804924\n",
      "trial: 3, iter: 8800, curr loss: 1.212038516998291, avg loss: 1.2605956715345383\n",
      "trial: 3, iter: 9000, curr loss: 1.2490323781967163, avg loss: 1.266440857052803\n",
      "trial: 3, iter: 9200, curr loss: 1.2605241537094116, avg loss: 1.2623953169584274\n",
      "trial: 3, iter: 9400, curr loss: 1.2973347902297974, avg loss: 1.2639571392536164\n",
      "trial: 3, iter: 9600, curr loss: 1.2565381526947021, avg loss: 1.2630042254924774\n",
      "trial: 3, iter: 9800, curr loss: 1.2756123542785645, avg loss: 1.2605013579130173\n",
      "trial: 3, iter: 10000, curr loss: 1.2342700958251953, avg loss: 1.263512596487999\n",
      "trial: 3, iter: 10200, curr loss: 1.2918977737426758, avg loss: 1.2627438765764236\n",
      "trial: 3, iter: 10400, curr loss: 1.2517260313034058, avg loss: 1.262258106470108\n",
      "trial: 3, iter: 10600, curr loss: 1.2702572345733643, avg loss: 1.2647721356153487\n",
      "trial: 3, iter: 10800, curr loss: 1.2613370418548584, avg loss: 1.2594424146413803\n",
      "trial: 3, iter: 11000, curr loss: 1.239709734916687, avg loss: 1.2649713993072509\n",
      "trial: 3, iter: 11200, curr loss: 1.2897595167160034, avg loss: 1.2620036971569062\n",
      "trial: 3, iter: 11400, curr loss: 1.2632085084915161, avg loss: 1.2642958569526672\n",
      "trial: 3, iter: 11600, curr loss: 1.234466791152954, avg loss: 1.264456993341446\n",
      "trial: 3, iter: 11800, curr loss: 1.2719870805740356, avg loss: 1.2622377038002015\n",
      "trial: 3, iter: 12000, curr loss: 1.2675936222076416, avg loss: 1.2605991369485856\n",
      "trial: 3, iter: 12200, curr loss: 1.2696902751922607, avg loss: 1.26193741440773\n",
      "trial: 3, iter: 12400, curr loss: 1.30905020236969, avg loss: 1.2650894731283189\n",
      "trial: 3, iter: 12600, curr loss: 1.2065621614456177, avg loss: 1.2581279492378235\n",
      "trial: 3, iter: 12800, curr loss: 1.206264615058899, avg loss: 1.2600421059131621\n",
      "trial: 3, iter: 13000, curr loss: 1.2718405723571777, avg loss: 1.2629117691516876\n",
      "trial: 3, iter: 13200, curr loss: 1.2538750171661377, avg loss: 1.2608053922653197\n",
      "trial: 3, iter: 13400, curr loss: 1.2729412317276, avg loss: 1.261381458044052\n",
      "trial: 3, iter: 13600, curr loss: 1.2913907766342163, avg loss: 1.2608187544345855\n",
      "trial: 3, iter: 13800, curr loss: 1.3038347959518433, avg loss: 1.2606621086597443\n",
      "trial: 3, iter: 14000, curr loss: 1.2946187257766724, avg loss: 1.2598569935560227\n",
      "trial: 3, iter: 14200, curr loss: 1.2254724502563477, avg loss: 1.263174815773964\n",
      "trial: 3, iter: 14400, curr loss: 1.287516474723816, avg loss: 1.2609031808376312\n",
      "trial: 3, iter: 14600, curr loss: 1.2594223022460938, avg loss: 1.2620394295454025\n",
      "trial: 3, iter: 14800, curr loss: 1.229691505432129, avg loss: 1.26151387155056\n",
      "trial: 3, iter: 15000, curr loss: 1.2823430299758911, avg loss: 1.2619671911001205\n",
      "trial: 3, iter: 15200, curr loss: 1.2375808954238892, avg loss: 1.261240085363388\n",
      "trial: 3, iter: 15400, curr loss: 1.2640514373779297, avg loss: 1.2614504146575927\n",
      "trial: 3, iter: 15600, curr loss: 1.2882839441299438, avg loss: 1.2630805778503418\n",
      "trial: 3, ldr: 0.2545913755893707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860015869140625, avg loss: 1.386316823363304\n",
      "trial: 4, iter: 400, curr loss: 1.3562228679656982, avg loss: 1.3772182685136796\n",
      "trial: 4, iter: 600, curr loss: 1.3096574544906616, avg loss: 1.3405099701881409\n",
      "trial: 4, iter: 800, curr loss: 1.3036261796951294, avg loss: 1.320649760365486\n",
      "trial: 4, iter: 1000, curr loss: 1.3027373552322388, avg loss: 1.3145147413015366\n",
      "trial: 4, iter: 1200, curr loss: 1.3126410245895386, avg loss: 1.3099537938833237\n",
      "trial: 4, iter: 1400, curr loss: 1.288177251815796, avg loss: 1.3042853033542634\n",
      "trial: 4, iter: 1600, curr loss: 1.276058316230774, avg loss: 1.2974172681570053\n",
      "trial: 4, iter: 1800, curr loss: 1.2794690132141113, avg loss: 1.29107066988945\n",
      "trial: 4, iter: 2000, curr loss: 1.269540548324585, avg loss: 1.2843026161193847\n",
      "trial: 4, iter: 2200, curr loss: 1.2978737354278564, avg loss: 1.278037555217743\n",
      "trial: 4, iter: 2400, curr loss: 1.2337967157363892, avg loss: 1.2740774077177048\n",
      "trial: 4, iter: 2600, curr loss: 1.2838327884674072, avg loss: 1.2704158163070678\n",
      "trial: 4, iter: 2800, curr loss: 1.2597442865371704, avg loss: 1.2728843837976456\n",
      "trial: 4, iter: 3000, curr loss: 1.248924970626831, avg loss: 1.2692753064632416\n",
      "trial: 4, iter: 3200, curr loss: 1.2678107023239136, avg loss: 1.2701619446277619\n",
      "trial: 4, iter: 3400, curr loss: 1.252991795539856, avg loss: 1.2684286278486252\n",
      "trial: 4, iter: 3600, curr loss: 1.3028231859207153, avg loss: 1.2680334275960923\n",
      "trial: 4, iter: 3800, curr loss: 1.3244116306304932, avg loss: 1.2675339740514755\n",
      "trial: 4, iter: 4000, curr loss: 1.2529513835906982, avg loss: 1.2676525193452834\n",
      "trial: 4, iter: 4200, curr loss: 1.2626841068267822, avg loss: 1.268298978805542\n",
      "trial: 4, iter: 4400, curr loss: 1.2392704486846924, avg loss: 1.266497133374214\n",
      "trial: 4, iter: 4600, curr loss: 1.2996606826782227, avg loss: 1.2698053097724915\n",
      "trial: 4, iter: 4800, curr loss: 1.2373751401901245, avg loss: 1.266991110444069\n",
      "trial: 4, iter: 5000, curr loss: 1.3022664785385132, avg loss: 1.2689082270860672\n",
      "trial: 4, iter: 5200, curr loss: 1.2249218225479126, avg loss: 1.266129464507103\n",
      "trial: 4, iter: 5400, curr loss: 1.2678545713424683, avg loss: 1.2692158275842667\n",
      "trial: 4, iter: 5600, curr loss: 1.240605115890503, avg loss: 1.2655841100215912\n",
      "trial: 4, iter: 5800, curr loss: 1.2272273302078247, avg loss: 1.2670330065488815\n",
      "trial: 4, iter: 6000, curr loss: 1.262897253036499, avg loss: 1.2677713114023208\n",
      "trial: 4, iter: 6200, curr loss: 1.2673933506011963, avg loss: 1.2644698321819305\n",
      "trial: 4, iter: 6400, curr loss: 1.233149528503418, avg loss: 1.263537306189537\n",
      "trial: 4, iter: 6600, curr loss: 1.292506456375122, avg loss: 1.2645881581306457\n",
      "trial: 4, iter: 6800, curr loss: 1.2200772762298584, avg loss: 1.2660485517978668\n",
      "trial: 4, iter: 7000, curr loss: 1.2842988967895508, avg loss: 1.2648376578092575\n",
      "trial: 4, iter: 7200, curr loss: 1.2905852794647217, avg loss: 1.265506706237793\n",
      "trial: 4, iter: 7400, curr loss: 1.251204252243042, avg loss: 1.26092305123806\n",
      "trial: 4, iter: 7600, curr loss: 1.272748351097107, avg loss: 1.265136831998825\n",
      "trial: 4, iter: 7800, curr loss: 1.2509897947311401, avg loss: 1.2646392005681992\n",
      "trial: 4, iter: 8000, curr loss: 1.2391157150268555, avg loss: 1.2615370696783066\n",
      "trial: 4, iter: 8200, curr loss: 1.2478724718093872, avg loss: 1.264690834879875\n",
      "trial: 4, iter: 8400, curr loss: 1.2108912467956543, avg loss: 1.2636683410406113\n",
      "trial: 4, iter: 8600, curr loss: 1.2430156469345093, avg loss: 1.2634489613771438\n",
      "trial: 4, iter: 8800, curr loss: 1.2802295684814453, avg loss: 1.2633949685096741\n",
      "trial: 4, iter: 9000, curr loss: 1.2451599836349487, avg loss: 1.2650565415620805\n",
      "trial: 4, iter: 9200, curr loss: 1.2633017301559448, avg loss: 1.2659989559650422\n",
      "trial: 4, iter: 9400, curr loss: 1.2819783687591553, avg loss: 1.2600896698236466\n",
      "trial: 4, iter: 9600, curr loss: 1.2329045534133911, avg loss: 1.263062716126442\n",
      "trial: 4, iter: 9800, curr loss: 1.2548757791519165, avg loss: 1.2617767548561096\n",
      "trial: 4, iter: 10000, curr loss: 1.248964786529541, avg loss: 1.2625382214784622\n",
      "trial: 4, iter: 10200, curr loss: 1.2794151306152344, avg loss: 1.263468696475029\n",
      "trial: 4, iter: 10400, curr loss: 1.2449593544006348, avg loss: 1.2631940567493438\n",
      "trial: 4, iter: 10600, curr loss: 1.2625356912612915, avg loss: 1.2615443080663682\n",
      "trial: 4, iter: 10800, curr loss: 1.277077078819275, avg loss: 1.2639258420467376\n",
      "trial: 4, iter: 11000, curr loss: 1.2438607215881348, avg loss: 1.2626197016239167\n",
      "trial: 4, iter: 11200, curr loss: 1.2426396608352661, avg loss: 1.263752561211586\n",
      "trial: 4, iter: 11400, curr loss: 1.2876914739608765, avg loss: 1.2617133092880248\n",
      "trial: 4, iter: 11600, curr loss: 1.2543067932128906, avg loss: 1.2665878927707672\n",
      "trial: 4, iter: 11800, curr loss: 1.2829402685165405, avg loss: 1.2616904920339584\n",
      "trial: 4, iter: 12000, curr loss: 1.2685965299606323, avg loss: 1.2626076406240463\n",
      "trial: 4, iter: 12200, curr loss: 1.2717636823654175, avg loss: 1.263203071951866\n",
      "trial: 4, iter: 12400, curr loss: 1.2504299879074097, avg loss: 1.2620336812734605\n",
      "trial: 4, iter: 12600, curr loss: 1.265786051750183, avg loss: 1.2606205260753631\n",
      "trial: 4, iter: 12800, curr loss: 1.3145923614501953, avg loss: 1.2634877449274062\n",
      "trial: 4, iter: 13000, curr loss: 1.2276972532272339, avg loss: 1.260012109875679\n",
      "trial: 4, iter: 13200, curr loss: 1.273447871208191, avg loss: 1.2641461598873138\n",
      "trial: 4, iter: 13400, curr loss: 1.2534445524215698, avg loss: 1.2632756221294403\n",
      "trial: 4, iter: 13600, curr loss: 1.2599372863769531, avg loss: 1.2648850464820862\n",
      "trial: 4, iter: 13800, curr loss: 1.293377161026001, avg loss: 1.2606851649284363\n",
      "trial: 4, iter: 14000, curr loss: 1.2790647745132446, avg loss: 1.2624561369419098\n",
      "trial: 4, iter: 14200, curr loss: 1.2475005388259888, avg loss: 1.2626508742570877\n",
      "trial: 4, iter: 14400, curr loss: 1.261232852935791, avg loss: 1.2611852771043777\n",
      "trial: 4, iter: 14600, curr loss: 1.2508535385131836, avg loss: 1.263367314338684\n",
      "trial: 4, iter: 14800, curr loss: 1.3054932355880737, avg loss: 1.262913742661476\n",
      "trial: 4, iter: 15000, curr loss: 1.2641462087631226, avg loss: 1.2612319141626358\n",
      "trial: 4, iter: 15200, curr loss: 1.2350430488586426, avg loss: 1.2612431752681732\n",
      "trial: 4, iter: 15400, curr loss: 1.2340189218521118, avg loss: 1.2613015896081925\n",
      "trial: 4, iter: 15600, curr loss: 1.2426413297653198, avg loss: 1.2602058392763138\n",
      "trial: 4, ldr: 0.19839581847190857\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3839129209518433, avg loss: 1.3867111670970917\n",
      "trial: 5, iter: 400, curr loss: 1.370779037475586, avg loss: 1.3829035544395447\n",
      "trial: 5, iter: 600, curr loss: 1.3366281986236572, avg loss: 1.3540585786104202\n",
      "trial: 5, iter: 800, curr loss: 1.313244104385376, avg loss: 1.3278049331903459\n",
      "trial: 5, iter: 1000, curr loss: 1.3025493621826172, avg loss: 1.3171492129564286\n",
      "trial: 5, iter: 1200, curr loss: 1.2870770692825317, avg loss: 1.3132536810636521\n",
      "trial: 5, iter: 1400, curr loss: 1.3387980461120605, avg loss: 1.3126171988248825\n",
      "trial: 5, iter: 1600, curr loss: 1.3305059671401978, avg loss: 1.3042024385929107\n",
      "trial: 5, iter: 1800, curr loss: 1.3003220558166504, avg loss: 1.3020905166864396\n",
      "trial: 5, iter: 2000, curr loss: 1.2760019302368164, avg loss: 1.2964067834615707\n",
      "trial: 5, iter: 2200, curr loss: 1.2785987854003906, avg loss: 1.290308598279953\n",
      "trial: 5, iter: 2400, curr loss: 1.297342300415039, avg loss: 1.2863121265172959\n",
      "trial: 5, iter: 2600, curr loss: 1.2826716899871826, avg loss: 1.277152030467987\n",
      "trial: 5, iter: 2800, curr loss: 1.2809826135635376, avg loss: 1.2742383778095245\n",
      "trial: 5, iter: 3000, curr loss: 1.26132333278656, avg loss: 1.2758150857686996\n",
      "trial: 5, iter: 3200, curr loss: 1.274839162826538, avg loss: 1.2694004517793656\n",
      "trial: 5, iter: 3400, curr loss: 1.2708384990692139, avg loss: 1.2717383700609206\n",
      "trial: 5, iter: 3600, curr loss: 1.2975770235061646, avg loss: 1.2694786179065705\n",
      "trial: 5, iter: 3800, curr loss: 1.2561246156692505, avg loss: 1.270358500480652\n",
      "trial: 5, iter: 4000, curr loss: 1.204383134841919, avg loss: 1.2677031719684602\n",
      "trial: 5, iter: 4200, curr loss: 1.281607985496521, avg loss: 1.2656711345911027\n",
      "trial: 5, iter: 4400, curr loss: 1.254569411277771, avg loss: 1.2675714480876923\n",
      "trial: 5, iter: 4600, curr loss: 1.2592928409576416, avg loss: 1.269812568426132\n",
      "trial: 5, iter: 4800, curr loss: 1.2872835397720337, avg loss: 1.2660642981529235\n",
      "trial: 5, iter: 5000, curr loss: 1.2808685302734375, avg loss: 1.264871702194214\n",
      "trial: 5, iter: 5200, curr loss: 1.2861722707748413, avg loss: 1.267444161772728\n",
      "trial: 5, iter: 5400, curr loss: 1.2394649982452393, avg loss: 1.267546768784523\n",
      "trial: 5, iter: 5600, curr loss: 1.232957124710083, avg loss: 1.2664439100027085\n",
      "trial: 5, iter: 5800, curr loss: 1.270184874534607, avg loss: 1.2688046687841414\n",
      "trial: 5, iter: 6000, curr loss: 1.3250588178634644, avg loss: 1.2613659608364105\n",
      "trial: 5, iter: 6200, curr loss: 1.2091341018676758, avg loss: 1.2632606261968613\n",
      "trial: 5, iter: 6400, curr loss: 1.265604019165039, avg loss: 1.2649540597200393\n",
      "trial: 5, iter: 6600, curr loss: 1.233030915260315, avg loss: 1.2660915285348893\n",
      "trial: 5, iter: 6800, curr loss: 1.2221945524215698, avg loss: 1.2661059403419495\n",
      "trial: 5, iter: 7000, curr loss: 1.2859951257705688, avg loss: 1.2649166870117188\n",
      "trial: 5, iter: 7200, curr loss: 1.233968734741211, avg loss: 1.2597794997692109\n",
      "trial: 5, iter: 7400, curr loss: 1.305544137954712, avg loss: 1.2657744336128234\n",
      "trial: 5, iter: 7600, curr loss: 1.278032898902893, avg loss: 1.265006449818611\n",
      "trial: 5, iter: 7800, curr loss: 1.2555503845214844, avg loss: 1.2643589037656784\n",
      "trial: 5, iter: 8000, curr loss: 1.2900934219360352, avg loss: 1.2610338419675826\n",
      "trial: 5, iter: 8200, curr loss: 1.2449220418930054, avg loss: 1.2629738450050354\n",
      "trial: 5, iter: 8400, curr loss: 1.2599246501922607, avg loss: 1.2651270341873169\n",
      "trial: 5, iter: 8600, curr loss: 1.295294165611267, avg loss: 1.263028939962387\n",
      "trial: 5, iter: 8800, curr loss: 1.292199730873108, avg loss: 1.263176828622818\n",
      "trial: 5, iter: 9000, curr loss: 1.25852632522583, avg loss: 1.2656554561853408\n",
      "trial: 5, iter: 9200, curr loss: 1.2639857530593872, avg loss: 1.265420150756836\n",
      "trial: 5, iter: 9400, curr loss: 1.256494164466858, avg loss: 1.261323247551918\n",
      "trial: 5, iter: 9600, curr loss: 1.2261611223220825, avg loss: 1.2650882482528687\n",
      "trial: 5, iter: 9800, curr loss: 1.287782073020935, avg loss: 1.26273630797863\n",
      "trial: 5, iter: 10000, curr loss: 1.2697395086288452, avg loss: 1.2645862376689911\n",
      "trial: 5, iter: 10200, curr loss: 1.2495118379592896, avg loss: 1.2635952949523925\n",
      "trial: 5, iter: 10400, curr loss: 1.2642375230789185, avg loss: 1.2655747783184053\n",
      "trial: 5, iter: 10600, curr loss: 1.223886489868164, avg loss: 1.2621655720472336\n",
      "trial: 5, iter: 10800, curr loss: 1.2243056297302246, avg loss: 1.2604182106256485\n",
      "trial: 5, iter: 11000, curr loss: 1.2785212993621826, avg loss: 1.260785167813301\n",
      "trial: 5, iter: 11200, curr loss: 1.2471524477005005, avg loss: 1.2625249862670898\n",
      "trial: 5, iter: 11400, curr loss: 1.2763408422470093, avg loss: 1.2598671400547028\n",
      "trial: 5, iter: 11600, curr loss: 1.2644681930541992, avg loss: 1.2610025799274445\n",
      "trial: 5, iter: 11800, curr loss: 1.2736743688583374, avg loss: 1.2637561744451522\n",
      "trial: 5, iter: 12000, curr loss: 1.2557661533355713, avg loss: 1.261589776277542\n",
      "trial: 5, iter: 12200, curr loss: 1.2956898212432861, avg loss: 1.265264284014702\n",
      "trial: 5, iter: 12400, curr loss: 1.2649271488189697, avg loss: 1.2606528997421265\n",
      "trial: 5, iter: 12600, curr loss: 1.2614028453826904, avg loss: 1.2635051727294921\n",
      "trial: 5, iter: 12800, curr loss: 1.2519843578338623, avg loss: 1.2606607401371002\n",
      "trial: 5, iter: 13000, curr loss: 1.2469382286071777, avg loss: 1.260127180814743\n",
      "trial: 5, iter: 13200, curr loss: 1.2570085525512695, avg loss: 1.2615395933389664\n",
      "trial: 5, iter: 13400, curr loss: 1.27714204788208, avg loss: 1.2606420201063155\n",
      "trial: 5, iter: 13600, curr loss: 1.2468119859695435, avg loss: 1.2633679491281509\n",
      "trial: 5, iter: 13800, curr loss: 1.3248051404953003, avg loss: 1.2617574006319046\n",
      "trial: 5, iter: 14000, curr loss: 1.2803926467895508, avg loss: 1.258223751783371\n",
      "trial: 5, iter: 14200, curr loss: 1.2811899185180664, avg loss: 1.2606906282901764\n",
      "trial: 5, iter: 14400, curr loss: 1.278590440750122, avg loss: 1.263729362487793\n",
      "trial: 5, iter: 14600, curr loss: 1.254711389541626, avg loss: 1.2608023846149445\n",
      "trial: 5, iter: 14800, curr loss: 1.287966251373291, avg loss: 1.2617550146579743\n",
      "trial: 5, iter: 15000, curr loss: 1.2427988052368164, avg loss: 1.2644517743587493\n",
      "trial: 5, iter: 15200, curr loss: 1.3032170534133911, avg loss: 1.2634938472509385\n",
      "trial: 5, iter: 15400, curr loss: 1.265112280845642, avg loss: 1.262754784822464\n",
      "trial: 5, iter: 15600, curr loss: 1.2531979084014893, avg loss: 1.262462810277939\n",
      "trial: 5, ldr: 0.28023484349250793\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.24762541353702544\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3889421224594116, avg loss: 1.3868239951133727\n",
      "trial: 1, iter: 400, curr loss: 1.380135416984558, avg loss: 1.3851459479331971\n",
      "trial: 1, iter: 600, curr loss: 1.3468915224075317, avg loss: 1.3683394557237625\n",
      "trial: 1, iter: 800, curr loss: 1.3097378015518188, avg loss: 1.3296314120292663\n",
      "trial: 1, iter: 1000, curr loss: 1.3013333082199097, avg loss: 1.3185756230354309\n",
      "trial: 1, iter: 1200, curr loss: 1.3086919784545898, avg loss: 1.3166411858797074\n",
      "trial: 1, iter: 1400, curr loss: 1.299008846282959, avg loss: 1.3080202895402908\n",
      "trial: 1, iter: 1600, curr loss: 1.3169515132904053, avg loss: 1.3018553906679153\n",
      "trial: 1, iter: 1800, curr loss: 1.2735111713409424, avg loss: 1.2921777296066284\n",
      "trial: 1, iter: 2000, curr loss: 1.2864285707473755, avg loss: 1.2896534591913222\n",
      "trial: 1, iter: 2200, curr loss: 1.2350863218307495, avg loss: 1.284285031557083\n",
      "trial: 1, iter: 2400, curr loss: 1.2739638090133667, avg loss: 1.279861860871315\n",
      "trial: 1, iter: 2600, curr loss: 1.2541602849960327, avg loss: 1.276450583934784\n",
      "trial: 1, iter: 2800, curr loss: 1.2733322381973267, avg loss: 1.276607437133789\n",
      "trial: 1, iter: 3000, curr loss: 1.2794201374053955, avg loss: 1.2737098294496536\n",
      "trial: 1, iter: 3200, curr loss: 1.3085705041885376, avg loss: 1.2709084993600845\n",
      "trial: 1, iter: 3400, curr loss: 1.2702299356460571, avg loss: 1.2695115280151368\n",
      "trial: 1, iter: 3600, curr loss: 1.3106828927993774, avg loss: 1.2680691164731979\n",
      "trial: 1, iter: 3800, curr loss: 1.3165801763534546, avg loss: 1.2707363814115524\n",
      "trial: 1, iter: 4000, curr loss: 1.2444195747375488, avg loss: 1.2672662442922593\n",
      "trial: 1, iter: 4200, curr loss: 1.2355526685714722, avg loss: 1.2660341727733613\n",
      "trial: 1, iter: 4400, curr loss: 1.2615511417388916, avg loss: 1.2667009490728378\n",
      "trial: 1, iter: 4600, curr loss: 1.2810969352722168, avg loss: 1.2632191169261933\n",
      "trial: 1, iter: 4800, curr loss: 1.2583764791488647, avg loss: 1.269753846526146\n",
      "trial: 1, iter: 5000, curr loss: 1.2975432872772217, avg loss: 1.2690940982103347\n",
      "trial: 1, iter: 5200, curr loss: 1.2503037452697754, avg loss: 1.2677574455738068\n",
      "trial: 1, iter: 5400, curr loss: 1.2167258262634277, avg loss: 1.2670601779222488\n",
      "trial: 1, iter: 5600, curr loss: 1.2451380491256714, avg loss: 1.2659928321838378\n",
      "trial: 1, iter: 5800, curr loss: 1.3288981914520264, avg loss: 1.2673602092266083\n",
      "trial: 1, iter: 6000, curr loss: 1.2302693128585815, avg loss: 1.2655723971128463\n",
      "trial: 1, iter: 6200, curr loss: 1.2982547283172607, avg loss: 1.2667979204654694\n",
      "trial: 1, iter: 6400, curr loss: 1.2585481405258179, avg loss: 1.2654315972328185\n",
      "trial: 1, iter: 6600, curr loss: 1.245360016822815, avg loss: 1.266580051779747\n",
      "trial: 1, iter: 6800, curr loss: 1.2645090818405151, avg loss: 1.265295427441597\n",
      "trial: 1, iter: 7000, curr loss: 1.2622047662734985, avg loss: 1.2651761084795\n",
      "trial: 1, iter: 7200, curr loss: 1.2823927402496338, avg loss: 1.2671907705068588\n",
      "trial: 1, iter: 7400, curr loss: 1.2755098342895508, avg loss: 1.2648678636550903\n",
      "trial: 1, iter: 7600, curr loss: 1.3116602897644043, avg loss: 1.2637169879674912\n",
      "trial: 1, iter: 7800, curr loss: 1.2602934837341309, avg loss: 1.2654207640886306\n",
      "trial: 1, iter: 8000, curr loss: 1.2930546998977661, avg loss: 1.2636709541082383\n",
      "trial: 1, iter: 8200, curr loss: 1.285538673400879, avg loss: 1.2688638371229173\n",
      "trial: 1, iter: 8400, curr loss: 1.2209235429763794, avg loss: 1.2631383454799652\n",
      "trial: 1, iter: 8600, curr loss: 1.2559653520584106, avg loss: 1.263266522884369\n",
      "trial: 1, iter: 8800, curr loss: 1.284312129020691, avg loss: 1.2659627109766007\n",
      "trial: 1, iter: 9000, curr loss: 1.2588797807693481, avg loss: 1.2632307207584381\n",
      "trial: 1, iter: 9200, curr loss: 1.2334132194519043, avg loss: 1.2631728410720826\n",
      "trial: 1, iter: 9400, curr loss: 1.2484709024429321, avg loss: 1.262676914334297\n",
      "trial: 1, iter: 9600, curr loss: 1.3005183935165405, avg loss: 1.2637341207265853\n",
      "trial: 1, iter: 9800, curr loss: 1.287574291229248, avg loss: 1.2633933240175248\n",
      "trial: 1, iter: 10000, curr loss: 1.2674646377563477, avg loss: 1.2667903804779053\n",
      "trial: 1, iter: 10200, curr loss: 1.276841163635254, avg loss: 1.2605227679014206\n",
      "trial: 1, iter: 10400, curr loss: 1.216081142425537, avg loss: 1.2620282369852065\n",
      "trial: 1, iter: 10600, curr loss: 1.2453522682189941, avg loss: 1.2633095270395278\n",
      "trial: 1, iter: 10800, curr loss: 1.286854863166809, avg loss: 1.2667357474565506\n",
      "trial: 1, iter: 11000, curr loss: 1.2566465139389038, avg loss: 1.2642481100559235\n",
      "trial: 1, iter: 11200, curr loss: 1.2430100440979004, avg loss: 1.2651821321249008\n",
      "trial: 1, iter: 11400, curr loss: 1.2633147239685059, avg loss: 1.2650705647468568\n",
      "trial: 1, iter: 11600, curr loss: 1.2987699508666992, avg loss: 1.263677648305893\n",
      "trial: 1, iter: 11800, curr loss: 1.2544128894805908, avg loss: 1.2652388912439347\n",
      "trial: 1, iter: 12000, curr loss: 1.270653247833252, avg loss: 1.266896498799324\n",
      "trial: 1, iter: 12200, curr loss: 1.315390944480896, avg loss: 1.2629528105258943\n",
      "trial: 1, iter: 12400, curr loss: 1.2897921800613403, avg loss: 1.2654482704401016\n",
      "trial: 1, iter: 12600, curr loss: 1.208179235458374, avg loss: 1.264713928103447\n",
      "trial: 1, iter: 12800, curr loss: 1.2424678802490234, avg loss: 1.2594986230134964\n",
      "trial: 1, iter: 13000, curr loss: 1.250306248664856, avg loss: 1.2617562997341156\n",
      "trial: 1, iter: 13200, curr loss: 1.2492729425430298, avg loss: 1.2671730422973633\n",
      "trial: 1, iter: 13400, curr loss: 1.26194429397583, avg loss: 1.2654936069250107\n",
      "trial: 1, iter: 13600, curr loss: 1.230180263519287, avg loss: 1.2653036314249038\n",
      "trial: 1, iter: 13800, curr loss: 1.2606604099273682, avg loss: 1.2618716591596604\n",
      "trial: 1, iter: 14000, curr loss: 1.265868902206421, avg loss: 1.2643721532821655\n",
      "trial: 1, iter: 14200, curr loss: 1.275294542312622, avg loss: 1.2623414915800095\n",
      "trial: 1, iter: 14400, curr loss: 1.2503756284713745, avg loss: 1.2649905061721802\n",
      "trial: 1, iter: 14600, curr loss: 1.225821852684021, avg loss: 1.2636832720041276\n",
      "trial: 1, iter: 14800, curr loss: 1.255637764930725, avg loss: 1.2648327672481536\n",
      "trial: 1, iter: 15000, curr loss: 1.2415286302566528, avg loss: 1.2598843854665756\n",
      "trial: 1, iter: 15200, curr loss: 1.2525813579559326, avg loss: 1.2622188740968705\n",
      "trial: 1, iter: 15400, curr loss: 1.240838646888733, avg loss: 1.2642055815458297\n",
      "trial: 1, iter: 15600, curr loss: 1.2421588897705078, avg loss: 1.2655962383747101\n",
      "trial: 1, ldr: 0.2784891724586487\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3889679908752441, avg loss: 1.3871904277801514\n",
      "trial: 2, iter: 400, curr loss: 1.382941484451294, avg loss: 1.3841348361968995\n",
      "trial: 2, iter: 600, curr loss: 1.336766004562378, avg loss: 1.3644175660610198\n",
      "trial: 2, iter: 800, curr loss: 1.298262119293213, avg loss: 1.3278030049800873\n",
      "trial: 2, iter: 1000, curr loss: 1.2796889543533325, avg loss: 1.3164737367630004\n",
      "trial: 2, iter: 1200, curr loss: 1.3439271450042725, avg loss: 1.3091410189867019\n",
      "trial: 2, iter: 1400, curr loss: 1.3136115074157715, avg loss: 1.3065622246265411\n",
      "trial: 2, iter: 1600, curr loss: 1.3214701414108276, avg loss: 1.2952520561218261\n",
      "trial: 2, iter: 1800, curr loss: 1.2946555614471436, avg loss: 1.2897256779670716\n",
      "trial: 2, iter: 2000, curr loss: 1.3251327276229858, avg loss: 1.2831063234806062\n",
      "trial: 2, iter: 2200, curr loss: 1.2987322807312012, avg loss: 1.2784847402572632\n",
      "trial: 2, iter: 2400, curr loss: 1.2746095657348633, avg loss: 1.2748708415031433\n",
      "trial: 2, iter: 2600, curr loss: 1.3060752153396606, avg loss: 1.274253699183464\n",
      "trial: 2, iter: 2800, curr loss: 1.2773429155349731, avg loss: 1.2725133657455445\n",
      "trial: 2, iter: 3000, curr loss: 1.2947664260864258, avg loss: 1.269843174815178\n",
      "trial: 2, iter: 3200, curr loss: 1.2630765438079834, avg loss: 1.270196567773819\n",
      "trial: 2, iter: 3400, curr loss: 1.2826555967330933, avg loss: 1.2691100549697876\n",
      "trial: 2, iter: 3600, curr loss: 1.2930269241333008, avg loss: 1.2698314994573594\n",
      "trial: 2, iter: 3800, curr loss: 1.230985403060913, avg loss: 1.2688962465524674\n",
      "trial: 2, iter: 4000, curr loss: 1.2421783208847046, avg loss: 1.2697183161973953\n",
      "trial: 2, iter: 4200, curr loss: 1.2714016437530518, avg loss: 1.268579558134079\n",
      "trial: 2, iter: 4400, curr loss: 1.2622002363204956, avg loss: 1.2677050149440765\n",
      "trial: 2, iter: 4600, curr loss: 1.3188804388046265, avg loss: 1.2666756612062455\n",
      "trial: 2, iter: 4800, curr loss: 1.2242426872253418, avg loss: 1.267676253914833\n",
      "trial: 2, iter: 5000, curr loss: 1.260515570640564, avg loss: 1.2671645081043243\n",
      "trial: 2, iter: 5200, curr loss: 1.2737582921981812, avg loss: 1.2703161019086837\n",
      "trial: 2, iter: 5400, curr loss: 1.2785991430282593, avg loss: 1.2679962342977524\n",
      "trial: 2, iter: 5600, curr loss: 1.265835165977478, avg loss: 1.2655703616142273\n",
      "trial: 2, iter: 5800, curr loss: 1.2807948589324951, avg loss: 1.2722134387493134\n",
      "trial: 2, iter: 6000, curr loss: 1.2370020151138306, avg loss: 1.2664142733812331\n",
      "trial: 2, iter: 6200, curr loss: 1.2485315799713135, avg loss: 1.2646178567409516\n",
      "trial: 2, iter: 6400, curr loss: 1.2584080696105957, avg loss: 1.2638568609952927\n",
      "trial: 2, iter: 6600, curr loss: 1.2881345748901367, avg loss: 1.2667971569299699\n",
      "trial: 2, iter: 6800, curr loss: 1.2687568664550781, avg loss: 1.2649185013771058\n",
      "trial: 2, iter: 7000, curr loss: 1.2264630794525146, avg loss: 1.2690979379415512\n",
      "trial: 2, iter: 7200, curr loss: 1.2258260250091553, avg loss: 1.2654836583137512\n",
      "trial: 2, iter: 7400, curr loss: 1.2522528171539307, avg loss: 1.2663089615106582\n",
      "trial: 2, iter: 7600, curr loss: 1.243909239768982, avg loss: 1.2667041629552842\n",
      "trial: 2, iter: 7800, curr loss: 1.2495354413986206, avg loss: 1.2628957653045654\n",
      "trial: 2, iter: 8000, curr loss: 1.250305414199829, avg loss: 1.262761254310608\n",
      "trial: 2, iter: 8200, curr loss: 1.2932865619659424, avg loss: 1.2632764464616775\n",
      "trial: 2, iter: 8400, curr loss: 1.2846400737762451, avg loss: 1.2647435814142227\n",
      "trial: 2, iter: 8600, curr loss: 1.2699317932128906, avg loss: 1.2649922692775726\n",
      "trial: 2, iter: 8800, curr loss: 1.2820039987564087, avg loss: 1.2618134796619416\n",
      "trial: 2, iter: 9000, curr loss: 1.2808283567428589, avg loss: 1.2641603189706803\n",
      "trial: 2, iter: 9200, curr loss: 1.2435566186904907, avg loss: 1.2612596088647843\n",
      "trial: 2, iter: 9400, curr loss: 1.2380213737487793, avg loss: 1.2639990454912187\n",
      "trial: 2, iter: 9600, curr loss: 1.2217944860458374, avg loss: 1.2633923923969268\n",
      "trial: 2, iter: 9800, curr loss: 1.2700541019439697, avg loss: 1.2663163048028947\n",
      "trial: 2, iter: 10000, curr loss: 1.2706230878829956, avg loss: 1.262647493481636\n",
      "trial: 2, iter: 10200, curr loss: 1.2840285301208496, avg loss: 1.2650183087587357\n",
      "trial: 2, iter: 10400, curr loss: 1.2429864406585693, avg loss: 1.2645729100704193\n",
      "trial: 2, iter: 10600, curr loss: 1.2193764448165894, avg loss: 1.2648955076932906\n",
      "trial: 2, iter: 10800, curr loss: 1.2430949211120605, avg loss: 1.2641008114814758\n",
      "trial: 2, iter: 11000, curr loss: 1.2215214967727661, avg loss: 1.2654088604450227\n",
      "trial: 2, iter: 11200, curr loss: 1.2673901319503784, avg loss: 1.2615667277574538\n",
      "trial: 2, iter: 11400, curr loss: 1.2507208585739136, avg loss: 1.2625463497638703\n",
      "trial: 2, iter: 11600, curr loss: 1.2456740140914917, avg loss: 1.2632979613542556\n",
      "trial: 2, iter: 11800, curr loss: 1.243454098701477, avg loss: 1.2617292207479478\n",
      "trial: 2, iter: 12000, curr loss: 1.292145013809204, avg loss: 1.2640469789505004\n",
      "trial: 2, iter: 12200, curr loss: 1.28934907913208, avg loss: 1.2666353327035904\n",
      "trial: 2, iter: 12400, curr loss: 1.248145341873169, avg loss: 1.2623332351446153\n",
      "trial: 2, iter: 12600, curr loss: 1.2353973388671875, avg loss: 1.2668069022893906\n",
      "trial: 2, iter: 12800, curr loss: 1.3010389804840088, avg loss: 1.2654086691141129\n",
      "trial: 2, iter: 13000, curr loss: 1.2795052528381348, avg loss: 1.2608419001102447\n",
      "trial: 2, iter: 13200, curr loss: 1.2448251247406006, avg loss: 1.265157811641693\n",
      "trial: 2, iter: 13400, curr loss: 1.2501496076583862, avg loss: 1.2668816286325455\n",
      "trial: 2, iter: 13600, curr loss: 1.2470166683197021, avg loss: 1.261204229593277\n",
      "trial: 2, iter: 13800, curr loss: 1.274275302886963, avg loss: 1.2673854756355285\n",
      "trial: 2, iter: 14000, curr loss: 1.2885218858718872, avg loss: 1.267969433069229\n",
      "trial: 2, iter: 14200, curr loss: 1.2750741243362427, avg loss: 1.2619368290901185\n",
      "trial: 2, iter: 14400, curr loss: 1.2288525104522705, avg loss: 1.2626423120498658\n",
      "trial: 2, iter: 14600, curr loss: 1.2558807134628296, avg loss: 1.2643944817781447\n",
      "trial: 2, iter: 14800, curr loss: 1.2790933847427368, avg loss: 1.2597002792358398\n",
      "trial: 2, iter: 15000, curr loss: 1.2618292570114136, avg loss: 1.2608801424503326\n",
      "trial: 2, iter: 15200, curr loss: 1.29341721534729, avg loss: 1.2661771470308303\n",
      "trial: 2, iter: 15400, curr loss: 1.2921286821365356, avg loss: 1.2588210821151733\n",
      "trial: 2, iter: 15600, curr loss: 1.2780693769454956, avg loss: 1.2602636444568633\n",
      "trial: 2, ldr: 0.20286810398101807\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3866974115371704, avg loss: 1.386876568198204\n",
      "trial: 3, iter: 400, curr loss: 1.3645075559616089, avg loss: 1.3810740274190902\n",
      "trial: 3, iter: 600, curr loss: 1.3367725610733032, avg loss: 1.3433245044946671\n",
      "trial: 3, iter: 800, curr loss: 1.3040064573287964, avg loss: 1.3189521449804307\n",
      "trial: 3, iter: 1000, curr loss: 1.3100769519805908, avg loss: 1.3153233659267425\n",
      "trial: 3, iter: 1200, curr loss: 1.2964179515838623, avg loss: 1.3079852855205536\n",
      "trial: 3, iter: 1400, curr loss: 1.270347237586975, avg loss: 1.3035856264829635\n",
      "trial: 3, iter: 1600, curr loss: 1.289726734161377, avg loss: 1.2971539956331253\n",
      "trial: 3, iter: 1800, curr loss: 1.2824963331222534, avg loss: 1.2926645147800446\n",
      "trial: 3, iter: 2000, curr loss: 1.2677608728408813, avg loss: 1.2913739061355591\n",
      "trial: 3, iter: 2200, curr loss: 1.2707619667053223, avg loss: 1.283745568394661\n",
      "trial: 3, iter: 2400, curr loss: 1.2777888774871826, avg loss: 1.282203596830368\n",
      "trial: 3, iter: 2600, curr loss: 1.2655067443847656, avg loss: 1.2806566244363784\n",
      "trial: 3, iter: 2800, curr loss: 1.2535909414291382, avg loss: 1.2798927974700929\n",
      "trial: 3, iter: 3000, curr loss: 1.2803707122802734, avg loss: 1.275716347694397\n",
      "trial: 3, iter: 3200, curr loss: 1.2847678661346436, avg loss: 1.275897597670555\n",
      "trial: 3, iter: 3400, curr loss: 1.2709553241729736, avg loss: 1.2706811863183975\n",
      "trial: 3, iter: 3600, curr loss: 1.2508374452590942, avg loss: 1.2743070048093796\n",
      "trial: 3, iter: 3800, curr loss: 1.2297720909118652, avg loss: 1.2747995573282243\n",
      "trial: 3, iter: 4000, curr loss: 1.2715331315994263, avg loss: 1.2717434442043305\n",
      "trial: 3, iter: 4200, curr loss: 1.2665225267410278, avg loss: 1.2690290415287018\n",
      "trial: 3, iter: 4400, curr loss: 1.274307131767273, avg loss: 1.2703309923410415\n",
      "trial: 3, iter: 4600, curr loss: 1.280137538909912, avg loss: 1.2713665229082107\n",
      "trial: 3, iter: 4800, curr loss: 1.2587584257125854, avg loss: 1.2688118124008179\n",
      "trial: 3, iter: 5000, curr loss: 1.251434087753296, avg loss: 1.2697037702798843\n",
      "trial: 3, iter: 5200, curr loss: 1.231075644493103, avg loss: 1.2687214177846908\n",
      "trial: 3, iter: 5400, curr loss: 1.293677806854248, avg loss: 1.268624262213707\n",
      "trial: 3, iter: 5600, curr loss: 1.2582086324691772, avg loss: 1.2673811966180801\n",
      "trial: 3, iter: 5800, curr loss: 1.2637584209442139, avg loss: 1.2670767122507096\n",
      "trial: 3, iter: 6000, curr loss: 1.2377386093139648, avg loss: 1.2673964923620225\n",
      "trial: 3, iter: 6200, curr loss: 1.2670129537582397, avg loss: 1.2654355901479721\n",
      "trial: 3, iter: 6400, curr loss: 1.2870858907699585, avg loss: 1.2672153741121293\n",
      "trial: 3, iter: 6600, curr loss: 1.2947697639465332, avg loss: 1.2643276530504226\n",
      "trial: 3, iter: 6800, curr loss: 1.269595742225647, avg loss: 1.2683098071813583\n",
      "trial: 3, iter: 7000, curr loss: 1.2246298789978027, avg loss: 1.2631687647104264\n",
      "trial: 3, iter: 7200, curr loss: 1.2400100231170654, avg loss: 1.265771843791008\n",
      "trial: 3, iter: 7400, curr loss: 1.242310643196106, avg loss: 1.264050155878067\n",
      "trial: 3, iter: 7600, curr loss: 1.2622686624526978, avg loss: 1.2666290152072905\n",
      "trial: 3, iter: 7800, curr loss: 1.2597694396972656, avg loss: 1.267132979631424\n",
      "trial: 3, iter: 8000, curr loss: 1.2858731746673584, avg loss: 1.265844959616661\n",
      "trial: 3, iter: 8200, curr loss: 1.2578611373901367, avg loss: 1.263651984333992\n",
      "trial: 3, iter: 8400, curr loss: 1.2103077173233032, avg loss: 1.2632113111019134\n",
      "trial: 3, iter: 8600, curr loss: 1.2746015787124634, avg loss: 1.2648607748746872\n",
      "trial: 3, iter: 8800, curr loss: 1.3446539640426636, avg loss: 1.2661941081285477\n",
      "trial: 3, iter: 9000, curr loss: 1.2869609594345093, avg loss: 1.2667985451221466\n",
      "trial: 3, iter: 9200, curr loss: 1.2571945190429688, avg loss: 1.2675492787361144\n",
      "trial: 3, iter: 9400, curr loss: 1.2730737924575806, avg loss: 1.2628963834047318\n",
      "trial: 3, iter: 9600, curr loss: 1.297568917274475, avg loss: 1.265601814389229\n",
      "trial: 3, iter: 9800, curr loss: 1.266409158706665, avg loss: 1.2668066811561585\n",
      "trial: 3, iter: 10000, curr loss: 1.2703971862792969, avg loss: 1.261283209323883\n",
      "trial: 3, iter: 10200, curr loss: 1.2787772417068481, avg loss: 1.2638471454381943\n",
      "trial: 3, iter: 10400, curr loss: 1.2630943059921265, avg loss: 1.2637651234865188\n",
      "trial: 3, iter: 10600, curr loss: 1.282178521156311, avg loss: 1.2627726602554321\n",
      "trial: 3, iter: 10800, curr loss: 1.2419407367706299, avg loss: 1.2656006634235382\n",
      "trial: 3, iter: 11000, curr loss: 1.2754839658737183, avg loss: 1.2653555297851562\n",
      "trial: 3, iter: 11200, curr loss: 1.2892526388168335, avg loss: 1.2607416135072709\n",
      "trial: 3, iter: 11400, curr loss: 1.238057017326355, avg loss: 1.261397156715393\n",
      "trial: 3, iter: 11600, curr loss: 1.2519469261169434, avg loss: 1.2646519500017166\n",
      "trial: 3, iter: 11800, curr loss: 1.2638702392578125, avg loss: 1.2614925634860992\n",
      "trial: 3, iter: 12000, curr loss: 1.2980468273162842, avg loss: 1.262053568959236\n",
      "trial: 3, iter: 12200, curr loss: 1.281017541885376, avg loss: 1.26341803252697\n",
      "trial: 3, iter: 12400, curr loss: 1.2548936605453491, avg loss: 1.2609489250183106\n",
      "trial: 3, iter: 12600, curr loss: 1.2425596714019775, avg loss: 1.2616774547100067\n",
      "trial: 3, iter: 12800, curr loss: 1.253514289855957, avg loss: 1.263645864725113\n",
      "trial: 3, iter: 13000, curr loss: 1.2583158016204834, avg loss: 1.2629078817367554\n",
      "trial: 3, iter: 13200, curr loss: 1.2456858158111572, avg loss: 1.2617885226011276\n",
      "trial: 3, iter: 13400, curr loss: 1.2356524467468262, avg loss: 1.2635980647802354\n",
      "trial: 3, iter: 13600, curr loss: 1.230674147605896, avg loss: 1.2620751088857651\n",
      "trial: 3, iter: 13800, curr loss: 1.2774518728256226, avg loss: 1.2651607537269591\n",
      "trial: 3, iter: 14000, curr loss: 1.2599024772644043, avg loss: 1.2628096336126327\n",
      "trial: 3, iter: 14200, curr loss: 1.3056436777114868, avg loss: 1.2653298437595368\n",
      "trial: 3, iter: 14400, curr loss: 1.2844290733337402, avg loss: 1.2629875564575195\n",
      "trial: 3, iter: 14600, curr loss: 1.3210922479629517, avg loss: 1.2633104300498963\n",
      "trial: 3, iter: 14800, curr loss: 1.2694926261901855, avg loss: 1.2616715604066848\n",
      "trial: 3, iter: 15000, curr loss: 1.2502704858779907, avg loss: 1.2613992869853974\n",
      "trial: 3, iter: 15200, curr loss: 1.26283860206604, avg loss: 1.2629920589923858\n",
      "trial: 3, iter: 15400, curr loss: 1.2724180221557617, avg loss: 1.2618476420640945\n",
      "trial: 3, iter: 15600, curr loss: 1.2634272575378418, avg loss: 1.261157637834549\n",
      "trial: 3, ldr: 0.2897360920906067\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.391498327255249, avg loss: 1.386918049454689\n",
      "trial: 4, iter: 400, curr loss: 1.372328758239746, avg loss: 1.3835888653993607\n",
      "trial: 4, iter: 600, curr loss: 1.3073889017105103, avg loss: 1.3559564411640168\n",
      "trial: 4, iter: 800, curr loss: 1.3053938150405884, avg loss: 1.325377346277237\n",
      "trial: 4, iter: 1000, curr loss: 1.289192795753479, avg loss: 1.317041510939598\n",
      "trial: 4, iter: 1200, curr loss: 1.329551339149475, avg loss: 1.3127238833904267\n",
      "trial: 4, iter: 1400, curr loss: 1.2947126626968384, avg loss: 1.3067130172252654\n",
      "trial: 4, iter: 1600, curr loss: 1.329633355140686, avg loss: 1.3004967761039734\n",
      "trial: 4, iter: 1800, curr loss: 1.3070148229599, avg loss: 1.296803069114685\n",
      "trial: 4, iter: 2000, curr loss: 1.260501503944397, avg loss: 1.2907677793502808\n",
      "trial: 4, iter: 2200, curr loss: 1.3135371208190918, avg loss: 1.284020214676857\n",
      "trial: 4, iter: 2400, curr loss: 1.2848275899887085, avg loss: 1.2778821641206741\n",
      "trial: 4, iter: 2600, curr loss: 1.2833037376403809, avg loss: 1.2741135740280152\n",
      "trial: 4, iter: 2800, curr loss: 1.2815929651260376, avg loss: 1.2716088896989823\n",
      "trial: 4, iter: 3000, curr loss: 1.2816261053085327, avg loss: 1.2763026958703996\n",
      "trial: 4, iter: 3200, curr loss: 1.2489045858383179, avg loss: 1.2744093924760818\n",
      "trial: 4, iter: 3400, curr loss: 1.2778353691101074, avg loss: 1.2706090712547302\n",
      "trial: 4, iter: 3600, curr loss: 1.2761799097061157, avg loss: 1.2727292692661285\n",
      "trial: 4, iter: 3800, curr loss: 1.2912578582763672, avg loss: 1.2706926846504212\n",
      "trial: 4, iter: 4000, curr loss: 1.2626597881317139, avg loss: 1.270727408528328\n",
      "trial: 4, iter: 4200, curr loss: 1.2487496137619019, avg loss: 1.2726779085397721\n",
      "trial: 4, iter: 4400, curr loss: 1.2700568437576294, avg loss: 1.2692828375101088\n",
      "trial: 4, iter: 4600, curr loss: 1.2807693481445312, avg loss: 1.2681342411041259\n",
      "trial: 4, iter: 4800, curr loss: 1.2917474508285522, avg loss: 1.2683260494470596\n",
      "trial: 4, iter: 5000, curr loss: 1.2540795803070068, avg loss: 1.2682107979059218\n",
      "trial: 4, iter: 5200, curr loss: 1.2781596183776855, avg loss: 1.2706018990278245\n",
      "trial: 4, iter: 5400, curr loss: 1.3134745359420776, avg loss: 1.265349844098091\n",
      "trial: 4, iter: 5600, curr loss: 1.2375155687332153, avg loss: 1.268565635085106\n",
      "trial: 4, iter: 5800, curr loss: 1.2848385572433472, avg loss: 1.2701225912570953\n",
      "trial: 4, iter: 6000, curr loss: 1.2372410297393799, avg loss: 1.2651981103420258\n",
      "trial: 4, iter: 6200, curr loss: 1.2676564455032349, avg loss: 1.2659449535608291\n",
      "trial: 4, iter: 6400, curr loss: 1.2847882509231567, avg loss: 1.266365743279457\n",
      "trial: 4, iter: 6600, curr loss: 1.2911304235458374, avg loss: 1.26580859541893\n",
      "trial: 4, iter: 6800, curr loss: 1.2628345489501953, avg loss: 1.2655604833364487\n",
      "trial: 4, iter: 7000, curr loss: 1.2374166250228882, avg loss: 1.2648627960681915\n",
      "trial: 4, iter: 7200, curr loss: 1.2518230676651, avg loss: 1.2641080850362778\n",
      "trial: 4, iter: 7400, curr loss: 1.2731826305389404, avg loss: 1.265032547712326\n",
      "trial: 4, iter: 7600, curr loss: 1.2747323513031006, avg loss: 1.2674860596656798\n",
      "trial: 4, iter: 7800, curr loss: 1.2778679132461548, avg loss: 1.2642147797346115\n",
      "trial: 4, iter: 8000, curr loss: 1.3111217021942139, avg loss: 1.2635548514127732\n",
      "trial: 4, iter: 8200, curr loss: 1.2305428981781006, avg loss: 1.2626295650005341\n",
      "trial: 4, iter: 8400, curr loss: 1.2658684253692627, avg loss: 1.2671467167139054\n",
      "trial: 4, iter: 8600, curr loss: 1.2808669805526733, avg loss: 1.267464919090271\n",
      "trial: 4, iter: 8800, curr loss: 1.2510594129562378, avg loss: 1.2679239529371262\n",
      "trial: 4, iter: 9000, curr loss: 1.2440274953842163, avg loss: 1.263843207359314\n",
      "trial: 4, iter: 9200, curr loss: 1.2192862033843994, avg loss: 1.2630555135011674\n",
      "trial: 4, iter: 9400, curr loss: 1.2665090560913086, avg loss: 1.2637358367443086\n",
      "trial: 4, iter: 9600, curr loss: 1.2837727069854736, avg loss: 1.264143944978714\n",
      "trial: 4, iter: 9800, curr loss: 1.2695999145507812, avg loss: 1.2658391398191453\n",
      "trial: 4, iter: 10000, curr loss: 1.2696986198425293, avg loss: 1.2648741322755814\n",
      "trial: 4, iter: 10200, curr loss: 1.307639241218567, avg loss: 1.2669528156518937\n",
      "trial: 4, iter: 10400, curr loss: 1.2653838396072388, avg loss: 1.2662353205680847\n",
      "trial: 4, iter: 10600, curr loss: 1.2581508159637451, avg loss: 1.2624492716789246\n",
      "trial: 4, iter: 10800, curr loss: 1.2785166501998901, avg loss: 1.2673799109458923\n",
      "trial: 4, iter: 11000, curr loss: 1.2624566555023193, avg loss: 1.2659623003005982\n",
      "trial: 4, iter: 11200, curr loss: 1.2885109186172485, avg loss: 1.266226545572281\n",
      "trial: 4, iter: 11400, curr loss: 1.251103401184082, avg loss: 1.266215660572052\n",
      "trial: 4, iter: 11600, curr loss: 1.2837624549865723, avg loss: 1.2631220865249633\n",
      "trial: 4, iter: 11800, curr loss: 1.2919833660125732, avg loss: 1.2612030589580536\n",
      "trial: 4, iter: 12000, curr loss: 1.2462104558944702, avg loss: 1.2593759208917619\n",
      "trial: 4, iter: 12200, curr loss: 1.2591280937194824, avg loss: 1.261906595826149\n",
      "trial: 4, iter: 12400, curr loss: 1.2589257955551147, avg loss: 1.261480793952942\n",
      "trial: 4, iter: 12600, curr loss: 1.22529935836792, avg loss: 1.2618147075176238\n",
      "trial: 4, iter: 12800, curr loss: 1.2341424226760864, avg loss: 1.2642144292593003\n",
      "trial: 4, iter: 13000, curr loss: 1.2470133304595947, avg loss: 1.2651081758737563\n",
      "trial: 4, iter: 13200, curr loss: 1.2551794052124023, avg loss: 1.2593508070707322\n",
      "trial: 4, iter: 13400, curr loss: 1.240007996559143, avg loss: 1.2619387698173523\n",
      "trial: 4, iter: 13600, curr loss: 1.2717052698135376, avg loss: 1.2633176827430725\n",
      "trial: 4, iter: 13800, curr loss: 1.274096131324768, avg loss: 1.265936935544014\n",
      "trial: 4, iter: 14000, curr loss: 1.2237138748168945, avg loss: 1.2649942696094514\n",
      "trial: 4, iter: 14200, curr loss: 1.3017772436141968, avg loss: 1.2618956446647644\n",
      "trial: 4, iter: 14400, curr loss: 1.2450240850448608, avg loss: 1.2628368270397186\n",
      "trial: 4, iter: 14600, curr loss: 1.2358165979385376, avg loss: 1.2645921593904494\n",
      "trial: 4, iter: 14800, curr loss: 1.2705302238464355, avg loss: 1.262548468708992\n",
      "trial: 4, iter: 15000, curr loss: 1.2321127653121948, avg loss: 1.2630756092071533\n",
      "trial: 4, iter: 15200, curr loss: 1.2777659893035889, avg loss: 1.2618485790491105\n",
      "trial: 4, iter: 15400, curr loss: 1.2381529808044434, avg loss: 1.262367656826973\n",
      "trial: 4, iter: 15600, curr loss: 1.2538602352142334, avg loss: 1.2623972326517106\n",
      "trial: 4, ldr: 0.29856744408607483\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385547399520874, avg loss: 1.3869420158863068\n",
      "trial: 5, iter: 400, curr loss: 1.3801097869873047, avg loss: 1.3842412376403808\n",
      "trial: 5, iter: 600, curr loss: 1.338128685951233, avg loss: 1.36178879737854\n",
      "trial: 5, iter: 800, curr loss: 1.3487505912780762, avg loss: 1.3290864467620849\n",
      "trial: 5, iter: 1000, curr loss: 1.304430603981018, avg loss: 1.3178009378910065\n",
      "trial: 5, iter: 1200, curr loss: 1.2848107814788818, avg loss: 1.3112339389324188\n",
      "trial: 5, iter: 1400, curr loss: 1.2934852838516235, avg loss: 1.3033736300468446\n",
      "trial: 5, iter: 1600, curr loss: 1.2580260038375854, avg loss: 1.299961885213852\n",
      "trial: 5, iter: 1800, curr loss: 1.277515172958374, avg loss: 1.2898532342910767\n",
      "trial: 5, iter: 2000, curr loss: 1.2324539422988892, avg loss: 1.28404398560524\n",
      "trial: 5, iter: 2200, curr loss: 1.2546470165252686, avg loss: 1.2756853860616684\n",
      "trial: 5, iter: 2400, curr loss: 1.2566800117492676, avg loss: 1.2749427986145019\n",
      "trial: 5, iter: 2600, curr loss: 1.2794647216796875, avg loss: 1.2743090558052064\n",
      "trial: 5, iter: 2800, curr loss: 1.2355308532714844, avg loss: 1.2718037283420562\n",
      "trial: 5, iter: 3000, curr loss: 1.2435587644577026, avg loss: 1.2674945205450059\n",
      "trial: 5, iter: 3200, curr loss: 1.281625747680664, avg loss: 1.268143520951271\n",
      "trial: 5, iter: 3400, curr loss: 1.2393218278884888, avg loss: 1.2673281222581863\n",
      "trial: 5, iter: 3600, curr loss: 1.2694220542907715, avg loss: 1.2686935037374496\n",
      "trial: 5, iter: 3800, curr loss: 1.2823576927185059, avg loss: 1.268047975897789\n",
      "trial: 5, iter: 4000, curr loss: 1.299194574356079, avg loss: 1.269478706717491\n",
      "trial: 5, iter: 4200, curr loss: 1.2510323524475098, avg loss: 1.2649821662902831\n",
      "trial: 5, iter: 4400, curr loss: 1.2966928482055664, avg loss: 1.2672117376327514\n",
      "trial: 5, iter: 4600, curr loss: 1.2946263551712036, avg loss: 1.265859380364418\n",
      "trial: 5, iter: 4800, curr loss: 1.269108533859253, avg loss: 1.2682052040100098\n",
      "trial: 5, iter: 5000, curr loss: 1.2754815816879272, avg loss: 1.2633206886053086\n",
      "trial: 5, iter: 5200, curr loss: 1.2356606721878052, avg loss: 1.263741943836212\n",
      "trial: 5, iter: 5400, curr loss: 1.3008233308792114, avg loss: 1.2666213154792785\n",
      "trial: 5, iter: 5600, curr loss: 1.2418025732040405, avg loss: 1.26783689558506\n",
      "trial: 5, iter: 5800, curr loss: 1.2477378845214844, avg loss: 1.2639768075942994\n",
      "trial: 5, iter: 6000, curr loss: 1.244330883026123, avg loss: 1.2688313847780228\n",
      "trial: 5, iter: 6200, curr loss: 1.2331117391586304, avg loss: 1.264114854335785\n",
      "trial: 5, iter: 6400, curr loss: 1.2325063943862915, avg loss: 1.2678717917203903\n",
      "trial: 5, iter: 6600, curr loss: 1.2733337879180908, avg loss: 1.2648120158910752\n",
      "trial: 5, iter: 6800, curr loss: 1.3146275281906128, avg loss: 1.262791548371315\n",
      "trial: 5, iter: 7000, curr loss: 1.2610634565353394, avg loss: 1.2610691744089126\n",
      "trial: 5, iter: 7200, curr loss: 1.2553151845932007, avg loss: 1.2666184437274932\n",
      "trial: 5, iter: 7400, curr loss: 1.2897708415985107, avg loss: 1.2648010903596878\n",
      "trial: 5, iter: 7600, curr loss: 1.2798770666122437, avg loss: 1.2648356902599334\n",
      "trial: 5, iter: 7800, curr loss: 1.235107183456421, avg loss: 1.2651475262641907\n",
      "trial: 5, iter: 8000, curr loss: 1.3123350143432617, avg loss: 1.2640830689668656\n",
      "trial: 5, iter: 8200, curr loss: 1.2578600645065308, avg loss: 1.2620576947927475\n",
      "trial: 5, iter: 8400, curr loss: 1.2646098136901855, avg loss: 1.2649064218997956\n",
      "trial: 5, iter: 8600, curr loss: 1.292786717414856, avg loss: 1.2624904787540436\n",
      "trial: 5, iter: 8800, curr loss: 1.2542966604232788, avg loss: 1.2672352612018585\n",
      "trial: 5, iter: 9000, curr loss: 1.2500215768814087, avg loss: 1.2610914993286133\n",
      "trial: 5, iter: 9200, curr loss: 1.2527600526809692, avg loss: 1.2646276587247849\n",
      "trial: 5, iter: 9400, curr loss: 1.3302212953567505, avg loss: 1.2657375353574754\n",
      "trial: 5, iter: 9600, curr loss: 1.2043826580047607, avg loss: 1.2607891911268234\n",
      "trial: 5, iter: 9800, curr loss: 1.230640172958374, avg loss: 1.261963038444519\n",
      "trial: 5, iter: 10000, curr loss: 1.2948791980743408, avg loss: 1.2646467757225037\n",
      "trial: 5, iter: 10200, curr loss: 1.2969624996185303, avg loss: 1.264148815870285\n",
      "trial: 5, iter: 10400, curr loss: 1.2423781156539917, avg loss: 1.2592437744140625\n",
      "trial: 5, iter: 10600, curr loss: 1.2831634283065796, avg loss: 1.2656756818294526\n",
      "trial: 5, iter: 10800, curr loss: 1.2357326745986938, avg loss: 1.2616768950223922\n",
      "trial: 5, iter: 11000, curr loss: 1.2497841119766235, avg loss: 1.2625029945373536\n",
      "trial: 5, iter: 11200, curr loss: 1.2701737880706787, avg loss: 1.265284064412117\n",
      "trial: 5, iter: 11400, curr loss: 1.295888900756836, avg loss: 1.2647245174646378\n",
      "trial: 5, iter: 11600, curr loss: 1.2606908082962036, avg loss: 1.2601928168535232\n",
      "trial: 5, iter: 11800, curr loss: 1.225011944770813, avg loss: 1.265986851453781\n",
      "trial: 5, iter: 12000, curr loss: 1.2687716484069824, avg loss: 1.263510940670967\n",
      "trial: 5, iter: 12200, curr loss: 1.2702765464782715, avg loss: 1.26394660115242\n",
      "trial: 5, iter: 12400, curr loss: 1.2734612226486206, avg loss: 1.2613992309570312\n",
      "trial: 5, iter: 12600, curr loss: 1.3173519372940063, avg loss: 1.2624870896339417\n",
      "trial: 5, iter: 12800, curr loss: 1.246468424797058, avg loss: 1.264001249074936\n",
      "trial: 5, iter: 13000, curr loss: 1.2086001634597778, avg loss: 1.2604062354564667\n",
      "trial: 5, iter: 13200, curr loss: 1.3007205724716187, avg loss: 1.262305455803871\n",
      "trial: 5, iter: 13400, curr loss: 1.2608977556228638, avg loss: 1.2617614114284514\n",
      "trial: 5, iter: 13600, curr loss: 1.2517144680023193, avg loss: 1.2617014586925506\n",
      "trial: 5, iter: 13800, curr loss: 1.228325605392456, avg loss: 1.2606120890378951\n",
      "trial: 5, iter: 14000, curr loss: 1.2880339622497559, avg loss: 1.2608841222524643\n",
      "trial: 5, iter: 14200, curr loss: 1.2530503273010254, avg loss: 1.2639658081531524\n",
      "trial: 5, iter: 14400, curr loss: 1.3146575689315796, avg loss: 1.2620326006412506\n",
      "trial: 5, iter: 14600, curr loss: 1.271638035774231, avg loss: 1.2636877280473708\n",
      "trial: 5, iter: 14800, curr loss: 1.2392910718917847, avg loss: 1.2617492854595185\n",
      "trial: 5, iter: 15000, curr loss: 1.225713849067688, avg loss: 1.262721012234688\n",
      "trial: 5, iter: 15200, curr loss: 1.2615814208984375, avg loss: 1.2619665604829788\n",
      "trial: 5, iter: 15400, curr loss: 1.268114447593689, avg loss: 1.2609556013345717\n",
      "trial: 5, iter: 15600, curr loss: 1.25081205368042, avg loss: 1.2598829072713853\n",
      "trial: 5, ldr: 0.30861717462539673\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.275655597448349\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3851840496063232, avg loss: 1.386969011425972\n",
      "trial: 1, iter: 400, curr loss: 1.3772050142288208, avg loss: 1.3822157210111619\n",
      "trial: 1, iter: 600, curr loss: 1.3299294710159302, avg loss: 1.357707917690277\n",
      "trial: 1, iter: 800, curr loss: 1.3033947944641113, avg loss: 1.3309276127815246\n",
      "trial: 1, iter: 1000, curr loss: 1.2938811779022217, avg loss: 1.3191469991207123\n",
      "trial: 1, iter: 1200, curr loss: 1.3201372623443604, avg loss: 1.3141541868448257\n",
      "trial: 1, iter: 1400, curr loss: 1.285036563873291, avg loss: 1.310829895734787\n",
      "trial: 1, iter: 1600, curr loss: 1.2979439496994019, avg loss: 1.3050971341133117\n",
      "trial: 1, iter: 1800, curr loss: 1.3023827075958252, avg loss: 1.3000131249427795\n",
      "trial: 1, iter: 2000, curr loss: 1.2884048223495483, avg loss: 1.2927392250299454\n",
      "trial: 1, iter: 2200, curr loss: 1.2747870683670044, avg loss: 1.2909119725227356\n",
      "trial: 1, iter: 2400, curr loss: 1.2718340158462524, avg loss: 1.282781503200531\n",
      "trial: 1, iter: 2600, curr loss: 1.2824857234954834, avg loss: 1.279875408411026\n",
      "trial: 1, iter: 2800, curr loss: 1.3091912269592285, avg loss: 1.276465851664543\n",
      "trial: 1, iter: 3000, curr loss: 1.2684327363967896, avg loss: 1.2740161967277528\n",
      "trial: 1, iter: 3200, curr loss: 1.2933473587036133, avg loss: 1.2694183558225631\n",
      "trial: 1, iter: 3400, curr loss: 1.2894611358642578, avg loss: 1.2710523372888565\n",
      "trial: 1, iter: 3600, curr loss: 1.289835810661316, avg loss: 1.2685635197162628\n",
      "trial: 1, iter: 3800, curr loss: 1.2819387912750244, avg loss: 1.2703103131055833\n",
      "trial: 1, iter: 4000, curr loss: 1.2568267583847046, avg loss: 1.2660720866918564\n",
      "trial: 1, iter: 4200, curr loss: 1.2717869281768799, avg loss: 1.2662080484628677\n",
      "trial: 1, iter: 4400, curr loss: 1.261473536491394, avg loss: 1.2633734571933746\n",
      "trial: 1, iter: 4600, curr loss: 1.2897047996520996, avg loss: 1.2624458986520768\n",
      "trial: 1, iter: 4800, curr loss: 1.2305946350097656, avg loss: 1.2658307087421417\n",
      "trial: 1, iter: 5000, curr loss: 1.2820472717285156, avg loss: 1.2653465753793716\n",
      "trial: 1, iter: 5200, curr loss: 1.2334915399551392, avg loss: 1.2662914723157883\n",
      "trial: 1, iter: 5400, curr loss: 1.2701115608215332, avg loss: 1.2643622398376464\n",
      "trial: 1, iter: 5600, curr loss: 1.25450599193573, avg loss: 1.2634558540582657\n",
      "trial: 1, iter: 5800, curr loss: 1.2801607847213745, avg loss: 1.2669029235839844\n",
      "trial: 1, iter: 6000, curr loss: 1.2616074085235596, avg loss: 1.2629355895519256\n",
      "trial: 1, iter: 6200, curr loss: 1.2518725395202637, avg loss: 1.2657477390766143\n",
      "trial: 1, iter: 6400, curr loss: 1.2386937141418457, avg loss: 1.2647616231441499\n",
      "trial: 1, iter: 6600, curr loss: 1.2789478302001953, avg loss: 1.2654956871271132\n",
      "trial: 1, iter: 6800, curr loss: 1.286526083946228, avg loss: 1.26571164727211\n",
      "trial: 1, iter: 7000, curr loss: 1.2555183172225952, avg loss: 1.2649147844314574\n",
      "trial: 1, iter: 7200, curr loss: 1.310895323753357, avg loss: 1.2676933723688126\n",
      "trial: 1, iter: 7400, curr loss: 1.2667698860168457, avg loss: 1.2637504893541336\n",
      "trial: 1, iter: 7600, curr loss: 1.2522566318511963, avg loss: 1.2622537511587142\n",
      "trial: 1, iter: 7800, curr loss: 1.2655972242355347, avg loss: 1.2649188661575317\n",
      "trial: 1, iter: 8000, curr loss: 1.312857747077942, avg loss: 1.263800864815712\n",
      "trial: 1, iter: 8200, curr loss: 1.2772490978240967, avg loss: 1.2647745937108994\n",
      "trial: 1, iter: 8400, curr loss: 1.2487558126449585, avg loss: 1.263545687198639\n",
      "trial: 1, iter: 8600, curr loss: 1.2407652139663696, avg loss: 1.2663867563009261\n",
      "trial: 1, iter: 8800, curr loss: 1.263900637626648, avg loss: 1.2618169939517976\n",
      "trial: 1, iter: 9000, curr loss: 1.300262212753296, avg loss: 1.2676520437002181\n",
      "trial: 1, iter: 9200, curr loss: 1.2612566947937012, avg loss: 1.2620480996370316\n",
      "trial: 1, iter: 9400, curr loss: 1.2200648784637451, avg loss: 1.2636275672912598\n",
      "trial: 1, iter: 9600, curr loss: 1.2443971633911133, avg loss: 1.2628583413362504\n",
      "trial: 1, iter: 9800, curr loss: 1.267159342765808, avg loss: 1.2636250698566436\n",
      "trial: 1, iter: 10000, curr loss: 1.2327685356140137, avg loss: 1.2612679201364516\n",
      "trial: 1, iter: 10200, curr loss: 1.2942296266555786, avg loss: 1.2644455814361573\n",
      "trial: 1, iter: 10400, curr loss: 1.2392737865447998, avg loss: 1.2626034992933273\n",
      "trial: 1, iter: 10600, curr loss: 1.2663882970809937, avg loss: 1.261698259115219\n",
      "trial: 1, iter: 10800, curr loss: 1.255142331123352, avg loss: 1.2617350608110427\n",
      "trial: 1, iter: 11000, curr loss: 1.2329524755477905, avg loss: 1.2632349133491516\n",
      "trial: 1, iter: 11200, curr loss: 1.2613178491592407, avg loss: 1.2632020902633667\n",
      "trial: 1, iter: 11400, curr loss: 1.2664597034454346, avg loss: 1.2570711022615433\n",
      "trial: 1, iter: 11600, curr loss: 1.2454663515090942, avg loss: 1.2615468031167985\n",
      "trial: 1, iter: 11800, curr loss: 1.2790191173553467, avg loss: 1.2622116231918334\n",
      "trial: 1, iter: 12000, curr loss: 1.2615293264389038, avg loss: 1.2641847187280655\n",
      "trial: 1, iter: 12200, curr loss: 1.2319669723510742, avg loss: 1.2607333022356033\n",
      "trial: 1, iter: 12400, curr loss: 1.244307279586792, avg loss: 1.2617617255449296\n",
      "trial: 1, iter: 12600, curr loss: 1.279334306716919, avg loss: 1.2627704268693924\n",
      "trial: 1, iter: 12800, curr loss: 1.2723888158798218, avg loss: 1.258374024629593\n",
      "trial: 1, iter: 13000, curr loss: 1.274212121963501, avg loss: 1.262166701555252\n",
      "trial: 1, iter: 13200, curr loss: 1.270328402519226, avg loss: 1.2635977441072463\n",
      "trial: 1, iter: 13400, curr loss: 1.2437946796417236, avg loss: 1.2584294879436493\n",
      "trial: 1, iter: 13600, curr loss: 1.3072335720062256, avg loss: 1.2645191836357117\n",
      "trial: 1, iter: 13800, curr loss: 1.258093237876892, avg loss: 1.2606651055812836\n",
      "trial: 1, iter: 14000, curr loss: 1.228467345237732, avg loss: 1.2641446280479431\n",
      "trial: 1, iter: 14200, curr loss: 1.2845118045806885, avg loss: 1.2628170949220658\n",
      "trial: 1, iter: 14400, curr loss: 1.2793713808059692, avg loss: 1.2646089988946914\n",
      "trial: 1, iter: 14600, curr loss: 1.2462961673736572, avg loss: 1.26175783097744\n",
      "trial: 1, iter: 14800, curr loss: 1.2812840938568115, avg loss: 1.2569684052467347\n",
      "trial: 1, iter: 15000, curr loss: 1.301185965538025, avg loss: 1.260938510298729\n",
      "trial: 1, iter: 15200, curr loss: 1.2442703247070312, avg loss: 1.2598899787664413\n",
      "trial: 1, iter: 15400, curr loss: 1.2823725938796997, avg loss: 1.2623791456222535\n",
      "trial: 1, iter: 15600, curr loss: 1.3115469217300415, avg loss: 1.2626609843969345\n",
      "trial: 1, ldr: 0.24662934243679047\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3830360174179077, avg loss: 1.3874764132499695\n",
      "trial: 2, iter: 400, curr loss: 1.3765355348587036, avg loss: 1.3827227401733397\n",
      "trial: 2, iter: 600, curr loss: 1.3041669130325317, avg loss: 1.3474166250228883\n",
      "trial: 2, iter: 800, curr loss: 1.3094203472137451, avg loss: 1.3231332713365556\n",
      "trial: 2, iter: 1000, curr loss: 1.3089205026626587, avg loss: 1.314863564968109\n",
      "trial: 2, iter: 1200, curr loss: 1.2804670333862305, avg loss: 1.3095733314752578\n",
      "trial: 2, iter: 1400, curr loss: 1.2801748514175415, avg loss: 1.3064917361736297\n",
      "trial: 2, iter: 1600, curr loss: 1.282918095588684, avg loss: 1.3035289943218231\n",
      "trial: 2, iter: 1800, curr loss: 1.305573582649231, avg loss: 1.294589923620224\n",
      "trial: 2, iter: 2000, curr loss: 1.3014259338378906, avg loss: 1.2890291851758957\n",
      "trial: 2, iter: 2200, curr loss: 1.3014771938323975, avg loss: 1.286636647582054\n",
      "trial: 2, iter: 2400, curr loss: 1.2862894535064697, avg loss: 1.2804996871948242\n",
      "trial: 2, iter: 2600, curr loss: 1.2952789068222046, avg loss: 1.2789393526315689\n",
      "trial: 2, iter: 2800, curr loss: 1.2264795303344727, avg loss: 1.2812491685152054\n",
      "trial: 2, iter: 3000, curr loss: 1.2778373956680298, avg loss: 1.274976846575737\n",
      "trial: 2, iter: 3200, curr loss: 1.284125566482544, avg loss: 1.274933444261551\n",
      "trial: 2, iter: 3400, curr loss: 1.2695194482803345, avg loss: 1.2698103952407838\n",
      "trial: 2, iter: 3600, curr loss: 1.2578699588775635, avg loss: 1.2659019756317138\n",
      "trial: 2, iter: 3800, curr loss: 1.2741100788116455, avg loss: 1.2697502100467681\n",
      "trial: 2, iter: 4000, curr loss: 1.2765648365020752, avg loss: 1.2691856616735457\n",
      "trial: 2, iter: 4200, curr loss: 1.3091140985488892, avg loss: 1.2655126500129699\n",
      "trial: 2, iter: 4400, curr loss: 1.2992247343063354, avg loss: 1.2668516355752946\n",
      "trial: 2, iter: 4600, curr loss: 1.2550240755081177, avg loss: 1.2642045569419862\n",
      "trial: 2, iter: 4800, curr loss: 1.3149136304855347, avg loss: 1.2663653272390365\n",
      "trial: 2, iter: 5000, curr loss: 1.2751665115356445, avg loss: 1.2637668716907502\n",
      "trial: 2, iter: 5200, curr loss: 1.2610008716583252, avg loss: 1.2639987897872924\n",
      "trial: 2, iter: 5400, curr loss: 1.2779254913330078, avg loss: 1.2643866354227067\n",
      "trial: 2, iter: 5600, curr loss: 1.351683259010315, avg loss: 1.2645378875732423\n",
      "trial: 2, iter: 5800, curr loss: 1.2809892892837524, avg loss: 1.265738679766655\n",
      "trial: 2, iter: 6000, curr loss: 1.2226934432983398, avg loss: 1.2608754807710647\n",
      "trial: 2, iter: 6200, curr loss: 1.2578483819961548, avg loss: 1.26803955078125\n",
      "trial: 2, iter: 6400, curr loss: 1.254049301147461, avg loss: 1.2625762075185776\n",
      "trial: 2, iter: 6600, curr loss: 1.2852790355682373, avg loss: 1.266579622030258\n",
      "trial: 2, iter: 6800, curr loss: 1.2708436250686646, avg loss: 1.2652076005935669\n",
      "trial: 2, iter: 7000, curr loss: 1.2758560180664062, avg loss: 1.264264126420021\n",
      "trial: 2, iter: 7200, curr loss: 1.2330992221832275, avg loss: 1.2640748167037963\n",
      "trial: 2, iter: 7400, curr loss: 1.2570358514785767, avg loss: 1.2623769015073776\n",
      "trial: 2, iter: 7600, curr loss: 1.2735717296600342, avg loss: 1.2635997211933137\n",
      "trial: 2, iter: 7800, curr loss: 1.2611595392227173, avg loss: 1.262092216014862\n",
      "trial: 2, iter: 8000, curr loss: 1.2739882469177246, avg loss: 1.2649125754833221\n",
      "trial: 2, iter: 8200, curr loss: 1.2398114204406738, avg loss: 1.2635831731557845\n",
      "trial: 2, iter: 8400, curr loss: 1.2471281290054321, avg loss: 1.2633046036958695\n",
      "trial: 2, iter: 8600, curr loss: 1.286019206047058, avg loss: 1.2672303014993667\n",
      "trial: 2, iter: 8800, curr loss: 1.2426759004592896, avg loss: 1.2624185931682588\n",
      "trial: 2, iter: 9000, curr loss: 1.2199496030807495, avg loss: 1.2644737768173218\n",
      "trial: 2, iter: 9200, curr loss: 1.326848030090332, avg loss: 1.2698100793361664\n",
      "trial: 2, iter: 9400, curr loss: 1.2512640953063965, avg loss: 1.262903271317482\n",
      "trial: 2, iter: 9600, curr loss: 1.2541199922561646, avg loss: 1.2673436099290847\n",
      "trial: 2, iter: 9800, curr loss: 1.264795184135437, avg loss: 1.2617388421297073\n",
      "trial: 2, iter: 10000, curr loss: 1.2853233814239502, avg loss: 1.2626045167446136\n",
      "trial: 2, iter: 10200, curr loss: 1.2473565340042114, avg loss: 1.2602822881937028\n",
      "trial: 2, iter: 10400, curr loss: 1.2402784824371338, avg loss: 1.2651727044582366\n",
      "trial: 2, iter: 10600, curr loss: 1.281022310256958, avg loss: 1.261701231598854\n",
      "trial: 2, iter: 10800, curr loss: 1.2890069484710693, avg loss: 1.259888795018196\n",
      "trial: 2, iter: 11000, curr loss: 1.2454571723937988, avg loss: 1.2623120164871215\n",
      "trial: 2, iter: 11200, curr loss: 1.3192092180252075, avg loss: 1.264410691857338\n",
      "trial: 2, iter: 11400, curr loss: 1.2776789665222168, avg loss: 1.263235086798668\n",
      "trial: 2, iter: 11600, curr loss: 1.2514926195144653, avg loss: 1.260396739244461\n",
      "trial: 2, iter: 11800, curr loss: 1.268110752105713, avg loss: 1.2666035407781602\n",
      "trial: 2, iter: 12000, curr loss: 1.2710771560668945, avg loss: 1.2622591280937194\n",
      "trial: 2, iter: 12200, curr loss: 1.2735693454742432, avg loss: 1.2594782239198685\n",
      "trial: 2, iter: 12400, curr loss: 1.2603017091751099, avg loss: 1.2623087787628173\n",
      "trial: 2, iter: 12600, curr loss: 1.3203167915344238, avg loss: 1.2602119636535645\n",
      "trial: 2, iter: 12800, curr loss: 1.2998988628387451, avg loss: 1.2634294527769088\n",
      "trial: 2, iter: 13000, curr loss: 1.2849550247192383, avg loss: 1.2633466374874116\n",
      "trial: 2, iter: 13200, curr loss: 1.2361708879470825, avg loss: 1.2636235058307648\n",
      "trial: 2, iter: 13400, curr loss: 1.2540411949157715, avg loss: 1.2604092121124268\n",
      "trial: 2, iter: 13600, curr loss: 1.282025933265686, avg loss: 1.2592260038852692\n",
      "trial: 2, iter: 13800, curr loss: 1.2824211120605469, avg loss: 1.26327467918396\n",
      "trial: 2, iter: 14000, curr loss: 1.2880793809890747, avg loss: 1.2615418404340744\n",
      "trial: 2, iter: 14200, curr loss: 1.2806015014648438, avg loss: 1.2623513501882553\n",
      "trial: 2, iter: 14400, curr loss: 1.2378365993499756, avg loss: 1.2617147064208984\n",
      "trial: 2, iter: 14600, curr loss: 1.266890048980713, avg loss: 1.2601262885332107\n",
      "trial: 2, iter: 14800, curr loss: 1.253691554069519, avg loss: 1.2596426677703858\n",
      "trial: 2, iter: 15000, curr loss: 1.2564408779144287, avg loss: 1.2630073237419128\n",
      "trial: 2, iter: 15200, curr loss: 1.2924706935882568, avg loss: 1.2637157833576202\n",
      "trial: 2, iter: 15400, curr loss: 1.2774606943130493, avg loss: 1.2605695909261703\n",
      "trial: 2, iter: 15600, curr loss: 1.2569587230682373, avg loss: 1.2604653304815292\n",
      "trial: 2, ldr: 0.28004884719848633\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3830571174621582, avg loss: 1.3871827763319016\n",
      "trial: 3, iter: 400, curr loss: 1.3536014556884766, avg loss: 1.3785031229257583\n",
      "trial: 3, iter: 600, curr loss: 1.3577008247375488, avg loss: 1.3408163863420486\n",
      "trial: 3, iter: 800, curr loss: 1.377767562866211, avg loss: 1.3214362949132918\n",
      "trial: 3, iter: 1000, curr loss: 1.325369119644165, avg loss: 1.3131533992290496\n",
      "trial: 3, iter: 1200, curr loss: 1.2955656051635742, avg loss: 1.308350003361702\n",
      "trial: 3, iter: 1400, curr loss: 1.2834292650222778, avg loss: 1.3023640024662018\n",
      "trial: 3, iter: 1600, curr loss: 1.3097364902496338, avg loss: 1.300853612422943\n",
      "trial: 3, iter: 1800, curr loss: 1.2757030725479126, avg loss: 1.2938504320383073\n",
      "trial: 3, iter: 2000, curr loss: 1.3022496700286865, avg loss: 1.2858675163984299\n",
      "trial: 3, iter: 2200, curr loss: 1.254539966583252, avg loss: 1.281989830136299\n",
      "trial: 3, iter: 2400, curr loss: 1.2829617261886597, avg loss: 1.2756882774829865\n",
      "trial: 3, iter: 2600, curr loss: 1.2833325862884521, avg loss: 1.2747626948356627\n",
      "trial: 3, iter: 2800, curr loss: 1.2779229879379272, avg loss: 1.2756695884466172\n",
      "trial: 3, iter: 3000, curr loss: 1.3173468112945557, avg loss: 1.2713696980476379\n",
      "trial: 3, iter: 3200, curr loss: 1.25053071975708, avg loss: 1.2715073919296265\n",
      "trial: 3, iter: 3400, curr loss: 1.260967493057251, avg loss: 1.2695842069387435\n",
      "trial: 3, iter: 3600, curr loss: 1.237243890762329, avg loss: 1.2693844813108444\n",
      "trial: 3, iter: 3800, curr loss: 1.2382359504699707, avg loss: 1.2720550817251206\n",
      "trial: 3, iter: 4000, curr loss: 1.3143728971481323, avg loss: 1.2709693068265915\n",
      "trial: 3, iter: 4200, curr loss: 1.264967441558838, avg loss: 1.2691889369487763\n",
      "trial: 3, iter: 4400, curr loss: 1.230003833770752, avg loss: 1.2671190595626831\n",
      "trial: 3, iter: 4600, curr loss: 1.2321933507919312, avg loss: 1.2685470300912858\n",
      "trial: 3, iter: 4800, curr loss: 1.248873233795166, avg loss: 1.2656739604473115\n",
      "trial: 3, iter: 5000, curr loss: 1.2655596733093262, avg loss: 1.2645891386270522\n",
      "trial: 3, iter: 5200, curr loss: 1.299109935760498, avg loss: 1.2689929723739624\n",
      "trial: 3, iter: 5400, curr loss: 1.3007606267929077, avg loss: 1.2607416093349457\n",
      "trial: 3, iter: 5600, curr loss: 1.2796838283538818, avg loss: 1.2668737453222274\n",
      "trial: 3, iter: 5800, curr loss: 1.3117073774337769, avg loss: 1.2662883865833283\n",
      "trial: 3, iter: 6000, curr loss: 1.269220232963562, avg loss: 1.2671448343992233\n",
      "trial: 3, iter: 6200, curr loss: 1.2807599306106567, avg loss: 1.2634291851520538\n",
      "trial: 3, iter: 6400, curr loss: 1.2499040365219116, avg loss: 1.2644666796922683\n",
      "trial: 3, iter: 6600, curr loss: 1.2768737077713013, avg loss: 1.2658090394735337\n",
      "trial: 3, iter: 6800, curr loss: 1.2488117218017578, avg loss: 1.2676234209537507\n",
      "trial: 3, iter: 7000, curr loss: 1.2282196283340454, avg loss: 1.2657384258508682\n",
      "trial: 3, iter: 7200, curr loss: 1.245590329170227, avg loss: 1.2633377385139466\n",
      "trial: 3, iter: 7400, curr loss: 1.2600245475769043, avg loss: 1.2632422798871994\n",
      "trial: 3, iter: 7600, curr loss: 1.276438593864441, avg loss: 1.269403344988823\n",
      "trial: 3, iter: 7800, curr loss: 1.2443296909332275, avg loss: 1.2663610863685608\n",
      "trial: 3, iter: 8000, curr loss: 1.2828043699264526, avg loss: 1.2613902431726456\n",
      "trial: 3, iter: 8200, curr loss: 1.2876476049423218, avg loss: 1.2613663458824158\n",
      "trial: 3, iter: 8400, curr loss: 1.2595571279525757, avg loss: 1.2623807829618454\n",
      "trial: 3, iter: 8600, curr loss: 1.2945692539215088, avg loss: 1.264456113576889\n",
      "trial: 3, iter: 8800, curr loss: 1.273796796798706, avg loss: 1.2622677671909333\n",
      "trial: 3, iter: 9000, curr loss: 1.3188445568084717, avg loss: 1.2640917104482652\n",
      "trial: 3, iter: 9200, curr loss: 1.2475686073303223, avg loss: 1.260884993672371\n",
      "trial: 3, iter: 9400, curr loss: 1.2567157745361328, avg loss: 1.2621031868457795\n",
      "trial: 3, iter: 9600, curr loss: 1.2980023622512817, avg loss: 1.2632722193002701\n",
      "trial: 3, iter: 9800, curr loss: 1.2688238620758057, avg loss: 1.2611521637439729\n",
      "trial: 3, iter: 10000, curr loss: 1.1991912126541138, avg loss: 1.2606895005702972\n",
      "trial: 3, iter: 10200, curr loss: 1.269548773765564, avg loss: 1.265693575143814\n",
      "trial: 3, iter: 10400, curr loss: 1.2116122245788574, avg loss: 1.2627586895227432\n",
      "trial: 3, iter: 10600, curr loss: 1.2773597240447998, avg loss: 1.2652137458324433\n",
      "trial: 3, iter: 10800, curr loss: 1.250680685043335, avg loss: 1.2611940968036652\n",
      "trial: 3, iter: 11000, curr loss: 1.2267136573791504, avg loss: 1.2633618181943893\n",
      "trial: 3, iter: 11200, curr loss: 1.279649019241333, avg loss: 1.2640484935045242\n",
      "trial: 3, iter: 11400, curr loss: 1.2539587020874023, avg loss: 1.2617762130498886\n",
      "trial: 3, iter: 11600, curr loss: 1.3205890655517578, avg loss: 1.2624264019727707\n",
      "trial: 3, iter: 11800, curr loss: 1.2838599681854248, avg loss: 1.2612559068202973\n",
      "trial: 3, iter: 12000, curr loss: 1.231015682220459, avg loss: 1.2604622721672059\n",
      "trial: 3, iter: 12200, curr loss: 1.2748897075653076, avg loss: 1.2632325345277786\n",
      "trial: 3, iter: 12400, curr loss: 1.3001538515090942, avg loss: 1.259921128153801\n",
      "trial: 3, iter: 12600, curr loss: 1.2788591384887695, avg loss: 1.2592795068025588\n",
      "trial: 3, iter: 12800, curr loss: 1.2356820106506348, avg loss: 1.2635915219783782\n",
      "trial: 3, iter: 13000, curr loss: 1.2425059080123901, avg loss: 1.2633761745691299\n",
      "trial: 3, iter: 13200, curr loss: 1.3149555921554565, avg loss: 1.260107398033142\n",
      "trial: 3, iter: 13400, curr loss: 1.2482486963272095, avg loss: 1.261114580631256\n",
      "trial: 3, iter: 13600, curr loss: 1.2879884243011475, avg loss: 1.2634955799579621\n",
      "trial: 3, iter: 13800, curr loss: 1.2479465007781982, avg loss: 1.2597558605670929\n",
      "trial: 3, iter: 14000, curr loss: 1.3005090951919556, avg loss: 1.2608917075395585\n",
      "trial: 3, iter: 14200, curr loss: 1.32435142993927, avg loss: 1.2623108929395677\n",
      "trial: 3, iter: 14400, curr loss: 1.2677258253097534, avg loss: 1.2626093858480454\n",
      "trial: 3, iter: 14600, curr loss: 1.2850172519683838, avg loss: 1.2618229460716248\n",
      "trial: 3, iter: 14800, curr loss: 1.2567086219787598, avg loss: 1.26012300491333\n",
      "trial: 3, iter: 15000, curr loss: 1.267515778541565, avg loss: 1.2586262392997742\n",
      "trial: 3, iter: 15200, curr loss: 1.264070987701416, avg loss: 1.2618035942316055\n",
      "trial: 3, iter: 15400, curr loss: 1.2460124492645264, avg loss: 1.2595667904615402\n",
      "trial: 3, iter: 15600, curr loss: 1.2691324949264526, avg loss: 1.2626995074748992\n",
      "trial: 3, ldr: 0.2744956910610199\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3822908401489258, avg loss: 1.3868069571256638\n",
      "trial: 4, iter: 400, curr loss: 1.3742932081222534, avg loss: 1.3788358634710312\n",
      "trial: 4, iter: 600, curr loss: 1.344590187072754, avg loss: 1.3420008462667465\n",
      "trial: 4, iter: 800, curr loss: 1.2864795923233032, avg loss: 1.3212991964817047\n",
      "trial: 4, iter: 1000, curr loss: 1.313736081123352, avg loss: 1.3147486650943756\n",
      "trial: 4, iter: 1200, curr loss: 1.309116244316101, avg loss: 1.3095527225732804\n",
      "trial: 4, iter: 1400, curr loss: 1.2843842506408691, avg loss: 1.3056780582666396\n",
      "trial: 4, iter: 1600, curr loss: 1.2874109745025635, avg loss: 1.299289693236351\n",
      "trial: 4, iter: 1800, curr loss: 1.2786198854446411, avg loss: 1.292860820889473\n",
      "trial: 4, iter: 2000, curr loss: 1.2362666130065918, avg loss: 1.2901612150669097\n",
      "trial: 4, iter: 2200, curr loss: 1.3110629320144653, avg loss: 1.2819278204441071\n",
      "trial: 4, iter: 2400, curr loss: 1.2718020677566528, avg loss: 1.2760752123594283\n",
      "trial: 4, iter: 2600, curr loss: 1.279005765914917, avg loss: 1.2746999913454056\n",
      "trial: 4, iter: 2800, curr loss: 1.2578351497650146, avg loss: 1.2732911676168441\n",
      "trial: 4, iter: 3000, curr loss: 1.2727302312850952, avg loss: 1.2710707592964172\n",
      "trial: 4, iter: 3200, curr loss: 1.2649288177490234, avg loss: 1.2705735385417938\n",
      "trial: 4, iter: 3400, curr loss: 1.244382381439209, avg loss: 1.2696258455514908\n",
      "trial: 4, iter: 3600, curr loss: 1.3183361291885376, avg loss: 1.2703482896089553\n",
      "trial: 4, iter: 3800, curr loss: 1.2813975811004639, avg loss: 1.2703199553489686\n",
      "trial: 4, iter: 4000, curr loss: 1.24479341506958, avg loss: 1.2684377896785737\n",
      "trial: 4, iter: 4200, curr loss: 1.2547744512557983, avg loss: 1.2661170339584351\n",
      "trial: 4, iter: 4400, curr loss: 1.275848388671875, avg loss: 1.269522317647934\n",
      "trial: 4, iter: 4600, curr loss: 1.248414397239685, avg loss: 1.2688692164421083\n",
      "trial: 4, iter: 4800, curr loss: 1.236879825592041, avg loss: 1.2655370289087295\n",
      "trial: 4, iter: 5000, curr loss: 1.28006112575531, avg loss: 1.265228362083435\n",
      "trial: 4, iter: 5200, curr loss: 1.3029413223266602, avg loss: 1.266525877714157\n",
      "trial: 4, iter: 5400, curr loss: 1.2618355751037598, avg loss: 1.2671235638856888\n",
      "trial: 4, iter: 5600, curr loss: 1.265061616897583, avg loss: 1.2654151701927185\n",
      "trial: 4, iter: 5800, curr loss: 1.2380069494247437, avg loss: 1.263104739189148\n",
      "trial: 4, iter: 6000, curr loss: 1.2831635475158691, avg loss: 1.2650832545757293\n",
      "trial: 4, iter: 6200, curr loss: 1.269188404083252, avg loss: 1.2658080571889878\n",
      "trial: 4, iter: 6400, curr loss: 1.2660318613052368, avg loss: 1.2622257035970688\n",
      "trial: 4, iter: 6600, curr loss: 1.2710106372833252, avg loss: 1.264991231560707\n",
      "trial: 4, iter: 6800, curr loss: 1.2700386047363281, avg loss: 1.2634012305736542\n",
      "trial: 4, iter: 7000, curr loss: 1.256397008895874, avg loss: 1.2636406654119492\n",
      "trial: 4, iter: 7200, curr loss: 1.2521770000457764, avg loss: 1.263416913151741\n",
      "trial: 4, iter: 7400, curr loss: 1.246785044670105, avg loss: 1.262272601723671\n",
      "trial: 4, iter: 7600, curr loss: 1.2492992877960205, avg loss: 1.2665610843896866\n",
      "trial: 4, iter: 7800, curr loss: 1.2554161548614502, avg loss: 1.266699459552765\n",
      "trial: 4, iter: 8000, curr loss: 1.2480040788650513, avg loss: 1.2636462539434432\n",
      "trial: 4, iter: 8200, curr loss: 1.2365049123764038, avg loss: 1.2621858912706374\n",
      "trial: 4, iter: 8400, curr loss: 1.2924178838729858, avg loss: 1.2643431693315506\n",
      "trial: 4, iter: 8600, curr loss: 1.2773622274398804, avg loss: 1.2632609152793883\n",
      "trial: 4, iter: 8800, curr loss: 1.2302109003067017, avg loss: 1.2603462302684785\n",
      "trial: 4, iter: 9000, curr loss: 1.2484052181243896, avg loss: 1.2663241940736771\n",
      "trial: 4, iter: 9200, curr loss: 1.284991979598999, avg loss: 1.2604187941551208\n",
      "trial: 4, iter: 9400, curr loss: 1.2931917905807495, avg loss: 1.2624451011419295\n",
      "trial: 4, iter: 9600, curr loss: 1.281432032585144, avg loss: 1.2633971047401429\n",
      "trial: 4, iter: 9800, curr loss: 1.2379528284072876, avg loss: 1.2621408140659331\n",
      "trial: 4, iter: 10000, curr loss: 1.2723090648651123, avg loss: 1.261946175098419\n",
      "trial: 4, iter: 10200, curr loss: 1.267248272895813, avg loss: 1.2636244547367097\n",
      "trial: 4, iter: 10400, curr loss: 1.2670583724975586, avg loss: 1.2636068773269653\n",
      "trial: 4, iter: 10600, curr loss: 1.2312926054000854, avg loss: 1.262206610441208\n",
      "trial: 4, iter: 10800, curr loss: 1.265065312385559, avg loss: 1.2622711902856827\n",
      "trial: 4, iter: 11000, curr loss: 1.2939810752868652, avg loss: 1.26267449259758\n",
      "trial: 4, iter: 11200, curr loss: 1.2231426239013672, avg loss: 1.2622170853614807\n",
      "trial: 4, iter: 11400, curr loss: 1.293255090713501, avg loss: 1.2573057651519775\n",
      "trial: 4, iter: 11600, curr loss: 1.258596658706665, avg loss: 1.263099063038826\n",
      "trial: 4, iter: 11800, curr loss: 1.2321605682373047, avg loss: 1.2620446765422821\n",
      "trial: 4, iter: 12000, curr loss: 1.260455846786499, avg loss: 1.2625000077486037\n",
      "trial: 4, iter: 12200, curr loss: 1.3136190176010132, avg loss: 1.2666260308027268\n",
      "trial: 4, iter: 12400, curr loss: 1.2830346822738647, avg loss: 1.2614706081151963\n",
      "trial: 4, iter: 12600, curr loss: 1.2778786420822144, avg loss: 1.2607646721601486\n",
      "trial: 4, iter: 12800, curr loss: 1.2394590377807617, avg loss: 1.261745216846466\n",
      "trial: 4, iter: 13000, curr loss: 1.2664382457733154, avg loss: 1.2604867279529572\n",
      "trial: 4, iter: 13200, curr loss: 1.2338811159133911, avg loss: 1.2608767312765121\n",
      "trial: 4, iter: 13400, curr loss: 1.2888215780258179, avg loss: 1.26179057598114\n",
      "trial: 4, iter: 13600, curr loss: 1.2476201057434082, avg loss: 1.2577338355779648\n",
      "trial: 4, iter: 13800, curr loss: 1.2210893630981445, avg loss: 1.2607782274484634\n",
      "trial: 4, iter: 14000, curr loss: 1.236694574356079, avg loss: 1.261442928314209\n",
      "trial: 4, iter: 14200, curr loss: 1.283262848854065, avg loss: 1.2627397006750107\n",
      "trial: 4, iter: 14400, curr loss: 1.2621928453445435, avg loss: 1.2622290080785752\n",
      "trial: 4, iter: 14600, curr loss: 1.2604587078094482, avg loss: 1.2623691844940186\n",
      "trial: 4, iter: 14800, curr loss: 1.2321158647537231, avg loss: 1.2600423127412796\n",
      "trial: 4, iter: 15000, curr loss: 1.2910374402999878, avg loss: 1.263623765707016\n",
      "trial: 4, iter: 15200, curr loss: 1.2767516374588013, avg loss: 1.2584283876419067\n",
      "trial: 4, iter: 15400, curr loss: 1.2342514991760254, avg loss: 1.2606592851877212\n",
      "trial: 4, iter: 15600, curr loss: 1.235687017440796, avg loss: 1.258681532740593\n",
      "trial: 4, ldr: 0.31457096338272095\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3850398063659668, avg loss: 1.386728999018669\n",
      "trial: 5, iter: 400, curr loss: 1.3792856931686401, avg loss: 1.385597517490387\n",
      "trial: 5, iter: 600, curr loss: 1.3463456630706787, avg loss: 1.3707637906074523\n",
      "trial: 5, iter: 800, curr loss: 1.3331562280654907, avg loss: 1.330475515127182\n",
      "trial: 5, iter: 1000, curr loss: 1.3029550313949585, avg loss: 1.3166813272237778\n",
      "trial: 5, iter: 1200, curr loss: 1.3105138540267944, avg loss: 1.3085970902442932\n",
      "trial: 5, iter: 1400, curr loss: 1.283883810043335, avg loss: 1.30156059384346\n",
      "trial: 5, iter: 1600, curr loss: 1.314012885093689, avg loss: 1.2983980852365493\n",
      "trial: 5, iter: 1800, curr loss: 1.2587416172027588, avg loss: 1.290347820520401\n",
      "trial: 5, iter: 2000, curr loss: 1.2890533208847046, avg loss: 1.2860469597578048\n",
      "trial: 5, iter: 2200, curr loss: 1.2909103631973267, avg loss: 1.282047243118286\n",
      "trial: 5, iter: 2400, curr loss: 1.3065706491470337, avg loss: 1.2790701544284822\n",
      "trial: 5, iter: 2600, curr loss: 1.2927228212356567, avg loss: 1.2734643912315369\n",
      "trial: 5, iter: 2800, curr loss: 1.2624419927597046, avg loss: 1.2725849890708922\n",
      "trial: 5, iter: 3000, curr loss: 1.2271323204040527, avg loss: 1.2677164739370346\n",
      "trial: 5, iter: 3200, curr loss: 1.246666431427002, avg loss: 1.2670510762929916\n",
      "trial: 5, iter: 3400, curr loss: 1.2886713743209839, avg loss: 1.2683885657787324\n",
      "trial: 5, iter: 3600, curr loss: 1.2598516941070557, avg loss: 1.2667761933803559\n",
      "trial: 5, iter: 3800, curr loss: 1.3025790452957153, avg loss: 1.2692188769578934\n",
      "trial: 5, iter: 4000, curr loss: 1.2301850318908691, avg loss: 1.2628113096952438\n",
      "trial: 5, iter: 4200, curr loss: 1.262695550918579, avg loss: 1.2628278750181199\n",
      "trial: 5, iter: 4400, curr loss: 1.2109479904174805, avg loss: 1.265681393146515\n",
      "trial: 5, iter: 4600, curr loss: 1.277410626411438, avg loss: 1.2655357575416566\n",
      "trial: 5, iter: 4800, curr loss: 1.2872028350830078, avg loss: 1.2664575344324112\n",
      "trial: 5, iter: 5000, curr loss: 1.264211893081665, avg loss: 1.2657801026105882\n",
      "trial: 5, iter: 5200, curr loss: 1.2287590503692627, avg loss: 1.2634733444452286\n",
      "trial: 5, iter: 5400, curr loss: 1.3114222288131714, avg loss: 1.2641819930076599\n",
      "trial: 5, iter: 5600, curr loss: 1.2601008415222168, avg loss: 1.266235302090645\n",
      "trial: 5, iter: 5800, curr loss: 1.2520341873168945, avg loss: 1.2628925728797913\n",
      "trial: 5, iter: 6000, curr loss: 1.2831705808639526, avg loss: 1.264422563314438\n",
      "trial: 5, iter: 6200, curr loss: 1.2697241306304932, avg loss: 1.2637355190515518\n",
      "trial: 5, iter: 6400, curr loss: 1.2724186182022095, avg loss: 1.261760339140892\n",
      "trial: 5, iter: 6600, curr loss: 1.2752426862716675, avg loss: 1.262842488884926\n",
      "trial: 5, iter: 6800, curr loss: 1.257859230041504, avg loss: 1.2643668192625046\n",
      "trial: 5, iter: 7000, curr loss: 1.2144440412521362, avg loss: 1.2652486366033555\n",
      "trial: 5, iter: 7200, curr loss: 1.2574940919876099, avg loss: 1.2647245931625366\n",
      "trial: 5, iter: 7400, curr loss: 1.2879687547683716, avg loss: 1.2601168036460877\n",
      "trial: 5, iter: 7600, curr loss: 1.2639305591583252, avg loss: 1.2608172601461411\n",
      "trial: 5, iter: 7800, curr loss: 1.231201171875, avg loss: 1.2605502909421922\n",
      "trial: 5, iter: 8000, curr loss: 1.2852463722229004, avg loss: 1.261991304755211\n",
      "trial: 5, iter: 8200, curr loss: 1.2235298156738281, avg loss: 1.260828006863594\n",
      "trial: 5, iter: 8400, curr loss: 1.2548620700836182, avg loss: 1.2625121921300888\n",
      "trial: 5, iter: 8600, curr loss: 1.2160508632659912, avg loss: 1.2621730214357376\n",
      "trial: 5, iter: 8800, curr loss: 1.2604598999023438, avg loss: 1.2655063098669053\n",
      "trial: 5, iter: 9000, curr loss: 1.2680892944335938, avg loss: 1.265143052339554\n",
      "trial: 5, iter: 9200, curr loss: 1.2458539009094238, avg loss: 1.264113834500313\n",
      "trial: 5, iter: 9400, curr loss: 1.2406035661697388, avg loss: 1.2611713922023773\n",
      "trial: 5, iter: 9600, curr loss: 1.2211387157440186, avg loss: 1.259811977148056\n",
      "trial: 5, iter: 9800, curr loss: 1.282862663269043, avg loss: 1.2604786771535874\n",
      "trial: 5, iter: 10000, curr loss: 1.2705738544464111, avg loss: 1.2620797950029372\n",
      "trial: 5, iter: 10200, curr loss: 1.3426141738891602, avg loss: 1.26247050344944\n",
      "trial: 5, iter: 10400, curr loss: 1.2111709117889404, avg loss: 1.2612470877170563\n",
      "trial: 5, iter: 10600, curr loss: 1.3261480331420898, avg loss: 1.2624913185834885\n",
      "trial: 5, iter: 10800, curr loss: 1.2017043828964233, avg loss: 1.257861431837082\n",
      "trial: 5, iter: 11000, curr loss: 1.2774170637130737, avg loss: 1.2595863020420075\n",
      "trial: 5, iter: 11200, curr loss: 1.229849100112915, avg loss: 1.260499694943428\n",
      "trial: 5, iter: 11400, curr loss: 1.3055548667907715, avg loss: 1.2634442716836929\n",
      "trial: 5, iter: 11600, curr loss: 1.2565757036209106, avg loss: 1.2627746289968491\n",
      "trial: 5, iter: 11800, curr loss: 1.2733662128448486, avg loss: 1.2619401198625564\n",
      "trial: 5, iter: 12000, curr loss: 1.2675403356552124, avg loss: 1.2631094855070115\n",
      "trial: 5, iter: 12200, curr loss: 1.2803245782852173, avg loss: 1.2625719314813615\n",
      "trial: 5, iter: 12400, curr loss: 1.2991187572479248, avg loss: 1.2616869276762008\n",
      "trial: 5, iter: 12600, curr loss: 1.2906725406646729, avg loss: 1.2612296444177629\n",
      "trial: 5, iter: 12800, curr loss: 1.2507644891738892, avg loss: 1.259798299074173\n",
      "trial: 5, iter: 13000, curr loss: 1.2719579935073853, avg loss: 1.2612615740299224\n",
      "trial: 5, iter: 13200, curr loss: 1.280561923980713, avg loss: 1.26202849984169\n",
      "trial: 5, iter: 13400, curr loss: 1.1951453685760498, avg loss: 1.2619579547643662\n",
      "trial: 5, iter: 13600, curr loss: 1.2747185230255127, avg loss: 1.2616457754373551\n",
      "trial: 5, iter: 13800, curr loss: 1.2797422409057617, avg loss: 1.2599917924404145\n",
      "trial: 5, iter: 14000, curr loss: 1.2728509902954102, avg loss: 1.2596699851751327\n",
      "trial: 5, iter: 14200, curr loss: 1.2475664615631104, avg loss: 1.2629889047145844\n",
      "trial: 5, iter: 14400, curr loss: 1.2403244972229004, avg loss: 1.2624702209234238\n",
      "trial: 5, iter: 14600, curr loss: 1.2341253757476807, avg loss: 1.263194228410721\n",
      "trial: 5, iter: 14800, curr loss: 1.2400047779083252, avg loss: 1.2613330096006394\n",
      "trial: 5, iter: 15000, curr loss: 1.2963201999664307, avg loss: 1.2614321690797805\n",
      "trial: 5, iter: 15200, curr loss: 1.2918933629989624, avg loss: 1.2614318293333053\n",
      "trial: 5, iter: 15400, curr loss: 1.2991368770599365, avg loss: 1.2586570382118225\n",
      "trial: 5, iter: 15600, curr loss: 1.2454164028167725, avg loss: 1.261437767148018\n",
      "trial: 5, ldr: 0.20005644857883453\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26316025853157043\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3851804733276367, avg loss: 1.3870042711496353\n",
      "trial: 1, iter: 400, curr loss: 1.3683360815048218, avg loss: 1.3815466499328612\n",
      "trial: 1, iter: 600, curr loss: 1.3006548881530762, avg loss: 1.3465805649757385\n",
      "trial: 1, iter: 800, curr loss: 1.3142199516296387, avg loss: 1.324489968419075\n",
      "trial: 1, iter: 1000, curr loss: 1.3366127014160156, avg loss: 1.3143036490678788\n",
      "trial: 1, iter: 1200, curr loss: 1.298120141029358, avg loss: 1.310548415184021\n",
      "trial: 1, iter: 1400, curr loss: 1.2831945419311523, avg loss: 1.3026773351430894\n",
      "trial: 1, iter: 1600, curr loss: 1.2881993055343628, avg loss: 1.3008804267644882\n",
      "trial: 1, iter: 1800, curr loss: 1.2929538488388062, avg loss: 1.2953892302513124\n",
      "trial: 1, iter: 2000, curr loss: 1.2625024318695068, avg loss: 1.2901752138137816\n",
      "trial: 1, iter: 2200, curr loss: 1.267898440361023, avg loss: 1.2879609835147858\n",
      "trial: 1, iter: 2400, curr loss: 1.2768900394439697, avg loss: 1.2801354283094406\n",
      "trial: 1, iter: 2600, curr loss: 1.3045105934143066, avg loss: 1.275683434009552\n",
      "trial: 1, iter: 2800, curr loss: 1.2905865907669067, avg loss: 1.2739678913354873\n",
      "trial: 1, iter: 3000, curr loss: 1.2674834728240967, avg loss: 1.2724989080429077\n",
      "trial: 1, iter: 3200, curr loss: 1.2368897199630737, avg loss: 1.2685068649053575\n",
      "trial: 1, iter: 3400, curr loss: 1.2478034496307373, avg loss: 1.264451949596405\n",
      "trial: 1, iter: 3600, curr loss: 1.265958547592163, avg loss: 1.2692362362146377\n",
      "trial: 1, iter: 3800, curr loss: 1.24916672706604, avg loss: 1.2671101063489913\n",
      "trial: 1, iter: 4000, curr loss: 1.2361464500427246, avg loss: 1.2680031394958495\n",
      "trial: 1, iter: 4200, curr loss: 1.2474477291107178, avg loss: 1.267416330575943\n",
      "trial: 1, iter: 4400, curr loss: 1.268781065940857, avg loss: 1.2664749413728713\n",
      "trial: 1, iter: 4600, curr loss: 1.2849982976913452, avg loss: 1.2661954402923583\n",
      "trial: 1, iter: 4800, curr loss: 1.2811617851257324, avg loss: 1.2642698645591737\n",
      "trial: 1, iter: 5000, curr loss: 1.3048673868179321, avg loss: 1.2662439727783203\n",
      "trial: 1, iter: 5200, curr loss: 1.2757095098495483, avg loss: 1.2653582614660264\n",
      "trial: 1, iter: 5400, curr loss: 1.2798898220062256, avg loss: 1.2637984317541122\n",
      "trial: 1, iter: 5600, curr loss: 1.2794678211212158, avg loss: 1.2649218267202378\n",
      "trial: 1, iter: 5800, curr loss: 1.2882215976715088, avg loss: 1.2619347894191741\n",
      "trial: 1, iter: 6000, curr loss: 1.2550867795944214, avg loss: 1.2662575185298919\n",
      "trial: 1, iter: 6200, curr loss: 1.2722033262252808, avg loss: 1.2653466713428498\n",
      "trial: 1, iter: 6400, curr loss: 1.2884808778762817, avg loss: 1.2642032319307328\n",
      "trial: 1, iter: 6600, curr loss: 1.260266661643982, avg loss: 1.260634640455246\n",
      "trial: 1, iter: 6800, curr loss: 1.2559657096862793, avg loss: 1.2652299654483796\n",
      "trial: 1, iter: 7000, curr loss: 1.2290798425674438, avg loss: 1.263903090953827\n",
      "trial: 1, iter: 7200, curr loss: 1.2867867946624756, avg loss: 1.2630517387390137\n",
      "trial: 1, iter: 7400, curr loss: 1.2561341524124146, avg loss: 1.2627046805620195\n",
      "trial: 1, iter: 7600, curr loss: 1.2776389122009277, avg loss: 1.2632956796884536\n",
      "trial: 1, iter: 7800, curr loss: 1.2618725299835205, avg loss: 1.2648888778686525\n",
      "trial: 1, iter: 8000, curr loss: 1.2261874675750732, avg loss: 1.2620878970623017\n",
      "trial: 1, iter: 8200, curr loss: 1.2675271034240723, avg loss: 1.2639334774017335\n",
      "trial: 1, iter: 8400, curr loss: 1.2278568744659424, avg loss: 1.2610004019737244\n",
      "trial: 1, iter: 8600, curr loss: 1.2843272686004639, avg loss: 1.2641238296031951\n",
      "trial: 1, iter: 8800, curr loss: 1.266347050666809, avg loss: 1.26462621986866\n",
      "trial: 1, iter: 9000, curr loss: 1.2871662378311157, avg loss: 1.2635470324754714\n",
      "trial: 1, iter: 9200, curr loss: 1.2633119821548462, avg loss: 1.2625168949365615\n",
      "trial: 1, iter: 9400, curr loss: 1.2412530183792114, avg loss: 1.2629449415206908\n",
      "trial: 1, iter: 9600, curr loss: 1.279816746711731, avg loss: 1.2642302876710891\n",
      "trial: 1, iter: 9800, curr loss: 1.236532211303711, avg loss: 1.2609330821037292\n",
      "trial: 1, iter: 10000, curr loss: 1.2755159139633179, avg loss: 1.263878184556961\n",
      "trial: 1, iter: 10200, curr loss: 1.2303111553192139, avg loss: 1.2600936287641524\n",
      "trial: 1, iter: 10400, curr loss: 1.304648518562317, avg loss: 1.2616685074567795\n",
      "trial: 1, iter: 10600, curr loss: 1.270176887512207, avg loss: 1.2622041606903076\n",
      "trial: 1, iter: 10800, curr loss: 1.2297674417495728, avg loss: 1.2632171642780303\n",
      "trial: 1, iter: 11000, curr loss: 1.2634761333465576, avg loss: 1.2620010197162628\n",
      "trial: 1, iter: 11200, curr loss: 1.2847307920455933, avg loss: 1.2613901782035828\n",
      "trial: 1, iter: 11400, curr loss: 1.2553199529647827, avg loss: 1.260323470234871\n",
      "trial: 1, iter: 11600, curr loss: 1.2442268133163452, avg loss: 1.2593147355318068\n",
      "trial: 1, iter: 11800, curr loss: 1.2834351062774658, avg loss: 1.2611832636594773\n",
      "trial: 1, iter: 12000, curr loss: 1.2485002279281616, avg loss: 1.2613992381095886\n",
      "trial: 1, iter: 12200, curr loss: 1.2804476022720337, avg loss: 1.2606093233823776\n",
      "trial: 1, iter: 12400, curr loss: 1.2297759056091309, avg loss: 1.2566101622581483\n",
      "trial: 1, iter: 12600, curr loss: 1.2372413873672485, avg loss: 1.2633812868595122\n",
      "trial: 1, iter: 12800, curr loss: 1.2755610942840576, avg loss: 1.2585943228006362\n",
      "trial: 1, iter: 13000, curr loss: 1.2510582208633423, avg loss: 1.2628386789560317\n",
      "trial: 1, iter: 13200, curr loss: 1.2731941938400269, avg loss: 1.262180704474449\n",
      "trial: 1, iter: 13400, curr loss: 1.2921069860458374, avg loss: 1.262871578335762\n",
      "trial: 1, iter: 13600, curr loss: 1.272714376449585, avg loss: 1.2608078372478486\n",
      "trial: 1, iter: 13800, curr loss: 1.2562755346298218, avg loss: 1.2615677696466445\n",
      "trial: 1, iter: 14000, curr loss: 1.3046379089355469, avg loss: 1.2619490200281143\n",
      "trial: 1, iter: 14200, curr loss: 1.2734344005584717, avg loss: 1.259633247256279\n",
      "trial: 1, iter: 14400, curr loss: 1.2617223262786865, avg loss: 1.260918236374855\n",
      "trial: 1, iter: 14600, curr loss: 1.2674739360809326, avg loss: 1.2590895879268647\n",
      "trial: 1, iter: 14800, curr loss: 1.2850875854492188, avg loss: 1.264746252298355\n",
      "trial: 1, iter: 15000, curr loss: 1.2443492412567139, avg loss: 1.2605267989635467\n",
      "trial: 1, iter: 15200, curr loss: 1.2966396808624268, avg loss: 1.2624259120225907\n",
      "trial: 1, iter: 15400, curr loss: 1.2632488012313843, avg loss: 1.259685411453247\n",
      "trial: 1, iter: 15600, curr loss: 1.2863221168518066, avg loss: 1.261601459980011\n",
      "trial: 1, ldr: 0.23684066534042358\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.385103464126587, avg loss: 1.3868777388334275\n",
      "trial: 2, iter: 400, curr loss: 1.3714613914489746, avg loss: 1.3811554855108261\n",
      "trial: 2, iter: 600, curr loss: 1.345688819885254, avg loss: 1.3438968235254287\n",
      "trial: 2, iter: 800, curr loss: 1.3083075284957886, avg loss: 1.3204156154394149\n",
      "trial: 2, iter: 1000, curr loss: 1.3104275465011597, avg loss: 1.3126710736751557\n",
      "trial: 2, iter: 1200, curr loss: 1.305760145187378, avg loss: 1.3071480983495711\n",
      "trial: 2, iter: 1400, curr loss: 1.28531014919281, avg loss: 1.303173440694809\n",
      "trial: 2, iter: 1600, curr loss: 1.3075107336044312, avg loss: 1.296051608324051\n",
      "trial: 2, iter: 1800, curr loss: 1.2943553924560547, avg loss: 1.292118166089058\n",
      "trial: 2, iter: 2000, curr loss: 1.2799540758132935, avg loss: 1.2874761909246444\n",
      "trial: 2, iter: 2200, curr loss: 1.2932517528533936, avg loss: 1.2840519589185715\n",
      "trial: 2, iter: 2400, curr loss: 1.2379391193389893, avg loss: 1.2806471931934356\n",
      "trial: 2, iter: 2600, curr loss: 1.2636899948120117, avg loss: 1.2785901165008544\n",
      "trial: 2, iter: 2800, curr loss: 1.312790870666504, avg loss: 1.2739480417966842\n",
      "trial: 2, iter: 3000, curr loss: 1.2048403024673462, avg loss: 1.270212768316269\n",
      "trial: 2, iter: 3200, curr loss: 1.2466795444488525, avg loss: 1.2701261800527572\n",
      "trial: 2, iter: 3400, curr loss: 1.249809980392456, avg loss: 1.270139797925949\n",
      "trial: 2, iter: 3600, curr loss: 1.3105192184448242, avg loss: 1.268584457039833\n",
      "trial: 2, iter: 3800, curr loss: 1.2089637517929077, avg loss: 1.2662316703796386\n",
      "trial: 2, iter: 4000, curr loss: 1.234200358390808, avg loss: 1.2702175003290177\n",
      "trial: 2, iter: 4200, curr loss: 1.2500566244125366, avg loss: 1.2650858926773072\n",
      "trial: 2, iter: 4400, curr loss: 1.265934705734253, avg loss: 1.2673109620809555\n",
      "trial: 2, iter: 4600, curr loss: 1.2722506523132324, avg loss: 1.265506722331047\n",
      "trial: 2, iter: 4800, curr loss: 1.2656582593917847, avg loss: 1.2669610679149628\n",
      "trial: 2, iter: 5000, curr loss: 1.2452259063720703, avg loss: 1.2641409468650817\n",
      "trial: 2, iter: 5200, curr loss: 1.2589399814605713, avg loss: 1.2614227724075318\n",
      "trial: 2, iter: 5400, curr loss: 1.3036599159240723, avg loss: 1.2651111853122712\n",
      "trial: 2, iter: 5600, curr loss: 1.2815223932266235, avg loss: 1.2638832998275757\n",
      "trial: 2, iter: 5800, curr loss: 1.2934411764144897, avg loss: 1.266296534538269\n",
      "trial: 2, iter: 6000, curr loss: 1.312812089920044, avg loss: 1.2650456875562668\n",
      "trial: 2, iter: 6200, curr loss: 1.284123420715332, avg loss: 1.2663589799404145\n",
      "trial: 2, iter: 6400, curr loss: 1.2216356992721558, avg loss: 1.263149356842041\n",
      "trial: 2, iter: 6600, curr loss: 1.25741708278656, avg loss: 1.2641011542081833\n",
      "trial: 2, iter: 6800, curr loss: 1.314634919166565, avg loss: 1.2617045718431472\n",
      "trial: 2, iter: 7000, curr loss: 1.2466826438903809, avg loss: 1.2647600543498994\n",
      "trial: 2, iter: 7200, curr loss: 1.2921767234802246, avg loss: 1.259747942686081\n",
      "trial: 2, iter: 7400, curr loss: 1.2762975692749023, avg loss: 1.262786210179329\n",
      "trial: 2, iter: 7600, curr loss: 1.2596564292907715, avg loss: 1.2618279844522475\n",
      "trial: 2, iter: 7800, curr loss: 1.2362040281295776, avg loss: 1.261556614637375\n",
      "trial: 2, iter: 8000, curr loss: 1.285548448562622, avg loss: 1.263961324095726\n",
      "trial: 2, iter: 8200, curr loss: 1.2496846914291382, avg loss: 1.2603057312965393\n",
      "trial: 2, iter: 8400, curr loss: 1.2659378051757812, avg loss: 1.2613955026865005\n",
      "trial: 2, iter: 8600, curr loss: 1.2607903480529785, avg loss: 1.260748661160469\n",
      "trial: 2, iter: 8800, curr loss: 1.2817342281341553, avg loss: 1.2627521365880967\n",
      "trial: 2, iter: 9000, curr loss: 1.277167558670044, avg loss: 1.2633895808458329\n",
      "trial: 2, iter: 9200, curr loss: 1.2610118389129639, avg loss: 1.2625077253580093\n",
      "trial: 2, iter: 9400, curr loss: 1.2451452016830444, avg loss: 1.2619167101383209\n",
      "trial: 2, iter: 9600, curr loss: 1.2951112985610962, avg loss: 1.2607221215963365\n",
      "trial: 2, iter: 9800, curr loss: 1.261705756187439, avg loss: 1.2574131268262863\n",
      "trial: 2, iter: 10000, curr loss: 1.2255927324295044, avg loss: 1.259340700507164\n",
      "trial: 2, iter: 10200, curr loss: 1.2610551118850708, avg loss: 1.2588170391321183\n",
      "trial: 2, iter: 10400, curr loss: 1.259626865386963, avg loss: 1.261643186211586\n",
      "trial: 2, iter: 10600, curr loss: 1.2487175464630127, avg loss: 1.2586491733789444\n",
      "trial: 2, iter: 10800, curr loss: 1.1957138776779175, avg loss: 1.261170797944069\n",
      "trial: 2, iter: 11000, curr loss: 1.3004125356674194, avg loss: 1.2578261065483094\n",
      "trial: 2, iter: 11200, curr loss: 1.262148141860962, avg loss: 1.262806243300438\n",
      "trial: 2, iter: 11400, curr loss: 1.2523925304412842, avg loss: 1.262320691347122\n",
      "trial: 2, iter: 11600, curr loss: 1.2355084419250488, avg loss: 1.2597501254081727\n",
      "trial: 2, iter: 11800, curr loss: 1.2344940900802612, avg loss: 1.2595940160751342\n",
      "trial: 2, iter: 12000, curr loss: 1.2636789083480835, avg loss: 1.2613996267318726\n",
      "trial: 2, iter: 12200, curr loss: 1.2437142133712769, avg loss: 1.2614175075292586\n",
      "trial: 2, iter: 12400, curr loss: 1.251358985900879, avg loss: 1.2588793051242828\n",
      "trial: 2, iter: 12600, curr loss: 1.2570477724075317, avg loss: 1.2641352707147597\n",
      "trial: 2, iter: 12800, curr loss: 1.2909387350082397, avg loss: 1.2622541308403015\n",
      "trial: 2, iter: 13000, curr loss: 1.2454493045806885, avg loss: 1.2616507452726364\n",
      "trial: 2, iter: 13200, curr loss: 1.2479231357574463, avg loss: 1.2590010380744934\n",
      "trial: 2, iter: 13400, curr loss: 1.2672239542007446, avg loss: 1.262406152486801\n",
      "trial: 2, iter: 13600, curr loss: 1.293639898300171, avg loss: 1.2629474371671676\n",
      "trial: 2, iter: 13800, curr loss: 1.2617417573928833, avg loss: 1.2612974178791045\n",
      "trial: 2, iter: 14000, curr loss: 1.2740463018417358, avg loss: 1.2612355482578277\n",
      "trial: 2, iter: 14200, curr loss: 1.2749568223953247, avg loss: 1.2583394253253937\n",
      "trial: 2, iter: 14400, curr loss: 1.2804267406463623, avg loss: 1.2605664813518525\n",
      "trial: 2, iter: 14600, curr loss: 1.2367526292800903, avg loss: 1.2603679180145264\n",
      "trial: 2, iter: 14800, curr loss: 1.2273584604263306, avg loss: 1.2594813895225525\n",
      "trial: 2, iter: 15000, curr loss: 1.2016370296478271, avg loss: 1.258414558172226\n",
      "trial: 2, iter: 15200, curr loss: 1.2367857694625854, avg loss: 1.2619369256496429\n",
      "trial: 2, iter: 15400, curr loss: 1.2928627729415894, avg loss: 1.260379464030266\n",
      "trial: 2, iter: 15600, curr loss: 1.230164647102356, avg loss: 1.2593497508764266\n",
      "trial: 2, ldr: 0.2912293076515198\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3863223791122437, avg loss: 1.386822566986084\n",
      "trial: 3, iter: 400, curr loss: 1.36960768699646, avg loss: 1.3827477705478668\n",
      "trial: 3, iter: 600, curr loss: 1.3491442203521729, avg loss: 1.3467781311273574\n",
      "trial: 3, iter: 800, curr loss: 1.337748408317566, avg loss: 1.3201165521144866\n",
      "trial: 3, iter: 1000, curr loss: 1.3530426025390625, avg loss: 1.316356366276741\n",
      "trial: 3, iter: 1200, curr loss: 1.3116146326065063, avg loss: 1.3088436651229858\n",
      "trial: 3, iter: 1400, curr loss: 1.3022724390029907, avg loss: 1.3042726933956146\n",
      "trial: 3, iter: 1600, curr loss: 1.282332420349121, avg loss: 1.3011746335029601\n",
      "trial: 3, iter: 1800, curr loss: 1.315413475036621, avg loss: 1.2938366121053695\n",
      "trial: 3, iter: 2000, curr loss: 1.3154352903366089, avg loss: 1.2869649481773378\n",
      "trial: 3, iter: 2200, curr loss: 1.2792223691940308, avg loss: 1.2795392751693726\n",
      "trial: 3, iter: 2400, curr loss: 1.2719099521636963, avg loss: 1.2759120869636535\n",
      "trial: 3, iter: 2600, curr loss: 1.255487084388733, avg loss: 1.271259017586708\n",
      "trial: 3, iter: 2800, curr loss: 1.2673702239990234, avg loss: 1.2668736386299133\n",
      "trial: 3, iter: 3000, curr loss: 1.256474494934082, avg loss: 1.2695577317476272\n",
      "trial: 3, iter: 3200, curr loss: 1.2400333881378174, avg loss: 1.2694371330738068\n",
      "trial: 3, iter: 3400, curr loss: 1.2553173303604126, avg loss: 1.26523668885231\n",
      "trial: 3, iter: 3600, curr loss: 1.243676781654358, avg loss: 1.2647470390796662\n",
      "trial: 3, iter: 3800, curr loss: 1.2344883680343628, avg loss: 1.2671907526254653\n",
      "trial: 3, iter: 4000, curr loss: 1.2387052774429321, avg loss: 1.2667617011070251\n",
      "trial: 3, iter: 4200, curr loss: 1.2405585050582886, avg loss: 1.2671269583702087\n",
      "trial: 3, iter: 4400, curr loss: 1.2388440370559692, avg loss: 1.2643125283718109\n",
      "trial: 3, iter: 4600, curr loss: 1.24372136592865, avg loss: 1.2642112869024276\n",
      "trial: 3, iter: 4800, curr loss: 1.2534823417663574, avg loss: 1.2681580609083176\n",
      "trial: 3, iter: 5000, curr loss: 1.3318061828613281, avg loss: 1.2628795474767684\n",
      "trial: 3, iter: 5200, curr loss: 1.224601149559021, avg loss: 1.2615624845027924\n",
      "trial: 3, iter: 5400, curr loss: 1.2144203186035156, avg loss: 1.2646332168579102\n",
      "trial: 3, iter: 5600, curr loss: 1.2534703016281128, avg loss: 1.2598604595661163\n",
      "trial: 3, iter: 5800, curr loss: 1.2971463203430176, avg loss: 1.2652675414085388\n",
      "trial: 3, iter: 6000, curr loss: 1.2526562213897705, avg loss: 1.2637313205003737\n",
      "trial: 3, iter: 6200, curr loss: 1.3054527044296265, avg loss: 1.2618942701816558\n",
      "trial: 3, iter: 6400, curr loss: 1.290677785873413, avg loss: 1.267843069434166\n",
      "trial: 3, iter: 6600, curr loss: 1.2439430952072144, avg loss: 1.262599260210991\n",
      "trial: 3, iter: 6800, curr loss: 1.2504594326019287, avg loss: 1.2639725345373154\n",
      "trial: 3, iter: 7000, curr loss: 1.248106837272644, avg loss: 1.2618131065368652\n",
      "trial: 3, iter: 7200, curr loss: 1.2772308588027954, avg loss: 1.2635116076469421\n",
      "trial: 3, iter: 7400, curr loss: 1.256876826286316, avg loss: 1.2628357005119324\n",
      "trial: 3, iter: 7600, curr loss: 1.304990291595459, avg loss: 1.2645737540721893\n",
      "trial: 3, iter: 7800, curr loss: 1.2787138223648071, avg loss: 1.260514984726906\n",
      "trial: 3, iter: 8000, curr loss: 1.253352165222168, avg loss: 1.263698509335518\n",
      "trial: 3, iter: 8200, curr loss: 1.21482515335083, avg loss: 1.261457815170288\n",
      "trial: 3, iter: 8400, curr loss: 1.298814296722412, avg loss: 1.2654347002506257\n",
      "trial: 3, iter: 8600, curr loss: 1.2376794815063477, avg loss: 1.2596300333738326\n",
      "trial: 3, iter: 8800, curr loss: 1.2271634340286255, avg loss: 1.261901409626007\n",
      "trial: 3, iter: 9000, curr loss: 1.2898682355880737, avg loss: 1.2640560626983643\n",
      "trial: 3, iter: 9200, curr loss: 1.23070228099823, avg loss: 1.2584426367282868\n",
      "trial: 3, iter: 9400, curr loss: 1.2989156246185303, avg loss: 1.2635427796840668\n",
      "trial: 3, iter: 9600, curr loss: 1.2636759281158447, avg loss: 1.2647385162115097\n",
      "trial: 3, iter: 9800, curr loss: 1.2677791118621826, avg loss: 1.2630056601762771\n",
      "trial: 3, iter: 10000, curr loss: 1.2656910419464111, avg loss: 1.26326842546463\n",
      "trial: 3, iter: 10200, curr loss: 1.2571443319320679, avg loss: 1.2629873341321944\n",
      "trial: 3, iter: 10400, curr loss: 1.2554495334625244, avg loss: 1.2597589945793153\n",
      "trial: 3, iter: 10600, curr loss: 1.240072250366211, avg loss: 1.258518767952919\n",
      "trial: 3, iter: 10800, curr loss: 1.2735341787338257, avg loss: 1.2628260028362275\n",
      "trial: 3, iter: 11000, curr loss: 1.27800714969635, avg loss: 1.2618071728944777\n",
      "trial: 3, iter: 11200, curr loss: 1.2490551471710205, avg loss: 1.2611175912618637\n",
      "trial: 3, iter: 11400, curr loss: 1.2903521060943604, avg loss: 1.263056485056877\n",
      "trial: 3, iter: 11600, curr loss: 1.2702269554138184, avg loss: 1.2631085741519927\n",
      "trial: 3, iter: 11800, curr loss: 1.3066293001174927, avg loss: 1.2606662547588348\n",
      "trial: 3, iter: 12000, curr loss: 1.2521991729736328, avg loss: 1.261507676243782\n",
      "trial: 3, iter: 12200, curr loss: 1.2410049438476562, avg loss: 1.2580032366514207\n",
      "trial: 3, iter: 12400, curr loss: 1.2872189283370972, avg loss: 1.2610341799259186\n",
      "trial: 3, iter: 12600, curr loss: 1.2403690814971924, avg loss: 1.2586243849992753\n",
      "trial: 3, iter: 12800, curr loss: 1.2917046546936035, avg loss: 1.26130145072937\n",
      "trial: 3, iter: 13000, curr loss: 1.2777732610702515, avg loss: 1.262659952044487\n",
      "trial: 3, iter: 13200, curr loss: 1.2624359130859375, avg loss: 1.2608875393867494\n",
      "trial: 3, iter: 13400, curr loss: 1.2556378841400146, avg loss: 1.2637675285339356\n",
      "trial: 3, iter: 13600, curr loss: 1.2712336778640747, avg loss: 1.25923779129982\n",
      "trial: 3, iter: 13800, curr loss: 1.2164705991744995, avg loss: 1.2607201552391052\n",
      "trial: 3, iter: 14000, curr loss: 1.2715991735458374, avg loss: 1.2620029950141907\n",
      "trial: 3, iter: 14200, curr loss: 1.2570769786834717, avg loss: 1.2570683765411377\n",
      "trial: 3, iter: 14400, curr loss: 1.2457140684127808, avg loss: 1.2588517314195633\n",
      "trial: 3, iter: 14600, curr loss: 1.255527377128601, avg loss: 1.2576731234788894\n",
      "trial: 3, iter: 14800, curr loss: 1.2593055963516235, avg loss: 1.262105364203453\n",
      "trial: 3, iter: 15000, curr loss: 1.224423885345459, avg loss: 1.2614440137147904\n",
      "trial: 3, iter: 15200, curr loss: 1.279999852180481, avg loss: 1.2567339646816253\n",
      "trial: 3, iter: 15400, curr loss: 1.2774003744125366, avg loss: 1.2615905207395555\n",
      "trial: 3, iter: 15600, curr loss: 1.298056960105896, avg loss: 1.2605198258161545\n",
      "trial: 3, ldr: 0.280383825302124\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3856632709503174, avg loss: 1.3865882456302643\n",
      "trial: 4, iter: 400, curr loss: 1.363577961921692, avg loss: 1.3767164647579193\n",
      "trial: 4, iter: 600, curr loss: 1.3625116348266602, avg loss: 1.3382954490184784\n",
      "trial: 4, iter: 800, curr loss: 1.3299745321273804, avg loss: 1.320923563838005\n",
      "trial: 4, iter: 1000, curr loss: 1.3058587312698364, avg loss: 1.3174869042634965\n",
      "trial: 4, iter: 1200, curr loss: 1.291871190071106, avg loss: 1.3127856773138047\n",
      "trial: 4, iter: 1400, curr loss: 1.3066595792770386, avg loss: 1.3042726480960847\n",
      "trial: 4, iter: 1600, curr loss: 1.277318000793457, avg loss: 1.3023349565267563\n",
      "trial: 4, iter: 1800, curr loss: 1.2813189029693604, avg loss: 1.2963447594642639\n",
      "trial: 4, iter: 2000, curr loss: 1.2709378004074097, avg loss: 1.2917630416154862\n",
      "trial: 4, iter: 2200, curr loss: 1.3151792287826538, avg loss: 1.2860524433851241\n",
      "trial: 4, iter: 2400, curr loss: 1.2588458061218262, avg loss: 1.2771611469984054\n",
      "trial: 4, iter: 2600, curr loss: 1.3279157876968384, avg loss: 1.2756479859352112\n",
      "trial: 4, iter: 2800, curr loss: 1.2860151529312134, avg loss: 1.2762502974271774\n",
      "trial: 4, iter: 3000, curr loss: 1.2755303382873535, avg loss: 1.2708913868665694\n",
      "trial: 4, iter: 3200, curr loss: 1.2859091758728027, avg loss: 1.2685800713300706\n",
      "trial: 4, iter: 3400, curr loss: 1.2575652599334717, avg loss: 1.268207077383995\n",
      "trial: 4, iter: 3600, curr loss: 1.2322660684585571, avg loss: 1.267766774892807\n",
      "trial: 4, iter: 3800, curr loss: 1.2578730583190918, avg loss: 1.2656512880325317\n",
      "trial: 4, iter: 4000, curr loss: 1.317107915878296, avg loss: 1.2685288155078889\n",
      "trial: 4, iter: 4200, curr loss: 1.2551590204238892, avg loss: 1.2680585885047913\n",
      "trial: 4, iter: 4400, curr loss: 1.3250093460083008, avg loss: 1.2666844993829727\n",
      "trial: 4, iter: 4600, curr loss: 1.2273327112197876, avg loss: 1.2656041169166565\n",
      "trial: 4, iter: 4800, curr loss: 1.2496600151062012, avg loss: 1.2642201644182205\n",
      "trial: 4, iter: 5000, curr loss: 1.2622241973876953, avg loss: 1.262364186644554\n",
      "trial: 4, iter: 5200, curr loss: 1.211413860321045, avg loss: 1.2645937210321427\n",
      "trial: 4, iter: 5400, curr loss: 1.2419625520706177, avg loss: 1.264199954867363\n",
      "trial: 4, iter: 5600, curr loss: 1.2912968397140503, avg loss: 1.2624164515733718\n",
      "trial: 4, iter: 5800, curr loss: 1.2828431129455566, avg loss: 1.2646940314769746\n",
      "trial: 4, iter: 6000, curr loss: 1.2601696252822876, avg loss: 1.2622613298892975\n",
      "trial: 4, iter: 6200, curr loss: 1.258967399597168, avg loss: 1.2661400073766709\n",
      "trial: 4, iter: 6400, curr loss: 1.297523021697998, avg loss: 1.2651994979381562\n",
      "trial: 4, iter: 6600, curr loss: 1.284653902053833, avg loss: 1.2626416969299317\n",
      "trial: 4, iter: 6800, curr loss: 1.300301432609558, avg loss: 1.2662869524955749\n",
      "trial: 4, iter: 7000, curr loss: 1.2269432544708252, avg loss: 1.262843403816223\n",
      "trial: 4, iter: 7200, curr loss: 1.2710834741592407, avg loss: 1.2632564419507981\n",
      "trial: 4, iter: 7400, curr loss: 1.261386513710022, avg loss: 1.2618426913022995\n",
      "trial: 4, iter: 7600, curr loss: 1.2435736656188965, avg loss: 1.2601538521051407\n",
      "trial: 4, iter: 7800, curr loss: 1.2914820909500122, avg loss: 1.2649139285087585\n",
      "trial: 4, iter: 8000, curr loss: 1.2763867378234863, avg loss: 1.2626867413520813\n",
      "trial: 4, iter: 8200, curr loss: 1.341392159461975, avg loss: 1.2593045103549958\n",
      "trial: 4, iter: 8400, curr loss: 1.241375207901001, avg loss: 1.2616595834493638\n",
      "trial: 4, iter: 8600, curr loss: 1.2346714735031128, avg loss: 1.2617753726243972\n",
      "trial: 4, iter: 8800, curr loss: 1.2532401084899902, avg loss: 1.2625017416477204\n",
      "trial: 4, iter: 9000, curr loss: 1.2526863813400269, avg loss: 1.260301441550255\n",
      "trial: 4, iter: 9200, curr loss: 1.2215380668640137, avg loss: 1.26107517182827\n",
      "trial: 4, iter: 9400, curr loss: 1.2626588344573975, avg loss: 1.2622448056936264\n",
      "trial: 4, iter: 9600, curr loss: 1.306732416152954, avg loss: 1.259843093752861\n",
      "trial: 4, iter: 9800, curr loss: 1.300126552581787, avg loss: 1.2598761433362962\n",
      "trial: 4, iter: 10000, curr loss: 1.2827329635620117, avg loss: 1.2620921891927719\n",
      "trial: 4, iter: 10200, curr loss: 1.2491273880004883, avg loss: 1.2632763624191283\n",
      "trial: 4, iter: 10400, curr loss: 1.2738178968429565, avg loss: 1.2625499385595322\n",
      "trial: 4, iter: 10600, curr loss: 1.2190388441085815, avg loss: 1.2575092399120331\n",
      "trial: 4, iter: 10800, curr loss: 1.2779285907745361, avg loss: 1.2590978157520294\n",
      "trial: 4, iter: 11000, curr loss: 1.267566442489624, avg loss: 1.2603436690568923\n",
      "trial: 4, iter: 11200, curr loss: 1.3093029260635376, avg loss: 1.2616553294658661\n",
      "trial: 4, iter: 11400, curr loss: 1.2818608283996582, avg loss: 1.2629380518198012\n",
      "trial: 4, iter: 11600, curr loss: 1.2591898441314697, avg loss: 1.2620987594127655\n",
      "trial: 4, iter: 11800, curr loss: 1.2499700784683228, avg loss: 1.2612745177745819\n",
      "trial: 4, iter: 12000, curr loss: 1.2272658348083496, avg loss: 1.2610580796003341\n",
      "trial: 4, iter: 12200, curr loss: 1.255816102027893, avg loss: 1.2633228540420531\n",
      "trial: 4, iter: 12400, curr loss: 1.2404295206069946, avg loss: 1.2591983354091645\n",
      "trial: 4, iter: 12600, curr loss: 1.2795771360397339, avg loss: 1.2617598587274552\n",
      "trial: 4, iter: 12800, curr loss: 1.290010690689087, avg loss: 1.2592176979780196\n",
      "trial: 4, iter: 13000, curr loss: 1.2756032943725586, avg loss: 1.2581884920597077\n",
      "trial: 4, iter: 13200, curr loss: 1.2396246194839478, avg loss: 1.2631207102537154\n",
      "trial: 4, iter: 13400, curr loss: 1.295364260673523, avg loss: 1.2623545759916306\n",
      "trial: 4, iter: 13600, curr loss: 1.2726619243621826, avg loss: 1.2612812060117722\n",
      "trial: 4, iter: 13800, curr loss: 1.270559310913086, avg loss: 1.2568957096338271\n",
      "trial: 4, iter: 14000, curr loss: 1.263873815536499, avg loss: 1.2643141484260558\n",
      "trial: 4, iter: 14200, curr loss: 1.2812752723693848, avg loss: 1.2620167547464372\n",
      "trial: 4, iter: 14400, curr loss: 1.2016685009002686, avg loss: 1.261246377825737\n",
      "trial: 4, iter: 14600, curr loss: 1.2399826049804688, avg loss: 1.2555589652061463\n",
      "trial: 4, iter: 14800, curr loss: 1.2792035341262817, avg loss: 1.2597673189640046\n",
      "trial: 4, iter: 15000, curr loss: 1.2602410316467285, avg loss: 1.2595353758335113\n",
      "trial: 4, iter: 15200, curr loss: 1.2164807319641113, avg loss: 1.26323813021183\n",
      "trial: 4, iter: 15400, curr loss: 1.2529964447021484, avg loss: 1.2645859605073928\n",
      "trial: 4, iter: 15600, curr loss: 1.2583835124969482, avg loss: 1.2634373128414154\n",
      "trial: 4, ldr: 0.2608209550380707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860251903533936, avg loss: 1.386133524775505\n",
      "trial: 5, iter: 400, curr loss: 1.3556767702102661, avg loss: 1.374008212685585\n",
      "trial: 5, iter: 600, curr loss: 1.3545485734939575, avg loss: 1.3314154434204102\n",
      "trial: 5, iter: 800, curr loss: 1.3341702222824097, avg loss: 1.3165146136283874\n",
      "trial: 5, iter: 1000, curr loss: 1.3129761219024658, avg loss: 1.3117523807287217\n",
      "trial: 5, iter: 1200, curr loss: 1.2968461513519287, avg loss: 1.3062382334470748\n",
      "trial: 5, iter: 1400, curr loss: 1.280552625656128, avg loss: 1.300798262357712\n",
      "trial: 5, iter: 1600, curr loss: 1.2555716037750244, avg loss: 1.2968404978513717\n",
      "trial: 5, iter: 1800, curr loss: 1.2720199823379517, avg loss: 1.2889153891801834\n",
      "trial: 5, iter: 2000, curr loss: 1.2598869800567627, avg loss: 1.284861131310463\n",
      "trial: 5, iter: 2200, curr loss: 1.273048996925354, avg loss: 1.2779011803865432\n",
      "trial: 5, iter: 2400, curr loss: 1.2942465543746948, avg loss: 1.2739974480867386\n",
      "trial: 5, iter: 2600, curr loss: 1.2257441282272339, avg loss: 1.2706523710489273\n",
      "trial: 5, iter: 2800, curr loss: 1.311062216758728, avg loss: 1.2694703209400178\n",
      "trial: 5, iter: 3000, curr loss: 1.252583622932434, avg loss: 1.269539453983307\n",
      "trial: 5, iter: 3200, curr loss: 1.316142201423645, avg loss: 1.267935991883278\n",
      "trial: 5, iter: 3400, curr loss: 1.249262809753418, avg loss: 1.2689859771728516\n",
      "trial: 5, iter: 3600, curr loss: 1.2397222518920898, avg loss: 1.270834386944771\n",
      "trial: 5, iter: 3800, curr loss: 1.2278380393981934, avg loss: 1.2657819044589997\n",
      "trial: 5, iter: 4000, curr loss: 1.2407941818237305, avg loss: 1.2674784028530122\n",
      "trial: 5, iter: 4200, curr loss: 1.2324609756469727, avg loss: 1.2677939963340759\n",
      "trial: 5, iter: 4400, curr loss: 1.2549835443496704, avg loss: 1.2698788249492645\n",
      "trial: 5, iter: 4600, curr loss: 1.2645306587219238, avg loss: 1.267616604566574\n",
      "trial: 5, iter: 4800, curr loss: 1.2452346086502075, avg loss: 1.264197314977646\n",
      "trial: 5, iter: 5000, curr loss: 1.2057926654815674, avg loss: 1.265318507552147\n",
      "trial: 5, iter: 5200, curr loss: 1.2829539775848389, avg loss: 1.2644761711359025\n",
      "trial: 5, iter: 5400, curr loss: 1.217736005783081, avg loss: 1.26215440928936\n",
      "trial: 5, iter: 5600, curr loss: 1.2804574966430664, avg loss: 1.2650887697935105\n",
      "trial: 5, iter: 5800, curr loss: 1.2569125890731812, avg loss: 1.2643458241224288\n",
      "trial: 5, iter: 6000, curr loss: 1.287046194076538, avg loss: 1.2629380816221236\n",
      "trial: 5, iter: 6200, curr loss: 1.2968288660049438, avg loss: 1.266195089817047\n",
      "trial: 5, iter: 6400, curr loss: 1.2533873319625854, avg loss: 1.2654686450958252\n",
      "trial: 5, iter: 6600, curr loss: 1.2458114624023438, avg loss: 1.2632130253314973\n",
      "trial: 5, iter: 6800, curr loss: 1.2342015504837036, avg loss: 1.2628253245353698\n",
      "trial: 5, iter: 7000, curr loss: 1.2279857397079468, avg loss: 1.2625664085149766\n",
      "trial: 5, iter: 7200, curr loss: 1.229134440422058, avg loss: 1.2668701845407486\n",
      "trial: 5, iter: 7400, curr loss: 1.2774393558502197, avg loss: 1.263813899755478\n",
      "trial: 5, iter: 7600, curr loss: 1.2619988918304443, avg loss: 1.25910925924778\n",
      "trial: 5, iter: 7800, curr loss: 1.277396321296692, avg loss: 1.2629451715946198\n",
      "trial: 5, iter: 8000, curr loss: 1.2731128931045532, avg loss: 1.2651785796880721\n",
      "trial: 5, iter: 8200, curr loss: 1.3156251907348633, avg loss: 1.2606989598274232\n",
      "trial: 5, iter: 8400, curr loss: 1.2607351541519165, avg loss: 1.2622430205345154\n",
      "trial: 5, iter: 8600, curr loss: 1.3123831748962402, avg loss: 1.259741033911705\n",
      "trial: 5, iter: 8800, curr loss: 1.2890961170196533, avg loss: 1.2627470922470092\n",
      "trial: 5, iter: 9000, curr loss: 1.2860900163650513, avg loss: 1.2630029594898224\n",
      "trial: 5, iter: 9200, curr loss: 1.2600157260894775, avg loss: 1.259964628815651\n",
      "trial: 5, iter: 9400, curr loss: 1.2339863777160645, avg loss: 1.2626162457466126\n",
      "trial: 5, iter: 9600, curr loss: 1.248924970626831, avg loss: 1.262119296193123\n",
      "trial: 5, iter: 9800, curr loss: 1.2511183023452759, avg loss: 1.260199544429779\n",
      "trial: 5, iter: 10000, curr loss: 1.2855610847473145, avg loss: 1.2601055020093919\n",
      "trial: 5, iter: 10200, curr loss: 1.208047866821289, avg loss: 1.2631317847967147\n",
      "trial: 5, iter: 10400, curr loss: 1.2536994218826294, avg loss: 1.26117378115654\n",
      "trial: 5, iter: 10600, curr loss: 1.245147466659546, avg loss: 1.2634796476364136\n",
      "trial: 5, iter: 10800, curr loss: 1.282426357269287, avg loss: 1.262184926867485\n",
      "trial: 5, iter: 11000, curr loss: 1.2608400583267212, avg loss: 1.2629817867279052\n",
      "trial: 5, iter: 11200, curr loss: 1.2122669219970703, avg loss: 1.2615004044771194\n",
      "trial: 5, iter: 11400, curr loss: 1.27840256690979, avg loss: 1.2588364207744598\n",
      "trial: 5, iter: 11600, curr loss: 1.2576059103012085, avg loss: 1.2600015854835511\n",
      "trial: 5, iter: 11800, curr loss: 1.2812575101852417, avg loss: 1.257185199856758\n",
      "trial: 5, iter: 12000, curr loss: 1.282696008682251, avg loss: 1.2650190150737763\n",
      "trial: 5, iter: 12200, curr loss: 1.249936819076538, avg loss: 1.2589949530363083\n",
      "trial: 5, iter: 12400, curr loss: 1.2657629251480103, avg loss: 1.258877369761467\n",
      "trial: 5, iter: 12600, curr loss: 1.2836133241653442, avg loss: 1.2587554252147675\n",
      "trial: 5, iter: 12800, curr loss: 1.2359983921051025, avg loss: 1.2587565422058105\n",
      "trial: 5, iter: 13000, curr loss: 1.2628120183944702, avg loss: 1.2602033042907714\n",
      "trial: 5, iter: 13200, curr loss: 1.274928331375122, avg loss: 1.26118887424469\n",
      "trial: 5, iter: 13400, curr loss: 1.2641069889068604, avg loss: 1.2626036274433137\n",
      "trial: 5, iter: 13600, curr loss: 1.249497652053833, avg loss: 1.2620355099439622\n",
      "trial: 5, iter: 13800, curr loss: 1.231980323791504, avg loss: 1.2593703311681748\n",
      "trial: 5, iter: 14000, curr loss: 1.2466322183609009, avg loss: 1.2595206969976425\n",
      "trial: 5, iter: 14200, curr loss: 1.2551451921463013, avg loss: 1.2621347171068191\n",
      "trial: 5, iter: 14400, curr loss: 1.2798058986663818, avg loss: 1.2636758768558503\n",
      "trial: 5, iter: 14600, curr loss: 1.2293386459350586, avg loss: 1.2612890952825546\n",
      "trial: 5, iter: 14800, curr loss: 1.2581313848495483, avg loss: 1.25755133330822\n",
      "trial: 5, iter: 15000, curr loss: 1.2715197801589966, avg loss: 1.262977007627487\n",
      "trial: 5, iter: 15200, curr loss: 1.2567802667617798, avg loss: 1.2636637771129609\n",
      "trial: 5, iter: 15400, curr loss: 1.2243071794509888, avg loss: 1.2588253194093704\n",
      "trial: 5, iter: 15600, curr loss: 1.2772215604782104, avg loss: 1.2596931129693985\n",
      "trial: 5, ldr: 0.240406334400177\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.261936217546463\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.384850263595581, avg loss: 1.3867419904470444\n",
      "trial: 1, iter: 400, curr loss: 1.372261881828308, avg loss: 1.3795406031608581\n",
      "trial: 1, iter: 600, curr loss: 1.3207722902297974, avg loss: 1.3461528420448303\n",
      "trial: 1, iter: 800, curr loss: 1.3183727264404297, avg loss: 1.3259086006879806\n",
      "trial: 1, iter: 1000, curr loss: 1.3267971277236938, avg loss: 1.3167734426259994\n",
      "trial: 1, iter: 1200, curr loss: 1.2557764053344727, avg loss: 1.3125042897462844\n",
      "trial: 1, iter: 1400, curr loss: 1.3100184202194214, avg loss: 1.3081825113296508\n",
      "trial: 1, iter: 1600, curr loss: 1.3104666471481323, avg loss: 1.3034630078077316\n",
      "trial: 1, iter: 1800, curr loss: 1.3175554275512695, avg loss: 1.2977826225757598\n",
      "trial: 1, iter: 2000, curr loss: 1.2853078842163086, avg loss: 1.29269866168499\n",
      "trial: 1, iter: 2200, curr loss: 1.290991187095642, avg loss: 1.2851921248435973\n",
      "trial: 1, iter: 2400, curr loss: 1.2175003290176392, avg loss: 1.2775540906190872\n",
      "trial: 1, iter: 2600, curr loss: 1.2740942239761353, avg loss: 1.272640162706375\n",
      "trial: 1, iter: 2800, curr loss: 1.2789480686187744, avg loss: 1.2708355629444121\n",
      "trial: 1, iter: 3000, curr loss: 1.2852873802185059, avg loss: 1.2699512684345244\n",
      "trial: 1, iter: 3200, curr loss: 1.2314963340759277, avg loss: 1.267206597328186\n",
      "trial: 1, iter: 3400, curr loss: 1.2966923713684082, avg loss: 1.2686265909671783\n",
      "trial: 1, iter: 3600, curr loss: 1.2355103492736816, avg loss: 1.2661176896095276\n",
      "trial: 1, iter: 3800, curr loss: 1.2828799486160278, avg loss: 1.2677021032571794\n",
      "trial: 1, iter: 4000, curr loss: 1.236447811126709, avg loss: 1.2639466840028764\n",
      "trial: 1, iter: 4200, curr loss: 1.3083754777908325, avg loss: 1.267478985786438\n",
      "trial: 1, iter: 4400, curr loss: 1.299941062927246, avg loss: 1.2669619131088257\n",
      "trial: 1, iter: 4600, curr loss: 1.2488049268722534, avg loss: 1.265439851284027\n",
      "trial: 1, iter: 4800, curr loss: 1.2620494365692139, avg loss: 1.2665674197673797\n",
      "trial: 1, iter: 5000, curr loss: 1.2607046365737915, avg loss: 1.2658389163017274\n",
      "trial: 1, iter: 5200, curr loss: 1.2408987283706665, avg loss: 1.2659849452972411\n",
      "trial: 1, iter: 5400, curr loss: 1.278496265411377, avg loss: 1.267545042037964\n",
      "trial: 1, iter: 5600, curr loss: 1.1934645175933838, avg loss: 1.2648600149154663\n",
      "trial: 1, iter: 5800, curr loss: 1.2909857034683228, avg loss: 1.266190575361252\n",
      "trial: 1, iter: 6000, curr loss: 1.2618114948272705, avg loss: 1.262357119321823\n",
      "trial: 1, iter: 6200, curr loss: 1.2828011512756348, avg loss: 1.2660097217559814\n",
      "trial: 1, iter: 6400, curr loss: 1.2288897037506104, avg loss: 1.2646412974596024\n",
      "trial: 1, iter: 6600, curr loss: 1.2848085165023804, avg loss: 1.2649770611524582\n",
      "trial: 1, iter: 6800, curr loss: 1.291231632232666, avg loss: 1.2645120179653169\n",
      "trial: 1, iter: 7000, curr loss: 1.2672874927520752, avg loss: 1.2646907156705856\n",
      "trial: 1, iter: 7200, curr loss: 1.2871427536010742, avg loss: 1.2639010673761368\n",
      "trial: 1, iter: 7400, curr loss: 1.2591688632965088, avg loss: 1.2632193797826767\n",
      "trial: 1, iter: 7600, curr loss: 1.2812681198120117, avg loss: 1.2631511902809143\n",
      "trial: 1, iter: 7800, curr loss: 1.260280728340149, avg loss: 1.2633614057302476\n",
      "trial: 1, iter: 8000, curr loss: 1.2253481149673462, avg loss: 1.264047811627388\n",
      "trial: 1, iter: 8200, curr loss: 1.2669051885604858, avg loss: 1.264889470934868\n",
      "trial: 1, iter: 8400, curr loss: 1.2261189222335815, avg loss: 1.2639958614110947\n",
      "trial: 1, iter: 8600, curr loss: 1.280500054359436, avg loss: 1.2656704878807068\n",
      "trial: 1, iter: 8800, curr loss: 1.2787809371948242, avg loss: 1.264050930738449\n",
      "trial: 1, iter: 9000, curr loss: 1.2335816621780396, avg loss: 1.2599530655145645\n",
      "trial: 1, iter: 9200, curr loss: 1.2531718015670776, avg loss: 1.2610772687196732\n",
      "trial: 1, iter: 9400, curr loss: 1.2366206645965576, avg loss: 1.2643974763154984\n",
      "trial: 1, iter: 9600, curr loss: 1.247259497642517, avg loss: 1.2674593031406403\n",
      "trial: 1, iter: 9800, curr loss: 1.268675446510315, avg loss: 1.2605527901649476\n",
      "trial: 1, iter: 10000, curr loss: 1.2485967874526978, avg loss: 1.26123395383358\n",
      "trial: 1, iter: 10200, curr loss: 1.214651346206665, avg loss: 1.265103268623352\n",
      "trial: 1, iter: 10400, curr loss: 1.279262900352478, avg loss: 1.2632311671972274\n",
      "trial: 1, iter: 10600, curr loss: 1.2530823945999146, avg loss: 1.2632281631231308\n",
      "trial: 1, iter: 10800, curr loss: 1.3066569566726685, avg loss: 1.2655160760879516\n",
      "trial: 1, iter: 11000, curr loss: 1.2564207315444946, avg loss: 1.2621894639730453\n",
      "trial: 1, iter: 11200, curr loss: 1.2078019380569458, avg loss: 1.2610667204856874\n",
      "trial: 1, iter: 11400, curr loss: 1.2275266647338867, avg loss: 1.2633431661128998\n",
      "trial: 1, iter: 11600, curr loss: 1.2752659320831299, avg loss: 1.2615736150741577\n",
      "trial: 1, iter: 11800, curr loss: 1.234551191329956, avg loss: 1.261190071105957\n",
      "trial: 1, iter: 12000, curr loss: 1.2764958143234253, avg loss: 1.2633468145132065\n",
      "trial: 1, iter: 12200, curr loss: 1.2258106470108032, avg loss: 1.2612270575761795\n",
      "trial: 1, iter: 12400, curr loss: 1.2323524951934814, avg loss: 1.2612896221876144\n",
      "trial: 1, iter: 12600, curr loss: 1.2443193197250366, avg loss: 1.2582736939191819\n",
      "trial: 1, iter: 12800, curr loss: 1.2871464490890503, avg loss: 1.2589736109972\n",
      "trial: 1, iter: 13000, curr loss: 1.268843650817871, avg loss: 1.2634355342388153\n",
      "trial: 1, iter: 13200, curr loss: 1.2902827262878418, avg loss: 1.259565377831459\n",
      "trial: 1, iter: 13400, curr loss: 1.2516709566116333, avg loss: 1.2608507907390594\n",
      "trial: 1, iter: 13600, curr loss: 1.2968801259994507, avg loss: 1.2641995853185655\n",
      "trial: 1, iter: 13800, curr loss: 1.251801609992981, avg loss: 1.2622733372449875\n",
      "trial: 1, iter: 14000, curr loss: 1.2729703187942505, avg loss: 1.2609104496240615\n",
      "trial: 1, iter: 14200, curr loss: 1.2756726741790771, avg loss: 1.2610784536600113\n",
      "trial: 1, iter: 14400, curr loss: 1.2807687520980835, avg loss: 1.2597357350587846\n",
      "trial: 1, iter: 14600, curr loss: 1.261411428451538, avg loss: 1.262729790210724\n",
      "trial: 1, iter: 14800, curr loss: 1.305387020111084, avg loss: 1.2628877830505372\n",
      "trial: 1, iter: 15000, curr loss: 1.2584872245788574, avg loss: 1.262124746441841\n",
      "trial: 1, iter: 15200, curr loss: 1.2636643648147583, avg loss: 1.26017451941967\n",
      "trial: 1, iter: 15400, curr loss: 1.2942230701446533, avg loss: 1.2619992035627365\n",
      "trial: 1, iter: 15600, curr loss: 1.279798150062561, avg loss: 1.2608162814378738\n",
      "trial: 1, ldr: 0.2879779040813446\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387452244758606, avg loss: 1.38646539747715\n",
      "trial: 2, iter: 400, curr loss: 1.3642631769180298, avg loss: 1.3805020660161973\n",
      "trial: 2, iter: 600, curr loss: 1.3349933624267578, avg loss: 1.3452595978975297\n",
      "trial: 2, iter: 800, curr loss: 1.312836766242981, avg loss: 1.324667602777481\n",
      "trial: 2, iter: 1000, curr loss: 1.326149344444275, avg loss: 1.3164390099048615\n",
      "trial: 2, iter: 1200, curr loss: 1.2992398738861084, avg loss: 1.30878586769104\n",
      "trial: 2, iter: 1400, curr loss: 1.3076577186584473, avg loss: 1.3021731317043304\n",
      "trial: 2, iter: 1600, curr loss: 1.2916908264160156, avg loss: 1.2951104295253755\n",
      "trial: 2, iter: 1800, curr loss: 1.2419443130493164, avg loss: 1.2867649281024933\n",
      "trial: 2, iter: 2000, curr loss: 1.2973536252975464, avg loss: 1.2836307066679\n",
      "trial: 2, iter: 2200, curr loss: 1.2590786218643188, avg loss: 1.2761585319042206\n",
      "trial: 2, iter: 2400, curr loss: 1.2673382759094238, avg loss: 1.274039205312729\n",
      "trial: 2, iter: 2600, curr loss: 1.2882648706436157, avg loss: 1.2711519396305084\n",
      "trial: 2, iter: 2800, curr loss: 1.2352157831192017, avg loss: 1.2708332645893097\n",
      "trial: 2, iter: 3000, curr loss: 1.2604795694351196, avg loss: 1.2741940146684647\n",
      "trial: 2, iter: 3200, curr loss: 1.262589454650879, avg loss: 1.270134768486023\n",
      "trial: 2, iter: 3400, curr loss: 1.2460638284683228, avg loss: 1.26902334690094\n",
      "trial: 2, iter: 3600, curr loss: 1.2865803241729736, avg loss: 1.2665045815706253\n",
      "trial: 2, iter: 3800, curr loss: 1.2361849546432495, avg loss: 1.2665685492753982\n",
      "trial: 2, iter: 4000, curr loss: 1.2981168031692505, avg loss: 1.2663275903463365\n",
      "trial: 2, iter: 4200, curr loss: 1.2819290161132812, avg loss: 1.267290290594101\n",
      "trial: 2, iter: 4400, curr loss: 1.2347071170806885, avg loss: 1.2705204325914383\n",
      "trial: 2, iter: 4600, curr loss: 1.254538655281067, avg loss: 1.2685955029726028\n",
      "trial: 2, iter: 4800, curr loss: 1.251587152481079, avg loss: 1.2665629214048386\n",
      "trial: 2, iter: 5000, curr loss: 1.2368102073669434, avg loss: 1.2647929638624191\n",
      "trial: 2, iter: 5200, curr loss: 1.2530022859573364, avg loss: 1.266526842713356\n",
      "trial: 2, iter: 5400, curr loss: 1.2619812488555908, avg loss: 1.2659747618436814\n",
      "trial: 2, iter: 5600, curr loss: 1.2982937097549438, avg loss: 1.2654555141925812\n",
      "trial: 2, iter: 5800, curr loss: 1.2651063203811646, avg loss: 1.2652532523870468\n",
      "trial: 2, iter: 6000, curr loss: 1.2732850313186646, avg loss: 1.2651208382844925\n",
      "trial: 2, iter: 6200, curr loss: 1.2705655097961426, avg loss: 1.2653705817461014\n",
      "trial: 2, iter: 6400, curr loss: 1.227192759513855, avg loss: 1.2609991896152497\n",
      "trial: 2, iter: 6600, curr loss: 1.2845869064331055, avg loss: 1.2631230443716048\n",
      "trial: 2, iter: 6800, curr loss: 1.2618228197097778, avg loss: 1.2648916935920715\n",
      "trial: 2, iter: 7000, curr loss: 1.3466343879699707, avg loss: 1.2650164556503296\n",
      "trial: 2, iter: 7200, curr loss: 1.2537437677383423, avg loss: 1.2657314717769623\n",
      "trial: 2, iter: 7400, curr loss: 1.2341865301132202, avg loss: 1.26500481903553\n",
      "trial: 2, iter: 7600, curr loss: 1.229396939277649, avg loss: 1.2653246426582336\n",
      "trial: 2, iter: 7800, curr loss: 1.261022925376892, avg loss: 1.2647759652137756\n",
      "trial: 2, iter: 8000, curr loss: 1.2630175352096558, avg loss: 1.2654218846559524\n",
      "trial: 2, iter: 8200, curr loss: 1.281833529472351, avg loss: 1.2610952204465866\n",
      "trial: 2, iter: 8400, curr loss: 1.2720487117767334, avg loss: 1.2622220867872238\n",
      "trial: 2, iter: 8600, curr loss: 1.2327687740325928, avg loss: 1.2632062780857085\n",
      "trial: 2, iter: 8800, curr loss: 1.2542222738265991, avg loss: 1.2634907740354537\n",
      "trial: 2, iter: 9000, curr loss: 1.262481689453125, avg loss: 1.2668001013994217\n",
      "trial: 2, iter: 9200, curr loss: 1.2465720176696777, avg loss: 1.2646948033571244\n",
      "trial: 2, iter: 9400, curr loss: 1.2295104265213013, avg loss: 1.264245001077652\n",
      "trial: 2, iter: 9600, curr loss: 1.2585513591766357, avg loss: 1.26208476126194\n",
      "trial: 2, iter: 9800, curr loss: 1.2395896911621094, avg loss: 1.2626622760295867\n",
      "trial: 2, iter: 10000, curr loss: 1.3089241981506348, avg loss: 1.2633630925416945\n",
      "trial: 2, iter: 10200, curr loss: 1.243701457977295, avg loss: 1.2622062808275223\n",
      "trial: 2, iter: 10400, curr loss: 1.2789994478225708, avg loss: 1.2644762152433395\n",
      "trial: 2, iter: 10600, curr loss: 1.2934967279434204, avg loss: 1.2644799572229386\n",
      "trial: 2, iter: 10800, curr loss: 1.2957755327224731, avg loss: 1.2632332479953765\n",
      "trial: 2, iter: 11000, curr loss: 1.302398920059204, avg loss: 1.2613307821750641\n",
      "trial: 2, iter: 11200, curr loss: 1.2653474807739258, avg loss: 1.2612376809120178\n",
      "trial: 2, iter: 11400, curr loss: 1.248908519744873, avg loss: 1.2627532744407655\n",
      "trial: 2, iter: 11600, curr loss: 1.2536547183990479, avg loss: 1.2623563259840012\n",
      "trial: 2, iter: 11800, curr loss: 1.3187791109085083, avg loss: 1.2594748902320863\n",
      "trial: 2, iter: 12000, curr loss: 1.225441575050354, avg loss: 1.2626800286769866\n",
      "trial: 2, iter: 12200, curr loss: 1.2762194871902466, avg loss: 1.260354778766632\n",
      "trial: 2, iter: 12400, curr loss: 1.2789289951324463, avg loss: 1.2628551334142686\n",
      "trial: 2, iter: 12600, curr loss: 1.2692787647247314, avg loss: 1.2608233600854875\n",
      "trial: 2, iter: 12800, curr loss: 1.2793824672698975, avg loss: 1.2642676389217378\n",
      "trial: 2, iter: 13000, curr loss: 1.2713549137115479, avg loss: 1.2635379421710968\n",
      "trial: 2, iter: 13200, curr loss: 1.2851158380508423, avg loss: 1.2634345811605454\n",
      "trial: 2, iter: 13400, curr loss: 1.2594538927078247, avg loss: 1.2571310639381408\n",
      "trial: 2, iter: 13600, curr loss: 1.2401080131530762, avg loss: 1.261692503094673\n",
      "trial: 2, iter: 13800, curr loss: 1.2555842399597168, avg loss: 1.2650932478904724\n",
      "trial: 2, iter: 14000, curr loss: 1.2644234895706177, avg loss: 1.260617532134056\n",
      "trial: 2, iter: 14200, curr loss: 1.2818455696105957, avg loss: 1.2614534622430802\n",
      "trial: 2, iter: 14400, curr loss: 1.2611099481582642, avg loss: 1.2623489856719972\n",
      "trial: 2, iter: 14600, curr loss: 1.3060009479522705, avg loss: 1.2591574114561082\n",
      "trial: 2, iter: 14800, curr loss: 1.2378959655761719, avg loss: 1.263506405353546\n",
      "trial: 2, iter: 15000, curr loss: 1.285784363746643, avg loss: 1.2635469317436219\n",
      "trial: 2, iter: 15200, curr loss: 1.309072732925415, avg loss: 1.26189560174942\n",
      "trial: 2, iter: 15400, curr loss: 1.2867132425308228, avg loss: 1.2622888082265853\n",
      "trial: 2, iter: 15600, curr loss: 1.2592027187347412, avg loss: 1.258460847735405\n",
      "trial: 2, ldr: 0.2918137013912201\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3835874795913696, avg loss: 1.3872265136241912\n",
      "trial: 3, iter: 400, curr loss: 1.381677508354187, avg loss: 1.381214388012886\n",
      "trial: 3, iter: 600, curr loss: 1.3646714687347412, avg loss: 1.3467546105384827\n",
      "trial: 3, iter: 800, curr loss: 1.2928749322891235, avg loss: 1.321191314458847\n",
      "trial: 3, iter: 1000, curr loss: 1.2946181297302246, avg loss: 1.310131761431694\n",
      "trial: 3, iter: 1200, curr loss: 1.3048229217529297, avg loss: 1.308453034758568\n",
      "trial: 3, iter: 1400, curr loss: 1.324675440788269, avg loss: 1.308366720676422\n",
      "trial: 3, iter: 1600, curr loss: 1.2889747619628906, avg loss: 1.3020095509290694\n",
      "trial: 3, iter: 1800, curr loss: 1.329350471496582, avg loss: 1.2964080065488814\n",
      "trial: 3, iter: 2000, curr loss: 1.316838026046753, avg loss: 1.2904195165634156\n",
      "trial: 3, iter: 2200, curr loss: 1.3178582191467285, avg loss: 1.289767462015152\n",
      "trial: 3, iter: 2400, curr loss: 1.2540525197982788, avg loss: 1.280910621881485\n",
      "trial: 3, iter: 2600, curr loss: 1.2667704820632935, avg loss: 1.276854230761528\n",
      "trial: 3, iter: 2800, curr loss: 1.225457787513733, avg loss: 1.2750743073225022\n",
      "trial: 3, iter: 3000, curr loss: 1.2950979471206665, avg loss: 1.2744214093685151\n",
      "trial: 3, iter: 3200, curr loss: 1.2902098894119263, avg loss: 1.2722921442985535\n",
      "trial: 3, iter: 3400, curr loss: 1.2988945245742798, avg loss: 1.2722290772199631\n",
      "trial: 3, iter: 3600, curr loss: 1.3037997484207153, avg loss: 1.2696393048763275\n",
      "trial: 3, iter: 3800, curr loss: 1.2547047138214111, avg loss: 1.2665219902992249\n",
      "trial: 3, iter: 4000, curr loss: 1.2493906021118164, avg loss: 1.2690691721439362\n",
      "trial: 3, iter: 4200, curr loss: 1.2621327638626099, avg loss: 1.2652707570791244\n",
      "trial: 3, iter: 4400, curr loss: 1.2403427362442017, avg loss: 1.2656010472774506\n",
      "trial: 3, iter: 4600, curr loss: 1.263451099395752, avg loss: 1.2661467278003693\n",
      "trial: 3, iter: 4800, curr loss: 1.219931960105896, avg loss: 1.266255080103874\n",
      "trial: 3, iter: 5000, curr loss: 1.2494767904281616, avg loss: 1.2660580366849898\n",
      "trial: 3, iter: 5200, curr loss: 1.2611160278320312, avg loss: 1.267718983888626\n",
      "trial: 3, iter: 5400, curr loss: 1.2441288232803345, avg loss: 1.2652841234207153\n",
      "trial: 3, iter: 5600, curr loss: 1.3036569356918335, avg loss: 1.265688481926918\n",
      "trial: 3, iter: 5800, curr loss: 1.2895481586456299, avg loss: 1.265836221575737\n",
      "trial: 3, iter: 6000, curr loss: 1.2853254079818726, avg loss: 1.2647855246067048\n",
      "trial: 3, iter: 6200, curr loss: 1.2776165008544922, avg loss: 1.2632491326332091\n",
      "trial: 3, iter: 6400, curr loss: 1.294304609298706, avg loss: 1.265562698841095\n",
      "trial: 3, iter: 6600, curr loss: 1.2689439058303833, avg loss: 1.2631625562906266\n",
      "trial: 3, iter: 6800, curr loss: 1.2711083889007568, avg loss: 1.2655734997987746\n",
      "trial: 3, iter: 7000, curr loss: 1.2826964855194092, avg loss: 1.2671406239271163\n",
      "trial: 3, iter: 7200, curr loss: 1.3018460273742676, avg loss: 1.2665725380182267\n",
      "trial: 3, iter: 7400, curr loss: 1.2591462135314941, avg loss: 1.2628414058685302\n",
      "trial: 3, iter: 7600, curr loss: 1.2692760229110718, avg loss: 1.2662134236097335\n",
      "trial: 3, iter: 7800, curr loss: 1.2845666408538818, avg loss: 1.2680303460359574\n",
      "trial: 3, iter: 8000, curr loss: 1.272371768951416, avg loss: 1.2644496524333955\n",
      "trial: 3, iter: 8200, curr loss: 1.2900882959365845, avg loss: 1.2634341925382615\n",
      "trial: 3, iter: 8400, curr loss: 1.270416021347046, avg loss: 1.2667385578155517\n",
      "trial: 3, iter: 8600, curr loss: 1.2507063150405884, avg loss: 1.264530918598175\n",
      "trial: 3, iter: 8800, curr loss: 1.2673524618148804, avg loss: 1.2648036485910417\n",
      "trial: 3, iter: 9000, curr loss: 1.2609013319015503, avg loss: 1.2650488781929017\n",
      "trial: 3, iter: 9200, curr loss: 1.3053120374679565, avg loss: 1.2599281537532807\n",
      "trial: 3, iter: 9400, curr loss: 1.2919203042984009, avg loss: 1.2619749408960343\n",
      "trial: 3, iter: 9600, curr loss: 1.2447113990783691, avg loss: 1.2653587865829468\n",
      "trial: 3, iter: 9800, curr loss: 1.2597510814666748, avg loss: 1.2613871204853058\n",
      "trial: 3, iter: 10000, curr loss: 1.2375580072402954, avg loss: 1.2613752919435501\n",
      "trial: 3, iter: 10200, curr loss: 1.2730381488800049, avg loss: 1.2646055263280869\n",
      "trial: 3, iter: 10400, curr loss: 1.2534265518188477, avg loss: 1.2650923907756806\n",
      "trial: 3, iter: 10600, curr loss: 1.253157615661621, avg loss: 1.2625733995437622\n",
      "trial: 3, iter: 10800, curr loss: 1.2197730541229248, avg loss: 1.2631578063964843\n",
      "trial: 3, iter: 11000, curr loss: 1.28667151927948, avg loss: 1.2609659844636918\n",
      "trial: 3, iter: 11200, curr loss: 1.2824984788894653, avg loss: 1.2647576916217804\n",
      "trial: 3, iter: 11400, curr loss: 1.288122534751892, avg loss: 1.2627152293920516\n",
      "trial: 3, iter: 11600, curr loss: 1.3059101104736328, avg loss: 1.2608670723438262\n",
      "trial: 3, iter: 11800, curr loss: 1.266882300376892, avg loss: 1.2668152642250061\n",
      "trial: 3, iter: 12000, curr loss: 1.261481761932373, avg loss: 1.2653483897447586\n",
      "trial: 3, iter: 12200, curr loss: 1.25869619846344, avg loss: 1.264537626504898\n",
      "trial: 3, iter: 12400, curr loss: 1.276263952255249, avg loss: 1.2648203057050704\n",
      "trial: 3, iter: 12600, curr loss: 1.3046146631240845, avg loss: 1.2626991134881973\n",
      "trial: 3, iter: 12800, curr loss: 1.2452062368392944, avg loss: 1.2618456095457078\n",
      "trial: 3, iter: 13000, curr loss: 1.2768034934997559, avg loss: 1.2646327674388886\n",
      "trial: 3, iter: 13200, curr loss: 1.2579811811447144, avg loss: 1.2646086955070495\n",
      "trial: 3, iter: 13400, curr loss: 1.2296444177627563, avg loss: 1.2595158398151398\n",
      "trial: 3, iter: 13600, curr loss: 1.3003989458084106, avg loss: 1.2613833349943162\n",
      "trial: 3, iter: 13800, curr loss: 1.2503032684326172, avg loss: 1.2595835411548615\n",
      "trial: 3, iter: 14000, curr loss: 1.2819840908050537, avg loss: 1.2639897572994232\n",
      "trial: 3, iter: 14200, curr loss: 1.2811707258224487, avg loss: 1.264058582186699\n",
      "trial: 3, iter: 14400, curr loss: 1.2158514261245728, avg loss: 1.2589519673585892\n",
      "trial: 3, iter: 14600, curr loss: 1.2512271404266357, avg loss: 1.265233593583107\n",
      "trial: 3, iter: 14800, curr loss: 1.2553240060806274, avg loss: 1.2609880125522615\n",
      "trial: 3, iter: 15000, curr loss: 1.2597568035125732, avg loss: 1.2615249490737914\n",
      "trial: 3, iter: 15200, curr loss: 1.2635574340820312, avg loss: 1.2628923279047013\n",
      "trial: 3, iter: 15400, curr loss: 1.3057035207748413, avg loss: 1.2649935096502305\n",
      "trial: 3, iter: 15600, curr loss: 1.1959420442581177, avg loss: 1.2591972732543946\n",
      "trial: 3, ldr: 0.24925467371940613\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838289976119995, avg loss: 1.3866366881132126\n",
      "trial: 4, iter: 400, curr loss: 1.3698033094406128, avg loss: 1.378612193465233\n",
      "trial: 4, iter: 600, curr loss: 1.3445574045181274, avg loss: 1.339116553068161\n",
      "trial: 4, iter: 800, curr loss: 1.3026174306869507, avg loss: 1.3194512987136842\n",
      "trial: 4, iter: 1000, curr loss: 1.3145309686660767, avg loss: 1.3093367141485215\n",
      "trial: 4, iter: 1200, curr loss: 1.3130489587783813, avg loss: 1.3037091934680938\n",
      "trial: 4, iter: 1400, curr loss: 1.3159786462783813, avg loss: 1.2972965520620345\n",
      "trial: 4, iter: 1600, curr loss: 1.3258856534957886, avg loss: 1.2916092473268508\n",
      "trial: 4, iter: 1800, curr loss: 1.2860627174377441, avg loss: 1.2846076500415802\n",
      "trial: 4, iter: 2000, curr loss: 1.2386014461517334, avg loss: 1.2774265307188033\n",
      "trial: 4, iter: 2200, curr loss: 1.264837622642517, avg loss: 1.2785347265005111\n",
      "trial: 4, iter: 2400, curr loss: 1.219425916671753, avg loss: 1.270503993034363\n",
      "trial: 4, iter: 2600, curr loss: 1.2533044815063477, avg loss: 1.2738738930225373\n",
      "trial: 4, iter: 2800, curr loss: 1.2703269720077515, avg loss: 1.2695148640871048\n",
      "trial: 4, iter: 3000, curr loss: 1.2459536790847778, avg loss: 1.2705988794565202\n",
      "trial: 4, iter: 3200, curr loss: 1.2981148958206177, avg loss: 1.2662418299913407\n",
      "trial: 4, iter: 3400, curr loss: 1.3175311088562012, avg loss: 1.266675894856453\n",
      "trial: 4, iter: 3600, curr loss: 1.2737064361572266, avg loss: 1.267791051864624\n",
      "trial: 4, iter: 3800, curr loss: 1.2371704578399658, avg loss: 1.268927617073059\n",
      "trial: 4, iter: 4000, curr loss: 1.2465789318084717, avg loss: 1.266765884757042\n",
      "trial: 4, iter: 4200, curr loss: 1.2543264627456665, avg loss: 1.264184137582779\n",
      "trial: 4, iter: 4400, curr loss: 1.2385362386703491, avg loss: 1.2664782547950744\n",
      "trial: 4, iter: 4600, curr loss: 1.206026554107666, avg loss: 1.2640656530857086\n",
      "trial: 4, iter: 4800, curr loss: 1.226979374885559, avg loss: 1.2679971259832383\n",
      "trial: 4, iter: 5000, curr loss: 1.2585082054138184, avg loss: 1.2643154126405716\n",
      "trial: 4, iter: 5200, curr loss: 1.261827826499939, avg loss: 1.263414055109024\n",
      "trial: 4, iter: 5400, curr loss: 1.2398194074630737, avg loss: 1.266883026957512\n",
      "trial: 4, iter: 5600, curr loss: 1.2260373830795288, avg loss: 1.2635231751203537\n",
      "trial: 4, iter: 5800, curr loss: 1.2331970930099487, avg loss: 1.2649211198091508\n",
      "trial: 4, iter: 6000, curr loss: 1.253232479095459, avg loss: 1.2634014856815339\n",
      "trial: 4, iter: 6200, curr loss: 1.2758584022521973, avg loss: 1.2633955878019334\n",
      "trial: 4, iter: 6400, curr loss: 1.280616044998169, avg loss: 1.2678827226161957\n",
      "trial: 4, iter: 6600, curr loss: 1.2370589971542358, avg loss: 1.2643958896398544\n",
      "trial: 4, iter: 6800, curr loss: 1.2404024600982666, avg loss: 1.2666486668586732\n",
      "trial: 4, iter: 7000, curr loss: 1.2535414695739746, avg loss: 1.2642184448242189\n",
      "trial: 4, iter: 7200, curr loss: 1.3023145198822021, avg loss: 1.2606228125095367\n",
      "trial: 4, iter: 7400, curr loss: 1.2753163576126099, avg loss: 1.263195927143097\n",
      "trial: 4, iter: 7600, curr loss: 1.2806627750396729, avg loss: 1.2639308732748031\n",
      "trial: 4, iter: 7800, curr loss: 1.2778635025024414, avg loss: 1.2635673350095749\n",
      "trial: 4, iter: 8000, curr loss: 1.2186574935913086, avg loss: 1.262010878920555\n",
      "trial: 4, iter: 8200, curr loss: 1.2590426206588745, avg loss: 1.2611442965269088\n",
      "trial: 4, iter: 8400, curr loss: 1.255627989768982, avg loss: 1.264351469874382\n",
      "trial: 4, iter: 8600, curr loss: 1.2768374681472778, avg loss: 1.2632125401496888\n",
      "trial: 4, iter: 8800, curr loss: 1.2960611581802368, avg loss: 1.262887853384018\n",
      "trial: 4, iter: 9000, curr loss: 1.2303403615951538, avg loss: 1.2622942572832108\n",
      "trial: 4, iter: 9200, curr loss: 1.2667632102966309, avg loss: 1.2647005480527878\n",
      "trial: 4, iter: 9400, curr loss: 1.2421208620071411, avg loss: 1.2652269673347474\n",
      "trial: 4, iter: 9600, curr loss: 1.286224126815796, avg loss: 1.2636136031150818\n",
      "trial: 4, iter: 9800, curr loss: 1.2349469661712646, avg loss: 1.2637426686286926\n",
      "trial: 4, iter: 10000, curr loss: 1.2495225667953491, avg loss: 1.2622068226337433\n",
      "trial: 4, iter: 10200, curr loss: 1.2203127145767212, avg loss: 1.2610135066509247\n",
      "trial: 4, iter: 10400, curr loss: 1.2492355108261108, avg loss: 1.2642653614282608\n",
      "trial: 4, iter: 10600, curr loss: 1.226855754852295, avg loss: 1.2620799607038498\n",
      "trial: 4, iter: 10800, curr loss: 1.2179718017578125, avg loss: 1.2629817587137222\n",
      "trial: 4, iter: 11000, curr loss: 1.2517473697662354, avg loss: 1.2646374595165253\n",
      "trial: 4, iter: 11200, curr loss: 1.2488632202148438, avg loss: 1.2614214086532594\n",
      "trial: 4, iter: 11400, curr loss: 1.2192898988723755, avg loss: 1.2628831589221954\n",
      "trial: 4, iter: 11600, curr loss: 1.227485179901123, avg loss: 1.2615482622385026\n",
      "trial: 4, iter: 11800, curr loss: 1.2595558166503906, avg loss: 1.2627650594711304\n",
      "trial: 4, iter: 12000, curr loss: 1.278829574584961, avg loss: 1.2596889448165893\n",
      "trial: 4, iter: 12200, curr loss: 1.2427765130996704, avg loss: 1.2610835099220277\n",
      "trial: 4, iter: 12400, curr loss: 1.3123183250427246, avg loss: 1.2606252110004426\n",
      "trial: 4, iter: 12600, curr loss: 1.2874425649642944, avg loss: 1.2611104243993758\n",
      "trial: 4, iter: 12800, curr loss: 1.25192129611969, avg loss: 1.2624251866340637\n",
      "trial: 4, iter: 13000, curr loss: 1.2515252828598022, avg loss: 1.262718380689621\n",
      "trial: 4, iter: 13200, curr loss: 1.2346702814102173, avg loss: 1.2655968469381333\n",
      "trial: 4, iter: 13400, curr loss: 1.2619752883911133, avg loss: 1.2624585956335068\n",
      "trial: 4, iter: 13600, curr loss: 1.2654670476913452, avg loss: 1.2618644881248473\n",
      "trial: 4, iter: 13800, curr loss: 1.2435152530670166, avg loss: 1.2618448323011398\n",
      "trial: 4, iter: 14000, curr loss: 1.2427442073822021, avg loss: 1.2576757901906968\n",
      "trial: 4, iter: 14200, curr loss: 1.2493394613265991, avg loss: 1.2627360761165618\n",
      "trial: 4, iter: 14400, curr loss: 1.256103277206421, avg loss: 1.262502812743187\n",
      "trial: 4, iter: 14600, curr loss: 1.2437329292297363, avg loss: 1.261829402446747\n",
      "trial: 4, iter: 14800, curr loss: 1.2684506177902222, avg loss: 1.2633649045228958\n",
      "trial: 4, iter: 15000, curr loss: 1.2341688871383667, avg loss: 1.2605600422620773\n",
      "trial: 4, iter: 15200, curr loss: 1.2586678266525269, avg loss: 1.263090261220932\n",
      "trial: 4, iter: 15400, curr loss: 1.2640914916992188, avg loss: 1.2615793931484223\n",
      "trial: 4, iter: 15600, curr loss: 1.2538150548934937, avg loss: 1.2607654815912246\n",
      "trial: 4, ldr: 0.26005545258522034\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3889318704605103, avg loss: 1.3866835415363312\n",
      "trial: 5, iter: 400, curr loss: 1.372510552406311, avg loss: 1.3808905965089797\n",
      "trial: 5, iter: 600, curr loss: 1.3174564838409424, avg loss: 1.343729731440544\n",
      "trial: 5, iter: 800, curr loss: 1.3015941381454468, avg loss: 1.323343475461006\n",
      "trial: 5, iter: 1000, curr loss: 1.3248156309127808, avg loss: 1.3147678035497665\n",
      "trial: 5, iter: 1200, curr loss: 1.2971333265304565, avg loss: 1.3063113957643508\n",
      "trial: 5, iter: 1400, curr loss: 1.2831690311431885, avg loss: 1.3003690558671952\n",
      "trial: 5, iter: 1600, curr loss: 1.27569580078125, avg loss: 1.2976484024524688\n",
      "trial: 5, iter: 1800, curr loss: 1.3133589029312134, avg loss: 1.2941662174463273\n",
      "trial: 5, iter: 2000, curr loss: 1.2803468704223633, avg loss: 1.2824835234880447\n",
      "trial: 5, iter: 2200, curr loss: 1.2811030149459839, avg loss: 1.2819745630025863\n",
      "trial: 5, iter: 2400, curr loss: 1.2835171222686768, avg loss: 1.2774373763799667\n",
      "trial: 5, iter: 2600, curr loss: 1.2046682834625244, avg loss: 1.2721523773670196\n",
      "trial: 5, iter: 2800, curr loss: 1.2639192342758179, avg loss: 1.2702225178480149\n",
      "trial: 5, iter: 3000, curr loss: 1.2650957107543945, avg loss: 1.2693637895584107\n",
      "trial: 5, iter: 3200, curr loss: 1.2977906465530396, avg loss: 1.2704123455286025\n",
      "trial: 5, iter: 3400, curr loss: 1.2603946924209595, avg loss: 1.2704344868659974\n",
      "trial: 5, iter: 3600, curr loss: 1.254176378250122, avg loss: 1.2691168475151062\n",
      "trial: 5, iter: 3800, curr loss: 1.2831809520721436, avg loss: 1.2684292805194854\n",
      "trial: 5, iter: 4000, curr loss: 1.2649017572402954, avg loss: 1.264940161705017\n",
      "trial: 5, iter: 4200, curr loss: 1.2254939079284668, avg loss: 1.2672656506299973\n",
      "trial: 5, iter: 4400, curr loss: 1.216947317123413, avg loss: 1.2687768918275832\n",
      "trial: 5, iter: 4600, curr loss: 1.2704658508300781, avg loss: 1.2703460824489594\n",
      "trial: 5, iter: 4800, curr loss: 1.2663968801498413, avg loss: 1.2656454408168794\n",
      "trial: 5, iter: 5000, curr loss: 1.2491590976715088, avg loss: 1.2665884870290756\n",
      "trial: 5, iter: 5200, curr loss: 1.281660556793213, avg loss: 1.2632900822162627\n",
      "trial: 5, iter: 5400, curr loss: 1.2858103513717651, avg loss: 1.2649177610874176\n",
      "trial: 5, iter: 5600, curr loss: 1.2492800951004028, avg loss: 1.2637741649150849\n",
      "trial: 5, iter: 5800, curr loss: 1.2987618446350098, avg loss: 1.2651698988676072\n",
      "trial: 5, iter: 6000, curr loss: 1.261251449584961, avg loss: 1.2665633887052536\n",
      "trial: 5, iter: 6200, curr loss: 1.2597978115081787, avg loss: 1.2663559836149216\n",
      "trial: 5, iter: 6400, curr loss: 1.275146245956421, avg loss: 1.2643119013309478\n",
      "trial: 5, iter: 6600, curr loss: 1.2917418479919434, avg loss: 1.263694953918457\n",
      "trial: 5, iter: 6800, curr loss: 1.294735074043274, avg loss: 1.2658254075050355\n",
      "trial: 5, iter: 7000, curr loss: 1.2514066696166992, avg loss: 1.2617860698699952\n",
      "trial: 5, iter: 7200, curr loss: 1.2715461254119873, avg loss: 1.2654874795675277\n",
      "trial: 5, iter: 7400, curr loss: 1.2781575918197632, avg loss: 1.2662692791223527\n",
      "trial: 5, iter: 7600, curr loss: 1.279608964920044, avg loss: 1.2654535740613937\n",
      "trial: 5, iter: 7800, curr loss: 1.2437803745269775, avg loss: 1.2627812016010285\n",
      "trial: 5, iter: 8000, curr loss: 1.2173899412155151, avg loss: 1.2640422523021697\n",
      "trial: 5, iter: 8200, curr loss: 1.2864681482315063, avg loss: 1.2638375341892243\n",
      "trial: 5, iter: 8400, curr loss: 1.2532905340194702, avg loss: 1.2635865932703019\n",
      "trial: 5, iter: 8600, curr loss: 1.2843135595321655, avg loss: 1.2643332880735398\n",
      "trial: 5, iter: 8800, curr loss: 1.2532750368118286, avg loss: 1.2667612302303315\n",
      "trial: 5, iter: 9000, curr loss: 1.2200579643249512, avg loss: 1.2616317945718765\n",
      "trial: 5, iter: 9200, curr loss: 1.2784218788146973, avg loss: 1.2634859651327133\n",
      "trial: 5, iter: 9400, curr loss: 1.2392909526824951, avg loss: 1.256967943906784\n",
      "trial: 5, iter: 9600, curr loss: 1.263947606086731, avg loss: 1.264755876660347\n",
      "trial: 5, iter: 9800, curr loss: 1.2573020458221436, avg loss: 1.2644971346855163\n",
      "trial: 5, iter: 10000, curr loss: 1.2594096660614014, avg loss: 1.2633936506509782\n",
      "trial: 5, iter: 10200, curr loss: 1.2901581525802612, avg loss: 1.2637834936380385\n",
      "trial: 5, iter: 10400, curr loss: 1.276945948600769, avg loss: 1.2612865751981734\n",
      "trial: 5, iter: 10600, curr loss: 1.2279359102249146, avg loss: 1.2640681123733521\n",
      "trial: 5, iter: 10800, curr loss: 1.2542575597763062, avg loss: 1.262636166214943\n",
      "trial: 5, iter: 11000, curr loss: 1.2180399894714355, avg loss: 1.2618890804052354\n",
      "trial: 5, iter: 11200, curr loss: 1.2249902486801147, avg loss: 1.2593407547473907\n",
      "trial: 5, iter: 11400, curr loss: 1.2440792322158813, avg loss: 1.26046584546566\n",
      "trial: 5, iter: 11600, curr loss: 1.2636576890945435, avg loss: 1.2618585169315337\n",
      "trial: 5, iter: 11800, curr loss: 1.2473926544189453, avg loss: 1.261053261756897\n",
      "trial: 5, iter: 12000, curr loss: 1.2759859561920166, avg loss: 1.2623273104429245\n",
      "trial: 5, iter: 12200, curr loss: 1.2319128513336182, avg loss: 1.2644517695903779\n",
      "trial: 5, iter: 12400, curr loss: 1.2721892595291138, avg loss: 1.262336481809616\n",
      "trial: 5, iter: 12600, curr loss: 1.2549980878829956, avg loss: 1.2611465013027192\n",
      "trial: 5, iter: 12800, curr loss: 1.2871264219284058, avg loss: 1.2633243572711945\n",
      "trial: 5, iter: 13000, curr loss: 1.243210792541504, avg loss: 1.2599199867248536\n",
      "trial: 5, iter: 13200, curr loss: 1.2321492433547974, avg loss: 1.2599333703517914\n",
      "trial: 5, iter: 13400, curr loss: 1.2452703714370728, avg loss: 1.2616515570878983\n",
      "trial: 5, iter: 13600, curr loss: 1.270596981048584, avg loss: 1.2671863394975662\n",
      "trial: 5, iter: 13800, curr loss: 1.2544786930084229, avg loss: 1.2584151256084442\n",
      "trial: 5, iter: 14000, curr loss: 1.2415122985839844, avg loss: 1.2619827044010163\n",
      "trial: 5, iter: 14200, curr loss: 1.2595415115356445, avg loss: 1.2610708475112915\n",
      "trial: 5, iter: 14400, curr loss: 1.3107675313949585, avg loss: 1.261619295477867\n",
      "trial: 5, iter: 14600, curr loss: 1.2893563508987427, avg loss: 1.2642881643772126\n",
      "trial: 5, iter: 14800, curr loss: 1.272362470626831, avg loss: 1.2606419438123704\n",
      "trial: 5, iter: 15000, curr loss: 1.2296348810195923, avg loss: 1.2602850997447967\n",
      "trial: 5, iter: 15200, curr loss: 1.2063016891479492, avg loss: 1.260337046980858\n",
      "trial: 5, iter: 15400, curr loss: 1.2520803213119507, avg loss: 1.2612542486190796\n",
      "trial: 5, iter: 15600, curr loss: 1.2722736597061157, avg loss: 1.2550414216518402\n",
      "trial: 5, ldr: 0.24348708987236023\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26651776432991026\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3808605670928955, avg loss: 1.3864844685792923\n",
      "trial: 1, iter: 400, curr loss: 1.3827251195907593, avg loss: 1.3812545311450959\n",
      "trial: 1, iter: 600, curr loss: 1.2891727685928345, avg loss: 1.3422980016469956\n",
      "trial: 1, iter: 800, curr loss: 1.305005431175232, avg loss: 1.3196241664886474\n",
      "trial: 1, iter: 1000, curr loss: 1.3124668598175049, avg loss: 1.3135142350196838\n",
      "trial: 1, iter: 1200, curr loss: 1.3158149719238281, avg loss: 1.3054634022712708\n",
      "trial: 1, iter: 1400, curr loss: 1.299491286277771, avg loss: 1.299441141486168\n",
      "trial: 1, iter: 1600, curr loss: 1.3321713209152222, avg loss: 1.2936885094642638\n",
      "trial: 1, iter: 1800, curr loss: 1.2956032752990723, avg loss: 1.2881499314308167\n",
      "trial: 1, iter: 2000, curr loss: 1.2972313165664673, avg loss: 1.2834606450796127\n",
      "trial: 1, iter: 2200, curr loss: 1.2411986589431763, avg loss: 1.275602124929428\n",
      "trial: 1, iter: 2400, curr loss: 1.278388261795044, avg loss: 1.2742415535449982\n",
      "trial: 1, iter: 2600, curr loss: 1.2601840496063232, avg loss: 1.271810514330864\n",
      "trial: 1, iter: 2800, curr loss: 1.3266069889068604, avg loss: 1.2730723518133162\n",
      "trial: 1, iter: 3000, curr loss: 1.279787540435791, avg loss: 1.2698938703536988\n",
      "trial: 1, iter: 3200, curr loss: 1.3094881772994995, avg loss: 1.2715699833631515\n",
      "trial: 1, iter: 3400, curr loss: 1.2993035316467285, avg loss: 1.2667636102437974\n",
      "trial: 1, iter: 3600, curr loss: 1.271773099899292, avg loss: 1.2694069975614548\n",
      "trial: 1, iter: 3800, curr loss: 1.2358564138412476, avg loss: 1.2656489503383637\n",
      "trial: 1, iter: 4000, curr loss: 1.2531228065490723, avg loss: 1.2652660858631135\n",
      "trial: 1, iter: 4200, curr loss: 1.3285194635391235, avg loss: 1.2663723754882812\n",
      "trial: 1, iter: 4400, curr loss: 1.279012680053711, avg loss: 1.262956886291504\n",
      "trial: 1, iter: 4600, curr loss: 1.261481761932373, avg loss: 1.2669949805736542\n",
      "trial: 1, iter: 4800, curr loss: 1.3297933340072632, avg loss: 1.2649528646469117\n",
      "trial: 1, iter: 5000, curr loss: 1.2365458011627197, avg loss: 1.2683273184299468\n",
      "trial: 1, iter: 5200, curr loss: 1.241842269897461, avg loss: 1.267604839205742\n",
      "trial: 1, iter: 5400, curr loss: 1.2841452360153198, avg loss: 1.2671890205144882\n",
      "trial: 1, iter: 5600, curr loss: 1.272779107093811, avg loss: 1.2661263149976731\n",
      "trial: 1, iter: 5800, curr loss: 1.2549012899398804, avg loss: 1.2656368881464004\n",
      "trial: 1, iter: 6000, curr loss: 1.21390962600708, avg loss: 1.2627559512853623\n",
      "trial: 1, iter: 6200, curr loss: 1.2780253887176514, avg loss: 1.2682491886615752\n",
      "trial: 1, iter: 6400, curr loss: 1.2651375532150269, avg loss: 1.267116168141365\n",
      "trial: 1, iter: 6600, curr loss: 1.226004719734192, avg loss: 1.2689166021347047\n",
      "trial: 1, iter: 6800, curr loss: 1.2873963117599487, avg loss: 1.265716335773468\n",
      "trial: 1, iter: 7000, curr loss: 1.2594542503356934, avg loss: 1.2644928365945816\n",
      "trial: 1, iter: 7200, curr loss: 1.2633049488067627, avg loss: 1.2649970763921738\n",
      "trial: 1, iter: 7400, curr loss: 1.3211021423339844, avg loss: 1.2653540515899657\n",
      "trial: 1, iter: 7600, curr loss: 1.2493977546691895, avg loss: 1.2648884212970735\n",
      "trial: 1, iter: 7800, curr loss: 1.2671469449996948, avg loss: 1.2631336736679077\n",
      "trial: 1, iter: 8000, curr loss: 1.2734006643295288, avg loss: 1.2625870299339295\n",
      "trial: 1, iter: 8200, curr loss: 1.2921397686004639, avg loss: 1.265545796751976\n",
      "trial: 1, iter: 8400, curr loss: 1.2837414741516113, avg loss: 1.2639219611883163\n",
      "trial: 1, iter: 8600, curr loss: 1.2880667448043823, avg loss: 1.2668225377798081\n",
      "trial: 1, iter: 8800, curr loss: 1.25748610496521, avg loss: 1.2638616418838502\n",
      "trial: 1, iter: 9000, curr loss: 1.276561975479126, avg loss: 1.2663060945272446\n",
      "trial: 1, iter: 9200, curr loss: 1.2277195453643799, avg loss: 1.2636056888103484\n",
      "trial: 1, iter: 9400, curr loss: 1.2712117433547974, avg loss: 1.2618198984861373\n",
      "trial: 1, iter: 9600, curr loss: 1.276663064956665, avg loss: 1.26251111805439\n",
      "trial: 1, iter: 9800, curr loss: 1.2351840734481812, avg loss: 1.263144547343254\n",
      "trial: 1, iter: 10000, curr loss: 1.3072514533996582, avg loss: 1.261982752084732\n",
      "trial: 1, iter: 10200, curr loss: 1.2638732194900513, avg loss: 1.2607096844911576\n",
      "trial: 1, iter: 10400, curr loss: 1.2689037322998047, avg loss: 1.2612963545322418\n",
      "trial: 1, iter: 10600, curr loss: 1.2786110639572144, avg loss: 1.2620668971538545\n",
      "trial: 1, iter: 10800, curr loss: 1.2590264081954956, avg loss: 1.2606963783502578\n",
      "trial: 1, iter: 11000, curr loss: 1.2393304109573364, avg loss: 1.261493712067604\n",
      "trial: 1, iter: 11200, curr loss: 1.2862460613250732, avg loss: 1.2670847183465959\n",
      "trial: 1, iter: 11400, curr loss: 1.2532576322555542, avg loss: 1.261602423787117\n",
      "trial: 1, iter: 11600, curr loss: 1.243520736694336, avg loss: 1.261908791065216\n",
      "trial: 1, iter: 11800, curr loss: 1.2556507587432861, avg loss: 1.2615433686971664\n",
      "trial: 1, iter: 12000, curr loss: 1.2426245212554932, avg loss: 1.2624517428874968\n",
      "trial: 1, iter: 12200, curr loss: 1.2769962549209595, avg loss: 1.2637337058782578\n",
      "trial: 1, iter: 12400, curr loss: 1.2972017526626587, avg loss: 1.2610060679912567\n",
      "trial: 1, iter: 12600, curr loss: 1.2692017555236816, avg loss: 1.2636688488721848\n",
      "trial: 1, iter: 12800, curr loss: 1.2878457307815552, avg loss: 1.2627567499876022\n",
      "trial: 1, iter: 13000, curr loss: 1.2893513441085815, avg loss: 1.264584499001503\n",
      "trial: 1, iter: 13200, curr loss: 1.2353999614715576, avg loss: 1.2630889731645585\n",
      "trial: 1, iter: 13400, curr loss: 1.297343134880066, avg loss: 1.2590028780698777\n",
      "trial: 1, iter: 13600, curr loss: 1.2532892227172852, avg loss: 1.2609904307126998\n",
      "trial: 1, iter: 13800, curr loss: 1.2911767959594727, avg loss: 1.2667966777086257\n",
      "trial: 1, iter: 14000, curr loss: 1.2711749076843262, avg loss: 1.2629824435710908\n",
      "trial: 1, iter: 14200, curr loss: 1.2503089904785156, avg loss: 1.2631085407733917\n",
      "trial: 1, iter: 14400, curr loss: 1.27200186252594, avg loss: 1.2666811579465866\n",
      "trial: 1, iter: 14600, curr loss: 1.2253642082214355, avg loss: 1.2621926027536392\n",
      "trial: 1, iter: 14800, curr loss: 1.2036737203598022, avg loss: 1.259755546450615\n",
      "trial: 1, iter: 15000, curr loss: 1.2501823902130127, avg loss: 1.260334650874138\n",
      "trial: 1, iter: 15200, curr loss: 1.269710898399353, avg loss: 1.26193816781044\n",
      "trial: 1, iter: 15400, curr loss: 1.2331793308258057, avg loss: 1.2648243236541747\n",
      "trial: 1, iter: 15600, curr loss: 1.258756399154663, avg loss: 1.2618704694509506\n",
      "trial: 1, ldr: 0.21652257442474365\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3834505081176758, avg loss: 1.3866948890686035\n",
      "trial: 2, iter: 400, curr loss: 1.363161325454712, avg loss: 1.3791991585493089\n",
      "trial: 2, iter: 600, curr loss: 1.3019979000091553, avg loss: 1.3399821865558623\n",
      "trial: 2, iter: 800, curr loss: 1.3313541412353516, avg loss: 1.3164450097084046\n",
      "trial: 2, iter: 1000, curr loss: 1.2882376909255981, avg loss: 1.3101847213506699\n",
      "trial: 2, iter: 1200, curr loss: 1.3077198266983032, avg loss: 1.3036736840009688\n",
      "trial: 2, iter: 1400, curr loss: 1.2895922660827637, avg loss: 1.29821166574955\n",
      "trial: 2, iter: 1600, curr loss: 1.280222773551941, avg loss: 1.2890941727161407\n",
      "trial: 2, iter: 1800, curr loss: 1.2960597276687622, avg loss: 1.283906244635582\n",
      "trial: 2, iter: 2000, curr loss: 1.2729800939559937, avg loss: 1.2792968440055847\n",
      "trial: 2, iter: 2200, curr loss: 1.276350736618042, avg loss: 1.275883058309555\n",
      "trial: 2, iter: 2400, curr loss: 1.294441819190979, avg loss: 1.2747176903486253\n",
      "trial: 2, iter: 2600, curr loss: 1.2516251802444458, avg loss: 1.2715640413761138\n",
      "trial: 2, iter: 2800, curr loss: 1.2571216821670532, avg loss: 1.2712254482507706\n",
      "trial: 2, iter: 3000, curr loss: 1.2940744161605835, avg loss: 1.2670278036594391\n",
      "trial: 2, iter: 3200, curr loss: 1.2362695932388306, avg loss: 1.2712220627069473\n",
      "trial: 2, iter: 3400, curr loss: 1.255645751953125, avg loss: 1.268896650671959\n",
      "trial: 2, iter: 3600, curr loss: 1.2438950538635254, avg loss: 1.2694336646795272\n",
      "trial: 2, iter: 3800, curr loss: 1.2609409093856812, avg loss: 1.269240778684616\n",
      "trial: 2, iter: 4000, curr loss: 1.2901146411895752, avg loss: 1.2690607637166977\n",
      "trial: 2, iter: 4200, curr loss: 1.2707405090332031, avg loss: 1.2659413397312165\n",
      "trial: 2, iter: 4400, curr loss: 1.3030304908752441, avg loss: 1.2660007619857787\n",
      "trial: 2, iter: 4600, curr loss: 1.2890022993087769, avg loss: 1.2667382395267486\n",
      "trial: 2, iter: 4800, curr loss: 1.2471550703048706, avg loss: 1.262316601872444\n",
      "trial: 2, iter: 5000, curr loss: 1.281891107559204, avg loss: 1.268407679796219\n",
      "trial: 2, iter: 5200, curr loss: 1.24882972240448, avg loss: 1.263131628036499\n",
      "trial: 2, iter: 5400, curr loss: 1.241855502128601, avg loss: 1.265017020702362\n",
      "trial: 2, iter: 5600, curr loss: 1.2675251960754395, avg loss: 1.2671164464950562\n",
      "trial: 2, iter: 5800, curr loss: 1.2613894939422607, avg loss: 1.2663467973470688\n",
      "trial: 2, iter: 6000, curr loss: 1.2896395921707153, avg loss: 1.266065250635147\n",
      "trial: 2, iter: 6200, curr loss: 1.2681909799575806, avg loss: 1.2658283472061158\n",
      "trial: 2, iter: 6400, curr loss: 1.2672604322433472, avg loss: 1.2653289777040482\n",
      "trial: 2, iter: 6600, curr loss: 1.2578929662704468, avg loss: 1.2640317815542221\n",
      "trial: 2, iter: 6800, curr loss: 1.2584258317947388, avg loss: 1.2637368154525757\n",
      "trial: 2, iter: 7000, curr loss: 1.2313895225524902, avg loss: 1.2663157099485398\n",
      "trial: 2, iter: 7200, curr loss: 1.2257602214813232, avg loss: 1.2640672212839126\n",
      "trial: 2, iter: 7400, curr loss: 1.2396961450576782, avg loss: 1.2641749262809754\n",
      "trial: 2, iter: 7600, curr loss: 1.2650715112686157, avg loss: 1.2659188401699066\n",
      "trial: 2, iter: 7800, curr loss: 1.2362699508666992, avg loss: 1.267679165005684\n",
      "trial: 2, iter: 8000, curr loss: 1.260979175567627, avg loss: 1.2635491943359376\n",
      "trial: 2, iter: 8200, curr loss: 1.2266250848770142, avg loss: 1.2658929818868636\n",
      "trial: 2, iter: 8400, curr loss: 1.2815630435943604, avg loss: 1.263969514966011\n",
      "trial: 2, iter: 8600, curr loss: 1.2698328495025635, avg loss: 1.2636073756217956\n",
      "trial: 2, iter: 8800, curr loss: 1.2798898220062256, avg loss: 1.2605920952558518\n",
      "trial: 2, iter: 9000, curr loss: 1.2282888889312744, avg loss: 1.2645654314756394\n",
      "trial: 2, iter: 9200, curr loss: 1.309231162071228, avg loss: 1.2642238450050354\n",
      "trial: 2, iter: 9400, curr loss: 1.2824976444244385, avg loss: 1.2632959759235383\n",
      "trial: 2, iter: 9600, curr loss: 1.2831794023513794, avg loss: 1.2650963240861892\n",
      "trial: 2, iter: 9800, curr loss: 1.2188931703567505, avg loss: 1.2628977024555206\n",
      "trial: 2, iter: 10000, curr loss: 1.2607386112213135, avg loss: 1.2659352272748947\n",
      "trial: 2, iter: 10200, curr loss: 1.2781647443771362, avg loss: 1.2669065874814986\n",
      "trial: 2, iter: 10400, curr loss: 1.249903678894043, avg loss: 1.2634852302074433\n",
      "trial: 2, iter: 10600, curr loss: 1.2663837671279907, avg loss: 1.2657550036907197\n",
      "trial: 2, iter: 10800, curr loss: 1.2638347148895264, avg loss: 1.2617474108934403\n",
      "trial: 2, iter: 11000, curr loss: 1.240889072418213, avg loss: 1.263025967478752\n",
      "trial: 2, iter: 11200, curr loss: 1.288994312286377, avg loss: 1.2640088963508607\n",
      "trial: 2, iter: 11400, curr loss: 1.2562469244003296, avg loss: 1.2617993104457854\n",
      "trial: 2, iter: 11600, curr loss: 1.2359575033187866, avg loss: 1.2632448327541352\n",
      "trial: 2, iter: 11800, curr loss: 1.2614771127700806, avg loss: 1.2628225648403169\n",
      "trial: 2, iter: 12000, curr loss: 1.3069682121276855, avg loss: 1.26508045732975\n",
      "trial: 2, iter: 12200, curr loss: 1.2532345056533813, avg loss: 1.2625016742944717\n",
      "trial: 2, iter: 12400, curr loss: 1.275143027305603, avg loss: 1.26258416056633\n",
      "trial: 2, iter: 12600, curr loss: 1.2937465906143188, avg loss: 1.2614632451534271\n",
      "trial: 2, iter: 12800, curr loss: 1.3005456924438477, avg loss: 1.2626819360256194\n",
      "trial: 2, iter: 13000, curr loss: 1.2938976287841797, avg loss: 1.2616999489068985\n",
      "trial: 2, iter: 13200, curr loss: 1.2740813493728638, avg loss: 1.2632292252779007\n",
      "trial: 2, iter: 13400, curr loss: 1.2595880031585693, avg loss: 1.2615022367239\n",
      "trial: 2, iter: 13600, curr loss: 1.2254356145858765, avg loss: 1.2627955943346023\n",
      "trial: 2, iter: 13800, curr loss: 1.265512466430664, avg loss: 1.2624358642101288\n",
      "trial: 2, iter: 14000, curr loss: 1.2871453762054443, avg loss: 1.2622110748291016\n",
      "trial: 2, iter: 14200, curr loss: 1.2247658967971802, avg loss: 1.2633273029327392\n",
      "trial: 2, iter: 14400, curr loss: 1.2520400285720825, avg loss: 1.2616352671384812\n",
      "trial: 2, iter: 14600, curr loss: 1.2669453620910645, avg loss: 1.2646230250597\n",
      "trial: 2, iter: 14800, curr loss: 1.2195472717285156, avg loss: 1.2592448568344117\n",
      "trial: 2, iter: 15000, curr loss: 1.3024553060531616, avg loss: 1.2628177118301391\n",
      "trial: 2, iter: 15200, curr loss: 1.269463062286377, avg loss: 1.2601943981647492\n",
      "trial: 2, iter: 15400, curr loss: 1.2087252140045166, avg loss: 1.262790585756302\n",
      "trial: 2, iter: 15600, curr loss: 1.2460147142410278, avg loss: 1.2601070666313172\n",
      "trial: 2, ldr: 0.29864564538002014\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.381942868232727, avg loss: 1.3861804461479188\n",
      "trial: 3, iter: 400, curr loss: 1.3543646335601807, avg loss: 1.3762366080284119\n",
      "trial: 3, iter: 600, curr loss: 1.3494243621826172, avg loss: 1.343614313006401\n",
      "trial: 3, iter: 800, curr loss: 1.273875117301941, avg loss: 1.3226684093475343\n",
      "trial: 3, iter: 1000, curr loss: 1.3466665744781494, avg loss: 1.3160995280742644\n",
      "trial: 3, iter: 1200, curr loss: 1.2846834659576416, avg loss: 1.3123516184091568\n",
      "trial: 3, iter: 1400, curr loss: 1.283055067062378, avg loss: 1.3045728766918183\n",
      "trial: 3, iter: 1600, curr loss: 1.3153283596038818, avg loss: 1.298295601606369\n",
      "trial: 3, iter: 1800, curr loss: 1.2583870887756348, avg loss: 1.2900685667991638\n",
      "trial: 3, iter: 2000, curr loss: 1.301012396812439, avg loss: 1.2838743865489959\n",
      "trial: 3, iter: 2200, curr loss: 1.296842098236084, avg loss: 1.278640919327736\n",
      "trial: 3, iter: 2400, curr loss: 1.2753498554229736, avg loss: 1.2754370504617691\n",
      "trial: 3, iter: 2600, curr loss: 1.339956283569336, avg loss: 1.275442681312561\n",
      "trial: 3, iter: 2800, curr loss: 1.2828290462493896, avg loss: 1.2729556065797807\n",
      "trial: 3, iter: 3000, curr loss: 1.2729994058609009, avg loss: 1.2728940945863725\n",
      "trial: 3, iter: 3200, curr loss: 1.2457594871520996, avg loss: 1.2702054357528687\n",
      "trial: 3, iter: 3400, curr loss: 1.3025844097137451, avg loss: 1.271696504354477\n",
      "trial: 3, iter: 3600, curr loss: 1.2638988494873047, avg loss: 1.2675096362829208\n",
      "trial: 3, iter: 3800, curr loss: 1.2517908811569214, avg loss: 1.271328673362732\n",
      "trial: 3, iter: 4000, curr loss: 1.2839179039001465, avg loss: 1.2657099455595016\n",
      "trial: 3, iter: 4200, curr loss: 1.284862756729126, avg loss: 1.2676140505075455\n",
      "trial: 3, iter: 4400, curr loss: 1.232757329940796, avg loss: 1.2704955321550369\n",
      "trial: 3, iter: 4600, curr loss: 1.2816897630691528, avg loss: 1.2679890531301499\n",
      "trial: 3, iter: 4800, curr loss: 1.2821987867355347, avg loss: 1.2691069585084915\n",
      "trial: 3, iter: 5000, curr loss: 1.2955381870269775, avg loss: 1.2674942326545715\n",
      "trial: 3, iter: 5200, curr loss: 1.2860217094421387, avg loss: 1.2659467828273774\n",
      "trial: 3, iter: 5400, curr loss: 1.2832396030426025, avg loss: 1.2679762852191925\n",
      "trial: 3, iter: 5600, curr loss: 1.245908260345459, avg loss: 1.2627401065826416\n",
      "trial: 3, iter: 5800, curr loss: 1.3007022142410278, avg loss: 1.2663087171316147\n",
      "trial: 3, iter: 6000, curr loss: 1.3261315822601318, avg loss: 1.2674424183368682\n",
      "trial: 3, iter: 6200, curr loss: 1.2742691040039062, avg loss: 1.2645112675428392\n",
      "trial: 3, iter: 6400, curr loss: 1.2507925033569336, avg loss: 1.2661901718378068\n",
      "trial: 3, iter: 6600, curr loss: 1.2649452686309814, avg loss: 1.2661783802509308\n",
      "trial: 3, iter: 6800, curr loss: 1.28139328956604, avg loss: 1.2683554136753081\n",
      "trial: 3, iter: 7000, curr loss: 1.2370774745941162, avg loss: 1.265888404250145\n",
      "trial: 3, iter: 7200, curr loss: 1.2340134382247925, avg loss: 1.2661622124910354\n",
      "trial: 3, iter: 7400, curr loss: 1.2762528657913208, avg loss: 1.2618942779302598\n",
      "trial: 3, iter: 7600, curr loss: 1.2631504535675049, avg loss: 1.266209096312523\n",
      "trial: 3, iter: 7800, curr loss: 1.2688865661621094, avg loss: 1.263909723162651\n",
      "trial: 3, iter: 8000, curr loss: 1.2740081548690796, avg loss: 1.2666424816846849\n",
      "trial: 3, iter: 8200, curr loss: 1.2591044902801514, avg loss: 1.2655964356660843\n",
      "trial: 3, iter: 8400, curr loss: 1.2101787328720093, avg loss: 1.2629542988538742\n",
      "trial: 3, iter: 8600, curr loss: 1.2014830112457275, avg loss: 1.2615026158094407\n",
      "trial: 3, iter: 8800, curr loss: 1.2515054941177368, avg loss: 1.2642740380764008\n",
      "trial: 3, iter: 9000, curr loss: 1.249923825263977, avg loss: 1.2618049633502961\n",
      "trial: 3, iter: 9200, curr loss: 1.3287750482559204, avg loss: 1.2671924084424973\n",
      "trial: 3, iter: 9400, curr loss: 1.2394272089004517, avg loss: 1.26316037774086\n",
      "trial: 3, iter: 9600, curr loss: 1.279393196105957, avg loss: 1.2630816465616226\n",
      "trial: 3, iter: 9800, curr loss: 1.2588704824447632, avg loss: 1.2645929819345474\n",
      "trial: 3, iter: 10000, curr loss: 1.2593168020248413, avg loss: 1.2664122021198272\n",
      "trial: 3, iter: 10200, curr loss: 1.2554128170013428, avg loss: 1.2666355437040329\n",
      "trial: 3, iter: 10400, curr loss: 1.243601679801941, avg loss: 1.261728110909462\n",
      "trial: 3, iter: 10600, curr loss: 1.2505934238433838, avg loss: 1.2651139885187148\n",
      "trial: 3, iter: 10800, curr loss: 1.2311042547225952, avg loss: 1.2654017436504363\n",
      "trial: 3, iter: 11000, curr loss: 1.2659131288528442, avg loss: 1.2651468074321748\n",
      "trial: 3, iter: 11200, curr loss: 1.2841991186141968, avg loss: 1.2646056431531907\n",
      "trial: 3, iter: 11400, curr loss: 1.2539159059524536, avg loss: 1.2625414907932282\n",
      "trial: 3, iter: 11600, curr loss: 1.269426703453064, avg loss: 1.2629028290510178\n",
      "trial: 3, iter: 11800, curr loss: 1.2756471633911133, avg loss: 1.2642550390958787\n",
      "trial: 3, iter: 12000, curr loss: 1.271533489227295, avg loss: 1.2619997781515122\n",
      "trial: 3, iter: 12200, curr loss: 1.2750176191329956, avg loss: 1.2618689829111098\n",
      "trial: 3, iter: 12400, curr loss: 1.2687969207763672, avg loss: 1.2633582830429078\n",
      "trial: 3, iter: 12600, curr loss: 1.3117488622665405, avg loss: 1.2617308366298676\n",
      "trial: 3, iter: 12800, curr loss: 1.286241054534912, avg loss: 1.2635463058948517\n",
      "trial: 3, iter: 13000, curr loss: 1.286850094795227, avg loss: 1.2606741428375243\n",
      "trial: 3, iter: 13200, curr loss: 1.289893627166748, avg loss: 1.2635020005702973\n",
      "trial: 3, iter: 13400, curr loss: 1.2388594150543213, avg loss: 1.25980712890625\n",
      "trial: 3, iter: 13600, curr loss: 1.2806456089019775, avg loss: 1.2618116027116775\n",
      "trial: 3, iter: 13800, curr loss: 1.2797768115997314, avg loss: 1.2622705924510955\n",
      "trial: 3, iter: 14000, curr loss: 1.256466269493103, avg loss: 1.262431862950325\n",
      "trial: 3, iter: 14200, curr loss: 1.301507592201233, avg loss: 1.2633769422769547\n",
      "trial: 3, iter: 14400, curr loss: 1.2532448768615723, avg loss: 1.2585812717676164\n",
      "trial: 3, iter: 14600, curr loss: 1.2909049987792969, avg loss: 1.2620158737897873\n",
      "trial: 3, iter: 14800, curr loss: 1.2286839485168457, avg loss: 1.2626875841617584\n",
      "trial: 3, iter: 15000, curr loss: 1.2358243465423584, avg loss: 1.2608568954467774\n",
      "trial: 3, iter: 15200, curr loss: 1.2297574281692505, avg loss: 1.2639080089330674\n",
      "trial: 3, iter: 15400, curr loss: 1.2628692388534546, avg loss: 1.2634225296974182\n",
      "trial: 3, iter: 15600, curr loss: 1.230452537536621, avg loss: 1.2635686427354813\n",
      "trial: 3, ldr: 0.2797313928604126\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3845269680023193, avg loss: 1.386787363886833\n",
      "trial: 4, iter: 400, curr loss: 1.384436011314392, avg loss: 1.3831076395511628\n",
      "trial: 4, iter: 600, curr loss: 1.317682147026062, avg loss: 1.3556875586509705\n",
      "trial: 4, iter: 800, curr loss: 1.334973692893982, avg loss: 1.326482993364334\n",
      "trial: 4, iter: 1000, curr loss: 1.2788846492767334, avg loss: 1.3181903755664826\n",
      "trial: 4, iter: 1200, curr loss: 1.3182326555252075, avg loss: 1.3110456359386444\n",
      "trial: 4, iter: 1400, curr loss: 1.280056357383728, avg loss: 1.3050958520174027\n",
      "trial: 4, iter: 1600, curr loss: 1.287669062614441, avg loss: 1.3028427147865296\n",
      "trial: 4, iter: 1800, curr loss: 1.267183780670166, avg loss: 1.299035816192627\n",
      "trial: 4, iter: 2000, curr loss: 1.2879054546356201, avg loss: 1.2913919931650162\n",
      "trial: 4, iter: 2200, curr loss: 1.2935720682144165, avg loss: 1.2807610136270524\n",
      "trial: 4, iter: 2400, curr loss: 1.2690101861953735, avg loss: 1.2785976433753967\n",
      "trial: 4, iter: 2600, curr loss: 1.2559354305267334, avg loss: 1.2757308888435364\n",
      "trial: 4, iter: 2800, curr loss: 1.2575451135635376, avg loss: 1.2734907698631286\n",
      "trial: 4, iter: 3000, curr loss: 1.2804598808288574, avg loss: 1.2713715839385986\n",
      "trial: 4, iter: 3200, curr loss: 1.2149473428726196, avg loss: 1.269969121813774\n",
      "trial: 4, iter: 3400, curr loss: 1.3013349771499634, avg loss: 1.2710671442747117\n",
      "trial: 4, iter: 3600, curr loss: 1.2877023220062256, avg loss: 1.2702750289440154\n",
      "trial: 4, iter: 3800, curr loss: 1.2682909965515137, avg loss: 1.2698474645614624\n",
      "trial: 4, iter: 4000, curr loss: 1.268441915512085, avg loss: 1.2686190503835677\n",
      "trial: 4, iter: 4200, curr loss: 1.235852837562561, avg loss: 1.2695066994428634\n",
      "trial: 4, iter: 4400, curr loss: 1.2147172689437866, avg loss: 1.2669567888975144\n",
      "trial: 4, iter: 4600, curr loss: 1.299243688583374, avg loss: 1.2691220271587371\n",
      "trial: 4, iter: 4800, curr loss: 1.2711917161941528, avg loss: 1.266511487364769\n",
      "trial: 4, iter: 5000, curr loss: 1.2774051427841187, avg loss: 1.2677179032564163\n",
      "trial: 4, iter: 5200, curr loss: 1.2370291948318481, avg loss: 1.2646880680322647\n",
      "trial: 4, iter: 5400, curr loss: 1.28452730178833, avg loss: 1.2665255171060563\n",
      "trial: 4, iter: 5600, curr loss: 1.265538215637207, avg loss: 1.2701592671871185\n",
      "trial: 4, iter: 5800, curr loss: 1.2904551029205322, avg loss: 1.2621461153030396\n",
      "trial: 4, iter: 6000, curr loss: 1.2454264163970947, avg loss: 1.2663005894422532\n",
      "trial: 4, iter: 6200, curr loss: 1.3139787912368774, avg loss: 1.2642574608325958\n",
      "trial: 4, iter: 6400, curr loss: 1.2647382020950317, avg loss: 1.2673198211193084\n",
      "trial: 4, iter: 6600, curr loss: 1.248764157295227, avg loss: 1.2646789330244064\n",
      "trial: 4, iter: 6800, curr loss: 1.2506248950958252, avg loss: 1.266497209072113\n",
      "trial: 4, iter: 7000, curr loss: 1.266029953956604, avg loss: 1.2626221251487733\n",
      "trial: 4, iter: 7200, curr loss: 1.245573878288269, avg loss: 1.2666344332695008\n",
      "trial: 4, iter: 7400, curr loss: 1.2823615074157715, avg loss: 1.2630475819110871\n",
      "trial: 4, iter: 7600, curr loss: 1.2698047161102295, avg loss: 1.2670110881328582\n",
      "trial: 4, iter: 7800, curr loss: 1.272627830505371, avg loss: 1.264676821231842\n",
      "trial: 4, iter: 8000, curr loss: 1.2698853015899658, avg loss: 1.2652726578712463\n",
      "trial: 4, iter: 8200, curr loss: 1.243735909461975, avg loss: 1.2622490030527116\n",
      "trial: 4, iter: 8400, curr loss: 1.2744905948638916, avg loss: 1.2635468751192094\n",
      "trial: 4, iter: 8600, curr loss: 1.2671712636947632, avg loss: 1.2664299702644348\n",
      "trial: 4, iter: 8800, curr loss: 1.213961124420166, avg loss: 1.2621316611766815\n",
      "trial: 4, iter: 9000, curr loss: 1.239701509475708, avg loss: 1.2620241415500641\n",
      "trial: 4, iter: 9200, curr loss: 1.287008285522461, avg loss: 1.2646984201669693\n",
      "trial: 4, iter: 9400, curr loss: 1.233025074005127, avg loss: 1.2652854770421982\n",
      "trial: 4, iter: 9600, curr loss: 1.2638416290283203, avg loss: 1.2622185105085373\n",
      "trial: 4, iter: 9800, curr loss: 1.2800880670547485, avg loss: 1.26400250852108\n",
      "trial: 4, iter: 10000, curr loss: 1.249405860900879, avg loss: 1.265525040626526\n",
      "trial: 4, iter: 10200, curr loss: 1.2750110626220703, avg loss: 1.2657968038320542\n",
      "trial: 4, iter: 10400, curr loss: 1.2490966320037842, avg loss: 1.2641964858770371\n",
      "trial: 4, iter: 10600, curr loss: 1.2650713920593262, avg loss: 1.264645426273346\n",
      "trial: 4, iter: 10800, curr loss: 1.22592031955719, avg loss: 1.2621466141939164\n",
      "trial: 4, iter: 11000, curr loss: 1.245793342590332, avg loss: 1.2630981063842774\n",
      "trial: 4, iter: 11200, curr loss: 1.2407798767089844, avg loss: 1.2638578814268113\n",
      "trial: 4, iter: 11400, curr loss: 1.3019986152648926, avg loss: 1.2631868922710419\n",
      "trial: 4, iter: 11600, curr loss: 1.2947487831115723, avg loss: 1.2643188560009002\n",
      "trial: 4, iter: 11800, curr loss: 1.286561131477356, avg loss: 1.2642296642065047\n",
      "trial: 4, iter: 12000, curr loss: 1.3215771913528442, avg loss: 1.261751537322998\n",
      "trial: 4, iter: 12200, curr loss: 1.2487480640411377, avg loss: 1.2647819018363953\n",
      "trial: 4, iter: 12400, curr loss: 1.2373288869857788, avg loss: 1.2640336018800735\n",
      "trial: 4, iter: 12600, curr loss: 1.2561203241348267, avg loss: 1.2607311022281646\n",
      "trial: 4, iter: 12800, curr loss: 1.2712526321411133, avg loss: 1.2655755883455277\n",
      "trial: 4, iter: 13000, curr loss: 1.2465715408325195, avg loss: 1.260542293190956\n",
      "trial: 4, iter: 13200, curr loss: 1.2435346841812134, avg loss: 1.263716797232628\n",
      "trial: 4, iter: 13400, curr loss: 1.2578740119934082, avg loss: 1.2649748533964158\n",
      "trial: 4, iter: 13600, curr loss: 1.3032678365707397, avg loss: 1.2653961771726607\n",
      "trial: 4, iter: 13800, curr loss: 1.2902920246124268, avg loss: 1.2662437695264817\n",
      "trial: 4, iter: 14000, curr loss: 1.2128609418869019, avg loss: 1.2649713885784148\n",
      "trial: 4, iter: 14200, curr loss: 1.300888180732727, avg loss: 1.2635244691371919\n",
      "trial: 4, iter: 14400, curr loss: 1.24900484085083, avg loss: 1.2629731237888335\n",
      "trial: 4, iter: 14600, curr loss: 1.2221719026565552, avg loss: 1.2643696290254594\n",
      "trial: 4, iter: 14800, curr loss: 1.2827154397964478, avg loss: 1.2618154501914978\n",
      "trial: 4, iter: 15000, curr loss: 1.2528878450393677, avg loss: 1.263879354596138\n",
      "trial: 4, iter: 15200, curr loss: 1.2292428016662598, avg loss: 1.261392520070076\n",
      "trial: 4, iter: 15400, curr loss: 1.2323582172393799, avg loss: 1.2632058727741242\n",
      "trial: 4, iter: 15600, curr loss: 1.2450535297393799, avg loss: 1.264645643234253\n",
      "trial: 4, ldr: 0.30836957693099976\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.383064866065979, avg loss: 1.3866702902317047\n",
      "trial: 5, iter: 400, curr loss: 1.3896547555923462, avg loss: 1.3857938480377197\n",
      "trial: 5, iter: 600, curr loss: 1.3773308992385864, avg loss: 1.3758113366365432\n",
      "trial: 5, iter: 800, curr loss: 1.3392417430877686, avg loss: 1.3411134111881255\n",
      "trial: 5, iter: 1000, curr loss: 1.3295361995697021, avg loss: 1.3254282075166701\n",
      "trial: 5, iter: 1200, curr loss: 1.2985018491744995, avg loss: 1.3192385119199752\n",
      "trial: 5, iter: 1400, curr loss: 1.3236374855041504, avg loss: 1.315199316740036\n",
      "trial: 5, iter: 1600, curr loss: 1.3171591758728027, avg loss: 1.3082902997732162\n",
      "trial: 5, iter: 1800, curr loss: 1.3208022117614746, avg loss: 1.305128378868103\n",
      "trial: 5, iter: 2000, curr loss: 1.2990082502365112, avg loss: 1.2982290399074554\n",
      "trial: 5, iter: 2200, curr loss: 1.3087633848190308, avg loss: 1.2939159643650056\n",
      "trial: 5, iter: 2400, curr loss: 1.2918102741241455, avg loss: 1.2905593007802962\n",
      "trial: 5, iter: 2600, curr loss: 1.2596794366836548, avg loss: 1.2834928411245345\n",
      "trial: 5, iter: 2800, curr loss: 1.2900676727294922, avg loss: 1.278141154050827\n",
      "trial: 5, iter: 3000, curr loss: 1.28043794631958, avg loss: 1.2772995203733444\n",
      "trial: 5, iter: 3200, curr loss: 1.2570621967315674, avg loss: 1.2747952669858933\n",
      "trial: 5, iter: 3400, curr loss: 1.2714829444885254, avg loss: 1.2725824296474457\n",
      "trial: 5, iter: 3600, curr loss: 1.2465660572052002, avg loss: 1.2724535989761352\n",
      "trial: 5, iter: 3800, curr loss: 1.2328404188156128, avg loss: 1.270772647857666\n",
      "trial: 5, iter: 4000, curr loss: 1.287482738494873, avg loss: 1.2726571530103683\n",
      "trial: 5, iter: 4200, curr loss: 1.2525330781936646, avg loss: 1.2709524214267731\n",
      "trial: 5, iter: 4400, curr loss: 1.2404382228851318, avg loss: 1.2687465918064118\n",
      "trial: 5, iter: 4600, curr loss: 1.2812480926513672, avg loss: 1.266623568534851\n",
      "trial: 5, iter: 4800, curr loss: 1.223398208618164, avg loss: 1.265953586101532\n",
      "trial: 5, iter: 5000, curr loss: 1.2282123565673828, avg loss: 1.2663803499937059\n",
      "trial: 5, iter: 5200, curr loss: 1.310503363609314, avg loss: 1.2714361542463302\n",
      "trial: 5, iter: 5400, curr loss: 1.2458820343017578, avg loss: 1.2700841754674912\n",
      "trial: 5, iter: 5600, curr loss: 1.2892303466796875, avg loss: 1.2664769381284713\n",
      "trial: 5, iter: 5800, curr loss: 1.2712515592575073, avg loss: 1.2656126451492309\n",
      "trial: 5, iter: 6000, curr loss: 1.256588339805603, avg loss: 1.2655125045776368\n",
      "trial: 5, iter: 6200, curr loss: 1.3154629468917847, avg loss: 1.265119366645813\n",
      "trial: 5, iter: 6400, curr loss: 1.2854021787643433, avg loss: 1.266478340625763\n",
      "trial: 5, iter: 6600, curr loss: 1.2625969648361206, avg loss: 1.2657572895288467\n",
      "trial: 5, iter: 6800, curr loss: 1.2681962251663208, avg loss: 1.2647493541240693\n",
      "trial: 5, iter: 7000, curr loss: 1.276752233505249, avg loss: 1.2645989483594895\n",
      "trial: 5, iter: 7200, curr loss: 1.2797236442565918, avg loss: 1.266045761704445\n",
      "trial: 5, iter: 7400, curr loss: 1.2654945850372314, avg loss: 1.2673429650068284\n",
      "trial: 5, iter: 7600, curr loss: 1.3265020847320557, avg loss: 1.2662012904882431\n",
      "trial: 5, iter: 7800, curr loss: 1.2750812768936157, avg loss: 1.2623923867940903\n",
      "trial: 5, iter: 8000, curr loss: 1.2678537368774414, avg loss: 1.261646145582199\n",
      "trial: 5, iter: 8200, curr loss: 1.2519177198410034, avg loss: 1.26306977391243\n",
      "trial: 5, iter: 8400, curr loss: 1.2718918323516846, avg loss: 1.2635657411813737\n",
      "trial: 5, iter: 8600, curr loss: 1.2717481851577759, avg loss: 1.268444725871086\n",
      "trial: 5, iter: 8800, curr loss: 1.2491388320922852, avg loss: 1.2653910851478576\n",
      "trial: 5, iter: 9000, curr loss: 1.3454996347427368, avg loss: 1.26481098651886\n",
      "trial: 5, iter: 9200, curr loss: 1.2294644117355347, avg loss: 1.263064040541649\n",
      "trial: 5, iter: 9400, curr loss: 1.341058373451233, avg loss: 1.2642763775587083\n",
      "trial: 5, iter: 9600, curr loss: 1.2388107776641846, avg loss: 1.2619245564937591\n",
      "trial: 5, iter: 9800, curr loss: 1.2716652154922485, avg loss: 1.2649634915590287\n",
      "trial: 5, iter: 10000, curr loss: 1.2450658082962036, avg loss: 1.2629515653848649\n",
      "trial: 5, iter: 10200, curr loss: 1.2798188924789429, avg loss: 1.266086035966873\n",
      "trial: 5, iter: 10400, curr loss: 1.221075415611267, avg loss: 1.2670786064863204\n",
      "trial: 5, iter: 10600, curr loss: 1.2602897882461548, avg loss: 1.2619652485847472\n",
      "trial: 5, iter: 10800, curr loss: 1.2814350128173828, avg loss: 1.2652638864517212\n",
      "trial: 5, iter: 11000, curr loss: 1.2483835220336914, avg loss: 1.260629546046257\n",
      "trial: 5, iter: 11200, curr loss: 1.2261749505996704, avg loss: 1.263295543193817\n",
      "trial: 5, iter: 11400, curr loss: 1.32265043258667, avg loss: 1.2621882575750352\n",
      "trial: 5, iter: 11600, curr loss: 1.2645212411880493, avg loss: 1.2654432249069214\n",
      "trial: 5, iter: 11800, curr loss: 1.3166613578796387, avg loss: 1.2634852558374405\n",
      "trial: 5, iter: 12000, curr loss: 1.2964791059494019, avg loss: 1.2632645630836488\n",
      "trial: 5, iter: 12200, curr loss: 1.296737790107727, avg loss: 1.2625456196069718\n",
      "trial: 5, iter: 12400, curr loss: 1.297315001487732, avg loss: 1.263149242401123\n",
      "trial: 5, iter: 12600, curr loss: 1.298196792602539, avg loss: 1.2620139396190644\n",
      "trial: 5, iter: 12800, curr loss: 1.2675116062164307, avg loss: 1.2629039120674133\n",
      "trial: 5, iter: 13000, curr loss: 1.2395169734954834, avg loss: 1.260749967098236\n",
      "trial: 5, iter: 13200, curr loss: 1.2539112567901611, avg loss: 1.2640398067235947\n",
      "trial: 5, iter: 13400, curr loss: 1.267142415046692, avg loss: 1.2616975158452988\n",
      "trial: 5, iter: 13600, curr loss: 1.2141501903533936, avg loss: 1.2615763038396834\n",
      "trial: 5, iter: 13800, curr loss: 1.3103632926940918, avg loss: 1.2630386924743653\n",
      "trial: 5, iter: 14000, curr loss: 1.259656310081482, avg loss: 1.2633297884464263\n",
      "trial: 5, iter: 14200, curr loss: 1.3060969114303589, avg loss: 1.2610270977020264\n",
      "trial: 5, iter: 14400, curr loss: 1.2454793453216553, avg loss: 1.2601854342222214\n",
      "trial: 5, iter: 14600, curr loss: 1.2860794067382812, avg loss: 1.2628922075033189\n",
      "trial: 5, iter: 14800, curr loss: 1.266993761062622, avg loss: 1.2605129498243333\n",
      "trial: 5, iter: 15000, curr loss: 1.2796155214309692, avg loss: 1.2610009431838989\n",
      "trial: 5, iter: 15200, curr loss: 1.275205135345459, avg loss: 1.263776638507843\n",
      "trial: 5, iter: 15400, curr loss: 1.221423864364624, avg loss: 1.2634380656480788\n",
      "trial: 5, iter: 15600, curr loss: 1.3007786273956299, avg loss: 1.2592970967292785\n",
      "trial: 5, ldr: 0.24473999440670013\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26960183680057526\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.387415885925293, avg loss: 1.3866694593429565\n",
      "trial: 1, iter: 400, curr loss: 1.3741486072540283, avg loss: 1.3813049077987671\n",
      "trial: 1, iter: 600, curr loss: 1.3495765924453735, avg loss: 1.344715144634247\n",
      "trial: 1, iter: 800, curr loss: 1.3256078958511353, avg loss: 1.3234483414888383\n",
      "trial: 1, iter: 1000, curr loss: 1.2992323637008667, avg loss: 1.3130208641290664\n",
      "trial: 1, iter: 1200, curr loss: 1.2835010290145874, avg loss: 1.3072290289402009\n",
      "trial: 1, iter: 1400, curr loss: 1.3170108795166016, avg loss: 1.3028986126184463\n",
      "trial: 1, iter: 1600, curr loss: 1.3044641017913818, avg loss: 1.2987226390838622\n",
      "trial: 1, iter: 1800, curr loss: 1.2656476497650146, avg loss: 1.2889753460884095\n",
      "trial: 1, iter: 2000, curr loss: 1.2794743776321411, avg loss: 1.284985300898552\n",
      "trial: 1, iter: 2200, curr loss: 1.277701497077942, avg loss: 1.282283684015274\n",
      "trial: 1, iter: 2400, curr loss: 1.2197610139846802, avg loss: 1.2750657618045806\n",
      "trial: 1, iter: 2600, curr loss: 1.287003517150879, avg loss: 1.2736932563781738\n",
      "trial: 1, iter: 2800, curr loss: 1.2772977352142334, avg loss: 1.27146358191967\n",
      "trial: 1, iter: 3000, curr loss: 1.292664647102356, avg loss: 1.2711936086416245\n",
      "trial: 1, iter: 3200, curr loss: 1.2714840173721313, avg loss: 1.2688495922088623\n",
      "trial: 1, iter: 3400, curr loss: 1.3069205284118652, avg loss: 1.266581357717514\n",
      "trial: 1, iter: 3600, curr loss: 1.2570774555206299, avg loss: 1.2651447319984437\n",
      "trial: 1, iter: 3800, curr loss: 1.2935596704483032, avg loss: 1.266997492313385\n",
      "trial: 1, iter: 4000, curr loss: 1.28449285030365, avg loss: 1.2659908723831177\n",
      "trial: 1, iter: 4200, curr loss: 1.229171633720398, avg loss: 1.26623292863369\n",
      "trial: 1, iter: 4400, curr loss: 1.2400368452072144, avg loss: 1.2687779080867767\n",
      "trial: 1, iter: 4600, curr loss: 1.2396631240844727, avg loss: 1.26322283744812\n",
      "trial: 1, iter: 4800, curr loss: 1.2786864042282104, avg loss: 1.268333265185356\n",
      "trial: 1, iter: 5000, curr loss: 1.3136370182037354, avg loss: 1.2621810561418534\n",
      "trial: 1, iter: 5200, curr loss: 1.2235757112503052, avg loss: 1.2591288763284683\n",
      "trial: 1, iter: 5400, curr loss: 1.2577217817306519, avg loss: 1.2644970947504044\n",
      "trial: 1, iter: 5600, curr loss: 1.2527484893798828, avg loss: 1.262656679749489\n",
      "trial: 1, iter: 5800, curr loss: 1.2825372219085693, avg loss: 1.265534179210663\n",
      "trial: 1, iter: 6000, curr loss: 1.2963241338729858, avg loss: 1.2645747035741806\n",
      "trial: 1, iter: 6200, curr loss: 1.2600771188735962, avg loss: 1.2601234990358352\n",
      "trial: 1, iter: 6400, curr loss: 1.2880327701568604, avg loss: 1.2642779761552811\n",
      "trial: 1, iter: 6600, curr loss: 1.2233964204788208, avg loss: 1.2664578551054\n",
      "trial: 1, iter: 6800, curr loss: 1.2487752437591553, avg loss: 1.2642314583063126\n",
      "trial: 1, iter: 7000, curr loss: 1.2891621589660645, avg loss: 1.2608535659313203\n",
      "trial: 1, iter: 7200, curr loss: 1.2252943515777588, avg loss: 1.2626994669437408\n",
      "trial: 1, iter: 7400, curr loss: 1.2263493537902832, avg loss: 1.2630074137449265\n",
      "trial: 1, iter: 7600, curr loss: 1.2385928630828857, avg loss: 1.2622313970327377\n",
      "trial: 1, iter: 7800, curr loss: 1.279503583908081, avg loss: 1.2616526627540587\n",
      "trial: 1, iter: 8000, curr loss: 1.223284363746643, avg loss: 1.2608246451616287\n",
      "trial: 1, iter: 8200, curr loss: 1.2301132678985596, avg loss: 1.2619930982589722\n",
      "trial: 1, iter: 8400, curr loss: 1.2782909870147705, avg loss: 1.260528461933136\n",
      "trial: 1, iter: 8600, curr loss: 1.3016718626022339, avg loss: 1.2662635576725005\n",
      "trial: 1, iter: 8800, curr loss: 1.2584718465805054, avg loss: 1.2605693769454955\n",
      "trial: 1, iter: 9000, curr loss: 1.3126039505004883, avg loss: 1.2617636770009995\n",
      "trial: 1, iter: 9200, curr loss: 1.2432125806808472, avg loss: 1.2603596472740173\n",
      "trial: 1, iter: 9400, curr loss: 1.2524491548538208, avg loss: 1.2593774491548537\n",
      "trial: 1, iter: 9600, curr loss: 1.297391653060913, avg loss: 1.2627512055635453\n",
      "trial: 1, iter: 9800, curr loss: 1.2708739042282104, avg loss: 1.2586664825677871\n",
      "trial: 1, iter: 10000, curr loss: 1.2849594354629517, avg loss: 1.2591870385408401\n",
      "trial: 1, iter: 10200, curr loss: 1.2226340770721436, avg loss: 1.2610576623678207\n",
      "trial: 1, iter: 10400, curr loss: 1.3002151250839233, avg loss: 1.2609722936153411\n",
      "trial: 1, iter: 10600, curr loss: 1.2714691162109375, avg loss: 1.2615231442451478\n",
      "trial: 1, iter: 10800, curr loss: 1.242077350616455, avg loss: 1.2582207685709\n",
      "trial: 1, iter: 11000, curr loss: 1.2321674823760986, avg loss: 1.2579909491539\n",
      "trial: 1, iter: 11200, curr loss: 1.2681065797805786, avg loss: 1.2614914643764497\n",
      "trial: 1, iter: 11400, curr loss: 1.2746957540512085, avg loss: 1.2585780853033066\n",
      "trial: 1, iter: 11600, curr loss: 1.2317668199539185, avg loss: 1.2660643702745438\n",
      "trial: 1, iter: 11800, curr loss: 1.2901039123535156, avg loss: 1.2617517304420471\n",
      "trial: 1, iter: 12000, curr loss: 1.248678207397461, avg loss: 1.2582193273305893\n",
      "trial: 1, iter: 12200, curr loss: 1.2644480466842651, avg loss: 1.2627986001968383\n",
      "trial: 1, iter: 12400, curr loss: 1.27933931350708, avg loss: 1.2595955210924148\n",
      "trial: 1, iter: 12600, curr loss: 1.2300622463226318, avg loss: 1.2634037321805953\n",
      "trial: 1, iter: 12800, curr loss: 1.2913421392440796, avg loss: 1.262764136195183\n",
      "trial: 1, iter: 13000, curr loss: 1.220995306968689, avg loss: 1.2582756441831588\n",
      "trial: 1, iter: 13200, curr loss: 1.2361127138137817, avg loss: 1.2594792991876602\n",
      "trial: 1, iter: 13400, curr loss: 1.2542258501052856, avg loss: 1.264001414179802\n",
      "trial: 1, iter: 13600, curr loss: 1.2775144577026367, avg loss: 1.2616008931398393\n",
      "trial: 1, iter: 13800, curr loss: 1.2860385179519653, avg loss: 1.2576319098472595\n",
      "trial: 1, iter: 14000, curr loss: 1.2744818925857544, avg loss: 1.2590078514814378\n",
      "trial: 1, iter: 14200, curr loss: 1.2671159505844116, avg loss: 1.2578495061397552\n",
      "trial: 1, iter: 14400, curr loss: 1.2654809951782227, avg loss: 1.2612594002485276\n",
      "trial: 1, iter: 14600, curr loss: 1.2658005952835083, avg loss: 1.2626591688394546\n",
      "trial: 1, iter: 14800, curr loss: 1.2143146991729736, avg loss: 1.2600031965970993\n",
      "trial: 1, iter: 15000, curr loss: 1.2716838121414185, avg loss: 1.2594894003868102\n",
      "trial: 1, iter: 15200, curr loss: 1.266666054725647, avg loss: 1.2596536415815354\n",
      "trial: 1, iter: 15400, curr loss: 1.2574049234390259, avg loss: 1.2610435837507248\n",
      "trial: 1, iter: 15600, curr loss: 1.27130126953125, avg loss: 1.2642822748422622\n",
      "trial: 1, ldr: 0.25759974122047424\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.382765293121338, avg loss: 1.3861781769990922\n",
      "trial: 2, iter: 400, curr loss: 1.3211944103240967, avg loss: 1.3695160007476808\n",
      "trial: 2, iter: 600, curr loss: 1.3011926412582397, avg loss: 1.3315285205841065\n",
      "trial: 2, iter: 800, curr loss: 1.3563542366027832, avg loss: 1.3180096447467804\n",
      "trial: 2, iter: 1000, curr loss: 1.308124303817749, avg loss: 1.308000939488411\n",
      "trial: 2, iter: 1200, curr loss: 1.317550778388977, avg loss: 1.3077803504467012\n",
      "trial: 2, iter: 1400, curr loss: 1.3162168264389038, avg loss: 1.3016186279058457\n",
      "trial: 2, iter: 1600, curr loss: 1.2793301343917847, avg loss: 1.2943667328357698\n",
      "trial: 2, iter: 1800, curr loss: 1.2391221523284912, avg loss: 1.2865493601560594\n",
      "trial: 2, iter: 2000, curr loss: 1.2550190687179565, avg loss: 1.28080603659153\n",
      "trial: 2, iter: 2200, curr loss: 1.291289210319519, avg loss: 1.2768699270486832\n",
      "trial: 2, iter: 2400, curr loss: 1.249691367149353, avg loss: 1.2717764604091644\n",
      "trial: 2, iter: 2600, curr loss: 1.2939633131027222, avg loss: 1.2721178936958313\n",
      "trial: 2, iter: 2800, curr loss: 1.2836116552352905, avg loss: 1.2718298935890198\n",
      "trial: 2, iter: 3000, curr loss: 1.285338044166565, avg loss: 1.2643224674463271\n",
      "trial: 2, iter: 3200, curr loss: 1.2713264226913452, avg loss: 1.2692399787902833\n",
      "trial: 2, iter: 3400, curr loss: 1.2816979885101318, avg loss: 1.2669083124399185\n",
      "trial: 2, iter: 3600, curr loss: 1.2618842124938965, avg loss: 1.269398346543312\n",
      "trial: 2, iter: 3800, curr loss: 1.2509770393371582, avg loss: 1.2635133731365205\n",
      "trial: 2, iter: 4000, curr loss: 1.2523093223571777, avg loss: 1.2658117604255676\n",
      "trial: 2, iter: 4200, curr loss: 1.292565941810608, avg loss: 1.265521261692047\n",
      "trial: 2, iter: 4400, curr loss: 1.2303003072738647, avg loss: 1.2643047642707825\n",
      "trial: 2, iter: 4600, curr loss: 1.2907686233520508, avg loss: 1.267704017162323\n",
      "trial: 2, iter: 4800, curr loss: 1.3028132915496826, avg loss: 1.2648595476150513\n",
      "trial: 2, iter: 5000, curr loss: 1.2301092147827148, avg loss: 1.2643013137578964\n",
      "trial: 2, iter: 5200, curr loss: 1.216721773147583, avg loss: 1.2651410615444183\n",
      "trial: 2, iter: 5400, curr loss: 1.2729606628417969, avg loss: 1.2617601180076599\n",
      "trial: 2, iter: 5600, curr loss: 1.285237431526184, avg loss: 1.266685764193535\n",
      "trial: 2, iter: 5800, curr loss: 1.2527209520339966, avg loss: 1.263318355679512\n",
      "trial: 2, iter: 6000, curr loss: 1.2462407350540161, avg loss: 1.2661520248651505\n",
      "trial: 2, iter: 6200, curr loss: 1.3078856468200684, avg loss: 1.2642846018075944\n",
      "trial: 2, iter: 6400, curr loss: 1.2564747333526611, avg loss: 1.2595869022607804\n",
      "trial: 2, iter: 6600, curr loss: 1.2324490547180176, avg loss: 1.262792404294014\n",
      "trial: 2, iter: 6800, curr loss: 1.2666410207748413, avg loss: 1.262986603975296\n",
      "trial: 2, iter: 7000, curr loss: 1.2571641206741333, avg loss: 1.261487867832184\n",
      "trial: 2, iter: 7200, curr loss: 1.2339146137237549, avg loss: 1.2621777933835983\n",
      "trial: 2, iter: 7400, curr loss: 1.2847639322280884, avg loss: 1.2611888456344604\n",
      "trial: 2, iter: 7600, curr loss: 1.2672560214996338, avg loss: 1.2617326247692109\n",
      "trial: 2, iter: 7800, curr loss: 1.2187138795852661, avg loss: 1.2644003021717072\n",
      "trial: 2, iter: 8000, curr loss: 1.2720048427581787, avg loss: 1.2640427911281586\n",
      "trial: 2, iter: 8200, curr loss: 1.3040695190429688, avg loss: 1.2619892954826355\n",
      "trial: 2, iter: 8400, curr loss: 1.1848891973495483, avg loss: 1.2612529957294465\n",
      "trial: 2, iter: 8600, curr loss: 1.294456124305725, avg loss: 1.2620649302005769\n",
      "trial: 2, iter: 8800, curr loss: 1.2423675060272217, avg loss: 1.266494745016098\n",
      "trial: 2, iter: 9000, curr loss: 1.2868186235427856, avg loss: 1.2622904700040818\n",
      "trial: 2, iter: 9200, curr loss: 1.2357873916625977, avg loss: 1.2594705539941788\n",
      "trial: 2, iter: 9400, curr loss: 1.2456696033477783, avg loss: 1.263538248538971\n",
      "trial: 2, iter: 9600, curr loss: 1.2651927471160889, avg loss: 1.2593683117628098\n",
      "trial: 2, iter: 9800, curr loss: 1.2678335905075073, avg loss: 1.2624256080389022\n",
      "trial: 2, iter: 10000, curr loss: 1.305030345916748, avg loss: 1.261970796585083\n",
      "trial: 2, iter: 10200, curr loss: 1.2191299200057983, avg loss: 1.2618465578556062\n",
      "trial: 2, iter: 10400, curr loss: 1.276646375656128, avg loss: 1.2642160004377365\n",
      "trial: 2, iter: 10600, curr loss: 1.2477575540542603, avg loss: 1.2615628224611282\n",
      "trial: 2, iter: 10800, curr loss: 1.270340085029602, avg loss: 1.2617747920751572\n",
      "trial: 2, iter: 11000, curr loss: 1.2511056661605835, avg loss: 1.26234718978405\n",
      "trial: 2, iter: 11200, curr loss: 1.2656617164611816, avg loss: 1.2626268750429153\n",
      "trial: 2, iter: 11400, curr loss: 1.2742164134979248, avg loss: 1.2586499071121215\n",
      "trial: 2, iter: 11600, curr loss: 1.2999637126922607, avg loss: 1.2619545686244964\n",
      "trial: 2, iter: 11800, curr loss: 1.2773640155792236, avg loss: 1.258305172920227\n",
      "trial: 2, iter: 12000, curr loss: 1.2571812868118286, avg loss: 1.2611538898944854\n",
      "trial: 2, iter: 12200, curr loss: 1.2592674493789673, avg loss: 1.261357191801071\n",
      "trial: 2, iter: 12400, curr loss: 1.2793996334075928, avg loss: 1.2636164993047714\n",
      "trial: 2, iter: 12600, curr loss: 1.2286731004714966, avg loss: 1.2589956659078598\n",
      "trial: 2, iter: 12800, curr loss: 1.3090393543243408, avg loss: 1.2577348297834396\n",
      "trial: 2, iter: 13000, curr loss: 1.2831206321716309, avg loss: 1.2613260352611542\n",
      "trial: 2, iter: 13200, curr loss: 1.2986936569213867, avg loss: 1.2593788141012192\n",
      "trial: 2, iter: 13400, curr loss: 1.2752516269683838, avg loss: 1.258249095082283\n",
      "trial: 2, iter: 13600, curr loss: 1.2673379182815552, avg loss: 1.25785185277462\n",
      "trial: 2, iter: 13800, curr loss: 1.2482376098632812, avg loss: 1.2600957494974137\n",
      "trial: 2, iter: 14000, curr loss: 1.2653788328170776, avg loss: 1.259152820110321\n",
      "trial: 2, iter: 14200, curr loss: 1.2826474905014038, avg loss: 1.2622316801548004\n",
      "trial: 2, iter: 14400, curr loss: 1.2663288116455078, avg loss: 1.2597293400764464\n",
      "trial: 2, iter: 14600, curr loss: 1.2330535650253296, avg loss: 1.2595639950037003\n",
      "trial: 2, iter: 14800, curr loss: 1.3102061748504639, avg loss: 1.2622411388158798\n",
      "trial: 2, iter: 15000, curr loss: 1.2384543418884277, avg loss: 1.2574246472120285\n",
      "trial: 2, iter: 15200, curr loss: 1.25344717502594, avg loss: 1.2620563769340516\n",
      "trial: 2, iter: 15400, curr loss: 1.259430170059204, avg loss: 1.2612260955572128\n",
      "trial: 2, iter: 15600, curr loss: 1.251190185546875, avg loss: 1.2606775552034377\n",
      "trial: 2, ldr: 0.2695051431655884\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3861749172210693, avg loss: 1.3868777829408645\n",
      "trial: 3, iter: 400, curr loss: 1.3741116523742676, avg loss: 1.381687087416649\n",
      "trial: 3, iter: 600, curr loss: 1.3154163360595703, avg loss: 1.3422430282831193\n",
      "trial: 3, iter: 800, curr loss: 1.3220616579055786, avg loss: 1.317247530221939\n",
      "trial: 3, iter: 1000, curr loss: 1.3262183666229248, avg loss: 1.30969697535038\n",
      "trial: 3, iter: 1200, curr loss: 1.343351125717163, avg loss: 1.3081741809844971\n",
      "trial: 3, iter: 1400, curr loss: 1.2975404262542725, avg loss: 1.3024773281812667\n",
      "trial: 3, iter: 1600, curr loss: 1.3085263967514038, avg loss: 1.2975436103343965\n",
      "trial: 3, iter: 1800, curr loss: 1.2847477197647095, avg loss: 1.2916368848085404\n",
      "trial: 3, iter: 2000, curr loss: 1.2671102285385132, avg loss: 1.2871697860956193\n",
      "trial: 3, iter: 2200, curr loss: 1.2727370262145996, avg loss: 1.280662963986397\n",
      "trial: 3, iter: 2400, curr loss: 1.2789421081542969, avg loss: 1.276431970000267\n",
      "trial: 3, iter: 2600, curr loss: 1.2613754272460938, avg loss: 1.272530757188797\n",
      "trial: 3, iter: 2800, curr loss: 1.2490967512130737, avg loss: 1.2687090665102005\n",
      "trial: 3, iter: 3000, curr loss: 1.278447151184082, avg loss: 1.270136107802391\n",
      "trial: 3, iter: 3200, curr loss: 1.2595446109771729, avg loss: 1.2692116516828538\n",
      "trial: 3, iter: 3400, curr loss: 1.2413586378097534, avg loss: 1.2675786638259887\n",
      "trial: 3, iter: 3600, curr loss: 1.2873787879943848, avg loss: 1.2662591642141343\n",
      "trial: 3, iter: 3800, curr loss: 1.2683656215667725, avg loss: 1.2685951507091522\n",
      "trial: 3, iter: 4000, curr loss: 1.3041051626205444, avg loss: 1.2636610490083695\n",
      "trial: 3, iter: 4200, curr loss: 1.247950553894043, avg loss: 1.265473303794861\n",
      "trial: 3, iter: 4400, curr loss: 1.2120059728622437, avg loss: 1.2631410825252534\n",
      "trial: 3, iter: 4600, curr loss: 1.2367960214614868, avg loss: 1.2659516000747681\n",
      "trial: 3, iter: 4800, curr loss: 1.239060401916504, avg loss: 1.2665748727321624\n",
      "trial: 3, iter: 5000, curr loss: 1.2907572984695435, avg loss: 1.2646139174699784\n",
      "trial: 3, iter: 5200, curr loss: 1.3187611103057861, avg loss: 1.2642389929294586\n",
      "trial: 3, iter: 5400, curr loss: 1.2765753269195557, avg loss: 1.2632326018810272\n",
      "trial: 3, iter: 5600, curr loss: 1.2509242296218872, avg loss: 1.2664652156829834\n",
      "trial: 3, iter: 5800, curr loss: 1.2597228288650513, avg loss: 1.2645138812065124\n",
      "trial: 3, iter: 6000, curr loss: 1.2440171241760254, avg loss: 1.261440115571022\n",
      "trial: 3, iter: 6200, curr loss: 1.2673587799072266, avg loss: 1.2635497331619263\n",
      "trial: 3, iter: 6400, curr loss: 1.2806826829910278, avg loss: 1.264732196331024\n",
      "trial: 3, iter: 6600, curr loss: 1.248686671257019, avg loss: 1.2622735732793808\n",
      "trial: 3, iter: 6800, curr loss: 1.2830333709716797, avg loss: 1.2656678265333177\n",
      "trial: 3, iter: 7000, curr loss: 1.2384228706359863, avg loss: 1.261268234848976\n",
      "trial: 3, iter: 7200, curr loss: 1.251274585723877, avg loss: 1.2626263058185578\n",
      "trial: 3, iter: 7400, curr loss: 1.274109125137329, avg loss: 1.2615883880853653\n",
      "trial: 3, iter: 7600, curr loss: 1.2787362337112427, avg loss: 1.2618812674283981\n",
      "trial: 3, iter: 7800, curr loss: 1.269911766052246, avg loss: 1.264074222445488\n",
      "trial: 3, iter: 8000, curr loss: 1.2457395792007446, avg loss: 1.2670987689495086\n",
      "trial: 3, iter: 8200, curr loss: 1.2777602672576904, avg loss: 1.259496877193451\n",
      "trial: 3, iter: 8400, curr loss: 1.2983145713806152, avg loss: 1.2621250003576279\n",
      "trial: 3, iter: 8600, curr loss: 1.2581020593643188, avg loss: 1.2626683527231217\n",
      "trial: 3, iter: 8800, curr loss: 1.2402700185775757, avg loss: 1.2618247586488724\n",
      "trial: 3, iter: 9000, curr loss: 1.2760075330734253, avg loss: 1.264247152209282\n",
      "trial: 3, iter: 9200, curr loss: 1.2545942068099976, avg loss: 1.2590665417909621\n",
      "trial: 3, iter: 9400, curr loss: 1.2487692832946777, avg loss: 1.2632203924655914\n",
      "trial: 3, iter: 9600, curr loss: 1.2494914531707764, avg loss: 1.2600282061100005\n",
      "trial: 3, iter: 9800, curr loss: 1.2276703119277954, avg loss: 1.259576200246811\n",
      "trial: 3, iter: 10000, curr loss: 1.2317862510681152, avg loss: 1.2616777235269547\n",
      "trial: 3, iter: 10200, curr loss: 1.28531813621521, avg loss: 1.2643475079536437\n",
      "trial: 3, iter: 10400, curr loss: 1.2619582414627075, avg loss: 1.261421378850937\n",
      "trial: 3, iter: 10600, curr loss: 1.2893701791763306, avg loss: 1.2610484039783478\n",
      "trial: 3, iter: 10800, curr loss: 1.267523169517517, avg loss: 1.2644045996665954\n",
      "trial: 3, iter: 11000, curr loss: 1.2781656980514526, avg loss: 1.2589365857839585\n",
      "trial: 3, iter: 11200, curr loss: 1.3097139596939087, avg loss: 1.2600245887041093\n",
      "trial: 3, iter: 11400, curr loss: 1.205369234085083, avg loss: 1.2595722258090973\n",
      "trial: 3, iter: 11600, curr loss: 1.2650222778320312, avg loss: 1.2618590235710143\n",
      "trial: 3, iter: 11800, curr loss: 1.2218899726867676, avg loss: 1.2634463095664978\n",
      "trial: 3, iter: 12000, curr loss: 1.276397705078125, avg loss: 1.2562688541412355\n",
      "trial: 3, iter: 12200, curr loss: 1.297569751739502, avg loss: 1.264745872616768\n",
      "trial: 3, iter: 12400, curr loss: 1.2557638883590698, avg loss: 1.2623199570178985\n",
      "trial: 3, iter: 12600, curr loss: 1.2555657625198364, avg loss: 1.25999587059021\n",
      "trial: 3, iter: 12800, curr loss: 1.2623718976974487, avg loss: 1.2595263618230819\n",
      "trial: 3, iter: 13000, curr loss: 1.2515804767608643, avg loss: 1.2608204728364945\n",
      "trial: 3, iter: 13200, curr loss: 1.2348625659942627, avg loss: 1.2603403931856156\n",
      "trial: 3, iter: 13400, curr loss: 1.2675942182540894, avg loss: 1.2591255050897598\n",
      "trial: 3, iter: 13600, curr loss: 1.2757229804992676, avg loss: 1.2602276033163071\n",
      "trial: 3, iter: 13800, curr loss: 1.2924838066101074, avg loss: 1.2592310398817061\n",
      "trial: 3, iter: 14000, curr loss: 1.2572135925292969, avg loss: 1.2602535462379456\n",
      "trial: 3, iter: 14200, curr loss: 1.264692783355713, avg loss: 1.2600277227163315\n",
      "trial: 3, iter: 14400, curr loss: 1.2594482898712158, avg loss: 1.2601398402452468\n",
      "trial: 3, iter: 14600, curr loss: 1.2913312911987305, avg loss: 1.2633047556877137\n",
      "trial: 3, iter: 14800, curr loss: 1.236089825630188, avg loss: 1.2624448126554488\n",
      "trial: 3, iter: 15000, curr loss: 1.2844910621643066, avg loss: 1.2612876999378204\n",
      "trial: 3, iter: 15200, curr loss: 1.285231351852417, avg loss: 1.2613957107067109\n",
      "trial: 3, iter: 15400, curr loss: 1.3103997707366943, avg loss: 1.2605207389593125\n",
      "trial: 3, iter: 15600, curr loss: 1.276125192642212, avg loss: 1.2640319967269897\n",
      "trial: 3, ldr: 0.265747606754303\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.384765625, avg loss: 1.3869870364665986\n",
      "trial: 4, iter: 400, curr loss: 1.3805487155914307, avg loss: 1.384832620024681\n",
      "trial: 4, iter: 600, curr loss: 1.3205504417419434, avg loss: 1.3641342449188232\n",
      "trial: 4, iter: 800, curr loss: 1.3235608339309692, avg loss: 1.3286990410089492\n",
      "trial: 4, iter: 1000, curr loss: 1.3307209014892578, avg loss: 1.3167032533884049\n",
      "trial: 4, iter: 1200, curr loss: 1.3005424737930298, avg loss: 1.3105207353830337\n",
      "trial: 4, iter: 1400, curr loss: 1.2736248970031738, avg loss: 1.306076111793518\n",
      "trial: 4, iter: 1600, curr loss: 1.3206907510757446, avg loss: 1.3013756471872329\n",
      "trial: 4, iter: 1800, curr loss: 1.3007829189300537, avg loss: 1.2957619565725327\n",
      "trial: 4, iter: 2000, curr loss: 1.3053444623947144, avg loss: 1.2908545327186585\n",
      "trial: 4, iter: 2200, curr loss: 1.3091405630111694, avg loss: 1.2831355446577073\n",
      "trial: 4, iter: 2400, curr loss: 1.2827692031860352, avg loss: 1.27510966360569\n",
      "trial: 4, iter: 2600, curr loss: 1.272336721420288, avg loss: 1.2759224110841751\n",
      "trial: 4, iter: 2800, curr loss: 1.2804508209228516, avg loss: 1.2740515112876891\n",
      "trial: 4, iter: 3000, curr loss: 1.263727068901062, avg loss: 1.2705424624681472\n",
      "trial: 4, iter: 3200, curr loss: 1.24593186378479, avg loss: 1.2700350201129913\n",
      "trial: 4, iter: 3400, curr loss: 1.280355453491211, avg loss: 1.270436316728592\n",
      "trial: 4, iter: 3600, curr loss: 1.2705249786376953, avg loss: 1.267221333384514\n",
      "trial: 4, iter: 3800, curr loss: 1.2869986295700073, avg loss: 1.2678965175151824\n",
      "trial: 4, iter: 4000, curr loss: 1.2580783367156982, avg loss: 1.2655111253261566\n",
      "trial: 4, iter: 4200, curr loss: 1.279536247253418, avg loss: 1.270108396410942\n",
      "trial: 4, iter: 4400, curr loss: 1.247067928314209, avg loss: 1.2639120876789094\n",
      "trial: 4, iter: 4600, curr loss: 1.2535954713821411, avg loss: 1.2678865200281144\n",
      "trial: 4, iter: 4800, curr loss: 1.2911372184753418, avg loss: 1.2650738030672073\n",
      "trial: 4, iter: 5000, curr loss: 1.2760131359100342, avg loss: 1.2662396520376205\n",
      "trial: 4, iter: 5200, curr loss: 1.2601808309555054, avg loss: 1.2622287774085998\n",
      "trial: 4, iter: 5400, curr loss: 1.2458933591842651, avg loss: 1.2648710244894028\n",
      "trial: 4, iter: 5600, curr loss: 1.216742992401123, avg loss: 1.264934088587761\n",
      "trial: 4, iter: 5800, curr loss: 1.2871413230895996, avg loss: 1.266403369307518\n",
      "trial: 4, iter: 6000, curr loss: 1.2451835870742798, avg loss: 1.2623979449272156\n",
      "trial: 4, iter: 6200, curr loss: 1.2005565166473389, avg loss: 1.2629641503095628\n",
      "trial: 4, iter: 6400, curr loss: 1.269482135772705, avg loss: 1.2636715519428252\n",
      "trial: 4, iter: 6600, curr loss: 1.2562793493270874, avg loss: 1.263328154683113\n",
      "trial: 4, iter: 6800, curr loss: 1.2696939706802368, avg loss: 1.2631285881996155\n",
      "trial: 4, iter: 7000, curr loss: 1.1865134239196777, avg loss: 1.262968447804451\n",
      "trial: 4, iter: 7200, curr loss: 1.2588011026382446, avg loss: 1.2602131456136703\n",
      "trial: 4, iter: 7400, curr loss: 1.2750608921051025, avg loss: 1.2634214740991592\n",
      "trial: 4, iter: 7600, curr loss: 1.240358591079712, avg loss: 1.264766018986702\n",
      "trial: 4, iter: 7800, curr loss: 1.27495276927948, avg loss: 1.2627026385068894\n",
      "trial: 4, iter: 8000, curr loss: 1.2403779029846191, avg loss: 1.2612074410915375\n",
      "trial: 4, iter: 8200, curr loss: 1.33846116065979, avg loss: 1.265432049036026\n",
      "trial: 4, iter: 8400, curr loss: 1.2163341045379639, avg loss: 1.2625833290815354\n",
      "trial: 4, iter: 8600, curr loss: 1.2619191408157349, avg loss: 1.2598066169023514\n",
      "trial: 4, iter: 8800, curr loss: 1.2893390655517578, avg loss: 1.264481271505356\n",
      "trial: 4, iter: 9000, curr loss: 1.3143762350082397, avg loss: 1.262095957994461\n",
      "trial: 4, iter: 9200, curr loss: 1.2483749389648438, avg loss: 1.2639731699228287\n",
      "trial: 4, iter: 9400, curr loss: 1.20707106590271, avg loss: 1.2617409121990204\n",
      "trial: 4, iter: 9600, curr loss: 1.2757869958877563, avg loss: 1.2621750390529634\n",
      "trial: 4, iter: 9800, curr loss: 1.2900958061218262, avg loss: 1.2625263285636903\n",
      "trial: 4, iter: 10000, curr loss: 1.2692184448242188, avg loss: 1.264543816447258\n",
      "trial: 4, iter: 10200, curr loss: 1.2545982599258423, avg loss: 1.261586121916771\n",
      "trial: 4, iter: 10400, curr loss: 1.2193408012390137, avg loss: 1.2617555552721023\n",
      "trial: 4, iter: 10600, curr loss: 1.2124700546264648, avg loss: 1.2597451728582383\n",
      "trial: 4, iter: 10800, curr loss: 1.2922250032424927, avg loss: 1.2640515232086182\n",
      "trial: 4, iter: 11000, curr loss: 1.2774240970611572, avg loss: 1.2596772140264512\n",
      "trial: 4, iter: 11200, curr loss: 1.2340255975723267, avg loss: 1.2600638717412949\n",
      "trial: 4, iter: 11400, curr loss: 1.2558612823486328, avg loss: 1.2611314898729324\n",
      "trial: 4, iter: 11600, curr loss: 1.2167659997940063, avg loss: 1.2593901246786117\n",
      "trial: 4, iter: 11800, curr loss: 1.3072937726974487, avg loss: 1.2613138395547867\n",
      "trial: 4, iter: 12000, curr loss: 1.311911940574646, avg loss: 1.267991499900818\n",
      "trial: 4, iter: 12200, curr loss: 1.2995398044586182, avg loss: 1.2600516110658646\n",
      "trial: 4, iter: 12400, curr loss: 1.2884669303894043, avg loss: 1.2585988956689835\n",
      "trial: 4, iter: 12600, curr loss: 1.2336232662200928, avg loss: 1.261755907535553\n",
      "trial: 4, iter: 12800, curr loss: 1.2934577465057373, avg loss: 1.2629861688613893\n",
      "trial: 4, iter: 13000, curr loss: 1.278958797454834, avg loss: 1.2632653975486756\n",
      "trial: 4, iter: 13200, curr loss: 1.230757713317871, avg loss: 1.2603753048181534\n",
      "trial: 4, iter: 13400, curr loss: 1.2650904655456543, avg loss: 1.2590194624662399\n",
      "trial: 4, iter: 13600, curr loss: 1.247495174407959, avg loss: 1.2595662301778794\n",
      "trial: 4, iter: 13800, curr loss: 1.216727614402771, avg loss: 1.2611428087949752\n",
      "trial: 4, iter: 14000, curr loss: 1.230406641960144, avg loss: 1.2640434539318084\n",
      "trial: 4, iter: 14200, curr loss: 1.214052677154541, avg loss: 1.2588052189350127\n",
      "trial: 4, iter: 14400, curr loss: 1.2262316942214966, avg loss: 1.2604054301977157\n",
      "trial: 4, iter: 14600, curr loss: 1.2667169570922852, avg loss: 1.2602040827274323\n",
      "trial: 4, iter: 14800, curr loss: 1.2672197818756104, avg loss: 1.2584541130065918\n",
      "trial: 4, iter: 15000, curr loss: 1.2639145851135254, avg loss: 1.2595101547241212\n",
      "trial: 4, iter: 15200, curr loss: 1.241292953491211, avg loss: 1.2595421195030212\n",
      "trial: 4, iter: 15400, curr loss: 1.2730284929275513, avg loss: 1.2600685852766036\n",
      "trial: 4, iter: 15600, curr loss: 1.2833876609802246, avg loss: 1.2590741157531737\n",
      "trial: 4, ldr: 0.2984423339366913\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3870713710784912, avg loss: 1.3867030042409896\n",
      "trial: 5, iter: 400, curr loss: 1.3657104969024658, avg loss: 1.3819063436985015\n",
      "trial: 5, iter: 600, curr loss: 1.3131378889083862, avg loss: 1.3492268681526185\n",
      "trial: 5, iter: 800, curr loss: 1.3460134267807007, avg loss: 1.3252292597293853\n",
      "trial: 5, iter: 1000, curr loss: 1.3805625438690186, avg loss: 1.3157676231861115\n",
      "trial: 5, iter: 1200, curr loss: 1.2920191287994385, avg loss: 1.3135775917768477\n",
      "trial: 5, iter: 1400, curr loss: 1.3144879341125488, avg loss: 1.3061052966117859\n",
      "trial: 5, iter: 1600, curr loss: 1.2940794229507446, avg loss: 1.3015617388486862\n",
      "trial: 5, iter: 1800, curr loss: 1.2879290580749512, avg loss: 1.294706580042839\n",
      "trial: 5, iter: 2000, curr loss: 1.2724426984786987, avg loss: 1.2880041205883026\n",
      "trial: 5, iter: 2200, curr loss: 1.2852720022201538, avg loss: 1.283038728237152\n",
      "trial: 5, iter: 2400, curr loss: 1.2487661838531494, avg loss: 1.2789764088392257\n",
      "trial: 5, iter: 2600, curr loss: 1.2543576955795288, avg loss: 1.2742333590984345\n",
      "trial: 5, iter: 2800, curr loss: 1.2860609292984009, avg loss: 1.2737518471479417\n",
      "trial: 5, iter: 3000, curr loss: 1.2627239227294922, avg loss: 1.2684387093782425\n",
      "trial: 5, iter: 3200, curr loss: 1.234496831893921, avg loss: 1.2687605017423629\n",
      "trial: 5, iter: 3400, curr loss: 1.2776334285736084, avg loss: 1.2704280596971511\n",
      "trial: 5, iter: 3600, curr loss: 1.2802391052246094, avg loss: 1.2671028584241868\n",
      "trial: 5, iter: 3800, curr loss: 1.2647278308868408, avg loss: 1.2643789899349214\n",
      "trial: 5, iter: 4000, curr loss: 1.271152138710022, avg loss: 1.26717227935791\n",
      "trial: 5, iter: 4200, curr loss: 1.2777844667434692, avg loss: 1.2664537155628204\n",
      "trial: 5, iter: 4400, curr loss: 1.2648036479949951, avg loss: 1.2681049543619156\n",
      "trial: 5, iter: 4600, curr loss: 1.2482119798660278, avg loss: 1.2664032167196273\n",
      "trial: 5, iter: 4800, curr loss: 1.2482733726501465, avg loss: 1.266532483100891\n",
      "trial: 5, iter: 5000, curr loss: 1.3269364833831787, avg loss: 1.2642604774236679\n",
      "trial: 5, iter: 5200, curr loss: 1.2615150213241577, avg loss: 1.265439584851265\n",
      "trial: 5, iter: 5400, curr loss: 1.264012098312378, avg loss: 1.263519446849823\n",
      "trial: 5, iter: 5600, curr loss: 1.2924355268478394, avg loss: 1.2638668024539947\n",
      "trial: 5, iter: 5800, curr loss: 1.2080203294754028, avg loss: 1.260490835905075\n",
      "trial: 5, iter: 6000, curr loss: 1.2667007446289062, avg loss: 1.2649712824821473\n",
      "trial: 5, iter: 6200, curr loss: 1.284252643585205, avg loss: 1.2629196697473526\n",
      "trial: 5, iter: 6400, curr loss: 1.2688511610031128, avg loss: 1.26158425450325\n",
      "trial: 5, iter: 6600, curr loss: 1.272834300994873, avg loss: 1.2642489886283874\n",
      "trial: 5, iter: 6800, curr loss: 1.2444032430648804, avg loss: 1.2643045192956925\n",
      "trial: 5, iter: 7000, curr loss: 1.2501089572906494, avg loss: 1.2624278408288956\n",
      "trial: 5, iter: 7200, curr loss: 1.2870194911956787, avg loss: 1.2623769211769105\n",
      "trial: 5, iter: 7400, curr loss: 1.2567638158798218, avg loss: 1.2610326915979386\n",
      "trial: 5, iter: 7600, curr loss: 1.2920966148376465, avg loss: 1.2644195741415023\n",
      "trial: 5, iter: 7800, curr loss: 1.2863190174102783, avg loss: 1.2667801934480667\n",
      "trial: 5, iter: 8000, curr loss: 1.2766079902648926, avg loss: 1.26400462269783\n",
      "trial: 5, iter: 8200, curr loss: 1.2966967821121216, avg loss: 1.2623144763708114\n",
      "trial: 5, iter: 8400, curr loss: 1.2895303964614868, avg loss: 1.2628800988197326\n",
      "trial: 5, iter: 8600, curr loss: 1.270336627960205, avg loss: 1.2635068857669831\n",
      "trial: 5, iter: 8800, curr loss: 1.2756154537200928, avg loss: 1.2638325595855713\n",
      "trial: 5, iter: 9000, curr loss: 1.2456862926483154, avg loss: 1.258867685198784\n",
      "trial: 5, iter: 9200, curr loss: 1.2447067499160767, avg loss: 1.2593655955791474\n",
      "trial: 5, iter: 9400, curr loss: 1.2605619430541992, avg loss: 1.2598541963100434\n",
      "trial: 5, iter: 9600, curr loss: 1.2771071195602417, avg loss: 1.261131088733673\n",
      "trial: 5, iter: 9800, curr loss: 1.234006643295288, avg loss: 1.258973452448845\n",
      "trial: 5, iter: 10000, curr loss: 1.2700642347335815, avg loss: 1.2658322554826738\n",
      "trial: 5, iter: 10200, curr loss: 1.2279767990112305, avg loss: 1.2623090785741806\n",
      "trial: 5, iter: 10400, curr loss: 1.2506674528121948, avg loss: 1.2616838866472244\n",
      "trial: 5, iter: 10600, curr loss: 1.2660719156265259, avg loss: 1.260945296883583\n",
      "trial: 5, iter: 10800, curr loss: 1.262206792831421, avg loss: 1.2574351799488068\n",
      "trial: 5, iter: 11000, curr loss: 1.1971622705459595, avg loss: 1.264390702843666\n",
      "trial: 5, iter: 11200, curr loss: 1.2295032739639282, avg loss: 1.259668778181076\n",
      "trial: 5, iter: 11400, curr loss: 1.2922013998031616, avg loss: 1.260856682062149\n",
      "trial: 5, iter: 11600, curr loss: 1.2321821451187134, avg loss: 1.261708035469055\n",
      "trial: 5, iter: 11800, curr loss: 1.2454665899276733, avg loss: 1.2596203941106796\n",
      "trial: 5, iter: 12000, curr loss: 1.2399725914001465, avg loss: 1.261943843960762\n",
      "trial: 5, iter: 12200, curr loss: 1.282586932182312, avg loss: 1.2634671527147292\n",
      "trial: 5, iter: 12400, curr loss: 1.2658839225769043, avg loss: 1.2598979300260544\n",
      "trial: 5, iter: 12600, curr loss: 1.278394103050232, avg loss: 1.2620266902446746\n",
      "trial: 5, iter: 12800, curr loss: 1.2444555759429932, avg loss: 1.2608663052320481\n",
      "trial: 5, iter: 13000, curr loss: 1.224371314048767, avg loss: 1.2612866485118865\n",
      "trial: 5, iter: 13200, curr loss: 1.3099172115325928, avg loss: 1.2616581094264985\n",
      "trial: 5, iter: 13400, curr loss: 1.2496470212936401, avg loss: 1.2582551193237306\n",
      "trial: 5, iter: 13600, curr loss: 1.2402251958847046, avg loss: 1.2600722062587737\n",
      "trial: 5, iter: 13800, curr loss: 1.257216215133667, avg loss: 1.2614863854646683\n",
      "trial: 5, iter: 14000, curr loss: 1.2290018796920776, avg loss: 1.259228475689888\n",
      "trial: 5, iter: 14200, curr loss: 1.226412057876587, avg loss: 1.259991369843483\n",
      "trial: 5, iter: 14400, curr loss: 1.271338701248169, avg loss: 1.2589812707901\n",
      "trial: 5, iter: 14600, curr loss: 1.252676248550415, avg loss: 1.2628988939523698\n",
      "trial: 5, iter: 14800, curr loss: 1.2384381294250488, avg loss: 1.2614711958169937\n",
      "trial: 5, iter: 15000, curr loss: 1.2112891674041748, avg loss: 1.2593813288211821\n",
      "trial: 5, iter: 15200, curr loss: 1.235824704170227, avg loss: 1.2627253305912018\n",
      "trial: 5, iter: 15400, curr loss: 1.2945778369903564, avg loss: 1.258153185248375\n",
      "trial: 5, iter: 15600, curr loss: 1.2519632577896118, avg loss: 1.2612641245126723\n",
      "trial: 5, ldr: 0.22336171567440033\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2629313081502914\n",
      "Experiment done with data path: ./data/catNon-lin-NI_4/data.50k.dz10.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_11/data.20k.dz50.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3884226083755493, avg loss: 1.3874185901880265\n",
      "trial: 1, iter: 400, curr loss: 1.386447548866272, avg loss: 1.3866448837518692\n",
      "trial: 1, iter: 600, curr loss: 1.3864521980285645, avg loss: 1.3866197121143342\n",
      "trial: 1, iter: 800, curr loss: 1.3816107511520386, avg loss: 1.3858377599716187\n",
      "trial: 1, iter: 1000, curr loss: 1.3782809972763062, avg loss: 1.3801572293043136\n",
      "trial: 1, iter: 1200, curr loss: 1.3700180053710938, avg loss: 1.370151281952858\n",
      "trial: 1, iter: 1400, curr loss: 1.3506253957748413, avg loss: 1.3672774237394334\n",
      "trial: 1, iter: 1600, curr loss: 1.3778668642044067, avg loss: 1.3620631206035614\n",
      "trial: 1, iter: 1800, curr loss: 1.359421730041504, avg loss: 1.3565255171060562\n",
      "trial: 1, iter: 2000, curr loss: 1.3516168594360352, avg loss: 1.3517646032571793\n",
      "trial: 1, iter: 2200, curr loss: 1.3792728185653687, avg loss: 1.3455617368221282\n",
      "trial: 1, iter: 2400, curr loss: 1.3478059768676758, avg loss: 1.3379808634519577\n",
      "trial: 1, iter: 2600, curr loss: 1.3227304220199585, avg loss: 1.3338739281892777\n",
      "trial: 1, iter: 2800, curr loss: 1.3204960823059082, avg loss: 1.3308510267734528\n",
      "trial: 1, iter: 3000, curr loss: 1.3349825143814087, avg loss: 1.32721730530262\n",
      "trial: 1, iter: 3200, curr loss: 1.3193875551223755, avg loss: 1.3227383685112\n",
      "trial: 1, iter: 3400, curr loss: 1.3351624011993408, avg loss: 1.3193162971735\n",
      "trial: 1, iter: 3600, curr loss: 1.337170124053955, avg loss: 1.3168222361803055\n",
      "trial: 1, iter: 3800, curr loss: 1.3149058818817139, avg loss: 1.3177969592809677\n",
      "trial: 1, iter: 4000, curr loss: 1.3007328510284424, avg loss: 1.3108961153030396\n",
      "trial: 1, iter: 4200, curr loss: 1.3127506971359253, avg loss: 1.3125745528936386\n",
      "trial: 1, iter: 4400, curr loss: 1.2953287363052368, avg loss: 1.3082379537820816\n",
      "trial: 1, iter: 4600, curr loss: 1.3096427917480469, avg loss: 1.3094515734910965\n",
      "trial: 1, iter: 4800, curr loss: 1.3706090450286865, avg loss: 1.3072703862190247\n",
      "trial: 1, iter: 5000, curr loss: 1.3149161338806152, avg loss: 1.3061727458238601\n",
      "trial: 1, iter: 5200, curr loss: 1.2801949977874756, avg loss: 1.3075838083028792\n",
      "trial: 1, iter: 5400, curr loss: 1.3017194271087646, avg loss: 1.3051241260766984\n",
      "trial: 1, iter: 5600, curr loss: 1.304294228553772, avg loss: 1.3038234341144561\n",
      "trial: 1, iter: 5800, curr loss: 1.2591255903244019, avg loss: 1.3062479478120803\n",
      "trial: 1, iter: 6000, curr loss: 1.2988133430480957, avg loss: 1.301606610417366\n",
      "trial: 1, iter: 6200, curr loss: 1.2806644439697266, avg loss: 1.298640883564949\n",
      "trial: 1, ldr: 0.3017456531524658\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3900772333145142, avg loss: 1.3876893562078476\n",
      "trial: 2, iter: 400, curr loss: 1.3856866359710693, avg loss: 1.3866891157627106\n",
      "trial: 2, iter: 600, curr loss: 1.3845767974853516, avg loss: 1.3860564011335372\n",
      "trial: 2, iter: 800, curr loss: 1.3814340829849243, avg loss: 1.3847822338342666\n",
      "trial: 2, iter: 1000, curr loss: 1.3678638935089111, avg loss: 1.3757280725240708\n",
      "trial: 2, iter: 1200, curr loss: 1.3548814058303833, avg loss: 1.3694825184345245\n",
      "trial: 2, iter: 1400, curr loss: 1.360282063484192, avg loss: 1.3640093755722047\n",
      "trial: 2, iter: 1600, curr loss: 1.3643158674240112, avg loss: 1.36247325360775\n",
      "trial: 2, iter: 1800, curr loss: 1.3618738651275635, avg loss: 1.3598795866966247\n",
      "trial: 2, iter: 2000, curr loss: 1.3795169591903687, avg loss: 1.3550331860780715\n",
      "trial: 2, iter: 2200, curr loss: 1.3525677919387817, avg loss: 1.347669032216072\n",
      "trial: 2, iter: 2400, curr loss: 1.3456209897994995, avg loss: 1.341289125084877\n",
      "trial: 2, iter: 2600, curr loss: 1.337249517440796, avg loss: 1.3368427377939225\n",
      "trial: 2, iter: 2800, curr loss: 1.2975473403930664, avg loss: 1.3274306958913804\n",
      "trial: 2, iter: 3000, curr loss: 1.2998567819595337, avg loss: 1.3261581397056579\n",
      "trial: 2, iter: 3200, curr loss: 1.339139461517334, avg loss: 1.323681663274765\n",
      "trial: 2, iter: 3400, curr loss: 1.3294259309768677, avg loss: 1.320218677520752\n",
      "trial: 2, iter: 3600, curr loss: 1.3229856491088867, avg loss: 1.3172476726770401\n",
      "trial: 2, iter: 3800, curr loss: 1.299061894416809, avg loss: 1.316348633170128\n",
      "trial: 2, iter: 4000, curr loss: 1.306782841682434, avg loss: 1.3175037372112275\n",
      "trial: 2, iter: 4200, curr loss: 1.3331406116485596, avg loss: 1.311389871239662\n",
      "trial: 2, iter: 4400, curr loss: 1.2662110328674316, avg loss: 1.310487961769104\n",
      "trial: 2, iter: 4600, curr loss: 1.2902288436889648, avg loss: 1.3099725234508515\n",
      "trial: 2, iter: 4800, curr loss: 1.332872986793518, avg loss: 1.305938690304756\n",
      "trial: 2, iter: 5000, curr loss: 1.292992353439331, avg loss: 1.303580954670906\n",
      "trial: 2, iter: 5200, curr loss: 1.2847435474395752, avg loss: 1.3077917838096618\n",
      "trial: 2, iter: 5400, curr loss: 1.3384990692138672, avg loss: 1.3052825260162353\n",
      "trial: 2, iter: 5600, curr loss: 1.367324709892273, avg loss: 1.3037953352928162\n",
      "trial: 2, iter: 5800, curr loss: 1.3062281608581543, avg loss: 1.3036178898811341\n",
      "trial: 2, iter: 6000, curr loss: 1.3229495286941528, avg loss: 1.3028591620922088\n",
      "trial: 2, iter: 6200, curr loss: 1.321279525756836, avg loss: 1.3015268695354463\n",
      "trial: 2, ldr: 0.30039551854133606\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3904951810836792, avg loss: 1.3875430327653886\n",
      "trial: 3, iter: 400, curr loss: 1.3847521543502808, avg loss: 1.3865824556350708\n",
      "trial: 3, iter: 600, curr loss: 1.3801696300506592, avg loss: 1.3849953365325929\n",
      "trial: 3, iter: 800, curr loss: 1.374380350112915, avg loss: 1.376320751309395\n",
      "trial: 3, iter: 1000, curr loss: 1.3592908382415771, avg loss: 1.369155494570732\n",
      "trial: 3, iter: 1200, curr loss: 1.365466594696045, avg loss: 1.3666466140747071\n",
      "trial: 3, iter: 1400, curr loss: 1.3513957262039185, avg loss: 1.363397005200386\n",
      "trial: 3, iter: 1600, curr loss: 1.3445806503295898, avg loss: 1.360005070567131\n",
      "trial: 3, iter: 1800, curr loss: 1.3697335720062256, avg loss: 1.3551971942186356\n",
      "trial: 3, iter: 2000, curr loss: 1.3607510328292847, avg loss: 1.3487175637483597\n",
      "trial: 3, iter: 2200, curr loss: 1.336190938949585, avg loss: 1.3419824576377868\n",
      "trial: 3, iter: 2400, curr loss: 1.3434703350067139, avg loss: 1.3371496218442918\n",
      "trial: 3, iter: 2600, curr loss: 1.320710301399231, avg loss: 1.3332107627391816\n",
      "trial: 3, iter: 2800, curr loss: 1.3108060359954834, avg loss: 1.3296248799562453\n",
      "trial: 3, iter: 3000, curr loss: 1.3071807622909546, avg loss: 1.3293816488981247\n",
      "trial: 3, iter: 3200, curr loss: 1.307149887084961, avg loss: 1.3273746371269226\n",
      "trial: 3, iter: 3400, curr loss: 1.3104939460754395, avg loss: 1.32195487678051\n",
      "trial: 3, iter: 3600, curr loss: 1.2984323501586914, avg loss: 1.3190032869577408\n",
      "trial: 3, iter: 3800, curr loss: 1.2929285764694214, avg loss: 1.3169488072395326\n",
      "trial: 3, iter: 4000, curr loss: 1.3296819925308228, avg loss: 1.315300901532173\n",
      "trial: 3, iter: 4200, curr loss: 1.302958607673645, avg loss: 1.314775948524475\n",
      "trial: 3, iter: 4400, curr loss: 1.3041377067565918, avg loss: 1.3127197462320328\n",
      "trial: 3, iter: 4600, curr loss: 1.2707083225250244, avg loss: 1.313108025789261\n",
      "trial: 3, iter: 4800, curr loss: 1.283280849456787, avg loss: 1.3071813255548477\n",
      "trial: 3, iter: 5000, curr loss: 1.2863454818725586, avg loss: 1.310223239660263\n",
      "trial: 3, iter: 5200, curr loss: 1.318846583366394, avg loss: 1.3062579399347305\n",
      "trial: 3, iter: 5400, curr loss: 1.2895722389221191, avg loss: 1.3071549385786057\n",
      "trial: 3, iter: 5600, curr loss: 1.3015940189361572, avg loss: 1.3043713402748107\n",
      "trial: 3, iter: 5800, curr loss: 1.3216791152954102, avg loss: 1.303406776189804\n",
      "trial: 3, iter: 6000, curr loss: 1.3033686876296997, avg loss: 1.304290075302124\n",
      "trial: 3, iter: 6200, curr loss: 1.3291326761245728, avg loss: 1.30662732899189\n",
      "trial: 3, ldr: 0.21564561128616333\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3845571279525757, avg loss: 1.387153587937355\n",
      "trial: 4, iter: 400, curr loss: 1.3840845823287964, avg loss: 1.386696342229843\n",
      "trial: 4, iter: 600, curr loss: 1.3870521783828735, avg loss: 1.3859399890899657\n",
      "trial: 4, iter: 800, curr loss: 1.3840371370315552, avg loss: 1.3850358760356902\n",
      "trial: 4, iter: 1000, curr loss: 1.3688949346542358, avg loss: 1.3769050526618958\n",
      "trial: 4, iter: 1200, curr loss: 1.3680346012115479, avg loss: 1.3670785164833068\n",
      "trial: 4, iter: 1400, curr loss: 1.3472012281417847, avg loss: 1.3631688857078552\n",
      "trial: 4, iter: 1600, curr loss: 1.3589662313461304, avg loss: 1.360712038874626\n",
      "trial: 4, iter: 1800, curr loss: 1.3645035028457642, avg loss: 1.355997143983841\n",
      "trial: 4, iter: 2000, curr loss: 1.3715860843658447, avg loss: 1.354649733901024\n",
      "trial: 4, iter: 2200, curr loss: 1.3492941856384277, avg loss: 1.3466650795936586\n",
      "trial: 4, iter: 2400, curr loss: 1.3479251861572266, avg loss: 1.3370327532291413\n",
      "trial: 4, iter: 2600, curr loss: 1.334363579750061, avg loss: 1.3313200813531876\n",
      "trial: 4, iter: 2800, curr loss: 1.332317590713501, avg loss: 1.3283437931537627\n",
      "trial: 4, iter: 3000, curr loss: 1.2951887845993042, avg loss: 1.3253426134586335\n",
      "trial: 4, iter: 3200, curr loss: 1.3241338729858398, avg loss: 1.322684555053711\n",
      "trial: 4, iter: 3400, curr loss: 1.341747760772705, avg loss: 1.320448865890503\n",
      "trial: 4, iter: 3600, curr loss: 1.3353244066238403, avg loss: 1.317393295764923\n",
      "trial: 4, iter: 3800, curr loss: 1.3022854328155518, avg loss: 1.3148344272375108\n",
      "trial: 4, iter: 4000, curr loss: 1.2964180707931519, avg loss: 1.3130019474029542\n",
      "trial: 4, iter: 4200, curr loss: 1.300478458404541, avg loss: 1.309771238565445\n",
      "trial: 4, iter: 4400, curr loss: 1.295183539390564, avg loss: 1.3083635526895523\n",
      "trial: 4, iter: 4600, curr loss: 1.3150867223739624, avg loss: 1.3083343601226807\n",
      "trial: 4, iter: 4800, curr loss: 1.2919909954071045, avg loss: 1.3108401167392731\n",
      "trial: 4, iter: 5000, curr loss: 1.3061052560806274, avg loss: 1.3060625332593918\n",
      "trial: 4, iter: 5200, curr loss: 1.303999662399292, avg loss: 1.307837991118431\n",
      "trial: 4, iter: 5400, curr loss: 1.2899439334869385, avg loss: 1.3015979844331742\n",
      "trial: 4, iter: 5600, curr loss: 1.2930668592453003, avg loss: 1.3035798972845078\n",
      "trial: 4, iter: 5800, curr loss: 1.3557523488998413, avg loss: 1.3018362027406694\n",
      "trial: 4, iter: 6000, curr loss: 1.3045777082443237, avg loss: 1.300555192232132\n",
      "trial: 4, iter: 6200, curr loss: 1.290421485900879, avg loss: 1.2991778123378754\n",
      "trial: 4, ldr: 0.2086367905139923\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3842750787734985, avg loss: 1.3875221139192582\n",
      "trial: 5, iter: 400, curr loss: 1.3875224590301514, avg loss: 1.3867437678575516\n",
      "trial: 5, iter: 600, curr loss: 1.3867892026901245, avg loss: 1.3864622068405152\n",
      "trial: 5, iter: 800, curr loss: 1.3868238925933838, avg loss: 1.3856599855422973\n",
      "trial: 5, iter: 1000, curr loss: 1.377703309059143, avg loss: 1.3828634685277938\n",
      "trial: 5, iter: 1200, curr loss: 1.3785961866378784, avg loss: 1.3769549113512038\n",
      "trial: 5, iter: 1400, curr loss: 1.355586051940918, avg loss: 1.368236613869667\n",
      "trial: 5, iter: 1600, curr loss: 1.3368492126464844, avg loss: 1.3660597497224807\n",
      "trial: 5, iter: 1800, curr loss: 1.3936220407485962, avg loss: 1.3647559595108032\n",
      "trial: 5, iter: 2000, curr loss: 1.3809682130813599, avg loss: 1.361870443224907\n",
      "trial: 5, iter: 2200, curr loss: 1.3462928533554077, avg loss: 1.3601220381259918\n",
      "trial: 5, iter: 2400, curr loss: 1.3502755165100098, avg loss: 1.3580869233608246\n",
      "trial: 5, iter: 2600, curr loss: 1.3374419212341309, avg loss: 1.353757981657982\n",
      "trial: 5, iter: 2800, curr loss: 1.3565878868103027, avg loss: 1.3468678712844848\n",
      "trial: 5, iter: 3000, curr loss: 1.3210023641586304, avg loss: 1.3390467143058777\n",
      "trial: 5, iter: 3200, curr loss: 1.3233771324157715, avg loss: 1.3324856489896775\n",
      "trial: 5, iter: 3400, curr loss: 1.3198065757751465, avg loss: 1.32474928855896\n",
      "trial: 5, iter: 3600, curr loss: 1.3183796405792236, avg loss: 1.3239134466648101\n",
      "trial: 5, iter: 3800, curr loss: 1.2874339818954468, avg loss: 1.3196396327018738\n",
      "trial: 5, iter: 4000, curr loss: 1.3125512599945068, avg loss: 1.3187787806987763\n",
      "trial: 5, iter: 4200, curr loss: 1.3056042194366455, avg loss: 1.3185927921533585\n",
      "trial: 5, iter: 4400, curr loss: 1.3146986961364746, avg loss: 1.3153609776496886\n",
      "trial: 5, iter: 4600, curr loss: 1.3042361736297607, avg loss: 1.316468789577484\n",
      "trial: 5, iter: 4800, curr loss: 1.2810285091400146, avg loss: 1.3110536336898804\n",
      "trial: 5, iter: 5000, curr loss: 1.308040976524353, avg loss: 1.3088685458898544\n",
      "trial: 5, iter: 5200, curr loss: 1.3055177927017212, avg loss: 1.3087580925226212\n",
      "trial: 5, iter: 5400, curr loss: 1.2873001098632812, avg loss: 1.3040223920345306\n",
      "trial: 5, iter: 5600, curr loss: 1.322189211845398, avg loss: 1.303420649766922\n",
      "trial: 5, iter: 5800, curr loss: 1.2706902027130127, avg loss: 1.3042288488149643\n",
      "trial: 5, iter: 6000, curr loss: 1.2814502716064453, avg loss: 1.301749786734581\n",
      "trial: 5, iter: 6200, curr loss: 1.3071048259735107, avg loss: 1.2989083766937255\n",
      "trial: 5, ldr: 0.2570202052593231\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.25668875575065614\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3887242078781128, avg loss: 1.3872817200422287\n",
      "trial: 1, iter: 400, curr loss: 1.384372591972351, avg loss: 1.3864049726724625\n",
      "trial: 1, iter: 600, curr loss: 1.3839880228042603, avg loss: 1.3859793692827225\n",
      "trial: 1, iter: 800, curr loss: 1.3830878734588623, avg loss: 1.3834970444440842\n",
      "trial: 1, iter: 1000, curr loss: 1.3699830770492554, avg loss: 1.3745246785879135\n",
      "trial: 1, iter: 1200, curr loss: 1.3659443855285645, avg loss: 1.3670619612932204\n",
      "trial: 1, iter: 1400, curr loss: 1.3550281524658203, avg loss: 1.3658293163776398\n",
      "trial: 1, iter: 1600, curr loss: 1.3707084655761719, avg loss: 1.3626777088642121\n",
      "trial: 1, iter: 1800, curr loss: 1.3705424070358276, avg loss: 1.3617520236968994\n",
      "trial: 1, iter: 2000, curr loss: 1.3260475397109985, avg loss: 1.3563840913772582\n",
      "trial: 1, iter: 2200, curr loss: 1.3524283170700073, avg loss: 1.355445974469185\n",
      "trial: 1, iter: 2400, curr loss: 1.322759985923767, avg loss: 1.3489299249649047\n",
      "trial: 1, iter: 2600, curr loss: 1.3110392093658447, avg loss: 1.3419688999652863\n",
      "trial: 1, iter: 2800, curr loss: 1.287941575050354, avg loss: 1.3321320128440857\n",
      "trial: 1, iter: 3000, curr loss: 1.324223518371582, avg loss: 1.3298078060150147\n",
      "trial: 1, iter: 3200, curr loss: 1.3332619667053223, avg loss: 1.3244639867544175\n",
      "trial: 1, iter: 3400, curr loss: 1.3102632761001587, avg loss: 1.322570100426674\n",
      "trial: 1, iter: 3600, curr loss: 1.3152629137039185, avg loss: 1.3175233602523804\n",
      "trial: 1, iter: 3800, curr loss: 1.322719931602478, avg loss: 1.3146265864372253\n",
      "trial: 1, iter: 4000, curr loss: 1.30850350856781, avg loss: 1.3142078614234924\n",
      "trial: 1, iter: 4200, curr loss: 1.3227301836013794, avg loss: 1.3120977574586867\n",
      "trial: 1, iter: 4400, curr loss: 1.3083813190460205, avg loss: 1.306389611363411\n",
      "trial: 1, iter: 4600, curr loss: 1.2849498987197876, avg loss: 1.3082134526968003\n",
      "trial: 1, iter: 4800, curr loss: 1.2817357778549194, avg loss: 1.3087518453598022\n",
      "trial: 1, iter: 5000, curr loss: 1.3352845907211304, avg loss: 1.3061094641685487\n",
      "trial: 1, iter: 5200, curr loss: 1.3208850622177124, avg loss: 1.3019556301832198\n",
      "trial: 1, iter: 5400, curr loss: 1.3297154903411865, avg loss: 1.3052149987220765\n",
      "trial: 1, iter: 5600, curr loss: 1.307999849319458, avg loss: 1.3011888802051543\n",
      "trial: 1, iter: 5800, curr loss: 1.3674334287643433, avg loss: 1.301725971698761\n",
      "trial: 1, iter: 6000, curr loss: 1.2819830179214478, avg loss: 1.2973027086257936\n",
      "trial: 1, iter: 6200, curr loss: 1.2889502048492432, avg loss: 1.2996160614490508\n",
      "trial: 1, ldr: 0.23564516007900238\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387052297592163, avg loss: 1.3873866194486617\n",
      "trial: 2, iter: 400, curr loss: 1.3871277570724487, avg loss: 1.3865559595823287\n",
      "trial: 2, iter: 600, curr loss: 1.385785460472107, avg loss: 1.3866766965389252\n",
      "trial: 2, iter: 800, curr loss: 1.3874071836471558, avg loss: 1.386658815741539\n",
      "trial: 2, iter: 1000, curr loss: 1.3872681856155396, avg loss: 1.386370411515236\n",
      "trial: 2, iter: 1200, curr loss: 1.3847676515579224, avg loss: 1.3856009846925736\n",
      "trial: 2, iter: 1400, curr loss: 1.3781112432479858, avg loss: 1.381053946018219\n",
      "trial: 2, iter: 1600, curr loss: 1.359160304069519, avg loss: 1.3716525197029115\n",
      "trial: 2, iter: 1800, curr loss: 1.359228253364563, avg loss: 1.3675272715091706\n",
      "trial: 2, iter: 2000, curr loss: 1.366502046585083, avg loss: 1.3642757081985473\n",
      "trial: 2, iter: 2200, curr loss: 1.355921983718872, avg loss: 1.3619632869958878\n",
      "trial: 2, iter: 2400, curr loss: 1.3799482583999634, avg loss: 1.3588643819093704\n",
      "trial: 2, iter: 2600, curr loss: 1.358416199684143, avg loss: 1.3533904302120208\n",
      "trial: 2, iter: 2800, curr loss: 1.331497311592102, avg loss: 1.3455104947090148\n",
      "trial: 2, iter: 3000, curr loss: 1.3426648378372192, avg loss: 1.3368725419044494\n",
      "trial: 2, iter: 3200, curr loss: 1.3506159782409668, avg loss: 1.3299540817737578\n",
      "trial: 2, iter: 3400, curr loss: 1.3282339572906494, avg loss: 1.3271235918998718\n",
      "trial: 2, iter: 3600, curr loss: 1.3192609548568726, avg loss: 1.320813032388687\n",
      "trial: 2, iter: 3800, curr loss: 1.3291542530059814, avg loss: 1.324022399187088\n",
      "trial: 2, iter: 4000, curr loss: 1.293497085571289, avg loss: 1.3178600561618805\n",
      "trial: 2, iter: 4200, curr loss: 1.300567388534546, avg loss: 1.316499091386795\n",
      "trial: 2, iter: 4400, curr loss: 1.3141393661499023, avg loss: 1.3115260887145996\n",
      "trial: 2, iter: 4600, curr loss: 1.3026587963104248, avg loss: 1.3124088603258133\n",
      "trial: 2, iter: 4800, curr loss: 1.3304256200790405, avg loss: 1.3109361511468887\n",
      "trial: 2, iter: 5000, curr loss: 1.3042200803756714, avg loss: 1.3084751814603806\n",
      "trial: 2, iter: 5200, curr loss: 1.289237141609192, avg loss: 1.3074928790330886\n",
      "trial: 2, iter: 5400, curr loss: 1.3303192853927612, avg loss: 1.310959158539772\n",
      "trial: 2, iter: 5600, curr loss: 1.2950184345245361, avg loss: 1.3068380773067474\n",
      "trial: 2, iter: 5800, curr loss: 1.3035084009170532, avg loss: 1.3047092956304551\n",
      "trial: 2, iter: 6000, curr loss: 1.350943684577942, avg loss: 1.3039537692070007\n",
      "trial: 2, iter: 6200, curr loss: 1.2987957000732422, avg loss: 1.3042333763837815\n",
      "trial: 2, ldr: 0.20163115859031677\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3867530822753906, avg loss: 1.3872846424579621\n",
      "trial: 3, iter: 400, curr loss: 1.3884741067886353, avg loss: 1.3870667093992233\n",
      "trial: 3, iter: 600, curr loss: 1.3896631002426147, avg loss: 1.3865194845199584\n",
      "trial: 3, iter: 800, curr loss: 1.3830320835113525, avg loss: 1.3863145208358765\n",
      "trial: 3, iter: 1000, curr loss: 1.3812330961227417, avg loss: 1.3835468894243241\n",
      "trial: 3, iter: 1200, curr loss: 1.3739906549453735, avg loss: 1.3744612234830855\n",
      "trial: 3, iter: 1400, curr loss: 1.3535301685333252, avg loss: 1.368917979001999\n",
      "trial: 3, iter: 1600, curr loss: 1.3441038131713867, avg loss: 1.3636739271879197\n",
      "trial: 3, iter: 1800, curr loss: 1.3755086660385132, avg loss: 1.3596534788608552\n",
      "trial: 3, iter: 2000, curr loss: 1.362181544303894, avg loss: 1.3570342445373536\n",
      "trial: 3, iter: 2200, curr loss: 1.3635324239730835, avg loss: 1.3510959184169768\n",
      "trial: 3, iter: 2400, curr loss: 1.3232179880142212, avg loss: 1.3469827497005462\n",
      "trial: 3, iter: 2600, curr loss: 1.3217952251434326, avg loss: 1.341817255616188\n",
      "trial: 3, iter: 2800, curr loss: 1.3304531574249268, avg loss: 1.3336382555961608\n",
      "trial: 3, iter: 3000, curr loss: 1.3451170921325684, avg loss: 1.325668625831604\n",
      "trial: 3, iter: 3200, curr loss: 1.3472751379013062, avg loss: 1.3251694005727768\n",
      "trial: 3, iter: 3400, curr loss: 1.3057657480239868, avg loss: 1.318174610733986\n",
      "trial: 3, iter: 3600, curr loss: 1.2883610725402832, avg loss: 1.3185522508621217\n",
      "trial: 3, iter: 3800, curr loss: 1.309256911277771, avg loss: 1.3154339307546616\n",
      "trial: 3, iter: 4000, curr loss: 1.2955554723739624, avg loss: 1.315412010550499\n",
      "trial: 3, iter: 4200, curr loss: 1.301129937171936, avg loss: 1.3134526377916336\n",
      "trial: 3, iter: 4400, curr loss: 1.309752106666565, avg loss: 1.3108211159706116\n",
      "trial: 3, iter: 4600, curr loss: 1.3093249797821045, avg loss: 1.3101016932725906\n",
      "trial: 3, iter: 4800, curr loss: 1.276320219039917, avg loss: 1.307691758275032\n",
      "trial: 3, iter: 5000, curr loss: 1.3119313716888428, avg loss: 1.3069409865140915\n",
      "trial: 3, iter: 5200, curr loss: 1.2946480512619019, avg loss: 1.3055160558223724\n",
      "trial: 3, iter: 5400, curr loss: 1.2946804761886597, avg loss: 1.3034131449460984\n",
      "trial: 3, iter: 5600, curr loss: 1.3506231307983398, avg loss: 1.3051830124855042\n",
      "trial: 3, iter: 5800, curr loss: 1.324752926826477, avg loss: 1.3018084555864333\n",
      "trial: 3, iter: 6000, curr loss: 1.2566795349121094, avg loss: 1.3013192307949066\n",
      "trial: 3, iter: 6200, curr loss: 1.3086440563201904, avg loss: 1.3015798372030258\n",
      "trial: 3, ldr: 0.22291013598442078\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3869273662567139, avg loss: 1.3876511836051941\n",
      "trial: 4, iter: 400, curr loss: 1.3868651390075684, avg loss: 1.3864809322357177\n",
      "trial: 4, iter: 600, curr loss: 1.3842839002609253, avg loss: 1.386235368847847\n",
      "trial: 4, iter: 800, curr loss: 1.381443977355957, avg loss: 1.3853459864854814\n",
      "trial: 4, iter: 1000, curr loss: 1.369527816772461, avg loss: 1.3764547020196916\n",
      "trial: 4, iter: 1200, curr loss: 1.3611414432525635, avg loss: 1.3679641944169998\n",
      "trial: 4, iter: 1400, curr loss: 1.377253770828247, avg loss: 1.3629204696416855\n",
      "trial: 4, iter: 1600, curr loss: 1.3525209426879883, avg loss: 1.3594896513223649\n",
      "trial: 4, iter: 1800, curr loss: 1.3531239032745361, avg loss: 1.3588172870874404\n",
      "trial: 4, iter: 2000, curr loss: 1.3488836288452148, avg loss: 1.3519952845573426\n",
      "trial: 4, iter: 2200, curr loss: 1.309625267982483, avg loss: 1.3497329419851303\n",
      "trial: 4, iter: 2400, curr loss: 1.3426040410995483, avg loss: 1.3403586804866792\n",
      "trial: 4, iter: 2600, curr loss: 1.3316603899002075, avg loss: 1.335916156768799\n",
      "trial: 4, iter: 2800, curr loss: 1.325105905532837, avg loss: 1.3322781008481979\n",
      "trial: 4, iter: 3000, curr loss: 1.3242106437683105, avg loss: 1.326552887558937\n",
      "trial: 4, iter: 3200, curr loss: 1.3727502822875977, avg loss: 1.3231807833909988\n",
      "trial: 4, iter: 3400, curr loss: 1.316714882850647, avg loss: 1.3209945523738862\n",
      "trial: 4, iter: 3600, curr loss: 1.269230604171753, avg loss: 1.3198395228385926\n",
      "trial: 4, iter: 3800, curr loss: 1.3299378156661987, avg loss: 1.314554648399353\n",
      "trial: 4, iter: 4000, curr loss: 1.3072528839111328, avg loss: 1.31196364402771\n",
      "trial: 4, iter: 4200, curr loss: 1.2896935939788818, avg loss: 1.3111552608013153\n",
      "trial: 4, iter: 4400, curr loss: 1.266451120376587, avg loss: 1.3109854990243912\n",
      "trial: 4, iter: 4600, curr loss: 1.3022161722183228, avg loss: 1.307500439286232\n",
      "trial: 4, iter: 4800, curr loss: 1.3156613111495972, avg loss: 1.3105066496133804\n",
      "trial: 4, iter: 5000, curr loss: 1.3244571685791016, avg loss: 1.3053656977415085\n",
      "trial: 4, iter: 5200, curr loss: 1.3186739683151245, avg loss: 1.3065262937545776\n",
      "trial: 4, iter: 5400, curr loss: 1.3045525550842285, avg loss: 1.302049635052681\n",
      "trial: 4, iter: 5600, curr loss: 1.2883113622665405, avg loss: 1.3007020902633668\n",
      "trial: 4, iter: 5800, curr loss: 1.3216279745101929, avg loss: 1.3028440475463867\n",
      "trial: 4, iter: 6000, curr loss: 1.2844953536987305, avg loss: 1.3011092001199722\n",
      "trial: 4, iter: 6200, curr loss: 1.292290210723877, avg loss: 1.3000031346082688\n",
      "trial: 4, ldr: 0.20207802951335907\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882485628128052, avg loss: 1.3873779487609863\n",
      "trial: 5, iter: 400, curr loss: 1.387374997138977, avg loss: 1.3868792372941972\n",
      "trial: 5, iter: 600, curr loss: 1.3870983123779297, avg loss: 1.3865649104118347\n",
      "trial: 5, iter: 800, curr loss: 1.3866806030273438, avg loss: 1.3863024365901948\n",
      "trial: 5, iter: 1000, curr loss: 1.3868478536605835, avg loss: 1.3860127794742585\n",
      "trial: 5, iter: 1200, curr loss: 1.3685176372528076, avg loss: 1.379227986931801\n",
      "trial: 5, iter: 1400, curr loss: 1.3687639236450195, avg loss: 1.3694105231761933\n",
      "trial: 5, iter: 1600, curr loss: 1.3571289777755737, avg loss: 1.3635587775707245\n",
      "trial: 5, iter: 1800, curr loss: 1.3425930738449097, avg loss: 1.3605677312612534\n",
      "trial: 5, iter: 2000, curr loss: 1.3374459743499756, avg loss: 1.3556074196100234\n",
      "trial: 5, iter: 2200, curr loss: 1.348713994026184, avg loss: 1.3475453782081603\n",
      "trial: 5, iter: 2400, curr loss: 1.3251144886016846, avg loss: 1.3433335477113724\n",
      "trial: 5, iter: 2600, curr loss: 1.3476288318634033, avg loss: 1.3348860496282577\n",
      "trial: 5, iter: 2800, curr loss: 1.3130431175231934, avg loss: 1.3286282902956008\n",
      "trial: 5, iter: 3000, curr loss: 1.3333210945129395, avg loss: 1.327559870481491\n",
      "trial: 5, iter: 3200, curr loss: 1.327455997467041, avg loss: 1.3252369809150695\n",
      "trial: 5, iter: 3400, curr loss: 1.2820749282836914, avg loss: 1.321163536310196\n",
      "trial: 5, iter: 3600, curr loss: 1.3105862140655518, avg loss: 1.3191314542293548\n",
      "trial: 5, iter: 3800, curr loss: 1.3132038116455078, avg loss: 1.3145220172405243\n",
      "trial: 5, iter: 4000, curr loss: 1.3185715675354004, avg loss: 1.3138661229610442\n",
      "trial: 5, iter: 4200, curr loss: 1.3080567121505737, avg loss: 1.3143148690462112\n",
      "trial: 5, iter: 4400, curr loss: 1.3067363500595093, avg loss: 1.30927161693573\n",
      "trial: 5, iter: 4600, curr loss: 1.303654670715332, avg loss: 1.308366820216179\n",
      "trial: 5, iter: 4800, curr loss: 1.3171800374984741, avg loss: 1.3053850632905961\n",
      "trial: 5, iter: 5000, curr loss: 1.3199046850204468, avg loss: 1.302735943198204\n",
      "trial: 5, iter: 5200, curr loss: 1.2995799779891968, avg loss: 1.3046399182081223\n",
      "trial: 5, iter: 5400, curr loss: 1.2959784269332886, avg loss: 1.3035133326053618\n",
      "trial: 5, iter: 5600, curr loss: 1.2824407815933228, avg loss: 1.3047819763422013\n",
      "trial: 5, iter: 5800, curr loss: 1.3073700666427612, avg loss: 1.2995582288503646\n",
      "trial: 5, iter: 6000, curr loss: 1.2720519304275513, avg loss: 1.2985377293825149\n",
      "trial: 5, iter: 6200, curr loss: 1.3007928133010864, avg loss: 1.2982518315315246\n",
      "trial: 5, ldr: 0.17910192906856537\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20827328264713288\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386939525604248, avg loss: 1.3875739973783494\n",
      "trial: 1, iter: 400, curr loss: 1.3866472244262695, avg loss: 1.3870737969875335\n",
      "trial: 1, iter: 600, curr loss: 1.3861528635025024, avg loss: 1.3863380253314972\n",
      "trial: 1, iter: 800, curr loss: 1.3875236511230469, avg loss: 1.3860991364717483\n",
      "trial: 1, iter: 1000, curr loss: 1.378826379776001, avg loss: 1.3823086488246918\n",
      "trial: 1, iter: 1200, curr loss: 1.3775928020477295, avg loss: 1.3713063514232635\n",
      "trial: 1, iter: 1400, curr loss: 1.3681553602218628, avg loss: 1.3660903841257095\n",
      "trial: 1, iter: 1600, curr loss: 1.3643718957901, avg loss: 1.3624922013282776\n",
      "trial: 1, iter: 1800, curr loss: 1.362687110900879, avg loss: 1.3586645138263702\n",
      "trial: 1, iter: 2000, curr loss: 1.341700792312622, avg loss: 1.3534221321344375\n",
      "trial: 1, iter: 2200, curr loss: 1.3384827375411987, avg loss: 1.3447556829452514\n",
      "trial: 1, iter: 2400, curr loss: 1.3380128145217896, avg loss: 1.3367040628194808\n",
      "trial: 1, iter: 2600, curr loss: 1.32196843624115, avg loss: 1.33675586104393\n",
      "trial: 1, iter: 2800, curr loss: 1.3070844411849976, avg loss: 1.3287489700317383\n",
      "trial: 1, iter: 3000, curr loss: 1.2833877801895142, avg loss: 1.3230128973722457\n",
      "trial: 1, iter: 3200, curr loss: 1.3347148895263672, avg loss: 1.3196370327472686\n",
      "trial: 1, iter: 3400, curr loss: 1.3101798295974731, avg loss: 1.319733941555023\n",
      "trial: 1, iter: 3600, curr loss: 1.2726386785507202, avg loss: 1.31641320168972\n",
      "trial: 1, iter: 3800, curr loss: 1.2958077192306519, avg loss: 1.312484956383705\n",
      "trial: 1, iter: 4000, curr loss: 1.329125165939331, avg loss: 1.312312239408493\n",
      "trial: 1, iter: 4200, curr loss: 1.3178842067718506, avg loss: 1.310685044527054\n",
      "trial: 1, iter: 4400, curr loss: 1.31438148021698, avg loss: 1.3075671350955964\n",
      "trial: 1, iter: 4600, curr loss: 1.3308751583099365, avg loss: 1.3077475160360337\n",
      "trial: 1, iter: 4800, curr loss: 1.2932387590408325, avg loss: 1.3067259997129441\n",
      "trial: 1, iter: 5000, curr loss: 1.3078926801681519, avg loss: 1.3030336517095567\n",
      "trial: 1, iter: 5200, curr loss: 1.3335071802139282, avg loss: 1.304670562148094\n",
      "trial: 1, iter: 5400, curr loss: 1.3178609609603882, avg loss: 1.301395388841629\n",
      "trial: 1, iter: 5600, curr loss: 1.316422462463379, avg loss: 1.3000149410963058\n",
      "trial: 1, iter: 5800, curr loss: 1.3078830242156982, avg loss: 1.300890738964081\n",
      "trial: 1, iter: 6000, curr loss: 1.3234316110610962, avg loss: 1.2992235481739045\n",
      "trial: 1, iter: 6200, curr loss: 1.239608883857727, avg loss: 1.29763014793396\n",
      "trial: 1, ldr: 0.28083154559135437\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3837493658065796, avg loss: 1.3876683139801025\n",
      "trial: 2, iter: 400, curr loss: 1.3824446201324463, avg loss: 1.3867756122350692\n",
      "trial: 2, iter: 600, curr loss: 1.3859626054763794, avg loss: 1.3865050196647644\n",
      "trial: 2, iter: 800, curr loss: 1.383018970489502, avg loss: 1.3859076553583145\n",
      "trial: 2, iter: 1000, curr loss: 1.3787199258804321, avg loss: 1.3829626137018203\n",
      "trial: 2, iter: 1200, curr loss: 1.3589731454849243, avg loss: 1.3719015091657638\n",
      "trial: 2, iter: 1400, curr loss: 1.3517184257507324, avg loss: 1.364682786464691\n",
      "trial: 2, iter: 1600, curr loss: 1.3471293449401855, avg loss: 1.3611621785163879\n",
      "trial: 2, iter: 1800, curr loss: 1.355080246925354, avg loss: 1.360301247239113\n",
      "trial: 2, iter: 2000, curr loss: 1.346979022026062, avg loss: 1.3544044780731201\n",
      "trial: 2, iter: 2200, curr loss: 1.3413053750991821, avg loss: 1.348198476433754\n",
      "trial: 2, iter: 2400, curr loss: 1.3426237106323242, avg loss: 1.3428074991703034\n",
      "trial: 2, iter: 2600, curr loss: 1.3270690441131592, avg loss: 1.3336229467391967\n",
      "trial: 2, iter: 2800, curr loss: 1.34586763381958, avg loss: 1.327290969491005\n",
      "trial: 2, iter: 3000, curr loss: 1.3186564445495605, avg loss: 1.3241286599636077\n",
      "trial: 2, iter: 3200, curr loss: 1.337093710899353, avg loss: 1.3205353534221649\n",
      "trial: 2, iter: 3400, curr loss: 1.3475582599639893, avg loss: 1.3178881853818893\n",
      "trial: 2, iter: 3600, curr loss: 1.328025460243225, avg loss: 1.3157457822561265\n",
      "trial: 2, iter: 3800, curr loss: 1.3187386989593506, avg loss: 1.31281230032444\n",
      "trial: 2, iter: 4000, curr loss: 1.3160381317138672, avg loss: 1.3116967648267746\n",
      "trial: 2, iter: 4200, curr loss: 1.289101004600525, avg loss: 1.308363648056984\n",
      "trial: 2, iter: 4400, curr loss: 1.2909021377563477, avg loss: 1.3078525048494338\n",
      "trial: 2, iter: 4600, curr loss: 1.3331584930419922, avg loss: 1.3071759915351868\n",
      "trial: 2, iter: 4800, curr loss: 1.2896546125411987, avg loss: 1.3050160312652588\n",
      "trial: 2, iter: 5000, curr loss: 1.2762905359268188, avg loss: 1.3016729635000228\n",
      "trial: 2, iter: 5200, curr loss: 1.3190070390701294, avg loss: 1.3010377824306487\n",
      "trial: 2, iter: 5400, curr loss: 1.3194273710250854, avg loss: 1.3007329791784286\n",
      "trial: 2, iter: 5600, curr loss: 1.2939373254776, avg loss: 1.2959329748153687\n",
      "trial: 2, iter: 5800, curr loss: 1.3244620561599731, avg loss: 1.298831981420517\n",
      "trial: 2, iter: 6000, curr loss: 1.326352834701538, avg loss: 1.2980809754133225\n",
      "trial: 2, iter: 6200, curr loss: 1.2893507480621338, avg loss: 1.2996797800064086\n",
      "trial: 2, ldr: 0.20405817031860352\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873000144958496, avg loss: 1.387223242521286\n",
      "trial: 3, iter: 400, curr loss: 1.3881487846374512, avg loss: 1.386753688454628\n",
      "trial: 3, iter: 600, curr loss: 1.3840413093566895, avg loss: 1.3859926521778108\n",
      "trial: 3, iter: 800, curr loss: 1.382163405418396, avg loss: 1.3827134740352631\n",
      "trial: 3, iter: 1000, curr loss: 1.3708231449127197, avg loss: 1.372582232952118\n",
      "trial: 3, iter: 1200, curr loss: 1.352969765663147, avg loss: 1.3656384134292603\n",
      "trial: 3, iter: 1400, curr loss: 1.3682280778884888, avg loss: 1.3603714209795\n",
      "trial: 3, iter: 1600, curr loss: 1.368861198425293, avg loss: 1.3582352930307389\n",
      "trial: 3, iter: 1800, curr loss: 1.3501874208450317, avg loss: 1.3512698537111283\n",
      "trial: 3, iter: 2000, curr loss: 1.3507884740829468, avg loss: 1.3482741987705231\n",
      "trial: 3, iter: 2200, curr loss: 1.3447293043136597, avg loss: 1.340626986026764\n",
      "trial: 3, iter: 2400, curr loss: 1.3402012586593628, avg loss: 1.3344434094429016\n",
      "trial: 3, iter: 2600, curr loss: 1.3044084310531616, avg loss: 1.3283800286054612\n",
      "trial: 3, iter: 2800, curr loss: 1.3125072717666626, avg loss: 1.3236174207925797\n",
      "trial: 3, iter: 3000, curr loss: 1.3320471048355103, avg loss: 1.3209266608953476\n",
      "trial: 3, iter: 3200, curr loss: 1.2780930995941162, avg loss: 1.318352560400963\n",
      "trial: 3, iter: 3400, curr loss: 1.3313696384429932, avg loss: 1.3179902255535125\n",
      "trial: 3, iter: 3600, curr loss: 1.3291248083114624, avg loss: 1.3147139436006545\n",
      "trial: 3, iter: 3800, curr loss: 1.3217546939849854, avg loss: 1.312689179778099\n",
      "trial: 3, iter: 4000, curr loss: 1.2911447286605835, avg loss: 1.3118587094545364\n",
      "trial: 3, iter: 4200, curr loss: 1.2939831018447876, avg loss: 1.3093345832824708\n",
      "trial: 3, iter: 4400, curr loss: 1.2884886264801025, avg loss: 1.3058168751001358\n",
      "trial: 3, iter: 4600, curr loss: 1.289068579673767, avg loss: 1.3078311812877654\n",
      "trial: 3, iter: 4800, curr loss: 1.3073991537094116, avg loss: 1.3021607112884521\n",
      "trial: 3, iter: 5000, curr loss: 1.2656567096710205, avg loss: 1.3018456423282623\n",
      "trial: 3, iter: 5200, curr loss: 1.3207039833068848, avg loss: 1.3017074048519135\n",
      "trial: 3, iter: 5400, curr loss: 1.3112719058990479, avg loss: 1.3006906592845917\n",
      "trial: 3, iter: 5600, curr loss: 1.277562141418457, avg loss: 1.300889630317688\n",
      "trial: 3, iter: 5800, curr loss: 1.2985094785690308, avg loss: 1.3000842434167863\n",
      "trial: 3, iter: 6000, curr loss: 1.3146382570266724, avg loss: 1.3001962417364121\n",
      "trial: 3, iter: 6200, curr loss: 1.2744389772415161, avg loss: 1.2953651469945908\n",
      "trial: 3, ldr: 0.25756019353866577\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3852910995483398, avg loss: 1.3870187455415726\n",
      "trial: 4, iter: 400, curr loss: 1.3870729207992554, avg loss: 1.3865539622306824\n",
      "trial: 4, iter: 600, curr loss: 1.383086919784546, avg loss: 1.3854717189073562\n",
      "trial: 4, iter: 800, curr loss: 1.366776704788208, avg loss: 1.3819261056184768\n",
      "trial: 4, iter: 1000, curr loss: 1.3853604793548584, avg loss: 1.3734691375494004\n",
      "trial: 4, iter: 1200, curr loss: 1.3468079566955566, avg loss: 1.3673738718032837\n",
      "trial: 4, iter: 1400, curr loss: 1.3637900352478027, avg loss: 1.3642372792959214\n",
      "trial: 4, iter: 1600, curr loss: 1.377342939376831, avg loss: 1.3598366117477416\n",
      "trial: 4, iter: 1800, curr loss: 1.349229335784912, avg loss: 1.358905649781227\n",
      "trial: 4, iter: 2000, curr loss: 1.347757339477539, avg loss: 1.35379585981369\n",
      "trial: 4, iter: 2200, curr loss: 1.369832158088684, avg loss: 1.3488891786336898\n",
      "trial: 4, iter: 2400, curr loss: 1.3460584878921509, avg loss: 1.3392621171474457\n",
      "trial: 4, iter: 2600, curr loss: 1.3263193368911743, avg loss: 1.333238177895546\n",
      "trial: 4, iter: 2800, curr loss: 1.3346285820007324, avg loss: 1.3313375473022462\n",
      "trial: 4, iter: 3000, curr loss: 1.3522024154663086, avg loss: 1.3236745941638945\n",
      "trial: 4, iter: 3200, curr loss: 1.327369213104248, avg loss: 1.3196976882219316\n",
      "trial: 4, iter: 3400, curr loss: 1.3218648433685303, avg loss: 1.3168429559469224\n",
      "trial: 4, iter: 3600, curr loss: 1.3251547813415527, avg loss: 1.315866569876671\n",
      "trial: 4, iter: 3800, curr loss: 1.3110374212265015, avg loss: 1.3119698613882065\n",
      "trial: 4, iter: 4000, curr loss: 1.2952755689620972, avg loss: 1.3108368456363677\n",
      "trial: 4, iter: 4200, curr loss: 1.3115992546081543, avg loss: 1.3087912899255754\n",
      "trial: 4, iter: 4400, curr loss: 1.3162224292755127, avg loss: 1.308098654150963\n",
      "trial: 4, iter: 4600, curr loss: 1.3371940851211548, avg loss: 1.30567966401577\n",
      "trial: 4, iter: 4800, curr loss: 1.2886037826538086, avg loss: 1.305110470056534\n",
      "trial: 4, iter: 5000, curr loss: 1.3061848878860474, avg loss: 1.3050071674585342\n",
      "trial: 4, iter: 5200, curr loss: 1.259016990661621, avg loss: 1.303638156056404\n",
      "trial: 4, iter: 5400, curr loss: 1.2931225299835205, avg loss: 1.3036552584171295\n",
      "trial: 4, iter: 5600, curr loss: 1.269223690032959, avg loss: 1.3000120216608047\n",
      "trial: 4, iter: 5800, curr loss: 1.3096849918365479, avg loss: 1.3040552616119385\n",
      "trial: 4, iter: 6000, curr loss: 1.3212844133377075, avg loss: 1.3011189782619477\n",
      "trial: 4, iter: 6200, curr loss: 1.323091745376587, avg loss: 1.2969365286827088\n",
      "trial: 4, ldr: 0.3392225205898285\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3935602903366089, avg loss: 1.387529319524765\n",
      "trial: 5, iter: 400, curr loss: 1.386224389076233, avg loss: 1.3867502123117448\n",
      "trial: 5, iter: 600, curr loss: 1.387112021446228, avg loss: 1.3863005459308624\n",
      "trial: 5, iter: 800, curr loss: 1.383029818534851, avg loss: 1.384517906308174\n",
      "trial: 5, iter: 1000, curr loss: 1.3782529830932617, avg loss: 1.3745466923713685\n",
      "trial: 5, iter: 1200, curr loss: 1.3601301908493042, avg loss: 1.3647819262742997\n",
      "trial: 5, iter: 1400, curr loss: 1.3655215501785278, avg loss: 1.3616488218307494\n",
      "trial: 5, iter: 1600, curr loss: 1.3438082933425903, avg loss: 1.3584425514936447\n",
      "trial: 5, iter: 1800, curr loss: 1.3672616481781006, avg loss: 1.3511102682352065\n",
      "trial: 5, iter: 2000, curr loss: 1.3443363904953003, avg loss: 1.3474507635831834\n",
      "trial: 5, iter: 2200, curr loss: 1.3451693058013916, avg loss: 1.3381390768289565\n",
      "trial: 5, iter: 2400, curr loss: 1.3482155799865723, avg loss: 1.3313685673475266\n",
      "trial: 5, iter: 2600, curr loss: 1.3064465522766113, avg loss: 1.3296380186080932\n",
      "trial: 5, iter: 2800, curr loss: 1.3229055404663086, avg loss: 1.322897682785988\n",
      "trial: 5, iter: 3000, curr loss: 1.3470524549484253, avg loss: 1.3225441139936447\n",
      "trial: 5, iter: 3200, curr loss: 1.2903342247009277, avg loss: 1.32006511926651\n",
      "trial: 5, iter: 3400, curr loss: 1.299035906791687, avg loss: 1.317319466471672\n",
      "trial: 5, iter: 3600, curr loss: 1.3289790153503418, avg loss: 1.3164767068624497\n",
      "trial: 5, iter: 3800, curr loss: 1.3192827701568604, avg loss: 1.3141733008623122\n",
      "trial: 5, iter: 4000, curr loss: 1.3173797130584717, avg loss: 1.312775150537491\n",
      "trial: 5, iter: 4200, curr loss: 1.3252596855163574, avg loss: 1.312706816792488\n",
      "trial: 5, iter: 4400, curr loss: 1.297738790512085, avg loss: 1.3111522853374482\n",
      "trial: 5, iter: 4600, curr loss: 1.3100743293762207, avg loss: 1.3102313303947448\n",
      "trial: 5, iter: 4800, curr loss: 1.3143563270568848, avg loss: 1.30558702647686\n",
      "trial: 5, iter: 5000, curr loss: 1.2990381717681885, avg loss: 1.3053640222549439\n",
      "trial: 5, iter: 5200, curr loss: 1.297317624092102, avg loss: 1.3090891927480697\n",
      "trial: 5, iter: 5400, curr loss: 1.2760014533996582, avg loss: 1.3043191093206405\n",
      "trial: 5, iter: 5600, curr loss: 1.344476342201233, avg loss: 1.3016635191440582\n",
      "trial: 5, iter: 5800, curr loss: 1.312790870666504, avg loss: 1.3044540482759475\n",
      "trial: 5, iter: 6000, curr loss: 1.3050236701965332, avg loss: 1.29990227997303\n",
      "trial: 5, iter: 6200, curr loss: 1.2810438871383667, avg loss: 1.297924411892891\n",
      "trial: 5, ldr: 0.27944961190223694\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.27222440838813783\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3886160850524902, avg loss: 1.387324560880661\n",
      "trial: 1, iter: 400, curr loss: 1.3885776996612549, avg loss: 1.3865017414093017\n",
      "trial: 1, iter: 600, curr loss: 1.386501431465149, avg loss: 1.3864883387088776\n",
      "trial: 1, iter: 800, curr loss: 1.3840457201004028, avg loss: 1.38617771089077\n",
      "trial: 1, iter: 1000, curr loss: 1.3845535516738892, avg loss: 1.3849789279699325\n",
      "trial: 1, iter: 1200, curr loss: 1.39154851436615, avg loss: 1.3776420348882674\n",
      "trial: 1, iter: 1400, curr loss: 1.365654468536377, avg loss: 1.3689682078361511\n",
      "trial: 1, iter: 1600, curr loss: 1.3619848489761353, avg loss: 1.362846645116806\n",
      "trial: 1, iter: 1800, curr loss: 1.3319060802459717, avg loss: 1.3569043362140656\n",
      "trial: 1, iter: 2000, curr loss: 1.3362019062042236, avg loss: 1.35437084376812\n",
      "trial: 1, iter: 2200, curr loss: 1.349076271057129, avg loss: 1.348384099006653\n",
      "trial: 1, iter: 2400, curr loss: 1.3295519351959229, avg loss: 1.3412521475553512\n",
      "trial: 1, iter: 2600, curr loss: 1.345325231552124, avg loss: 1.336289765238762\n",
      "trial: 1, iter: 2800, curr loss: 1.3469423055648804, avg loss: 1.3311896646022796\n",
      "trial: 1, iter: 3000, curr loss: 1.3114728927612305, avg loss: 1.3275143200159072\n",
      "trial: 1, iter: 3200, curr loss: 1.3043380975723267, avg loss: 1.3239746004343034\n",
      "trial: 1, iter: 3400, curr loss: 1.2898306846618652, avg loss: 1.320442373752594\n",
      "trial: 1, iter: 3600, curr loss: 1.3033744096755981, avg loss: 1.3170756471157075\n",
      "trial: 1, iter: 3800, curr loss: 1.3709709644317627, avg loss: 1.3151608806848527\n",
      "trial: 1, iter: 4000, curr loss: 1.3132777214050293, avg loss: 1.317995468378067\n",
      "trial: 1, iter: 4200, curr loss: 1.310590147972107, avg loss: 1.3167024010419845\n",
      "trial: 1, iter: 4400, curr loss: 1.3069922924041748, avg loss: 1.3120235121250152\n",
      "trial: 1, iter: 4600, curr loss: 1.3026248216629028, avg loss: 1.3102110087871552\n",
      "trial: 1, iter: 4800, curr loss: 1.2956302165985107, avg loss: 1.3091666156053543\n",
      "trial: 1, iter: 5000, curr loss: 1.269399881362915, avg loss: 1.306123383641243\n",
      "trial: 1, iter: 5200, curr loss: 1.276656150817871, avg loss: 1.3040596586465836\n",
      "trial: 1, iter: 5400, curr loss: 1.3157575130462646, avg loss: 1.3074652236700057\n",
      "trial: 1, iter: 5600, curr loss: 1.2875792980194092, avg loss: 1.3044855451583863\n",
      "trial: 1, iter: 5800, curr loss: 1.3020086288452148, avg loss: 1.3025544899702073\n",
      "trial: 1, iter: 6000, curr loss: 1.2911391258239746, avg loss: 1.306228084564209\n",
      "trial: 1, iter: 6200, curr loss: 1.3211051225662231, avg loss: 1.300201977491379\n",
      "trial: 1, ldr: 0.2548641264438629\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3852077722549438, avg loss: 1.3873316180706023\n",
      "trial: 2, iter: 400, curr loss: 1.38633131980896, avg loss: 1.3867017650604248\n",
      "trial: 2, iter: 600, curr loss: 1.3854807615280151, avg loss: 1.3865334618091583\n",
      "trial: 2, iter: 800, curr loss: 1.3850653171539307, avg loss: 1.386038230061531\n",
      "trial: 2, iter: 1000, curr loss: 1.3809549808502197, avg loss: 1.3817468112707139\n",
      "trial: 2, iter: 1200, curr loss: 1.3921754360198975, avg loss: 1.372138876914978\n",
      "trial: 2, iter: 1400, curr loss: 1.3677515983581543, avg loss: 1.3662010073661803\n",
      "trial: 2, iter: 1600, curr loss: 1.3619513511657715, avg loss: 1.3631709188222885\n",
      "trial: 2, iter: 1800, curr loss: 1.3586267232894897, avg loss: 1.3592898315191269\n",
      "trial: 2, iter: 2000, curr loss: 1.3529553413391113, avg loss: 1.3573784857988358\n",
      "trial: 2, iter: 2200, curr loss: 1.366266131401062, avg loss: 1.3498142808675766\n",
      "trial: 2, iter: 2400, curr loss: 1.358094334602356, avg loss: 1.3427817034721374\n",
      "trial: 2, iter: 2600, curr loss: 1.323587417602539, avg loss: 1.3385801196098328\n",
      "trial: 2, iter: 2800, curr loss: 1.3555006980895996, avg loss: 1.327443122267723\n",
      "trial: 2, iter: 3000, curr loss: 1.3161399364471436, avg loss: 1.325750816464424\n",
      "trial: 2, iter: 3200, curr loss: 1.3349502086639404, avg loss: 1.3205031996965408\n",
      "trial: 2, iter: 3400, curr loss: 1.3232026100158691, avg loss: 1.3200261080265046\n",
      "trial: 2, iter: 3600, curr loss: 1.3188245296478271, avg loss: 1.3175288158655167\n",
      "trial: 2, iter: 3800, curr loss: 1.328918695449829, avg loss: 1.3117003220319747\n",
      "trial: 2, iter: 4000, curr loss: 1.3030463457107544, avg loss: 1.3139859247207641\n",
      "trial: 2, iter: 4200, curr loss: 1.3319822549819946, avg loss: 1.3126757341623305\n",
      "trial: 2, iter: 4400, curr loss: 1.3087480068206787, avg loss: 1.3079101634025574\n",
      "trial: 2, iter: 4600, curr loss: 1.3037320375442505, avg loss: 1.3078824764490127\n",
      "trial: 2, iter: 4800, curr loss: 1.2971882820129395, avg loss: 1.3068276786804198\n",
      "trial: 2, iter: 5000, curr loss: 1.3300848007202148, avg loss: 1.3058802872896194\n",
      "trial: 2, iter: 5200, curr loss: 1.299371361732483, avg loss: 1.3057680934667588\n",
      "trial: 2, iter: 5400, curr loss: 1.2908055782318115, avg loss: 1.3034854543209076\n",
      "trial: 2, iter: 5600, curr loss: 1.2912333011627197, avg loss: 1.3009068673849107\n",
      "trial: 2, iter: 5800, curr loss: 1.3263288736343384, avg loss: 1.3028235161304473\n",
      "trial: 2, iter: 6000, curr loss: 1.2973045110702515, avg loss: 1.2998273110389709\n",
      "trial: 2, iter: 6200, curr loss: 1.3063147068023682, avg loss: 1.3007977098226546\n",
      "trial: 2, ldr: 0.2730260193347931\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.38457453250885, avg loss: 1.3873866927623748\n",
      "trial: 3, iter: 400, curr loss: 1.3849601745605469, avg loss: 1.3866311711072923\n",
      "trial: 3, iter: 600, curr loss: 1.391913890838623, avg loss: 1.3856823861598968\n",
      "trial: 3, iter: 800, curr loss: 1.3845014572143555, avg loss: 1.382834982275963\n",
      "trial: 3, iter: 1000, curr loss: 1.3745203018188477, avg loss: 1.3791268038749696\n",
      "trial: 3, iter: 1200, curr loss: 1.353083610534668, avg loss: 1.3725602906942367\n",
      "trial: 3, iter: 1400, curr loss: 1.373692512512207, avg loss: 1.3677785408496856\n",
      "trial: 3, iter: 1600, curr loss: 1.3700511455535889, avg loss: 1.3648043233156204\n",
      "trial: 3, iter: 1800, curr loss: 1.3361246585845947, avg loss: 1.3631821501255035\n",
      "trial: 3, iter: 2000, curr loss: 1.365844964981079, avg loss: 1.3614743810892105\n",
      "trial: 3, iter: 2200, curr loss: 1.3810293674468994, avg loss: 1.3571689599752426\n",
      "trial: 3, iter: 2400, curr loss: 1.3365517854690552, avg loss: 1.3483672380447387\n",
      "trial: 3, iter: 2600, curr loss: 1.3142160177230835, avg loss: 1.3384046924114228\n",
      "trial: 3, iter: 2800, curr loss: 1.31961989402771, avg loss: 1.3325709080696106\n",
      "trial: 3, iter: 3000, curr loss: 1.3249342441558838, avg loss: 1.3263787233829498\n",
      "trial: 3, iter: 3200, curr loss: 1.3172130584716797, avg loss: 1.3240300971269607\n",
      "trial: 3, iter: 3400, curr loss: 1.3053655624389648, avg loss: 1.3227058589458465\n",
      "trial: 3, iter: 3600, curr loss: 1.333326816558838, avg loss: 1.3170263624191285\n",
      "trial: 3, iter: 3800, curr loss: 1.3207932710647583, avg loss: 1.3190216672420503\n",
      "trial: 3, iter: 4000, curr loss: 1.3257521390914917, avg loss: 1.3163896471261978\n",
      "trial: 3, iter: 4200, curr loss: 1.322924017906189, avg loss: 1.3162418049573898\n",
      "trial: 3, iter: 4400, curr loss: 1.3315942287445068, avg loss: 1.3153994125127793\n",
      "trial: 3, iter: 4600, curr loss: 1.3071986436843872, avg loss: 1.3071739000082017\n",
      "trial: 3, iter: 4800, curr loss: 1.2980668544769287, avg loss: 1.3087276482582093\n",
      "trial: 3, iter: 5000, curr loss: 1.2844852209091187, avg loss: 1.3088018268346786\n",
      "trial: 3, iter: 5200, curr loss: 1.3272771835327148, avg loss: 1.3089098995923996\n",
      "trial: 3, iter: 5400, curr loss: 1.2947906255722046, avg loss: 1.3078975105285644\n",
      "trial: 3, iter: 5600, curr loss: 1.3044465780258179, avg loss: 1.3042174196243286\n",
      "trial: 3, iter: 5800, curr loss: 1.3190703392028809, avg loss: 1.3026267457008363\n",
      "trial: 3, iter: 6000, curr loss: 1.2802504301071167, avg loss: 1.3027743887901306\n",
      "trial: 3, iter: 6200, curr loss: 1.300307273864746, avg loss: 1.2984945940971375\n",
      "trial: 3, ldr: 0.25743764638900757\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3873682022094727, avg loss: 1.3872207003831862\n",
      "trial: 4, iter: 400, curr loss: 1.3892848491668701, avg loss: 1.3867060738801955\n",
      "trial: 4, iter: 600, curr loss: 1.3894329071044922, avg loss: 1.3864080917835235\n",
      "trial: 4, iter: 800, curr loss: 1.385144591331482, avg loss: 1.3850016939640044\n",
      "trial: 4, iter: 1000, curr loss: 1.3833519220352173, avg loss: 1.3753970116376877\n",
      "trial: 4, iter: 1200, curr loss: 1.352687954902649, avg loss: 1.367775109410286\n",
      "trial: 4, iter: 1400, curr loss: 1.350078821182251, avg loss: 1.3624303060770036\n",
      "trial: 4, iter: 1600, curr loss: 1.3808118104934692, avg loss: 1.3615648591518401\n",
      "trial: 4, iter: 1800, curr loss: 1.3586578369140625, avg loss: 1.3541667050123214\n",
      "trial: 4, iter: 2000, curr loss: 1.3424795866012573, avg loss: 1.3455220317840577\n",
      "trial: 4, iter: 2200, curr loss: 1.350635290145874, avg loss: 1.338854004740715\n",
      "trial: 4, iter: 2400, curr loss: 1.3548495769500732, avg loss: 1.3317909729480744\n",
      "trial: 4, iter: 2600, curr loss: 1.3157929182052612, avg loss: 1.3291190463304519\n",
      "trial: 4, iter: 2800, curr loss: 1.308232307434082, avg loss: 1.3230429434776305\n",
      "trial: 4, iter: 3000, curr loss: 1.2936595678329468, avg loss: 1.318149038553238\n",
      "trial: 4, iter: 3200, curr loss: 1.309032917022705, avg loss: 1.3195271688699721\n",
      "trial: 4, iter: 3400, curr loss: 1.3189470767974854, avg loss: 1.3174064415693283\n",
      "trial: 4, iter: 3600, curr loss: 1.3064160346984863, avg loss: 1.312685284614563\n",
      "trial: 4, iter: 3800, curr loss: 1.3131382465362549, avg loss: 1.3110252368450164\n",
      "trial: 4, iter: 4000, curr loss: 1.311211109161377, avg loss: 1.311449534893036\n",
      "trial: 4, iter: 4200, curr loss: 1.2946463823318481, avg loss: 1.3098008882999421\n",
      "trial: 4, iter: 4400, curr loss: 1.293745756149292, avg loss: 1.3078688442707063\n",
      "trial: 4, iter: 4600, curr loss: 1.3360451459884644, avg loss: 1.3064804595708848\n",
      "trial: 4, iter: 4800, curr loss: 1.3211051225662231, avg loss: 1.3080405491590499\n",
      "trial: 4, iter: 5000, curr loss: 1.3435959815979004, avg loss: 1.3046183228492736\n",
      "trial: 4, iter: 5200, curr loss: 1.3097535371780396, avg loss: 1.3028799253702164\n",
      "trial: 4, iter: 5400, curr loss: 1.2984132766723633, avg loss: 1.3026755201816558\n",
      "trial: 4, iter: 5600, curr loss: 1.3105636835098267, avg loss: 1.2987859708070755\n",
      "trial: 4, iter: 5800, curr loss: 1.2958316802978516, avg loss: 1.3032073241472244\n",
      "trial: 4, iter: 6000, curr loss: 1.3029574155807495, avg loss: 1.2979246073961257\n",
      "trial: 4, iter: 6200, curr loss: 1.2728463411331177, avg loss: 1.298188853263855\n",
      "trial: 4, ldr: 0.2868933081626892\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3866231441497803, avg loss: 1.3873031997680665\n",
      "trial: 5, iter: 400, curr loss: 1.3896669149398804, avg loss: 1.3867008203268052\n",
      "trial: 5, iter: 600, curr loss: 1.3863545656204224, avg loss: 1.3864626771211623\n",
      "trial: 5, iter: 800, curr loss: 1.38511323928833, avg loss: 1.3863748162984848\n",
      "trial: 5, iter: 1000, curr loss: 1.3810101747512817, avg loss: 1.3851731860637664\n",
      "trial: 5, iter: 1200, curr loss: 1.3880494832992554, avg loss: 1.3790692114830017\n",
      "trial: 5, iter: 1400, curr loss: 1.3792780637741089, avg loss: 1.3696248495578767\n",
      "trial: 5, iter: 1600, curr loss: 1.3670552968978882, avg loss: 1.3650105273723603\n",
      "trial: 5, iter: 1800, curr loss: 1.343367338180542, avg loss: 1.3618729102611542\n",
      "trial: 5, iter: 2000, curr loss: 1.3541467189788818, avg loss: 1.3587776589393616\n",
      "trial: 5, iter: 2200, curr loss: 1.3347456455230713, avg loss: 1.351313166618347\n",
      "trial: 5, iter: 2400, curr loss: 1.3293507099151611, avg loss: 1.3416749030351638\n",
      "trial: 5, iter: 2600, curr loss: 1.3417181968688965, avg loss: 1.3354510688781738\n",
      "trial: 5, iter: 2800, curr loss: 1.3354990482330322, avg loss: 1.3305853098630904\n",
      "trial: 5, iter: 3000, curr loss: 1.3027300834655762, avg loss: 1.3266218554973603\n",
      "trial: 5, iter: 3200, curr loss: 1.3129899501800537, avg loss: 1.3228532725572586\n",
      "trial: 5, iter: 3400, curr loss: 1.3113704919815063, avg loss: 1.3164363050460814\n",
      "trial: 5, iter: 3600, curr loss: 1.3101063966751099, avg loss: 1.3187868934869766\n",
      "trial: 5, iter: 3800, curr loss: 1.317428469657898, avg loss: 1.3163498955965043\n",
      "trial: 5, iter: 4000, curr loss: 1.2980542182922363, avg loss: 1.313141284584999\n",
      "trial: 5, iter: 4200, curr loss: 1.3098914623260498, avg loss: 1.310875398516655\n",
      "trial: 5, iter: 4400, curr loss: 1.305850625038147, avg loss: 1.3109719473123551\n",
      "trial: 5, iter: 4600, curr loss: 1.31204092502594, avg loss: 1.3094806283712388\n",
      "trial: 5, iter: 4800, curr loss: 1.2896742820739746, avg loss: 1.3099695086479186\n",
      "trial: 5, iter: 5000, curr loss: 1.296330451965332, avg loss: 1.303648271560669\n",
      "trial: 5, iter: 5200, curr loss: 1.2918503284454346, avg loss: 1.3058701038360596\n",
      "trial: 5, iter: 5400, curr loss: 1.2984168529510498, avg loss: 1.3054867166280746\n",
      "trial: 5, iter: 5600, curr loss: 1.2855112552642822, avg loss: 1.301782175898552\n",
      "trial: 5, iter: 5800, curr loss: 1.3129000663757324, avg loss: 1.302917981147766\n",
      "trial: 5, iter: 6000, curr loss: 1.2871447801589966, avg loss: 1.3021409446001053\n",
      "trial: 5, iter: 6200, curr loss: 1.294802188873291, avg loss: 1.299448183774948\n",
      "trial: 5, ldr: 0.24292367696762085\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2630289554595947\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386837124824524, avg loss: 1.3871826803684235\n",
      "trial: 1, iter: 400, curr loss: 1.3842841386795044, avg loss: 1.3868478065729142\n",
      "trial: 1, iter: 600, curr loss: 1.3869915008544922, avg loss: 1.3864477586746216\n",
      "trial: 1, iter: 800, curr loss: 1.3876806497573853, avg loss: 1.3861956954002381\n",
      "trial: 1, iter: 1000, curr loss: 1.3827136754989624, avg loss: 1.3857945930957793\n",
      "trial: 1, iter: 1200, curr loss: 1.3843472003936768, avg loss: 1.3836979484558105\n",
      "trial: 1, iter: 1400, curr loss: 1.3710819482803345, avg loss: 1.376250404715538\n",
      "trial: 1, iter: 1600, curr loss: 1.3643916845321655, avg loss: 1.3682395535707474\n",
      "trial: 1, iter: 1800, curr loss: 1.3631166219711304, avg loss: 1.3640081369876862\n",
      "trial: 1, iter: 2000, curr loss: 1.3733470439910889, avg loss: 1.361775932908058\n",
      "trial: 1, iter: 2200, curr loss: 1.3687032461166382, avg loss: 1.357499048113823\n",
      "trial: 1, iter: 2400, curr loss: 1.3572334051132202, avg loss: 1.3557728385925294\n",
      "trial: 1, iter: 2600, curr loss: 1.3371800184249878, avg loss: 1.3503313100337981\n",
      "trial: 1, iter: 2800, curr loss: 1.3371273279190063, avg loss: 1.3427632391452788\n",
      "trial: 1, iter: 3000, curr loss: 1.3598531484603882, avg loss: 1.3360067242383957\n",
      "trial: 1, iter: 3200, curr loss: 1.325305700302124, avg loss: 1.3302820998430251\n",
      "trial: 1, iter: 3400, curr loss: 1.326554536819458, avg loss: 1.3237349283695221\n",
      "trial: 1, iter: 3600, curr loss: 1.3092730045318604, avg loss: 1.319845877289772\n",
      "trial: 1, iter: 3800, curr loss: 1.3035091161727905, avg loss: 1.3135756188631058\n",
      "trial: 1, iter: 4000, curr loss: 1.3108938932418823, avg loss: 1.3150498479604722\n",
      "trial: 1, iter: 4200, curr loss: 1.2978283166885376, avg loss: 1.3147191035747527\n",
      "trial: 1, iter: 4400, curr loss: 1.3133432865142822, avg loss: 1.3136898112297057\n",
      "trial: 1, iter: 4600, curr loss: 1.2847398519515991, avg loss: 1.310307035446167\n",
      "trial: 1, iter: 4800, curr loss: 1.319872498512268, avg loss: 1.310390059351921\n",
      "trial: 1, iter: 5000, curr loss: 1.2988840341567993, avg loss: 1.3079023689031601\n",
      "trial: 1, iter: 5200, curr loss: 1.3073971271514893, avg loss: 1.3075681787729263\n",
      "trial: 1, iter: 5400, curr loss: 1.2980161905288696, avg loss: 1.3028614073991776\n",
      "trial: 1, iter: 5600, curr loss: 1.3051689863204956, avg loss: 1.3018477267026902\n",
      "trial: 1, iter: 5800, curr loss: 1.3361414670944214, avg loss: 1.29907332777977\n",
      "trial: 1, iter: 6000, curr loss: 1.2974764108657837, avg loss: 1.3010392910242081\n",
      "trial: 1, iter: 6200, curr loss: 1.3325464725494385, avg loss: 1.2965525531768798\n",
      "trial: 1, ldr: 0.2523151636123657\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3871097564697266, avg loss: 1.3872867500782013\n",
      "trial: 2, iter: 400, curr loss: 1.3878618478775024, avg loss: 1.3866807752847672\n",
      "trial: 2, iter: 600, curr loss: 1.3832453489303589, avg loss: 1.386228142976761\n",
      "trial: 2, iter: 800, curr loss: 1.3694279193878174, avg loss: 1.3810754436254502\n",
      "trial: 2, iter: 1000, curr loss: 1.3608307838439941, avg loss: 1.3710698121786118\n",
      "trial: 2, iter: 1200, curr loss: 1.3784312009811401, avg loss: 1.3667687267065047\n",
      "trial: 2, iter: 1400, curr loss: 1.393968105316162, avg loss: 1.361862655878067\n",
      "trial: 2, iter: 1600, curr loss: 1.3548362255096436, avg loss: 1.3565031534433365\n",
      "trial: 2, iter: 1800, curr loss: 1.33126699924469, avg loss: 1.3509570735692977\n",
      "trial: 2, iter: 2000, curr loss: 1.3441702127456665, avg loss: 1.3438712465763092\n",
      "trial: 2, iter: 2200, curr loss: 1.3315489292144775, avg loss: 1.339117892384529\n",
      "trial: 2, iter: 2400, curr loss: 1.3374155759811401, avg loss: 1.3345494556427002\n",
      "trial: 2, iter: 2600, curr loss: 1.3215380907058716, avg loss: 1.3273695313930511\n",
      "trial: 2, iter: 2800, curr loss: 1.31047523021698, avg loss: 1.326837095618248\n",
      "trial: 2, iter: 3000, curr loss: 1.2989435195922852, avg loss: 1.3216583514213562\n",
      "trial: 2, iter: 3200, curr loss: 1.3305399417877197, avg loss: 1.317386618256569\n",
      "trial: 2, iter: 3400, curr loss: 1.3427811861038208, avg loss: 1.3149355512857437\n",
      "trial: 2, iter: 3600, curr loss: 1.3498690128326416, avg loss: 1.3158821427822114\n",
      "trial: 2, iter: 3800, curr loss: 1.306131362915039, avg loss: 1.3129456168413163\n",
      "trial: 2, iter: 4000, curr loss: 1.3244682550430298, avg loss: 1.3117245411872864\n",
      "trial: 2, iter: 4200, curr loss: 1.3035595417022705, avg loss: 1.3104491931200029\n",
      "trial: 2, iter: 4400, curr loss: 1.2912201881408691, avg loss: 1.3089797806739807\n",
      "trial: 2, iter: 4600, curr loss: 1.3558896780014038, avg loss: 1.3082088339328766\n",
      "trial: 2, iter: 4800, curr loss: 1.3022502660751343, avg loss: 1.3093586039543152\n",
      "trial: 2, iter: 5000, curr loss: 1.3038605451583862, avg loss: 1.3038030433654786\n",
      "trial: 2, iter: 5200, curr loss: 1.2785425186157227, avg loss: 1.3038030457496643\n",
      "trial: 2, iter: 5400, curr loss: 1.3067141771316528, avg loss: 1.301648309826851\n",
      "trial: 2, iter: 5600, curr loss: 1.3028022050857544, avg loss: 1.3039688420295716\n",
      "trial: 2, iter: 5800, curr loss: 1.3165768384933472, avg loss: 1.3007987892627717\n",
      "trial: 2, iter: 6000, curr loss: 1.2875754833221436, avg loss: 1.302698121070862\n",
      "trial: 2, iter: 6200, curr loss: 1.290125846862793, avg loss: 1.2992486608028413\n",
      "trial: 2, ldr: 0.3168438971042633\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3866270780563354, avg loss: 1.3872249525785447\n",
      "trial: 3, iter: 400, curr loss: 1.3892656564712524, avg loss: 1.3866818863153458\n",
      "trial: 3, iter: 600, curr loss: 1.3849104642868042, avg loss: 1.3861465364694596\n",
      "trial: 3, iter: 800, curr loss: 1.3820720911026, avg loss: 1.384365965127945\n",
      "trial: 3, iter: 1000, curr loss: 1.3765910863876343, avg loss: 1.3745176178216933\n",
      "trial: 3, iter: 1200, curr loss: 1.3709969520568848, avg loss: 1.3654303967952728\n",
      "trial: 3, iter: 1400, curr loss: 1.358496069908142, avg loss: 1.36120740711689\n",
      "trial: 3, iter: 1600, curr loss: 1.3380876779556274, avg loss: 1.3587134611606597\n",
      "trial: 3, iter: 1800, curr loss: 1.3571135997772217, avg loss: 1.356879603266716\n",
      "trial: 3, iter: 2000, curr loss: 1.342531681060791, avg loss: 1.3516177946329118\n",
      "trial: 3, iter: 2200, curr loss: 1.3228371143341064, avg loss: 1.3404632407426833\n",
      "trial: 3, iter: 2400, curr loss: 1.3496545553207397, avg loss: 1.3348915672302246\n",
      "trial: 3, iter: 2600, curr loss: 1.2977782487869263, avg loss: 1.3290475815534593\n",
      "trial: 3, iter: 2800, curr loss: 1.3573215007781982, avg loss: 1.326650463938713\n",
      "trial: 3, iter: 3000, curr loss: 1.3372725248336792, avg loss: 1.3237840497493745\n",
      "trial: 3, iter: 3200, curr loss: 1.3520216941833496, avg loss: 1.3194411194324493\n",
      "trial: 3, iter: 3400, curr loss: 1.288256287574768, avg loss: 1.316745207309723\n",
      "trial: 3, iter: 3600, curr loss: 1.3062528371810913, avg loss: 1.3119918543100357\n",
      "trial: 3, iter: 3800, curr loss: 1.3155075311660767, avg loss: 1.3129666763544083\n",
      "trial: 3, iter: 4000, curr loss: 1.2751635313034058, avg loss: 1.3112496942281724\n",
      "trial: 3, iter: 4200, curr loss: 1.3037614822387695, avg loss: 1.3105043691396714\n",
      "trial: 3, iter: 4400, curr loss: 1.3381320238113403, avg loss: 1.3079046761989594\n",
      "trial: 3, iter: 4600, curr loss: 1.271527647972107, avg loss: 1.307562109231949\n",
      "trial: 3, iter: 4800, curr loss: 1.321265697479248, avg loss: 1.3053715097904206\n",
      "trial: 3, iter: 5000, curr loss: 1.3260177373886108, avg loss: 1.3073584568500518\n",
      "trial: 3, iter: 5200, curr loss: 1.293573021888733, avg loss: 1.3023752480745316\n",
      "trial: 3, iter: 5400, curr loss: 1.2887895107269287, avg loss: 1.303504495024681\n",
      "trial: 3, iter: 5600, curr loss: 1.3256819248199463, avg loss: 1.304447392821312\n",
      "trial: 3, iter: 5800, curr loss: 1.2960424423217773, avg loss: 1.3013305550813674\n",
      "trial: 3, iter: 6000, curr loss: 1.2866710424423218, avg loss: 1.299573096036911\n",
      "trial: 3, iter: 6200, curr loss: 1.2897318601608276, avg loss: 1.3003891587257386\n",
      "trial: 3, ldr: 0.259804368019104\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386511206626892, avg loss: 1.387459754347801\n",
      "trial: 4, iter: 400, curr loss: 1.383864164352417, avg loss: 1.386665137410164\n",
      "trial: 4, iter: 600, curr loss: 1.3855221271514893, avg loss: 1.3863646709918975\n",
      "trial: 4, iter: 800, curr loss: 1.3857686519622803, avg loss: 1.3854765421152115\n",
      "trial: 4, iter: 1000, curr loss: 1.38850998878479, avg loss: 1.3787986463308335\n",
      "trial: 4, iter: 1200, curr loss: 1.3470460176467896, avg loss: 1.3685433763265609\n",
      "trial: 4, iter: 1400, curr loss: 1.3732893466949463, avg loss: 1.3646370071172713\n",
      "trial: 4, iter: 1600, curr loss: 1.3545305728912354, avg loss: 1.3590632593631744\n",
      "trial: 4, iter: 1800, curr loss: 1.3575712442398071, avg loss: 1.3558754575252534\n",
      "trial: 4, iter: 2000, curr loss: 1.3409405946731567, avg loss: 1.3493806970119477\n",
      "trial: 4, iter: 2200, curr loss: 1.3599302768707275, avg loss: 1.3401598578691483\n",
      "trial: 4, iter: 2400, curr loss: 1.3324579000473022, avg loss: 1.335720370411873\n",
      "trial: 4, iter: 2600, curr loss: 1.3353850841522217, avg loss: 1.3315098512172698\n",
      "trial: 4, iter: 2800, curr loss: 1.3544937372207642, avg loss: 1.326734492778778\n",
      "trial: 4, iter: 3000, curr loss: 1.3362277746200562, avg loss: 1.3221895676851272\n",
      "trial: 4, iter: 3200, curr loss: 1.3174030780792236, avg loss: 1.3222521352767944\n",
      "trial: 4, iter: 3400, curr loss: 1.317521095275879, avg loss: 1.3187541806697844\n",
      "trial: 4, iter: 3600, curr loss: 1.3331528902053833, avg loss: 1.3168700510263442\n",
      "trial: 4, iter: 3800, curr loss: 1.2864214181900024, avg loss: 1.3146427583694458\n",
      "trial: 4, iter: 4000, curr loss: 1.3172154426574707, avg loss: 1.3126645129919052\n",
      "trial: 4, iter: 4200, curr loss: 1.2948817014694214, avg loss: 1.3098597353696824\n",
      "trial: 4, iter: 4400, curr loss: 1.3169447183609009, avg loss: 1.3061541712284088\n",
      "trial: 4, iter: 4600, curr loss: 1.3649566173553467, avg loss: 1.3077755641937256\n",
      "trial: 4, iter: 4800, curr loss: 1.270751714706421, avg loss: 1.3029412889480592\n",
      "trial: 4, iter: 5000, curr loss: 1.2896071672439575, avg loss: 1.3011962705850602\n",
      "trial: 4, iter: 5200, curr loss: 1.268170952796936, avg loss: 1.3003406774997712\n",
      "trial: 4, iter: 5400, curr loss: 1.3153067827224731, avg loss: 1.299094244837761\n",
      "trial: 4, iter: 5600, curr loss: 1.331773042678833, avg loss: 1.2983462554216385\n",
      "trial: 4, iter: 5800, curr loss: 1.3230571746826172, avg loss: 1.296575762629509\n",
      "trial: 4, iter: 6000, curr loss: 1.2970733642578125, avg loss: 1.2989197885990142\n",
      "trial: 4, iter: 6200, curr loss: 1.3013983964920044, avg loss: 1.297163752913475\n",
      "trial: 4, ldr: 0.33386942744255066\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3879148960113525, avg loss: 1.3873266571760177\n",
      "trial: 5, iter: 400, curr loss: 1.3893250226974487, avg loss: 1.3865598875284195\n",
      "trial: 5, iter: 600, curr loss: 1.3851499557495117, avg loss: 1.386435294151306\n",
      "trial: 5, iter: 800, curr loss: 1.3866878747940063, avg loss: 1.3861100625991822\n",
      "trial: 5, iter: 1000, curr loss: 1.3822672367095947, avg loss: 1.3834591495990753\n",
      "trial: 5, iter: 1200, curr loss: 1.382551670074463, avg loss: 1.3726038938760758\n",
      "trial: 5, iter: 1400, curr loss: 1.3701186180114746, avg loss: 1.36510395526886\n",
      "trial: 5, iter: 1600, curr loss: 1.368164300918579, avg loss: 1.3624960446357728\n",
      "trial: 5, iter: 1800, curr loss: 1.3882548809051514, avg loss: 1.3565296447277069\n",
      "trial: 5, iter: 2000, curr loss: 1.332227110862732, avg loss: 1.3536485302448273\n",
      "trial: 5, iter: 2200, curr loss: 1.3539457321166992, avg loss: 1.3476931273937225\n",
      "trial: 5, iter: 2400, curr loss: 1.355326771736145, avg loss: 1.3390287870168687\n",
      "trial: 5, iter: 2600, curr loss: 1.3832181692123413, avg loss: 1.3358501118421555\n",
      "trial: 5, iter: 2800, curr loss: 1.3305116891860962, avg loss: 1.3309550780057906\n",
      "trial: 5, iter: 3000, curr loss: 1.3027832508087158, avg loss: 1.3261474907398223\n",
      "trial: 5, iter: 3200, curr loss: 1.2963087558746338, avg loss: 1.325185139775276\n",
      "trial: 5, iter: 3400, curr loss: 1.309049129486084, avg loss: 1.3228389275074006\n",
      "trial: 5, iter: 3600, curr loss: 1.3181978464126587, avg loss: 1.3174274969100952\n",
      "trial: 5, iter: 3800, curr loss: 1.3338887691497803, avg loss: 1.3158257138729095\n",
      "trial: 5, iter: 4000, curr loss: 1.33111572265625, avg loss: 1.3159209501743316\n",
      "trial: 5, iter: 4200, curr loss: 1.3222671747207642, avg loss: 1.313987935781479\n",
      "trial: 5, iter: 4400, curr loss: 1.275168538093567, avg loss: 1.3114145177602767\n",
      "trial: 5, iter: 4600, curr loss: 1.339373230934143, avg loss: 1.3108309936523437\n",
      "trial: 5, iter: 4800, curr loss: 1.283543586730957, avg loss: 1.3103295934200287\n",
      "trial: 5, iter: 5000, curr loss: 1.2932320833206177, avg loss: 1.3059870994091034\n",
      "trial: 5, iter: 5200, curr loss: 1.2672920227050781, avg loss: 1.304829755425453\n",
      "trial: 5, iter: 5400, curr loss: 1.2976120710372925, avg loss: 1.3092786407470702\n",
      "trial: 5, iter: 5600, curr loss: 1.3037339448928833, avg loss: 1.3062600976228713\n",
      "trial: 5, iter: 5800, curr loss: 1.3313437700271606, avg loss: 1.3039812433719635\n",
      "trial: 5, iter: 6000, curr loss: 1.3110913038253784, avg loss: 1.3023207926750182\n",
      "trial: 5, iter: 6200, curr loss: 1.2788633108139038, avg loss: 1.3019797682762146\n",
      "trial: 5, ldr: 0.272565096616745\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2870795905590057\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3885356187820435, avg loss: 1.3874694156646727\n",
      "trial: 1, iter: 400, curr loss: 1.3866580724716187, avg loss: 1.3866443991661073\n",
      "trial: 1, iter: 600, curr loss: 1.3855403661727905, avg loss: 1.3863947463035584\n",
      "trial: 1, iter: 800, curr loss: 1.3856465816497803, avg loss: 1.385781826376915\n",
      "trial: 1, iter: 1000, curr loss: 1.3751113414764404, avg loss: 1.3823219335079193\n",
      "trial: 1, iter: 1200, curr loss: 1.377999186515808, avg loss: 1.3769949644804\n",
      "trial: 1, iter: 1400, curr loss: 1.3643354177474976, avg loss: 1.3710573226213456\n",
      "trial: 1, iter: 1600, curr loss: 1.362526297569275, avg loss: 1.3676703435182571\n",
      "trial: 1, iter: 1800, curr loss: 1.3597232103347778, avg loss: 1.3651018661260605\n",
      "trial: 1, iter: 2000, curr loss: 1.3604851961135864, avg loss: 1.361904878616333\n",
      "trial: 1, iter: 2200, curr loss: 1.347716212272644, avg loss: 1.360056346654892\n",
      "trial: 1, iter: 2400, curr loss: 1.3459583520889282, avg loss: 1.3569815802574157\n",
      "trial: 1, iter: 2600, curr loss: 1.3477808237075806, avg loss: 1.3514301258325576\n",
      "trial: 1, iter: 2800, curr loss: 1.330069899559021, avg loss: 1.341042065024376\n",
      "trial: 1, iter: 3000, curr loss: 1.3499287366867065, avg loss: 1.3369361227750778\n",
      "trial: 1, iter: 3200, curr loss: 1.3221992254257202, avg loss: 1.330945253968239\n",
      "trial: 1, iter: 3400, curr loss: 1.3232250213623047, avg loss: 1.3252675604820252\n",
      "trial: 1, iter: 3600, curr loss: 1.3303910493850708, avg loss: 1.3242140167951584\n",
      "trial: 1, iter: 3800, curr loss: 1.3110746145248413, avg loss: 1.3186048197746276\n",
      "trial: 1, iter: 4000, curr loss: 1.3318581581115723, avg loss: 1.315819666981697\n",
      "trial: 1, iter: 4200, curr loss: 1.308440923690796, avg loss: 1.3154490667581558\n",
      "trial: 1, iter: 4400, curr loss: 1.30741548538208, avg loss: 1.313259125351906\n",
      "trial: 1, iter: 4600, curr loss: 1.3084672689437866, avg loss: 1.3126599669456482\n",
      "trial: 1, iter: 4800, curr loss: 1.2860277891159058, avg loss: 1.314331533908844\n",
      "trial: 1, iter: 5000, curr loss: 1.2877229452133179, avg loss: 1.308905254006386\n",
      "trial: 1, iter: 5200, curr loss: 1.3047516345977783, avg loss: 1.3084687900543213\n",
      "trial: 1, iter: 5400, curr loss: 1.3154222965240479, avg loss: 1.306176671385765\n",
      "trial: 1, iter: 5600, curr loss: 1.301656723022461, avg loss: 1.3043871694803237\n",
      "trial: 1, iter: 5800, curr loss: 1.300250768661499, avg loss: 1.3034950292110443\n",
      "trial: 1, iter: 6000, curr loss: 1.288879632949829, avg loss: 1.3026154774427414\n",
      "trial: 1, iter: 6200, curr loss: 1.2740309238433838, avg loss: 1.3009029978513718\n",
      "trial: 1, ldr: 0.3103606700897217\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3861076831817627, avg loss: 1.3868156343698501\n",
      "trial: 2, iter: 400, curr loss: 1.3871999979019165, avg loss: 1.3865408629179001\n",
      "trial: 2, iter: 600, curr loss: 1.3884235620498657, avg loss: 1.3863295060396195\n",
      "trial: 2, iter: 800, curr loss: 1.3820104598999023, avg loss: 1.3850266951322556\n",
      "trial: 2, iter: 1000, curr loss: 1.376099705696106, avg loss: 1.3812955135107041\n",
      "trial: 2, iter: 1200, curr loss: 1.3755114078521729, avg loss: 1.3780785930156707\n",
      "trial: 2, iter: 1400, curr loss: 1.3777830600738525, avg loss: 1.3716589099168777\n",
      "trial: 2, iter: 1600, curr loss: 1.3656326532363892, avg loss: 1.3669913810491563\n",
      "trial: 2, iter: 1800, curr loss: 1.3467357158660889, avg loss: 1.3659188854694366\n",
      "trial: 2, iter: 2000, curr loss: 1.3706318140029907, avg loss: 1.365071519613266\n",
      "trial: 2, iter: 2200, curr loss: 1.3522313833236694, avg loss: 1.362116522192955\n",
      "trial: 2, iter: 2400, curr loss: 1.3764700889587402, avg loss: 1.3584334766864776\n",
      "trial: 2, iter: 2600, curr loss: 1.3509398698806763, avg loss: 1.3560164791345597\n",
      "trial: 2, iter: 2800, curr loss: 1.347727656364441, avg loss: 1.3514854300022126\n",
      "trial: 2, iter: 3000, curr loss: 1.3423959016799927, avg loss: 1.3418849802017212\n",
      "trial: 2, iter: 3200, curr loss: 1.3676155805587769, avg loss: 1.3377052980661392\n",
      "trial: 2, iter: 3400, curr loss: 1.3588509559631348, avg loss: 1.336532819867134\n",
      "trial: 2, iter: 3600, curr loss: 1.33830726146698, avg loss: 1.332582604289055\n",
      "trial: 2, iter: 3800, curr loss: 1.3457057476043701, avg loss: 1.3274786788225175\n",
      "trial: 2, iter: 4000, curr loss: 1.3453916311264038, avg loss: 1.3247501593828201\n",
      "trial: 2, iter: 4200, curr loss: 1.3272998332977295, avg loss: 1.3218573021888733\n",
      "trial: 2, iter: 4400, curr loss: 1.3310621976852417, avg loss: 1.3214479547739029\n",
      "trial: 2, iter: 4600, curr loss: 1.298794150352478, avg loss: 1.3152039015293122\n",
      "trial: 2, iter: 4800, curr loss: 1.3005682229995728, avg loss: 1.3156856286525727\n",
      "trial: 2, iter: 5000, curr loss: 1.2915138006210327, avg loss: 1.3125104612112046\n",
      "trial: 2, iter: 5200, curr loss: 1.3289471864700317, avg loss: 1.3120135480165482\n",
      "trial: 2, iter: 5400, curr loss: 1.326045036315918, avg loss: 1.3072746175527572\n",
      "trial: 2, iter: 5600, curr loss: 1.295457363128662, avg loss: 1.307846245765686\n",
      "trial: 2, iter: 5800, curr loss: 1.2888157367706299, avg loss: 1.3038793647289275\n",
      "trial: 2, iter: 6000, curr loss: 1.3226017951965332, avg loss: 1.3034892815351486\n",
      "trial: 2, iter: 6200, curr loss: 1.2955111265182495, avg loss: 1.305249779820442\n",
      "trial: 2, ldr: 0.26299920678138733\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3916212320327759, avg loss: 1.387277575135231\n",
      "trial: 3, iter: 400, curr loss: 1.3852834701538086, avg loss: 1.3868239480257034\n",
      "trial: 3, iter: 600, curr loss: 1.3850641250610352, avg loss: 1.386409957408905\n",
      "trial: 3, iter: 800, curr loss: 1.3843555450439453, avg loss: 1.3860254883766174\n",
      "trial: 3, iter: 1000, curr loss: 1.378037452697754, avg loss: 1.3812862432003021\n",
      "trial: 3, iter: 1200, curr loss: 1.376656174659729, avg loss: 1.3724281311035156\n",
      "trial: 3, iter: 1400, curr loss: 1.3628424406051636, avg loss: 1.367912656068802\n",
      "trial: 3, iter: 1600, curr loss: 1.3653497695922852, avg loss: 1.361878177523613\n",
      "trial: 3, iter: 1800, curr loss: 1.3665969371795654, avg loss: 1.3602502620220185\n",
      "trial: 3, iter: 2000, curr loss: 1.3693547248840332, avg loss: 1.3550866401195527\n",
      "trial: 3, iter: 2200, curr loss: 1.3310096263885498, avg loss: 1.3499781435728073\n",
      "trial: 3, iter: 2400, curr loss: 1.3422013521194458, avg loss: 1.340161637067795\n",
      "trial: 3, iter: 2600, curr loss: 1.373068928718567, avg loss: 1.331367642879486\n",
      "trial: 3, iter: 2800, curr loss: 1.3569748401641846, avg loss: 1.3292723155021668\n",
      "trial: 3, iter: 3000, curr loss: 1.3158007860183716, avg loss: 1.3265318328142166\n",
      "trial: 3, iter: 3200, curr loss: 1.3284927606582642, avg loss: 1.3231099212169648\n",
      "trial: 3, iter: 3400, curr loss: 1.2950853109359741, avg loss: 1.3201223933696746\n",
      "trial: 3, iter: 3600, curr loss: 1.3237839937210083, avg loss: 1.3168905138969422\n",
      "trial: 3, iter: 3800, curr loss: 1.3302185535430908, avg loss: 1.3158248788118363\n",
      "trial: 3, iter: 4000, curr loss: 1.283308982849121, avg loss: 1.3159546947479248\n",
      "trial: 3, iter: 4200, curr loss: 1.2826422452926636, avg loss: 1.3102077782154082\n",
      "trial: 3, iter: 4400, curr loss: 1.3126338720321655, avg loss: 1.31362287402153\n",
      "trial: 3, iter: 4600, curr loss: 1.3072171211242676, avg loss: 1.310003826022148\n",
      "trial: 3, iter: 4800, curr loss: 1.294480562210083, avg loss: 1.3072742038965226\n",
      "trial: 3, iter: 5000, curr loss: 1.310060739517212, avg loss: 1.3065435761213302\n",
      "trial: 3, iter: 5200, curr loss: 1.3354499340057373, avg loss: 1.3078339326381683\n",
      "trial: 3, iter: 5400, curr loss: 1.2690211534500122, avg loss: 1.3065693998336791\n",
      "trial: 3, iter: 5600, curr loss: 1.2896755933761597, avg loss: 1.3054312926530838\n",
      "trial: 3, iter: 5800, curr loss: 1.3042006492614746, avg loss: 1.3028227186203003\n",
      "trial: 3, iter: 6000, curr loss: 1.3137531280517578, avg loss: 1.3047588616609573\n",
      "trial: 3, iter: 6200, curr loss: 1.303285002708435, avg loss: 1.3019314068555832\n",
      "trial: 3, ldr: 0.2265578657388687\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386997938156128, avg loss: 1.3870987647771835\n",
      "trial: 4, iter: 400, curr loss: 1.3865605592727661, avg loss: 1.386774794459343\n",
      "trial: 4, iter: 600, curr loss: 1.387330412864685, avg loss: 1.3862821036577224\n",
      "trial: 4, iter: 800, curr loss: 1.3849687576293945, avg loss: 1.3863457095623017\n",
      "trial: 4, iter: 1000, curr loss: 1.3851144313812256, avg loss: 1.3861191779375077\n",
      "trial: 4, iter: 1200, curr loss: 1.377105474472046, avg loss: 1.383972744345665\n",
      "trial: 4, iter: 1400, curr loss: 1.3678581714630127, avg loss: 1.3755724620819092\n",
      "trial: 4, iter: 1600, curr loss: 1.39609956741333, avg loss: 1.3678413385152817\n",
      "trial: 4, iter: 1800, curr loss: 1.3569061756134033, avg loss: 1.3652126950025558\n",
      "trial: 4, iter: 2000, curr loss: 1.3875367641448975, avg loss: 1.3610747665166856\n",
      "trial: 4, iter: 2200, curr loss: 1.3621865510940552, avg loss: 1.3574512219429016\n",
      "trial: 4, iter: 2400, curr loss: 1.3596502542495728, avg loss: 1.353864912390709\n",
      "trial: 4, iter: 2600, curr loss: 1.3419288396835327, avg loss: 1.3457266724109649\n",
      "trial: 4, iter: 2800, curr loss: 1.3196227550506592, avg loss: 1.3383106541633607\n",
      "trial: 4, iter: 3000, curr loss: 1.3353122472763062, avg loss: 1.3320510303974151\n",
      "trial: 4, iter: 3200, curr loss: 1.3218847513198853, avg loss: 1.3282868856191634\n",
      "trial: 4, iter: 3400, curr loss: 1.3390909433364868, avg loss: 1.32581461250782\n",
      "trial: 4, iter: 3600, curr loss: 1.3081014156341553, avg loss: 1.3231022000312804\n",
      "trial: 4, iter: 3800, curr loss: 1.3366785049438477, avg loss: 1.3187114411592484\n",
      "trial: 4, iter: 4000, curr loss: 1.343555212020874, avg loss: 1.3172086405754089\n",
      "trial: 4, iter: 4200, curr loss: 1.2946114540100098, avg loss: 1.3161074525117875\n",
      "trial: 4, iter: 4400, curr loss: 1.3141157627105713, avg loss: 1.3129059046506881\n",
      "trial: 4, iter: 4600, curr loss: 1.2917219400405884, avg loss: 1.3111535120010376\n",
      "trial: 4, iter: 4800, curr loss: 1.2941174507141113, avg loss: 1.3073274433612823\n",
      "trial: 4, iter: 5000, curr loss: 1.3132014274597168, avg loss: 1.3112782424688338\n",
      "trial: 4, iter: 5200, curr loss: 1.3040815591812134, avg loss: 1.3057063919305802\n",
      "trial: 4, iter: 5400, curr loss: 1.3086178302764893, avg loss: 1.3065895354747772\n",
      "trial: 4, iter: 5600, curr loss: 1.322591781616211, avg loss: 1.3040053927898407\n",
      "trial: 4, iter: 5800, curr loss: 1.3159620761871338, avg loss: 1.30318840444088\n",
      "trial: 4, iter: 6000, curr loss: 1.310492992401123, avg loss: 1.3043373000621796\n",
      "trial: 4, iter: 6200, curr loss: 1.3128857612609863, avg loss: 1.2982542288303376\n",
      "trial: 4, ldr: 0.26778915524482727\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3879095315933228, avg loss: 1.3871688330173493\n",
      "trial: 5, iter: 400, curr loss: 1.3872889280319214, avg loss: 1.386662529706955\n",
      "trial: 5, iter: 600, curr loss: 1.3872264623641968, avg loss: 1.3862012100219727\n",
      "trial: 5, iter: 800, curr loss: 1.3714323043823242, avg loss: 1.3825014328956604\n",
      "trial: 5, iter: 1000, curr loss: 1.3654673099517822, avg loss: 1.3712933909893037\n",
      "trial: 5, iter: 1200, curr loss: 1.3623135089874268, avg loss: 1.3655150598287582\n",
      "trial: 5, iter: 1400, curr loss: 1.3487398624420166, avg loss: 1.3612081432342529\n",
      "trial: 5, iter: 1600, curr loss: 1.3515785932540894, avg loss: 1.3596762019395827\n",
      "trial: 5, iter: 1800, curr loss: 1.3500005006790161, avg loss: 1.3538668769598008\n",
      "trial: 5, iter: 2000, curr loss: 1.316996455192566, avg loss: 1.346782375574112\n",
      "trial: 5, iter: 2200, curr loss: 1.337292194366455, avg loss: 1.3415737414360047\n",
      "trial: 5, iter: 2400, curr loss: 1.3411012887954712, avg loss: 1.3356904208660125\n",
      "trial: 5, iter: 2600, curr loss: 1.3089966773986816, avg loss: 1.3276686155796051\n",
      "trial: 5, iter: 2800, curr loss: 1.3140103816986084, avg loss: 1.3266912001371383\n",
      "trial: 5, iter: 3000, curr loss: 1.324278712272644, avg loss: 1.3229978215694427\n",
      "trial: 5, iter: 3200, curr loss: 1.3214631080627441, avg loss: 1.3218402820825577\n",
      "trial: 5, iter: 3400, curr loss: 1.292985200881958, avg loss: 1.318519784808159\n",
      "trial: 5, iter: 3600, curr loss: 1.2990472316741943, avg loss: 1.3137060701847076\n",
      "trial: 5, iter: 3800, curr loss: 1.279384732246399, avg loss: 1.3165212225914003\n",
      "trial: 5, iter: 4000, curr loss: 1.2939153909683228, avg loss: 1.3116709047555923\n",
      "trial: 5, iter: 4200, curr loss: 1.3336104154586792, avg loss: 1.3118398487567902\n",
      "trial: 5, iter: 4400, curr loss: 1.3439419269561768, avg loss: 1.308525425195694\n",
      "trial: 5, iter: 4600, curr loss: 1.297340989112854, avg loss: 1.310298421382904\n",
      "trial: 5, iter: 4800, curr loss: 1.2967532873153687, avg loss: 1.310232316851616\n",
      "trial: 5, iter: 5000, curr loss: 1.3090404272079468, avg loss: 1.3075911700725555\n",
      "trial: 5, iter: 5200, curr loss: 1.323462724685669, avg loss: 1.3050855749845505\n",
      "trial: 5, iter: 5400, curr loss: 1.2777397632598877, avg loss: 1.3045925092697144\n",
      "trial: 5, iter: 5600, curr loss: 1.2894338369369507, avg loss: 1.304326302409172\n",
      "trial: 5, iter: 5800, curr loss: 1.3164434432983398, avg loss: 1.2998985570669175\n",
      "trial: 5, iter: 6000, curr loss: 1.315406322479248, avg loss: 1.302652575969696\n",
      "trial: 5, iter: 6200, curr loss: 1.3040467500686646, avg loss: 1.2993386745452882\n",
      "trial: 5, ldr: 0.25462955236434937\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26446729004383085\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3885759115219116, avg loss: 1.3874062287807465\n",
      "trial: 1, iter: 400, curr loss: 1.3856006860733032, avg loss: 1.386652764081955\n",
      "trial: 1, iter: 600, curr loss: 1.386985182762146, avg loss: 1.3866057372093201\n",
      "trial: 1, iter: 800, curr loss: 1.3863030672073364, avg loss: 1.3860856837034226\n",
      "trial: 1, iter: 1000, curr loss: 1.3817224502563477, avg loss: 1.3845471113920211\n",
      "trial: 1, iter: 1200, curr loss: 1.3732529878616333, avg loss: 1.3739324098825454\n",
      "trial: 1, iter: 1400, curr loss: 1.3665516376495361, avg loss: 1.3652442520856858\n",
      "trial: 1, iter: 1600, curr loss: 1.3655775785446167, avg loss: 1.3625070494413376\n",
      "trial: 1, iter: 1800, curr loss: 1.3651762008666992, avg loss: 1.357423084974289\n",
      "trial: 1, iter: 2000, curr loss: 1.3479129076004028, avg loss: 1.3508835405111312\n",
      "trial: 1, iter: 2200, curr loss: 1.332045555114746, avg loss: 1.3445438307523727\n",
      "trial: 1, iter: 2400, curr loss: 1.3300743103027344, avg loss: 1.337768549323082\n",
      "trial: 1, iter: 2600, curr loss: 1.3391854763031006, avg loss: 1.3341945117712022\n",
      "trial: 1, iter: 2800, curr loss: 1.3074265718460083, avg loss: 1.3281689560413361\n",
      "trial: 1, iter: 3000, curr loss: 1.3037701845169067, avg loss: 1.3242873859405517\n",
      "trial: 1, iter: 3200, curr loss: 1.2986810207366943, avg loss: 1.3216088289022445\n",
      "trial: 1, iter: 3400, curr loss: 1.3328090906143188, avg loss: 1.3196520870923996\n",
      "trial: 1, iter: 3600, curr loss: 1.2994238138198853, avg loss: 1.315063451528549\n",
      "trial: 1, iter: 3800, curr loss: 1.2820358276367188, avg loss: 1.3127302926778794\n",
      "trial: 1, iter: 4000, curr loss: 1.3009854555130005, avg loss: 1.3127539569139481\n",
      "trial: 1, iter: 4200, curr loss: 1.2858836650848389, avg loss: 1.3103501427173614\n",
      "trial: 1, iter: 4400, curr loss: 1.3342596292495728, avg loss: 1.3090910053253173\n",
      "trial: 1, iter: 4600, curr loss: 1.305545687675476, avg loss: 1.309086816906929\n",
      "trial: 1, iter: 4800, curr loss: 1.318913459777832, avg loss: 1.3079355585575103\n",
      "trial: 1, iter: 5000, curr loss: 1.3101590871810913, avg loss: 1.3048358523845673\n",
      "trial: 1, iter: 5200, curr loss: 1.359521508216858, avg loss: 1.307015826702118\n",
      "trial: 1, iter: 5400, curr loss: 1.305816888809204, avg loss: 1.3018307185173035\n",
      "trial: 1, iter: 5600, curr loss: 1.3215357065200806, avg loss: 1.3035567164421082\n",
      "trial: 1, iter: 5800, curr loss: 1.3352162837982178, avg loss: 1.2988203144073487\n",
      "trial: 1, iter: 6000, curr loss: 1.2815152406692505, avg loss: 1.2995504784584044\n",
      "trial: 1, iter: 6200, curr loss: 1.2766368389129639, avg loss: 1.301351568698883\n",
      "trial: 1, ldr: 0.2676036059856415\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3897217512130737, avg loss: 1.3876546376943588\n",
      "trial: 2, iter: 400, curr loss: 1.3863985538482666, avg loss: 1.386808574795723\n",
      "trial: 2, iter: 600, curr loss: 1.3857795000076294, avg loss: 1.3863219344615936\n",
      "trial: 2, iter: 800, curr loss: 1.3762067556381226, avg loss: 1.3840244513750077\n",
      "trial: 2, iter: 1000, curr loss: 1.3792856931686401, avg loss: 1.3747296661138535\n",
      "trial: 2, iter: 1200, curr loss: 1.3739970922470093, avg loss: 1.3701732099056243\n",
      "trial: 2, iter: 1400, curr loss: 1.366986632347107, avg loss: 1.3658404242992401\n",
      "trial: 2, iter: 1600, curr loss: 1.3525254726409912, avg loss: 1.3605725264549255\n",
      "trial: 2, iter: 1800, curr loss: 1.3420937061309814, avg loss: 1.3596717774868012\n",
      "trial: 2, iter: 2000, curr loss: 1.3470678329467773, avg loss: 1.351343605518341\n",
      "trial: 2, iter: 2200, curr loss: 1.337365984916687, avg loss: 1.3434389352798461\n",
      "trial: 2, iter: 2400, curr loss: 1.3396527767181396, avg loss: 1.339555870294571\n",
      "trial: 2, iter: 2600, curr loss: 1.3564467430114746, avg loss: 1.3322067219018936\n",
      "trial: 2, iter: 2800, curr loss: 1.3243318796157837, avg loss: 1.3272312706708909\n",
      "trial: 2, iter: 3000, curr loss: 1.2944897413253784, avg loss: 1.3228577888011932\n",
      "trial: 2, iter: 3200, curr loss: 1.3407851457595825, avg loss: 1.3216881668567657\n",
      "trial: 2, iter: 3400, curr loss: 1.3060137033462524, avg loss: 1.319491424560547\n",
      "trial: 2, iter: 3600, curr loss: 1.3255681991577148, avg loss: 1.3135109698772431\n",
      "trial: 2, iter: 3800, curr loss: 1.3272470235824585, avg loss: 1.3156144559383391\n",
      "trial: 2, iter: 4000, curr loss: 1.3037933111190796, avg loss: 1.3120047181844712\n",
      "trial: 2, iter: 4200, curr loss: 1.3153252601623535, avg loss: 1.3107291853427887\n",
      "trial: 2, iter: 4400, curr loss: 1.2840182781219482, avg loss: 1.3117545694112778\n",
      "trial: 2, iter: 4600, curr loss: 1.3100674152374268, avg loss: 1.3083390140533446\n",
      "trial: 2, iter: 4800, curr loss: 1.3175283670425415, avg loss: 1.3090697997808456\n",
      "trial: 2, iter: 5000, curr loss: 1.295701026916504, avg loss: 1.305489946603775\n",
      "trial: 2, iter: 5200, curr loss: 1.2946914434432983, avg loss: 1.3047667157649994\n",
      "trial: 2, iter: 5400, curr loss: 1.3064560890197754, avg loss: 1.3040669405460357\n",
      "trial: 2, iter: 5600, curr loss: 1.2916887998580933, avg loss: 1.3051736825704574\n",
      "trial: 2, iter: 5800, curr loss: 1.2844513654708862, avg loss: 1.3034715968370438\n",
      "trial: 2, iter: 6000, curr loss: 1.285939335823059, avg loss: 1.3018834626674651\n",
      "trial: 2, iter: 6200, curr loss: 1.3165764808654785, avg loss: 1.3019358837604522\n",
      "trial: 2, ldr: 0.23756325244903564\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3837615251541138, avg loss: 1.387486106157303\n",
      "trial: 3, iter: 400, curr loss: 1.3875083923339844, avg loss: 1.3865472817420958\n",
      "trial: 3, iter: 600, curr loss: 1.3821018934249878, avg loss: 1.3853441846370698\n",
      "trial: 3, iter: 800, curr loss: 1.3793549537658691, avg loss: 1.381210158467293\n",
      "trial: 3, iter: 1000, curr loss: 1.3791948556900024, avg loss: 1.3742270147800446\n",
      "trial: 3, iter: 1200, curr loss: 1.3536344766616821, avg loss: 1.3682132863998413\n",
      "trial: 3, iter: 1400, curr loss: 1.3481879234313965, avg loss: 1.3629604029655455\n",
      "trial: 3, iter: 1600, curr loss: 1.3492624759674072, avg loss: 1.3632798677682876\n",
      "trial: 3, iter: 1800, curr loss: 1.3475208282470703, avg loss: 1.359988563656807\n",
      "trial: 3, iter: 2000, curr loss: 1.346112847328186, avg loss: 1.3536454445123673\n",
      "trial: 3, iter: 2200, curr loss: 1.3356283903121948, avg loss: 1.3507971066236495\n",
      "trial: 3, iter: 2400, curr loss: 1.357259750366211, avg loss: 1.3455168068408967\n",
      "trial: 3, iter: 2600, curr loss: 1.3180809020996094, avg loss: 1.3368341779708863\n",
      "trial: 3, iter: 2800, curr loss: 1.3360371589660645, avg loss: 1.3347484600543975\n",
      "trial: 3, iter: 3000, curr loss: 1.3230303525924683, avg loss: 1.3282894366979598\n",
      "trial: 3, iter: 3200, curr loss: 1.3249425888061523, avg loss: 1.323645183444023\n",
      "trial: 3, iter: 3400, curr loss: 1.3097630739212036, avg loss: 1.3207574343681336\n",
      "trial: 3, iter: 3600, curr loss: 1.2988191843032837, avg loss: 1.3172625714540482\n",
      "trial: 3, iter: 3800, curr loss: 1.285337209701538, avg loss: 1.3163321655988693\n",
      "trial: 3, iter: 4000, curr loss: 1.3597996234893799, avg loss: 1.315634982585907\n",
      "trial: 3, iter: 4200, curr loss: 1.2898634672164917, avg loss: 1.3140799081325532\n",
      "trial: 3, iter: 4400, curr loss: 1.29731023311615, avg loss: 1.3143629378080368\n",
      "trial: 3, iter: 4600, curr loss: 1.290694236755371, avg loss: 1.3141280436515808\n",
      "trial: 3, iter: 4800, curr loss: 1.3037079572677612, avg loss: 1.310961377620697\n",
      "trial: 3, iter: 5000, curr loss: 1.2950046062469482, avg loss: 1.3067995643615722\n",
      "trial: 3, iter: 5200, curr loss: 1.3187659978866577, avg loss: 1.3110884094238282\n",
      "trial: 3, iter: 5400, curr loss: 1.3166093826293945, avg loss: 1.3072815269231797\n",
      "trial: 3, iter: 5600, curr loss: 1.2684341669082642, avg loss: 1.306192524433136\n",
      "trial: 3, iter: 5800, curr loss: 1.3090453147888184, avg loss: 1.3052574378252029\n",
      "trial: 3, iter: 6000, curr loss: 1.2844600677490234, avg loss: 1.3065012449026108\n",
      "trial: 3, iter: 6200, curr loss: 1.292782187461853, avg loss: 1.3023741167783738\n",
      "trial: 3, ldr: 0.2974418103694916\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865370750427246, avg loss: 1.387335143685341\n",
      "trial: 4, iter: 400, curr loss: 1.3862985372543335, avg loss: 1.3864912652969361\n",
      "trial: 4, iter: 600, curr loss: 1.3847466707229614, avg loss: 1.3861414885520935\n",
      "trial: 4, iter: 800, curr loss: 1.380413293838501, avg loss: 1.3817937916517258\n",
      "trial: 4, iter: 1000, curr loss: 1.3510096073150635, avg loss: 1.3706790977716445\n",
      "trial: 4, iter: 1200, curr loss: 1.3542557954788208, avg loss: 1.3674413526058198\n",
      "trial: 4, iter: 1400, curr loss: 1.369451880455017, avg loss: 1.362862877845764\n",
      "trial: 4, iter: 1600, curr loss: 1.3572204113006592, avg loss: 1.3589855545759202\n",
      "trial: 4, iter: 1800, curr loss: 1.3718310594558716, avg loss: 1.3530143547058104\n",
      "trial: 4, iter: 2000, curr loss: 1.3628791570663452, avg loss: 1.3472979855537415\n",
      "trial: 4, iter: 2200, curr loss: 1.341065764427185, avg loss: 1.3424976348876954\n",
      "trial: 4, iter: 2400, curr loss: 1.3612524271011353, avg loss: 1.3365682071447373\n",
      "trial: 4, iter: 2600, curr loss: 1.322516679763794, avg loss: 1.332883841395378\n",
      "trial: 4, iter: 2800, curr loss: 1.2948678731918335, avg loss: 1.328800424337387\n",
      "trial: 4, iter: 3000, curr loss: 1.3292076587677002, avg loss: 1.324684928059578\n",
      "trial: 4, iter: 3200, curr loss: 1.3235877752304077, avg loss: 1.3212126231193542\n",
      "trial: 4, iter: 3400, curr loss: 1.3445848226547241, avg loss: 1.3188505858182906\n",
      "trial: 4, iter: 3600, curr loss: 1.328196406364441, avg loss: 1.317233077287674\n",
      "trial: 4, iter: 3800, curr loss: 1.2990728616714478, avg loss: 1.3119480735063553\n",
      "trial: 4, iter: 4000, curr loss: 1.3424419164657593, avg loss: 1.3106080275774001\n",
      "trial: 4, iter: 4200, curr loss: 1.3513131141662598, avg loss: 1.3134208858013152\n",
      "trial: 4, iter: 4400, curr loss: 1.3231449127197266, avg loss: 1.3096666580438614\n",
      "trial: 4, iter: 4600, curr loss: 1.31442129611969, avg loss: 1.3114252358675003\n",
      "trial: 4, iter: 4800, curr loss: 1.2823057174682617, avg loss: 1.305745117664337\n",
      "trial: 4, iter: 5000, curr loss: 1.3408186435699463, avg loss: 1.307957659959793\n",
      "trial: 4, iter: 5200, curr loss: 1.3055380582809448, avg loss: 1.3044172698259353\n",
      "trial: 4, iter: 5400, curr loss: 1.3108240365982056, avg loss: 1.3061463594436646\n",
      "trial: 4, iter: 5600, curr loss: 1.3351781368255615, avg loss: 1.305725831389427\n",
      "trial: 4, iter: 5800, curr loss: 1.3476978540420532, avg loss: 1.3019377464056014\n",
      "trial: 4, iter: 6000, curr loss: 1.3412487506866455, avg loss: 1.3026121324300766\n",
      "trial: 4, iter: 6200, curr loss: 1.3231828212738037, avg loss: 1.2987643903493882\n",
      "trial: 4, ldr: 0.23345695436000824\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3865967988967896, avg loss: 1.3873126834630967\n",
      "trial: 5, iter: 400, curr loss: 1.3895065784454346, avg loss: 1.3865506893396378\n",
      "trial: 5, iter: 600, curr loss: 1.3896220922470093, avg loss: 1.386285321712494\n",
      "trial: 5, iter: 800, curr loss: 1.3794220685958862, avg loss: 1.3844011580944062\n",
      "trial: 5, iter: 1000, curr loss: 1.3691859245300293, avg loss: 1.3735624086856841\n",
      "trial: 5, iter: 1200, curr loss: 1.3554986715316772, avg loss: 1.366319670677185\n",
      "trial: 5, iter: 1400, curr loss: 1.3725618124008179, avg loss: 1.3642144060134889\n",
      "trial: 5, iter: 1600, curr loss: 1.3539934158325195, avg loss: 1.360332993865013\n",
      "trial: 5, iter: 1800, curr loss: 1.3593851327896118, avg loss: 1.3567147547006606\n",
      "trial: 5, iter: 2000, curr loss: 1.352505087852478, avg loss: 1.3502796548604965\n",
      "trial: 5, iter: 2200, curr loss: 1.332445740699768, avg loss: 1.3437225478887558\n",
      "trial: 5, iter: 2400, curr loss: 1.3417673110961914, avg loss: 1.3364966076612472\n",
      "trial: 5, iter: 2600, curr loss: 1.357275366783142, avg loss: 1.3240209817886353\n",
      "trial: 5, iter: 2800, curr loss: 1.3434337377548218, avg loss: 1.3256684339046478\n",
      "trial: 5, iter: 3000, curr loss: 1.308362364768982, avg loss: 1.3214772737026215\n",
      "trial: 5, iter: 3200, curr loss: 1.3203489780426025, avg loss: 1.317583372592926\n",
      "trial: 5, iter: 3400, curr loss: 1.3058412075042725, avg loss: 1.3168193686008454\n",
      "trial: 5, iter: 3600, curr loss: 1.3416428565979004, avg loss: 1.3124048447608947\n",
      "trial: 5, iter: 3800, curr loss: 1.3430404663085938, avg loss: 1.311298090815544\n",
      "trial: 5, iter: 4000, curr loss: 1.31143319606781, avg loss: 1.3103649735450744\n",
      "trial: 5, iter: 4200, curr loss: 1.301759123802185, avg loss: 1.3097498106956482\n",
      "trial: 5, iter: 4400, curr loss: 1.3354458808898926, avg loss: 1.3064243870973586\n",
      "trial: 5, iter: 4600, curr loss: 1.2921552658081055, avg loss: 1.3034548145532607\n",
      "trial: 5, iter: 4800, curr loss: 1.300968885421753, avg loss: 1.3047650724649429\n",
      "trial: 5, iter: 5000, curr loss: 1.3177721500396729, avg loss: 1.301618908047676\n",
      "trial: 5, iter: 5200, curr loss: 1.2790230512619019, avg loss: 1.3004258590936661\n",
      "trial: 5, iter: 5400, curr loss: 1.3435122966766357, avg loss: 1.3036536633968354\n",
      "trial: 5, iter: 5600, curr loss: 1.3159891366958618, avg loss: 1.3000726437568664\n",
      "trial: 5, iter: 5800, curr loss: 1.3250842094421387, avg loss: 1.3012364840507507\n",
      "trial: 5, iter: 6000, curr loss: 1.2898240089416504, avg loss: 1.2961967426538468\n",
      "trial: 5, iter: 6200, curr loss: 1.3166056871414185, avg loss: 1.297243930697441\n",
      "trial: 5, ldr: 0.2750095725059509\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.26221503913402555\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38813054561615, avg loss: 1.3873087638616561\n",
      "trial: 1, iter: 400, curr loss: 1.3857923746109009, avg loss: 1.386694853901863\n",
      "trial: 1, iter: 600, curr loss: 1.3854912519454956, avg loss: 1.3862859684228896\n",
      "trial: 1, iter: 800, curr loss: 1.3824348449707031, avg loss: 1.3853930550813676\n",
      "trial: 1, iter: 1000, curr loss: 1.380983829498291, avg loss: 1.3804309213161468\n",
      "trial: 1, iter: 1200, curr loss: 1.3508141040802002, avg loss: 1.3712298685312272\n",
      "trial: 1, iter: 1400, curr loss: 1.3835853338241577, avg loss: 1.3673531818389892\n",
      "trial: 1, iter: 1600, curr loss: 1.3503779172897339, avg loss: 1.364142457842827\n",
      "trial: 1, iter: 1800, curr loss: 1.3508139848709106, avg loss: 1.365090156197548\n",
      "trial: 1, iter: 2000, curr loss: 1.3651307821273804, avg loss: 1.363000465631485\n",
      "trial: 1, iter: 2200, curr loss: 1.3604843616485596, avg loss: 1.362876148223877\n",
      "trial: 1, iter: 2400, curr loss: 1.360053539276123, avg loss: 1.3593060314655303\n",
      "trial: 1, iter: 2600, curr loss: 1.369750738143921, avg loss: 1.3561696881055831\n",
      "trial: 1, iter: 2800, curr loss: 1.3446656465530396, avg loss: 1.3506303018331527\n",
      "trial: 1, iter: 3000, curr loss: 1.352382779121399, avg loss: 1.3430365824699402\n",
      "trial: 1, iter: 3200, curr loss: 1.3408074378967285, avg loss: 1.3366490602493286\n",
      "trial: 1, iter: 3400, curr loss: 1.3108255863189697, avg loss: 1.3315298622846603\n",
      "trial: 1, iter: 3600, curr loss: 1.3427666425704956, avg loss: 1.3266654711961747\n",
      "trial: 1, iter: 3800, curr loss: 1.3562300205230713, avg loss: 1.3233936434984208\n",
      "trial: 1, iter: 4000, curr loss: 1.3115907907485962, avg loss: 1.3191272938251495\n",
      "trial: 1, iter: 4200, curr loss: 1.3144844770431519, avg loss: 1.3170135939121246\n",
      "trial: 1, iter: 4400, curr loss: 1.3030434846878052, avg loss: 1.3157446867227554\n",
      "trial: 1, iter: 4600, curr loss: 1.2793084383010864, avg loss: 1.3153692591190338\n",
      "trial: 1, iter: 4800, curr loss: 1.3007638454437256, avg loss: 1.308455577492714\n",
      "trial: 1, iter: 5000, curr loss: 1.285159707069397, avg loss: 1.3112048214673997\n",
      "trial: 1, iter: 5200, curr loss: 1.2719192504882812, avg loss: 1.3097586745023728\n",
      "trial: 1, iter: 5400, curr loss: 1.282318353652954, avg loss: 1.308350703716278\n",
      "trial: 1, iter: 5600, curr loss: 1.3097782135009766, avg loss: 1.3036862236261368\n",
      "trial: 1, iter: 5800, curr loss: 1.3229292631149292, avg loss: 1.3057732504606248\n",
      "trial: 1, iter: 6000, curr loss: 1.3115483522415161, avg loss: 1.3019369208812714\n",
      "trial: 1, iter: 6200, curr loss: 1.309228539466858, avg loss: 1.2998026913404466\n",
      "trial: 1, ldr: 0.22201770544052124\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.391917109489441, avg loss: 1.3873143243789672\n",
      "trial: 2, iter: 400, curr loss: 1.3868545293807983, avg loss: 1.3865341490507126\n",
      "trial: 2, iter: 600, curr loss: 1.387529730796814, avg loss: 1.386147471666336\n",
      "trial: 2, iter: 800, curr loss: 1.3865203857421875, avg loss: 1.3844711220264434\n",
      "trial: 2, iter: 1000, curr loss: 1.3828742504119873, avg loss: 1.3825716090202331\n",
      "trial: 2, iter: 1200, curr loss: 1.372846245765686, avg loss: 1.3776310098171234\n",
      "trial: 2, iter: 1400, curr loss: 1.3853100538253784, avg loss: 1.3690392452478408\n",
      "trial: 2, iter: 1600, curr loss: 1.3519996404647827, avg loss: 1.3646293205022813\n",
      "trial: 2, iter: 1800, curr loss: 1.3665125370025635, avg loss: 1.36252355158329\n",
      "trial: 2, iter: 2000, curr loss: 1.3375298976898193, avg loss: 1.35820472240448\n",
      "trial: 2, iter: 2200, curr loss: 1.337947964668274, avg loss: 1.353341322541237\n",
      "trial: 2, iter: 2400, curr loss: 1.3499301671981812, avg loss: 1.3459737807512284\n",
      "trial: 2, iter: 2600, curr loss: 1.3724026679992676, avg loss: 1.3380960088968277\n",
      "trial: 2, iter: 2800, curr loss: 1.3217779397964478, avg loss: 1.3322545951604843\n",
      "trial: 2, iter: 3000, curr loss: 1.309751272201538, avg loss: 1.3311347734928132\n",
      "trial: 2, iter: 3200, curr loss: 1.3284975290298462, avg loss: 1.323023927807808\n",
      "trial: 2, iter: 3400, curr loss: 1.313623309135437, avg loss: 1.318649942278862\n",
      "trial: 2, iter: 3600, curr loss: 1.3147974014282227, avg loss: 1.3192954206466674\n",
      "trial: 2, iter: 3800, curr loss: 1.3113784790039062, avg loss: 1.3159586882591248\n",
      "trial: 2, iter: 4000, curr loss: 1.323729157447815, avg loss: 1.3125113266706467\n",
      "trial: 2, iter: 4200, curr loss: 1.2788838148117065, avg loss: 1.3115981471538545\n",
      "trial: 2, iter: 4400, curr loss: 1.3173701763153076, avg loss: 1.3090990692377091\n",
      "trial: 2, iter: 4600, curr loss: 1.3151271343231201, avg loss: 1.3082500553131104\n",
      "trial: 2, iter: 4800, curr loss: 1.303998589515686, avg loss: 1.308553596138954\n",
      "trial: 2, iter: 5000, curr loss: 1.297003149986267, avg loss: 1.306283989548683\n",
      "trial: 2, iter: 5200, curr loss: 1.2898601293563843, avg loss: 1.3059599161148072\n",
      "trial: 2, iter: 5400, curr loss: 1.310794711112976, avg loss: 1.3051895594596863\n",
      "trial: 2, iter: 5600, curr loss: 1.27727210521698, avg loss: 1.304570255279541\n",
      "trial: 2, iter: 5800, curr loss: 1.3169574737548828, avg loss: 1.3013107293844224\n",
      "trial: 2, iter: 6000, curr loss: 1.3134288787841797, avg loss: 1.3029506808519364\n",
      "trial: 2, iter: 6200, curr loss: 1.3158502578735352, avg loss: 1.3003086459636688\n",
      "trial: 2, ldr: 0.2823156416416168\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3853508234024048, avg loss: 1.3874305748939515\n",
      "trial: 3, iter: 400, curr loss: 1.387296199798584, avg loss: 1.386716175675392\n",
      "trial: 3, iter: 600, curr loss: 1.3866839408874512, avg loss: 1.3863700485229493\n",
      "trial: 3, iter: 800, curr loss: 1.3862500190734863, avg loss: 1.3855727833509446\n",
      "trial: 3, iter: 1000, curr loss: 1.3825840950012207, avg loss: 1.3827304357290269\n",
      "trial: 3, iter: 1200, curr loss: 1.3530014753341675, avg loss: 1.3761059796810151\n",
      "trial: 3, iter: 1400, curr loss: 1.3665639162063599, avg loss: 1.3699382239580153\n",
      "trial: 3, iter: 1600, curr loss: 1.3657163381576538, avg loss: 1.3681180185079576\n",
      "trial: 3, iter: 1800, curr loss: 1.3474304676055908, avg loss: 1.3648323404788971\n",
      "trial: 3, iter: 2000, curr loss: 1.3547147512435913, avg loss: 1.3640191358327867\n",
      "trial: 3, iter: 2200, curr loss: 1.379638671875, avg loss: 1.3618613409996032\n",
      "trial: 3, iter: 2400, curr loss: 1.346181869506836, avg loss: 1.3584323227405548\n",
      "trial: 3, iter: 2600, curr loss: 1.3413887023925781, avg loss: 1.3557654219865798\n",
      "trial: 3, iter: 2800, curr loss: 1.334526777267456, avg loss: 1.3518623077869416\n",
      "trial: 3, iter: 3000, curr loss: 1.3503637313842773, avg loss: 1.3477582401037216\n",
      "trial: 3, iter: 3200, curr loss: 1.3293291330337524, avg loss: 1.340910129547119\n",
      "trial: 3, iter: 3400, curr loss: 1.334526777267456, avg loss: 1.3347822314500808\n",
      "trial: 3, iter: 3600, curr loss: 1.3592889308929443, avg loss: 1.3308207023143768\n",
      "trial: 3, iter: 3800, curr loss: 1.3277233839035034, avg loss: 1.3232059520483017\n",
      "trial: 3, iter: 4000, curr loss: 1.3093007802963257, avg loss: 1.3228579378128051\n",
      "trial: 3, iter: 4200, curr loss: 1.321122407913208, avg loss: 1.3216936141252518\n",
      "trial: 3, iter: 4400, curr loss: 1.2948660850524902, avg loss: 1.318144121170044\n",
      "trial: 3, iter: 4600, curr loss: 1.2918577194213867, avg loss: 1.3153393632173538\n",
      "trial: 3, iter: 4800, curr loss: 1.2918577194213867, avg loss: 1.3119280833005904\n",
      "trial: 3, iter: 5000, curr loss: 1.3220345973968506, avg loss: 1.3135883259773253\n",
      "trial: 3, iter: 5200, curr loss: 1.2989802360534668, avg loss: 1.3081560492515565\n",
      "trial: 3, iter: 5400, curr loss: 1.3530784845352173, avg loss: 1.3086922889947892\n",
      "trial: 3, iter: 5600, curr loss: 1.3187226057052612, avg loss: 1.3078425228595734\n",
      "trial: 3, iter: 5800, curr loss: 1.2691068649291992, avg loss: 1.3058645278215408\n",
      "trial: 3, iter: 6000, curr loss: 1.295073390007019, avg loss: 1.3038278204202651\n",
      "trial: 3, iter: 6200, curr loss: 1.3208109140396118, avg loss: 1.3030051732063292\n",
      "trial: 3, ldr: 0.26448124647140503\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386242151260376, avg loss: 1.387584347128868\n",
      "trial: 4, iter: 400, curr loss: 1.3850445747375488, avg loss: 1.3867016404867172\n",
      "trial: 4, iter: 600, curr loss: 1.3858273029327393, avg loss: 1.386294360756874\n",
      "trial: 4, iter: 800, curr loss: 1.3820464611053467, avg loss: 1.3848765563964844\n",
      "trial: 4, iter: 1000, curr loss: 1.3916634321212769, avg loss: 1.3796496230363846\n",
      "trial: 4, iter: 1200, curr loss: 1.342046856880188, avg loss: 1.3707219195365905\n",
      "trial: 4, iter: 1400, curr loss: 1.3678025007247925, avg loss: 1.3643169021606445\n",
      "trial: 4, iter: 1600, curr loss: 1.359169602394104, avg loss: 1.3628288793563843\n",
      "trial: 4, iter: 1800, curr loss: 1.3412578105926514, avg loss: 1.3582145887613297\n",
      "trial: 4, iter: 2000, curr loss: 1.3776510953903198, avg loss: 1.3538829910755157\n",
      "trial: 4, iter: 2200, curr loss: 1.3488960266113281, avg loss: 1.348929288983345\n",
      "trial: 4, iter: 2400, curr loss: 1.3572438955307007, avg loss: 1.34074324965477\n",
      "trial: 4, iter: 2600, curr loss: 1.3198405504226685, avg loss: 1.3369545209407807\n",
      "trial: 4, iter: 2800, curr loss: 1.2937369346618652, avg loss: 1.3319050377607347\n",
      "trial: 4, iter: 3000, curr loss: 1.3499352931976318, avg loss: 1.3295159250497819\n",
      "trial: 4, iter: 3200, curr loss: 1.3324918746948242, avg loss: 1.32408562541008\n",
      "trial: 4, iter: 3400, curr loss: 1.3001067638397217, avg loss: 1.3252485632896422\n",
      "trial: 4, iter: 3600, curr loss: 1.33521568775177, avg loss: 1.3191144114732742\n",
      "trial: 4, iter: 3800, curr loss: 1.3208938837051392, avg loss: 1.319236227273941\n",
      "trial: 4, iter: 4000, curr loss: 1.2840194702148438, avg loss: 1.3177165275812148\n",
      "trial: 4, iter: 4200, curr loss: 1.2920912504196167, avg loss: 1.3129873102903367\n",
      "trial: 4, iter: 4400, curr loss: 1.3306866884231567, avg loss: 1.3122751194238662\n",
      "trial: 4, iter: 4600, curr loss: 1.2982162237167358, avg loss: 1.3096107375621795\n",
      "trial: 4, iter: 4800, curr loss: 1.3375093936920166, avg loss: 1.3092394679784776\n",
      "trial: 4, iter: 5000, curr loss: 1.3167206048965454, avg loss: 1.3093454819917678\n",
      "trial: 4, iter: 5200, curr loss: 1.3085206747055054, avg loss: 1.3105737286806107\n",
      "trial: 4, iter: 5400, curr loss: 1.3128995895385742, avg loss: 1.3070208793878555\n",
      "trial: 4, iter: 5600, curr loss: 1.3425161838531494, avg loss: 1.3060906171798705\n",
      "trial: 4, iter: 5800, curr loss: 1.2731863260269165, avg loss: 1.3064951956272126\n",
      "trial: 4, iter: 6000, curr loss: 1.2889952659606934, avg loss: 1.3009202992916107\n",
      "trial: 4, iter: 6200, curr loss: 1.2523839473724365, avg loss: 1.3012148040533065\n",
      "trial: 4, ldr: 0.32302534580230713\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3876841068267822, avg loss: 1.3869991946220397\n",
      "trial: 5, iter: 400, curr loss: 1.3874224424362183, avg loss: 1.3866573071479797\n",
      "trial: 5, iter: 600, curr loss: 1.3870625495910645, avg loss: 1.3864552211761474\n",
      "trial: 5, iter: 800, curr loss: 1.3869847059249878, avg loss: 1.384222611784935\n",
      "trial: 5, iter: 1000, curr loss: 1.3710033893585205, avg loss: 1.3730695897340774\n",
      "trial: 5, iter: 1200, curr loss: 1.3801740407943726, avg loss: 1.3657433885335921\n",
      "trial: 5, iter: 1400, curr loss: 1.3491450548171997, avg loss: 1.3615339463949203\n",
      "trial: 5, iter: 1600, curr loss: 1.3524326086044312, avg loss: 1.3597870683670044\n",
      "trial: 5, iter: 1800, curr loss: 1.3495906591415405, avg loss: 1.354114512205124\n",
      "trial: 5, iter: 2000, curr loss: 1.3466519117355347, avg loss: 1.34919183075428\n",
      "trial: 5, iter: 2200, curr loss: 1.3536481857299805, avg loss: 1.3424677789211272\n",
      "trial: 5, iter: 2400, curr loss: 1.3467308282852173, avg loss: 1.3368339043855668\n",
      "trial: 5, iter: 2600, curr loss: 1.334208369255066, avg loss: 1.3318518936634063\n",
      "trial: 5, iter: 2800, curr loss: 1.3292611837387085, avg loss: 1.327259026169777\n",
      "trial: 5, iter: 3000, curr loss: 1.2889505624771118, avg loss: 1.3233294200897217\n",
      "trial: 5, iter: 3200, curr loss: 1.2953530550003052, avg loss: 1.3211566454172134\n",
      "trial: 5, iter: 3400, curr loss: 1.3224257230758667, avg loss: 1.3176968097686768\n",
      "trial: 5, iter: 3600, curr loss: 1.295060157775879, avg loss: 1.3189455217123032\n",
      "trial: 5, iter: 3800, curr loss: 1.3118035793304443, avg loss: 1.3124978095293045\n",
      "trial: 5, iter: 4000, curr loss: 1.318813681602478, avg loss: 1.3150826746225357\n",
      "trial: 5, iter: 4200, curr loss: 1.3100650310516357, avg loss: 1.3130436098575593\n",
      "trial: 5, iter: 4400, curr loss: 1.3239942789077759, avg loss: 1.3115364426374436\n",
      "trial: 5, iter: 4600, curr loss: 1.2949239015579224, avg loss: 1.3107399189472198\n",
      "trial: 5, iter: 4800, curr loss: 1.2978901863098145, avg loss: 1.3099734687805176\n",
      "trial: 5, iter: 5000, curr loss: 1.2749435901641846, avg loss: 1.3105664068460465\n",
      "trial: 5, iter: 5200, curr loss: 1.3190863132476807, avg loss: 1.3089295494556428\n",
      "trial: 5, iter: 5400, curr loss: 1.3308929204940796, avg loss: 1.3038899850845338\n",
      "trial: 5, iter: 5600, curr loss: 1.2851163148880005, avg loss: 1.3016091907024383\n",
      "trial: 5, iter: 5800, curr loss: 1.3017152547836304, avg loss: 1.3016068571805954\n",
      "trial: 5, iter: 6000, curr loss: 1.315129280090332, avg loss: 1.303682708144188\n",
      "trial: 5, iter: 6200, curr loss: 1.2955342531204224, avg loss: 1.302848643064499\n",
      "trial: 5, ldr: 0.20504102110862732\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.25937619209289553\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.388777494430542, avg loss: 1.3873209500312804\n",
      "trial: 1, iter: 400, curr loss: 1.3877099752426147, avg loss: 1.386660953760147\n",
      "trial: 1, iter: 600, curr loss: 1.3826712369918823, avg loss: 1.384838798046112\n",
      "trial: 1, iter: 800, curr loss: 1.3823864459991455, avg loss: 1.3774254626035691\n",
      "trial: 1, iter: 1000, curr loss: 1.3491542339324951, avg loss: 1.3669953811168671\n",
      "trial: 1, iter: 1200, curr loss: 1.3438674211502075, avg loss: 1.3621035403013229\n",
      "trial: 1, iter: 1400, curr loss: 1.3656864166259766, avg loss: 1.3579697984457015\n",
      "trial: 1, iter: 1600, curr loss: 1.3317420482635498, avg loss: 1.3564149677753448\n",
      "trial: 1, iter: 1800, curr loss: 1.3568603992462158, avg loss: 1.3478047847747803\n",
      "trial: 1, iter: 2000, curr loss: 1.3695616722106934, avg loss: 1.3430224299430846\n",
      "trial: 1, iter: 2200, curr loss: 1.3346375226974487, avg loss: 1.3371955585479736\n",
      "trial: 1, iter: 2400, curr loss: 1.3161526918411255, avg loss: 1.3321015620231629\n",
      "trial: 1, iter: 2600, curr loss: 1.322044849395752, avg loss: 1.3268379682302476\n",
      "trial: 1, iter: 2800, curr loss: 1.3276764154434204, avg loss: 1.3240982228517533\n",
      "trial: 1, iter: 3000, curr loss: 1.3186415433883667, avg loss: 1.3220280492305756\n",
      "trial: 1, iter: 3200, curr loss: 1.319454312324524, avg loss: 1.3205993711948394\n",
      "trial: 1, iter: 3400, curr loss: 1.3175415992736816, avg loss: 1.3165674388408661\n",
      "trial: 1, iter: 3600, curr loss: 1.321786880493164, avg loss: 1.3162978941202164\n",
      "trial: 1, iter: 3800, curr loss: 1.2962026596069336, avg loss: 1.311092558503151\n",
      "trial: 1, iter: 4000, curr loss: 1.3107491731643677, avg loss: 1.3135289943218231\n",
      "trial: 1, iter: 4200, curr loss: 1.2936596870422363, avg loss: 1.3121095621585845\n",
      "trial: 1, iter: 4400, curr loss: 1.2706602811813354, avg loss: 1.3086110335588454\n",
      "trial: 1, iter: 4600, curr loss: 1.282654047012329, avg loss: 1.3088453960418702\n",
      "trial: 1, iter: 4800, curr loss: 1.3028619289398193, avg loss: 1.306927962899208\n",
      "trial: 1, iter: 5000, curr loss: 1.3078107833862305, avg loss: 1.306512166261673\n",
      "trial: 1, iter: 5200, curr loss: 1.3090827465057373, avg loss: 1.3036107367277145\n",
      "trial: 1, iter: 5400, curr loss: 1.3172677755355835, avg loss: 1.3043958234786988\n",
      "trial: 1, iter: 5600, curr loss: 1.2863390445709229, avg loss: 1.3022939908504485\n",
      "trial: 1, iter: 5800, curr loss: 1.2307548522949219, avg loss: 1.3023070973157882\n",
      "trial: 1, iter: 6000, curr loss: 1.2902252674102783, avg loss: 1.3006705754995347\n",
      "trial: 1, iter: 6200, curr loss: 1.2879443168640137, avg loss: 1.2964810556173325\n",
      "trial: 1, ldr: 0.17575715482234955\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3826508522033691, avg loss: 1.3876989436149598\n",
      "trial: 2, iter: 400, curr loss: 1.390547752380371, avg loss: 1.386788575053215\n",
      "trial: 2, iter: 600, curr loss: 1.3839669227600098, avg loss: 1.3864103209972383\n",
      "trial: 2, iter: 800, curr loss: 1.3846584558486938, avg loss: 1.3860195398330688\n",
      "trial: 2, iter: 1000, curr loss: 1.374753475189209, avg loss: 1.380060357451439\n",
      "trial: 2, iter: 1200, curr loss: 1.3637033700942993, avg loss: 1.3718773919343947\n",
      "trial: 2, iter: 1400, curr loss: 1.3552625179290771, avg loss: 1.3637970995903015\n",
      "trial: 2, iter: 1600, curr loss: 1.348319172859192, avg loss: 1.3617437475919723\n",
      "trial: 2, iter: 1800, curr loss: 1.3574371337890625, avg loss: 1.3589533877372741\n",
      "trial: 2, iter: 2000, curr loss: 1.3538520336151123, avg loss: 1.3513406866788864\n",
      "trial: 2, iter: 2200, curr loss: 1.3253371715545654, avg loss: 1.3466047441959381\n",
      "trial: 2, iter: 2400, curr loss: 1.3066747188568115, avg loss: 1.3412420415878297\n",
      "trial: 2, iter: 2600, curr loss: 1.3201947212219238, avg loss: 1.334891783595085\n",
      "trial: 2, iter: 2800, curr loss: 1.3407621383666992, avg loss: 1.3334359240531921\n",
      "trial: 2, iter: 3000, curr loss: 1.3270140886306763, avg loss: 1.3289546662569045\n",
      "trial: 2, iter: 3200, curr loss: 1.3539546728134155, avg loss: 1.3246578645706177\n",
      "trial: 2, iter: 3400, curr loss: 1.2949507236480713, avg loss: 1.3231653970479966\n",
      "trial: 2, iter: 3600, curr loss: 1.3566858768463135, avg loss: 1.3203761154413223\n",
      "trial: 2, iter: 3800, curr loss: 1.3250904083251953, avg loss: 1.3198798710107804\n",
      "trial: 2, iter: 4000, curr loss: 1.376089096069336, avg loss: 1.317368621826172\n",
      "trial: 2, iter: 4200, curr loss: 1.3364627361297607, avg loss: 1.3153531432151795\n",
      "trial: 2, iter: 4400, curr loss: 1.3317686319351196, avg loss: 1.3130155909061432\n",
      "trial: 2, iter: 4600, curr loss: 1.2898441553115845, avg loss: 1.313842421770096\n",
      "trial: 2, iter: 4800, curr loss: 1.3127632141113281, avg loss: 1.3076684248447419\n",
      "trial: 2, iter: 5000, curr loss: 1.3388841152191162, avg loss: 1.3104579889774322\n",
      "trial: 2, iter: 5200, curr loss: 1.3322592973709106, avg loss: 1.3091012692451478\n",
      "trial: 2, iter: 5400, curr loss: 1.2844023704528809, avg loss: 1.3063008052110672\n",
      "trial: 2, iter: 5600, curr loss: 1.266271710395813, avg loss: 1.3058982157707215\n",
      "trial: 2, iter: 5800, curr loss: 1.2968735694885254, avg loss: 1.3058420503139496\n",
      "trial: 2, iter: 6000, curr loss: 1.3263757228851318, avg loss: 1.3044074857234955\n",
      "trial: 2, iter: 6200, curr loss: 1.2884148359298706, avg loss: 1.3031247496604919\n",
      "trial: 2, ldr: 0.24441513419151306\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.385692834854126, avg loss: 1.3870039582252502\n",
      "trial: 3, iter: 400, curr loss: 1.389007329940796, avg loss: 1.3866831851005554\n",
      "trial: 3, iter: 600, curr loss: 1.388346552848816, avg loss: 1.3862806171178819\n",
      "trial: 3, iter: 800, curr loss: 1.3790385723114014, avg loss: 1.3845351094007492\n",
      "trial: 3, iter: 1000, curr loss: 1.3819568157196045, avg loss: 1.3766503924131392\n",
      "trial: 3, iter: 1200, curr loss: 1.3691997528076172, avg loss: 1.367730810046196\n",
      "trial: 3, iter: 1400, curr loss: 1.3638889789581299, avg loss: 1.3657011705636979\n",
      "trial: 3, iter: 1600, curr loss: 1.369539499282837, avg loss: 1.3607789599895477\n",
      "trial: 3, iter: 1800, curr loss: 1.360379934310913, avg loss: 1.357876141667366\n",
      "trial: 3, iter: 2000, curr loss: 1.336022138595581, avg loss: 1.3538717955350876\n",
      "trial: 3, iter: 2200, curr loss: 1.3554106950759888, avg loss: 1.3473417693376541\n",
      "trial: 3, iter: 2400, curr loss: 1.3374731540679932, avg loss: 1.3414393895864487\n",
      "trial: 3, iter: 2600, curr loss: 1.3599393367767334, avg loss: 1.3372011572122573\n",
      "trial: 3, iter: 2800, curr loss: 1.320781946182251, avg loss: 1.3322301584482192\n",
      "trial: 3, iter: 3000, curr loss: 1.3428858518600464, avg loss: 1.3284008878469467\n",
      "trial: 3, iter: 3200, curr loss: 1.3639211654663086, avg loss: 1.327526103258133\n",
      "trial: 3, iter: 3400, curr loss: 1.3088171482086182, avg loss: 1.32307408452034\n",
      "trial: 3, iter: 3600, curr loss: 1.3189364671707153, avg loss: 1.3213629907369613\n",
      "trial: 3, iter: 3800, curr loss: 1.3217120170593262, avg loss: 1.3181673592329026\n",
      "trial: 3, iter: 4000, curr loss: 1.3471035957336426, avg loss: 1.3162699669599534\n",
      "trial: 3, iter: 4200, curr loss: 1.2950702905654907, avg loss: 1.3166045409440994\n",
      "trial: 3, iter: 4400, curr loss: 1.2874835729599, avg loss: 1.31521309196949\n",
      "trial: 3, iter: 4600, curr loss: 1.2880783081054688, avg loss: 1.3114732211828233\n",
      "trial: 3, iter: 4800, curr loss: 1.2941498756408691, avg loss: 1.3085039448738098\n",
      "trial: 3, iter: 5000, curr loss: 1.2936838865280151, avg loss: 1.3080441612005234\n",
      "trial: 3, iter: 5200, curr loss: 1.3060742616653442, avg loss: 1.3061514675617218\n",
      "trial: 3, iter: 5400, curr loss: 1.2801244258880615, avg loss: 1.3072496968507767\n",
      "trial: 3, iter: 5600, curr loss: 1.3192051649093628, avg loss: 1.3048723340034485\n",
      "trial: 3, iter: 5800, curr loss: 1.3167704343795776, avg loss: 1.3030489104986192\n",
      "trial: 3, iter: 6000, curr loss: 1.3024958372116089, avg loss: 1.3006288212537767\n",
      "trial: 3, iter: 6200, curr loss: 1.2933692932128906, avg loss: 1.299763890504837\n",
      "trial: 3, ldr: 0.22777655720710754\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388119101524353, avg loss: 1.3879115003347398\n",
      "trial: 4, iter: 400, curr loss: 1.3809473514556885, avg loss: 1.3865281754732133\n",
      "trial: 4, iter: 600, curr loss: 1.3824944496154785, avg loss: 1.3840700870752334\n",
      "trial: 4, iter: 800, curr loss: 1.3706128597259521, avg loss: 1.380337746143341\n",
      "trial: 4, iter: 1000, curr loss: 1.3734885454177856, avg loss: 1.3757413786649704\n",
      "trial: 4, iter: 1200, curr loss: 1.3581236600875854, avg loss: 1.368727570772171\n",
      "trial: 4, iter: 1400, curr loss: 1.3803797960281372, avg loss: 1.3670560550689697\n",
      "trial: 4, iter: 1600, curr loss: 1.3541181087493896, avg loss: 1.362093785405159\n",
      "trial: 4, iter: 1800, curr loss: 1.3692996501922607, avg loss: 1.3578850561380387\n",
      "trial: 4, iter: 2000, curr loss: 1.3607529401779175, avg loss: 1.351053111553192\n",
      "trial: 4, iter: 2200, curr loss: 1.3371225595474243, avg loss: 1.3437609726190567\n",
      "trial: 4, iter: 2400, curr loss: 1.3319605588912964, avg loss: 1.336603480577469\n",
      "trial: 4, iter: 2600, curr loss: 1.3590548038482666, avg loss: 1.3337690752744675\n",
      "trial: 4, iter: 2800, curr loss: 1.3522822856903076, avg loss: 1.3266400945186616\n",
      "trial: 4, iter: 3000, curr loss: 1.3255956172943115, avg loss: 1.3223004448413849\n",
      "trial: 4, iter: 3200, curr loss: 1.3144869804382324, avg loss: 1.320290515422821\n",
      "trial: 4, iter: 3400, curr loss: 1.3036446571350098, avg loss: 1.3197562557458877\n",
      "trial: 4, iter: 3600, curr loss: 1.2739145755767822, avg loss: 1.314173961877823\n",
      "trial: 4, iter: 3800, curr loss: 1.2802561521530151, avg loss: 1.3112701559066773\n",
      "trial: 4, iter: 4000, curr loss: 1.337670922279358, avg loss: 1.3113883018493653\n",
      "trial: 4, iter: 4200, curr loss: 1.307538628578186, avg loss: 1.3098338717222213\n",
      "trial: 4, iter: 4400, curr loss: 1.3103431463241577, avg loss: 1.3069325160980225\n",
      "trial: 4, iter: 4600, curr loss: 1.3154064416885376, avg loss: 1.3065668094158172\n",
      "trial: 4, iter: 4800, curr loss: 1.2929848432540894, avg loss: 1.3032805812358856\n",
      "trial: 4, iter: 5000, curr loss: 1.3002567291259766, avg loss: 1.3050088834762574\n",
      "trial: 4, iter: 5200, curr loss: 1.3210101127624512, avg loss: 1.304946750998497\n",
      "trial: 4, iter: 5400, curr loss: 1.300423264503479, avg loss: 1.3026517337560655\n",
      "trial: 4, iter: 5600, curr loss: 1.3394348621368408, avg loss: 1.3013056522607804\n",
      "trial: 4, iter: 5800, curr loss: 1.3104690313339233, avg loss: 1.3018170142173766\n",
      "trial: 4, iter: 6000, curr loss: 1.3249132633209229, avg loss: 1.2983404916524888\n",
      "trial: 4, iter: 6200, curr loss: 1.294625997543335, avg loss: 1.2964297181367874\n",
      "trial: 4, ldr: 0.29784873127937317\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387451171875, avg loss: 1.3871970558166504\n",
      "trial: 5, iter: 400, curr loss: 1.3839209079742432, avg loss: 1.3866223728656768\n",
      "trial: 5, iter: 600, curr loss: 1.3873305320739746, avg loss: 1.3860099685192109\n",
      "trial: 5, iter: 800, curr loss: 1.3815054893493652, avg loss: 1.3833766001462937\n",
      "trial: 5, iter: 1000, curr loss: 1.383306622505188, avg loss: 1.379091933965683\n",
      "trial: 5, iter: 1200, curr loss: 1.3603878021240234, avg loss: 1.3770189774036408\n",
      "trial: 5, iter: 1400, curr loss: 1.368358850479126, avg loss: 1.371802020072937\n",
      "trial: 5, iter: 1600, curr loss: 1.3342677354812622, avg loss: 1.3664855992794036\n",
      "trial: 5, iter: 1800, curr loss: 1.3580498695373535, avg loss: 1.3611978435516356\n",
      "trial: 5, iter: 2000, curr loss: 1.3609635829925537, avg loss: 1.3610094380378723\n",
      "trial: 5, iter: 2200, curr loss: 1.361053228378296, avg loss: 1.3566480427980423\n",
      "trial: 5, iter: 2400, curr loss: 1.350836157798767, avg loss: 1.3504531162977218\n",
      "trial: 5, iter: 2600, curr loss: 1.320089340209961, avg loss: 1.3433190310001373\n",
      "trial: 5, iter: 2800, curr loss: 1.323674201965332, avg loss: 1.3352196151018143\n",
      "trial: 5, iter: 3000, curr loss: 1.3264915943145752, avg loss: 1.3302915543317795\n",
      "trial: 5, iter: 3200, curr loss: 1.296006202697754, avg loss: 1.323594423532486\n",
      "trial: 5, iter: 3400, curr loss: 1.353286623954773, avg loss: 1.3207822823524475\n",
      "trial: 5, iter: 3600, curr loss: 1.3297619819641113, avg loss: 1.3212077033519745\n",
      "trial: 5, iter: 3800, curr loss: 1.2962225675582886, avg loss: 1.3157076805830001\n",
      "trial: 5, iter: 4000, curr loss: 1.2860453128814697, avg loss: 1.3164338654279708\n",
      "trial: 5, iter: 4200, curr loss: 1.3426815271377563, avg loss: 1.3137599837779999\n",
      "trial: 5, iter: 4400, curr loss: 1.3099210262298584, avg loss: 1.3122697919607162\n",
      "trial: 5, iter: 4600, curr loss: 1.2711858749389648, avg loss: 1.3077267736196518\n",
      "trial: 5, iter: 4800, curr loss: 1.2954857349395752, avg loss: 1.309218025803566\n",
      "trial: 5, iter: 5000, curr loss: 1.2743552923202515, avg loss: 1.3070450162887572\n",
      "trial: 5, iter: 5200, curr loss: 1.3126429319381714, avg loss: 1.3063696885108949\n",
      "trial: 5, iter: 5400, curr loss: 1.349534273147583, avg loss: 1.3057322537899017\n",
      "trial: 5, iter: 5600, curr loss: 1.2896326780319214, avg loss: 1.3058844512701036\n",
      "trial: 5, iter: 5800, curr loss: 1.291637659072876, avg loss: 1.3048699975013733\n",
      "trial: 5, iter: 6000, curr loss: 1.284651279449463, avg loss: 1.304992687702179\n",
      "trial: 5, iter: 6200, curr loss: 1.306679129600525, avg loss: 1.3017192476987838\n",
      "trial: 5, ldr: 0.21616636216640472\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2323927879333496\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3865892887115479, avg loss: 1.3874374479055405\n",
      "trial: 1, iter: 400, curr loss: 1.3854124546051025, avg loss: 1.3866800391674041\n",
      "trial: 1, iter: 600, curr loss: 1.3852274417877197, avg loss: 1.3861087691783904\n",
      "trial: 1, iter: 800, curr loss: 1.380454182624817, avg loss: 1.3835549396276474\n",
      "trial: 1, iter: 1000, curr loss: 1.363587737083435, avg loss: 1.3725111311674119\n",
      "trial: 1, iter: 1200, curr loss: 1.383941888809204, avg loss: 1.3658069986104966\n",
      "trial: 1, iter: 1400, curr loss: 1.3713668584823608, avg loss: 1.3620963400602342\n",
      "trial: 1, iter: 1600, curr loss: 1.3542687892913818, avg loss: 1.3564314562082291\n",
      "trial: 1, iter: 1800, curr loss: 1.364757776260376, avg loss: 1.3533493214845658\n",
      "trial: 1, iter: 2000, curr loss: 1.3183233737945557, avg loss: 1.3457653832435608\n",
      "trial: 1, iter: 2200, curr loss: 1.3172777891159058, avg loss: 1.3400111144781113\n",
      "trial: 1, iter: 2400, curr loss: 1.3271946907043457, avg loss: 1.3322409445047378\n",
      "trial: 1, iter: 2600, curr loss: 1.3396908044815063, avg loss: 1.3270997899770736\n",
      "trial: 1, iter: 2800, curr loss: 1.3093634843826294, avg loss: 1.3251076060533524\n",
      "trial: 1, iter: 3000, curr loss: 1.3077595233917236, avg loss: 1.3219286555051804\n",
      "trial: 1, iter: 3200, curr loss: 1.2849680185317993, avg loss: 1.3172873520851136\n",
      "trial: 1, iter: 3400, curr loss: 1.2938436269760132, avg loss: 1.3146280664205552\n",
      "trial: 1, iter: 3600, curr loss: 1.3466440439224243, avg loss: 1.3167889630794525\n",
      "trial: 1, iter: 3800, curr loss: 1.3541128635406494, avg loss: 1.313640850186348\n",
      "trial: 1, iter: 4000, curr loss: 1.351575493812561, avg loss: 1.3103256976604463\n",
      "trial: 1, iter: 4200, curr loss: 1.3111214637756348, avg loss: 1.312850348353386\n",
      "trial: 1, iter: 4400, curr loss: 1.3497885465621948, avg loss: 1.3096174651384354\n",
      "trial: 1, iter: 4600, curr loss: 1.3248192071914673, avg loss: 1.308653684258461\n",
      "trial: 1, iter: 4800, curr loss: 1.28563392162323, avg loss: 1.3077916783094405\n",
      "trial: 1, iter: 5000, curr loss: 1.2970606088638306, avg loss: 1.305029518008232\n",
      "trial: 1, iter: 5200, curr loss: 1.3103021383285522, avg loss: 1.301929284930229\n",
      "trial: 1, iter: 5400, curr loss: 1.322712779045105, avg loss: 1.3041095054149627\n",
      "trial: 1, iter: 5600, curr loss: 1.3192893266677856, avg loss: 1.3023442375659942\n",
      "trial: 1, iter: 5800, curr loss: 1.321445107460022, avg loss: 1.3017396634817124\n",
      "trial: 1, iter: 6000, curr loss: 1.302261233329773, avg loss: 1.301332259774208\n",
      "trial: 1, iter: 6200, curr loss: 1.26400625705719, avg loss: 1.2981535959243775\n",
      "trial: 1, ldr: 0.2905169129371643\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866617679595947, avg loss: 1.387019683122635\n",
      "trial: 2, iter: 400, curr loss: 1.3882994651794434, avg loss: 1.3866561734676361\n",
      "trial: 2, iter: 600, curr loss: 1.388687014579773, avg loss: 1.3865338629484176\n",
      "trial: 2, iter: 800, curr loss: 1.3856971263885498, avg loss: 1.386354804635048\n",
      "trial: 2, iter: 1000, curr loss: 1.3846073150634766, avg loss: 1.3860131043195725\n",
      "trial: 2, iter: 1200, curr loss: 1.3765515089035034, avg loss: 1.3821090185642242\n",
      "trial: 2, iter: 1400, curr loss: 1.3746203184127808, avg loss: 1.372254531979561\n",
      "trial: 2, iter: 1600, curr loss: 1.3897267580032349, avg loss: 1.367273645401001\n",
      "trial: 2, iter: 1800, curr loss: 1.363110065460205, avg loss: 1.3643818962574006\n",
      "trial: 2, iter: 2000, curr loss: 1.3495286703109741, avg loss: 1.3647709703445434\n",
      "trial: 2, iter: 2200, curr loss: 1.3501262664794922, avg loss: 1.361065586209297\n",
      "trial: 2, iter: 2400, curr loss: 1.3631149530410767, avg loss: 1.3593425399065018\n",
      "trial: 2, iter: 2600, curr loss: 1.3665968179702759, avg loss: 1.3571963101625442\n",
      "trial: 2, iter: 2800, curr loss: 1.357681393623352, avg loss: 1.3560334157943725\n",
      "trial: 2, iter: 3000, curr loss: 1.3604295253753662, avg loss: 1.3528355425596237\n",
      "trial: 2, iter: 3200, curr loss: 1.34171462059021, avg loss: 1.3444853007793427\n",
      "trial: 2, iter: 3400, curr loss: 1.3552601337432861, avg loss: 1.334904123544693\n",
      "trial: 2, iter: 3600, curr loss: 1.3343325853347778, avg loss: 1.3291911816596984\n",
      "trial: 2, iter: 3800, curr loss: 1.3348311185836792, avg loss: 1.3222117525339128\n",
      "trial: 2, iter: 4000, curr loss: 1.3099912405014038, avg loss: 1.3189626890420914\n",
      "trial: 2, iter: 4200, curr loss: 1.3091840744018555, avg loss: 1.3205153489112853\n",
      "trial: 2, iter: 4400, curr loss: 1.3405579328536987, avg loss: 1.3206858944892883\n",
      "trial: 2, iter: 4600, curr loss: 1.318097710609436, avg loss: 1.3154604744911194\n",
      "trial: 2, iter: 4800, curr loss: 1.285065770149231, avg loss: 1.3126570564508437\n",
      "trial: 2, iter: 5000, curr loss: 1.2803846597671509, avg loss: 1.3109153735637664\n",
      "trial: 2, iter: 5200, curr loss: 1.3125687837600708, avg loss: 1.307524174451828\n",
      "trial: 2, iter: 5400, curr loss: 1.3278857469558716, avg loss: 1.3084101724624633\n",
      "trial: 2, iter: 5600, curr loss: 1.308304786682129, avg loss: 1.3049806970357896\n",
      "trial: 2, iter: 5800, curr loss: 1.319284200668335, avg loss: 1.302604888677597\n",
      "trial: 2, iter: 6000, curr loss: 1.3039137125015259, avg loss: 1.302703178524971\n",
      "trial: 2, iter: 6200, curr loss: 1.2902177572250366, avg loss: 1.302025316953659\n",
      "trial: 2, ldr: 0.26553961634635925\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3857026100158691, avg loss: 1.3870466804504396\n",
      "trial: 3, iter: 400, curr loss: 1.3847109079360962, avg loss: 1.3865799760818482\n",
      "trial: 3, iter: 600, curr loss: 1.3842551708221436, avg loss: 1.3862999963760376\n",
      "trial: 3, iter: 800, curr loss: 1.3825817108154297, avg loss: 1.385484098792076\n",
      "trial: 3, iter: 1000, curr loss: 1.3635950088500977, avg loss: 1.3799433100223542\n",
      "trial: 3, iter: 1200, curr loss: 1.3675882816314697, avg loss: 1.3711164408922196\n",
      "trial: 3, iter: 1400, curr loss: 1.35889732837677, avg loss: 1.3666379886865616\n",
      "trial: 3, iter: 1600, curr loss: 1.3669227361679077, avg loss: 1.3629638999700546\n",
      "trial: 3, iter: 1800, curr loss: 1.3606348037719727, avg loss: 1.3582185536623002\n",
      "trial: 3, iter: 2000, curr loss: 1.3590909242630005, avg loss: 1.355200834274292\n",
      "trial: 3, iter: 2200, curr loss: 1.3474159240722656, avg loss: 1.35168498814106\n",
      "trial: 3, iter: 2400, curr loss: 1.335694670677185, avg loss: 1.339916431903839\n",
      "trial: 3, iter: 2600, curr loss: 1.3122942447662354, avg loss: 1.3319443261623383\n",
      "trial: 3, iter: 2800, curr loss: 1.3737818002700806, avg loss: 1.3283073455095291\n",
      "trial: 3, iter: 3000, curr loss: 1.339247226715088, avg loss: 1.322773396372795\n",
      "trial: 3, iter: 3200, curr loss: 1.3062469959259033, avg loss: 1.3231775534152985\n",
      "trial: 3, iter: 3400, curr loss: 1.3356213569641113, avg loss: 1.3184288704395295\n",
      "trial: 3, iter: 3600, curr loss: 1.310773253440857, avg loss: 1.3165796548128128\n",
      "trial: 3, iter: 3800, curr loss: 1.3224360942840576, avg loss: 1.314987976551056\n",
      "trial: 3, iter: 4000, curr loss: 1.3105919361114502, avg loss: 1.3145355427265166\n",
      "trial: 3, iter: 4200, curr loss: 1.3320810794830322, avg loss: 1.31469792842865\n",
      "trial: 3, iter: 4400, curr loss: 1.3368253707885742, avg loss: 1.3134178555011748\n",
      "trial: 3, iter: 4600, curr loss: 1.2926983833312988, avg loss: 1.3098019689321518\n",
      "trial: 3, iter: 4800, curr loss: 1.2823309898376465, avg loss: 1.309450061917305\n",
      "trial: 3, iter: 5000, curr loss: 1.3317124843597412, avg loss: 1.3077504324913025\n",
      "trial: 3, iter: 5200, curr loss: 1.309624433517456, avg loss: 1.3063050901889801\n",
      "trial: 3, iter: 5400, curr loss: 1.2725162506103516, avg loss: 1.3059977477788924\n",
      "trial: 3, iter: 5600, curr loss: 1.3144006729125977, avg loss: 1.301678283214569\n",
      "trial: 3, iter: 5800, curr loss: 1.2948380708694458, avg loss: 1.304302379488945\n",
      "trial: 3, iter: 6000, curr loss: 1.287137508392334, avg loss: 1.3027076905965804\n",
      "trial: 3, iter: 6200, curr loss: 1.317846655845642, avg loss: 1.3029855501651764\n",
      "trial: 3, ldr: 0.26993221044540405\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3877313137054443, avg loss: 1.3873162323236465\n",
      "trial: 4, iter: 400, curr loss: 1.3876395225524902, avg loss: 1.3865135037899017\n",
      "trial: 4, iter: 600, curr loss: 1.3847239017486572, avg loss: 1.3864562547206878\n",
      "trial: 4, iter: 800, curr loss: 1.3856806755065918, avg loss: 1.3859487068653107\n",
      "trial: 4, iter: 1000, curr loss: 1.3806343078613281, avg loss: 1.381803778409958\n",
      "trial: 4, iter: 1200, curr loss: 1.362990140914917, avg loss: 1.3709342366456985\n",
      "trial: 4, iter: 1400, curr loss: 1.3712466955184937, avg loss: 1.3639668315649032\n",
      "trial: 4, iter: 1600, curr loss: 1.3486543893814087, avg loss: 1.361499185562134\n",
      "trial: 4, iter: 1800, curr loss: 1.3395010232925415, avg loss: 1.3543701082468034\n",
      "trial: 4, iter: 2000, curr loss: 1.3532261848449707, avg loss: 1.3503703784942627\n",
      "trial: 4, iter: 2200, curr loss: 1.3418399095535278, avg loss: 1.344245235323906\n",
      "trial: 4, iter: 2400, curr loss: 1.3521273136138916, avg loss: 1.3383183097839355\n",
      "trial: 4, iter: 2600, curr loss: 1.3487012386322021, avg loss: 1.3323882114887238\n",
      "trial: 4, iter: 2800, curr loss: 1.315086007118225, avg loss: 1.3328569400310517\n",
      "trial: 4, iter: 3000, curr loss: 1.342463731765747, avg loss: 1.3266457104682923\n",
      "trial: 4, iter: 3200, curr loss: 1.2986788749694824, avg loss: 1.3215755206346511\n",
      "trial: 4, iter: 3400, curr loss: 1.295248031616211, avg loss: 1.3185909593105316\n",
      "trial: 4, iter: 3600, curr loss: 1.325946569442749, avg loss: 1.3163589960336686\n",
      "trial: 4, iter: 3800, curr loss: 1.288144826889038, avg loss: 1.3136153626441955\n",
      "trial: 4, iter: 4000, curr loss: 1.2849186658859253, avg loss: 1.3138268780708313\n",
      "trial: 4, iter: 4200, curr loss: 1.3087888956069946, avg loss: 1.31407681286335\n",
      "trial: 4, iter: 4400, curr loss: 1.3151583671569824, avg loss: 1.3090284484624863\n",
      "trial: 4, iter: 4600, curr loss: 1.300742745399475, avg loss: 1.308407998085022\n",
      "trial: 4, iter: 4800, curr loss: 1.2928330898284912, avg loss: 1.3095012497901917\n",
      "trial: 4, iter: 5000, curr loss: 1.333874225616455, avg loss: 1.3050838989019393\n",
      "trial: 4, iter: 5200, curr loss: 1.3357884883880615, avg loss: 1.3037316858768464\n",
      "trial: 4, iter: 5400, curr loss: 1.3167484998703003, avg loss: 1.3052036917209626\n",
      "trial: 4, iter: 5600, curr loss: 1.3077304363250732, avg loss: 1.303933300971985\n",
      "trial: 4, iter: 5800, curr loss: 1.3173611164093018, avg loss: 1.3018717581033707\n",
      "trial: 4, iter: 6000, curr loss: 1.2896919250488281, avg loss: 1.3016993719339371\n",
      "trial: 4, iter: 6200, curr loss: 1.3005746603012085, avg loss: 1.30196568608284\n",
      "trial: 4, ldr: 0.32516729831695557\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3868701457977295, avg loss: 1.3869700312614441\n",
      "trial: 5, iter: 400, curr loss: 1.3848308324813843, avg loss: 1.3868049478530884\n",
      "trial: 5, iter: 600, curr loss: 1.3842737674713135, avg loss: 1.386487450003624\n",
      "trial: 5, iter: 800, curr loss: 1.3840901851654053, avg loss: 1.3858122950792313\n",
      "trial: 5, iter: 1000, curr loss: 1.3851101398468018, avg loss: 1.3835194998979568\n",
      "trial: 5, iter: 1200, curr loss: 1.3554712533950806, avg loss: 1.3747744250297547\n",
      "trial: 5, iter: 1400, curr loss: 1.347123622894287, avg loss: 1.367530456185341\n",
      "trial: 5, iter: 1600, curr loss: 1.3573113679885864, avg loss: 1.3634070926904678\n",
      "trial: 5, iter: 1800, curr loss: 1.3539663553237915, avg loss: 1.3612371635437013\n",
      "trial: 5, iter: 2000, curr loss: 1.3673951625823975, avg loss: 1.3565259063243866\n",
      "trial: 5, iter: 2200, curr loss: 1.3619697093963623, avg loss: 1.3518510073423387\n",
      "trial: 5, iter: 2400, curr loss: 1.3406097888946533, avg loss: 1.3475038093328475\n",
      "trial: 5, iter: 2600, curr loss: 1.3347761631011963, avg loss: 1.3397337341308593\n",
      "trial: 5, iter: 2800, curr loss: 1.2944368124008179, avg loss: 1.3307865637540817\n",
      "trial: 5, iter: 3000, curr loss: 1.3358700275421143, avg loss: 1.326481876373291\n",
      "trial: 5, iter: 3200, curr loss: 1.3412188291549683, avg loss: 1.3233639216423034\n",
      "trial: 5, iter: 3400, curr loss: 1.2968239784240723, avg loss: 1.3175822597742082\n",
      "trial: 5, iter: 3600, curr loss: 1.3557558059692383, avg loss: 1.3198648273944855\n",
      "trial: 5, iter: 3800, curr loss: 1.2656699419021606, avg loss: 1.3143720495700837\n",
      "trial: 5, iter: 4000, curr loss: 1.321474313735962, avg loss: 1.315592318177223\n",
      "trial: 5, iter: 4200, curr loss: 1.3143495321273804, avg loss: 1.3110394775867462\n",
      "trial: 5, iter: 4400, curr loss: 1.2985862493515015, avg loss: 1.311804461479187\n",
      "trial: 5, iter: 4600, curr loss: 1.2949533462524414, avg loss: 1.3087685573101044\n",
      "trial: 5, iter: 4800, curr loss: 1.2986278533935547, avg loss: 1.30704607963562\n",
      "trial: 5, iter: 5000, curr loss: 1.3441847562789917, avg loss: 1.3075135517120362\n",
      "trial: 5, iter: 5200, curr loss: 1.30745530128479, avg loss: 1.3063021337985992\n",
      "trial: 5, iter: 5400, curr loss: 1.3342561721801758, avg loss: 1.3029512655735016\n",
      "trial: 5, iter: 5600, curr loss: 1.323667049407959, avg loss: 1.3015152490139008\n",
      "trial: 5, iter: 5800, curr loss: 1.3031005859375, avg loss: 1.3007744252681732\n",
      "trial: 5, iter: 6000, curr loss: 1.3028945922851562, avg loss: 1.2996032190322877\n",
      "trial: 5, iter: 6200, curr loss: 1.2879129648208618, avg loss: 1.2993829077482224\n",
      "trial: 5, ldr: 0.2579575777053833\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2818227231502533\n",
      "Experiment done with data path: ./data/catNon-lin-NI_11/data.20k.dz50.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_7/data.20k.dz20.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3864543437957764, avg loss: 1.387138375043869\n",
      "trial: 1, iter: 400, curr loss: 1.3860700130462646, avg loss: 1.386665363907814\n",
      "trial: 1, iter: 600, curr loss: 1.3843669891357422, avg loss: 1.3866334211826326\n",
      "trial: 1, iter: 800, curr loss: 1.3858710527420044, avg loss: 1.3863836580514908\n",
      "trial: 1, iter: 1000, curr loss: 1.384137511253357, avg loss: 1.3862679344415665\n",
      "trial: 1, iter: 1200, curr loss: 1.3853940963745117, avg loss: 1.3862761598825455\n",
      "trial: 1, iter: 1400, curr loss: 1.3853049278259277, avg loss: 1.3859499764442444\n",
      "trial: 1, iter: 1600, curr loss: 1.3862262964248657, avg loss: 1.3848581886291504\n",
      "trial: 1, iter: 1800, curr loss: 1.3773655891418457, avg loss: 1.3810631680488585\n",
      "trial: 1, iter: 2000, curr loss: 1.3672658205032349, avg loss: 1.3730310720205308\n",
      "trial: 1, iter: 2200, curr loss: 1.370309829711914, avg loss: 1.361053441762924\n",
      "trial: 1, iter: 2400, curr loss: 1.3453710079193115, avg loss: 1.349896889925003\n",
      "trial: 1, iter: 2600, curr loss: 1.3328595161437988, avg loss: 1.3458726423978806\n",
      "trial: 1, iter: 2800, curr loss: 1.338361144065857, avg loss: 1.3376675564050675\n",
      "trial: 1, iter: 3000, curr loss: 1.32973313331604, avg loss: 1.337055898308754\n",
      "trial: 1, iter: 3200, curr loss: 1.3385343551635742, avg loss: 1.3367390942573547\n",
      "trial: 1, iter: 3400, curr loss: 1.3092275857925415, avg loss: 1.3349024832248688\n",
      "trial: 1, iter: 3600, curr loss: 1.3302384614944458, avg loss: 1.3339005982875825\n",
      "trial: 1, iter: 3800, curr loss: 1.3400834798812866, avg loss: 1.3276299488544465\n",
      "trial: 1, iter: 4000, curr loss: 1.3372303247451782, avg loss: 1.330030888915062\n",
      "trial: 1, iter: 4200, curr loss: 1.333105206489563, avg loss: 1.330409792661667\n",
      "trial: 1, iter: 4400, curr loss: 1.3226336240768433, avg loss: 1.3253627598285675\n",
      "trial: 1, iter: 4600, curr loss: 1.3303874731063843, avg loss: 1.3270833170413971\n",
      "trial: 1, iter: 4800, curr loss: 1.3210145235061646, avg loss: 1.3271661871671676\n",
      "trial: 1, iter: 5000, curr loss: 1.324049711227417, avg loss: 1.3268367767333984\n",
      "trial: 1, iter: 5200, curr loss: 1.3127435445785522, avg loss: 1.3261860835552215\n",
      "trial: 1, iter: 5400, curr loss: 1.2693339586257935, avg loss: 1.3243363970518112\n",
      "trial: 1, iter: 5600, curr loss: 1.359728217124939, avg loss: 1.324095304608345\n",
      "trial: 1, iter: 5800, curr loss: 1.3193809986114502, avg loss: 1.3237939673662185\n",
      "trial: 1, iter: 6000, curr loss: 1.3335976600646973, avg loss: 1.321155521273613\n",
      "trial: 1, iter: 6200, curr loss: 1.3411228656768799, avg loss: 1.3181315594911576\n",
      "trial: 1, ldr: 0.05114457756280899\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387423038482666, avg loss: 1.3879670131206512\n",
      "trial: 2, iter: 400, curr loss: 1.3872400522232056, avg loss: 1.3868777167797088\n",
      "trial: 2, iter: 600, curr loss: 1.3875969648361206, avg loss: 1.3866032522916794\n",
      "trial: 2, iter: 800, curr loss: 1.3872835636138916, avg loss: 1.3867524528503419\n",
      "trial: 2, iter: 1000, curr loss: 1.3858078718185425, avg loss: 1.3865119022130967\n",
      "trial: 2, iter: 1200, curr loss: 1.3872867822647095, avg loss: 1.38617620408535\n",
      "trial: 2, iter: 1400, curr loss: 1.385115385055542, avg loss: 1.3860374426841735\n",
      "trial: 2, iter: 1600, curr loss: 1.3862903118133545, avg loss: 1.385479000210762\n",
      "trial: 2, iter: 1800, curr loss: 1.3788728713989258, avg loss: 1.383762611746788\n",
      "trial: 2, iter: 2000, curr loss: 1.3713830709457397, avg loss: 1.3808927434682845\n",
      "trial: 2, iter: 2200, curr loss: 1.3585761785507202, avg loss: 1.3742229568958282\n",
      "trial: 2, iter: 2400, curr loss: 1.3515008687973022, avg loss: 1.3653553813695907\n",
      "trial: 2, iter: 2600, curr loss: 1.378953456878662, avg loss: 1.3548582261800766\n",
      "trial: 2, iter: 2800, curr loss: 1.3461025953292847, avg loss: 1.3476209676265716\n",
      "trial: 2, iter: 3000, curr loss: 1.3600945472717285, avg loss: 1.339484845995903\n",
      "trial: 2, iter: 3200, curr loss: 1.3351668119430542, avg loss: 1.338210290670395\n",
      "trial: 2, iter: 3400, curr loss: 1.3000664710998535, avg loss: 1.335670381784439\n",
      "trial: 2, iter: 3600, curr loss: 1.3103853464126587, avg loss: 1.3320365607738496\n",
      "trial: 2, iter: 3800, curr loss: 1.3403708934783936, avg loss: 1.3311972188949586\n",
      "trial: 2, iter: 4000, curr loss: 1.3475167751312256, avg loss: 1.3299965810775758\n",
      "trial: 2, iter: 4200, curr loss: 1.3237534761428833, avg loss: 1.3290849655866623\n",
      "trial: 2, iter: 4400, curr loss: 1.3357669115066528, avg loss: 1.3281474858522415\n",
      "trial: 2, iter: 4600, curr loss: 1.2994691133499146, avg loss: 1.3265075343847275\n",
      "trial: 2, iter: 4800, curr loss: 1.2996234893798828, avg loss: 1.3219845616817474\n",
      "trial: 2, iter: 5000, curr loss: 1.345509648323059, avg loss: 1.324608062505722\n",
      "trial: 2, iter: 5200, curr loss: 1.3080836534500122, avg loss: 1.3232590758800507\n",
      "trial: 2, iter: 5400, curr loss: 1.3267008066177368, avg loss: 1.3254923683404922\n",
      "trial: 2, iter: 5600, curr loss: 1.3272281885147095, avg loss: 1.323255250453949\n",
      "trial: 2, iter: 5800, curr loss: 1.3002700805664062, avg loss: 1.3188526344299316\n",
      "trial: 2, iter: 6000, curr loss: 1.2971787452697754, avg loss: 1.3223109203577041\n",
      "trial: 2, iter: 6200, curr loss: 1.3210771083831787, avg loss: 1.3217057073116303\n",
      "trial: 2, ldr: -0.039784226566553116\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3872883319854736, avg loss: 1.3873718839883804\n",
      "trial: 3, iter: 400, curr loss: 1.385542869567871, avg loss: 1.386625212430954\n",
      "trial: 3, iter: 600, curr loss: 1.387537956237793, avg loss: 1.38657530605793\n",
      "trial: 3, iter: 800, curr loss: 1.3851979970932007, avg loss: 1.386487870812416\n",
      "trial: 3, iter: 1000, curr loss: 1.3861455917358398, avg loss: 1.3863872909545898\n",
      "trial: 3, iter: 1200, curr loss: 1.3865691423416138, avg loss: 1.3860687291622162\n",
      "trial: 3, iter: 1400, curr loss: 1.3834753036499023, avg loss: 1.3856668281555176\n",
      "trial: 3, iter: 1600, curr loss: 1.384624719619751, avg loss: 1.384740300178528\n",
      "trial: 3, iter: 1800, curr loss: 1.3820253610610962, avg loss: 1.3828895676136017\n",
      "trial: 3, iter: 2000, curr loss: 1.3733094930648804, avg loss: 1.3773936969041825\n",
      "trial: 3, iter: 2200, curr loss: 1.3791238069534302, avg loss: 1.372304978966713\n",
      "trial: 3, iter: 2400, curr loss: 1.3525152206420898, avg loss: 1.3619409340620041\n",
      "trial: 3, iter: 2600, curr loss: 1.344268560409546, avg loss: 1.354655848145485\n",
      "trial: 3, iter: 2800, curr loss: 1.3282147645950317, avg loss: 1.3467586719989777\n",
      "trial: 3, iter: 3000, curr loss: 1.344962477684021, avg loss: 1.34123604118824\n",
      "trial: 3, iter: 3200, curr loss: 1.3137593269348145, avg loss: 1.3363177704811096\n",
      "trial: 3, iter: 3400, curr loss: 1.3414201736450195, avg loss: 1.3356139487028122\n",
      "trial: 3, iter: 3600, curr loss: 1.3454934358596802, avg loss: 1.330577216744423\n",
      "trial: 3, iter: 3800, curr loss: 1.3223068714141846, avg loss: 1.3309735763072967\n",
      "trial: 3, iter: 4000, curr loss: 1.3397340774536133, avg loss: 1.3305072581768036\n",
      "trial: 3, iter: 4200, curr loss: 1.313814401626587, avg loss: 1.3297653019428253\n",
      "trial: 3, iter: 4400, curr loss: 1.3190100193023682, avg loss: 1.3271394962072371\n",
      "trial: 3, iter: 4600, curr loss: 1.328505277633667, avg loss: 1.3253943920135498\n",
      "trial: 3, iter: 4800, curr loss: 1.3286464214324951, avg loss: 1.325190799832344\n",
      "trial: 3, iter: 5000, curr loss: 1.308356761932373, avg loss: 1.3232859510183335\n",
      "trial: 3, iter: 5200, curr loss: 1.2976677417755127, avg loss: 1.324291418194771\n",
      "trial: 3, iter: 5400, curr loss: 1.3461281061172485, avg loss: 1.3246089297533035\n",
      "trial: 3, iter: 5600, curr loss: 1.3240426778793335, avg loss: 1.3214698511362075\n",
      "trial: 3, iter: 5800, curr loss: 1.3113906383514404, avg loss: 1.322161203622818\n",
      "trial: 3, iter: 6000, curr loss: 1.3219658136367798, avg loss: 1.3231215459108352\n",
      "trial: 3, iter: 6200, curr loss: 1.3366976976394653, avg loss: 1.3206047379970551\n",
      "trial: 3, ldr: -0.02041773311793804\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3872677087783813, avg loss: 1.3876647692918778\n",
      "trial: 4, iter: 400, curr loss: 1.3850369453430176, avg loss: 1.3867758721113206\n",
      "trial: 4, iter: 600, curr loss: 1.3853192329406738, avg loss: 1.3868005824089051\n",
      "trial: 4, iter: 800, curr loss: 1.3862264156341553, avg loss: 1.38664553463459\n",
      "trial: 4, iter: 1000, curr loss: 1.3843482732772827, avg loss: 1.3864549970626832\n",
      "trial: 4, iter: 1200, curr loss: 1.385133147239685, avg loss: 1.3864265209436417\n",
      "trial: 4, iter: 1400, curr loss: 1.3881155252456665, avg loss: 1.386008859872818\n",
      "trial: 4, iter: 1600, curr loss: 1.3826767206192017, avg loss: 1.3851989382505416\n",
      "trial: 4, iter: 1800, curr loss: 1.3815537691116333, avg loss: 1.3828005874156952\n",
      "trial: 4, iter: 2000, curr loss: 1.3699617385864258, avg loss: 1.376523361802101\n",
      "trial: 4, iter: 2200, curr loss: 1.3474760055541992, avg loss: 1.3661757826805114\n",
      "trial: 4, iter: 2400, curr loss: 1.3430333137512207, avg loss: 1.354596494436264\n",
      "trial: 4, iter: 2600, curr loss: 1.36652672290802, avg loss: 1.349134283065796\n",
      "trial: 4, iter: 2800, curr loss: 1.3237035274505615, avg loss: 1.3413041985034944\n",
      "trial: 4, iter: 3000, curr loss: 1.3549981117248535, avg loss: 1.3389862221479416\n",
      "trial: 4, iter: 3200, curr loss: 1.3379762172698975, avg loss: 1.3363709884881974\n",
      "trial: 4, iter: 3400, curr loss: 1.3619840145111084, avg loss: 1.334423493742943\n",
      "trial: 4, iter: 3600, curr loss: 1.36334228515625, avg loss: 1.3351023709774017\n",
      "trial: 4, iter: 3800, curr loss: 1.3319897651672363, avg loss: 1.3316142767667771\n",
      "trial: 4, iter: 4000, curr loss: 1.319351077079773, avg loss: 1.3327121430635451\n",
      "trial: 4, iter: 4200, curr loss: 1.3197319507598877, avg loss: 1.3271627002954482\n",
      "trial: 4, iter: 4400, curr loss: 1.349523663520813, avg loss: 1.3283469027280808\n",
      "trial: 4, iter: 4600, curr loss: 1.3419185876846313, avg loss: 1.3259526652097702\n",
      "trial: 4, iter: 4800, curr loss: 1.3324275016784668, avg loss: 1.3270540875196457\n",
      "trial: 4, iter: 5000, curr loss: 1.3079209327697754, avg loss: 1.3259433561563492\n",
      "trial: 4, iter: 5200, curr loss: 1.326326847076416, avg loss: 1.3251421797275542\n",
      "trial: 4, iter: 5400, curr loss: 1.3325358629226685, avg loss: 1.3243817812204361\n",
      "trial: 4, iter: 5600, curr loss: 1.3130847215652466, avg loss: 1.3236984795331954\n",
      "trial: 4, iter: 5800, curr loss: 1.3147987127304077, avg loss: 1.3256866806745529\n",
      "trial: 4, iter: 6000, curr loss: 1.3534733057022095, avg loss: 1.3228291243314743\n",
      "trial: 4, iter: 6200, curr loss: 1.3870272636413574, avg loss: 1.318102974295616\n",
      "trial: 4, ldr: 0.026669060811400414\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3854420185089111, avg loss: 1.3875035810470582\n",
      "trial: 5, iter: 400, curr loss: 1.384893774986267, avg loss: 1.3868748879432677\n",
      "trial: 5, iter: 600, curr loss: 1.3853052854537964, avg loss: 1.3866534680128098\n",
      "trial: 5, iter: 800, curr loss: 1.385938286781311, avg loss: 1.3865685218572616\n",
      "trial: 5, iter: 1000, curr loss: 1.385558009147644, avg loss: 1.3864726203680038\n",
      "trial: 5, iter: 1200, curr loss: 1.385120153427124, avg loss: 1.3860490548610687\n",
      "trial: 5, iter: 1400, curr loss: 1.384688138961792, avg loss: 1.3858082348108292\n",
      "trial: 5, iter: 1600, curr loss: 1.3834336996078491, avg loss: 1.3848345494270324\n",
      "trial: 5, iter: 1800, curr loss: 1.3806962966918945, avg loss: 1.3816691666841507\n",
      "trial: 5, iter: 2000, curr loss: 1.3848636150360107, avg loss: 1.3764137601852418\n",
      "trial: 5, iter: 2200, curr loss: 1.3577948808670044, avg loss: 1.366175497174263\n",
      "trial: 5, iter: 2400, curr loss: 1.364109992980957, avg loss: 1.3544962137937546\n",
      "trial: 5, iter: 2600, curr loss: 1.3602436780929565, avg loss: 1.3441914594173432\n",
      "trial: 5, iter: 2800, curr loss: 1.3470169305801392, avg loss: 1.3409977811574936\n",
      "trial: 5, iter: 3000, curr loss: 1.2977830171585083, avg loss: 1.3368840628862382\n",
      "trial: 5, iter: 3200, curr loss: 1.3209517002105713, avg loss: 1.3353916263580323\n",
      "trial: 5, iter: 3400, curr loss: 1.327905297279358, avg loss: 1.3288133502006532\n",
      "trial: 5, iter: 3600, curr loss: 1.3681656122207642, avg loss: 1.3335431414842605\n",
      "trial: 5, iter: 3800, curr loss: 1.3243696689605713, avg loss: 1.3271353489160538\n",
      "trial: 5, iter: 4000, curr loss: 1.338616132736206, avg loss: 1.3288457733392716\n",
      "trial: 5, iter: 4200, curr loss: 1.3326771259307861, avg loss: 1.3247712576389312\n",
      "trial: 5, iter: 4400, curr loss: 1.310833215713501, avg loss: 1.3237794953584672\n",
      "trial: 5, iter: 4600, curr loss: 1.3146567344665527, avg loss: 1.3234592258930207\n",
      "trial: 5, iter: 4800, curr loss: 1.3265087604522705, avg loss: 1.3239776122570037\n",
      "trial: 5, iter: 5000, curr loss: 1.3623102903366089, avg loss: 1.3243828946352005\n",
      "trial: 5, iter: 5200, curr loss: 1.3265459537506104, avg loss: 1.3197775065898896\n",
      "trial: 5, iter: 5400, curr loss: 1.326610803604126, avg loss: 1.32105921626091\n",
      "trial: 5, iter: 5600, curr loss: 1.3183168172836304, avg loss: 1.3195193779468537\n",
      "trial: 5, iter: 5800, curr loss: 1.3219295740127563, avg loss: 1.3213036757707597\n",
      "trial: 5, iter: 6000, curr loss: 1.2732205390930176, avg loss: 1.3185441446304322\n",
      "trial: 5, iter: 6200, curr loss: 1.2974239587783813, avg loss: 1.318569085597992\n",
      "trial: 5, ldr: 0.02080892026424408\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.007684119790792465\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.387688159942627, avg loss: 1.3869906747341156\n",
      "trial: 1, iter: 400, curr loss: 1.3861029148101807, avg loss: 1.3867705392837524\n",
      "trial: 1, iter: 600, curr loss: 1.3876560926437378, avg loss: 1.3866186195611954\n",
      "trial: 1, iter: 800, curr loss: 1.3871264457702637, avg loss: 1.3864676785469054\n",
      "trial: 1, iter: 1000, curr loss: 1.390272855758667, avg loss: 1.386146535873413\n",
      "trial: 1, iter: 1200, curr loss: 1.3844385147094727, avg loss: 1.386163471341133\n",
      "trial: 1, iter: 1400, curr loss: 1.3863916397094727, avg loss: 1.3862216359376907\n",
      "trial: 1, iter: 1600, curr loss: 1.3877087831497192, avg loss: 1.3855879664421082\n",
      "trial: 1, iter: 1800, curr loss: 1.389548420906067, avg loss: 1.3844475781917571\n",
      "trial: 1, iter: 2000, curr loss: 1.3854215145111084, avg loss: 1.3828626674413682\n",
      "trial: 1, iter: 2200, curr loss: 1.3739736080169678, avg loss: 1.37944768846035\n",
      "trial: 1, iter: 2400, curr loss: 1.371917963027954, avg loss: 1.3754618847370148\n",
      "trial: 1, iter: 2600, curr loss: 1.3688311576843262, avg loss: 1.3693413984775544\n",
      "trial: 1, iter: 2800, curr loss: 1.3410347700119019, avg loss: 1.3623179769515992\n",
      "trial: 1, iter: 3000, curr loss: 1.335568904876709, avg loss: 1.3544463068246841\n",
      "trial: 1, iter: 3200, curr loss: 1.3491343259811401, avg loss: 1.3485341191291809\n",
      "trial: 1, iter: 3400, curr loss: 1.3444875478744507, avg loss: 1.347609018087387\n",
      "trial: 1, iter: 3600, curr loss: 1.3585339784622192, avg loss: 1.340027305483818\n",
      "trial: 1, iter: 3800, curr loss: 1.3408396244049072, avg loss: 1.3381480979919433\n",
      "trial: 1, iter: 4000, curr loss: 1.353775143623352, avg loss: 1.3363858926296235\n",
      "trial: 1, iter: 4200, curr loss: 1.330372929573059, avg loss: 1.3314658546447753\n",
      "trial: 1, iter: 4400, curr loss: 1.3424519300460815, avg loss: 1.330912200808525\n",
      "trial: 1, iter: 4600, curr loss: 1.361419916152954, avg loss: 1.327149856686592\n",
      "trial: 1, iter: 4800, curr loss: 1.3467864990234375, avg loss: 1.328665673136711\n",
      "trial: 1, iter: 5000, curr loss: 1.3245511054992676, avg loss: 1.3253802263736725\n",
      "trial: 1, iter: 5200, curr loss: 1.356933355331421, avg loss: 1.3258512783050538\n",
      "trial: 1, iter: 5400, curr loss: 1.3359214067459106, avg loss: 1.3246924680471421\n",
      "trial: 1, iter: 5600, curr loss: 1.3341248035430908, avg loss: 1.3236352837085723\n",
      "trial: 1, iter: 5800, curr loss: 1.3169761896133423, avg loss: 1.32302778840065\n",
      "trial: 1, iter: 6000, curr loss: 1.3334355354309082, avg loss: 1.3209826868772507\n",
      "trial: 1, iter: 6200, curr loss: 1.3011125326156616, avg loss: 1.3205608379840852\n",
      "trial: 1, ldr: 0.014331048354506493\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3897874355316162, avg loss: 1.387193358540535\n",
      "trial: 2, iter: 400, curr loss: 1.388411283493042, avg loss: 1.3868310236930848\n",
      "trial: 2, iter: 600, curr loss: 1.3890595436096191, avg loss: 1.386584221124649\n",
      "trial: 2, iter: 800, curr loss: 1.3876146078109741, avg loss: 1.386462885737419\n",
      "trial: 2, iter: 1000, curr loss: 1.3879950046539307, avg loss: 1.3863229650259017\n",
      "trial: 2, iter: 1200, curr loss: 1.3854238986968994, avg loss: 1.386190180182457\n",
      "trial: 2, iter: 1400, curr loss: 1.3856019973754883, avg loss: 1.386006081700325\n",
      "trial: 2, iter: 1600, curr loss: 1.3833547830581665, avg loss: 1.3854350519180298\n",
      "trial: 2, iter: 1800, curr loss: 1.3798624277114868, avg loss: 1.3838874578475953\n",
      "trial: 2, iter: 2000, curr loss: 1.3819630146026611, avg loss: 1.3796203243732452\n",
      "trial: 2, iter: 2200, curr loss: 1.3588813543319702, avg loss: 1.3716688072681427\n",
      "trial: 2, iter: 2400, curr loss: 1.360107421875, avg loss: 1.3606917709112167\n",
      "trial: 2, iter: 2600, curr loss: 1.3623013496398926, avg loss: 1.350093855857849\n",
      "trial: 2, iter: 2800, curr loss: 1.3226549625396729, avg loss: 1.3416738432645798\n",
      "trial: 2, iter: 3000, curr loss: 1.3282941579818726, avg loss: 1.340310935974121\n",
      "trial: 2, iter: 3200, curr loss: 1.3317997455596924, avg loss: 1.3356898730993272\n",
      "trial: 2, iter: 3400, curr loss: 1.3158470392227173, avg loss: 1.3356809478998184\n",
      "trial: 2, iter: 3600, curr loss: 1.3407777547836304, avg loss: 1.3329330283403396\n",
      "trial: 2, iter: 3800, curr loss: 1.3314682245254517, avg loss: 1.3304404598474502\n",
      "trial: 2, iter: 4000, curr loss: 1.3398656845092773, avg loss: 1.328909723162651\n",
      "trial: 2, iter: 4200, curr loss: 1.3611525297164917, avg loss: 1.3247978782653809\n",
      "trial: 2, iter: 4400, curr loss: 1.3375898599624634, avg loss: 1.3274330925941467\n",
      "trial: 2, iter: 4600, curr loss: 1.339901328086853, avg loss: 1.3273079723119736\n",
      "trial: 2, iter: 4800, curr loss: 1.3273396492004395, avg loss: 1.3251673704385758\n",
      "trial: 2, iter: 5000, curr loss: 1.3442120552062988, avg loss: 1.3239155995845795\n",
      "trial: 2, iter: 5200, curr loss: 1.3514289855957031, avg loss: 1.322595482468605\n",
      "trial: 2, iter: 5400, curr loss: 1.3471894264221191, avg loss: 1.3224817830324174\n",
      "trial: 2, iter: 5600, curr loss: 1.314664602279663, avg loss: 1.3200241804122925\n",
      "trial: 2, iter: 5800, curr loss: 1.334227204322815, avg loss: 1.3208305376768112\n",
      "trial: 2, iter: 6000, curr loss: 1.291284441947937, avg loss: 1.3207665121555328\n",
      "trial: 2, iter: 6200, curr loss: 1.2993206977844238, avg loss: 1.3191476684808732\n",
      "trial: 2, ldr: 0.03888947144150734\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3867104053497314, avg loss: 1.38756289601326\n",
      "trial: 3, iter: 400, curr loss: 1.3839694261550903, avg loss: 1.3867202508449554\n",
      "trial: 3, iter: 600, curr loss: 1.3859858512878418, avg loss: 1.3866609835624695\n",
      "trial: 3, iter: 800, curr loss: 1.3868318796157837, avg loss: 1.3863885152339934\n",
      "trial: 3, iter: 1000, curr loss: 1.3863041400909424, avg loss: 1.3863576543331146\n",
      "trial: 3, iter: 1200, curr loss: 1.3857935667037964, avg loss: 1.3861281621456145\n",
      "trial: 3, iter: 1400, curr loss: 1.386885404586792, avg loss: 1.385590073466301\n",
      "trial: 3, iter: 1600, curr loss: 1.3848373889923096, avg loss: 1.3844369131326675\n",
      "trial: 3, iter: 1800, curr loss: 1.3907341957092285, avg loss: 1.3813428515195847\n",
      "trial: 3, iter: 2000, curr loss: 1.3717014789581299, avg loss: 1.3736791342496872\n",
      "trial: 3, iter: 2200, curr loss: 1.36728036403656, avg loss: 1.362381494641304\n",
      "trial: 3, iter: 2400, curr loss: 1.3474608659744263, avg loss: 1.3509789180755616\n",
      "trial: 3, iter: 2600, curr loss: 1.338115930557251, avg loss: 1.344329023361206\n",
      "trial: 3, iter: 2800, curr loss: 1.3352776765823364, avg loss: 1.3413917469978331\n",
      "trial: 3, iter: 3000, curr loss: 1.3281217813491821, avg loss: 1.3359397673606872\n",
      "trial: 3, iter: 3200, curr loss: 1.3425770998001099, avg loss: 1.3355705094337464\n",
      "trial: 3, iter: 3400, curr loss: 1.3149741888046265, avg loss: 1.3338699382543564\n",
      "trial: 3, iter: 3600, curr loss: 1.3352646827697754, avg loss: 1.3343097591400146\n",
      "trial: 3, iter: 3800, curr loss: 1.3121141195297241, avg loss: 1.3293440818786622\n",
      "trial: 3, iter: 4000, curr loss: 1.3163838386535645, avg loss: 1.3288801223039628\n",
      "trial: 3, iter: 4200, curr loss: 1.3107680082321167, avg loss: 1.3276831126213073\n",
      "trial: 3, iter: 4400, curr loss: 1.3145135641098022, avg loss: 1.327287238240242\n",
      "trial: 3, iter: 4600, curr loss: 1.3318307399749756, avg loss: 1.3283296394348145\n",
      "trial: 3, iter: 4800, curr loss: 1.3423457145690918, avg loss: 1.325770571231842\n",
      "trial: 3, iter: 5000, curr loss: 1.3258699178695679, avg loss: 1.3239183473587035\n",
      "trial: 3, iter: 5200, curr loss: 1.3159739971160889, avg loss: 1.3242540287971496\n",
      "trial: 3, iter: 5400, curr loss: 1.309303641319275, avg loss: 1.3221629631519318\n",
      "trial: 3, iter: 5600, curr loss: 1.3113600015640259, avg loss: 1.3231047576665877\n",
      "trial: 3, iter: 5800, curr loss: 1.307132601737976, avg loss: 1.3213268685340882\n",
      "trial: 3, iter: 6000, curr loss: 1.3016455173492432, avg loss: 1.3247521978616714\n",
      "trial: 3, iter: 6200, curr loss: 1.3115084171295166, avg loss: 1.3212969762086868\n",
      "trial: 3, ldr: 0.05432145297527313\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3856149911880493, avg loss: 1.3872707718610764\n",
      "trial: 4, iter: 400, curr loss: 1.387873888015747, avg loss: 1.3868334406614304\n",
      "trial: 4, iter: 600, curr loss: 1.385636329650879, avg loss: 1.3865383875370025\n",
      "trial: 4, iter: 800, curr loss: 1.3860245943069458, avg loss: 1.3862515658140182\n",
      "trial: 4, iter: 1000, curr loss: 1.3868639469146729, avg loss: 1.3863144212961196\n",
      "trial: 4, iter: 1200, curr loss: 1.3872854709625244, avg loss: 1.3860803180933\n",
      "trial: 4, iter: 1400, curr loss: 1.386396884918213, avg loss: 1.3855662423372268\n",
      "trial: 4, iter: 1600, curr loss: 1.3841073513031006, avg loss: 1.3842217719554901\n",
      "trial: 4, iter: 1800, curr loss: 1.3820499181747437, avg loss: 1.3816214776039124\n",
      "trial: 4, iter: 2000, curr loss: 1.3685436248779297, avg loss: 1.3777381640672683\n",
      "trial: 4, iter: 2200, curr loss: 1.359887719154358, avg loss: 1.3707970613241196\n",
      "trial: 4, iter: 2400, curr loss: 1.3667482137680054, avg loss: 1.3639331841468811\n",
      "trial: 4, iter: 2600, curr loss: 1.3561099767684937, avg loss: 1.3514653658866882\n",
      "trial: 4, iter: 2800, curr loss: 1.3059101104736328, avg loss: 1.3438364911079406\n",
      "trial: 4, iter: 3000, curr loss: 1.3317430019378662, avg loss: 1.3390967571735382\n",
      "trial: 4, iter: 3200, curr loss: 1.3142852783203125, avg loss: 1.3370639020204544\n",
      "trial: 4, iter: 3400, curr loss: 1.3285317420959473, avg loss: 1.3347433292865754\n",
      "trial: 4, iter: 3600, curr loss: 1.322546124458313, avg loss: 1.3338009059429168\n",
      "trial: 4, iter: 3800, curr loss: 1.31688392162323, avg loss: 1.3323009955883025\n",
      "trial: 4, iter: 4000, curr loss: 1.351584792137146, avg loss: 1.3306793040037155\n",
      "trial: 4, iter: 4200, curr loss: 1.3312057256698608, avg loss: 1.3294435650110246\n",
      "trial: 4, iter: 4400, curr loss: 1.3393833637237549, avg loss: 1.3254997730255127\n",
      "trial: 4, iter: 4600, curr loss: 1.3305031061172485, avg loss: 1.3258680665493012\n",
      "trial: 4, iter: 4800, curr loss: 1.3018444776535034, avg loss: 1.3281413996219635\n",
      "trial: 4, iter: 5000, curr loss: 1.3079156875610352, avg loss: 1.324893050789833\n",
      "trial: 4, iter: 5200, curr loss: 1.2994794845581055, avg loss: 1.3252072131633759\n",
      "trial: 4, iter: 5400, curr loss: 1.3207124471664429, avg loss: 1.3243736737966538\n",
      "trial: 4, iter: 5600, curr loss: 1.2845021486282349, avg loss: 1.322047101855278\n",
      "trial: 4, iter: 5800, curr loss: 1.329277753829956, avg loss: 1.3238894301652908\n",
      "trial: 4, iter: 6000, curr loss: 1.307851791381836, avg loss: 1.3223756194114684\n",
      "trial: 4, iter: 6200, curr loss: 1.3413699865341187, avg loss: 1.3224119138717652\n",
      "trial: 4, ldr: 0.03624172881245613\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3894271850585938, avg loss: 1.3870675623416902\n",
      "trial: 5, iter: 400, curr loss: 1.3872008323669434, avg loss: 1.3868704652786255\n",
      "trial: 5, iter: 600, curr loss: 1.3825806379318237, avg loss: 1.3864111202955245\n",
      "trial: 5, iter: 800, curr loss: 1.386959433555603, avg loss: 1.3865178793668747\n",
      "trial: 5, iter: 1000, curr loss: 1.3858346939086914, avg loss: 1.386291317343712\n",
      "trial: 5, iter: 1200, curr loss: 1.3876075744628906, avg loss: 1.3864529567956925\n",
      "trial: 5, iter: 1400, curr loss: 1.3855806589126587, avg loss: 1.386300076842308\n",
      "trial: 5, iter: 1600, curr loss: 1.383892297744751, avg loss: 1.3861666631698608\n",
      "trial: 5, iter: 1800, curr loss: 1.3882075548171997, avg loss: 1.3857187187671662\n",
      "trial: 5, iter: 2000, curr loss: 1.3883265256881714, avg loss: 1.3845636087656021\n",
      "trial: 5, iter: 2200, curr loss: 1.3905752897262573, avg loss: 1.3808392411470414\n",
      "trial: 5, iter: 2400, curr loss: 1.364471673965454, avg loss: 1.373967913389206\n",
      "trial: 5, iter: 2600, curr loss: 1.3604576587677002, avg loss: 1.3584584075212478\n",
      "trial: 5, iter: 2800, curr loss: 1.3230513334274292, avg loss: 1.347199000120163\n",
      "trial: 5, iter: 3000, curr loss: 1.3675518035888672, avg loss: 1.3417198300361632\n",
      "trial: 5, iter: 3200, curr loss: 1.312613844871521, avg loss: 1.3376109647750853\n",
      "trial: 5, iter: 3400, curr loss: 1.318769097328186, avg loss: 1.3358208930492401\n",
      "trial: 5, iter: 3600, curr loss: 1.3346424102783203, avg loss: 1.3347148275375367\n",
      "trial: 5, iter: 3800, curr loss: 1.3069385290145874, avg loss: 1.3320129680633546\n",
      "trial: 5, iter: 4000, curr loss: 1.2949614524841309, avg loss: 1.329994262456894\n",
      "trial: 5, iter: 4200, curr loss: 1.2921316623687744, avg loss: 1.3272308421134948\n",
      "trial: 5, iter: 4400, curr loss: 1.3314037322998047, avg loss: 1.3265372383594514\n",
      "trial: 5, iter: 4600, curr loss: 1.3374722003936768, avg loss: 1.3265204733610154\n",
      "trial: 5, iter: 4800, curr loss: 1.3324464559555054, avg loss: 1.3245718640089035\n",
      "trial: 5, iter: 5000, curr loss: 1.3045594692230225, avg loss: 1.3245670104026794\n",
      "trial: 5, iter: 5200, curr loss: 1.3133450746536255, avg loss: 1.3232638823986054\n",
      "trial: 5, iter: 5400, curr loss: 1.3360099792480469, avg loss: 1.326052538752556\n",
      "trial: 5, iter: 5600, curr loss: 1.3243427276611328, avg loss: 1.3214846378564835\n",
      "trial: 5, iter: 5800, curr loss: 1.328342080116272, avg loss: 1.3222929084300994\n",
      "trial: 5, iter: 6000, curr loss: 1.32085382938385, avg loss: 1.3205331325531007\n",
      "trial: 5, iter: 6200, curr loss: 1.314624547958374, avg loss: 1.3215388292074204\n",
      "trial: 5, ldr: 0.019768936559557915\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0327105276286602\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3877978324890137, avg loss: 1.387621596455574\n",
      "trial: 1, iter: 400, curr loss: 1.3820226192474365, avg loss: 1.3869082647562028\n",
      "trial: 1, iter: 600, curr loss: 1.3881423473358154, avg loss: 1.3866295433044433\n",
      "trial: 1, iter: 800, curr loss: 1.385710597038269, avg loss: 1.3864878028631211\n",
      "trial: 1, iter: 1000, curr loss: 1.3833810091018677, avg loss: 1.3865466332435608\n",
      "trial: 1, iter: 1200, curr loss: 1.3854711055755615, avg loss: 1.3863184833526612\n",
      "trial: 1, iter: 1400, curr loss: 1.3878920078277588, avg loss: 1.386216567158699\n",
      "trial: 1, iter: 1600, curr loss: 1.3843010663986206, avg loss: 1.385971364378929\n",
      "trial: 1, iter: 1800, curr loss: 1.3796087503433228, avg loss: 1.3850086802244186\n",
      "trial: 1, iter: 2000, curr loss: 1.3793758153915405, avg loss: 1.3821479642391206\n",
      "trial: 1, iter: 2200, curr loss: 1.3533763885498047, avg loss: 1.3735456264019013\n",
      "trial: 1, iter: 2400, curr loss: 1.347814679145813, avg loss: 1.3610965567827225\n",
      "trial: 1, iter: 2600, curr loss: 1.3714226484298706, avg loss: 1.3499184429645539\n",
      "trial: 1, iter: 2800, curr loss: 1.3488826751708984, avg loss: 1.3443584823608399\n",
      "trial: 1, iter: 3000, curr loss: 1.3401488065719604, avg loss: 1.340172177553177\n",
      "trial: 1, iter: 3200, curr loss: 1.3239731788635254, avg loss: 1.3357917219400406\n",
      "trial: 1, iter: 3400, curr loss: 1.3436700105667114, avg loss: 1.3337641614675522\n",
      "trial: 1, iter: 3600, curr loss: 1.3583635091781616, avg loss: 1.3340983361005783\n",
      "trial: 1, iter: 3800, curr loss: 1.3398538827896118, avg loss: 1.3327790558338166\n",
      "trial: 1, iter: 4000, curr loss: 1.333821177482605, avg loss: 1.3322303813695908\n",
      "trial: 1, iter: 4200, curr loss: 1.3314181566238403, avg loss: 1.3292353981733322\n",
      "trial: 1, iter: 4400, curr loss: 1.3008102178573608, avg loss: 1.3306200855970383\n",
      "trial: 1, iter: 4600, curr loss: 1.3190926313400269, avg loss: 1.3276059395074844\n",
      "trial: 1, iter: 4800, curr loss: 1.3422857522964478, avg loss: 1.3259307712316513\n",
      "trial: 1, iter: 5000, curr loss: 1.3032485246658325, avg loss: 1.3224957740306855\n",
      "trial: 1, iter: 5200, curr loss: 1.3282723426818848, avg loss: 1.3275983887910843\n",
      "trial: 1, iter: 5400, curr loss: 1.299190878868103, avg loss: 1.3265713149309157\n",
      "trial: 1, iter: 5600, curr loss: 1.3259527683258057, avg loss: 1.3240901613235474\n",
      "trial: 1, iter: 5800, curr loss: 1.3552701473236084, avg loss: 1.3231043064594268\n",
      "trial: 1, iter: 6000, curr loss: 1.364798903465271, avg loss: 1.3229588615894317\n",
      "trial: 1, iter: 6200, curr loss: 1.3586015701293945, avg loss: 1.3205665254592895\n",
      "trial: 1, ldr: 0.011510074138641357\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3867532014846802, avg loss: 1.3871619820594787\n",
      "trial: 2, iter: 400, curr loss: 1.3865314722061157, avg loss: 1.3867383885383606\n",
      "trial: 2, iter: 600, curr loss: 1.3879826068878174, avg loss: 1.3866106212139129\n",
      "trial: 2, iter: 800, curr loss: 1.3843656778335571, avg loss: 1.3864857810735702\n",
      "trial: 2, iter: 1000, curr loss: 1.3852144479751587, avg loss: 1.3863821083307266\n",
      "trial: 2, iter: 1200, curr loss: 1.3835200071334839, avg loss: 1.3859537148475647\n",
      "trial: 2, iter: 1400, curr loss: 1.386574625968933, avg loss: 1.3857166475057603\n",
      "trial: 2, iter: 1600, curr loss: 1.3908637762069702, avg loss: 1.3845771431922913\n",
      "trial: 2, iter: 1800, curr loss: 1.3799630403518677, avg loss: 1.383228355050087\n",
      "trial: 2, iter: 2000, curr loss: 1.3751065731048584, avg loss: 1.381477056145668\n",
      "trial: 2, iter: 2200, curr loss: 1.363280177116394, avg loss: 1.3768838989734649\n",
      "trial: 2, iter: 2400, curr loss: 1.3646241426467896, avg loss: 1.3690998756885528\n",
      "trial: 2, iter: 2600, curr loss: 1.3359622955322266, avg loss: 1.3570738500356674\n",
      "trial: 2, iter: 2800, curr loss: 1.3704174757003784, avg loss: 1.3480180591344832\n",
      "trial: 2, iter: 3000, curr loss: 1.3276827335357666, avg loss: 1.3424225842952728\n",
      "trial: 2, iter: 3200, curr loss: 1.3352280855178833, avg loss: 1.3389501655101776\n",
      "trial: 2, iter: 3400, curr loss: 1.332636833190918, avg loss: 1.337045942544937\n",
      "trial: 2, iter: 3600, curr loss: 1.3481062650680542, avg loss: 1.3338840609788896\n",
      "trial: 2, iter: 3800, curr loss: 1.3378053903579712, avg loss: 1.3328368562459945\n",
      "trial: 2, iter: 4000, curr loss: 1.3111214637756348, avg loss: 1.3319390106201172\n",
      "trial: 2, iter: 4200, curr loss: 1.3246623277664185, avg loss: 1.328756365776062\n",
      "trial: 2, iter: 4400, curr loss: 1.3021599054336548, avg loss: 1.3290763050317764\n",
      "trial: 2, iter: 4600, curr loss: 1.3131533861160278, avg loss: 1.3286863988637925\n",
      "trial: 2, iter: 4800, curr loss: 1.3321969509124756, avg loss: 1.3288155341148375\n",
      "trial: 2, iter: 5000, curr loss: 1.3327653408050537, avg loss: 1.3287314081192017\n",
      "trial: 2, iter: 5200, curr loss: 1.3305166959762573, avg loss: 1.3276084810495377\n",
      "trial: 2, iter: 5400, curr loss: 1.348805546760559, avg loss: 1.3266192424297332\n",
      "trial: 2, iter: 5600, curr loss: 1.3153403997421265, avg loss: 1.324741593003273\n",
      "trial: 2, iter: 5800, curr loss: 1.3216516971588135, avg loss: 1.3247713875770568\n",
      "trial: 2, iter: 6000, curr loss: 1.3508288860321045, avg loss: 1.3244584441184997\n",
      "trial: 2, iter: 6200, curr loss: 1.2963494062423706, avg loss: 1.3214254927635194\n",
      "trial: 2, ldr: 0.01506474893540144\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3867946863174438, avg loss: 1.3872854059934616\n",
      "trial: 3, iter: 400, curr loss: 1.3854042291641235, avg loss: 1.386745629310608\n",
      "trial: 3, iter: 600, curr loss: 1.3868293762207031, avg loss: 1.3865998834371567\n",
      "trial: 3, iter: 800, curr loss: 1.3885096311569214, avg loss: 1.3864266753196717\n",
      "trial: 3, iter: 1000, curr loss: 1.3867526054382324, avg loss: 1.3864684426784515\n",
      "trial: 3, iter: 1200, curr loss: 1.386168360710144, avg loss: 1.3863730728626251\n",
      "trial: 3, iter: 1400, curr loss: 1.385786533355713, avg loss: 1.3863192522525787\n",
      "trial: 3, iter: 1600, curr loss: 1.3843402862548828, avg loss: 1.3862056618928909\n",
      "trial: 3, iter: 1800, curr loss: 1.3879445791244507, avg loss: 1.3859431725740432\n",
      "trial: 3, iter: 2000, curr loss: 1.3843815326690674, avg loss: 1.3849273747205735\n",
      "trial: 3, iter: 2200, curr loss: 1.3786334991455078, avg loss: 1.3838921064138412\n",
      "trial: 3, iter: 2400, curr loss: 1.3780577182769775, avg loss: 1.3819247055053712\n",
      "trial: 3, iter: 2600, curr loss: 1.3871738910675049, avg loss: 1.3792310506105423\n",
      "trial: 3, iter: 2800, curr loss: 1.372898817062378, avg loss: 1.371735498905182\n",
      "trial: 3, iter: 3000, curr loss: 1.3653669357299805, avg loss: 1.3633215725421906\n",
      "trial: 3, iter: 3200, curr loss: 1.3431828022003174, avg loss: 1.3528716921806336\n",
      "trial: 3, iter: 3400, curr loss: 1.3420976400375366, avg loss: 1.3447570157051087\n",
      "trial: 3, iter: 3600, curr loss: 1.345689296722412, avg loss: 1.3398486387729645\n",
      "trial: 3, iter: 3800, curr loss: 1.3326359987258911, avg loss: 1.3388075375556945\n",
      "trial: 3, iter: 4000, curr loss: 1.3363803625106812, avg loss: 1.3354683470726014\n",
      "trial: 3, iter: 4200, curr loss: 1.31269109249115, avg loss: 1.335527365207672\n",
      "trial: 3, iter: 4400, curr loss: 1.3035789728164673, avg loss: 1.331194545030594\n",
      "trial: 3, iter: 4600, curr loss: 1.3163384199142456, avg loss: 1.331882157921791\n",
      "trial: 3, iter: 4800, curr loss: 1.3406413793563843, avg loss: 1.330673173069954\n",
      "trial: 3, iter: 5000, curr loss: 1.356119155883789, avg loss: 1.3302407467365265\n",
      "trial: 3, iter: 5200, curr loss: 1.3263916969299316, avg loss: 1.3266782438755036\n",
      "trial: 3, iter: 5400, curr loss: 1.365830659866333, avg loss: 1.3261244249343873\n",
      "trial: 3, iter: 5600, curr loss: 1.319021463394165, avg loss: 1.3249099111557008\n",
      "trial: 3, iter: 5800, curr loss: 1.316903829574585, avg loss: 1.3253861355781555\n",
      "trial: 3, iter: 6000, curr loss: 1.3120510578155518, avg loss: 1.3241322112083436\n",
      "trial: 3, iter: 6200, curr loss: 1.336159348487854, avg loss: 1.3230205965042114\n",
      "trial: 3, ldr: 0.0037546749226748943\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3862015008926392, avg loss: 1.3873849976062775\n",
      "trial: 4, iter: 400, curr loss: 1.3876163959503174, avg loss: 1.386710631251335\n",
      "trial: 4, iter: 600, curr loss: 1.385485291481018, avg loss: 1.3865761172771454\n",
      "trial: 4, iter: 800, curr loss: 1.3877978324890137, avg loss: 1.3861056792736053\n",
      "trial: 4, iter: 1000, curr loss: 1.3852217197418213, avg loss: 1.3856072610616683\n",
      "trial: 4, iter: 1200, curr loss: 1.3884297609329224, avg loss: 1.3841734611988068\n",
      "trial: 4, iter: 1400, curr loss: 1.3804798126220703, avg loss: 1.380796687602997\n",
      "trial: 4, iter: 1600, curr loss: 1.376888632774353, avg loss: 1.3733050763607024\n",
      "trial: 4, iter: 1800, curr loss: 1.3618190288543701, avg loss: 1.3614665865898132\n",
      "trial: 4, iter: 2000, curr loss: 1.366736650466919, avg loss: 1.3495333063602448\n",
      "trial: 4, iter: 2200, curr loss: 1.3848932981491089, avg loss: 1.3449023979902268\n",
      "trial: 4, iter: 2400, curr loss: 1.3245116472244263, avg loss: 1.3395693004131317\n",
      "trial: 4, iter: 2600, curr loss: 1.3538451194763184, avg loss: 1.3378419554233552\n",
      "trial: 4, iter: 2800, curr loss: 1.346320629119873, avg loss: 1.3362500715255736\n",
      "trial: 4, iter: 3000, curr loss: 1.3464934825897217, avg loss: 1.3335563886165618\n",
      "trial: 4, iter: 3200, curr loss: 1.337410569190979, avg loss: 1.3313182497024536\n",
      "trial: 4, iter: 3400, curr loss: 1.3246172666549683, avg loss: 1.3317637979984283\n",
      "trial: 4, iter: 3600, curr loss: 1.363858699798584, avg loss: 1.3293143236637115\n",
      "trial: 4, iter: 3800, curr loss: 1.3021345138549805, avg loss: 1.3297097373008728\n",
      "trial: 4, iter: 4000, curr loss: 1.309546709060669, avg loss: 1.3281571406126023\n",
      "trial: 4, iter: 4200, curr loss: 1.3434351682662964, avg loss: 1.3266441184282303\n",
      "trial: 4, iter: 4400, curr loss: 1.3133792877197266, avg loss: 1.3257423973083495\n",
      "trial: 4, iter: 4600, curr loss: 1.28933584690094, avg loss: 1.325915316939354\n",
      "trial: 4, iter: 4800, curr loss: 1.3172364234924316, avg loss: 1.3267315423488617\n",
      "trial: 4, iter: 5000, curr loss: 1.3160638809204102, avg loss: 1.3242010134458542\n",
      "trial: 4, iter: 5200, curr loss: 1.3370543718338013, avg loss: 1.3258758741617203\n",
      "trial: 4, iter: 5400, curr loss: 1.3115439414978027, avg loss: 1.3231862199306488\n",
      "trial: 4, iter: 5600, curr loss: 1.316423773765564, avg loss: 1.3231223088502884\n",
      "trial: 4, iter: 5800, curr loss: 1.3044345378875732, avg loss: 1.3190504276752473\n",
      "trial: 4, iter: 6000, curr loss: 1.3215817213058472, avg loss: 1.3190134263038635\n",
      "trial: 4, iter: 6200, curr loss: 1.2943942546844482, avg loss: 1.3195341843366624\n",
      "trial: 4, ldr: 0.05363873392343521\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3868595361709595, avg loss: 1.3871050548553467\n",
      "trial: 5, iter: 400, curr loss: 1.3874011039733887, avg loss: 1.3867970311641693\n",
      "trial: 5, iter: 600, curr loss: 1.3859542608261108, avg loss: 1.3866815656423568\n",
      "trial: 5, iter: 800, curr loss: 1.3883605003356934, avg loss: 1.3864384806156158\n",
      "trial: 5, iter: 1000, curr loss: 1.3890637159347534, avg loss: 1.3863638347387315\n",
      "trial: 5, iter: 1200, curr loss: 1.3870123624801636, avg loss: 1.3861843872070312\n",
      "trial: 5, iter: 1400, curr loss: 1.385378122329712, avg loss: 1.3858804005384444\n",
      "trial: 5, iter: 1600, curr loss: 1.383411169052124, avg loss: 1.384977900981903\n",
      "trial: 5, iter: 1800, curr loss: 1.3778315782546997, avg loss: 1.3818502634763719\n",
      "trial: 5, iter: 2000, curr loss: 1.3720837831497192, avg loss: 1.3752887392044066\n",
      "trial: 5, iter: 2200, curr loss: 1.3519866466522217, avg loss: 1.3638544738292695\n",
      "trial: 5, iter: 2400, curr loss: 1.3405920267105103, avg loss: 1.353296672105789\n",
      "trial: 5, iter: 2600, curr loss: 1.3446331024169922, avg loss: 1.345670205950737\n",
      "trial: 5, iter: 2800, curr loss: 1.3377652168273926, avg loss: 1.3391004264354707\n",
      "trial: 5, iter: 3000, curr loss: 1.3260774612426758, avg loss: 1.3380729895830155\n",
      "trial: 5, iter: 3200, curr loss: 1.3398534059524536, avg loss: 1.3354141396284103\n",
      "trial: 5, iter: 3400, curr loss: 1.317171335220337, avg loss: 1.335307766199112\n",
      "trial: 5, iter: 3600, curr loss: 1.3259905576705933, avg loss: 1.3334401959180833\n",
      "trial: 5, iter: 3800, curr loss: 1.3289210796356201, avg loss: 1.330890480875969\n",
      "trial: 5, iter: 4000, curr loss: 1.336371660232544, avg loss: 1.3282706105709077\n",
      "trial: 5, iter: 4200, curr loss: 1.348617434501648, avg loss: 1.33098146378994\n",
      "trial: 5, iter: 4400, curr loss: 1.3643373250961304, avg loss: 1.327395139336586\n",
      "trial: 5, iter: 4600, curr loss: 1.335339903831482, avg loss: 1.3275385785102845\n",
      "trial: 5, iter: 4800, curr loss: 1.3101997375488281, avg loss: 1.3254508274793624\n",
      "trial: 5, iter: 5000, curr loss: 1.3067797422409058, avg loss: 1.323644089102745\n",
      "trial: 5, iter: 5200, curr loss: 1.342738389968872, avg loss: 1.3247844964265822\n",
      "trial: 5, iter: 5400, curr loss: 1.3273649215698242, avg loss: 1.32361647605896\n",
      "trial: 5, iter: 5600, curr loss: 1.331188678741455, avg loss: 1.322491433620453\n",
      "trial: 5, iter: 5800, curr loss: 1.3051183223724365, avg loss: 1.322197015285492\n",
      "trial: 5, iter: 6000, curr loss: 1.3195182085037231, avg loss: 1.323212720155716\n",
      "trial: 5, iter: 6200, curr loss: 1.299456238746643, avg loss: 1.3193400382995606\n",
      "trial: 5, ldr: -0.0043733990751206875\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.015918966569006442\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3845034837722778, avg loss: 1.3870950025320052\n",
      "trial: 1, iter: 400, curr loss: 1.3851052522659302, avg loss: 1.3867313492298126\n",
      "trial: 1, iter: 600, curr loss: 1.3861075639724731, avg loss: 1.3864315330982209\n",
      "trial: 1, iter: 800, curr loss: 1.3892741203308105, avg loss: 1.3860324162244797\n",
      "trial: 1, iter: 1000, curr loss: 1.387233018875122, avg loss: 1.3861058753728868\n",
      "trial: 1, iter: 1200, curr loss: 1.3864281177520752, avg loss: 1.3855109989643097\n",
      "trial: 1, iter: 1400, curr loss: 1.38044011592865, avg loss: 1.3840230983495712\n",
      "trial: 1, iter: 1600, curr loss: 1.3851351737976074, avg loss: 1.3819864481687545\n",
      "trial: 1, iter: 1800, curr loss: 1.375410795211792, avg loss: 1.3784352666139603\n",
      "trial: 1, iter: 2000, curr loss: 1.3651641607284546, avg loss: 1.373872670531273\n",
      "trial: 1, iter: 2200, curr loss: 1.3795217275619507, avg loss: 1.369504572749138\n",
      "trial: 1, iter: 2400, curr loss: 1.3331279754638672, avg loss: 1.3643551641702651\n",
      "trial: 1, iter: 2600, curr loss: 1.34108304977417, avg loss: 1.3563630121946335\n",
      "trial: 1, iter: 2800, curr loss: 1.3354003429412842, avg loss: 1.3495689833164215\n",
      "trial: 1, iter: 3000, curr loss: 1.359780192375183, avg loss: 1.3476274353265763\n",
      "trial: 1, iter: 3200, curr loss: 1.3219698667526245, avg loss: 1.3424673438072205\n",
      "trial: 1, iter: 3400, curr loss: 1.3249162435531616, avg loss: 1.3392051029205323\n",
      "trial: 1, iter: 3600, curr loss: 1.304675579071045, avg loss: 1.3361106008291244\n",
      "trial: 1, iter: 3800, curr loss: 1.3277347087860107, avg loss: 1.3356786704063415\n",
      "trial: 1, iter: 4000, curr loss: 1.314955234527588, avg loss: 1.333733661174774\n",
      "trial: 1, iter: 4200, curr loss: 1.3325430154800415, avg loss: 1.3327022683620453\n",
      "trial: 1, iter: 4400, curr loss: 1.3107165098190308, avg loss: 1.3295601135492325\n",
      "trial: 1, iter: 4600, curr loss: 1.3377779722213745, avg loss: 1.3283916479349136\n",
      "trial: 1, iter: 4800, curr loss: 1.3242599964141846, avg loss: 1.3282043743133545\n",
      "trial: 1, iter: 5000, curr loss: 1.334373950958252, avg loss: 1.3278660088777543\n",
      "trial: 1, iter: 5200, curr loss: 1.3349534273147583, avg loss: 1.3254904216527938\n",
      "trial: 1, iter: 5400, curr loss: 1.28941011428833, avg loss: 1.3241832196712493\n",
      "trial: 1, iter: 5600, curr loss: 1.3360737562179565, avg loss: 1.3264438277482986\n",
      "trial: 1, iter: 5800, curr loss: 1.3133398294448853, avg loss: 1.3233047169446945\n",
      "trial: 1, iter: 6000, curr loss: 1.3273361921310425, avg loss: 1.3219323456287384\n",
      "trial: 1, iter: 6200, curr loss: 1.3466531038284302, avg loss: 1.326699047088623\n",
      "trial: 1, ldr: 0.01888895407319069\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3911305665969849, avg loss: 1.387518865466118\n",
      "trial: 2, iter: 400, curr loss: 1.3889126777648926, avg loss: 1.3866956049203873\n",
      "trial: 2, iter: 600, curr loss: 1.3846315145492554, avg loss: 1.3867292594909668\n",
      "trial: 2, iter: 800, curr loss: 1.3869305849075317, avg loss: 1.3865271973609925\n",
      "trial: 2, iter: 1000, curr loss: 1.38760244846344, avg loss: 1.3863886594772339\n",
      "trial: 2, iter: 1200, curr loss: 1.3875930309295654, avg loss: 1.3862872529029846\n",
      "trial: 2, iter: 1400, curr loss: 1.3861644268035889, avg loss: 1.3864001923799514\n",
      "trial: 2, iter: 1600, curr loss: 1.387032389640808, avg loss: 1.386316101551056\n",
      "trial: 2, iter: 1800, curr loss: 1.3867021799087524, avg loss: 1.3863927841186523\n",
      "trial: 2, iter: 2000, curr loss: 1.3875707387924194, avg loss: 1.3863021767139434\n",
      "trial: 2, iter: 2200, curr loss: 1.385199785232544, avg loss: 1.3858819502592086\n",
      "trial: 2, iter: 2400, curr loss: 1.3876636028289795, avg loss: 1.3851461029052734\n",
      "trial: 2, iter: 2600, curr loss: 1.3796418905258179, avg loss: 1.3825030797719955\n",
      "trial: 2, iter: 2800, curr loss: 1.378403663635254, avg loss: 1.3763751727342606\n",
      "trial: 2, iter: 3000, curr loss: 1.3674007654190063, avg loss: 1.3668636190891266\n",
      "trial: 2, iter: 3200, curr loss: 1.3501770496368408, avg loss: 1.3574966353178024\n",
      "trial: 2, iter: 3400, curr loss: 1.366565465927124, avg loss: 1.3477287530899047\n",
      "trial: 2, iter: 3600, curr loss: 1.3462580442428589, avg loss: 1.3417309683561325\n",
      "trial: 2, iter: 3800, curr loss: 1.3341009616851807, avg loss: 1.3397234004735947\n",
      "trial: 2, iter: 4000, curr loss: 1.355446219444275, avg loss: 1.3354833167791367\n",
      "trial: 2, iter: 4200, curr loss: 1.3365105390548706, avg loss: 1.3343538904190064\n",
      "trial: 2, iter: 4400, curr loss: 1.3422623872756958, avg loss: 1.3335677403211594\n",
      "trial: 2, iter: 4600, curr loss: 1.3355740308761597, avg loss: 1.33221613407135\n",
      "trial: 2, iter: 4800, curr loss: 1.3316329717636108, avg loss: 1.3274437594413757\n",
      "trial: 2, iter: 5000, curr loss: 1.3357532024383545, avg loss: 1.3263116472959517\n",
      "trial: 2, iter: 5200, curr loss: 1.3207314014434814, avg loss: 1.3266434013843535\n",
      "trial: 2, iter: 5400, curr loss: 1.3235808610916138, avg loss: 1.3271166741847993\n",
      "trial: 2, iter: 5600, curr loss: 1.3171855211257935, avg loss: 1.3239304369688034\n",
      "trial: 2, iter: 5800, curr loss: 1.3267793655395508, avg loss: 1.3252022469043732\n",
      "trial: 2, iter: 6000, curr loss: 1.3526450395584106, avg loss: 1.3258532118797302\n",
      "trial: 2, iter: 6200, curr loss: 1.3213920593261719, avg loss: 1.3237738782167434\n",
      "trial: 2, ldr: 0.03263852372765541\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3887492418289185, avg loss: 1.3871507859230041\n",
      "trial: 3, iter: 400, curr loss: 1.3893765211105347, avg loss: 1.386798815727234\n",
      "trial: 3, iter: 600, curr loss: 1.3878995180130005, avg loss: 1.3864615231752395\n",
      "trial: 3, iter: 800, curr loss: 1.3853189945220947, avg loss: 1.386545090675354\n",
      "trial: 3, iter: 1000, curr loss: 1.3864612579345703, avg loss: 1.3864378428459168\n",
      "trial: 3, iter: 1200, curr loss: 1.3850822448730469, avg loss: 1.3863749641180039\n",
      "trial: 3, iter: 1400, curr loss: 1.3857340812683105, avg loss: 1.3860960817337036\n",
      "trial: 3, iter: 1600, curr loss: 1.3833370208740234, avg loss: 1.385926241874695\n",
      "trial: 3, iter: 1800, curr loss: 1.3864527940750122, avg loss: 1.384851501584053\n",
      "trial: 3, iter: 2000, curr loss: 1.3860740661621094, avg loss: 1.3829114174842834\n",
      "trial: 3, iter: 2200, curr loss: 1.3701200485229492, avg loss: 1.378979189991951\n",
      "trial: 3, iter: 2400, curr loss: 1.367342233657837, avg loss: 1.370614007115364\n",
      "trial: 3, iter: 2600, curr loss: 1.3560155630111694, avg loss: 1.360747063755989\n",
      "trial: 3, iter: 2800, curr loss: 1.3367185592651367, avg loss: 1.350239617228508\n",
      "trial: 3, iter: 3000, curr loss: 1.3407552242279053, avg loss: 1.341849217414856\n",
      "trial: 3, iter: 3200, curr loss: 1.3106712102890015, avg loss: 1.339821531176567\n",
      "trial: 3, iter: 3400, curr loss: 1.335317850112915, avg loss: 1.3383523041009904\n",
      "trial: 3, iter: 3600, curr loss: 1.3566069602966309, avg loss: 1.3337340986728667\n",
      "trial: 3, iter: 3800, curr loss: 1.3301045894622803, avg loss: 1.3331783086061477\n",
      "trial: 3, iter: 4000, curr loss: 1.3105745315551758, avg loss: 1.3311563694477082\n",
      "trial: 3, iter: 4200, curr loss: 1.338371753692627, avg loss: 1.3284117728471756\n",
      "trial: 3, iter: 4400, curr loss: 1.3589413166046143, avg loss: 1.3274591517448426\n",
      "trial: 3, iter: 4600, curr loss: 1.3039599657058716, avg loss: 1.3263261604309082\n",
      "trial: 3, iter: 4800, curr loss: 1.291642665863037, avg loss: 1.3248458790779114\n",
      "trial: 3, iter: 5000, curr loss: 1.3230276107788086, avg loss: 1.3255956214666367\n",
      "trial: 3, iter: 5200, curr loss: 1.3226258754730225, avg loss: 1.3244858127832413\n",
      "trial: 3, iter: 5400, curr loss: 1.3342498540878296, avg loss: 1.3241229569911956\n",
      "trial: 3, iter: 5600, curr loss: 1.309363842010498, avg loss: 1.3205834007263184\n",
      "trial: 3, iter: 5800, curr loss: 1.3472747802734375, avg loss: 1.323641203045845\n",
      "trial: 3, iter: 6000, curr loss: 1.3161790370941162, avg loss: 1.321316927075386\n",
      "trial: 3, iter: 6200, curr loss: 1.3434864282608032, avg loss: 1.323207448720932\n",
      "trial: 3, ldr: 0.004447932355105877\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.383699893951416, avg loss: 1.3870323061943055\n",
      "trial: 4, iter: 400, curr loss: 1.390406608581543, avg loss: 1.3868203109502792\n",
      "trial: 4, iter: 600, curr loss: 1.3842616081237793, avg loss: 1.386506395339966\n",
      "trial: 4, iter: 800, curr loss: 1.3863297700881958, avg loss: 1.3864192962646484\n",
      "trial: 4, iter: 1000, curr loss: 1.3859564065933228, avg loss: 1.3862556797266006\n",
      "trial: 4, iter: 1200, curr loss: 1.3881117105484009, avg loss: 1.3861052352190018\n",
      "trial: 4, iter: 1400, curr loss: 1.3858439922332764, avg loss: 1.385479475259781\n",
      "trial: 4, iter: 1600, curr loss: 1.3830379247665405, avg loss: 1.3840154445171355\n",
      "trial: 4, iter: 1800, curr loss: 1.3748854398727417, avg loss: 1.3803352510929108\n",
      "trial: 4, iter: 2000, curr loss: 1.3709826469421387, avg loss: 1.3705758267641068\n",
      "trial: 4, iter: 2200, curr loss: 1.3694126605987549, avg loss: 1.3631831359863282\n",
      "trial: 4, iter: 2400, curr loss: 1.334283709526062, avg loss: 1.3513449668884276\n",
      "trial: 4, iter: 2600, curr loss: 1.3384456634521484, avg loss: 1.344062032699585\n",
      "trial: 4, iter: 2800, curr loss: 1.3077257871627808, avg loss: 1.3374298322200775\n",
      "trial: 4, iter: 3000, curr loss: 1.3280788660049438, avg loss: 1.337159413099289\n",
      "trial: 4, iter: 3200, curr loss: 1.3422660827636719, avg loss: 1.3344329607486725\n",
      "trial: 4, iter: 3400, curr loss: 1.3660423755645752, avg loss: 1.3320712733268738\n",
      "trial: 4, iter: 3600, curr loss: 1.31640625, avg loss: 1.3328596049547194\n",
      "trial: 4, iter: 3800, curr loss: 1.300946831703186, avg loss: 1.3287108969688415\n",
      "trial: 4, iter: 4000, curr loss: 1.3232780694961548, avg loss: 1.3293832165002823\n",
      "trial: 4, iter: 4200, curr loss: 1.3390893936157227, avg loss: 1.3271818774938584\n",
      "trial: 4, iter: 4400, curr loss: 1.321191668510437, avg loss: 1.3255974131822585\n",
      "trial: 4, iter: 4600, curr loss: 1.312031626701355, avg loss: 1.3266799873113633\n",
      "trial: 4, iter: 4800, curr loss: 1.312913179397583, avg loss: 1.3253512704372405\n",
      "trial: 4, iter: 5000, curr loss: 1.3417593240737915, avg loss: 1.3227479755878448\n",
      "trial: 4, iter: 5200, curr loss: 1.337917685508728, avg loss: 1.3248444539308548\n",
      "trial: 4, iter: 5400, curr loss: 1.3298101425170898, avg loss: 1.322442699074745\n",
      "trial: 4, iter: 5600, curr loss: 1.3363947868347168, avg loss: 1.324626434445381\n",
      "trial: 4, iter: 5800, curr loss: 1.3381532430648804, avg loss: 1.3222164928913116\n",
      "trial: 4, iter: 6000, curr loss: 1.3205301761627197, avg loss: 1.3190790539979935\n",
      "trial: 4, iter: 6200, curr loss: 1.3566697835922241, avg loss: 1.3209430253505707\n",
      "trial: 4, ldr: 0.013841659761965275\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.390176773071289, avg loss: 1.387729823589325\n",
      "trial: 5, iter: 400, curr loss: 1.3859643936157227, avg loss: 1.3869063812494278\n",
      "trial: 5, iter: 600, curr loss: 1.3857795000076294, avg loss: 1.3864456140995025\n",
      "trial: 5, iter: 800, curr loss: 1.3847343921661377, avg loss: 1.3864088785648345\n",
      "trial: 5, iter: 1000, curr loss: 1.3858983516693115, avg loss: 1.386239350438118\n",
      "trial: 5, iter: 1200, curr loss: 1.3842041492462158, avg loss: 1.3857359516620635\n",
      "trial: 5, iter: 1400, curr loss: 1.381874442100525, avg loss: 1.3844619387388228\n",
      "trial: 5, iter: 1600, curr loss: 1.3824416399002075, avg loss: 1.381511915922165\n",
      "trial: 5, iter: 1800, curr loss: 1.3553394079208374, avg loss: 1.3748350858688354\n",
      "trial: 5, iter: 2000, curr loss: 1.3588213920593262, avg loss: 1.3663129270076753\n",
      "trial: 5, iter: 2200, curr loss: 1.3509358167648315, avg loss: 1.3578174275159836\n",
      "trial: 5, iter: 2400, curr loss: 1.350067138671875, avg loss: 1.349703068137169\n",
      "trial: 5, iter: 2600, curr loss: 1.3424174785614014, avg loss: 1.3416915845870971\n",
      "trial: 5, iter: 2800, curr loss: 1.333659052848816, avg loss: 1.3381098926067352\n",
      "trial: 5, iter: 3000, curr loss: 1.3293952941894531, avg loss: 1.3340113455057143\n",
      "trial: 5, iter: 3200, curr loss: 1.3466074466705322, avg loss: 1.3339334696531295\n",
      "trial: 5, iter: 3400, curr loss: 1.3441061973571777, avg loss: 1.3329456490278244\n",
      "trial: 5, iter: 3600, curr loss: 1.323488712310791, avg loss: 1.3305128407478333\n",
      "trial: 5, iter: 3800, curr loss: 1.3339760303497314, avg loss: 1.333992794752121\n",
      "trial: 5, iter: 4000, curr loss: 1.3527987003326416, avg loss: 1.3306299072504044\n",
      "trial: 5, iter: 4200, curr loss: 1.339164137840271, avg loss: 1.3271684014797211\n",
      "trial: 5, iter: 4400, curr loss: 1.3371285200119019, avg loss: 1.3282971096038818\n",
      "trial: 5, iter: 4600, curr loss: 1.3020881414413452, avg loss: 1.3271703952550888\n",
      "trial: 5, iter: 4800, curr loss: 1.3352444171905518, avg loss: 1.3267030149698258\n",
      "trial: 5, iter: 5000, curr loss: 1.3145925998687744, avg loss: 1.3260404455661774\n",
      "trial: 5, iter: 5200, curr loss: 1.3135970830917358, avg loss: 1.3225563460588454\n",
      "trial: 5, iter: 5400, curr loss: 1.3003573417663574, avg loss: 1.322474506497383\n",
      "trial: 5, iter: 5600, curr loss: 1.323966383934021, avg loss: 1.3233061009645462\n",
      "trial: 5, iter: 5800, curr loss: 1.3205803632736206, avg loss: 1.322159696817398\n",
      "trial: 5, iter: 6000, curr loss: 1.3081145286560059, avg loss: 1.323942604660988\n",
      "trial: 5, iter: 6200, curr loss: 1.3008191585540771, avg loss: 1.3197271847724914\n",
      "trial: 5, ldr: 0.020723380148410797\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.01810809001326561\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3871034383773804, avg loss: 1.3872784024477005\n",
      "trial: 1, iter: 400, curr loss: 1.3858059644699097, avg loss: 1.3866230326890945\n",
      "trial: 1, iter: 600, curr loss: 1.3861255645751953, avg loss: 1.386580566763878\n",
      "trial: 1, iter: 800, curr loss: 1.386629581451416, avg loss: 1.3864259648323058\n",
      "trial: 1, iter: 1000, curr loss: 1.3870588541030884, avg loss: 1.3861433529853822\n",
      "trial: 1, iter: 1200, curr loss: 1.3874074220657349, avg loss: 1.3858535391092301\n",
      "trial: 1, iter: 1400, curr loss: 1.381910800933838, avg loss: 1.3851747047901153\n",
      "trial: 1, iter: 1600, curr loss: 1.3889646530151367, avg loss: 1.3827934330701828\n",
      "trial: 1, iter: 1800, curr loss: 1.3816378116607666, avg loss: 1.3789233368635179\n",
      "trial: 1, iter: 2000, curr loss: 1.363582968711853, avg loss: 1.372410273551941\n",
      "trial: 1, iter: 2200, curr loss: 1.3654483556747437, avg loss: 1.3644987171888352\n",
      "trial: 1, iter: 2400, curr loss: 1.3410780429840088, avg loss: 1.3563452124595643\n",
      "trial: 1, iter: 2600, curr loss: 1.355226993560791, avg loss: 1.3463571417331694\n",
      "trial: 1, iter: 2800, curr loss: 1.368691086769104, avg loss: 1.3439512091875077\n",
      "trial: 1, iter: 3000, curr loss: 1.3528673648834229, avg loss: 1.3377848905324936\n",
      "trial: 1, iter: 3200, curr loss: 1.3410502672195435, avg loss: 1.3356418794393539\n",
      "trial: 1, iter: 3400, curr loss: 1.3524724245071411, avg loss: 1.3331261110305785\n",
      "trial: 1, iter: 3600, curr loss: 1.353907823562622, avg loss: 1.3314440423250198\n",
      "trial: 1, iter: 3800, curr loss: 1.3342163562774658, avg loss: 1.3319010031223297\n",
      "trial: 1, iter: 4000, curr loss: 1.322808861732483, avg loss: 1.3277677720785142\n",
      "trial: 1, iter: 4200, curr loss: 1.3257654905319214, avg loss: 1.3289978778362275\n",
      "trial: 1, iter: 4400, curr loss: 1.3149210214614868, avg loss: 1.327723986506462\n",
      "trial: 1, iter: 4600, curr loss: 1.3315235376358032, avg loss: 1.3252274239063262\n",
      "trial: 1, iter: 4800, curr loss: 1.346850037574768, avg loss: 1.327241707444191\n",
      "trial: 1, iter: 5000, curr loss: 1.3579950332641602, avg loss: 1.3252346104383468\n",
      "trial: 1, iter: 5200, curr loss: 1.3798489570617676, avg loss: 1.3231291806697845\n",
      "trial: 1, iter: 5400, curr loss: 1.3180153369903564, avg loss: 1.3234177815914154\n",
      "trial: 1, iter: 5600, curr loss: 1.3011819124221802, avg loss: 1.3219340753555298\n",
      "trial: 1, iter: 5800, curr loss: 1.335314154624939, avg loss: 1.3196482241153717\n",
      "trial: 1, iter: 6000, curr loss: 1.3113521337509155, avg loss: 1.3224193823337556\n",
      "trial: 1, iter: 6200, curr loss: 1.275028944015503, avg loss: 1.3215311563014984\n",
      "trial: 1, ldr: 0.04261666163802147\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3827052116394043, avg loss: 1.387416586279869\n",
      "trial: 2, iter: 400, curr loss: 1.385642647743225, avg loss: 1.386693952679634\n",
      "trial: 2, iter: 600, curr loss: 1.388232946395874, avg loss: 1.3864224475622178\n",
      "trial: 2, iter: 800, curr loss: 1.385887861251831, avg loss: 1.3865069216489792\n",
      "trial: 2, iter: 1000, curr loss: 1.3838450908660889, avg loss: 1.386449289917946\n",
      "trial: 2, iter: 1200, curr loss: 1.3845635652542114, avg loss: 1.3863324075937271\n",
      "trial: 2, iter: 1400, curr loss: 1.3852367401123047, avg loss: 1.3859382182359696\n",
      "trial: 2, iter: 1600, curr loss: 1.3868162631988525, avg loss: 1.3851380467414856\n",
      "trial: 2, iter: 1800, curr loss: 1.3831998109817505, avg loss: 1.3825546860694886\n",
      "trial: 2, iter: 2000, curr loss: 1.3712979555130005, avg loss: 1.3777757728099822\n",
      "trial: 2, iter: 2200, curr loss: 1.3555257320404053, avg loss: 1.3679851949214936\n",
      "trial: 2, iter: 2400, curr loss: 1.358139157295227, avg loss: 1.3572910058498382\n",
      "trial: 2, iter: 2600, curr loss: 1.3305702209472656, avg loss: 1.3483935958147049\n",
      "trial: 2, iter: 2800, curr loss: 1.355616569519043, avg loss: 1.3415227776765823\n",
      "trial: 2, iter: 3000, curr loss: 1.3271857500076294, avg loss: 1.340097007751465\n",
      "trial: 2, iter: 3200, curr loss: 1.3116028308868408, avg loss: 1.3357243436574935\n",
      "trial: 2, iter: 3400, curr loss: 1.3287726640701294, avg loss: 1.3335151892900468\n",
      "trial: 2, iter: 3600, curr loss: 1.3382458686828613, avg loss: 1.3321455246210099\n",
      "trial: 2, iter: 3800, curr loss: 1.3491264581680298, avg loss: 1.3320905941724777\n",
      "trial: 2, iter: 4000, curr loss: 1.314490556716919, avg loss: 1.328123197555542\n",
      "trial: 2, iter: 4200, curr loss: 1.3021966218948364, avg loss: 1.3305165910720824\n",
      "trial: 2, iter: 4400, curr loss: 1.3196828365325928, avg loss: 1.3254889690876006\n",
      "trial: 2, iter: 4600, curr loss: 1.326654314994812, avg loss: 1.3243880075216294\n",
      "trial: 2, iter: 4800, curr loss: 1.278549313545227, avg loss: 1.3258525377511978\n",
      "trial: 2, iter: 5000, curr loss: 1.3430695533752441, avg loss: 1.3246761465072632\n",
      "trial: 2, iter: 5200, curr loss: 1.3439850807189941, avg loss: 1.3227645260095597\n",
      "trial: 2, iter: 5400, curr loss: 1.3124548196792603, avg loss: 1.3242587161064148\n",
      "trial: 2, iter: 5600, curr loss: 1.3391516208648682, avg loss: 1.3253309392929078\n",
      "trial: 2, iter: 5800, curr loss: 1.3327827453613281, avg loss: 1.3234320557117463\n",
      "trial: 2, iter: 6000, curr loss: 1.31536066532135, avg loss: 1.3219660121202468\n",
      "trial: 2, iter: 6200, curr loss: 1.324674129486084, avg loss: 1.3214524978399276\n",
      "trial: 2, ldr: -0.024150487035512924\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3880324363708496, avg loss: 1.3872689557075502\n",
      "trial: 3, iter: 400, curr loss: 1.3863999843597412, avg loss: 1.38670545399189\n",
      "trial: 3, iter: 600, curr loss: 1.3867542743682861, avg loss: 1.386798119544983\n",
      "trial: 3, iter: 800, curr loss: 1.3871041536331177, avg loss: 1.3865342766046524\n",
      "trial: 3, iter: 1000, curr loss: 1.3866006135940552, avg loss: 1.386346892118454\n",
      "trial: 3, iter: 1200, curr loss: 1.3853594064712524, avg loss: 1.386489953994751\n",
      "trial: 3, iter: 1400, curr loss: 1.3863970041275024, avg loss: 1.3862397468090057\n",
      "trial: 3, iter: 1600, curr loss: 1.3862988948822021, avg loss: 1.3860300838947297\n",
      "trial: 3, iter: 1800, curr loss: 1.381598711013794, avg loss: 1.3853165692090987\n",
      "trial: 3, iter: 2000, curr loss: 1.378970980644226, avg loss: 1.3834015727043152\n",
      "trial: 3, iter: 2200, curr loss: 1.3793237209320068, avg loss: 1.3812006849050522\n",
      "trial: 3, iter: 2400, curr loss: 1.372563362121582, avg loss: 1.3770458739995957\n",
      "trial: 3, iter: 2600, curr loss: 1.385453462600708, avg loss: 1.3711302030086516\n",
      "trial: 3, iter: 2800, curr loss: 1.3601112365722656, avg loss: 1.3625735449790954\n",
      "trial: 3, iter: 3000, curr loss: 1.3534480333328247, avg loss: 1.3543756306171417\n",
      "trial: 3, iter: 3200, curr loss: 1.3438161611557007, avg loss: 1.3444735240936279\n",
      "trial: 3, iter: 3400, curr loss: 1.3299986124038696, avg loss: 1.3395565837621688\n",
      "trial: 3, iter: 3600, curr loss: 1.3366575241088867, avg loss: 1.3355430603027343\n",
      "trial: 3, iter: 3800, curr loss: 1.3441649675369263, avg loss: 1.3331117326021193\n",
      "trial: 3, iter: 4000, curr loss: 1.3288699388504028, avg loss: 1.3304539144039154\n",
      "trial: 3, iter: 4200, curr loss: 1.3230947256088257, avg loss: 1.3286527156829835\n",
      "trial: 3, iter: 4400, curr loss: 1.3232362270355225, avg loss: 1.326534463763237\n",
      "trial: 3, iter: 4600, curr loss: 1.3144909143447876, avg loss: 1.3279888689517976\n",
      "trial: 3, iter: 4800, curr loss: 1.2955400943756104, avg loss: 1.3253035044670105\n",
      "trial: 3, iter: 5000, curr loss: 1.347442865371704, avg loss: 1.325220329761505\n",
      "trial: 3, iter: 5200, curr loss: 1.3252989053726196, avg loss: 1.3245580953359604\n",
      "trial: 3, iter: 5400, curr loss: 1.3497179746627808, avg loss: 1.3252952700853349\n",
      "trial: 3, iter: 5600, curr loss: 1.3290454149246216, avg loss: 1.32187897503376\n",
      "trial: 3, iter: 5800, curr loss: 1.3042738437652588, avg loss: 1.3220746463537216\n",
      "trial: 3, iter: 6000, curr loss: 1.3286398649215698, avg loss: 1.3217554438114165\n",
      "trial: 3, iter: 6200, curr loss: 1.3357537984848022, avg loss: 1.3208494037389755\n",
      "trial: 3, ldr: 0.02316410467028618\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3854035139083862, avg loss: 1.3874432909488679\n",
      "trial: 4, iter: 400, curr loss: 1.387062668800354, avg loss: 1.3866302847862244\n",
      "trial: 4, iter: 600, curr loss: 1.3866833448410034, avg loss: 1.3865322452783584\n",
      "trial: 4, iter: 800, curr loss: 1.3858579397201538, avg loss: 1.3864157819747924\n",
      "trial: 4, iter: 1000, curr loss: 1.3872463703155518, avg loss: 1.386287989616394\n",
      "trial: 4, iter: 1200, curr loss: 1.3868638277053833, avg loss: 1.386302523612976\n",
      "trial: 4, iter: 1400, curr loss: 1.385982871055603, avg loss: 1.3861449801921844\n",
      "trial: 4, iter: 1600, curr loss: 1.385208010673523, avg loss: 1.3860326212644578\n",
      "trial: 4, iter: 1800, curr loss: 1.3833738565444946, avg loss: 1.3853068852424621\n",
      "trial: 4, iter: 2000, curr loss: 1.3841602802276611, avg loss: 1.3837887346744537\n",
      "trial: 4, iter: 2200, curr loss: 1.3878132104873657, avg loss: 1.3788850408792497\n",
      "trial: 4, iter: 2400, curr loss: 1.3560782670974731, avg loss: 1.3692878895998002\n",
      "trial: 4, iter: 2600, curr loss: 1.3366014957427979, avg loss: 1.3553491508960724\n",
      "trial: 4, iter: 2800, curr loss: 1.3272759914398193, avg loss: 1.3470203167200088\n",
      "trial: 4, iter: 3000, curr loss: 1.354726791381836, avg loss: 1.340458265542984\n",
      "trial: 4, iter: 3200, curr loss: 1.3282501697540283, avg loss: 1.3389044713973999\n",
      "trial: 4, iter: 3400, curr loss: 1.3460263013839722, avg loss: 1.3375266319513321\n",
      "trial: 4, iter: 3600, curr loss: 1.356102466583252, avg loss: 1.332975777387619\n",
      "trial: 4, iter: 3800, curr loss: 1.314681887626648, avg loss: 1.3319559782743453\n",
      "trial: 4, iter: 4000, curr loss: 1.3381903171539307, avg loss: 1.330775372982025\n",
      "trial: 4, iter: 4200, curr loss: 1.3547910451889038, avg loss: 1.3324266320466995\n",
      "trial: 4, iter: 4400, curr loss: 1.3521966934204102, avg loss: 1.3292240273952485\n",
      "trial: 4, iter: 4600, curr loss: 1.343703031539917, avg loss: 1.3285006701946258\n",
      "trial: 4, iter: 4800, curr loss: 1.3163906335830688, avg loss: 1.3265604126453399\n",
      "trial: 4, iter: 5000, curr loss: 1.3358200788497925, avg loss: 1.325947961807251\n",
      "trial: 4, iter: 5200, curr loss: 1.3100316524505615, avg loss: 1.327437306046486\n",
      "trial: 4, iter: 5400, curr loss: 1.3509601354599, avg loss: 1.3214815241098403\n",
      "trial: 4, iter: 5600, curr loss: 1.3035117387771606, avg loss: 1.3230759596824646\n",
      "trial: 4, iter: 5800, curr loss: 1.3136707544326782, avg loss: 1.3224323731660843\n",
      "trial: 4, iter: 6000, curr loss: 1.3174999952316284, avg loss: 1.3233579111099243\n",
      "trial: 4, iter: 6200, curr loss: 1.295507550239563, avg loss: 1.3235609030723572\n",
      "trial: 4, ldr: -0.0046799881383776665\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3901909589767456, avg loss: 1.3873125129938126\n",
      "trial: 5, iter: 400, curr loss: 1.3862900733947754, avg loss: 1.3866976225376129\n",
      "trial: 5, iter: 600, curr loss: 1.3856202363967896, avg loss: 1.3863867312669753\n",
      "trial: 5, iter: 800, curr loss: 1.3876914978027344, avg loss: 1.3865128427743911\n",
      "trial: 5, iter: 1000, curr loss: 1.3870407342910767, avg loss: 1.3865182727575303\n",
      "trial: 5, iter: 1200, curr loss: 1.3849197626113892, avg loss: 1.3862376081943513\n",
      "trial: 5, iter: 1400, curr loss: 1.3873862028121948, avg loss: 1.3861462414264678\n",
      "trial: 5, iter: 1600, curr loss: 1.386806845664978, avg loss: 1.385833861231804\n",
      "trial: 5, iter: 1800, curr loss: 1.3792623281478882, avg loss: 1.3841895413398744\n",
      "trial: 5, iter: 2000, curr loss: 1.3778618574142456, avg loss: 1.3815892338752747\n",
      "trial: 5, iter: 2200, curr loss: 1.3745737075805664, avg loss: 1.3784648287296295\n",
      "trial: 5, iter: 2400, curr loss: 1.3543397188186646, avg loss: 1.3706593596935273\n",
      "trial: 5, iter: 2600, curr loss: 1.3538570404052734, avg loss: 1.3580580979585648\n",
      "trial: 5, iter: 2800, curr loss: 1.3377165794372559, avg loss: 1.3456080788373947\n",
      "trial: 5, iter: 3000, curr loss: 1.3428796529769897, avg loss: 1.3419507205486298\n",
      "trial: 5, iter: 3200, curr loss: 1.347978949546814, avg loss: 1.341533083319664\n",
      "trial: 5, iter: 3400, curr loss: 1.3522354364395142, avg loss: 1.33844497859478\n",
      "trial: 5, iter: 3600, curr loss: 1.3476089239120483, avg loss: 1.3332610988616944\n",
      "trial: 5, iter: 3800, curr loss: 1.319303274154663, avg loss: 1.3305526745319367\n",
      "trial: 5, iter: 4000, curr loss: 1.318841576576233, avg loss: 1.3282516318559647\n",
      "trial: 5, iter: 4200, curr loss: 1.3379507064819336, avg loss: 1.3298662942647934\n",
      "trial: 5, iter: 4400, curr loss: 1.322449803352356, avg loss: 1.3284841161966323\n",
      "trial: 5, iter: 4600, curr loss: 1.3111780881881714, avg loss: 1.3262603932619095\n",
      "trial: 5, iter: 4800, curr loss: 1.330419898033142, avg loss: 1.3257436496019364\n",
      "trial: 5, iter: 5000, curr loss: 1.3036158084869385, avg loss: 1.3280884325504303\n",
      "trial: 5, iter: 5200, curr loss: 1.3146865367889404, avg loss: 1.3249460422992707\n",
      "trial: 5, iter: 5400, curr loss: 1.3283747434616089, avg loss: 1.3230907547473907\n",
      "trial: 5, iter: 5600, curr loss: 1.3140219449996948, avg loss: 1.3251010537147523\n",
      "trial: 5, iter: 5800, curr loss: 1.304206132888794, avg loss: 1.3232347750663758\n",
      "trial: 5, iter: 6000, curr loss: 1.358560562133789, avg loss: 1.3209822654724122\n",
      "trial: 5, iter: 6200, curr loss: 1.3136725425720215, avg loss: 1.3230818724632263\n",
      "trial: 5, ldr: 0.0006195022142492235\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.007513958669733256\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386446237564087, avg loss: 1.3870116186141968\n",
      "trial: 1, iter: 400, curr loss: 1.3856064081192017, avg loss: 1.3866400200128555\n",
      "trial: 1, iter: 600, curr loss: 1.387713074684143, avg loss: 1.38673772752285\n",
      "trial: 1, iter: 800, curr loss: 1.3850598335266113, avg loss: 1.3865879851579666\n",
      "trial: 1, iter: 1000, curr loss: 1.3881909847259521, avg loss: 1.3862862342596054\n",
      "trial: 1, iter: 1200, curr loss: 1.384282112121582, avg loss: 1.3861717694997788\n",
      "trial: 1, iter: 1400, curr loss: 1.386304259300232, avg loss: 1.3857520824670793\n",
      "trial: 1, iter: 1600, curr loss: 1.3897321224212646, avg loss: 1.3849535447359085\n",
      "trial: 1, iter: 1800, curr loss: 1.3762919902801514, avg loss: 1.383442663550377\n",
      "trial: 1, iter: 2000, curr loss: 1.3800209760665894, avg loss: 1.380493133664131\n",
      "trial: 1, iter: 2200, curr loss: 1.3877897262573242, avg loss: 1.37632459461689\n",
      "trial: 1, iter: 2400, curr loss: 1.3693687915802002, avg loss: 1.3702485603094101\n",
      "trial: 1, iter: 2600, curr loss: 1.333336353302002, avg loss: 1.3604557722806931\n",
      "trial: 1, iter: 2800, curr loss: 1.337565541267395, avg loss: 1.353712211251259\n",
      "trial: 1, iter: 3000, curr loss: 1.3557438850402832, avg loss: 1.3445685172080994\n",
      "trial: 1, iter: 3200, curr loss: 1.3491289615631104, avg loss: 1.3405754107236862\n",
      "trial: 1, iter: 3400, curr loss: 1.3223726749420166, avg loss: 1.336514471769333\n",
      "trial: 1, iter: 3600, curr loss: 1.3413125276565552, avg loss: 1.33526735663414\n",
      "trial: 1, iter: 3800, curr loss: 1.3153953552246094, avg loss: 1.3318916189670562\n",
      "trial: 1, iter: 4000, curr loss: 1.3191384077072144, avg loss: 1.3346788907051086\n",
      "trial: 1, iter: 4200, curr loss: 1.29268217086792, avg loss: 1.3307321715354918\n",
      "trial: 1, iter: 4400, curr loss: 1.3170429468154907, avg loss: 1.3294128906726836\n",
      "trial: 1, iter: 4600, curr loss: 1.3308067321777344, avg loss: 1.3286580961942673\n",
      "trial: 1, iter: 4800, curr loss: 1.3348160982131958, avg loss: 1.3283539313077926\n",
      "trial: 1, iter: 5000, curr loss: 1.312352180480957, avg loss: 1.3253746992349624\n",
      "trial: 1, iter: 5200, curr loss: 1.3718438148498535, avg loss: 1.3248622262477874\n",
      "trial: 1, iter: 5400, curr loss: 1.3195420503616333, avg loss: 1.3240899980068206\n",
      "trial: 1, iter: 5600, curr loss: 1.3169031143188477, avg loss: 1.3211626744270324\n",
      "trial: 1, iter: 5800, curr loss: 1.3631502389907837, avg loss: 1.321724174618721\n",
      "trial: 1, iter: 6000, curr loss: 1.290464162826538, avg loss: 1.3232489961385727\n",
      "trial: 1, iter: 6200, curr loss: 1.3178340196609497, avg loss: 1.3229079639911652\n",
      "trial: 1, ldr: 0.00616665743291378\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3839025497436523, avg loss: 1.387307175397873\n",
      "trial: 2, iter: 400, curr loss: 1.3880072832107544, avg loss: 1.38680832862854\n",
      "trial: 2, iter: 600, curr loss: 1.3840361833572388, avg loss: 1.3869336634874343\n",
      "trial: 2, iter: 800, curr loss: 1.3877439498901367, avg loss: 1.3865364056825638\n",
      "trial: 2, iter: 1000, curr loss: 1.3846772909164429, avg loss: 1.3863625574111937\n",
      "trial: 2, iter: 1200, curr loss: 1.3908798694610596, avg loss: 1.3860075318813323\n",
      "trial: 2, iter: 1400, curr loss: 1.382939338684082, avg loss: 1.385594796538353\n",
      "trial: 2, iter: 1600, curr loss: 1.3856215476989746, avg loss: 1.3845329594612121\n",
      "trial: 2, iter: 1800, curr loss: 1.375457763671875, avg loss: 1.3820900857448577\n",
      "trial: 2, iter: 2000, curr loss: 1.3643368482589722, avg loss: 1.378738266825676\n",
      "trial: 2, iter: 2200, curr loss: 1.3631397485733032, avg loss: 1.373385848402977\n",
      "trial: 2, iter: 2400, curr loss: 1.3792119026184082, avg loss: 1.3665135449171066\n",
      "trial: 2, iter: 2600, curr loss: 1.3394818305969238, avg loss: 1.3558913141489028\n",
      "trial: 2, iter: 2800, curr loss: 1.3790600299835205, avg loss: 1.3468663090467452\n",
      "trial: 2, iter: 3000, curr loss: 1.371992588043213, avg loss: 1.3423745334148407\n",
      "trial: 2, iter: 3200, curr loss: 1.3064591884613037, avg loss: 1.3395162481069565\n",
      "trial: 2, iter: 3400, curr loss: 1.3325560092926025, avg loss: 1.3378907108306886\n",
      "trial: 2, iter: 3600, curr loss: 1.328471302986145, avg loss: 1.3323275727033614\n",
      "trial: 2, iter: 3800, curr loss: 1.311474323272705, avg loss: 1.331904535293579\n",
      "trial: 2, iter: 4000, curr loss: 1.3342169523239136, avg loss: 1.3307268941402435\n",
      "trial: 2, iter: 4200, curr loss: 1.3198555707931519, avg loss: 1.3300964039564134\n",
      "trial: 2, iter: 4400, curr loss: 1.3247812986373901, avg loss: 1.329262307882309\n",
      "trial: 2, iter: 4600, curr loss: 1.3133565187454224, avg loss: 1.328088790178299\n",
      "trial: 2, iter: 4800, curr loss: 1.3302712440490723, avg loss: 1.3272560745477677\n",
      "trial: 2, iter: 5000, curr loss: 1.3040482997894287, avg loss: 1.3244492971897126\n",
      "trial: 2, iter: 5200, curr loss: 1.326380729675293, avg loss: 1.3257213217020034\n",
      "trial: 2, iter: 5400, curr loss: 1.3567860126495361, avg loss: 1.3256690359115602\n",
      "trial: 2, iter: 5600, curr loss: 1.3201818466186523, avg loss: 1.3223870795965196\n",
      "trial: 2, iter: 5800, curr loss: 1.3144371509552002, avg loss: 1.3196274840831757\n",
      "trial: 2, iter: 6000, curr loss: 1.309870958328247, avg loss: 1.3237775373458862\n",
      "trial: 2, iter: 6200, curr loss: 1.3335472345352173, avg loss: 1.3233245712518693\n",
      "trial: 2, ldr: -0.031235773116350174\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3852574825286865, avg loss: 1.3870206820964812\n",
      "trial: 3, iter: 400, curr loss: 1.3855047225952148, avg loss: 1.3867095625400543\n",
      "trial: 3, iter: 600, curr loss: 1.3866385221481323, avg loss: 1.3864732909202575\n",
      "trial: 3, iter: 800, curr loss: 1.387794852256775, avg loss: 1.3864917635917664\n",
      "trial: 3, iter: 1000, curr loss: 1.3881996870040894, avg loss: 1.3863251304626465\n",
      "trial: 3, iter: 1200, curr loss: 1.385003924369812, avg loss: 1.3861557400226594\n",
      "trial: 3, iter: 1400, curr loss: 1.386446237564087, avg loss: 1.3860359424352646\n",
      "trial: 3, iter: 1600, curr loss: 1.3809963464736938, avg loss: 1.3851178258657455\n",
      "trial: 3, iter: 1800, curr loss: 1.3801807165145874, avg loss: 1.3831914496421813\n",
      "trial: 3, iter: 2000, curr loss: 1.3737201690673828, avg loss: 1.3809867656230927\n",
      "trial: 3, iter: 2200, curr loss: 1.3816417455673218, avg loss: 1.3753308910131454\n",
      "trial: 3, iter: 2400, curr loss: 1.371619462966919, avg loss: 1.3678047782182694\n",
      "trial: 3, iter: 2600, curr loss: 1.358368992805481, avg loss: 1.3572900807857513\n",
      "trial: 3, iter: 2800, curr loss: 1.3958642482757568, avg loss: 1.350093561410904\n",
      "trial: 3, iter: 3000, curr loss: 1.3547093868255615, avg loss: 1.3442935228347779\n",
      "trial: 3, iter: 3200, curr loss: 1.3410416841506958, avg loss: 1.3395597690343857\n",
      "trial: 3, iter: 3400, curr loss: 1.3161333799362183, avg loss: 1.3362617295980455\n",
      "trial: 3, iter: 3600, curr loss: 1.367095947265625, avg loss: 1.3358415514230728\n",
      "trial: 3, iter: 3800, curr loss: 1.3265830278396606, avg loss: 1.332966160774231\n",
      "trial: 3, iter: 4000, curr loss: 1.332938313484192, avg loss: 1.3308567267656326\n",
      "trial: 3, iter: 4200, curr loss: 1.3271831274032593, avg loss: 1.3325387078523636\n",
      "trial: 3, iter: 4400, curr loss: 1.3275790214538574, avg loss: 1.330347835421562\n",
      "trial: 3, iter: 4600, curr loss: 1.320865273475647, avg loss: 1.326533362865448\n",
      "trial: 3, iter: 4800, curr loss: 1.3401724100112915, avg loss: 1.3293190544843674\n",
      "trial: 3, iter: 5000, curr loss: 1.3581256866455078, avg loss: 1.3244846206903458\n",
      "trial: 3, iter: 5200, curr loss: 1.3351482152938843, avg loss: 1.3279832869768142\n",
      "trial: 3, iter: 5400, curr loss: 1.308275818824768, avg loss: 1.3249497818946838\n",
      "trial: 3, iter: 5600, curr loss: 1.31693434715271, avg loss: 1.3235593658685685\n",
      "trial: 3, iter: 5800, curr loss: 1.3333758115768433, avg loss: 1.3242162734270095\n",
      "trial: 3, iter: 6000, curr loss: 1.3094767332077026, avg loss: 1.3240968281030654\n",
      "trial: 3, iter: 6200, curr loss: 1.3374720811843872, avg loss: 1.32362611413002\n",
      "trial: 3, ldr: 0.02823731116950512\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3869483470916748, avg loss: 1.3874541455507279\n",
      "trial: 4, iter: 400, curr loss: 1.3879605531692505, avg loss: 1.3867717754840851\n",
      "trial: 4, iter: 600, curr loss: 1.388041377067566, avg loss: 1.386741235256195\n",
      "trial: 4, iter: 800, curr loss: 1.3868072032928467, avg loss: 1.386419969201088\n",
      "trial: 4, iter: 1000, curr loss: 1.3878462314605713, avg loss: 1.3864802330732346\n",
      "trial: 4, iter: 1200, curr loss: 1.3858968019485474, avg loss: 1.3864927804470062\n",
      "trial: 4, iter: 1400, curr loss: 1.3877450227737427, avg loss: 1.386312524676323\n",
      "trial: 4, iter: 1600, curr loss: 1.3857965469360352, avg loss: 1.3863182806968688\n",
      "trial: 4, iter: 1800, curr loss: 1.3851016759872437, avg loss: 1.386270545721054\n",
      "trial: 4, iter: 2000, curr loss: 1.3863800764083862, avg loss: 1.3860524439811706\n",
      "trial: 4, iter: 2200, curr loss: 1.3847719430923462, avg loss: 1.3855558520555495\n",
      "trial: 4, iter: 2400, curr loss: 1.3848708868026733, avg loss: 1.3846762353181838\n",
      "trial: 4, iter: 2600, curr loss: 1.3797287940979004, avg loss: 1.3817139726877212\n",
      "trial: 4, iter: 2800, curr loss: 1.3659955263137817, avg loss: 1.3781914085149765\n",
      "trial: 4, iter: 3000, curr loss: 1.3781564235687256, avg loss: 1.3718691611289977\n",
      "trial: 4, iter: 3200, curr loss: 1.347917914390564, avg loss: 1.361010200381279\n",
      "trial: 4, iter: 3400, curr loss: 1.3355613946914673, avg loss: 1.3518714463710786\n",
      "trial: 4, iter: 3600, curr loss: 1.3542717695236206, avg loss: 1.3432374173402786\n",
      "trial: 4, iter: 3800, curr loss: 1.314713716506958, avg loss: 1.3402422630786897\n",
      "trial: 4, iter: 4000, curr loss: 1.2993040084838867, avg loss: 1.3357505929470062\n",
      "trial: 4, iter: 4200, curr loss: 1.321603775024414, avg loss: 1.3354616820812226\n",
      "trial: 4, iter: 4400, curr loss: 1.3426657915115356, avg loss: 1.3338127827644348\n",
      "trial: 4, iter: 4600, curr loss: 1.318997859954834, avg loss: 1.332480326294899\n",
      "trial: 4, iter: 4800, curr loss: 1.3367379903793335, avg loss: 1.3301415234804153\n",
      "trial: 4, iter: 5000, curr loss: 1.3061670064926147, avg loss: 1.3279167467355728\n",
      "trial: 4, iter: 5200, curr loss: 1.3095417022705078, avg loss: 1.3292783409357072\n",
      "trial: 4, iter: 5400, curr loss: 1.3264961242675781, avg loss: 1.3255243092775344\n",
      "trial: 4, iter: 5600, curr loss: 1.335903286933899, avg loss: 1.3235050874948502\n",
      "trial: 4, iter: 5800, curr loss: 1.361719012260437, avg loss: 1.326207172870636\n",
      "trial: 4, iter: 6000, curr loss: 1.2946125268936157, avg loss: 1.3227180767059326\n",
      "trial: 4, iter: 6200, curr loss: 1.3339738845825195, avg loss: 1.32333720266819\n",
      "trial: 4, ldr: 0.051322467625141144\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3858095407485962, avg loss: 1.3870139169692992\n",
      "trial: 5, iter: 400, curr loss: 1.3874350786209106, avg loss: 1.3866797083616256\n",
      "trial: 5, iter: 600, curr loss: 1.3865864276885986, avg loss: 1.3865721279382706\n",
      "trial: 5, iter: 800, curr loss: 1.383121132850647, avg loss: 1.3862273389101027\n",
      "trial: 5, iter: 1000, curr loss: 1.3879948854446411, avg loss: 1.3863338232040405\n",
      "trial: 5, iter: 1200, curr loss: 1.3877465724945068, avg loss: 1.3859830760955811\n",
      "trial: 5, iter: 1400, curr loss: 1.384299397468567, avg loss: 1.3857794880867005\n",
      "trial: 5, iter: 1600, curr loss: 1.3838104009628296, avg loss: 1.3843972086906433\n",
      "trial: 5, iter: 1800, curr loss: 1.3777153491973877, avg loss: 1.3811523634195328\n",
      "trial: 5, iter: 2000, curr loss: 1.371151089668274, avg loss: 1.375883469581604\n",
      "trial: 5, iter: 2200, curr loss: 1.372820496559143, avg loss: 1.3667348110675812\n",
      "trial: 5, iter: 2400, curr loss: 1.3476579189300537, avg loss: 1.356043010354042\n",
      "trial: 5, iter: 2600, curr loss: 1.334197998046875, avg loss: 1.347554109096527\n",
      "trial: 5, iter: 2800, curr loss: 1.3525718450546265, avg loss: 1.3425411367416382\n",
      "trial: 5, iter: 3000, curr loss: 1.3385096788406372, avg loss: 1.3391657543182374\n",
      "trial: 5, iter: 3200, curr loss: 1.3393570184707642, avg loss: 1.334874954223633\n",
      "trial: 5, iter: 3400, curr loss: 1.3425145149230957, avg loss: 1.333783085346222\n",
      "trial: 5, iter: 3600, curr loss: 1.3127772808074951, avg loss: 1.3299091827869416\n",
      "trial: 5, iter: 3800, curr loss: 1.356208324432373, avg loss: 1.331003720164299\n",
      "trial: 5, iter: 4000, curr loss: 1.337262511253357, avg loss: 1.3289480584859847\n",
      "trial: 5, iter: 4200, curr loss: 1.3245813846588135, avg loss: 1.3271692663431167\n",
      "trial: 5, iter: 4400, curr loss: 1.3526500463485718, avg loss: 1.328621614575386\n",
      "trial: 5, iter: 4600, curr loss: 1.3516628742218018, avg loss: 1.327695950269699\n",
      "trial: 5, iter: 4800, curr loss: 1.3274201154708862, avg loss: 1.324388648867607\n",
      "trial: 5, iter: 5000, curr loss: 1.3345566987991333, avg loss: 1.325273597240448\n",
      "trial: 5, iter: 5200, curr loss: 1.3284192085266113, avg loss: 1.3206771928071976\n",
      "trial: 5, iter: 5400, curr loss: 1.3601089715957642, avg loss: 1.3233785408735275\n",
      "trial: 5, iter: 5600, curr loss: 1.318892478942871, avg loss: 1.32252387881279\n",
      "trial: 5, iter: 5800, curr loss: 1.3042045831680298, avg loss: 1.3213640636205672\n",
      "trial: 5, iter: 6000, curr loss: 1.34591805934906, avg loss: 1.320974550843239\n",
      "trial: 5, iter: 6200, curr loss: 1.3497636318206787, avg loss: 1.321926330924034\n",
      "trial: 5, ldr: 0.026652874425053596\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.016228707507252693\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386884331703186, avg loss: 1.3872756606340408\n",
      "trial: 1, iter: 400, curr loss: 1.387571930885315, avg loss: 1.3870630353689193\n",
      "trial: 1, iter: 600, curr loss: 1.3845816850662231, avg loss: 1.3867001610994338\n",
      "trial: 1, iter: 800, curr loss: 1.3852843046188354, avg loss: 1.386442546248436\n",
      "trial: 1, iter: 1000, curr loss: 1.3859490156173706, avg loss: 1.3866322487592697\n",
      "trial: 1, iter: 1200, curr loss: 1.389286994934082, avg loss: 1.3862215691804887\n",
      "trial: 1, iter: 1400, curr loss: 1.3839824199676514, avg loss: 1.3859746730327607\n",
      "trial: 1, iter: 1600, curr loss: 1.378796100616455, avg loss: 1.3850830417871476\n",
      "trial: 1, iter: 1800, curr loss: 1.3723676204681396, avg loss: 1.3821401882171631\n",
      "trial: 1, iter: 2000, curr loss: 1.3746238946914673, avg loss: 1.3765850043296814\n",
      "trial: 1, iter: 2200, curr loss: 1.3556407690048218, avg loss: 1.363955419063568\n",
      "trial: 1, iter: 2400, curr loss: 1.3483765125274658, avg loss: 1.3538795912265777\n",
      "trial: 1, iter: 2600, curr loss: 1.3288192749023438, avg loss: 1.3450841629505157\n",
      "trial: 1, iter: 2800, curr loss: 1.3231924772262573, avg loss: 1.338692918419838\n",
      "trial: 1, iter: 3000, curr loss: 1.343773365020752, avg loss: 1.3371537131071092\n",
      "trial: 1, iter: 3200, curr loss: 1.3096308708190918, avg loss: 1.3330878710746765\n",
      "trial: 1, iter: 3400, curr loss: 1.34805428981781, avg loss: 1.3323912280797958\n",
      "trial: 1, iter: 3600, curr loss: 1.3350918292999268, avg loss: 1.331082240343094\n",
      "trial: 1, iter: 3800, curr loss: 1.3306323289871216, avg loss: 1.3306696015596389\n",
      "trial: 1, iter: 4000, curr loss: 1.332318663597107, avg loss: 1.3282058870792388\n",
      "trial: 1, iter: 4200, curr loss: 1.3216524124145508, avg loss: 1.3295477849245072\n",
      "trial: 1, iter: 4400, curr loss: 1.3252999782562256, avg loss: 1.3282753127813338\n",
      "trial: 1, iter: 4600, curr loss: 1.2877379655838013, avg loss: 1.3264214235544205\n",
      "trial: 1, iter: 4800, curr loss: 1.3491370677947998, avg loss: 1.3264621740579605\n",
      "trial: 1, iter: 5000, curr loss: 1.291068434715271, avg loss: 1.3245521265268325\n",
      "trial: 1, iter: 5200, curr loss: 1.288885474205017, avg loss: 1.3232079523801803\n",
      "trial: 1, iter: 5400, curr loss: 1.3004772663116455, avg loss: 1.32373204767704\n",
      "trial: 1, iter: 5600, curr loss: 1.325590968132019, avg loss: 1.3230548214912414\n",
      "trial: 1, iter: 5800, curr loss: 1.3444697856903076, avg loss: 1.323213056921959\n",
      "trial: 1, iter: 6000, curr loss: 1.3244001865386963, avg loss: 1.3197529375553132\n",
      "trial: 1, iter: 6200, curr loss: 1.2862699031829834, avg loss: 1.319951615333557\n",
      "trial: 1, ldr: 0.019199680536985397\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3844152688980103, avg loss: 1.3872637498378753\n",
      "trial: 2, iter: 400, curr loss: 1.3862314224243164, avg loss: 1.3868352526426315\n",
      "trial: 2, iter: 600, curr loss: 1.3873376846313477, avg loss: 1.3864949148893357\n",
      "trial: 2, iter: 800, curr loss: 1.3862971067428589, avg loss: 1.3864691019058228\n",
      "trial: 2, iter: 1000, curr loss: 1.3876324892044067, avg loss: 1.3863522148132323\n",
      "trial: 2, iter: 1200, curr loss: 1.3872897624969482, avg loss: 1.3863004326820374\n",
      "trial: 2, iter: 1400, curr loss: 1.3882272243499756, avg loss: 1.3862999922037125\n",
      "trial: 2, iter: 1600, curr loss: 1.3852254152297974, avg loss: 1.386113197207451\n",
      "trial: 2, iter: 1800, curr loss: 1.383973240852356, avg loss: 1.3856891149282455\n",
      "trial: 2, iter: 2000, curr loss: 1.3802837133407593, avg loss: 1.3843139296770095\n",
      "trial: 2, iter: 2200, curr loss: 1.3708693981170654, avg loss: 1.3813428777456283\n",
      "trial: 2, iter: 2400, curr loss: 1.3730075359344482, avg loss: 1.377842748761177\n",
      "trial: 2, iter: 2600, curr loss: 1.3614895343780518, avg loss: 1.371109476685524\n",
      "trial: 2, iter: 2800, curr loss: 1.3442752361297607, avg loss: 1.357484626173973\n",
      "trial: 2, iter: 3000, curr loss: 1.3435717821121216, avg loss: 1.349514707326889\n",
      "trial: 2, iter: 3200, curr loss: 1.3357456922531128, avg loss: 1.3439568549394607\n",
      "trial: 2, iter: 3400, curr loss: 1.3572019338607788, avg loss: 1.3389451277256013\n",
      "trial: 2, iter: 3600, curr loss: 1.3417361974716187, avg loss: 1.3360663253068923\n",
      "trial: 2, iter: 3800, curr loss: 1.299478530883789, avg loss: 1.3332991582155227\n",
      "trial: 2, iter: 4000, curr loss: 1.361710548400879, avg loss: 1.3308465576171875\n",
      "trial: 2, iter: 4200, curr loss: 1.3455044031143188, avg loss: 1.330293480157852\n",
      "trial: 2, iter: 4400, curr loss: 1.331937551498413, avg loss: 1.3286630666255952\n",
      "trial: 2, iter: 4600, curr loss: 1.293120265007019, avg loss: 1.3293959605693817\n",
      "trial: 2, iter: 4800, curr loss: 1.2692673206329346, avg loss: 1.3233473509550095\n",
      "trial: 2, iter: 5000, curr loss: 1.3045074939727783, avg loss: 1.3254789835214615\n",
      "trial: 2, iter: 5200, curr loss: 1.3094319105148315, avg loss: 1.3205451083183288\n",
      "trial: 2, iter: 5400, curr loss: 1.2963581085205078, avg loss: 1.3254399544000626\n",
      "trial: 2, iter: 5600, curr loss: 1.3509974479675293, avg loss: 1.3221408742666245\n",
      "trial: 2, iter: 5800, curr loss: 1.3118972778320312, avg loss: 1.3221242713928223\n",
      "trial: 2, iter: 6000, curr loss: 1.3148503303527832, avg loss: 1.3201721018552781\n",
      "trial: 2, iter: 6200, curr loss: 1.3468538522720337, avg loss: 1.3195248752832414\n",
      "trial: 2, ldr: -0.019633082672953606\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3905137777328491, avg loss: 1.3871166044473648\n",
      "trial: 3, iter: 400, curr loss: 1.3909188508987427, avg loss: 1.386848245859146\n",
      "trial: 3, iter: 600, curr loss: 1.3843382596969604, avg loss: 1.3866532081365586\n",
      "trial: 3, iter: 800, curr loss: 1.3846079111099243, avg loss: 1.3865724861621858\n",
      "trial: 3, iter: 1000, curr loss: 1.3842334747314453, avg loss: 1.386317878961563\n",
      "trial: 3, iter: 1200, curr loss: 1.3878166675567627, avg loss: 1.3861941170692444\n",
      "trial: 3, iter: 1400, curr loss: 1.3847789764404297, avg loss: 1.3859985649585724\n",
      "trial: 3, iter: 1600, curr loss: 1.3825725317001343, avg loss: 1.384872470498085\n",
      "trial: 3, iter: 1800, curr loss: 1.3800476789474487, avg loss: 1.383401588201523\n",
      "trial: 3, iter: 2000, curr loss: 1.3766212463378906, avg loss: 1.3813609451055526\n",
      "trial: 3, iter: 2200, curr loss: 1.3694911003112793, avg loss: 1.3792947101593018\n",
      "trial: 3, iter: 2400, curr loss: 1.3676843643188477, avg loss: 1.3742283987998962\n",
      "trial: 3, iter: 2600, curr loss: 1.350731611251831, avg loss: 1.365273022055626\n",
      "trial: 3, iter: 2800, curr loss: 1.3411957025527954, avg loss: 1.3582310146093368\n",
      "trial: 3, iter: 3000, curr loss: 1.3364650011062622, avg loss: 1.3495274847745895\n",
      "trial: 3, iter: 3200, curr loss: 1.3569846153259277, avg loss: 1.3401526868343354\n",
      "trial: 3, iter: 3400, curr loss: 1.332724690437317, avg loss: 1.3393172615766524\n",
      "trial: 3, iter: 3600, curr loss: 1.3290523290634155, avg loss: 1.335768175125122\n",
      "trial: 3, iter: 3800, curr loss: 1.3273239135742188, avg loss: 1.334045286178589\n",
      "trial: 3, iter: 4000, curr loss: 1.3392616510391235, avg loss: 1.3306383150815964\n",
      "trial: 3, iter: 4200, curr loss: 1.3063523769378662, avg loss: 1.330133272409439\n",
      "trial: 3, iter: 4400, curr loss: 1.3579894304275513, avg loss: 1.327990152835846\n",
      "trial: 3, iter: 4600, curr loss: 1.332167387008667, avg loss: 1.3284484469890594\n",
      "trial: 3, iter: 4800, curr loss: 1.3027477264404297, avg loss: 1.3269478583335876\n",
      "trial: 3, iter: 5000, curr loss: 1.3029907941818237, avg loss: 1.3266213810443879\n",
      "trial: 3, iter: 5200, curr loss: 1.335003137588501, avg loss: 1.3228204292058945\n",
      "trial: 3, iter: 5400, curr loss: 1.336181879043579, avg loss: 1.3251942199468614\n",
      "trial: 3, iter: 5600, curr loss: 1.316460132598877, avg loss: 1.3242538976669311\n",
      "trial: 3, iter: 5800, curr loss: 1.296102523803711, avg loss: 1.3242254489660263\n",
      "trial: 3, iter: 6000, curr loss: 1.3104240894317627, avg loss: 1.3211414659023284\n",
      "trial: 3, iter: 6200, curr loss: 1.353716492652893, avg loss: 1.3232534915208816\n",
      "trial: 3, ldr: 0.016457846388220787\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386094331741333, avg loss: 1.38710711479187\n",
      "trial: 4, iter: 400, curr loss: 1.3871533870697021, avg loss: 1.3867883270978927\n",
      "trial: 4, iter: 600, curr loss: 1.3847087621688843, avg loss: 1.3863534128665924\n",
      "trial: 4, iter: 800, curr loss: 1.387586236000061, avg loss: 1.3861002618074416\n",
      "trial: 4, iter: 1000, curr loss: 1.384334683418274, avg loss: 1.385423212647438\n",
      "trial: 4, iter: 1200, curr loss: 1.3833757638931274, avg loss: 1.3834935438632965\n",
      "trial: 4, iter: 1400, curr loss: 1.3721450567245483, avg loss: 1.3781416589021682\n",
      "trial: 4, iter: 1600, curr loss: 1.3687896728515625, avg loss: 1.3693653863668442\n",
      "trial: 4, iter: 1800, curr loss: 1.3497923612594604, avg loss: 1.3600641196966172\n",
      "trial: 4, iter: 2000, curr loss: 1.3580526113510132, avg loss: 1.3498734468221665\n",
      "trial: 4, iter: 2200, curr loss: 1.3451855182647705, avg loss: 1.347256950736046\n",
      "trial: 4, iter: 2400, curr loss: 1.3311498165130615, avg loss: 1.3422843378782272\n",
      "trial: 4, iter: 2600, curr loss: 1.3515294790267944, avg loss: 1.3370457524061203\n",
      "trial: 4, iter: 2800, curr loss: 1.3069729804992676, avg loss: 1.337015934586525\n",
      "trial: 4, iter: 3000, curr loss: 1.3427751064300537, avg loss: 1.3341878211498261\n",
      "trial: 4, iter: 3200, curr loss: 1.3622643947601318, avg loss: 1.3293317514657974\n",
      "trial: 4, iter: 3400, curr loss: 1.3088839054107666, avg loss: 1.3310358399152755\n",
      "trial: 4, iter: 3600, curr loss: 1.3603322505950928, avg loss: 1.330079972743988\n",
      "trial: 4, iter: 3800, curr loss: 1.3295848369598389, avg loss: 1.3291089725494385\n",
      "trial: 4, iter: 4000, curr loss: 1.3200725317001343, avg loss: 1.3295816797018052\n",
      "trial: 4, iter: 4200, curr loss: 1.3451118469238281, avg loss: 1.3266259729862213\n",
      "trial: 4, iter: 4400, curr loss: 1.3537521362304688, avg loss: 1.326758122444153\n",
      "trial: 4, iter: 4600, curr loss: 1.326231598854065, avg loss: 1.3242233204841614\n",
      "trial: 4, iter: 4800, curr loss: 1.3022397756576538, avg loss: 1.3229553699493408\n",
      "trial: 4, iter: 5000, curr loss: 1.3419733047485352, avg loss: 1.3243822038173676\n",
      "trial: 4, iter: 5200, curr loss: 1.3050793409347534, avg loss: 1.322374547123909\n",
      "trial: 4, iter: 5400, curr loss: 1.3292570114135742, avg loss: 1.3232746624946594\n",
      "trial: 4, iter: 5600, curr loss: 1.3185522556304932, avg loss: 1.3222342205047608\n",
      "trial: 4, iter: 5800, curr loss: 1.3152413368225098, avg loss: 1.3221793693304063\n",
      "trial: 4, iter: 6000, curr loss: 1.3516966104507446, avg loss: 1.3196439999341965\n",
      "trial: 4, iter: 6200, curr loss: 1.3154100179672241, avg loss: 1.318260824084282\n",
      "trial: 4, ldr: 0.024682337418198586\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385749340057373, avg loss: 1.3871315014362335\n",
      "trial: 5, iter: 400, curr loss: 1.389235019683838, avg loss: 1.3866030722856522\n",
      "trial: 5, iter: 600, curr loss: 1.3877514600753784, avg loss: 1.386577277779579\n",
      "trial: 5, iter: 800, curr loss: 1.3848344087600708, avg loss: 1.3864221048355103\n",
      "trial: 5, iter: 1000, curr loss: 1.3853360414505005, avg loss: 1.386289768218994\n",
      "trial: 5, iter: 1200, curr loss: 1.3868142366409302, avg loss: 1.3862598484754562\n",
      "trial: 5, iter: 1400, curr loss: 1.3842557668685913, avg loss: 1.385969745516777\n",
      "trial: 5, iter: 1600, curr loss: 1.3865928649902344, avg loss: 1.385275161266327\n",
      "trial: 5, iter: 1800, curr loss: 1.3784360885620117, avg loss: 1.383702501654625\n",
      "trial: 5, iter: 2000, curr loss: 1.3865101337432861, avg loss: 1.381860116124153\n",
      "trial: 5, iter: 2200, curr loss: 1.3851393461227417, avg loss: 1.3796123909950255\n",
      "trial: 5, iter: 2400, curr loss: 1.3745996952056885, avg loss: 1.3770257085561752\n",
      "trial: 5, iter: 2600, curr loss: 1.3797894716262817, avg loss: 1.3727372735738754\n",
      "trial: 5, iter: 2800, curr loss: 1.350103497505188, avg loss: 1.3668025666475296\n",
      "trial: 5, iter: 3000, curr loss: 1.3532793521881104, avg loss: 1.3626612472534179\n",
      "trial: 5, iter: 3200, curr loss: 1.3626229763031006, avg loss: 1.3551765811443328\n",
      "trial: 5, iter: 3400, curr loss: 1.345603108406067, avg loss: 1.3493197232484817\n",
      "trial: 5, iter: 3600, curr loss: 1.3350090980529785, avg loss: 1.3427394390106202\n",
      "trial: 5, iter: 3800, curr loss: 1.3204671144485474, avg loss: 1.3407130813598633\n",
      "trial: 5, iter: 4000, curr loss: 1.352987289428711, avg loss: 1.3365684008598329\n",
      "trial: 5, iter: 4200, curr loss: 1.3189070224761963, avg loss: 1.334840602874756\n",
      "trial: 5, iter: 4400, curr loss: 1.3164150714874268, avg loss: 1.33230100274086\n",
      "trial: 5, iter: 4600, curr loss: 1.2984188795089722, avg loss: 1.3301896506547928\n",
      "trial: 5, iter: 4800, curr loss: 1.3296407461166382, avg loss: 1.328772519826889\n",
      "trial: 5, iter: 5000, curr loss: 1.3450897932052612, avg loss: 1.3300288677215577\n",
      "trial: 5, iter: 5200, curr loss: 1.3186105489730835, avg loss: 1.3282486766576767\n",
      "trial: 5, iter: 5400, curr loss: 1.3399831056594849, avg loss: 1.3281401598453522\n",
      "trial: 5, iter: 5600, curr loss: 1.3323519229888916, avg loss: 1.3260088455677033\n",
      "trial: 5, iter: 5800, curr loss: 1.3210505247116089, avg loss: 1.3250700879096984\n",
      "trial: 5, iter: 6000, curr loss: 1.3149770498275757, avg loss: 1.3251953130960465\n",
      "trial: 5, iter: 6200, curr loss: 1.3136944770812988, avg loss: 1.3230928760766982\n",
      "trial: 5, ldr: 0.03339740261435509\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.01482083685696125\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3877919912338257, avg loss: 1.3872165101766587\n",
      "trial: 1, iter: 400, curr loss: 1.3900758028030396, avg loss: 1.386931602358818\n",
      "trial: 1, iter: 600, curr loss: 1.3887184858322144, avg loss: 1.386686738729477\n",
      "trial: 1, iter: 800, curr loss: 1.3872504234313965, avg loss: 1.3865241926908494\n",
      "trial: 1, iter: 1000, curr loss: 1.3867430686950684, avg loss: 1.3864742082357406\n",
      "trial: 1, iter: 1200, curr loss: 1.3840281963348389, avg loss: 1.3861617374420165\n",
      "trial: 1, iter: 1400, curr loss: 1.386358618736267, avg loss: 1.3858546209335327\n",
      "trial: 1, iter: 1600, curr loss: 1.38373601436615, avg loss: 1.384925720691681\n",
      "trial: 1, iter: 1800, curr loss: 1.387769103050232, avg loss: 1.382574769258499\n",
      "trial: 1, iter: 2000, curr loss: 1.3634746074676514, avg loss: 1.3780425649881363\n",
      "trial: 1, iter: 2200, curr loss: 1.3721967935562134, avg loss: 1.3683784598112105\n",
      "trial: 1, iter: 2400, curr loss: 1.366213321685791, avg loss: 1.357150269150734\n",
      "trial: 1, iter: 2600, curr loss: 1.34255051612854, avg loss: 1.3464789861440658\n",
      "trial: 1, iter: 2800, curr loss: 1.3256995677947998, avg loss: 1.344463011622429\n",
      "trial: 1, iter: 3000, curr loss: 1.3213708400726318, avg loss: 1.3384621560573577\n",
      "trial: 1, iter: 3200, curr loss: 1.3627040386199951, avg loss: 1.3354537343978883\n",
      "trial: 1, iter: 3400, curr loss: 1.356741189956665, avg loss: 1.3354404646158218\n",
      "trial: 1, iter: 3600, curr loss: 1.3271085023880005, avg loss: 1.3332196474075317\n",
      "trial: 1, iter: 3800, curr loss: 1.343160629272461, avg loss: 1.3314266055822372\n",
      "trial: 1, iter: 4000, curr loss: 1.3042980432510376, avg loss: 1.3296692246198654\n",
      "trial: 1, iter: 4200, curr loss: 1.3362934589385986, avg loss: 1.331746838092804\n",
      "trial: 1, iter: 4400, curr loss: 1.3484987020492554, avg loss: 1.3279934877157211\n",
      "trial: 1, iter: 4600, curr loss: 1.3586229085922241, avg loss: 1.3260546380281448\n",
      "trial: 1, iter: 4800, curr loss: 1.300869345664978, avg loss: 1.3261102366447448\n",
      "trial: 1, iter: 5000, curr loss: 1.340517520904541, avg loss: 1.3257890367507934\n",
      "trial: 1, iter: 5200, curr loss: 1.2911540269851685, avg loss: 1.3263801085948943\n",
      "trial: 1, iter: 5400, curr loss: 1.3066685199737549, avg loss: 1.3237471169233321\n",
      "trial: 1, iter: 5600, curr loss: 1.3194093704223633, avg loss: 1.3242624723911285\n",
      "trial: 1, iter: 5800, curr loss: 1.3134276866912842, avg loss: 1.3224181789159775\n",
      "trial: 1, iter: 6000, curr loss: 1.316170573234558, avg loss: 1.3209797364473344\n",
      "trial: 1, iter: 6200, curr loss: 1.3269652128219604, avg loss: 1.3224283665418626\n",
      "trial: 1, ldr: -0.015710199251770973\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3860536813735962, avg loss: 1.3875726956129073\n",
      "trial: 2, iter: 400, curr loss: 1.384642481803894, avg loss: 1.3868188881874084\n",
      "trial: 2, iter: 600, curr loss: 1.3878772258758545, avg loss: 1.3865616530179978\n",
      "trial: 2, iter: 800, curr loss: 1.3865371942520142, avg loss: 1.3865127867460252\n",
      "trial: 2, iter: 1000, curr loss: 1.3861660957336426, avg loss: 1.3864569985866546\n",
      "trial: 2, iter: 1200, curr loss: 1.38446044921875, avg loss: 1.3863007932901383\n",
      "trial: 2, iter: 1400, curr loss: 1.3844562768936157, avg loss: 1.3860408717393875\n",
      "trial: 2, iter: 1600, curr loss: 1.382591724395752, avg loss: 1.3855977314710617\n",
      "trial: 2, iter: 1800, curr loss: 1.3800724744796753, avg loss: 1.3843206226825715\n",
      "trial: 2, iter: 2000, curr loss: 1.38510000705719, avg loss: 1.383040253520012\n",
      "trial: 2, iter: 2200, curr loss: 1.3846211433410645, avg loss: 1.3813914370536804\n",
      "trial: 2, iter: 2400, curr loss: 1.377386212348938, avg loss: 1.3781647825241088\n",
      "trial: 2, iter: 2600, curr loss: 1.3749231100082397, avg loss: 1.3721946638822555\n",
      "trial: 2, iter: 2800, curr loss: 1.3383792638778687, avg loss: 1.3631384736299514\n",
      "trial: 2, iter: 3000, curr loss: 1.344488501548767, avg loss: 1.3538996225595474\n",
      "trial: 2, iter: 3200, curr loss: 1.3355029821395874, avg loss: 1.3472232276201248\n",
      "trial: 2, iter: 3400, curr loss: 1.3400726318359375, avg loss: 1.342764650583267\n",
      "trial: 2, iter: 3600, curr loss: 1.340498924255371, avg loss: 1.336460674405098\n",
      "trial: 2, iter: 3800, curr loss: 1.3352253437042236, avg loss: 1.335640429854393\n",
      "trial: 2, iter: 4000, curr loss: 1.3227288722991943, avg loss: 1.3320784759521485\n",
      "trial: 2, iter: 4200, curr loss: 1.3237066268920898, avg loss: 1.3314515018463136\n",
      "trial: 2, iter: 4400, curr loss: 1.3119860887527466, avg loss: 1.3313327038288116\n",
      "trial: 2, iter: 4600, curr loss: 1.3332804441452026, avg loss: 1.3266800916194916\n",
      "trial: 2, iter: 4800, curr loss: 1.3349566459655762, avg loss: 1.3305355143547057\n",
      "trial: 2, iter: 5000, curr loss: 1.3398292064666748, avg loss: 1.328917931318283\n",
      "trial: 2, iter: 5200, curr loss: 1.3585487604141235, avg loss: 1.3278455579280852\n",
      "trial: 2, iter: 5400, curr loss: 1.321847677230835, avg loss: 1.325737987756729\n",
      "trial: 2, iter: 5600, curr loss: 1.3384822607040405, avg loss: 1.3255058640241624\n",
      "trial: 2, iter: 5800, curr loss: 1.3273886442184448, avg loss: 1.325126491189003\n",
      "trial: 2, iter: 6000, curr loss: 1.3385896682739258, avg loss: 1.3227399742603303\n",
      "trial: 2, iter: 6200, curr loss: 1.316479206085205, avg loss: 1.324498211145401\n",
      "trial: 2, ldr: -0.0070062316954135895\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3928080797195435, avg loss: 1.3873405873775482\n",
      "trial: 3, iter: 400, curr loss: 1.3877010345458984, avg loss: 1.386540954709053\n",
      "trial: 3, iter: 600, curr loss: 1.3857815265655518, avg loss: 1.3865647214651107\n",
      "trial: 3, iter: 800, curr loss: 1.3863111734390259, avg loss: 1.3863736486434937\n",
      "trial: 3, iter: 1000, curr loss: 1.384755253791809, avg loss: 1.386432302594185\n",
      "trial: 3, iter: 1200, curr loss: 1.3868579864501953, avg loss: 1.386421142220497\n",
      "trial: 3, iter: 1400, curr loss: 1.388196349143982, avg loss: 1.3863161504268646\n",
      "trial: 3, iter: 1600, curr loss: 1.3852746486663818, avg loss: 1.3863499599695206\n",
      "trial: 3, iter: 1800, curr loss: 1.3866389989852905, avg loss: 1.3863252526521683\n",
      "trial: 3, iter: 2000, curr loss: 1.3850078582763672, avg loss: 1.3861776453256607\n",
      "trial: 3, iter: 2200, curr loss: 1.3846607208251953, avg loss: 1.3857471585273742\n",
      "trial: 3, iter: 2400, curr loss: 1.380436658859253, avg loss: 1.3841706836223602\n",
      "trial: 3, iter: 2600, curr loss: 1.3793070316314697, avg loss: 1.3813180863857268\n",
      "trial: 3, iter: 2800, curr loss: 1.3757085800170898, avg loss: 1.3754199969768524\n",
      "trial: 3, iter: 3000, curr loss: 1.35477876663208, avg loss: 1.3655649679899216\n",
      "trial: 3, iter: 3200, curr loss: 1.3886183500289917, avg loss: 1.3535389000177382\n",
      "trial: 3, iter: 3400, curr loss: 1.3163436651229858, avg loss: 1.3444108420610428\n",
      "trial: 3, iter: 3600, curr loss: 1.3322792053222656, avg loss: 1.3423037719726563\n",
      "trial: 3, iter: 3800, curr loss: 1.3315484523773193, avg loss: 1.3394423323869704\n",
      "trial: 3, iter: 4000, curr loss: 1.3610203266143799, avg loss: 1.3386371928453444\n",
      "trial: 3, iter: 4200, curr loss: 1.3400964736938477, avg loss: 1.3351824879646301\n",
      "trial: 3, iter: 4400, curr loss: 1.3236258029937744, avg loss: 1.3306473660469056\n",
      "trial: 3, iter: 4600, curr loss: 1.329845666885376, avg loss: 1.3325899946689606\n",
      "trial: 3, iter: 4800, curr loss: 1.3372094631195068, avg loss: 1.3298326814174652\n",
      "trial: 3, iter: 5000, curr loss: 1.3253203630447388, avg loss: 1.3307721984386445\n",
      "trial: 3, iter: 5200, curr loss: 1.3308281898498535, avg loss: 1.3273935210704804\n",
      "trial: 3, iter: 5400, curr loss: 1.3269907236099243, avg loss: 1.3263650941848755\n",
      "trial: 3, iter: 5600, curr loss: 1.3208949565887451, avg loss: 1.3272346305847167\n",
      "trial: 3, iter: 5800, curr loss: 1.3306357860565186, avg loss: 1.3231348806619645\n",
      "trial: 3, iter: 6000, curr loss: 1.3384772539138794, avg loss: 1.3237321066856385\n",
      "trial: 3, iter: 6200, curr loss: 1.301093578338623, avg loss: 1.3254618334770203\n",
      "trial: 3, ldr: -0.0028488459065556526\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865076303482056, avg loss: 1.3877253669500351\n",
      "trial: 4, iter: 400, curr loss: 1.3878633975982666, avg loss: 1.386701847910881\n",
      "trial: 4, iter: 600, curr loss: 1.389318585395813, avg loss: 1.386725355386734\n",
      "trial: 4, iter: 800, curr loss: 1.3837770223617554, avg loss: 1.3864950352907182\n",
      "trial: 4, iter: 1000, curr loss: 1.3877151012420654, avg loss: 1.3867192995548248\n",
      "trial: 4, iter: 1200, curr loss: 1.3867073059082031, avg loss: 1.38632304251194\n",
      "trial: 4, iter: 1400, curr loss: 1.385462760925293, avg loss: 1.3862981981039046\n",
      "trial: 4, iter: 1600, curr loss: 1.3876698017120361, avg loss: 1.3858010846376418\n",
      "trial: 4, iter: 1800, curr loss: 1.383424997329712, avg loss: 1.384998050928116\n",
      "trial: 4, iter: 2000, curr loss: 1.3757244348526, avg loss: 1.3821358859539032\n",
      "trial: 4, iter: 2200, curr loss: 1.3792455196380615, avg loss: 1.3759875464439393\n",
      "trial: 4, iter: 2400, curr loss: 1.3758138418197632, avg loss: 1.3642636030912398\n",
      "trial: 4, iter: 2600, curr loss: 1.3409193754196167, avg loss: 1.3524127489328384\n",
      "trial: 4, iter: 2800, curr loss: 1.3563957214355469, avg loss: 1.3452879387140273\n",
      "trial: 4, iter: 3000, curr loss: 1.3235464096069336, avg loss: 1.3412702268362044\n",
      "trial: 4, iter: 3200, curr loss: 1.3439102172851562, avg loss: 1.3386484932899476\n",
      "trial: 4, iter: 3400, curr loss: 1.3185701370239258, avg loss: 1.3370523101091385\n",
      "trial: 4, iter: 3600, curr loss: 1.3361293077468872, avg loss: 1.3322116547822953\n",
      "trial: 4, iter: 3800, curr loss: 1.331805944442749, avg loss: 1.332318617105484\n",
      "trial: 4, iter: 4000, curr loss: 1.3314483165740967, avg loss: 1.3298856389522553\n",
      "trial: 4, iter: 4200, curr loss: 1.3352160453796387, avg loss: 1.3296009117364884\n",
      "trial: 4, iter: 4400, curr loss: 1.3473656177520752, avg loss: 1.3298262751102448\n",
      "trial: 4, iter: 4600, curr loss: 1.3118990659713745, avg loss: 1.3290198653936387\n",
      "trial: 4, iter: 4800, curr loss: 1.34857177734375, avg loss: 1.3282607692480086\n",
      "trial: 4, iter: 5000, curr loss: 1.3516396284103394, avg loss: 1.325271588563919\n",
      "trial: 4, iter: 5200, curr loss: 1.3107149600982666, avg loss: 1.3273789697885514\n",
      "trial: 4, iter: 5400, curr loss: 1.3317465782165527, avg loss: 1.3257224023342133\n",
      "trial: 4, iter: 5600, curr loss: 1.3227475881576538, avg loss: 1.3260174798965454\n",
      "trial: 4, iter: 5800, curr loss: 1.3221805095672607, avg loss: 1.327097954750061\n",
      "trial: 4, iter: 6000, curr loss: 1.3163774013519287, avg loss: 1.324422595500946\n",
      "trial: 4, iter: 6200, curr loss: 1.2790931463241577, avg loss: 1.3202144938707352\n",
      "trial: 4, ldr: -0.009469863958656788\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3908121585845947, avg loss: 1.3872430962324143\n",
      "trial: 5, iter: 400, curr loss: 1.383979320526123, avg loss: 1.386555200815201\n",
      "trial: 5, iter: 600, curr loss: 1.3869774341583252, avg loss: 1.386519045829773\n",
      "trial: 5, iter: 800, curr loss: 1.3875380754470825, avg loss: 1.3864899045228958\n",
      "trial: 5, iter: 1000, curr loss: 1.3872531652450562, avg loss: 1.3863582718372345\n",
      "trial: 5, iter: 1200, curr loss: 1.3862202167510986, avg loss: 1.3861986434459685\n",
      "trial: 5, iter: 1400, curr loss: 1.3848952054977417, avg loss: 1.3861930310726165\n",
      "trial: 5, iter: 1600, curr loss: 1.3844735622406006, avg loss: 1.3858610200881958\n",
      "trial: 5, iter: 1800, curr loss: 1.3883775472640991, avg loss: 1.385039256811142\n",
      "trial: 5, iter: 2000, curr loss: 1.3817566633224487, avg loss: 1.3823735469579697\n",
      "trial: 5, iter: 2200, curr loss: 1.3782809972763062, avg loss: 1.3755520045757295\n",
      "trial: 5, iter: 2400, curr loss: 1.353582501411438, avg loss: 1.3633458638191223\n",
      "trial: 5, iter: 2600, curr loss: 1.3499058485031128, avg loss: 1.3510716235637665\n",
      "trial: 5, iter: 2800, curr loss: 1.3104887008666992, avg loss: 1.34307241499424\n",
      "trial: 5, iter: 3000, curr loss: 1.368930459022522, avg loss: 1.3386238342523575\n",
      "trial: 5, iter: 3200, curr loss: 1.323553442955017, avg loss: 1.337652062177658\n",
      "trial: 5, iter: 3400, curr loss: 1.3514556884765625, avg loss: 1.3353502297401427\n",
      "trial: 5, iter: 3600, curr loss: 1.3514972925186157, avg loss: 1.3327591979503632\n",
      "trial: 5, iter: 3800, curr loss: 1.3284580707550049, avg loss: 1.3287001127004623\n",
      "trial: 5, iter: 4000, curr loss: 1.3335274457931519, avg loss: 1.3297911888360978\n",
      "trial: 5, iter: 4200, curr loss: 1.3300843238830566, avg loss: 1.3285609686374664\n",
      "trial: 5, iter: 4400, curr loss: 1.3206861019134521, avg loss: 1.3283190244436265\n",
      "trial: 5, iter: 4600, curr loss: 1.3034945726394653, avg loss: 1.326945844888687\n",
      "trial: 5, iter: 4800, curr loss: 1.326560139656067, avg loss: 1.3259271430969237\n",
      "trial: 5, iter: 5000, curr loss: 1.3344796895980835, avg loss: 1.323938355445862\n",
      "trial: 5, iter: 5200, curr loss: 1.312849760055542, avg loss: 1.3234770166873933\n",
      "trial: 5, iter: 5400, curr loss: 1.337497353553772, avg loss: 1.3213271409273148\n",
      "trial: 5, iter: 5600, curr loss: 1.3458658456802368, avg loss: 1.3212814635038377\n",
      "trial: 5, iter: 5800, curr loss: 1.2987943887710571, avg loss: 1.3223242259025574\n",
      "trial: 5, iter: 6000, curr loss: 1.3471378087997437, avg loss: 1.3199845796823502\n",
      "trial: 5, iter: 6200, curr loss: 1.334877371788025, avg loss: 1.321040791273117\n",
      "trial: 5, ldr: 0.010994074866175652\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00480821318924427\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3844614028930664, avg loss: 1.3873079937696458\n",
      "trial: 1, iter: 400, curr loss: 1.3907439708709717, avg loss: 1.3866289842128754\n",
      "trial: 1, iter: 600, curr loss: 1.3865910768508911, avg loss: 1.386430742740631\n",
      "trial: 1, iter: 800, curr loss: 1.3888431787490845, avg loss: 1.3865434086322785\n",
      "trial: 1, iter: 1000, curr loss: 1.387116551399231, avg loss: 1.3863312077522278\n",
      "trial: 1, iter: 1200, curr loss: 1.3874129056930542, avg loss: 1.385987356901169\n",
      "trial: 1, iter: 1400, curr loss: 1.3839524984359741, avg loss: 1.3856993103027344\n",
      "trial: 1, iter: 1600, curr loss: 1.380406141281128, avg loss: 1.3845518553256988\n",
      "trial: 1, iter: 1800, curr loss: 1.3776390552520752, avg loss: 1.3833138048648834\n",
      "trial: 1, iter: 2000, curr loss: 1.3861650228500366, avg loss: 1.3789797550439835\n",
      "trial: 1, iter: 2200, curr loss: 1.379846453666687, avg loss: 1.3728355813026427\n",
      "trial: 1, iter: 2400, curr loss: 1.3381569385528564, avg loss: 1.3627087414264678\n",
      "trial: 1, iter: 2600, curr loss: 1.3656046390533447, avg loss: 1.3499911016225814\n",
      "trial: 1, iter: 2800, curr loss: 1.3510372638702393, avg loss: 1.3435646241903305\n",
      "trial: 1, iter: 3000, curr loss: 1.3237383365631104, avg loss: 1.3384826254844666\n",
      "trial: 1, iter: 3200, curr loss: 1.3181612491607666, avg loss: 1.3351465994119645\n",
      "trial: 1, iter: 3400, curr loss: 1.331805944442749, avg loss: 1.3335418313741685\n",
      "trial: 1, iter: 3600, curr loss: 1.3181954622268677, avg loss: 1.3308967679738999\n",
      "trial: 1, iter: 3800, curr loss: 1.3555160760879517, avg loss: 1.330153598189354\n",
      "trial: 1, iter: 4000, curr loss: 1.3033899068832397, avg loss: 1.3275716024637223\n",
      "trial: 1, iter: 4200, curr loss: 1.3512967824935913, avg loss: 1.3290455728769301\n",
      "trial: 1, iter: 4400, curr loss: 1.323401689529419, avg loss: 1.328161472082138\n",
      "trial: 1, iter: 4600, curr loss: 1.3252348899841309, avg loss: 1.3264434146881103\n",
      "trial: 1, iter: 4800, curr loss: 1.3288094997406006, avg loss: 1.325520042181015\n",
      "trial: 1, iter: 5000, curr loss: 1.3135637044906616, avg loss: 1.322963178753853\n",
      "trial: 1, iter: 5200, curr loss: 1.3191217184066772, avg loss: 1.3246186113357543\n",
      "trial: 1, iter: 5400, curr loss: 1.355501413345337, avg loss: 1.3212671995162963\n",
      "trial: 1, iter: 5600, curr loss: 1.290437936782837, avg loss: 1.323117839694023\n",
      "trial: 1, iter: 5800, curr loss: 1.318798542022705, avg loss: 1.3236045223474502\n",
      "trial: 1, iter: 6000, curr loss: 1.351063847541809, avg loss: 1.3162510126829148\n",
      "trial: 1, iter: 6200, curr loss: 1.3269002437591553, avg loss: 1.3210138499736785\n",
      "trial: 1, ldr: 0.006448101252317429\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3878508806228638, avg loss: 1.3874528366327286\n",
      "trial: 2, iter: 400, curr loss: 1.388037919998169, avg loss: 1.386921380162239\n",
      "trial: 2, iter: 600, curr loss: 1.3888685703277588, avg loss: 1.3865555065870285\n",
      "trial: 2, iter: 800, curr loss: 1.3874505758285522, avg loss: 1.3868070429563522\n",
      "trial: 2, iter: 1000, curr loss: 1.3858925104141235, avg loss: 1.3864203149080276\n",
      "trial: 2, iter: 1200, curr loss: 1.383865475654602, avg loss: 1.3863521832227708\n",
      "trial: 2, iter: 1400, curr loss: 1.386682152748108, avg loss: 1.3860848343372345\n",
      "trial: 2, iter: 1600, curr loss: 1.3845689296722412, avg loss: 1.3856396913528441\n",
      "trial: 2, iter: 1800, curr loss: 1.38340163230896, avg loss: 1.3845498353242873\n",
      "trial: 2, iter: 2000, curr loss: 1.3780518770217896, avg loss: 1.3812831276655197\n",
      "trial: 2, iter: 2200, curr loss: 1.3639205694198608, avg loss: 1.37619948387146\n",
      "trial: 2, iter: 2400, curr loss: 1.3583482503890991, avg loss: 1.3649700391292572\n",
      "trial: 2, iter: 2600, curr loss: 1.3752883672714233, avg loss: 1.352949429154396\n",
      "trial: 2, iter: 2800, curr loss: 1.3502814769744873, avg loss: 1.345114575624466\n",
      "trial: 2, iter: 3000, curr loss: 1.3634787797927856, avg loss: 1.3421419668197632\n",
      "trial: 2, iter: 3200, curr loss: 1.3402142524719238, avg loss: 1.335829753279686\n",
      "trial: 2, iter: 3400, curr loss: 1.2996058464050293, avg loss: 1.3340804302692413\n",
      "trial: 2, iter: 3600, curr loss: 1.3087643384933472, avg loss: 1.3309520828723906\n",
      "trial: 2, iter: 3800, curr loss: 1.318101167678833, avg loss: 1.3294347661733628\n",
      "trial: 2, iter: 4000, curr loss: 1.306971549987793, avg loss: 1.327885113954544\n",
      "trial: 2, iter: 4200, curr loss: 1.3167656660079956, avg loss: 1.3245791238546372\n",
      "trial: 2, iter: 4400, curr loss: 1.3374015092849731, avg loss: 1.3265349578857422\n",
      "trial: 2, iter: 4600, curr loss: 1.3559107780456543, avg loss: 1.3272577476501466\n",
      "trial: 2, iter: 4800, curr loss: 1.332535982131958, avg loss: 1.3258987921476364\n",
      "trial: 2, iter: 5000, curr loss: 1.340545892715454, avg loss: 1.3239278382062911\n",
      "trial: 2, iter: 5200, curr loss: 1.3505769968032837, avg loss: 1.325368646979332\n",
      "trial: 2, iter: 5400, curr loss: 1.31394624710083, avg loss: 1.3221774077415467\n",
      "trial: 2, iter: 5600, curr loss: 1.3321199417114258, avg loss: 1.3210373890399933\n",
      "trial: 2, iter: 5800, curr loss: 1.3320364952087402, avg loss: 1.320328384041786\n",
      "trial: 2, iter: 6000, curr loss: 1.3217624425888062, avg loss: 1.3220970219373702\n",
      "trial: 2, iter: 6200, curr loss: 1.3493807315826416, avg loss: 1.3215292686223983\n",
      "trial: 2, ldr: 0.027503784745931625\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3863917589187622, avg loss: 1.387115124464035\n",
      "trial: 3, iter: 400, curr loss: 1.3858603239059448, avg loss: 1.3867571383714676\n",
      "trial: 3, iter: 600, curr loss: 1.385911464691162, avg loss: 1.3866444420814514\n",
      "trial: 3, iter: 800, curr loss: 1.3831583261489868, avg loss: 1.3865382504463195\n",
      "trial: 3, iter: 1000, curr loss: 1.3879350423812866, avg loss: 1.3865461653470994\n",
      "trial: 3, iter: 1200, curr loss: 1.3846385478973389, avg loss: 1.3864181619882583\n",
      "trial: 3, iter: 1400, curr loss: 1.387524962425232, avg loss: 1.3862592470645905\n",
      "trial: 3, iter: 1600, curr loss: 1.3861712217330933, avg loss: 1.3861756885051728\n",
      "trial: 3, iter: 1800, curr loss: 1.3849074840545654, avg loss: 1.386074841618538\n",
      "trial: 3, iter: 2000, curr loss: 1.383575201034546, avg loss: 1.3851864939928056\n",
      "trial: 3, iter: 2200, curr loss: 1.3836113214492798, avg loss: 1.3826410514116287\n",
      "trial: 3, iter: 2400, curr loss: 1.3684028387069702, avg loss: 1.3766958701610565\n",
      "trial: 3, iter: 2600, curr loss: 1.3723571300506592, avg loss: 1.366751669049263\n",
      "trial: 3, iter: 2800, curr loss: 1.360477328300476, avg loss: 1.3545509159564972\n",
      "trial: 3, iter: 3000, curr loss: 1.359485149383545, avg loss: 1.3460136407613754\n",
      "trial: 3, iter: 3200, curr loss: 1.324069857597351, avg loss: 1.340437200665474\n",
      "trial: 3, iter: 3400, curr loss: 1.3280638456344604, avg loss: 1.3380690044164658\n",
      "trial: 3, iter: 3600, curr loss: 1.3374274969100952, avg loss: 1.332643895149231\n",
      "trial: 3, iter: 3800, curr loss: 1.3264145851135254, avg loss: 1.3315000039339067\n",
      "trial: 3, iter: 4000, curr loss: 1.3396228551864624, avg loss: 1.331248791217804\n",
      "trial: 3, iter: 4200, curr loss: 1.3024358749389648, avg loss: 1.3307316535711289\n",
      "trial: 3, iter: 4400, curr loss: 1.3245655298233032, avg loss: 1.325659852027893\n",
      "trial: 3, iter: 4600, curr loss: 1.3174834251403809, avg loss: 1.3240935868024826\n",
      "trial: 3, iter: 4800, curr loss: 1.3048570156097412, avg loss: 1.32730872631073\n",
      "trial: 3, iter: 5000, curr loss: 1.3249962329864502, avg loss: 1.3275326305627824\n",
      "trial: 3, iter: 5200, curr loss: 1.301972508430481, avg loss: 1.323816892504692\n",
      "trial: 3, iter: 5400, curr loss: 1.357035756111145, avg loss: 1.3235046696662902\n",
      "trial: 3, iter: 5600, curr loss: 1.326733112335205, avg loss: 1.3240220022201539\n",
      "trial: 3, iter: 5800, curr loss: 1.3125331401824951, avg loss: 1.3198923426866531\n",
      "trial: 3, iter: 6000, curr loss: 1.31551194190979, avg loss: 1.3220034968852996\n",
      "trial: 3, iter: 6200, curr loss: 1.3160415887832642, avg loss: 1.3219241613149644\n",
      "trial: 3, ldr: 0.0052934871055185795\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3862382173538208, avg loss: 1.387563041448593\n",
      "trial: 4, iter: 400, curr loss: 1.3841989040374756, avg loss: 1.3867031973600388\n",
      "trial: 4, iter: 600, curr loss: 1.3859001398086548, avg loss: 1.3867745405435563\n",
      "trial: 4, iter: 800, curr loss: 1.3853609561920166, avg loss: 1.3865237408876419\n",
      "trial: 4, iter: 1000, curr loss: 1.3867545127868652, avg loss: 1.3863312023878098\n",
      "trial: 4, iter: 1200, curr loss: 1.3862577676773071, avg loss: 1.3862834149599075\n",
      "trial: 4, iter: 1400, curr loss: 1.3850460052490234, avg loss: 1.3861126917600632\n",
      "trial: 4, iter: 1600, curr loss: 1.3810888528823853, avg loss: 1.3855133259296417\n",
      "trial: 4, iter: 1800, curr loss: 1.3778067827224731, avg loss: 1.3835901647806168\n",
      "trial: 4, iter: 2000, curr loss: 1.3740640878677368, avg loss: 1.3801967602968217\n",
      "trial: 4, iter: 2200, curr loss: 1.3742270469665527, avg loss: 1.3709663659334184\n",
      "trial: 4, iter: 2400, curr loss: 1.3455390930175781, avg loss: 1.3590550994873047\n",
      "trial: 4, iter: 2600, curr loss: 1.3333663940429688, avg loss: 1.349627184867859\n",
      "trial: 4, iter: 2800, curr loss: 1.3444005250930786, avg loss: 1.3429753643274307\n",
      "trial: 4, iter: 3000, curr loss: 1.3300045728683472, avg loss: 1.3377432060241699\n",
      "trial: 4, iter: 3200, curr loss: 1.3455309867858887, avg loss: 1.334482151865959\n",
      "trial: 4, iter: 3400, curr loss: 1.3209280967712402, avg loss: 1.3310593116283416\n",
      "trial: 4, iter: 3600, curr loss: 1.3500518798828125, avg loss: 1.3316824489831924\n",
      "trial: 4, iter: 3800, curr loss: 1.321953535079956, avg loss: 1.3283971148729323\n",
      "trial: 4, iter: 4000, curr loss: 1.3390071392059326, avg loss: 1.3262818533182144\n",
      "trial: 4, iter: 4200, curr loss: 1.3545379638671875, avg loss: 1.3276522356271743\n",
      "trial: 4, iter: 4400, curr loss: 1.3290314674377441, avg loss: 1.3247830414772033\n",
      "trial: 4, iter: 4600, curr loss: 1.3384363651275635, avg loss: 1.3245949810743332\n",
      "trial: 4, iter: 4800, curr loss: 1.3074138164520264, avg loss: 1.324573073387146\n",
      "trial: 4, iter: 5000, curr loss: 1.3216745853424072, avg loss: 1.3213872516155243\n",
      "trial: 4, iter: 5200, curr loss: 1.3264788389205933, avg loss: 1.322223391532898\n",
      "trial: 4, iter: 5400, curr loss: 1.3067469596862793, avg loss: 1.3242518085241317\n",
      "trial: 4, iter: 5600, curr loss: 1.307837724685669, avg loss: 1.3215164083242417\n",
      "trial: 4, iter: 5800, curr loss: 1.3080052137374878, avg loss: 1.3213473796844482\n",
      "trial: 4, iter: 6000, curr loss: 1.321558952331543, avg loss: 1.3199866706132888\n",
      "trial: 4, iter: 6200, curr loss: 1.343320608139038, avg loss: 1.3152503603696823\n",
      "trial: 4, ldr: 0.015207529999315739\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3916374444961548, avg loss: 1.3873549568653107\n",
      "trial: 5, iter: 400, curr loss: 1.3861056566238403, avg loss: 1.3869446194171906\n",
      "trial: 5, iter: 600, curr loss: 1.3856581449508667, avg loss: 1.3867045652866363\n",
      "trial: 5, iter: 800, curr loss: 1.3868346214294434, avg loss: 1.386566035747528\n",
      "trial: 5, iter: 1000, curr loss: 1.3865224123001099, avg loss: 1.386568590402603\n",
      "trial: 5, iter: 1200, curr loss: 1.387580156326294, avg loss: 1.3863316208124161\n",
      "trial: 5, iter: 1400, curr loss: 1.3866008520126343, avg loss: 1.3860706037282944\n",
      "trial: 5, iter: 1600, curr loss: 1.3868083953857422, avg loss: 1.3855700588226318\n",
      "trial: 5, iter: 1800, curr loss: 1.3880277872085571, avg loss: 1.3833856213092803\n",
      "trial: 5, iter: 2000, curr loss: 1.3776862621307373, avg loss: 1.3783394336700439\n",
      "trial: 5, iter: 2200, curr loss: 1.3609576225280762, avg loss: 1.3700900894403458\n",
      "trial: 5, iter: 2400, curr loss: 1.3516299724578857, avg loss: 1.3586252731084825\n",
      "trial: 5, iter: 2600, curr loss: 1.3236891031265259, avg loss: 1.346550155878067\n",
      "trial: 5, iter: 2800, curr loss: 1.3303040266036987, avg loss: 1.3403092139959336\n",
      "trial: 5, iter: 3000, curr loss: 1.3215724229812622, avg loss: 1.338633463382721\n",
      "trial: 5, iter: 3200, curr loss: 1.3253496885299683, avg loss: 1.3359059494733811\n",
      "trial: 5, iter: 3400, curr loss: 1.3151921033859253, avg loss: 1.332426884174347\n",
      "trial: 5, iter: 3600, curr loss: 1.2794584035873413, avg loss: 1.330406363606453\n",
      "trial: 5, iter: 3800, curr loss: 1.290811538696289, avg loss: 1.3294183146953582\n",
      "trial: 5, iter: 4000, curr loss: 1.3086507320404053, avg loss: 1.3283793711662293\n",
      "trial: 5, iter: 4200, curr loss: 1.3448269367218018, avg loss: 1.3258550107479095\n",
      "trial: 5, iter: 4400, curr loss: 1.3156930208206177, avg loss: 1.3250889849662781\n",
      "trial: 5, iter: 4600, curr loss: 1.309406042098999, avg loss: 1.3243654155731202\n",
      "trial: 5, iter: 4800, curr loss: 1.3204076290130615, avg loss: 1.3234140825271608\n",
      "trial: 5, iter: 5000, curr loss: 1.3373903036117554, avg loss: 1.322542688846588\n",
      "trial: 5, iter: 5200, curr loss: 1.3325631618499756, avg loss: 1.3217096793651582\n",
      "trial: 5, iter: 5400, curr loss: 1.3154911994934082, avg loss: 1.319417777657509\n",
      "trial: 5, iter: 5600, curr loss: 1.3144642114639282, avg loss: 1.3210098189115524\n",
      "trial: 5, iter: 5800, curr loss: 1.34419846534729, avg loss: 1.320889305472374\n",
      "trial: 5, iter: 6000, curr loss: 1.3054783344268799, avg loss: 1.3173077934980393\n",
      "trial: 5, iter: 6200, curr loss: 1.3044568300247192, avg loss: 1.315742899775505\n",
      "trial: 5, ldr: -0.02147778309881687\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0065950240008533\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.385473608970642, avg loss: 1.3874168962240219\n",
      "trial: 1, iter: 400, curr loss: 1.3938086032867432, avg loss: 1.386903578042984\n",
      "trial: 1, iter: 600, curr loss: 1.386494517326355, avg loss: 1.3867347013950349\n",
      "trial: 1, iter: 800, curr loss: 1.3861955404281616, avg loss: 1.3865538227558136\n",
      "trial: 1, iter: 1000, curr loss: 1.391587734222412, avg loss: 1.3864237874746324\n",
      "trial: 1, iter: 1200, curr loss: 1.3835095167160034, avg loss: 1.3863228523731232\n",
      "trial: 1, iter: 1400, curr loss: 1.3868664503097534, avg loss: 1.3864380759000778\n",
      "trial: 1, iter: 1600, curr loss: 1.3846123218536377, avg loss: 1.3860738676786424\n",
      "trial: 1, iter: 1800, curr loss: 1.3852260112762451, avg loss: 1.3853576081991195\n",
      "trial: 1, iter: 2000, curr loss: 1.382338285446167, avg loss: 1.3836262547969818\n",
      "trial: 1, iter: 2200, curr loss: 1.3742687702178955, avg loss: 1.3795174956321716\n",
      "trial: 1, iter: 2400, curr loss: 1.351444125175476, avg loss: 1.3704072493314743\n",
      "trial: 1, iter: 2600, curr loss: 1.3585065603256226, avg loss: 1.3586504596471787\n",
      "trial: 1, iter: 2800, curr loss: 1.3334767818450928, avg loss: 1.3487576580047607\n",
      "trial: 1, iter: 3000, curr loss: 1.3315218687057495, avg loss: 1.341033452153206\n",
      "trial: 1, iter: 3200, curr loss: 1.3514316082000732, avg loss: 1.339024425148964\n",
      "trial: 1, iter: 3400, curr loss: 1.310577154159546, avg loss: 1.3365152448415756\n",
      "trial: 1, iter: 3600, curr loss: 1.3570953607559204, avg loss: 1.3303475189208984\n",
      "trial: 1, iter: 3800, curr loss: 1.3302711248397827, avg loss: 1.3300476115942002\n",
      "trial: 1, iter: 4000, curr loss: 1.3266019821166992, avg loss: 1.3320776909589767\n",
      "trial: 1, iter: 4200, curr loss: 1.325163722038269, avg loss: 1.32844034075737\n",
      "trial: 1, iter: 4400, curr loss: 1.317539095878601, avg loss: 1.3258683669567108\n",
      "trial: 1, iter: 4600, curr loss: 1.3209632635116577, avg loss: 1.3270224982500076\n",
      "trial: 1, iter: 4800, curr loss: 1.314715027809143, avg loss: 1.3287041360139846\n",
      "trial: 1, iter: 5000, curr loss: 1.321557641029358, avg loss: 1.3249188655614852\n",
      "trial: 1, iter: 5200, curr loss: 1.3189712762832642, avg loss: 1.3239315086603165\n",
      "trial: 1, iter: 5400, curr loss: 1.3621374368667603, avg loss: 1.3238673990964889\n",
      "trial: 1, iter: 5600, curr loss: 1.3372044563293457, avg loss: 1.3239182245731353\n",
      "trial: 1, iter: 5800, curr loss: 1.33804452419281, avg loss: 1.3221077531576158\n",
      "trial: 1, iter: 6000, curr loss: 1.3129311800003052, avg loss: 1.3220793461799623\n",
      "trial: 1, iter: 6200, curr loss: 1.2944071292877197, avg loss: 1.3202100598812103\n",
      "trial: 1, ldr: 0.02705385722219944\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3850414752960205, avg loss: 1.3871163856983184\n",
      "trial: 2, iter: 400, curr loss: 1.3873060941696167, avg loss: 1.38669864654541\n",
      "trial: 2, iter: 600, curr loss: 1.3844438791275024, avg loss: 1.3866130477190017\n",
      "trial: 2, iter: 800, curr loss: 1.3842723369598389, avg loss: 1.386546977162361\n",
      "trial: 2, iter: 1000, curr loss: 1.386306881904602, avg loss: 1.3864437687397002\n",
      "trial: 2, iter: 1200, curr loss: 1.3862812519073486, avg loss: 1.3864198392629623\n",
      "trial: 2, iter: 1400, curr loss: 1.3844808340072632, avg loss: 1.3862640756368636\n",
      "trial: 2, iter: 1600, curr loss: 1.3846440315246582, avg loss: 1.3861160337924958\n",
      "trial: 2, iter: 1800, curr loss: 1.3854702711105347, avg loss: 1.3858418601751328\n",
      "trial: 2, iter: 2000, curr loss: 1.381649136543274, avg loss: 1.3847419142723083\n",
      "trial: 2, iter: 2200, curr loss: 1.3785040378570557, avg loss: 1.3828192889690398\n",
      "trial: 2, iter: 2400, curr loss: 1.3843531608581543, avg loss: 1.381155589222908\n",
      "trial: 2, iter: 2600, curr loss: 1.386443853378296, avg loss: 1.3769959539175034\n",
      "trial: 2, iter: 2800, curr loss: 1.3578459024429321, avg loss: 1.3684126150608062\n",
      "trial: 2, iter: 3000, curr loss: 1.368062138557434, avg loss: 1.357519788146019\n",
      "trial: 2, iter: 3200, curr loss: 1.338210105895996, avg loss: 1.3467899507284165\n",
      "trial: 2, iter: 3400, curr loss: 1.3684489727020264, avg loss: 1.342700509428978\n",
      "trial: 2, iter: 3600, curr loss: 1.3527709245681763, avg loss: 1.3396021181344986\n",
      "trial: 2, iter: 3800, curr loss: 1.3270448446273804, avg loss: 1.3347087681293488\n",
      "trial: 2, iter: 4000, curr loss: 1.3226262331008911, avg loss: 1.332222622036934\n",
      "trial: 2, iter: 4200, curr loss: 1.3394176959991455, avg loss: 1.328570745587349\n",
      "trial: 2, iter: 4400, curr loss: 1.3305171728134155, avg loss: 1.3284423887729644\n",
      "trial: 2, iter: 4600, curr loss: 1.3158727884292603, avg loss: 1.3266884845495224\n",
      "trial: 2, iter: 4800, curr loss: 1.3450247049331665, avg loss: 1.3278614348173141\n",
      "trial: 2, iter: 5000, curr loss: 1.2996004819869995, avg loss: 1.3262774235010146\n",
      "trial: 2, iter: 5200, curr loss: 1.3466075658798218, avg loss: 1.3258968126773834\n",
      "trial: 2, iter: 5400, curr loss: 1.3564287424087524, avg loss: 1.3241480028629302\n",
      "trial: 2, iter: 5600, curr loss: 1.3295167684555054, avg loss: 1.3217343878746033\n",
      "trial: 2, iter: 5800, curr loss: 1.319033145904541, avg loss: 1.3216053068637847\n",
      "trial: 2, iter: 6000, curr loss: 1.2940328121185303, avg loss: 1.3217204505205153\n",
      "trial: 2, iter: 6200, curr loss: 1.3502874374389648, avg loss: 1.3203807479143144\n",
      "trial: 2, ldr: -0.012189020402729511\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3855831623077393, avg loss: 1.3872933077812195\n",
      "trial: 3, iter: 400, curr loss: 1.386853575706482, avg loss: 1.3868084996938705\n",
      "trial: 3, iter: 600, curr loss: 1.3865278959274292, avg loss: 1.3865200424194335\n",
      "trial: 3, iter: 800, curr loss: 1.3857148885726929, avg loss: 1.3862779873609543\n",
      "trial: 3, iter: 1000, curr loss: 1.3838499784469604, avg loss: 1.3861060535907745\n",
      "trial: 3, iter: 1200, curr loss: 1.3822078704833984, avg loss: 1.38539699614048\n",
      "trial: 3, iter: 1400, curr loss: 1.3915021419525146, avg loss: 1.3835936427116393\n",
      "trial: 3, iter: 1600, curr loss: 1.3857343196868896, avg loss: 1.3808639413118362\n",
      "trial: 3, iter: 1800, curr loss: 1.3769205808639526, avg loss: 1.3767216050624846\n",
      "trial: 3, iter: 2000, curr loss: 1.3719514608383179, avg loss: 1.3689942455291748\n",
      "trial: 3, iter: 2200, curr loss: 1.3548667430877686, avg loss: 1.3605975472927094\n",
      "trial: 3, iter: 2400, curr loss: 1.3575540781021118, avg loss: 1.3489448481798172\n",
      "trial: 3, iter: 2600, curr loss: 1.3073387145996094, avg loss: 1.3459133672714234\n",
      "trial: 3, iter: 2800, curr loss: 1.3184260129928589, avg loss: 1.3411436951160431\n",
      "trial: 3, iter: 3000, curr loss: 1.3204097747802734, avg loss: 1.336309444308281\n",
      "trial: 3, iter: 3200, curr loss: 1.3325212001800537, avg loss: 1.336344962120056\n",
      "trial: 3, iter: 3400, curr loss: 1.3714133501052856, avg loss: 1.333932297229767\n",
      "trial: 3, iter: 3600, curr loss: 1.3451833724975586, avg loss: 1.3320834368467331\n",
      "trial: 3, iter: 3800, curr loss: 1.327308177947998, avg loss: 1.3325396817922592\n",
      "trial: 3, iter: 4000, curr loss: 1.3407045602798462, avg loss: 1.3277280235290527\n",
      "trial: 3, iter: 4200, curr loss: 1.3225650787353516, avg loss: 1.3298125731945039\n",
      "trial: 3, iter: 4400, curr loss: 1.3487334251403809, avg loss: 1.3280856728553772\n",
      "trial: 3, iter: 4600, curr loss: 1.3032315969467163, avg loss: 1.325454980134964\n",
      "trial: 3, iter: 4800, curr loss: 1.3535971641540527, avg loss: 1.3247258788347245\n",
      "trial: 3, iter: 5000, curr loss: 1.3009288311004639, avg loss: 1.3258464312553406\n",
      "trial: 3, iter: 5200, curr loss: 1.318784475326538, avg loss: 1.3239747786521912\n",
      "trial: 3, iter: 5400, curr loss: 1.317260503768921, avg loss: 1.3226669663190842\n",
      "trial: 3, iter: 5600, curr loss: 1.304403305053711, avg loss: 1.322745236158371\n",
      "trial: 3, iter: 5800, curr loss: 1.3189435005187988, avg loss: 1.3212580376863479\n",
      "trial: 3, iter: 6000, curr loss: 1.3202327489852905, avg loss: 1.3200760000944138\n",
      "trial: 3, iter: 6200, curr loss: 1.3449772596359253, avg loss: 1.321586458683014\n",
      "trial: 3, ldr: 0.01715870574116707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386834979057312, avg loss: 1.3872994899749755\n",
      "trial: 4, iter: 400, curr loss: 1.3852030038833618, avg loss: 1.3868047547340394\n",
      "trial: 4, iter: 600, curr loss: 1.3849090337753296, avg loss: 1.3866440641880036\n",
      "trial: 4, iter: 800, curr loss: 1.390057921409607, avg loss: 1.3864550971984864\n",
      "trial: 4, iter: 1000, curr loss: 1.3869857788085938, avg loss: 1.3862731289863586\n",
      "trial: 4, iter: 1200, curr loss: 1.386950969696045, avg loss: 1.3858285170793534\n",
      "trial: 4, iter: 1400, curr loss: 1.3842402696609497, avg loss: 1.385233981013298\n",
      "trial: 4, iter: 1600, curr loss: 1.3762402534484863, avg loss: 1.3834656381607056\n",
      "trial: 4, iter: 1800, curr loss: 1.3761868476867676, avg loss: 1.3801859164237975\n",
      "trial: 4, iter: 2000, curr loss: 1.3700135946273804, avg loss: 1.3762406355142593\n",
      "trial: 4, iter: 2200, curr loss: 1.3654193878173828, avg loss: 1.3691047978401185\n",
      "trial: 4, iter: 2400, curr loss: 1.36388099193573, avg loss: 1.358923681974411\n",
      "trial: 4, iter: 2600, curr loss: 1.363500714302063, avg loss: 1.349288238286972\n",
      "trial: 4, iter: 2800, curr loss: 1.3482316732406616, avg loss: 1.341633416414261\n",
      "trial: 4, iter: 3000, curr loss: 1.346172571182251, avg loss: 1.3374546515941619\n",
      "trial: 4, iter: 3200, curr loss: 1.326244831085205, avg loss: 1.334738250374794\n",
      "trial: 4, iter: 3400, curr loss: 1.346663236618042, avg loss: 1.3341751164197921\n",
      "trial: 4, iter: 3600, curr loss: 1.285678744316101, avg loss: 1.332859497666359\n",
      "trial: 4, iter: 3800, curr loss: 1.3204784393310547, avg loss: 1.3302029871940613\n",
      "trial: 4, iter: 4000, curr loss: 1.3381341695785522, avg loss: 1.3307891273498536\n",
      "trial: 4, iter: 4200, curr loss: 1.333986520767212, avg loss: 1.3284680485725402\n",
      "trial: 4, iter: 4400, curr loss: 1.3217939138412476, avg loss: 1.327375613451004\n",
      "trial: 4, iter: 4600, curr loss: 1.3436490297317505, avg loss: 1.3273093008995056\n",
      "trial: 4, iter: 4800, curr loss: 1.2717680931091309, avg loss: 1.3251235938072206\n",
      "trial: 4, iter: 5000, curr loss: 1.3178863525390625, avg loss: 1.3222429502010344\n",
      "trial: 4, iter: 5200, curr loss: 1.3228460550308228, avg loss: 1.3227346456050872\n",
      "trial: 4, iter: 5400, curr loss: 1.3268734216690063, avg loss: 1.3236615025997163\n",
      "trial: 4, iter: 5600, curr loss: 1.3082340955734253, avg loss: 1.3253682750463485\n",
      "trial: 4, iter: 5800, curr loss: 1.2691993713378906, avg loss: 1.3215577238798142\n",
      "trial: 4, iter: 6000, curr loss: 1.3210340738296509, avg loss: 1.3212210541963578\n",
      "trial: 4, iter: 6200, curr loss: 1.3210203647613525, avg loss: 1.320886293053627\n",
      "trial: 4, ldr: 0.004543273244053125\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387251377105713, avg loss: 1.3875922608375548\n",
      "trial: 5, iter: 400, curr loss: 1.389341950416565, avg loss: 1.3868911772966386\n",
      "trial: 5, iter: 600, curr loss: 1.383691668510437, avg loss: 1.3864812248945235\n",
      "trial: 5, iter: 800, curr loss: 1.3870004415512085, avg loss: 1.3866922891139983\n",
      "trial: 5, iter: 1000, curr loss: 1.3856234550476074, avg loss: 1.3860814028978348\n",
      "trial: 5, iter: 1200, curr loss: 1.3873330354690552, avg loss: 1.3861202472448348\n",
      "trial: 5, iter: 1400, curr loss: 1.3842679262161255, avg loss: 1.3853747582435607\n",
      "trial: 5, iter: 1600, curr loss: 1.3792147636413574, avg loss: 1.3843028658628465\n",
      "trial: 5, iter: 1800, curr loss: 1.3780962228775024, avg loss: 1.3822323077917098\n",
      "trial: 5, iter: 2000, curr loss: 1.3838045597076416, avg loss: 1.379950032234192\n",
      "trial: 5, iter: 2200, curr loss: 1.3682364225387573, avg loss: 1.3764038789272308\n",
      "trial: 5, iter: 2400, curr loss: 1.3586064577102661, avg loss: 1.3701806497573852\n",
      "trial: 5, iter: 2600, curr loss: 1.3521829843521118, avg loss: 1.3607456171512604\n",
      "trial: 5, iter: 2800, curr loss: 1.3422473669052124, avg loss: 1.353636575937271\n",
      "trial: 5, iter: 3000, curr loss: 1.357743740081787, avg loss: 1.3464190584421158\n",
      "trial: 5, iter: 3200, curr loss: 1.3488308191299438, avg loss: 1.339399113059044\n",
      "trial: 5, iter: 3400, curr loss: 1.338685154914856, avg loss: 1.3359700602293014\n",
      "trial: 5, iter: 3600, curr loss: 1.2991727590560913, avg loss: 1.3333732032775878\n",
      "trial: 5, iter: 3800, curr loss: 1.3184702396392822, avg loss: 1.3317135626077652\n",
      "trial: 5, iter: 4000, curr loss: 1.3460592031478882, avg loss: 1.3325345021486283\n",
      "trial: 5, iter: 4200, curr loss: 1.3398921489715576, avg loss: 1.328180307149887\n",
      "trial: 5, iter: 4400, curr loss: 1.3499157428741455, avg loss: 1.3268652856349945\n",
      "trial: 5, iter: 4600, curr loss: 1.335338830947876, avg loss: 1.327262854576111\n",
      "trial: 5, iter: 4800, curr loss: 1.3211525678634644, avg loss: 1.3270602226257324\n",
      "trial: 5, iter: 5000, curr loss: 1.3030307292938232, avg loss: 1.3243216645717621\n",
      "trial: 5, iter: 5200, curr loss: 1.3185573816299438, avg loss: 1.3234078371524811\n",
      "trial: 5, iter: 5400, curr loss: 1.3521424531936646, avg loss: 1.3210102391242982\n",
      "trial: 5, iter: 5600, curr loss: 1.3114912509918213, avg loss: 1.3239082169532777\n",
      "trial: 5, iter: 5800, curr loss: 1.3518580198287964, avg loss: 1.3213494282960891\n",
      "trial: 5, iter: 6000, curr loss: 1.3136875629425049, avg loss: 1.321778809428215\n",
      "trial: 5, iter: 6200, curr loss: 1.3055951595306396, avg loss: 1.3213870930671692\n",
      "trial: 5, ldr: 0.012704486958682537\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.009854260552674531\n",
      "Experiment done with data path: ./data/catNon-lin-NI_7/data.20k.dz20.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_16/data.50k.dz100.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.389398455619812, avg loss: 1.3872654992341995\n",
      "trial: 1, iter: 400, curr loss: 1.3831990957260132, avg loss: 1.3867301630973816\n",
      "trial: 1, iter: 600, curr loss: 1.3903559446334839, avg loss: 1.3864775216579437\n",
      "trial: 1, iter: 800, curr loss: 1.3866158723831177, avg loss: 1.3864137428998946\n",
      "trial: 1, iter: 1000, curr loss: 1.3875255584716797, avg loss: 1.3863756996393204\n",
      "trial: 1, iter: 1200, curr loss: 1.3854007720947266, avg loss: 1.3864475393295288\n",
      "trial: 1, iter: 1400, curr loss: 1.385525107383728, avg loss: 1.3863750886917114\n",
      "trial: 1, iter: 1600, curr loss: 1.3864320516586304, avg loss: 1.3864124912023543\n",
      "trial: 1, iter: 1800, curr loss: 1.3872528076171875, avg loss: 1.3864335715770721\n",
      "trial: 1, iter: 2000, curr loss: 1.386218786239624, avg loss: 1.3864081335067748\n",
      "trial: 1, iter: 2200, curr loss: 1.3860535621643066, avg loss: 1.3864344424009323\n",
      "trial: 1, iter: 2400, curr loss: 1.385844349861145, avg loss: 1.3864506411552429\n",
      "trial: 1, iter: 2600, curr loss: 1.3864012956619263, avg loss: 1.3864016062021256\n",
      "trial: 1, iter: 2800, curr loss: 1.3869328498840332, avg loss: 1.3863069927692413\n",
      "trial: 1, iter: 3000, curr loss: 1.3858647346496582, avg loss: 1.3863767009973527\n",
      "trial: 1, iter: 3200, curr loss: 1.385730504989624, avg loss: 1.386453177332878\n",
      "trial: 1, iter: 3400, curr loss: 1.3863258361816406, avg loss: 1.3863270992040635\n",
      "trial: 1, iter: 3600, curr loss: 1.385572075843811, avg loss: 1.3862749129533767\n",
      "trial: 1, iter: 3800, curr loss: 1.3862380981445312, avg loss: 1.386333060860634\n",
      "trial: 1, iter: 4000, curr loss: 1.387677788734436, avg loss: 1.386323910355568\n",
      "trial: 1, iter: 4200, curr loss: 1.3863499164581299, avg loss: 1.3863622945547105\n",
      "trial: 1, iter: 4400, curr loss: 1.385877013206482, avg loss: 1.3863611698150635\n",
      "trial: 1, iter: 4600, curr loss: 1.3867088556289673, avg loss: 1.3863117617368699\n",
      "trial: 1, iter: 4800, curr loss: 1.3863403797149658, avg loss: 1.386313025355339\n",
      "trial: 1, iter: 5000, curr loss: 1.386352300643921, avg loss: 1.3863040989637374\n",
      "trial: 1, iter: 5200, curr loss: 1.3868988752365112, avg loss: 1.3863119280338287\n",
      "trial: 1, iter: 5400, curr loss: 1.3862451314926147, avg loss: 1.386332237124443\n",
      "trial: 1, iter: 5600, curr loss: 1.3868188858032227, avg loss: 1.386306254863739\n",
      "trial: 1, iter: 5800, curr loss: 1.3863706588745117, avg loss: 1.3862911766767503\n",
      "trial: 1, iter: 6000, curr loss: 1.3843085765838623, avg loss: 1.3863081312179566\n",
      "trial: 1, iter: 6200, curr loss: 1.3872971534729004, avg loss: 1.386364695429802\n",
      "trial: 1, iter: 6400, curr loss: 1.386892557144165, avg loss: 1.3863004636764527\n",
      "trial: 1, iter: 6600, curr loss: 1.3867180347442627, avg loss: 1.3863210988044739\n",
      "trial: 1, iter: 6800, curr loss: 1.3845423460006714, avg loss: 1.3863725507259368\n",
      "trial: 1, iter: 7000, curr loss: 1.3862844705581665, avg loss: 1.3863630437850951\n",
      "trial: 1, iter: 7200, curr loss: 1.3866493701934814, avg loss: 1.386387990117073\n",
      "trial: 1, iter: 7400, curr loss: 1.3856730461120605, avg loss: 1.3863111591339112\n",
      "trial: 1, iter: 7600, curr loss: 1.3862841129302979, avg loss: 1.3863415956497191\n",
      "trial: 1, iter: 7800, curr loss: 1.387525200843811, avg loss: 1.3862746620178223\n",
      "trial: 1, iter: 8000, curr loss: 1.3863525390625, avg loss: 1.3863530886173248\n",
      "trial: 1, iter: 8200, curr loss: 1.3870799541473389, avg loss: 1.3862790387868882\n",
      "trial: 1, iter: 8400, curr loss: 1.3861857652664185, avg loss: 1.386360263824463\n",
      "trial: 1, iter: 8600, curr loss: 1.3864291906356812, avg loss: 1.3862955290079118\n",
      "trial: 1, iter: 8800, curr loss: 1.386660099029541, avg loss: 1.3862969452142715\n",
      "trial: 1, iter: 9000, curr loss: 1.3862838745117188, avg loss: 1.3863058906793595\n",
      "trial: 1, iter: 9200, curr loss: 1.3862769603729248, avg loss: 1.3863086360692978\n",
      "trial: 1, iter: 9400, curr loss: 1.3861531019210815, avg loss: 1.3863117599487305\n",
      "trial: 1, iter: 9600, curr loss: 1.3859074115753174, avg loss: 1.3863280123472215\n",
      "trial: 1, iter: 9800, curr loss: 1.3864763975143433, avg loss: 1.3863247454166412\n",
      "trial: 1, iter: 10000, curr loss: 1.3862358331680298, avg loss: 1.3863198000192642\n",
      "trial: 1, iter: 10200, curr loss: 1.3863157033920288, avg loss: 1.3863078099489212\n",
      "trial: 1, iter: 10400, curr loss: 1.385611653327942, avg loss: 1.3862940764427185\n",
      "trial: 1, iter: 10600, curr loss: 1.386035442352295, avg loss: 1.386334121823311\n",
      "trial: 1, iter: 10800, curr loss: 1.3863242864608765, avg loss: 1.3863161742687224\n",
      "trial: 1, iter: 11000, curr loss: 1.385859489440918, avg loss: 1.386298348903656\n",
      "trial: 1, iter: 11200, curr loss: 1.386308193206787, avg loss: 1.3862991935014726\n",
      "trial: 1, iter: 11400, curr loss: 1.3859463930130005, avg loss: 1.3863216304779054\n",
      "trial: 1, iter: 11600, curr loss: 1.3861843347549438, avg loss: 1.3862974345684052\n",
      "trial: 1, iter: 11800, curr loss: 1.386823058128357, avg loss: 1.386315346956253\n",
      "trial: 1, iter: 12000, curr loss: 1.3862696886062622, avg loss: 1.3862974673509598\n",
      "trial: 1, iter: 12200, curr loss: 1.386159062385559, avg loss: 1.386307572722435\n",
      "trial: 1, iter: 12400, curr loss: 1.3863270282745361, avg loss: 1.386299468278885\n",
      "trial: 1, iter: 12600, curr loss: 1.3861743211746216, avg loss: 1.3863038790225983\n",
      "trial: 1, iter: 12800, curr loss: 1.386235237121582, avg loss: 1.3863025516271592\n",
      "trial: 1, iter: 13000, curr loss: 1.3862015008926392, avg loss: 1.3863156950473785\n",
      "trial: 1, iter: 13200, curr loss: 1.386313557624817, avg loss: 1.3862875193357467\n",
      "trial: 1, iter: 13400, curr loss: 1.3862816095352173, avg loss: 1.386304172873497\n",
      "trial: 1, iter: 13600, curr loss: 1.3863016366958618, avg loss: 1.3862975639104844\n",
      "trial: 1, iter: 13800, curr loss: 1.3863000869750977, avg loss: 1.386295056939125\n",
      "trial: 1, iter: 14000, curr loss: 1.3862954378128052, avg loss: 1.3862946546077728\n",
      "trial: 1, iter: 14200, curr loss: 1.3862944841384888, avg loss: 1.3862946563959122\n",
      "trial: 1, iter: 14400, curr loss: 1.386295199394226, avg loss: 1.3862946623563766\n",
      "trial: 1, iter: 14600, curr loss: 1.3862948417663574, avg loss: 1.3862949687242507\n",
      "trial: 1, iter: 14800, curr loss: 1.3862937688827515, avg loss: 1.386294520497322\n",
      "trial: 1, iter: 15000, curr loss: 1.3862965106964111, avg loss: 1.386294520497322\n",
      "trial: 1, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862945264577866\n",
      "trial: 1, iter: 15400, curr loss: 1.3861762285232544, avg loss: 1.386294686794281\n",
      "trial: 1, iter: 15600, curr loss: 1.3858469724655151, avg loss: 1.386272035241127\n",
      "trial: 1, ldr: -0.0020153773948550224\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3858113288879395, avg loss: 1.3869475436210632\n",
      "trial: 2, iter: 400, curr loss: 1.3842954635620117, avg loss: 1.3866050958633422\n",
      "trial: 2, iter: 600, curr loss: 1.3874620199203491, avg loss: 1.3865123718976975\n",
      "trial: 2, iter: 800, curr loss: 1.3873015642166138, avg loss: 1.3865565884113311\n",
      "trial: 2, iter: 1000, curr loss: 1.3855936527252197, avg loss: 1.3863349592685699\n",
      "trial: 2, iter: 1200, curr loss: 1.386235237121582, avg loss: 1.3864604806900025\n",
      "trial: 2, iter: 1400, curr loss: 1.3864490985870361, avg loss: 1.3863473111391067\n",
      "trial: 2, iter: 1600, curr loss: 1.3868638277053833, avg loss: 1.3863932770490646\n",
      "trial: 2, iter: 1800, curr loss: 1.3861374855041504, avg loss: 1.3863300329446793\n",
      "trial: 2, iter: 2000, curr loss: 1.386323094367981, avg loss: 1.3863297808170318\n",
      "trial: 2, iter: 2200, curr loss: 1.3864017724990845, avg loss: 1.3863574695587157\n",
      "trial: 2, iter: 2400, curr loss: 1.3857837915420532, avg loss: 1.386241279244423\n",
      "trial: 2, iter: 2600, curr loss: 1.386197805404663, avg loss: 1.386466194987297\n",
      "trial: 2, iter: 2800, curr loss: 1.3861650228500366, avg loss: 1.3863792723417283\n",
      "trial: 2, iter: 3000, curr loss: 1.3863654136657715, avg loss: 1.386406151652336\n",
      "trial: 2, iter: 3200, curr loss: 1.3861110210418701, avg loss: 1.3863667404651643\n",
      "trial: 2, iter: 3400, curr loss: 1.3856325149536133, avg loss: 1.3863007855415344\n",
      "trial: 2, iter: 3600, curr loss: 1.38715660572052, avg loss: 1.3863794213533402\n",
      "trial: 2, iter: 3800, curr loss: 1.3870398998260498, avg loss: 1.3863770443201064\n",
      "trial: 2, iter: 4000, curr loss: 1.3863712549209595, avg loss: 1.3863698023557662\n",
      "trial: 2, iter: 4200, curr loss: 1.3855938911437988, avg loss: 1.3863078320026399\n",
      "trial: 2, iter: 4400, curr loss: 1.3861347436904907, avg loss: 1.3863296431303025\n",
      "trial: 2, iter: 4600, curr loss: 1.386234164237976, avg loss: 1.3863296753168106\n",
      "trial: 2, iter: 4800, curr loss: 1.3861244916915894, avg loss: 1.3863209104537964\n",
      "trial: 2, iter: 5000, curr loss: 1.3864902257919312, avg loss: 1.38631396651268\n",
      "trial: 2, iter: 5200, curr loss: 1.3864485025405884, avg loss: 1.386306933760643\n",
      "trial: 2, iter: 5400, curr loss: 1.3859901428222656, avg loss: 1.3863241279125214\n",
      "trial: 2, iter: 5600, curr loss: 1.3862619400024414, avg loss: 1.3863398414850234\n",
      "trial: 2, iter: 5800, curr loss: 1.3872950077056885, avg loss: 1.3863099813461304\n",
      "trial: 2, iter: 6000, curr loss: 1.386205792427063, avg loss: 1.3863093215227127\n",
      "trial: 2, iter: 6200, curr loss: 1.38674795627594, avg loss: 1.3863236033916473\n",
      "trial: 2, iter: 6400, curr loss: 1.3859528303146362, avg loss: 1.3863033360242845\n",
      "trial: 2, iter: 6600, curr loss: 1.386012077331543, avg loss: 1.3863244253396987\n",
      "trial: 2, iter: 6800, curr loss: 1.3863905668258667, avg loss: 1.3862939316034317\n",
      "trial: 2, iter: 7000, curr loss: 1.386297345161438, avg loss: 1.3863308393955232\n",
      "trial: 2, iter: 7200, curr loss: 1.3863050937652588, avg loss: 1.3863074308633805\n",
      "trial: 2, iter: 7400, curr loss: 1.386098861694336, avg loss: 1.3862893766164779\n",
      "trial: 2, iter: 7600, curr loss: 1.3863065242767334, avg loss: 1.3863093942403792\n",
      "trial: 2, iter: 7800, curr loss: 1.3859999179840088, avg loss: 1.3862855452299119\n",
      "trial: 2, iter: 8000, curr loss: 1.3860702514648438, avg loss: 1.3863441842794417\n",
      "trial: 2, iter: 8200, curr loss: 1.3871173858642578, avg loss: 1.3864293056726456\n",
      "trial: 2, iter: 8400, curr loss: 1.3866047859191895, avg loss: 1.3863593488931656\n",
      "trial: 2, iter: 8600, curr loss: 1.3855382204055786, avg loss: 1.3863176590204238\n",
      "trial: 2, iter: 8800, curr loss: 1.3862215280532837, avg loss: 1.38633935213089\n",
      "trial: 2, iter: 9000, curr loss: 1.3860970735549927, avg loss: 1.3863115859031678\n",
      "trial: 2, iter: 9200, curr loss: 1.38650381565094, avg loss: 1.386306940317154\n",
      "trial: 2, iter: 9400, curr loss: 1.3863980770111084, avg loss: 1.3862597966194152\n",
      "trial: 2, iter: 9600, curr loss: 1.3863029479980469, avg loss: 1.3863481134176254\n",
      "trial: 2, iter: 9800, curr loss: 1.3851432800292969, avg loss: 1.386277877688408\n",
      "trial: 2, iter: 10000, curr loss: 1.3857320547103882, avg loss: 1.3862930542230607\n",
      "trial: 2, iter: 10200, curr loss: 1.3862879276275635, avg loss: 1.3863726252317428\n",
      "trial: 2, iter: 10400, curr loss: 1.3859981298446655, avg loss: 1.386330013871193\n",
      "trial: 2, iter: 10600, curr loss: 1.3862890005111694, avg loss: 1.3863128352165222\n",
      "trial: 2, iter: 10800, curr loss: 1.3865073919296265, avg loss: 1.386300637125969\n",
      "trial: 2, iter: 11000, curr loss: 1.3861263990402222, avg loss: 1.3863231164216996\n",
      "trial: 2, iter: 11200, curr loss: 1.3862268924713135, avg loss: 1.3863198637962342\n",
      "trial: 2, iter: 11400, curr loss: 1.38666570186615, avg loss: 1.3862875550985336\n",
      "trial: 2, iter: 11600, curr loss: 1.386298418045044, avg loss: 1.3863151329755783\n",
      "trial: 2, iter: 11800, curr loss: 1.3862236738204956, avg loss: 1.3863054895401001\n",
      "trial: 2, iter: 12000, curr loss: 1.3864120244979858, avg loss: 1.3862929075956345\n",
      "trial: 2, iter: 12200, curr loss: 1.3863136768341064, avg loss: 1.386308377981186\n",
      "trial: 2, iter: 12400, curr loss: 1.386353850364685, avg loss: 1.3862939792871476\n",
      "trial: 2, iter: 12600, curr loss: 1.3861162662506104, avg loss: 1.3862928068637848\n",
      "trial: 2, iter: 12800, curr loss: 1.386135220527649, avg loss: 1.386286581158638\n",
      "trial: 2, iter: 13000, curr loss: 1.3861626386642456, avg loss: 1.3863020235300063\n",
      "trial: 2, iter: 13200, curr loss: 1.386276125907898, avg loss: 1.3862986850738526\n",
      "trial: 2, iter: 13400, curr loss: 1.3864343166351318, avg loss: 1.386295884847641\n",
      "trial: 2, iter: 13600, curr loss: 1.3861947059631348, avg loss: 1.386301395893097\n",
      "trial: 2, iter: 13800, curr loss: 1.3862968683242798, avg loss: 1.3863004034757613\n",
      "trial: 2, iter: 14000, curr loss: 1.3862943649291992, avg loss: 1.3862970197200775\n",
      "trial: 2, iter: 14200, curr loss: 1.3863539695739746, avg loss: 1.3862950998544692\n",
      "trial: 2, iter: 14400, curr loss: 1.3862943649291992, avg loss: 1.3862957954406738\n",
      "trial: 2, iter: 14600, curr loss: 1.3862944841384888, avg loss: 1.386294419169426\n",
      "trial: 2, iter: 14800, curr loss: 1.3862954378128052, avg loss: 1.3862951481342316\n",
      "trial: 2, iter: 15000, curr loss: 1.3862942457199097, avg loss: 1.3862944465875626\n",
      "trial: 2, iter: 15200, curr loss: 1.3862941265106201, avg loss: 1.3862950134277343\n",
      "trial: 2, iter: 15400, curr loss: 1.3862948417663574, avg loss: 1.3862946224212647\n",
      "trial: 2, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862945967912674\n",
      "trial: 2, ldr: -3.4663333536855134e-08\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3887988328933716, avg loss: 1.387293549180031\n",
      "trial: 3, iter: 400, curr loss: 1.3868188858032227, avg loss: 1.3866192233562469\n",
      "trial: 3, iter: 600, curr loss: 1.3867812156677246, avg loss: 1.3865272152423858\n",
      "trial: 3, iter: 800, curr loss: 1.3882298469543457, avg loss: 1.3865078395605088\n",
      "trial: 3, iter: 1000, curr loss: 1.3871121406555176, avg loss: 1.3865874320268632\n",
      "trial: 3, iter: 1200, curr loss: 1.3872096538543701, avg loss: 1.3864439690113068\n",
      "trial: 3, iter: 1400, curr loss: 1.3851054906845093, avg loss: 1.3863166856765747\n",
      "trial: 3, iter: 1600, curr loss: 1.3852442502975464, avg loss: 1.3863415813446045\n",
      "trial: 3, iter: 1800, curr loss: 1.3859548568725586, avg loss: 1.3864807438850404\n",
      "trial: 3, iter: 2000, curr loss: 1.386610507965088, avg loss: 1.3863363164663314\n",
      "trial: 3, iter: 2200, curr loss: 1.3867417573928833, avg loss: 1.3863437086343766\n",
      "trial: 3, iter: 2400, curr loss: 1.3861045837402344, avg loss: 1.386354101896286\n",
      "trial: 3, iter: 2600, curr loss: 1.3862968683242798, avg loss: 1.3863323467969895\n",
      "trial: 3, iter: 2800, curr loss: 1.3866716623306274, avg loss: 1.386347748041153\n",
      "trial: 3, iter: 3000, curr loss: 1.3865381479263306, avg loss: 1.386361113190651\n",
      "trial: 3, iter: 3200, curr loss: 1.3856157064437866, avg loss: 1.3863524961471558\n",
      "trial: 3, iter: 3400, curr loss: 1.386975646018982, avg loss: 1.386286507844925\n",
      "trial: 3, iter: 3600, curr loss: 1.3862680196762085, avg loss: 1.3863832306861879\n",
      "trial: 3, iter: 3800, curr loss: 1.386339545249939, avg loss: 1.386355881690979\n",
      "trial: 3, iter: 4000, curr loss: 1.386112928390503, avg loss: 1.3862843799591065\n",
      "trial: 3, iter: 4200, curr loss: 1.386515736579895, avg loss: 1.3863294637203216\n",
      "trial: 3, iter: 4400, curr loss: 1.3858816623687744, avg loss: 1.3863700598478317\n",
      "trial: 3, iter: 4600, curr loss: 1.3859413862228394, avg loss: 1.3862958872318267\n",
      "trial: 3, iter: 4800, curr loss: 1.3863767385482788, avg loss: 1.3863603168725966\n",
      "trial: 3, iter: 5000, curr loss: 1.385986328125, avg loss: 1.3863173615932465\n",
      "trial: 3, iter: 5200, curr loss: 1.3870635032653809, avg loss: 1.3863682496547698\n",
      "trial: 3, iter: 5400, curr loss: 1.3866515159606934, avg loss: 1.3863559454679488\n",
      "trial: 3, iter: 5600, curr loss: 1.3858227729797363, avg loss: 1.3862609124183656\n",
      "trial: 3, iter: 5800, curr loss: 1.3867881298065186, avg loss: 1.3863614904880524\n",
      "trial: 3, iter: 6000, curr loss: 1.38595712184906, avg loss: 1.3863318210840225\n",
      "trial: 3, iter: 6200, curr loss: 1.3864283561706543, avg loss: 1.3863162994384766\n",
      "trial: 3, iter: 6400, curr loss: 1.3860746622085571, avg loss: 1.3863512617349625\n",
      "trial: 3, iter: 6600, curr loss: 1.387004017829895, avg loss: 1.3863189649581908\n",
      "trial: 3, iter: 6800, curr loss: 1.386480689048767, avg loss: 1.386326726078987\n",
      "trial: 3, iter: 7000, curr loss: 1.3868720531463623, avg loss: 1.3862485349178315\n",
      "trial: 3, iter: 7200, curr loss: 1.3866002559661865, avg loss: 1.3863587939739228\n",
      "trial: 3, iter: 7400, curr loss: 1.3869225978851318, avg loss: 1.3862958651781083\n",
      "trial: 3, iter: 7600, curr loss: 1.386562705039978, avg loss: 1.3862867909669876\n",
      "trial: 3, iter: 7800, curr loss: 1.386967658996582, avg loss: 1.3863362234830856\n",
      "trial: 3, iter: 8000, curr loss: 1.3862289190292358, avg loss: 1.386320121884346\n",
      "trial: 3, iter: 8200, curr loss: 1.3864208459854126, avg loss: 1.3862926775217057\n",
      "trial: 3, iter: 8400, curr loss: 1.3862379789352417, avg loss: 1.3862573379278182\n",
      "trial: 3, iter: 8600, curr loss: 1.38558828830719, avg loss: 1.3863651639223098\n",
      "trial: 3, iter: 8800, curr loss: 1.3866938352584839, avg loss: 1.3863016521930696\n",
      "trial: 3, iter: 9000, curr loss: 1.3861783742904663, avg loss: 1.3863589441776276\n",
      "trial: 3, iter: 9200, curr loss: 1.3875313997268677, avg loss: 1.386368117928505\n",
      "trial: 3, iter: 9400, curr loss: 1.3853983879089355, avg loss: 1.3865001386404037\n",
      "trial: 3, iter: 9600, curr loss: 1.385549545288086, avg loss: 1.3864489257335664\n",
      "trial: 3, iter: 9800, curr loss: 1.386260747909546, avg loss: 1.3863146781921387\n",
      "trial: 3, iter: 10000, curr loss: 1.386663794517517, avg loss: 1.38631354033947\n",
      "trial: 3, iter: 10200, curr loss: 1.3854533433914185, avg loss: 1.386290016770363\n",
      "trial: 3, iter: 10400, curr loss: 1.3858540058135986, avg loss: 1.3862811172008513\n",
      "trial: 3, iter: 10600, curr loss: 1.3866206407546997, avg loss: 1.3863364106416702\n",
      "trial: 3, iter: 10800, curr loss: 1.38630211353302, avg loss: 1.3862981659173965\n",
      "trial: 3, iter: 11000, curr loss: 1.3864725828170776, avg loss: 1.3862942695617675\n",
      "trial: 3, iter: 11200, curr loss: 1.386254072189331, avg loss: 1.3862872272729874\n",
      "trial: 3, iter: 11400, curr loss: 1.3862521648406982, avg loss: 1.386311667561531\n",
      "trial: 3, iter: 11600, curr loss: 1.3862720727920532, avg loss: 1.3862789851427078\n",
      "trial: 3, iter: 11800, curr loss: 1.3863091468811035, avg loss: 1.3863108760118485\n",
      "trial: 3, iter: 12000, curr loss: 1.3863506317138672, avg loss: 1.3863092374801635\n",
      "trial: 3, iter: 12200, curr loss: 1.3866853713989258, avg loss: 1.3862939900159836\n",
      "trial: 3, iter: 12400, curr loss: 1.386301875114441, avg loss: 1.3862955051660537\n",
      "trial: 3, iter: 12600, curr loss: 1.3863877058029175, avg loss: 1.386299992799759\n",
      "trial: 3, iter: 12800, curr loss: 1.3863188028335571, avg loss: 1.3862959194183349\n",
      "trial: 3, iter: 13000, curr loss: 1.3863160610198975, avg loss: 1.3862993949651718\n",
      "trial: 3, iter: 13200, curr loss: 1.386246919631958, avg loss: 1.3862982606887817\n",
      "trial: 3, iter: 13400, curr loss: 1.3861751556396484, avg loss: 1.386301097869873\n",
      "trial: 3, iter: 13600, curr loss: 1.3863716125488281, avg loss: 1.3863005065917968\n",
      "trial: 3, iter: 13800, curr loss: 1.386258840560913, avg loss: 1.3863004112243653\n",
      "trial: 3, iter: 14000, curr loss: 1.3863768577575684, avg loss: 1.3862935781478882\n",
      "trial: 3, iter: 14200, curr loss: 1.3863084316253662, avg loss: 1.3862988525629043\n",
      "trial: 3, iter: 14400, curr loss: 1.3863013982772827, avg loss: 1.386295763850212\n",
      "trial: 3, iter: 14600, curr loss: 1.386380672454834, avg loss: 1.3862948167324065\n",
      "trial: 3, iter: 14800, curr loss: 1.3862966299057007, avg loss: 1.3862991791963577\n",
      "trial: 3, iter: 15000, curr loss: 1.3863263130187988, avg loss: 1.3862952214479447\n",
      "trial: 3, iter: 15200, curr loss: 1.3862652778625488, avg loss: 1.3862929713726044\n",
      "trial: 3, iter: 15400, curr loss: 1.3863756656646729, avg loss: 1.386293122768402\n",
      "trial: 3, iter: 15600, curr loss: 1.3861920833587646, avg loss: 1.3862996047735214\n",
      "trial: 3, ldr: -0.000857580394949764\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3852657079696655, avg loss: 1.3873212838172913\n",
      "trial: 4, iter: 400, curr loss: 1.387298822402954, avg loss: 1.386735758781433\n",
      "trial: 4, iter: 600, curr loss: 1.3861068487167358, avg loss: 1.3866072326898575\n",
      "trial: 4, iter: 800, curr loss: 1.3874404430389404, avg loss: 1.3864850503206254\n",
      "trial: 4, iter: 1000, curr loss: 1.3861223459243774, avg loss: 1.3865331673622132\n",
      "trial: 4, iter: 1200, curr loss: 1.3865766525268555, avg loss: 1.3865219324827194\n",
      "trial: 4, iter: 1400, curr loss: 1.3856678009033203, avg loss: 1.3863857048749924\n",
      "trial: 4, iter: 1600, curr loss: 1.3861935138702393, avg loss: 1.3864307737350463\n",
      "trial: 4, iter: 1800, curr loss: 1.3859368562698364, avg loss: 1.3863841676712036\n",
      "trial: 4, iter: 2000, curr loss: 1.3872860670089722, avg loss: 1.3863395297527312\n",
      "trial: 4, iter: 2200, curr loss: 1.3852897882461548, avg loss: 1.3863320684432983\n",
      "trial: 4, iter: 2400, curr loss: 1.3864668607711792, avg loss: 1.3863395285606384\n",
      "trial: 4, iter: 2600, curr loss: 1.3858779668807983, avg loss: 1.3864874720573426\n",
      "trial: 4, iter: 2800, curr loss: 1.3874362707138062, avg loss: 1.386396608352661\n",
      "trial: 4, iter: 3000, curr loss: 1.3861078023910522, avg loss: 1.386387785077095\n",
      "trial: 4, iter: 3200, curr loss: 1.3858963251113892, avg loss: 1.386398903131485\n",
      "trial: 4, iter: 3400, curr loss: 1.3872897624969482, avg loss: 1.3864082235097885\n",
      "trial: 4, iter: 3600, curr loss: 1.3871099948883057, avg loss: 1.3863532078266143\n",
      "trial: 4, iter: 3800, curr loss: 1.3862167596817017, avg loss: 1.386420869231224\n",
      "trial: 4, iter: 4000, curr loss: 1.3860467672348022, avg loss: 1.3863430267572403\n",
      "trial: 4, iter: 4200, curr loss: 1.3860715627670288, avg loss: 1.386352819800377\n",
      "trial: 4, iter: 4400, curr loss: 1.3866075277328491, avg loss: 1.386370816230774\n",
      "trial: 4, iter: 4600, curr loss: 1.3864232301712036, avg loss: 1.3863229632377625\n",
      "trial: 4, iter: 4800, curr loss: 1.3860554695129395, avg loss: 1.3862902802228927\n",
      "trial: 4, iter: 5000, curr loss: 1.3867188692092896, avg loss: 1.3862627810239792\n",
      "trial: 4, iter: 5200, curr loss: 1.3874685764312744, avg loss: 1.386383838057518\n",
      "trial: 4, iter: 5400, curr loss: 1.3855584859848022, avg loss: 1.3864012783765793\n",
      "trial: 4, iter: 5600, curr loss: 1.3866480588912964, avg loss: 1.3863453787565232\n",
      "trial: 4, iter: 5800, curr loss: 1.3860132694244385, avg loss: 1.386362910270691\n",
      "trial: 4, iter: 6000, curr loss: 1.386375904083252, avg loss: 1.3863224589824676\n",
      "trial: 4, iter: 6200, curr loss: 1.3860760927200317, avg loss: 1.3862915402650833\n",
      "trial: 4, iter: 6400, curr loss: 1.3864827156066895, avg loss: 1.3863313180208205\n",
      "trial: 4, iter: 6600, curr loss: 1.386364459991455, avg loss: 1.386302592754364\n",
      "trial: 4, iter: 6800, curr loss: 1.3860920667648315, avg loss: 1.38628193795681\n",
      "trial: 4, iter: 7000, curr loss: 1.386006236076355, avg loss: 1.3863138604164122\n",
      "trial: 4, iter: 7200, curr loss: 1.3862308263778687, avg loss: 1.3863324129581451\n",
      "trial: 4, iter: 7400, curr loss: 1.3862367868423462, avg loss: 1.386315467953682\n",
      "trial: 4, iter: 7600, curr loss: 1.3856474161148071, avg loss: 1.3863114190101624\n",
      "trial: 4, iter: 7800, curr loss: 1.3862638473510742, avg loss: 1.3863356280326844\n",
      "trial: 4, iter: 8000, curr loss: 1.386114239692688, avg loss: 1.3862977945804595\n",
      "trial: 4, iter: 8200, curr loss: 1.3865095376968384, avg loss: 1.3862914472818375\n",
      "trial: 4, iter: 8400, curr loss: 1.386408805847168, avg loss: 1.3863177394866943\n",
      "trial: 4, iter: 8600, curr loss: 1.38650643825531, avg loss: 1.3863075923919679\n",
      "trial: 4, iter: 8800, curr loss: 1.3863718509674072, avg loss: 1.3863016432523727\n",
      "trial: 4, iter: 9000, curr loss: 1.38623046875, avg loss: 1.3862935441732407\n",
      "trial: 4, iter: 9200, curr loss: 1.3861501216888428, avg loss: 1.3863078653812408\n",
      "trial: 4, iter: 9400, curr loss: 1.3859224319458008, avg loss: 1.3863070607185364\n",
      "trial: 4, iter: 9600, curr loss: 1.3860701322555542, avg loss: 1.386312761902809\n",
      "trial: 4, iter: 9800, curr loss: 1.3864489793777466, avg loss: 1.3863000762462616\n",
      "trial: 4, iter: 10000, curr loss: 1.3863896131515503, avg loss: 1.3863024616241455\n",
      "trial: 4, iter: 10200, curr loss: 1.3863554000854492, avg loss: 1.3863006514310836\n",
      "trial: 4, iter: 10400, curr loss: 1.3865985870361328, avg loss: 1.386305650472641\n",
      "trial: 4, iter: 10600, curr loss: 1.3860573768615723, avg loss: 1.3863024693727493\n",
      "trial: 4, iter: 10800, curr loss: 1.3862603902816772, avg loss: 1.3862946492433548\n",
      "trial: 4, iter: 11000, curr loss: 1.3866655826568604, avg loss: 1.386263700723648\n",
      "trial: 4, iter: 11200, curr loss: 1.3854743242263794, avg loss: 1.3863213402032852\n",
      "trial: 4, iter: 11400, curr loss: 1.3861873149871826, avg loss: 1.386371813416481\n",
      "trial: 4, iter: 11600, curr loss: 1.3877371549606323, avg loss: 1.3863523876667023\n",
      "trial: 4, iter: 11800, curr loss: 1.3863121271133423, avg loss: 1.3863276165723801\n",
      "trial: 4, iter: 12000, curr loss: 1.3866974115371704, avg loss: 1.386302845478058\n",
      "trial: 4, iter: 12200, curr loss: 1.3861949443817139, avg loss: 1.386312808394432\n",
      "trial: 4, iter: 12400, curr loss: 1.3866955041885376, avg loss: 1.3863048976659775\n",
      "trial: 4, iter: 12600, curr loss: 1.3865857124328613, avg loss: 1.3863227814435959\n",
      "trial: 4, iter: 12800, curr loss: 1.3862221240997314, avg loss: 1.386312113404274\n",
      "trial: 4, iter: 13000, curr loss: 1.3861578702926636, avg loss: 1.386295285820961\n",
      "trial: 4, iter: 13200, curr loss: 1.3862090110778809, avg loss: 1.3863089817762375\n",
      "trial: 4, iter: 13400, curr loss: 1.3862574100494385, avg loss: 1.3863041967153549\n",
      "trial: 4, iter: 13600, curr loss: 1.3860756158828735, avg loss: 1.3862961786985397\n",
      "trial: 4, iter: 13800, curr loss: 1.3862708806991577, avg loss: 1.3863014644384384\n",
      "trial: 4, iter: 14000, curr loss: 1.3867915868759155, avg loss: 1.3862586438655853\n",
      "trial: 4, iter: 14200, curr loss: 1.3860654830932617, avg loss: 1.386311188340187\n",
      "trial: 4, iter: 14400, curr loss: 1.386275053024292, avg loss: 1.3863220965862275\n",
      "trial: 4, iter: 14600, curr loss: 1.386396050453186, avg loss: 1.3862998777627944\n",
      "trial: 4, iter: 14800, curr loss: 1.3861552476882935, avg loss: 1.3862874227762223\n",
      "trial: 4, iter: 15000, curr loss: 1.3864034414291382, avg loss: 1.386295735836029\n",
      "trial: 4, iter: 15200, curr loss: 1.3862268924713135, avg loss: 1.3863099807500838\n",
      "trial: 4, iter: 15400, curr loss: 1.3862206935882568, avg loss: 1.3862945783138274\n",
      "trial: 4, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3862698465585708\n",
      "trial: 4, ldr: -0.0016514257295057178\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387241244316101, avg loss: 1.387678097486496\n",
      "trial: 5, iter: 400, curr loss: 1.387203335762024, avg loss: 1.3867378008365632\n",
      "trial: 5, iter: 600, curr loss: 1.386150598526001, avg loss: 1.3866730403900147\n",
      "trial: 5, iter: 800, curr loss: 1.3868434429168701, avg loss: 1.3865326523780823\n",
      "trial: 5, iter: 1000, curr loss: 1.386153221130371, avg loss: 1.3864348912239075\n",
      "trial: 5, iter: 1200, curr loss: 1.3886823654174805, avg loss: 1.3865293121337892\n",
      "trial: 5, iter: 1400, curr loss: 1.3870508670806885, avg loss: 1.3863487750291825\n",
      "trial: 5, iter: 1600, curr loss: 1.387024164199829, avg loss: 1.3864011716842652\n",
      "trial: 5, iter: 1800, curr loss: 1.3865234851837158, avg loss: 1.386440051794052\n",
      "trial: 5, iter: 2000, curr loss: 1.388923168182373, avg loss: 1.3864662855863572\n",
      "trial: 5, iter: 2200, curr loss: 1.3862419128417969, avg loss: 1.3864371758699416\n",
      "trial: 5, iter: 2400, curr loss: 1.387072205543518, avg loss: 1.3863694423437118\n",
      "trial: 5, iter: 2600, curr loss: 1.3852348327636719, avg loss: 1.386339944601059\n",
      "trial: 5, iter: 2800, curr loss: 1.3861818313598633, avg loss: 1.3863807255029679\n",
      "trial: 5, iter: 3000, curr loss: 1.385888695716858, avg loss: 1.3863791644573211\n",
      "trial: 5, iter: 3200, curr loss: 1.3863805532455444, avg loss: 1.3863684773445129\n",
      "trial: 5, iter: 3400, curr loss: 1.387282371520996, avg loss: 1.3863403874635696\n",
      "trial: 5, iter: 3600, curr loss: 1.385945439338684, avg loss: 1.386349040865898\n",
      "trial: 5, iter: 3800, curr loss: 1.3865587711334229, avg loss: 1.3863002955913544\n",
      "trial: 5, iter: 4000, curr loss: 1.3863455057144165, avg loss: 1.386299524307251\n",
      "trial: 5, iter: 4200, curr loss: 1.386410117149353, avg loss: 1.3863464361429214\n",
      "trial: 5, iter: 4400, curr loss: 1.385920524597168, avg loss: 1.3863021886348725\n",
      "trial: 5, iter: 4600, curr loss: 1.385956883430481, avg loss: 1.386348552107811\n",
      "trial: 5, iter: 4800, curr loss: 1.386695384979248, avg loss: 1.386347827911377\n",
      "trial: 5, iter: 5000, curr loss: 1.3859901428222656, avg loss: 1.3863373446464538\n",
      "trial: 5, iter: 5200, curr loss: 1.3869669437408447, avg loss: 1.3863187283277512\n",
      "trial: 5, iter: 5400, curr loss: 1.3862496614456177, avg loss: 1.3863138979673386\n",
      "trial: 5, iter: 5600, curr loss: 1.3859667778015137, avg loss: 1.3862923669815064\n",
      "trial: 5, iter: 5800, curr loss: 1.3863441944122314, avg loss: 1.3863167971372605\n",
      "trial: 5, iter: 6000, curr loss: 1.3861382007598877, avg loss: 1.3863298738002776\n",
      "trial: 5, iter: 6200, curr loss: 1.38597571849823, avg loss: 1.3862688273191452\n",
      "trial: 5, iter: 6400, curr loss: 1.386080026626587, avg loss: 1.3863032752275466\n",
      "trial: 5, iter: 6600, curr loss: 1.3862369060516357, avg loss: 1.386309139728546\n",
      "trial: 5, iter: 6800, curr loss: 1.3865091800689697, avg loss: 1.386303918361664\n",
      "trial: 5, iter: 7000, curr loss: 1.3864667415618896, avg loss: 1.386270633339882\n",
      "trial: 5, iter: 7200, curr loss: 1.386206865310669, avg loss: 1.3863271170854568\n",
      "trial: 5, iter: 7400, curr loss: 1.3863346576690674, avg loss: 1.3863194102048875\n",
      "trial: 5, iter: 7600, curr loss: 1.387020230293274, avg loss: 1.386315522789955\n",
      "trial: 5, iter: 7800, curr loss: 1.3859816789627075, avg loss: 1.38632657289505\n",
      "trial: 5, iter: 8000, curr loss: 1.386154055595398, avg loss: 1.3863534045219421\n",
      "trial: 5, iter: 8200, curr loss: 1.3863691091537476, avg loss: 1.3863454580307006\n",
      "trial: 5, iter: 8400, curr loss: 1.3860646486282349, avg loss: 1.3862974613904953\n",
      "trial: 5, iter: 8600, curr loss: 1.3865793943405151, avg loss: 1.3863018423318862\n",
      "trial: 5, iter: 8800, curr loss: 1.3866503238677979, avg loss: 1.3863040947914123\n",
      "trial: 5, iter: 9000, curr loss: 1.3862735033035278, avg loss: 1.3863059318065643\n",
      "trial: 5, iter: 9200, curr loss: 1.3864357471466064, avg loss: 1.3862968009710313\n",
      "trial: 5, iter: 9400, curr loss: 1.386035442352295, avg loss: 1.3862987494468688\n",
      "trial: 5, iter: 9600, curr loss: 1.3872982263565063, avg loss: 1.3862673985958098\n",
      "trial: 5, iter: 9800, curr loss: 1.3864930868148804, avg loss: 1.3863667356967926\n",
      "trial: 5, iter: 10000, curr loss: 1.3866524696350098, avg loss: 1.3863022488355636\n",
      "trial: 5, iter: 10200, curr loss: 1.3865422010421753, avg loss: 1.3863319426774978\n",
      "trial: 5, iter: 10400, curr loss: 1.3873926401138306, avg loss: 1.3863762652873992\n",
      "trial: 5, iter: 10600, curr loss: 1.3858931064605713, avg loss: 1.3862988781929015\n",
      "trial: 5, iter: 10800, curr loss: 1.3862555027008057, avg loss: 1.3863428395986557\n",
      "trial: 5, iter: 11000, curr loss: 1.3860688209533691, avg loss: 1.3863022780418397\n",
      "trial: 5, iter: 11200, curr loss: 1.3860135078430176, avg loss: 1.3862990379333495\n",
      "trial: 5, iter: 11400, curr loss: 1.38702392578125, avg loss: 1.3863031953573226\n",
      "trial: 5, iter: 11600, curr loss: 1.3865513801574707, avg loss: 1.3864058047533034\n",
      "trial: 5, iter: 11800, curr loss: 1.3859251737594604, avg loss: 1.3863307690620423\n",
      "trial: 5, iter: 12000, curr loss: 1.386268973350525, avg loss: 1.3863303142786025\n",
      "trial: 5, iter: 12200, curr loss: 1.3861933946609497, avg loss: 1.3863101768493653\n",
      "trial: 5, iter: 12400, curr loss: 1.3846158981323242, avg loss: 1.3862397891283036\n",
      "trial: 5, iter: 12600, curr loss: 1.3867863416671753, avg loss: 1.3863702434301377\n",
      "trial: 5, iter: 12800, curr loss: 1.3861041069030762, avg loss: 1.38631858587265\n",
      "trial: 5, iter: 13000, curr loss: 1.3865082263946533, avg loss: 1.3862952268123627\n",
      "trial: 5, iter: 13200, curr loss: 1.3863608837127686, avg loss: 1.3863026666641236\n",
      "trial: 5, iter: 13400, curr loss: 1.386216402053833, avg loss: 1.3863204342126847\n",
      "trial: 5, iter: 13600, curr loss: 1.3865737915039062, avg loss: 1.3862944358587266\n",
      "trial: 5, iter: 13800, curr loss: 1.3861829042434692, avg loss: 1.386299250125885\n",
      "trial: 5, iter: 14000, curr loss: 1.3861112594604492, avg loss: 1.3862935882806777\n",
      "trial: 5, iter: 14200, curr loss: 1.3864266872406006, avg loss: 1.3862957108020781\n",
      "trial: 5, iter: 14400, curr loss: 1.386543869972229, avg loss: 1.3862848699092865\n",
      "trial: 5, iter: 14600, curr loss: 1.3866612911224365, avg loss: 1.3862700712680818\n",
      "trial: 5, iter: 14800, curr loss: 1.386143445968628, avg loss: 1.3862931764125823\n",
      "trial: 5, iter: 15000, curr loss: 1.3864283561706543, avg loss: 1.3863071870803834\n",
      "trial: 5, iter: 15200, curr loss: 1.386444330215454, avg loss: 1.386301217675209\n",
      "trial: 5, iter: 15400, curr loss: 1.3864564895629883, avg loss: 1.3863205760717392\n",
      "trial: 5, iter: 15600, curr loss: 1.3864014148712158, avg loss: 1.3862981992959975\n",
      "trial: 5, ldr: -0.0011561812134459615\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0011361198792180006\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3891541957855225, avg loss: 1.38736299097538\n",
      "trial: 1, iter: 400, curr loss: 1.3863638639450073, avg loss: 1.3866983616352082\n",
      "trial: 1, iter: 600, curr loss: 1.3863141536712646, avg loss: 1.3864513140916825\n",
      "trial: 1, iter: 800, curr loss: 1.3855856657028198, avg loss: 1.3865383690595627\n",
      "trial: 1, iter: 1000, curr loss: 1.3873947858810425, avg loss: 1.3865728604793548\n",
      "trial: 1, iter: 1200, curr loss: 1.3857759237289429, avg loss: 1.386420323252678\n",
      "trial: 1, iter: 1400, curr loss: 1.3854115009307861, avg loss: 1.3863793098926545\n",
      "trial: 1, iter: 1600, curr loss: 1.3869752883911133, avg loss: 1.3864973294734955\n",
      "trial: 1, iter: 1800, curr loss: 1.385543942451477, avg loss: 1.3862924832105636\n",
      "trial: 1, iter: 2000, curr loss: 1.3856126070022583, avg loss: 1.386460633277893\n",
      "trial: 1, iter: 2200, curr loss: 1.3880681991577148, avg loss: 1.3864376282691955\n",
      "trial: 1, iter: 2400, curr loss: 1.3859702348709106, avg loss: 1.3863768291473388\n",
      "trial: 1, iter: 2600, curr loss: 1.38548743724823, avg loss: 1.386317411661148\n",
      "trial: 1, iter: 2800, curr loss: 1.3868451118469238, avg loss: 1.3863611245155334\n",
      "trial: 1, iter: 3000, curr loss: 1.387068271636963, avg loss: 1.3863890618085861\n",
      "trial: 1, iter: 3200, curr loss: 1.3864601850509644, avg loss: 1.3863902854919434\n",
      "trial: 1, iter: 3400, curr loss: 1.3867886066436768, avg loss: 1.3863519078493118\n",
      "trial: 1, iter: 3600, curr loss: 1.3863004446029663, avg loss: 1.3863151746988296\n",
      "trial: 1, iter: 3800, curr loss: 1.3857821226119995, avg loss: 1.386350600719452\n",
      "trial: 1, iter: 4000, curr loss: 1.3857128620147705, avg loss: 1.386294487118721\n",
      "trial: 1, iter: 4200, curr loss: 1.3860256671905518, avg loss: 1.386374795436859\n",
      "trial: 1, iter: 4400, curr loss: 1.3867220878601074, avg loss: 1.3862958097457885\n",
      "trial: 1, iter: 4600, curr loss: 1.3856894969940186, avg loss: 1.3863246673345566\n",
      "trial: 1, iter: 4800, curr loss: 1.3866474628448486, avg loss: 1.3863091558218001\n",
      "trial: 1, iter: 5000, curr loss: 1.3868180513381958, avg loss: 1.3863437980413438\n",
      "trial: 1, iter: 5200, curr loss: 1.3861194849014282, avg loss: 1.386313831806183\n",
      "trial: 1, iter: 5400, curr loss: 1.3857964277267456, avg loss: 1.386288868188858\n",
      "trial: 1, iter: 5600, curr loss: 1.3861271142959595, avg loss: 1.3864246165752412\n",
      "trial: 1, iter: 5800, curr loss: 1.387086033821106, avg loss: 1.3864197218418122\n",
      "trial: 1, iter: 6000, curr loss: 1.3857307434082031, avg loss: 1.3863630378246308\n",
      "trial: 1, iter: 6200, curr loss: 1.3862208127975464, avg loss: 1.3863371407985687\n",
      "trial: 1, iter: 6400, curr loss: 1.3869409561157227, avg loss: 1.3863082724809646\n",
      "trial: 1, iter: 6600, curr loss: 1.3858938217163086, avg loss: 1.386319972872734\n",
      "trial: 1, iter: 6800, curr loss: 1.3864450454711914, avg loss: 1.3863300997018815\n",
      "trial: 1, iter: 7000, curr loss: 1.386340856552124, avg loss: 1.3863096791505813\n",
      "trial: 1, iter: 7200, curr loss: 1.386183738708496, avg loss: 1.3863418209552765\n",
      "trial: 1, iter: 7400, curr loss: 1.3861521482467651, avg loss: 1.3862792682647704\n",
      "trial: 1, iter: 7600, curr loss: 1.3855977058410645, avg loss: 1.386296231150627\n",
      "trial: 1, iter: 7800, curr loss: 1.3866493701934814, avg loss: 1.3863753420114517\n",
      "trial: 1, iter: 8000, curr loss: 1.3866782188415527, avg loss: 1.3863042050600052\n",
      "trial: 1, iter: 8200, curr loss: 1.3864967823028564, avg loss: 1.3862897539138794\n",
      "trial: 1, iter: 8400, curr loss: 1.3862384557724, avg loss: 1.3863427489995956\n",
      "trial: 1, iter: 8600, curr loss: 1.3863216638565063, avg loss: 1.386301901936531\n",
      "trial: 1, iter: 8800, curr loss: 1.3861982822418213, avg loss: 1.386232575774193\n",
      "trial: 1, iter: 9000, curr loss: 1.385955572128296, avg loss: 1.3863708674907684\n",
      "trial: 1, iter: 9200, curr loss: 1.386468529701233, avg loss: 1.3863228893280028\n",
      "trial: 1, iter: 9400, curr loss: 1.3863478899002075, avg loss: 1.3863051003217697\n",
      "trial: 1, iter: 9600, curr loss: 1.3858827352523804, avg loss: 1.3862683671712874\n",
      "trial: 1, iter: 9800, curr loss: 1.3863834142684937, avg loss: 1.3863595932722093\n",
      "trial: 1, iter: 10000, curr loss: 1.3864439725875854, avg loss: 1.3863854378461837\n",
      "trial: 1, iter: 10200, curr loss: 1.386436104774475, avg loss: 1.3863421720266342\n",
      "trial: 1, iter: 10400, curr loss: 1.3863153457641602, avg loss: 1.3863818126916885\n",
      "trial: 1, iter: 10600, curr loss: 1.3860567808151245, avg loss: 1.386314747929573\n",
      "trial: 1, iter: 10800, curr loss: 1.3861949443817139, avg loss: 1.38630753159523\n",
      "trial: 1, iter: 11000, curr loss: 1.3861950635910034, avg loss: 1.3863176310062408\n",
      "trial: 1, iter: 11200, curr loss: 1.3863544464111328, avg loss: 1.386322197318077\n",
      "trial: 1, iter: 11400, curr loss: 1.3858582973480225, avg loss: 1.3862933486700058\n",
      "trial: 1, iter: 11600, curr loss: 1.385890245437622, avg loss: 1.3863076412677764\n",
      "trial: 1, iter: 11800, curr loss: 1.386367917060852, avg loss: 1.3863349306583403\n",
      "trial: 1, iter: 12000, curr loss: 1.386347770690918, avg loss: 1.3863069653511046\n",
      "trial: 1, iter: 12200, curr loss: 1.3859429359436035, avg loss: 1.386291241645813\n",
      "trial: 1, iter: 12400, curr loss: 1.386792778968811, avg loss: 1.3862999802827836\n",
      "trial: 1, iter: 12600, curr loss: 1.3864694833755493, avg loss: 1.3863200807571412\n",
      "trial: 1, iter: 12800, curr loss: 1.3863390684127808, avg loss: 1.3863237845897673\n",
      "trial: 1, iter: 13000, curr loss: 1.3861846923828125, avg loss: 1.386313362121582\n",
      "trial: 1, iter: 13200, curr loss: 1.386346697807312, avg loss: 1.3863113790750503\n",
      "trial: 1, iter: 13400, curr loss: 1.3861936330795288, avg loss: 1.3863047260046004\n",
      "trial: 1, iter: 13600, curr loss: 1.3865230083465576, avg loss: 1.3863236171007156\n",
      "trial: 1, iter: 13800, curr loss: 1.386626124382019, avg loss: 1.386296772956848\n",
      "trial: 1, iter: 14000, curr loss: 1.3856552839279175, avg loss: 1.3863012331724167\n",
      "trial: 1, iter: 14200, curr loss: 1.3861960172653198, avg loss: 1.3863666123151779\n",
      "trial: 1, iter: 14400, curr loss: 1.3864156007766724, avg loss: 1.3863264179229737\n",
      "trial: 1, iter: 14600, curr loss: 1.3866245746612549, avg loss: 1.3862596827745437\n",
      "trial: 1, iter: 14800, curr loss: 1.3860334157943726, avg loss: 1.3863149946928024\n",
      "trial: 1, iter: 15000, curr loss: 1.3860468864440918, avg loss: 1.3863472682237625\n",
      "trial: 1, iter: 15200, curr loss: 1.3865140676498413, avg loss: 1.3863372719287872\n",
      "trial: 1, iter: 15400, curr loss: 1.3864028453826904, avg loss: 1.3863394576311112\n",
      "trial: 1, iter: 15600, curr loss: 1.3861931562423706, avg loss: 1.3863242930173874\n",
      "trial: 1, ldr: 0.006435813382267952\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3833184242248535, avg loss: 1.3873844891786575\n",
      "trial: 2, iter: 400, curr loss: 1.3867766857147217, avg loss: 1.3868074506521224\n",
      "trial: 2, iter: 600, curr loss: 1.3857837915420532, avg loss: 1.3865770453214645\n",
      "trial: 2, iter: 800, curr loss: 1.388364553451538, avg loss: 1.3863368248939514\n",
      "trial: 2, iter: 1000, curr loss: 1.389046311378479, avg loss: 1.386492063999176\n",
      "trial: 2, iter: 1200, curr loss: 1.386201024055481, avg loss: 1.3864511096477508\n",
      "trial: 2, iter: 1400, curr loss: 1.3855705261230469, avg loss: 1.3863522797822951\n",
      "trial: 2, iter: 1600, curr loss: 1.3856040239334106, avg loss: 1.3864590734243394\n",
      "trial: 2, iter: 1800, curr loss: 1.3860968351364136, avg loss: 1.3863931536674499\n",
      "trial: 2, iter: 2000, curr loss: 1.3865402936935425, avg loss: 1.3863884645700455\n",
      "trial: 2, iter: 2200, curr loss: 1.3858447074890137, avg loss: 1.3864159947633743\n",
      "trial: 2, iter: 2400, curr loss: 1.3862881660461426, avg loss: 1.3862971234321595\n",
      "trial: 2, iter: 2600, curr loss: 1.3858685493469238, avg loss: 1.3863753688335418\n",
      "trial: 2, iter: 2800, curr loss: 1.3865013122558594, avg loss: 1.3863068282604218\n",
      "trial: 2, iter: 3000, curr loss: 1.3862193822860718, avg loss: 1.386325659751892\n",
      "trial: 2, iter: 3200, curr loss: 1.386807918548584, avg loss: 1.3863956570625304\n",
      "trial: 2, iter: 3400, curr loss: 1.3859492540359497, avg loss: 1.3863464939594268\n",
      "trial: 2, iter: 3600, curr loss: 1.3864326477050781, avg loss: 1.386294532418251\n",
      "trial: 2, iter: 3800, curr loss: 1.386305809020996, avg loss: 1.3863285130262375\n",
      "trial: 2, iter: 4000, curr loss: 1.3856470584869385, avg loss: 1.3863075435161591\n",
      "trial: 2, iter: 4200, curr loss: 1.3860028982162476, avg loss: 1.3864235091209411\n",
      "trial: 2, iter: 4400, curr loss: 1.3862043619155884, avg loss: 1.3863321614265443\n",
      "trial: 2, iter: 4600, curr loss: 1.3872368335723877, avg loss: 1.3863129067420958\n",
      "trial: 2, iter: 4800, curr loss: 1.3866277933120728, avg loss: 1.3863176774978638\n",
      "trial: 2, iter: 5000, curr loss: 1.3861430883407593, avg loss: 1.3862882912158967\n",
      "trial: 2, iter: 5200, curr loss: 1.387033462524414, avg loss: 1.386308686733246\n",
      "trial: 2, iter: 5400, curr loss: 1.386653184890747, avg loss: 1.386330559849739\n",
      "trial: 2, iter: 5600, curr loss: 1.3861017227172852, avg loss: 1.386290761232376\n",
      "trial: 2, iter: 5800, curr loss: 1.3864045143127441, avg loss: 1.3863622200489045\n",
      "trial: 2, iter: 6000, curr loss: 1.386905312538147, avg loss: 1.3862953692674638\n",
      "trial: 2, iter: 6200, curr loss: 1.386391520500183, avg loss: 1.3863517236709595\n",
      "trial: 2, iter: 6400, curr loss: 1.3862721920013428, avg loss: 1.3863281583786011\n",
      "trial: 2, iter: 6600, curr loss: 1.38628089427948, avg loss: 1.386316158771515\n",
      "trial: 2, iter: 6800, curr loss: 1.386321783065796, avg loss: 1.3863176530599595\n",
      "trial: 2, iter: 7000, curr loss: 1.386230230331421, avg loss: 1.3862953883409501\n",
      "trial: 2, iter: 7200, curr loss: 1.3866256475448608, avg loss: 1.3863776659965514\n",
      "trial: 2, iter: 7400, curr loss: 1.3871195316314697, avg loss: 1.3863122951984406\n",
      "trial: 2, iter: 7600, curr loss: 1.386103630065918, avg loss: 1.3863231837749481\n",
      "trial: 2, iter: 7800, curr loss: 1.3866612911224365, avg loss: 1.3863025599718093\n",
      "trial: 2, iter: 8000, curr loss: 1.384874939918518, avg loss: 1.3862567710876466\n",
      "trial: 2, iter: 8200, curr loss: 1.3879077434539795, avg loss: 1.386429584622383\n",
      "trial: 2, iter: 8400, curr loss: 1.386386752128601, avg loss: 1.386360827088356\n",
      "trial: 2, iter: 8600, curr loss: 1.3870749473571777, avg loss: 1.3862613558769226\n",
      "trial: 2, iter: 8800, curr loss: 1.38620924949646, avg loss: 1.3863296991586684\n",
      "trial: 2, iter: 9000, curr loss: 1.3861732482910156, avg loss: 1.3863220417499542\n",
      "trial: 2, iter: 9200, curr loss: 1.385939121246338, avg loss: 1.3863261115550995\n",
      "trial: 2, iter: 9400, curr loss: 1.3865604400634766, avg loss: 1.386317286491394\n",
      "trial: 2, iter: 9600, curr loss: 1.3852568864822388, avg loss: 1.386273490190506\n",
      "trial: 2, iter: 9800, curr loss: 1.386919617652893, avg loss: 1.3863447272777558\n",
      "trial: 2, iter: 10000, curr loss: 1.386020541191101, avg loss: 1.3863231527805329\n",
      "trial: 2, iter: 10200, curr loss: 1.3862802982330322, avg loss: 1.3863151597976684\n",
      "trial: 2, iter: 10400, curr loss: 1.386284589767456, avg loss: 1.3862995558977127\n",
      "trial: 2, iter: 10600, curr loss: 1.3857790231704712, avg loss: 1.3862945038080214\n",
      "trial: 2, iter: 10800, curr loss: 1.3863364458084106, avg loss: 1.38633606672287\n",
      "trial: 2, iter: 11000, curr loss: 1.3861061334609985, avg loss: 1.386302072405815\n",
      "trial: 2, iter: 11200, curr loss: 1.3863697052001953, avg loss: 1.3862992060184478\n",
      "trial: 2, iter: 11400, curr loss: 1.3864160776138306, avg loss: 1.386286284327507\n",
      "trial: 2, iter: 11600, curr loss: 1.386779546737671, avg loss: 1.386313157081604\n",
      "trial: 2, iter: 11800, curr loss: 1.386613368988037, avg loss: 1.3863106739521027\n",
      "trial: 2, iter: 12000, curr loss: 1.3862069845199585, avg loss: 1.3863100534677506\n",
      "trial: 2, iter: 12200, curr loss: 1.3865504264831543, avg loss: 1.3862978959083556\n",
      "trial: 2, iter: 12400, curr loss: 1.3863868713378906, avg loss: 1.3863163387775421\n",
      "trial: 2, iter: 12600, curr loss: 1.3861618041992188, avg loss: 1.3863005232810974\n",
      "trial: 2, iter: 12800, curr loss: 1.3863743543624878, avg loss: 1.38630845785141\n",
      "trial: 2, iter: 13000, curr loss: 1.3862957954406738, avg loss: 1.3863022565841674\n",
      "trial: 2, iter: 13200, curr loss: 1.3863760232925415, avg loss: 1.3863105982542039\n",
      "trial: 2, iter: 13400, curr loss: 1.386240005493164, avg loss: 1.3862998139858247\n",
      "trial: 2, iter: 13600, curr loss: 1.3862664699554443, avg loss: 1.3863101559877395\n",
      "trial: 2, iter: 13800, curr loss: 1.3864926099777222, avg loss: 1.3863295954465866\n",
      "trial: 2, iter: 14000, curr loss: 1.3862276077270508, avg loss: 1.3863035839796067\n",
      "trial: 2, iter: 14200, curr loss: 1.3860667943954468, avg loss: 1.3863105309009551\n",
      "trial: 2, iter: 14400, curr loss: 1.3864372968673706, avg loss: 1.386307834982872\n",
      "trial: 2, iter: 14600, curr loss: 1.3862755298614502, avg loss: 1.3863101923465728\n",
      "trial: 2, iter: 14800, curr loss: 1.3863381147384644, avg loss: 1.3863095086812973\n",
      "trial: 2, iter: 15000, curr loss: 1.3862069845199585, avg loss: 1.3863035959005356\n",
      "trial: 2, iter: 15200, curr loss: 1.3864014148712158, avg loss: 1.3863026440143584\n",
      "trial: 2, iter: 15400, curr loss: 1.3863744735717773, avg loss: 1.3862931513786316\n",
      "trial: 2, iter: 15600, curr loss: 1.3862826824188232, avg loss: 1.3863053351640702\n",
      "trial: 2, ldr: -8.743220678297803e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3896448612213135, avg loss: 1.3873815351724625\n",
      "trial: 3, iter: 400, curr loss: 1.3838670253753662, avg loss: 1.3865431588888169\n",
      "trial: 3, iter: 600, curr loss: 1.3882218599319458, avg loss: 1.386499855518341\n",
      "trial: 3, iter: 800, curr loss: 1.3861185312271118, avg loss: 1.3866406273841858\n",
      "trial: 3, iter: 1000, curr loss: 1.386812448501587, avg loss: 1.3864521133899688\n",
      "trial: 3, iter: 1200, curr loss: 1.3856480121612549, avg loss: 1.3864273661375046\n",
      "trial: 3, iter: 1400, curr loss: 1.3850771188735962, avg loss: 1.3863833236694336\n",
      "trial: 3, iter: 1600, curr loss: 1.3876991271972656, avg loss: 1.3863812804222106\n",
      "trial: 3, iter: 1800, curr loss: 1.3868876695632935, avg loss: 1.3863607305288315\n",
      "trial: 3, iter: 2000, curr loss: 1.3874024152755737, avg loss: 1.3863707864284516\n",
      "trial: 3, iter: 2200, curr loss: 1.3851454257965088, avg loss: 1.3863502854108811\n",
      "trial: 3, iter: 2400, curr loss: 1.3861315250396729, avg loss: 1.3864123213291168\n",
      "trial: 3, iter: 2600, curr loss: 1.3862955570220947, avg loss: 1.3863884764909744\n",
      "trial: 3, iter: 2800, curr loss: 1.3871833086013794, avg loss: 1.3863563114404678\n",
      "trial: 3, iter: 3000, curr loss: 1.3857725858688354, avg loss: 1.3863452309370041\n",
      "trial: 3, iter: 3200, curr loss: 1.3860567808151245, avg loss: 1.3863136184215545\n",
      "trial: 3, iter: 3400, curr loss: 1.3865009546279907, avg loss: 1.3863154524564743\n",
      "trial: 3, iter: 3600, curr loss: 1.3866604566574097, avg loss: 1.3863444304466248\n",
      "trial: 3, iter: 3800, curr loss: 1.386094570159912, avg loss: 1.3863808166980744\n",
      "trial: 3, iter: 4000, curr loss: 1.38736093044281, avg loss: 1.3862590211629868\n",
      "trial: 3, iter: 4200, curr loss: 1.3866609334945679, avg loss: 1.3863354903459548\n",
      "trial: 3, iter: 4400, curr loss: 1.3864916563034058, avg loss: 1.3863392233848573\n",
      "trial: 3, iter: 4600, curr loss: 1.3872137069702148, avg loss: 1.3863045907020568\n",
      "trial: 3, iter: 4800, curr loss: 1.3861262798309326, avg loss: 1.3863484632968903\n",
      "trial: 3, iter: 5000, curr loss: 1.3860588073730469, avg loss: 1.3862990206480026\n",
      "trial: 3, iter: 5200, curr loss: 1.386153221130371, avg loss: 1.386315910220146\n",
      "trial: 3, iter: 5400, curr loss: 1.3868787288665771, avg loss: 1.3864239716529847\n",
      "trial: 3, iter: 5600, curr loss: 1.3863426446914673, avg loss: 1.3863264620304108\n",
      "trial: 3, iter: 5800, curr loss: 1.385728120803833, avg loss: 1.3864155149459838\n",
      "trial: 3, iter: 6000, curr loss: 1.3865389823913574, avg loss: 1.3863273823261262\n",
      "trial: 3, iter: 6200, curr loss: 1.3859742879867554, avg loss: 1.3863351786136626\n",
      "trial: 3, iter: 6400, curr loss: 1.3859572410583496, avg loss: 1.38630537211895\n",
      "trial: 3, iter: 6600, curr loss: 1.3865227699279785, avg loss: 1.3863025629520416\n",
      "trial: 3, iter: 6800, curr loss: 1.3863821029663086, avg loss: 1.386297721862793\n",
      "trial: 3, iter: 7000, curr loss: 1.3860491514205933, avg loss: 1.3862976044416429\n",
      "trial: 3, iter: 7200, curr loss: 1.3864926099777222, avg loss: 1.3863042867183686\n",
      "trial: 3, iter: 7400, curr loss: 1.3862700462341309, avg loss: 1.3863107889890671\n",
      "trial: 3, iter: 7600, curr loss: 1.3865119218826294, avg loss: 1.3863344484567641\n",
      "trial: 3, iter: 7800, curr loss: 1.3863039016723633, avg loss: 1.3862872111797333\n",
      "trial: 3, iter: 8000, curr loss: 1.3863650560379028, avg loss: 1.386291953921318\n",
      "trial: 3, iter: 8200, curr loss: 1.386318564414978, avg loss: 1.3863148748874665\n",
      "trial: 3, iter: 8400, curr loss: 1.3864052295684814, avg loss: 1.3863359224796294\n",
      "trial: 3, iter: 8600, curr loss: 1.3859457969665527, avg loss: 1.3863008284568787\n",
      "trial: 3, iter: 8800, curr loss: 1.3868498802185059, avg loss: 1.386319701075554\n",
      "trial: 3, iter: 9000, curr loss: 1.3855788707733154, avg loss: 1.3863197618722916\n",
      "trial: 3, iter: 9200, curr loss: 1.3861867189407349, avg loss: 1.3863224202394486\n",
      "trial: 3, iter: 9400, curr loss: 1.3861528635025024, avg loss: 1.3863114374876022\n",
      "trial: 3, iter: 9600, curr loss: 1.386518955230713, avg loss: 1.3863052862882614\n",
      "trial: 3, iter: 9800, curr loss: 1.38577139377594, avg loss: 1.386299175620079\n",
      "trial: 3, iter: 10000, curr loss: 1.3860989809036255, avg loss: 1.3863102507591247\n",
      "trial: 3, iter: 10200, curr loss: 1.3863999843597412, avg loss: 1.3863247895240784\n",
      "trial: 3, iter: 10400, curr loss: 1.3864272832870483, avg loss: 1.3863216823339461\n",
      "trial: 3, iter: 10600, curr loss: 1.386304497718811, avg loss: 1.3863146966695785\n",
      "trial: 3, iter: 10800, curr loss: 1.3867183923721313, avg loss: 1.3863719594478607\n",
      "trial: 3, iter: 11000, curr loss: 1.3863602876663208, avg loss: 1.386302997469902\n",
      "trial: 3, iter: 11200, curr loss: 1.3859928846359253, avg loss: 1.3863353544473649\n",
      "trial: 3, iter: 11400, curr loss: 1.386028528213501, avg loss: 1.386304846405983\n",
      "trial: 3, iter: 11600, curr loss: 1.3861969709396362, avg loss: 1.3863259983062743\n",
      "trial: 3, iter: 11800, curr loss: 1.386183261871338, avg loss: 1.3862919145822525\n",
      "trial: 3, iter: 12000, curr loss: 1.386590838432312, avg loss: 1.3863430792093276\n",
      "trial: 3, iter: 12200, curr loss: 1.386509895324707, avg loss: 1.3863131123781205\n",
      "trial: 3, iter: 12400, curr loss: 1.3864293098449707, avg loss: 1.3863110625743866\n",
      "trial: 3, iter: 12600, curr loss: 1.3863199949264526, avg loss: 1.386312398314476\n",
      "trial: 3, iter: 12800, curr loss: 1.3863921165466309, avg loss: 1.3863153809309006\n",
      "trial: 3, iter: 13000, curr loss: 1.386301040649414, avg loss: 1.3862837666273118\n",
      "trial: 3, iter: 13200, curr loss: 1.3861536979675293, avg loss: 1.386303067803383\n",
      "trial: 3, iter: 13400, curr loss: 1.3863153457641602, avg loss: 1.3863208186626435\n",
      "trial: 3, iter: 13600, curr loss: 1.3862297534942627, avg loss: 1.386300036907196\n",
      "trial: 3, iter: 13800, curr loss: 1.3862082958221436, avg loss: 1.3862892949581147\n",
      "trial: 3, iter: 14000, curr loss: 1.3860399723052979, avg loss: 1.386287764310837\n",
      "trial: 3, iter: 14200, curr loss: 1.3862115144729614, avg loss: 1.3862965017557145\n",
      "trial: 3, iter: 14400, curr loss: 1.3865506649017334, avg loss: 1.3863844579458238\n",
      "trial: 3, iter: 14600, curr loss: 1.3864034414291382, avg loss: 1.386319898366928\n",
      "trial: 3, iter: 14800, curr loss: 1.3868404626846313, avg loss: 1.3863095688819884\n",
      "trial: 3, iter: 15000, curr loss: 1.3870444297790527, avg loss: 1.386235459446907\n",
      "trial: 3, iter: 15200, curr loss: 1.3862555027008057, avg loss: 1.386359867453575\n",
      "trial: 3, iter: 15400, curr loss: 1.3866121768951416, avg loss: 1.3863652104139328\n",
      "trial: 3, iter: 15600, curr loss: 1.3862377405166626, avg loss: 1.3862363529205322\n",
      "trial: 3, ldr: 0.006212475709617138\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3858375549316406, avg loss: 1.3873203200101853\n",
      "trial: 4, iter: 400, curr loss: 1.3874539136886597, avg loss: 1.3868237793445588\n",
      "trial: 4, iter: 600, curr loss: 1.388243317604065, avg loss: 1.3865245908498764\n",
      "trial: 4, iter: 800, curr loss: 1.3840229511260986, avg loss: 1.3864369463920594\n",
      "trial: 4, iter: 1000, curr loss: 1.3861888647079468, avg loss: 1.3864287823438644\n",
      "trial: 4, iter: 1200, curr loss: 1.3866982460021973, avg loss: 1.3864222145080567\n",
      "trial: 4, iter: 1400, curr loss: 1.386490821838379, avg loss: 1.3863928842544555\n",
      "trial: 4, iter: 1600, curr loss: 1.3869017362594604, avg loss: 1.3864414584636688\n",
      "trial: 4, iter: 1800, curr loss: 1.3860352039337158, avg loss: 1.386395524740219\n",
      "trial: 4, iter: 2000, curr loss: 1.3864985704421997, avg loss: 1.3864362245798112\n",
      "trial: 4, iter: 2200, curr loss: 1.3859504461288452, avg loss: 1.386298863887787\n",
      "trial: 4, iter: 2400, curr loss: 1.3860390186309814, avg loss: 1.3863550430536271\n",
      "trial: 4, iter: 2600, curr loss: 1.3849058151245117, avg loss: 1.3863116204738617\n",
      "trial: 4, iter: 2800, curr loss: 1.386968731880188, avg loss: 1.3863796108961106\n",
      "trial: 4, iter: 3000, curr loss: 1.386526346206665, avg loss: 1.3864253306388854\n",
      "trial: 4, iter: 3200, curr loss: 1.3864952325820923, avg loss: 1.3863787442445754\n",
      "trial: 4, iter: 3400, curr loss: 1.3864490985870361, avg loss: 1.3863299489021301\n",
      "trial: 4, iter: 3600, curr loss: 1.3862779140472412, avg loss: 1.3863510257005691\n",
      "trial: 4, iter: 3800, curr loss: 1.3869538307189941, avg loss: 1.3863134133815764\n",
      "trial: 4, iter: 4000, curr loss: 1.3858872652053833, avg loss: 1.3863524675369263\n",
      "trial: 4, iter: 4200, curr loss: 1.3866432905197144, avg loss: 1.3863175106048584\n",
      "trial: 4, iter: 4400, curr loss: 1.3860112428665161, avg loss: 1.3863145744800567\n",
      "trial: 4, iter: 4600, curr loss: 1.3859714269638062, avg loss: 1.3863637191057205\n",
      "trial: 4, iter: 4800, curr loss: 1.3866747617721558, avg loss: 1.3863219267129898\n",
      "trial: 4, iter: 5000, curr loss: 1.3864010572433472, avg loss: 1.386342672109604\n",
      "trial: 4, iter: 5200, curr loss: 1.3861486911773682, avg loss: 1.3863148081302643\n",
      "trial: 4, iter: 5400, curr loss: 1.386177897453308, avg loss: 1.3863401144742966\n",
      "trial: 4, iter: 5600, curr loss: 1.3866046667099, avg loss: 1.3863451439142227\n",
      "trial: 4, iter: 5800, curr loss: 1.3862454891204834, avg loss: 1.386365829706192\n",
      "trial: 4, iter: 6000, curr loss: 1.3865165710449219, avg loss: 1.3863075959682465\n",
      "trial: 4, iter: 6200, curr loss: 1.3856544494628906, avg loss: 1.3862871658802032\n",
      "trial: 4, iter: 6400, curr loss: 1.3861967325210571, avg loss: 1.3863461583852768\n",
      "trial: 4, iter: 6600, curr loss: 1.3863084316253662, avg loss: 1.386295989751816\n",
      "trial: 4, iter: 6800, curr loss: 1.3862948417663574, avg loss: 1.38629809319973\n",
      "trial: 4, iter: 7000, curr loss: 1.3862931728363037, avg loss: 1.386294674873352\n",
      "trial: 4, iter: 7200, curr loss: 1.3862944841384888, avg loss: 1.3862944257259369\n",
      "trial: 4, iter: 7400, curr loss: 1.3862956762313843, avg loss: 1.386294234395027\n",
      "trial: 4, iter: 7600, curr loss: 1.3862141370773315, avg loss: 1.38629434466362\n",
      "trial: 4, iter: 7800, curr loss: 1.386456847190857, avg loss: 1.3863058078289032\n",
      "trial: 4, iter: 8000, curr loss: 1.386153221130371, avg loss: 1.3863209223747253\n",
      "trial: 4, iter: 8200, curr loss: 1.3862693309783936, avg loss: 1.3862950259447098\n",
      "trial: 4, iter: 8400, curr loss: 1.3855481147766113, avg loss: 1.386410298347473\n",
      "trial: 4, iter: 8600, curr loss: 1.3860352039337158, avg loss: 1.3863317608833312\n",
      "trial: 4, iter: 8800, curr loss: 1.3868043422698975, avg loss: 1.3862865471839905\n",
      "trial: 4, iter: 9000, curr loss: 1.3864812850952148, avg loss: 1.386325758099556\n",
      "trial: 4, iter: 9200, curr loss: 1.386312484741211, avg loss: 1.386301040649414\n",
      "trial: 4, iter: 9400, curr loss: 1.3863929510116577, avg loss: 1.3862979555130004\n",
      "trial: 4, iter: 9600, curr loss: 1.3862308263778687, avg loss: 1.3862989526987075\n",
      "trial: 4, iter: 9800, curr loss: 1.3862651586532593, avg loss: 1.386298930644989\n",
      "trial: 4, iter: 10000, curr loss: 1.3862924575805664, avg loss: 1.3863078105449675\n",
      "trial: 4, iter: 10200, curr loss: 1.3862961530685425, avg loss: 1.3862953114509582\n",
      "trial: 4, iter: 10400, curr loss: 1.3862603902816772, avg loss: 1.386296998858452\n",
      "trial: 4, iter: 10600, curr loss: 1.3863269090652466, avg loss: 1.3862962275743484\n",
      "trial: 4, iter: 10800, curr loss: 1.3862559795379639, avg loss: 1.386297145485878\n",
      "trial: 4, iter: 11000, curr loss: 1.3862948417663574, avg loss: 1.3862967336177825\n",
      "trial: 4, iter: 11200, curr loss: 1.3863154649734497, avg loss: 1.3862952196598053\n",
      "trial: 4, iter: 11400, curr loss: 1.386295199394226, avg loss: 1.3862958121299744\n",
      "trial: 4, iter: 11600, curr loss: 1.3862944841384888, avg loss: 1.3862949204444885\n",
      "trial: 4, iter: 11800, curr loss: 1.3862948417663574, avg loss: 1.3862945640087128\n",
      "trial: 4, iter: 12000, curr loss: 1.3862944841384888, avg loss: 1.386294950246811\n",
      "trial: 4, iter: 12200, curr loss: 1.386294960975647, avg loss: 1.3862948936223984\n",
      "trial: 4, iter: 12400, curr loss: 1.3862943649291992, avg loss: 1.3862948787212372\n",
      "trial: 4, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.3862949365377426\n",
      "trial: 4, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.386294949054718\n",
      "trial: 4, iter: 13000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 13400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 4, ldr: 2.3841856489070778e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3908209800720215, avg loss: 1.3870860540866852\n",
      "trial: 5, iter: 400, curr loss: 1.3867137432098389, avg loss: 1.3867899340391159\n",
      "trial: 5, iter: 600, curr loss: 1.3863723278045654, avg loss: 1.386543024778366\n",
      "trial: 5, iter: 800, curr loss: 1.385547399520874, avg loss: 1.3864868664741516\n",
      "trial: 5, iter: 1000, curr loss: 1.3852005004882812, avg loss: 1.3864506095647813\n",
      "trial: 5, iter: 1200, curr loss: 1.3884563446044922, avg loss: 1.3864433008432389\n",
      "trial: 5, iter: 1400, curr loss: 1.3854416608810425, avg loss: 1.3864241820573806\n",
      "trial: 5, iter: 1600, curr loss: 1.386139154434204, avg loss: 1.3863364464044572\n",
      "trial: 5, iter: 1800, curr loss: 1.3862749338150024, avg loss: 1.3863960534334183\n",
      "trial: 5, iter: 2000, curr loss: 1.385847568511963, avg loss: 1.3863576436042786\n",
      "trial: 5, iter: 2200, curr loss: 1.3866069316864014, avg loss: 1.3863475465774535\n",
      "trial: 5, iter: 2400, curr loss: 1.386437177658081, avg loss: 1.3863395792245865\n",
      "trial: 5, iter: 2600, curr loss: 1.3870735168457031, avg loss: 1.386430897116661\n",
      "trial: 5, iter: 2800, curr loss: 1.3868424892425537, avg loss: 1.3864422869682311\n",
      "trial: 5, iter: 3000, curr loss: 1.3869651556015015, avg loss: 1.3863641738891601\n",
      "trial: 5, iter: 3200, curr loss: 1.386444091796875, avg loss: 1.386320795416832\n",
      "trial: 5, iter: 3400, curr loss: 1.3861143589019775, avg loss: 1.3863670134544372\n",
      "trial: 5, iter: 3600, curr loss: 1.3860357999801636, avg loss: 1.3863583636283874\n",
      "trial: 5, iter: 3800, curr loss: 1.3864595890045166, avg loss: 1.386320184469223\n",
      "trial: 5, iter: 4000, curr loss: 1.3864976167678833, avg loss: 1.3863321483135223\n",
      "trial: 5, iter: 4200, curr loss: 1.3853763341903687, avg loss: 1.3863249295949935\n",
      "trial: 5, iter: 4400, curr loss: 1.3857645988464355, avg loss: 1.3863676047325135\n",
      "trial: 5, iter: 4600, curr loss: 1.3860963582992554, avg loss: 1.3863989162445067\n",
      "trial: 5, iter: 4800, curr loss: 1.38601815700531, avg loss: 1.3863566708564758\n",
      "trial: 5, iter: 5000, curr loss: 1.3870415687561035, avg loss: 1.3863699591159822\n",
      "trial: 5, iter: 5200, curr loss: 1.3859460353851318, avg loss: 1.3863302946090699\n",
      "trial: 5, iter: 5400, curr loss: 1.3863084316253662, avg loss: 1.3863251477479934\n",
      "trial: 5, iter: 5600, curr loss: 1.3860126733779907, avg loss: 1.3863323837518693\n",
      "trial: 5, iter: 5800, curr loss: 1.3866279125213623, avg loss: 1.386312825679779\n",
      "trial: 5, iter: 6000, curr loss: 1.386339783668518, avg loss: 1.386310842037201\n",
      "trial: 5, iter: 6200, curr loss: 1.388342261314392, avg loss: 1.386329345703125\n",
      "trial: 5, iter: 6400, curr loss: 1.385854959487915, avg loss: 1.386371887922287\n",
      "trial: 5, iter: 6600, curr loss: 1.3858437538146973, avg loss: 1.3864167034626007\n",
      "trial: 5, iter: 6800, curr loss: 1.3864282369613647, avg loss: 1.386304305791855\n",
      "trial: 5, iter: 7000, curr loss: 1.3863418102264404, avg loss: 1.3863916838169097\n",
      "trial: 5, iter: 7200, curr loss: 1.3862062692642212, avg loss: 1.3863043284416199\n",
      "trial: 5, iter: 7400, curr loss: 1.3867461681365967, avg loss: 1.3863363814353944\n",
      "trial: 5, iter: 7600, curr loss: 1.3868075609207153, avg loss: 1.386305385828018\n",
      "trial: 5, iter: 7800, curr loss: 1.3860914707183838, avg loss: 1.386335865855217\n",
      "trial: 5, iter: 8000, curr loss: 1.3859243392944336, avg loss: 1.3863022720813751\n",
      "trial: 5, iter: 8200, curr loss: 1.3862510919570923, avg loss: 1.3862941306829453\n",
      "trial: 5, iter: 8400, curr loss: 1.3861764669418335, avg loss: 1.3863259065151214\n",
      "trial: 5, iter: 8600, curr loss: 1.3868975639343262, avg loss: 1.3863232505321503\n",
      "trial: 5, iter: 8800, curr loss: 1.386239767074585, avg loss: 1.386323247551918\n",
      "trial: 5, iter: 9000, curr loss: 1.386124610900879, avg loss: 1.3862956994771958\n",
      "trial: 5, iter: 9200, curr loss: 1.3863201141357422, avg loss: 1.3863105446100235\n",
      "trial: 5, iter: 9400, curr loss: 1.3863439559936523, avg loss: 1.3863061946630477\n",
      "trial: 5, iter: 9600, curr loss: 1.3864742517471313, avg loss: 1.3862858974933625\n",
      "trial: 5, iter: 9800, curr loss: 1.3864654302597046, avg loss: 1.386316009759903\n",
      "trial: 5, iter: 10000, curr loss: 1.3862520456314087, avg loss: 1.3863239252567292\n",
      "trial: 5, iter: 10200, curr loss: 1.3863277435302734, avg loss: 1.386303467154503\n",
      "trial: 5, iter: 10400, curr loss: 1.3863742351531982, avg loss: 1.3862995100021362\n",
      "trial: 5, iter: 10600, curr loss: 1.386417031288147, avg loss: 1.3862859278917312\n",
      "trial: 5, iter: 10800, curr loss: 1.3864898681640625, avg loss: 1.3862856751680375\n",
      "trial: 5, iter: 11000, curr loss: 1.3861093521118164, avg loss: 1.386297162771225\n",
      "trial: 5, iter: 11200, curr loss: 1.3864916563034058, avg loss: 1.3863063418865205\n",
      "trial: 5, iter: 11400, curr loss: 1.3865296840667725, avg loss: 1.3863230961561204\n",
      "trial: 5, iter: 11600, curr loss: 1.385561227798462, avg loss: 1.3863195246458053\n",
      "trial: 5, iter: 11800, curr loss: 1.3863451480865479, avg loss: 1.386362617611885\n",
      "trial: 5, iter: 12000, curr loss: 1.38614022731781, avg loss: 1.386181886792183\n",
      "trial: 5, iter: 12200, curr loss: 1.3864275217056274, avg loss: 1.3863558459281922\n",
      "trial: 5, iter: 12400, curr loss: 1.3864363431930542, avg loss: 1.386275927424431\n",
      "trial: 5, iter: 12600, curr loss: 1.3862216472625732, avg loss: 1.3863569551706314\n",
      "trial: 5, iter: 12800, curr loss: 1.3861219882965088, avg loss: 1.3863198202848435\n",
      "trial: 5, iter: 13000, curr loss: 1.3863152265548706, avg loss: 1.3862952476739883\n",
      "trial: 5, iter: 13200, curr loss: 1.3864461183547974, avg loss: 1.386273227930069\n",
      "trial: 5, iter: 13400, curr loss: 1.3859394788742065, avg loss: 1.3863141572475433\n",
      "trial: 5, iter: 13600, curr loss: 1.3862887620925903, avg loss: 1.3863370269536972\n",
      "trial: 5, iter: 13800, curr loss: 1.3862431049346924, avg loss: 1.386268008351326\n",
      "trial: 5, iter: 14000, curr loss: 1.3858932256698608, avg loss: 1.3862688726186752\n",
      "trial: 5, iter: 14200, curr loss: 1.3861310482025146, avg loss: 1.386327087879181\n",
      "trial: 5, iter: 14400, curr loss: 1.386277675628662, avg loss: 1.386300306916237\n",
      "trial: 5, iter: 14600, curr loss: 1.386141061782837, avg loss: 1.3862925732135774\n",
      "trial: 5, iter: 14800, curr loss: 1.386475920677185, avg loss: 1.3863039755821227\n",
      "trial: 5, iter: 15000, curr loss: 1.3866524696350098, avg loss: 1.386300112605095\n",
      "trial: 5, iter: 15200, curr loss: 1.3862224817276, avg loss: 1.3862982553243637\n",
      "trial: 5, iter: 15400, curr loss: 1.3863022327423096, avg loss: 1.3862924134731294\n",
      "trial: 5, iter: 15600, curr loss: 1.3863568305969238, avg loss: 1.386322250366211\n",
      "trial: 5, ldr: 0.0003522624319884926\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.002582671547131099\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3847967386245728, avg loss: 1.3873562425374986\n",
      "trial: 1, iter: 400, curr loss: 1.3868733644485474, avg loss: 1.386731548309326\n",
      "trial: 1, iter: 600, curr loss: 1.3869845867156982, avg loss: 1.386422528028488\n",
      "trial: 1, iter: 800, curr loss: 1.3858511447906494, avg loss: 1.386605803966522\n",
      "trial: 1, iter: 1000, curr loss: 1.3856837749481201, avg loss: 1.3864884984493255\n",
      "trial: 1, iter: 1200, curr loss: 1.3868014812469482, avg loss: 1.3864534598588945\n",
      "trial: 1, iter: 1400, curr loss: 1.387105941772461, avg loss: 1.3864619380235672\n",
      "trial: 1, iter: 1600, curr loss: 1.3858994245529175, avg loss: 1.3864022755622865\n",
      "trial: 1, iter: 1800, curr loss: 1.38762366771698, avg loss: 1.3863925403356552\n",
      "trial: 1, iter: 2000, curr loss: 1.3849701881408691, avg loss: 1.386375634074211\n",
      "trial: 1, iter: 2200, curr loss: 1.3859440088272095, avg loss: 1.3864281260967255\n",
      "trial: 1, iter: 2400, curr loss: 1.3863410949707031, avg loss: 1.3862972486019134\n",
      "trial: 1, iter: 2600, curr loss: 1.3862731456756592, avg loss: 1.386248486638069\n",
      "trial: 1, iter: 2800, curr loss: 1.3864555358886719, avg loss: 1.386397643685341\n",
      "trial: 1, iter: 3000, curr loss: 1.3873217105865479, avg loss: 1.3863586473464966\n",
      "trial: 1, iter: 3200, curr loss: 1.3867509365081787, avg loss: 1.3863853758573532\n",
      "trial: 1, iter: 3400, curr loss: 1.386462688446045, avg loss: 1.3864158833026885\n",
      "trial: 1, iter: 3600, curr loss: 1.3866815567016602, avg loss: 1.386367248892784\n",
      "trial: 1, iter: 3800, curr loss: 1.3871057033538818, avg loss: 1.3863398265838622\n",
      "trial: 1, iter: 4000, curr loss: 1.386276125907898, avg loss: 1.3863305032253266\n",
      "trial: 1, iter: 4200, curr loss: 1.3866939544677734, avg loss: 1.3863221251964568\n",
      "trial: 1, iter: 4400, curr loss: 1.3868355751037598, avg loss: 1.3862783539295196\n",
      "trial: 1, iter: 4600, curr loss: 1.3866550922393799, avg loss: 1.3863047581911088\n",
      "trial: 1, iter: 4800, curr loss: 1.3860373497009277, avg loss: 1.386343521475792\n",
      "trial: 1, iter: 5000, curr loss: 1.3858716487884521, avg loss: 1.3862838757038116\n",
      "trial: 1, iter: 5200, curr loss: 1.3866451978683472, avg loss: 1.386336065530777\n",
      "trial: 1, iter: 5400, curr loss: 1.385756015777588, avg loss: 1.3862795448303222\n",
      "trial: 1, iter: 5600, curr loss: 1.3864766359329224, avg loss: 1.3863147777318954\n",
      "trial: 1, iter: 5800, curr loss: 1.3864259719848633, avg loss: 1.3863411962985992\n",
      "trial: 1, iter: 6000, curr loss: 1.3875253200531006, avg loss: 1.3862870937585832\n",
      "trial: 1, iter: 6200, curr loss: 1.386215329170227, avg loss: 1.3863304895162583\n",
      "trial: 1, iter: 6400, curr loss: 1.3865641355514526, avg loss: 1.3863272649049758\n",
      "trial: 1, iter: 6600, curr loss: 1.3853617906570435, avg loss: 1.3863187676668167\n",
      "trial: 1, iter: 6800, curr loss: 1.3867545127868652, avg loss: 1.3863241815567016\n",
      "trial: 1, iter: 7000, curr loss: 1.3867771625518799, avg loss: 1.3863159424066545\n",
      "trial: 1, iter: 7200, curr loss: 1.3864418268203735, avg loss: 1.3862812739610673\n",
      "trial: 1, iter: 7400, curr loss: 1.3867602348327637, avg loss: 1.3863312304019928\n",
      "trial: 1, iter: 7600, curr loss: 1.3862375020980835, avg loss: 1.3863164055347443\n",
      "trial: 1, iter: 7800, curr loss: 1.3861656188964844, avg loss: 1.3863039726018906\n",
      "trial: 1, iter: 8000, curr loss: 1.3858606815338135, avg loss: 1.386297196149826\n",
      "trial: 1, iter: 8200, curr loss: 1.385673999786377, avg loss: 1.3863050985336303\n",
      "trial: 1, iter: 8400, curr loss: 1.385884165763855, avg loss: 1.3863328784704207\n",
      "trial: 1, iter: 8600, curr loss: 1.385989785194397, avg loss: 1.3863048458099365\n",
      "trial: 1, iter: 8800, curr loss: 1.3883965015411377, avg loss: 1.3863153976202012\n",
      "trial: 1, iter: 9000, curr loss: 1.3862581253051758, avg loss: 1.3862973183393479\n",
      "trial: 1, iter: 9200, curr loss: 1.3866043090820312, avg loss: 1.386352522969246\n",
      "trial: 1, iter: 9400, curr loss: 1.3862847089767456, avg loss: 1.3863282334804534\n",
      "trial: 1, iter: 9600, curr loss: 1.3864083290100098, avg loss: 1.3863113629817962\n",
      "trial: 1, iter: 9800, curr loss: 1.3862496614456177, avg loss: 1.3863027399778367\n",
      "trial: 1, iter: 10000, curr loss: 1.3864277601242065, avg loss: 1.3863354593515396\n",
      "trial: 1, iter: 10200, curr loss: 1.3862154483795166, avg loss: 1.38628201007843\n",
      "trial: 1, iter: 10400, curr loss: 1.3865255117416382, avg loss: 1.38635522544384\n",
      "trial: 1, iter: 10600, curr loss: 1.3877253532409668, avg loss: 1.386308441758156\n",
      "trial: 1, iter: 10800, curr loss: 1.3863664865493774, avg loss: 1.386361848115921\n",
      "trial: 1, iter: 11000, curr loss: 1.3863325119018555, avg loss: 1.3863079208135605\n",
      "trial: 1, iter: 11200, curr loss: 1.3859643936157227, avg loss: 1.3862913179397582\n",
      "trial: 1, iter: 11400, curr loss: 1.3866976499557495, avg loss: 1.3862860590219497\n",
      "trial: 1, iter: 11600, curr loss: 1.386136531829834, avg loss: 1.3863130271434785\n",
      "trial: 1, iter: 11800, curr loss: 1.3861980438232422, avg loss: 1.3862933045625687\n",
      "trial: 1, iter: 12000, curr loss: 1.3863532543182373, avg loss: 1.3862958693504333\n",
      "trial: 1, iter: 12200, curr loss: 1.3856453895568848, avg loss: 1.386288167834282\n",
      "trial: 1, iter: 12400, curr loss: 1.386133074760437, avg loss: 1.3863196438550949\n",
      "trial: 1, iter: 12600, curr loss: 1.3863444328308105, avg loss: 1.3863018834590912\n",
      "trial: 1, iter: 12800, curr loss: 1.3862252235412598, avg loss: 1.3862836372852325\n",
      "trial: 1, iter: 13000, curr loss: 1.3862632513046265, avg loss: 1.3863005727529525\n",
      "trial: 1, iter: 13200, curr loss: 1.3866386413574219, avg loss: 1.3863088196516038\n",
      "trial: 1, iter: 13400, curr loss: 1.3863352537155151, avg loss: 1.3862874573469162\n",
      "trial: 1, iter: 13600, curr loss: 1.3869402408599854, avg loss: 1.386409187912941\n",
      "trial: 1, iter: 13800, curr loss: 1.3863089084625244, avg loss: 1.3863233590126038\n",
      "trial: 1, iter: 14000, curr loss: 1.3862420320510864, avg loss: 1.3862976586818696\n",
      "trial: 1, iter: 14200, curr loss: 1.3861615657806396, avg loss: 1.3863035440444946\n",
      "trial: 1, iter: 14400, curr loss: 1.3863165378570557, avg loss: 1.386316146850586\n",
      "trial: 1, iter: 14600, curr loss: 1.385845422744751, avg loss: 1.3863019394874572\n",
      "trial: 1, iter: 14800, curr loss: 1.3868271112442017, avg loss: 1.3863185495138168\n",
      "trial: 1, iter: 15000, curr loss: 1.3863354921340942, avg loss: 1.3863156616687775\n",
      "trial: 1, iter: 15200, curr loss: 1.3862361907958984, avg loss: 1.3862977755069732\n",
      "trial: 1, iter: 15400, curr loss: 1.3862459659576416, avg loss: 1.3862887400388717\n",
      "trial: 1, iter: 15600, curr loss: 1.3862683773040771, avg loss: 1.3862998759746552\n",
      "trial: 1, ldr: 7.418377208523452e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386090636253357, avg loss: 1.387110316157341\n",
      "trial: 2, iter: 400, curr loss: 1.384801983833313, avg loss: 1.3865981101989746\n",
      "trial: 2, iter: 600, curr loss: 1.3840478658676147, avg loss: 1.3865370309352876\n",
      "trial: 2, iter: 800, curr loss: 1.3866705894470215, avg loss: 1.3864401841163636\n",
      "trial: 2, iter: 1000, curr loss: 1.385675311088562, avg loss: 1.3863775765895843\n",
      "trial: 2, iter: 1200, curr loss: 1.3856669664382935, avg loss: 1.3864241296052933\n",
      "trial: 2, iter: 1400, curr loss: 1.3861100673675537, avg loss: 1.3863047170639038\n",
      "trial: 2, iter: 1600, curr loss: 1.3864574432373047, avg loss: 1.3863931113481522\n",
      "trial: 2, iter: 1800, curr loss: 1.386446475982666, avg loss: 1.3863261598348617\n",
      "trial: 2, iter: 2000, curr loss: 1.3860574960708618, avg loss: 1.386306301355362\n",
      "trial: 2, iter: 2200, curr loss: 1.3856641054153442, avg loss: 1.3863877022266389\n",
      "trial: 2, iter: 2400, curr loss: 1.3866746425628662, avg loss: 1.3863204056024552\n",
      "trial: 2, iter: 2600, curr loss: 1.3865259885787964, avg loss: 1.386308447122574\n",
      "trial: 2, iter: 2800, curr loss: 1.3854069709777832, avg loss: 1.3863529509305954\n",
      "trial: 2, iter: 3000, curr loss: 1.3867177963256836, avg loss: 1.3863290828466415\n",
      "trial: 2, iter: 3200, curr loss: 1.3864221572875977, avg loss: 1.3863505816459656\n",
      "trial: 2, iter: 3400, curr loss: 1.386283278465271, avg loss: 1.3863081586360932\n",
      "trial: 2, iter: 3600, curr loss: 1.3864715099334717, avg loss: 1.386315325498581\n",
      "trial: 2, iter: 3800, curr loss: 1.38697350025177, avg loss: 1.3863032573461533\n",
      "trial: 2, iter: 4000, curr loss: 1.386398196220398, avg loss: 1.386337348818779\n",
      "trial: 2, iter: 4200, curr loss: 1.3862606287002563, avg loss: 1.3863193160295486\n",
      "trial: 2, iter: 4400, curr loss: 1.3860845565795898, avg loss: 1.3863205790519715\n",
      "trial: 2, iter: 4600, curr loss: 1.3867205381393433, avg loss: 1.386300675868988\n",
      "trial: 2, iter: 4800, curr loss: 1.3861509561538696, avg loss: 1.3863142484426498\n",
      "trial: 2, iter: 5000, curr loss: 1.3865731954574585, avg loss: 1.3863128346204758\n",
      "trial: 2, iter: 5200, curr loss: 1.3864730596542358, avg loss: 1.3863444298505783\n",
      "trial: 2, iter: 5400, curr loss: 1.3858803510665894, avg loss: 1.386316523551941\n",
      "trial: 2, iter: 5600, curr loss: 1.3861562013626099, avg loss: 1.3863221728801727\n",
      "trial: 2, iter: 5800, curr loss: 1.386870265007019, avg loss: 1.3863253688812256\n",
      "trial: 2, iter: 6000, curr loss: 1.3863765001296997, avg loss: 1.386323077082634\n",
      "trial: 2, iter: 6200, curr loss: 1.3868178129196167, avg loss: 1.3863521713018416\n",
      "trial: 2, iter: 6400, curr loss: 1.386435627937317, avg loss: 1.3863257163763045\n",
      "trial: 2, iter: 6600, curr loss: 1.386317253112793, avg loss: 1.3862829941511154\n",
      "trial: 2, iter: 6800, curr loss: 1.3868919610977173, avg loss: 1.3863725316524507\n",
      "trial: 2, iter: 7000, curr loss: 1.3860183954238892, avg loss: 1.386337952017784\n",
      "trial: 2, iter: 7200, curr loss: 1.3859412670135498, avg loss: 1.3863463026285172\n",
      "trial: 2, iter: 7400, curr loss: 1.386731743812561, avg loss: 1.386343606710434\n",
      "trial: 2, iter: 7600, curr loss: 1.3864476680755615, avg loss: 1.3863435173034668\n",
      "trial: 2, iter: 7800, curr loss: 1.3865265846252441, avg loss: 1.386308512687683\n",
      "trial: 2, iter: 8000, curr loss: 1.386357069015503, avg loss: 1.3863070112466813\n",
      "trial: 2, iter: 8200, curr loss: 1.3866249322891235, avg loss: 1.386307206749916\n",
      "trial: 2, iter: 8400, curr loss: 1.3862425088882446, avg loss: 1.3863046300411224\n",
      "trial: 2, iter: 8600, curr loss: 1.3864219188690186, avg loss: 1.386318730711937\n",
      "trial: 2, iter: 8800, curr loss: 1.3863892555236816, avg loss: 1.3862867724895478\n",
      "trial: 2, iter: 9000, curr loss: 1.386506199836731, avg loss: 1.3863412094116212\n",
      "trial: 2, iter: 9200, curr loss: 1.3869125843048096, avg loss: 1.3863758462667466\n",
      "trial: 2, iter: 9400, curr loss: 1.3871738910675049, avg loss: 1.3863287311792374\n",
      "trial: 2, iter: 9600, curr loss: 1.3861557245254517, avg loss: 1.386326737999916\n",
      "trial: 2, iter: 9800, curr loss: 1.3863444328308105, avg loss: 1.386322420835495\n",
      "trial: 2, iter: 10000, curr loss: 1.386243462562561, avg loss: 1.3863044571876526\n",
      "trial: 2, iter: 10200, curr loss: 1.386282205581665, avg loss: 1.3863085681200027\n",
      "trial: 2, iter: 10400, curr loss: 1.3863065242767334, avg loss: 1.3863020294904709\n",
      "trial: 2, iter: 10600, curr loss: 1.3862872123718262, avg loss: 1.3862945079803466\n",
      "trial: 2, iter: 10800, curr loss: 1.386284589767456, avg loss: 1.3862942069768907\n",
      "trial: 2, iter: 11000, curr loss: 1.3850345611572266, avg loss: 1.3862595772743225\n",
      "trial: 2, iter: 11200, curr loss: 1.3862924575805664, avg loss: 1.386331214904785\n",
      "trial: 2, iter: 11400, curr loss: 1.3862944841384888, avg loss: 1.3862942737340926\n",
      "trial: 2, iter: 11600, curr loss: 1.3862943649291992, avg loss: 1.3862943238019942\n",
      "trial: 2, iter: 11800, curr loss: 1.3862943649291992, avg loss: 1.3862945622205733\n",
      "trial: 2, iter: 12000, curr loss: 1.3862944841384888, avg loss: 1.386294488310814\n",
      "trial: 2, iter: 12200, curr loss: 1.3862944841384888, avg loss: 1.3862946617603302\n",
      "trial: 2, iter: 12400, curr loss: 1.386294960975647, avg loss: 1.3862947046756744\n",
      "trial: 2, iter: 12600, curr loss: 1.3862947225570679, avg loss: 1.3862948006391524\n",
      "trial: 2, iter: 12800, curr loss: 1.3862943649291992, avg loss: 1.3862945413589478\n",
      "trial: 2, iter: 13000, curr loss: 1.3862890005111694, avg loss: 1.3862943667173386\n",
      "trial: 2, iter: 13200, curr loss: 1.3862406015396118, avg loss: 1.3863364189863205\n",
      "trial: 2, iter: 13400, curr loss: 1.3866393566131592, avg loss: 1.386401036977768\n",
      "trial: 2, iter: 13600, curr loss: 1.3863106966018677, avg loss: 1.3863053691387177\n",
      "trial: 2, iter: 13800, curr loss: 1.386372685432434, avg loss: 1.3863081872463225\n",
      "trial: 2, iter: 14000, curr loss: 1.3860044479370117, avg loss: 1.3862841200828553\n",
      "trial: 2, iter: 14200, curr loss: 1.3859353065490723, avg loss: 1.386311232447624\n",
      "trial: 2, iter: 14400, curr loss: 1.3864554166793823, avg loss: 1.386303128004074\n",
      "trial: 2, iter: 14600, curr loss: 1.3862230777740479, avg loss: 1.3863046425580978\n",
      "trial: 2, iter: 14800, curr loss: 1.386338472366333, avg loss: 1.3862972688674926\n",
      "trial: 2, iter: 15000, curr loss: 1.3865489959716797, avg loss: 1.3862900727987288\n",
      "trial: 2, iter: 15200, curr loss: 1.3865402936935425, avg loss: 1.3863080751895904\n",
      "trial: 2, iter: 15400, curr loss: 1.3863013982772827, avg loss: 1.3863026696443557\n",
      "trial: 2, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3863003569841386\n",
      "trial: 2, ldr: 4.437954714830994e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.386595368385315, avg loss: 1.3872683143615723\n",
      "trial: 3, iter: 400, curr loss: 1.38866126537323, avg loss: 1.3867044985294341\n",
      "trial: 3, iter: 600, curr loss: 1.3854317665100098, avg loss: 1.3865390288829804\n",
      "trial: 3, iter: 800, curr loss: 1.385497808456421, avg loss: 1.386444900035858\n",
      "trial: 3, iter: 1000, curr loss: 1.3853490352630615, avg loss: 1.3864610934257506\n",
      "trial: 3, iter: 1200, curr loss: 1.3870055675506592, avg loss: 1.3864070093631744\n",
      "trial: 3, iter: 1400, curr loss: 1.3859102725982666, avg loss: 1.3863383799791336\n",
      "trial: 3, iter: 1600, curr loss: 1.3866323232650757, avg loss: 1.3863876032829285\n",
      "trial: 3, iter: 1800, curr loss: 1.3870357275009155, avg loss: 1.3863612657785416\n",
      "trial: 3, iter: 2000, curr loss: 1.3863632678985596, avg loss: 1.3863185513019562\n",
      "trial: 3, iter: 2200, curr loss: 1.3871281147003174, avg loss: 1.3862864500284195\n",
      "trial: 3, iter: 2400, curr loss: 1.386734127998352, avg loss: 1.3862739926576615\n",
      "trial: 3, iter: 2600, curr loss: 1.386548638343811, avg loss: 1.386326377391815\n",
      "trial: 3, iter: 2800, curr loss: 1.3867716789245605, avg loss: 1.3863557910919189\n",
      "trial: 3, iter: 3000, curr loss: 1.386646032333374, avg loss: 1.3863276654481889\n",
      "trial: 3, iter: 3200, curr loss: 1.3867886066436768, avg loss: 1.386372292637825\n",
      "trial: 3, iter: 3400, curr loss: 1.3867329359054565, avg loss: 1.3863123220205307\n",
      "trial: 3, iter: 3600, curr loss: 1.3861151933670044, avg loss: 1.3863215655088426\n",
      "trial: 3, iter: 3800, curr loss: 1.3862800598144531, avg loss: 1.3863822835683823\n",
      "trial: 3, iter: 4000, curr loss: 1.3852561712265015, avg loss: 1.3863462013006211\n",
      "trial: 3, iter: 4200, curr loss: 1.3872480392456055, avg loss: 1.3863534343242645\n",
      "trial: 3, iter: 4400, curr loss: 1.3861291408538818, avg loss: 1.386314914226532\n",
      "trial: 3, iter: 4600, curr loss: 1.3862385749816895, avg loss: 1.3863744473457336\n",
      "trial: 3, iter: 4800, curr loss: 1.386109471321106, avg loss: 1.3863714355230332\n",
      "trial: 3, iter: 5000, curr loss: 1.3863921165466309, avg loss: 1.3863355171680452\n",
      "trial: 3, iter: 5200, curr loss: 1.3859714269638062, avg loss: 1.3863314992189408\n",
      "trial: 3, iter: 5400, curr loss: 1.3875892162322998, avg loss: 1.3863301980495453\n",
      "trial: 3, iter: 5600, curr loss: 1.3892531394958496, avg loss: 1.3863351279497147\n",
      "trial: 3, iter: 5800, curr loss: 1.3849016427993774, avg loss: 1.3864176803827286\n",
      "trial: 3, iter: 6000, curr loss: 1.3865689039230347, avg loss: 1.3864046066999436\n",
      "trial: 3, iter: 6200, curr loss: 1.3888165950775146, avg loss: 1.3862993359565734\n",
      "trial: 3, iter: 6400, curr loss: 1.3863555192947388, avg loss: 1.386379411816597\n",
      "trial: 3, iter: 6600, curr loss: 1.3862240314483643, avg loss: 1.386316293478012\n",
      "trial: 3, iter: 6800, curr loss: 1.3862804174423218, avg loss: 1.3863345634937287\n",
      "trial: 3, iter: 7000, curr loss: 1.3857816457748413, avg loss: 1.386285765171051\n",
      "trial: 3, iter: 7200, curr loss: 1.3865386247634888, avg loss: 1.3863194221258164\n",
      "trial: 3, iter: 7400, curr loss: 1.3864233493804932, avg loss: 1.3863041973114014\n",
      "trial: 3, iter: 7600, curr loss: 1.3863341808319092, avg loss: 1.3863157045841217\n",
      "trial: 3, iter: 7800, curr loss: 1.386608362197876, avg loss: 1.3863020849227905\n",
      "trial: 3, iter: 8000, curr loss: 1.3866926431655884, avg loss: 1.3863276731967926\n",
      "trial: 3, iter: 8200, curr loss: 1.3862839937210083, avg loss: 1.3863197618722916\n",
      "trial: 3, iter: 8400, curr loss: 1.3863295316696167, avg loss: 1.3863223695755005\n",
      "trial: 3, iter: 8600, curr loss: 1.386913776397705, avg loss: 1.386295467019081\n",
      "trial: 3, iter: 8800, curr loss: 1.386573076248169, avg loss: 1.3862903451919555\n",
      "trial: 3, iter: 9000, curr loss: 1.386829137802124, avg loss: 1.386250330209732\n",
      "trial: 3, iter: 9200, curr loss: 1.3863716125488281, avg loss: 1.386327798962593\n",
      "trial: 3, iter: 9400, curr loss: 1.3863458633422852, avg loss: 1.3863079804182052\n",
      "trial: 3, iter: 9600, curr loss: 1.3862634897232056, avg loss: 1.3862933605909347\n",
      "trial: 3, iter: 9800, curr loss: 1.386304497718811, avg loss: 1.3863002717494965\n",
      "trial: 3, iter: 10000, curr loss: 1.3862961530685425, avg loss: 1.3862951928377152\n",
      "trial: 3, iter: 10200, curr loss: 1.386315107345581, avg loss: 1.3862948900461196\n",
      "trial: 3, iter: 10400, curr loss: 1.3862892389297485, avg loss: 1.386296993494034\n",
      "trial: 3, iter: 10600, curr loss: 1.386294960975647, avg loss: 1.386293573975563\n",
      "trial: 3, iter: 10800, curr loss: 1.3862944841384888, avg loss: 1.386294339299202\n",
      "trial: 3, iter: 11000, curr loss: 1.3860396146774292, avg loss: 1.3862966734170914\n",
      "trial: 3, iter: 11200, curr loss: 1.3861013650894165, avg loss: 1.3863069355487823\n",
      "trial: 3, iter: 11400, curr loss: 1.3862051963806152, avg loss: 1.3863110518455506\n",
      "trial: 3, iter: 11600, curr loss: 1.3865370750427246, avg loss: 1.3863088047504426\n",
      "trial: 3, iter: 11800, curr loss: 1.3862642049789429, avg loss: 1.386307207942009\n",
      "trial: 3, iter: 12000, curr loss: 1.3861968517303467, avg loss: 1.386298730969429\n",
      "trial: 3, iter: 12200, curr loss: 1.386238694190979, avg loss: 1.3862972235679627\n",
      "trial: 3, iter: 12400, curr loss: 1.3862923383712769, avg loss: 1.3862965142726897\n",
      "trial: 3, iter: 12600, curr loss: 1.3862943649291992, avg loss: 1.3862944889068602\n",
      "trial: 3, iter: 12800, curr loss: 1.3863307237625122, avg loss: 1.3863169306516647\n",
      "trial: 3, iter: 13000, curr loss: 1.3863617181777954, avg loss: 1.3863240313529968\n",
      "trial: 3, iter: 13200, curr loss: 1.3863478899002075, avg loss: 1.386301847100258\n",
      "trial: 3, iter: 13400, curr loss: 1.3862754106521606, avg loss: 1.3862959158420562\n",
      "trial: 3, iter: 13600, curr loss: 1.3863338232040405, avg loss: 1.386306129693985\n",
      "trial: 3, iter: 13800, curr loss: 1.3861860036849976, avg loss: 1.3863059020042419\n",
      "trial: 3, iter: 14000, curr loss: 1.3862947225570679, avg loss: 1.3862998950481416\n",
      "trial: 3, iter: 14200, curr loss: 1.3862944841384888, avg loss: 1.3862945652008056\n",
      "trial: 3, iter: 14400, curr loss: 1.386273980140686, avg loss: 1.3862944322824478\n",
      "trial: 3, iter: 14600, curr loss: 1.3862940073013306, avg loss: 1.3862938970327376\n",
      "trial: 3, iter: 14800, curr loss: 1.3862944841384888, avg loss: 1.386294537782669\n",
      "trial: 3, iter: 15000, curr loss: 1.386293888092041, avg loss: 1.3862936854362489\n",
      "trial: 3, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862953531742095\n",
      "trial: 3, iter: 15400, curr loss: 1.3862946033477783, avg loss: 1.3862943935394287\n",
      "trial: 3, iter: 15600, curr loss: 1.3862943649291992, avg loss: 1.3862950170040131\n",
      "trial: 3, ldr: -4.575344519253122e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3857377767562866, avg loss: 1.3874294942617416\n",
      "trial: 4, iter: 400, curr loss: 1.3875631093978882, avg loss: 1.3866894817352295\n",
      "trial: 4, iter: 600, curr loss: 1.3871551752090454, avg loss: 1.3866243588924407\n",
      "trial: 4, iter: 800, curr loss: 1.3854999542236328, avg loss: 1.3865109646320344\n",
      "trial: 4, iter: 1000, curr loss: 1.385105013847351, avg loss: 1.3863322693109512\n",
      "trial: 4, iter: 1200, curr loss: 1.3858118057250977, avg loss: 1.3865255844593047\n",
      "trial: 4, iter: 1400, curr loss: 1.386182188987732, avg loss: 1.3864679950475693\n",
      "trial: 4, iter: 1600, curr loss: 1.3856892585754395, avg loss: 1.386399237513542\n",
      "trial: 4, iter: 1800, curr loss: 1.3873505592346191, avg loss: 1.3864224058389665\n",
      "trial: 4, iter: 2000, curr loss: 1.3857868909835815, avg loss: 1.386293153166771\n",
      "trial: 4, iter: 2200, curr loss: 1.3872274160385132, avg loss: 1.3863100624084472\n",
      "trial: 4, iter: 2400, curr loss: 1.3870704174041748, avg loss: 1.3864959955215455\n",
      "trial: 4, iter: 2600, curr loss: 1.3863261938095093, avg loss: 1.386372793316841\n",
      "trial: 4, iter: 2800, curr loss: 1.3880248069763184, avg loss: 1.3863722449541092\n",
      "trial: 4, iter: 3000, curr loss: 1.3868364095687866, avg loss: 1.386354525089264\n",
      "trial: 4, iter: 3200, curr loss: 1.386654257774353, avg loss: 1.3863235461711882\n",
      "trial: 4, iter: 3400, curr loss: 1.3865232467651367, avg loss: 1.3863423705101012\n",
      "trial: 4, iter: 3600, curr loss: 1.3861802816390991, avg loss: 1.3863658380508423\n",
      "trial: 4, iter: 3800, curr loss: 1.386218786239624, avg loss: 1.3863575953245162\n",
      "trial: 4, iter: 4000, curr loss: 1.385533094406128, avg loss: 1.3863075017929076\n",
      "trial: 4, iter: 4200, curr loss: 1.3867117166519165, avg loss: 1.3863829135894776\n",
      "trial: 4, iter: 4400, curr loss: 1.3868235349655151, avg loss: 1.3863796615600585\n",
      "trial: 4, iter: 4600, curr loss: 1.3859515190124512, avg loss: 1.3863430392742158\n",
      "trial: 4, iter: 4800, curr loss: 1.3865514993667603, avg loss: 1.3864133262634277\n",
      "trial: 4, iter: 5000, curr loss: 1.3873525857925415, avg loss: 1.3863650858402252\n",
      "trial: 4, iter: 5200, curr loss: 1.3858041763305664, avg loss: 1.3863063889741898\n",
      "trial: 4, iter: 5400, curr loss: 1.3861284255981445, avg loss: 1.386376242041588\n",
      "trial: 4, iter: 5600, curr loss: 1.386466383934021, avg loss: 1.386359350681305\n",
      "trial: 4, iter: 5800, curr loss: 1.386173129081726, avg loss: 1.3862876188755036\n",
      "trial: 4, iter: 6000, curr loss: 1.3868005275726318, avg loss: 1.3863642919063568\n",
      "trial: 4, iter: 6200, curr loss: 1.3869751691818237, avg loss: 1.3863042706251145\n",
      "trial: 4, iter: 6400, curr loss: 1.3864219188690186, avg loss: 1.3863203889131546\n",
      "trial: 4, iter: 6600, curr loss: 1.3868905305862427, avg loss: 1.3862977808713912\n",
      "trial: 4, iter: 6800, curr loss: 1.386396884918213, avg loss: 1.3864720886945725\n",
      "trial: 4, iter: 7000, curr loss: 1.3867006301879883, avg loss: 1.386360479593277\n",
      "trial: 4, iter: 7200, curr loss: 1.3872519731521606, avg loss: 1.3864137637615204\n",
      "trial: 4, iter: 7400, curr loss: 1.386831283569336, avg loss: 1.38647625207901\n",
      "trial: 4, iter: 7600, curr loss: 1.386590600013733, avg loss: 1.3863016945123672\n",
      "trial: 4, iter: 7800, curr loss: 1.3859528303146362, avg loss: 1.3863268047571182\n",
      "trial: 4, iter: 8000, curr loss: 1.385947585105896, avg loss: 1.386349151134491\n",
      "trial: 4, iter: 8200, curr loss: 1.386620283126831, avg loss: 1.386325791478157\n",
      "trial: 4, iter: 8400, curr loss: 1.3864895105361938, avg loss: 1.386300790309906\n",
      "trial: 4, iter: 8600, curr loss: 1.3861265182495117, avg loss: 1.386304625272751\n",
      "trial: 4, iter: 8800, curr loss: 1.3864350318908691, avg loss: 1.386333258152008\n",
      "trial: 4, iter: 9000, curr loss: 1.386688470840454, avg loss: 1.3862988048791884\n",
      "trial: 4, iter: 9200, curr loss: 1.3864054679870605, avg loss: 1.3863325887918472\n",
      "trial: 4, iter: 9400, curr loss: 1.3861581087112427, avg loss: 1.3863149404525756\n",
      "trial: 4, iter: 9600, curr loss: 1.3863557577133179, avg loss: 1.3862950283288955\n",
      "trial: 4, iter: 9800, curr loss: 1.386160969734192, avg loss: 1.3863108694553374\n",
      "trial: 4, iter: 10000, curr loss: 1.3865958452224731, avg loss: 1.3862716156244277\n",
      "trial: 4, iter: 10200, curr loss: 1.3859225511550903, avg loss: 1.3863888001441955\n",
      "trial: 4, iter: 10400, curr loss: 1.3865538835525513, avg loss: 1.3863852262496947\n",
      "trial: 4, iter: 10600, curr loss: 1.3862717151641846, avg loss: 1.3863435846567154\n",
      "trial: 4, iter: 10800, curr loss: 1.3860632181167603, avg loss: 1.386306101679802\n",
      "trial: 4, iter: 11000, curr loss: 1.3862384557724, avg loss: 1.3863109189271927\n",
      "trial: 4, iter: 11200, curr loss: 1.3868577480316162, avg loss: 1.3863594830036163\n",
      "trial: 4, iter: 11400, curr loss: 1.3860145807266235, avg loss: 1.3863105857372284\n",
      "trial: 4, iter: 11600, curr loss: 1.3865233659744263, avg loss: 1.386358943581581\n",
      "trial: 4, iter: 11800, curr loss: 1.3866647481918335, avg loss: 1.3863836920261383\n",
      "trial: 4, iter: 12000, curr loss: 1.3867660760879517, avg loss: 1.3863632148504257\n",
      "trial: 4, iter: 12200, curr loss: 1.3863000869750977, avg loss: 1.3863425064086914\n",
      "trial: 4, iter: 12400, curr loss: 1.3869751691818237, avg loss: 1.3863184279203415\n",
      "trial: 4, iter: 12600, curr loss: 1.3862191438674927, avg loss: 1.3862834888696671\n",
      "trial: 4, iter: 12800, curr loss: 1.385789394378662, avg loss: 1.3863284474611282\n",
      "trial: 4, iter: 13000, curr loss: 1.3862824440002441, avg loss: 1.3863373011350633\n",
      "trial: 4, iter: 13200, curr loss: 1.386139988899231, avg loss: 1.3862913691997527\n",
      "trial: 4, iter: 13400, curr loss: 1.3860499858856201, avg loss: 1.3863072329759598\n",
      "trial: 4, iter: 13600, curr loss: 1.386183500289917, avg loss: 1.3863180375099182\n",
      "trial: 4, iter: 13800, curr loss: 1.386147141456604, avg loss: 1.3863035809993745\n",
      "trial: 4, iter: 14000, curr loss: 1.3862841129302979, avg loss: 1.386307784318924\n",
      "trial: 4, iter: 14200, curr loss: 1.3863346576690674, avg loss: 1.3863047045469283\n",
      "trial: 4, iter: 14400, curr loss: 1.3863840103149414, avg loss: 1.3863030809164048\n",
      "trial: 4, iter: 14600, curr loss: 1.386391520500183, avg loss: 1.3862980389595032\n",
      "trial: 4, iter: 14800, curr loss: 1.386292576789856, avg loss: 1.3863131856918336\n",
      "trial: 4, iter: 15000, curr loss: 1.386289358139038, avg loss: 1.386295810341835\n",
      "trial: 4, iter: 15200, curr loss: 1.3864555358886719, avg loss: 1.3862994188070297\n",
      "trial: 4, iter: 15400, curr loss: 1.3860360383987427, avg loss: 1.3863088172674178\n",
      "trial: 4, iter: 15600, curr loss: 1.386136770248413, avg loss: 1.3863071793317794\n",
      "trial: 4, ldr: 0.0010995334014296532\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.386932611465454, avg loss: 1.3873726731538774\n",
      "trial: 5, iter: 400, curr loss: 1.388890266418457, avg loss: 1.3867862969636917\n",
      "trial: 5, iter: 600, curr loss: 1.3841301202774048, avg loss: 1.3865512281656265\n",
      "trial: 5, iter: 800, curr loss: 1.3860429525375366, avg loss: 1.3864690554141998\n",
      "trial: 5, iter: 1000, curr loss: 1.388897180557251, avg loss: 1.3863349026441574\n",
      "trial: 5, iter: 1200, curr loss: 1.386202096939087, avg loss: 1.386427140235901\n",
      "trial: 5, iter: 1400, curr loss: 1.386516809463501, avg loss: 1.3863903445005417\n",
      "trial: 5, iter: 1600, curr loss: 1.3863273859024048, avg loss: 1.3863932639360428\n",
      "trial: 5, iter: 1800, curr loss: 1.3868416547775269, avg loss: 1.3864159959554672\n",
      "trial: 5, iter: 2000, curr loss: 1.3859926462173462, avg loss: 1.3863328433036803\n",
      "trial: 5, iter: 2200, curr loss: 1.3859772682189941, avg loss: 1.3863931149244308\n",
      "trial: 5, iter: 2400, curr loss: 1.3855100870132446, avg loss: 1.3864201784133912\n",
      "trial: 5, iter: 2600, curr loss: 1.3865032196044922, avg loss: 1.3864452707767487\n",
      "trial: 5, iter: 2800, curr loss: 1.3857378959655762, avg loss: 1.3863610261678696\n",
      "trial: 5, iter: 3000, curr loss: 1.386572241783142, avg loss: 1.3863688337802886\n",
      "trial: 5, iter: 3200, curr loss: 1.3852354288101196, avg loss: 1.3863771027326584\n",
      "trial: 5, iter: 3400, curr loss: 1.385386347770691, avg loss: 1.3863310700654983\n",
      "trial: 5, iter: 3600, curr loss: 1.3861147165298462, avg loss: 1.386329972743988\n",
      "trial: 5, iter: 3800, curr loss: 1.384902000427246, avg loss: 1.3864405119419099\n",
      "trial: 5, iter: 4000, curr loss: 1.3881049156188965, avg loss: 1.386409576535225\n",
      "trial: 5, iter: 4200, curr loss: 1.3858519792556763, avg loss: 1.3863509070873261\n",
      "trial: 5, iter: 4400, curr loss: 1.3864086866378784, avg loss: 1.3863606923818588\n",
      "trial: 5, iter: 4600, curr loss: 1.3856912851333618, avg loss: 1.3862774240970612\n",
      "trial: 5, iter: 4800, curr loss: 1.3858824968338013, avg loss: 1.3863542950153351\n",
      "trial: 5, iter: 5000, curr loss: 1.3858885765075684, avg loss: 1.386326965689659\n",
      "trial: 5, iter: 5200, curr loss: 1.386436939239502, avg loss: 1.386339818239212\n",
      "trial: 5, iter: 5400, curr loss: 1.3866015672683716, avg loss: 1.3863154703378677\n",
      "trial: 5, iter: 5600, curr loss: 1.3866068124771118, avg loss: 1.3863609725236892\n",
      "trial: 5, iter: 5800, curr loss: 1.3867679834365845, avg loss: 1.3863701909780501\n",
      "trial: 5, iter: 6000, curr loss: 1.385916829109192, avg loss: 1.3863682228326797\n",
      "trial: 5, iter: 6200, curr loss: 1.3851819038391113, avg loss: 1.3862878650426864\n",
      "trial: 5, iter: 6400, curr loss: 1.3863275051116943, avg loss: 1.3863727521896363\n",
      "trial: 5, iter: 6600, curr loss: 1.386184573173523, avg loss: 1.3863389629125595\n",
      "trial: 5, iter: 6800, curr loss: 1.3858591318130493, avg loss: 1.3863046759366988\n",
      "trial: 5, iter: 7000, curr loss: 1.3857603073120117, avg loss: 1.3862919402122498\n",
      "trial: 5, iter: 7200, curr loss: 1.386902928352356, avg loss: 1.386348550915718\n",
      "trial: 5, iter: 7400, curr loss: 1.3858463764190674, avg loss: 1.3863048869371415\n",
      "trial: 5, iter: 7600, curr loss: 1.386906623840332, avg loss: 1.386315599679947\n",
      "trial: 5, iter: 7800, curr loss: 1.3864021301269531, avg loss: 1.3863266319036485\n",
      "trial: 5, iter: 8000, curr loss: 1.3861125707626343, avg loss: 1.3863166660070418\n",
      "trial: 5, iter: 8200, curr loss: 1.3861572742462158, avg loss: 1.3863084375858308\n",
      "trial: 5, iter: 8400, curr loss: 1.3863126039505005, avg loss: 1.3863406425714493\n",
      "trial: 5, iter: 8600, curr loss: 1.386224627494812, avg loss: 1.3862546736001968\n",
      "trial: 5, iter: 8800, curr loss: 1.3863036632537842, avg loss: 1.3863169300556182\n",
      "trial: 5, iter: 9000, curr loss: 1.386275053024292, avg loss: 1.3863276964426041\n",
      "trial: 5, iter: 9200, curr loss: 1.3866441249847412, avg loss: 1.3862702935934066\n",
      "trial: 5, iter: 9400, curr loss: 1.3864004611968994, avg loss: 1.3863698863983154\n",
      "trial: 5, iter: 9600, curr loss: 1.386504888534546, avg loss: 1.3863951927423477\n",
      "trial: 5, iter: 9800, curr loss: 1.3861907720565796, avg loss: 1.3863500356674194\n",
      "trial: 5, iter: 10000, curr loss: 1.3865793943405151, avg loss: 1.3864120692014694\n",
      "trial: 5, iter: 10200, curr loss: 1.3869410753250122, avg loss: 1.3863218635320664\n",
      "trial: 5, iter: 10400, curr loss: 1.3864672183990479, avg loss: 1.386316450238228\n",
      "trial: 5, iter: 10600, curr loss: 1.3872853517532349, avg loss: 1.386301555633545\n",
      "trial: 5, iter: 10800, curr loss: 1.3865450620651245, avg loss: 1.386376781463623\n",
      "trial: 5, iter: 11000, curr loss: 1.3866578340530396, avg loss: 1.3862749087810515\n",
      "trial: 5, iter: 11200, curr loss: 1.3860118389129639, avg loss: 1.3863625890016555\n",
      "trial: 5, iter: 11400, curr loss: 1.3866236209869385, avg loss: 1.3863415217399597\n",
      "trial: 5, iter: 11600, curr loss: 1.385827660560608, avg loss: 1.3863238966464997\n",
      "trial: 5, iter: 11800, curr loss: 1.3859350681304932, avg loss: 1.386313223838806\n",
      "trial: 5, iter: 12000, curr loss: 1.3860048055648804, avg loss: 1.3863222324848175\n",
      "trial: 5, iter: 12200, curr loss: 1.3867946863174438, avg loss: 1.3863162195682526\n",
      "trial: 5, iter: 12400, curr loss: 1.386491298675537, avg loss: 1.3862741959095002\n",
      "trial: 5, iter: 12600, curr loss: 1.386538028717041, avg loss: 1.3863219118118286\n",
      "trial: 5, iter: 12800, curr loss: 1.3865439891815186, avg loss: 1.3863142067193985\n",
      "trial: 5, iter: 13000, curr loss: 1.3858722448349, avg loss: 1.3863248866796494\n",
      "trial: 5, iter: 13200, curr loss: 1.3861737251281738, avg loss: 1.3863249289989472\n",
      "trial: 5, iter: 13400, curr loss: 1.3859877586364746, avg loss: 1.3863026976585389\n",
      "trial: 5, iter: 13600, curr loss: 1.3869426250457764, avg loss: 1.3863130819797516\n",
      "trial: 5, iter: 13800, curr loss: 1.3866883516311646, avg loss: 1.3863323402404786\n",
      "trial: 5, iter: 14000, curr loss: 1.3863602876663208, avg loss: 1.3863148736953734\n",
      "trial: 5, iter: 14200, curr loss: 1.386275291442871, avg loss: 1.386315597295761\n",
      "trial: 5, iter: 14400, curr loss: 1.3864450454711914, avg loss: 1.386303376555443\n",
      "trial: 5, iter: 14600, curr loss: 1.3860914707183838, avg loss: 1.386310600042343\n",
      "trial: 5, iter: 14800, curr loss: 1.386198878288269, avg loss: 1.3863203179836274\n",
      "trial: 5, iter: 15000, curr loss: 1.386317253112793, avg loss: 1.3863026505708695\n",
      "trial: 5, iter: 15200, curr loss: 1.3862807750701904, avg loss: 1.386292740702629\n",
      "trial: 5, iter: 15400, curr loss: 1.3859304189682007, avg loss: 1.386293676495552\n",
      "trial: 5, iter: 15600, curr loss: 1.3860582113265991, avg loss: 1.386308953166008\n",
      "trial: 5, ldr: -0.0007693558000028133\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 8.004596489286087e-05\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386707067489624, avg loss: 1.387202917933464\n",
      "trial: 1, iter: 400, curr loss: 1.3863946199417114, avg loss: 1.3866976487636566\n",
      "trial: 1, iter: 600, curr loss: 1.3855303525924683, avg loss: 1.3866347408294677\n",
      "trial: 1, iter: 800, curr loss: 1.3868920803070068, avg loss: 1.3866196125745773\n",
      "trial: 1, iter: 1000, curr loss: 1.385475754737854, avg loss: 1.3865239942073821\n",
      "trial: 1, iter: 1200, curr loss: 1.3859140872955322, avg loss: 1.3864224070310593\n",
      "trial: 1, iter: 1400, curr loss: 1.385864496231079, avg loss: 1.3863544470071794\n",
      "trial: 1, iter: 1600, curr loss: 1.3886288404464722, avg loss: 1.3863349437713623\n",
      "trial: 1, iter: 1800, curr loss: 1.3862988948822021, avg loss: 1.3864484560489654\n",
      "trial: 1, iter: 2000, curr loss: 1.3850661516189575, avg loss: 1.3864366346597672\n",
      "trial: 1, iter: 2200, curr loss: 1.386386752128601, avg loss: 1.3864363080263138\n",
      "trial: 1, iter: 2400, curr loss: 1.3873299360275269, avg loss: 1.3863555359840394\n",
      "trial: 1, iter: 2600, curr loss: 1.385827660560608, avg loss: 1.3863154119253158\n",
      "trial: 1, iter: 2800, curr loss: 1.3860130310058594, avg loss: 1.3863808280229568\n",
      "trial: 1, iter: 3000, curr loss: 1.386484146118164, avg loss: 1.3863416230678558\n",
      "trial: 1, iter: 3200, curr loss: 1.3859678506851196, avg loss: 1.3863363367319108\n",
      "trial: 1, iter: 3400, curr loss: 1.3864387273788452, avg loss: 1.386304994225502\n",
      "trial: 1, iter: 3600, curr loss: 1.3871407508850098, avg loss: 1.3863416367769241\n",
      "trial: 1, iter: 3800, curr loss: 1.3854475021362305, avg loss: 1.3863021641969682\n",
      "trial: 1, iter: 4000, curr loss: 1.3858345746994019, avg loss: 1.3863448697328566\n",
      "trial: 1, iter: 4200, curr loss: 1.3859285116195679, avg loss: 1.3862968969345093\n",
      "trial: 1, iter: 4400, curr loss: 1.3870185613632202, avg loss: 1.3863033312559128\n",
      "trial: 1, iter: 4600, curr loss: 1.386755108833313, avg loss: 1.3863838893175124\n",
      "trial: 1, iter: 4800, curr loss: 1.3862968683242798, avg loss: 1.386314697265625\n",
      "trial: 1, iter: 5000, curr loss: 1.386414885520935, avg loss: 1.3863215255737305\n",
      "trial: 1, iter: 5200, curr loss: 1.3860549926757812, avg loss: 1.3863438093662261\n",
      "trial: 1, iter: 5400, curr loss: 1.385581612586975, avg loss: 1.3863384747505187\n",
      "trial: 1, iter: 5600, curr loss: 1.3864766359329224, avg loss: 1.3863425296545029\n",
      "trial: 1, iter: 5800, curr loss: 1.38614022731781, avg loss: 1.3863842642307282\n",
      "trial: 1, iter: 6000, curr loss: 1.3859034776687622, avg loss: 1.3862768876552582\n",
      "trial: 1, iter: 6200, curr loss: 1.3867462873458862, avg loss: 1.3863236808776855\n",
      "trial: 1, iter: 6400, curr loss: 1.385756492614746, avg loss: 1.3862701362371446\n",
      "trial: 1, iter: 6600, curr loss: 1.3863054513931274, avg loss: 1.3863445246219634\n",
      "trial: 1, iter: 6800, curr loss: 1.3862015008926392, avg loss: 1.3862993568181992\n",
      "trial: 1, iter: 7000, curr loss: 1.386643886566162, avg loss: 1.3862854164838792\n",
      "trial: 1, iter: 7200, curr loss: 1.3863683938980103, avg loss: 1.3863217306137086\n",
      "trial: 1, iter: 7400, curr loss: 1.3857194185256958, avg loss: 1.3862696784734725\n",
      "trial: 1, iter: 7600, curr loss: 1.3861764669418335, avg loss: 1.3863511264324189\n",
      "trial: 1, iter: 7800, curr loss: 1.3862721920013428, avg loss: 1.3862963312864303\n",
      "trial: 1, iter: 8000, curr loss: 1.3862029314041138, avg loss: 1.3862975031137466\n",
      "trial: 1, iter: 8200, curr loss: 1.3869061470031738, avg loss: 1.3863077193498612\n",
      "trial: 1, iter: 8400, curr loss: 1.3859003782272339, avg loss: 1.386353361606598\n",
      "trial: 1, iter: 8600, curr loss: 1.3858144283294678, avg loss: 1.3863929569721223\n",
      "trial: 1, iter: 8800, curr loss: 1.3873851299285889, avg loss: 1.386380439400673\n",
      "trial: 1, iter: 9000, curr loss: 1.3863128423690796, avg loss: 1.3864782875776291\n",
      "trial: 1, iter: 9200, curr loss: 1.3861738443374634, avg loss: 1.3863364207744597\n",
      "trial: 1, iter: 9400, curr loss: 1.3866324424743652, avg loss: 1.3863109582662583\n",
      "trial: 1, iter: 9600, curr loss: 1.3860682249069214, avg loss: 1.386326379776001\n",
      "trial: 1, iter: 9800, curr loss: 1.3870224952697754, avg loss: 1.386301280260086\n",
      "trial: 1, iter: 10000, curr loss: 1.386164665222168, avg loss: 1.3863452243804932\n",
      "trial: 1, iter: 10200, curr loss: 1.3861445188522339, avg loss: 1.3863070154190062\n",
      "trial: 1, iter: 10400, curr loss: 1.3859939575195312, avg loss: 1.386305428147316\n",
      "trial: 1, iter: 10600, curr loss: 1.3861225843429565, avg loss: 1.3862575197219849\n",
      "trial: 1, iter: 10800, curr loss: 1.38581120967865, avg loss: 1.3863538438081742\n",
      "trial: 1, iter: 11000, curr loss: 1.3861104249954224, avg loss: 1.3862975996732712\n",
      "trial: 1, iter: 11200, curr loss: 1.3862578868865967, avg loss: 1.3863111984729768\n",
      "trial: 1, iter: 11400, curr loss: 1.3863697052001953, avg loss: 1.3863214349746704\n",
      "trial: 1, iter: 11600, curr loss: 1.3864154815673828, avg loss: 1.3863075011968613\n",
      "trial: 1, iter: 11800, curr loss: 1.386242151260376, avg loss: 1.3863036686182022\n",
      "trial: 1, iter: 12000, curr loss: 1.3863916397094727, avg loss: 1.386296696662903\n",
      "trial: 1, iter: 12200, curr loss: 1.3857996463775635, avg loss: 1.3862966603040696\n",
      "trial: 1, iter: 12400, curr loss: 1.3861414194107056, avg loss: 1.3863179528713225\n",
      "trial: 1, iter: 12600, curr loss: 1.386164665222168, avg loss: 1.3862729436159134\n",
      "trial: 1, iter: 12800, curr loss: 1.3866370916366577, avg loss: 1.3863006770610808\n",
      "trial: 1, iter: 13000, curr loss: 1.3855853080749512, avg loss: 1.3862686800956725\n",
      "trial: 1, iter: 13200, curr loss: 1.386090874671936, avg loss: 1.3862905985116958\n",
      "trial: 1, iter: 13400, curr loss: 1.3864984512329102, avg loss: 1.3863007289171219\n",
      "trial: 1, iter: 13600, curr loss: 1.3862515687942505, avg loss: 1.3863039016723633\n",
      "trial: 1, iter: 13800, curr loss: 1.387441873550415, avg loss: 1.3862470716238022\n",
      "trial: 1, iter: 14000, curr loss: 1.386259913444519, avg loss: 1.3863372403383254\n",
      "trial: 1, iter: 14200, curr loss: 1.3863216638565063, avg loss: 1.3863289970159531\n",
      "trial: 1, iter: 14400, curr loss: 1.3863575458526611, avg loss: 1.3863039129972459\n",
      "trial: 1, iter: 14600, curr loss: 1.3861509561538696, avg loss: 1.386308616399765\n",
      "trial: 1, iter: 14800, curr loss: 1.3862303495407104, avg loss: 1.3863076388835907\n",
      "trial: 1, iter: 15000, curr loss: 1.3861503601074219, avg loss: 1.3862879836559296\n",
      "trial: 1, iter: 15200, curr loss: 1.3865125179290771, avg loss: 1.386295698285103\n",
      "trial: 1, iter: 15400, curr loss: 1.3860570192337036, avg loss: 1.3863014829158784\n",
      "trial: 1, iter: 15600, curr loss: 1.386301875114441, avg loss: 1.3863035726547241\n",
      "trial: 1, ldr: 0.00011992780491709709\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3865317106246948, avg loss: 1.3870244002342225\n",
      "trial: 2, iter: 400, curr loss: 1.3846673965454102, avg loss: 1.3867597818374633\n",
      "trial: 2, iter: 600, curr loss: 1.386824369430542, avg loss: 1.3866824638843536\n",
      "trial: 2, iter: 800, curr loss: 1.3869102001190186, avg loss: 1.3865218341350556\n",
      "trial: 2, iter: 1000, curr loss: 1.3908747434616089, avg loss: 1.3862996208667755\n",
      "trial: 2, iter: 1200, curr loss: 1.3866132497787476, avg loss: 1.3864799129962921\n",
      "trial: 2, iter: 1400, curr loss: 1.3860481977462769, avg loss: 1.3864597392082214\n",
      "trial: 2, iter: 1600, curr loss: 1.3861006498336792, avg loss: 1.3863747221231462\n",
      "trial: 2, iter: 1800, curr loss: 1.3857660293579102, avg loss: 1.3863786321878433\n",
      "trial: 2, iter: 2000, curr loss: 1.3866060972213745, avg loss: 1.3864238220453262\n",
      "trial: 2, iter: 2200, curr loss: 1.3867902755737305, avg loss: 1.3862652069330215\n",
      "trial: 2, iter: 2400, curr loss: 1.387068271636963, avg loss: 1.3864526969194413\n",
      "trial: 2, iter: 2600, curr loss: 1.3866440057754517, avg loss: 1.3863382560014725\n",
      "trial: 2, iter: 2800, curr loss: 1.3853521347045898, avg loss: 1.3863550895452499\n",
      "trial: 2, iter: 3000, curr loss: 1.3863742351531982, avg loss: 1.3863340842723846\n",
      "trial: 2, iter: 3200, curr loss: 1.3867413997650146, avg loss: 1.386347572207451\n",
      "trial: 2, iter: 3400, curr loss: 1.3869271278381348, avg loss: 1.3863444274663925\n",
      "trial: 2, iter: 3600, curr loss: 1.3853367567062378, avg loss: 1.3863846474885941\n",
      "trial: 2, iter: 3800, curr loss: 1.3867340087890625, avg loss: 1.3863382565975189\n",
      "trial: 2, iter: 4000, curr loss: 1.386383056640625, avg loss: 1.3863761174678801\n",
      "trial: 2, iter: 4200, curr loss: 1.3865978717803955, avg loss: 1.3863634490966796\n",
      "trial: 2, iter: 4400, curr loss: 1.387479305267334, avg loss: 1.386317687034607\n",
      "trial: 2, iter: 4600, curr loss: 1.3867952823638916, avg loss: 1.386379712820053\n",
      "trial: 2, iter: 4800, curr loss: 1.38643479347229, avg loss: 1.3863199651241302\n",
      "trial: 2, iter: 5000, curr loss: 1.385947585105896, avg loss: 1.3863539332151413\n",
      "trial: 2, iter: 5200, curr loss: 1.3852699995040894, avg loss: 1.3863064795732498\n",
      "trial: 2, iter: 5400, curr loss: 1.3860855102539062, avg loss: 1.3863232624530792\n",
      "trial: 2, iter: 5600, curr loss: 1.3875789642333984, avg loss: 1.3862941664457322\n",
      "trial: 2, iter: 5800, curr loss: 1.3864257335662842, avg loss: 1.3862580132484437\n",
      "trial: 2, iter: 6000, curr loss: 1.3864145278930664, avg loss: 1.3863382118940353\n",
      "trial: 2, iter: 6200, curr loss: 1.386267066001892, avg loss: 1.3863105511665343\n",
      "trial: 2, iter: 6400, curr loss: 1.386013388633728, avg loss: 1.3863062089681626\n",
      "trial: 2, iter: 6600, curr loss: 1.3854120969772339, avg loss: 1.386334426999092\n",
      "trial: 2, iter: 6800, curr loss: 1.38609778881073, avg loss: 1.3863233482837678\n",
      "trial: 2, iter: 7000, curr loss: 1.3861067295074463, avg loss: 1.3863882339000702\n",
      "trial: 2, iter: 7200, curr loss: 1.3859866857528687, avg loss: 1.3863141006231308\n",
      "trial: 2, iter: 7400, curr loss: 1.3863511085510254, avg loss: 1.386319409608841\n",
      "trial: 2, iter: 7600, curr loss: 1.3864445686340332, avg loss: 1.3863370090723037\n",
      "trial: 2, iter: 7800, curr loss: 1.3865383863449097, avg loss: 1.386262526512146\n",
      "trial: 2, iter: 8000, curr loss: 1.3860747814178467, avg loss: 1.3863664084672929\n",
      "trial: 2, iter: 8200, curr loss: 1.3860373497009277, avg loss: 1.3863096350431443\n",
      "trial: 2, iter: 8400, curr loss: 1.3864595890045166, avg loss: 1.3863736647367477\n",
      "trial: 2, iter: 8600, curr loss: 1.3871434926986694, avg loss: 1.386255335211754\n",
      "trial: 2, iter: 8800, curr loss: 1.3867405652999878, avg loss: 1.3863579720258712\n",
      "trial: 2, iter: 9000, curr loss: 1.3865017890930176, avg loss: 1.38631871342659\n",
      "trial: 2, iter: 9200, curr loss: 1.386263132095337, avg loss: 1.3863128262758255\n",
      "trial: 2, iter: 9400, curr loss: 1.386654019355774, avg loss: 1.386287322640419\n",
      "trial: 2, iter: 9600, curr loss: 1.3863883018493652, avg loss: 1.386327565908432\n",
      "trial: 2, iter: 9800, curr loss: 1.3859895467758179, avg loss: 1.3863020789623262\n",
      "trial: 2, iter: 10000, curr loss: 1.3864467144012451, avg loss: 1.386307315826416\n",
      "trial: 2, iter: 10200, curr loss: 1.3864675760269165, avg loss: 1.3863062483072282\n",
      "trial: 2, iter: 10400, curr loss: 1.3863258361816406, avg loss: 1.386349881887436\n",
      "trial: 2, iter: 10600, curr loss: 1.386305809020996, avg loss: 1.3863132911920548\n",
      "trial: 2, iter: 10800, curr loss: 1.3861539363861084, avg loss: 1.386301788687706\n",
      "trial: 2, iter: 11000, curr loss: 1.3861721754074097, avg loss: 1.3862982523441314\n",
      "trial: 2, iter: 11200, curr loss: 1.3864506483078003, avg loss: 1.3862997847795486\n",
      "trial: 2, iter: 11400, curr loss: 1.3866771459579468, avg loss: 1.3862791514396668\n",
      "trial: 2, iter: 11600, curr loss: 1.3862391710281372, avg loss: 1.3863121485710144\n",
      "trial: 2, iter: 11800, curr loss: 1.3867639303207397, avg loss: 1.3863110536336898\n",
      "trial: 2, iter: 12000, curr loss: 1.385574221611023, avg loss: 1.3863792288303376\n",
      "trial: 2, iter: 12200, curr loss: 1.386232852935791, avg loss: 1.3863341206312179\n",
      "trial: 2, iter: 12400, curr loss: 1.3868415355682373, avg loss: 1.3863176596164704\n",
      "trial: 2, iter: 12600, curr loss: 1.38639235496521, avg loss: 1.386327520608902\n",
      "trial: 2, iter: 12800, curr loss: 1.3863786458969116, avg loss: 1.3862974059581756\n",
      "trial: 2, iter: 13000, curr loss: 1.3862066268920898, avg loss: 1.3862935537099839\n",
      "trial: 2, iter: 13200, curr loss: 1.3860738277435303, avg loss: 1.3862922030687332\n",
      "trial: 2, iter: 13400, curr loss: 1.3859213590621948, avg loss: 1.3862752544879913\n",
      "trial: 2, iter: 13600, curr loss: 1.3865442276000977, avg loss: 1.3863337606191635\n",
      "trial: 2, iter: 13800, curr loss: 1.3862558603286743, avg loss: 1.386314435005188\n",
      "trial: 2, iter: 14000, curr loss: 1.3861920833587646, avg loss: 1.3863230884075164\n",
      "trial: 2, iter: 14200, curr loss: 1.38629150390625, avg loss: 1.3863167297840118\n",
      "trial: 2, iter: 14400, curr loss: 1.3862004280090332, avg loss: 1.386307384967804\n",
      "trial: 2, iter: 14600, curr loss: 1.3861297369003296, avg loss: 1.3863024181127548\n",
      "trial: 2, iter: 14800, curr loss: 1.3864965438842773, avg loss: 1.3863178181648255\n",
      "trial: 2, iter: 15000, curr loss: 1.3863447904586792, avg loss: 1.386295458674431\n",
      "trial: 2, iter: 15200, curr loss: 1.3862371444702148, avg loss: 1.3863017237186432\n",
      "trial: 2, iter: 15400, curr loss: 1.3865472078323364, avg loss: 1.3863050907850265\n",
      "trial: 2, iter: 15600, curr loss: 1.3860456943511963, avg loss: 1.3862938749790192\n",
      "trial: 2, ldr: 0.001626033685170114\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3859950304031372, avg loss: 1.3874080604314805\n",
      "trial: 3, iter: 400, curr loss: 1.3849996328353882, avg loss: 1.3867974889278412\n",
      "trial: 3, iter: 600, curr loss: 1.3856321573257446, avg loss: 1.3865517675876617\n",
      "trial: 3, iter: 800, curr loss: 1.3882790803909302, avg loss: 1.3864026594161987\n",
      "trial: 3, iter: 1000, curr loss: 1.3870054483413696, avg loss: 1.3865780246257782\n",
      "trial: 3, iter: 1200, curr loss: 1.3860206604003906, avg loss: 1.3863802671432495\n",
      "trial: 3, iter: 1400, curr loss: 1.3877009153366089, avg loss: 1.3864471006393433\n",
      "trial: 3, iter: 1600, curr loss: 1.3855020999908447, avg loss: 1.3864063954353332\n",
      "trial: 3, iter: 1800, curr loss: 1.3858892917633057, avg loss: 1.386433454155922\n",
      "trial: 3, iter: 2000, curr loss: 1.386334776878357, avg loss: 1.3863805061578751\n",
      "trial: 3, iter: 2200, curr loss: 1.386234164237976, avg loss: 1.386409466266632\n",
      "trial: 3, iter: 2400, curr loss: 1.3861560821533203, avg loss: 1.3863589310646056\n",
      "trial: 3, iter: 2600, curr loss: 1.3872326612472534, avg loss: 1.3863756424188614\n",
      "trial: 3, iter: 2800, curr loss: 1.3862255811691284, avg loss: 1.3863385117053986\n",
      "trial: 3, iter: 3000, curr loss: 1.3855249881744385, avg loss: 1.3863264000415803\n",
      "trial: 3, iter: 3200, curr loss: 1.385388970375061, avg loss: 1.3863874584436418\n",
      "trial: 3, iter: 3400, curr loss: 1.3857017755508423, avg loss: 1.3864270555973053\n",
      "trial: 3, iter: 3600, curr loss: 1.3857465982437134, avg loss: 1.3863738584518432\n",
      "trial: 3, iter: 3800, curr loss: 1.3860636949539185, avg loss: 1.3863615500926971\n",
      "trial: 3, iter: 4000, curr loss: 1.3863753080368042, avg loss: 1.3863707453012466\n",
      "trial: 3, iter: 4200, curr loss: 1.3860805034637451, avg loss: 1.3863320380449295\n",
      "trial: 3, iter: 4400, curr loss: 1.386541724205017, avg loss: 1.3862864530086518\n",
      "trial: 3, iter: 4600, curr loss: 1.3856229782104492, avg loss: 1.386297418475151\n",
      "trial: 3, iter: 4800, curr loss: 1.386293888092041, avg loss: 1.3863547068834305\n",
      "trial: 3, iter: 5000, curr loss: 1.386138677597046, avg loss: 1.386346263885498\n",
      "trial: 3, iter: 5200, curr loss: 1.38715660572052, avg loss: 1.386335653066635\n",
      "trial: 3, iter: 5400, curr loss: 1.3865702152252197, avg loss: 1.3863815832138062\n",
      "trial: 3, iter: 5600, curr loss: 1.386818528175354, avg loss: 1.386294316649437\n",
      "trial: 3, iter: 5800, curr loss: 1.3864777088165283, avg loss: 1.386332138776779\n",
      "trial: 3, iter: 6000, curr loss: 1.3865633010864258, avg loss: 1.3863157141208649\n",
      "trial: 3, iter: 6200, curr loss: 1.386832356452942, avg loss: 1.386297281384468\n",
      "trial: 3, iter: 6400, curr loss: 1.3862719535827637, avg loss: 1.3863446462154387\n",
      "trial: 3, iter: 6600, curr loss: 1.3861924409866333, avg loss: 1.3863111746311187\n",
      "trial: 3, iter: 6800, curr loss: 1.386387586593628, avg loss: 1.3863127475976944\n",
      "trial: 3, iter: 7000, curr loss: 1.3855398893356323, avg loss: 1.3862945193052292\n",
      "trial: 3, iter: 7200, curr loss: 1.3869073390960693, avg loss: 1.386299666762352\n",
      "trial: 3, iter: 7400, curr loss: 1.3860363960266113, avg loss: 1.3863189351558685\n",
      "trial: 3, iter: 7600, curr loss: 1.3864456415176392, avg loss: 1.386304508447647\n",
      "trial: 3, iter: 7800, curr loss: 1.3867237567901611, avg loss: 1.3863321471214294\n",
      "trial: 3, iter: 8000, curr loss: 1.386220097541809, avg loss: 1.3863094705343246\n",
      "trial: 3, iter: 8200, curr loss: 1.386245846748352, avg loss: 1.3862974447011949\n",
      "trial: 3, iter: 8400, curr loss: 1.3862992525100708, avg loss: 1.3862995487451553\n",
      "trial: 3, iter: 8600, curr loss: 1.385867953300476, avg loss: 1.3863402229547501\n",
      "trial: 3, iter: 8800, curr loss: 1.3863141536712646, avg loss: 1.38635072350502\n",
      "trial: 3, iter: 9000, curr loss: 1.386021614074707, avg loss: 1.3863216298818588\n",
      "trial: 3, iter: 9200, curr loss: 1.386846661567688, avg loss: 1.3863252305984497\n",
      "trial: 3, iter: 9400, curr loss: 1.3872312307357788, avg loss: 1.3862934857606888\n",
      "trial: 3, iter: 9600, curr loss: 1.3857388496398926, avg loss: 1.3862988084554673\n",
      "trial: 3, iter: 9800, curr loss: 1.3867696523666382, avg loss: 1.3863876909017563\n",
      "trial: 3, iter: 10000, curr loss: 1.3870247602462769, avg loss: 1.3863264477252961\n",
      "trial: 3, iter: 10200, curr loss: 1.3861901760101318, avg loss: 1.386330216526985\n",
      "trial: 3, iter: 10400, curr loss: 1.386335849761963, avg loss: 1.386318746805191\n",
      "trial: 3, iter: 10600, curr loss: 1.3864128589630127, avg loss: 1.386292548775673\n",
      "trial: 3, iter: 10800, curr loss: 1.3867392539978027, avg loss: 1.386311240196228\n",
      "trial: 3, iter: 11000, curr loss: 1.3864284753799438, avg loss: 1.3863316094875335\n",
      "trial: 3, iter: 11200, curr loss: 1.3867119550704956, avg loss: 1.3862887883186341\n",
      "trial: 3, iter: 11400, curr loss: 1.3863152265548706, avg loss: 1.3863388586044312\n",
      "trial: 3, iter: 11600, curr loss: 1.3861905336380005, avg loss: 1.3862945359945298\n",
      "trial: 3, iter: 11800, curr loss: 1.3864933252334595, avg loss: 1.3862952542304994\n",
      "trial: 3, iter: 12000, curr loss: 1.3863685131072998, avg loss: 1.3862958884239196\n",
      "trial: 3, iter: 12200, curr loss: 1.3862336874008179, avg loss: 1.3862802040576936\n",
      "trial: 3, iter: 12400, curr loss: 1.386214256286621, avg loss: 1.3862987715005874\n",
      "trial: 3, iter: 12600, curr loss: 1.386404037475586, avg loss: 1.3863001650571822\n",
      "trial: 3, iter: 12800, curr loss: 1.3863497972488403, avg loss: 1.3863046497106553\n",
      "trial: 3, iter: 13000, curr loss: 1.3860424757003784, avg loss: 1.3862853288650512\n",
      "trial: 3, iter: 13200, curr loss: 1.386428952217102, avg loss: 1.3863103795051575\n",
      "trial: 3, iter: 13400, curr loss: 1.3861844539642334, avg loss: 1.3862983667850495\n",
      "trial: 3, iter: 13600, curr loss: 1.386337399482727, avg loss: 1.38630490899086\n",
      "trial: 3, iter: 13800, curr loss: 1.3862941265106201, avg loss: 1.3862979501485824\n",
      "trial: 3, iter: 14000, curr loss: 1.3863357305526733, avg loss: 1.386293962597847\n",
      "trial: 3, iter: 14200, curr loss: 1.3862313032150269, avg loss: 1.3862965416908264\n",
      "trial: 3, iter: 14400, curr loss: 1.386142611503601, avg loss: 1.3863047885894775\n",
      "trial: 3, iter: 14600, curr loss: 1.3859065771102905, avg loss: 1.3862954360246658\n",
      "trial: 3, iter: 14800, curr loss: 1.3863537311553955, avg loss: 1.3863018423318862\n",
      "trial: 3, iter: 15000, curr loss: 1.386314868927002, avg loss: 1.3863029211759568\n",
      "trial: 3, iter: 15200, curr loss: 1.3862982988357544, avg loss: 1.38629565179348\n",
      "trial: 3, iter: 15400, curr loss: 1.386330246925354, avg loss: 1.3862944263219834\n",
      "trial: 3, iter: 15600, curr loss: 1.3863930702209473, avg loss: 1.386296461224556\n",
      "trial: 3, ldr: -0.0007813450647518039\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3885170221328735, avg loss: 1.387470661997795\n",
      "trial: 4, iter: 400, curr loss: 1.3840930461883545, avg loss: 1.3868068414926529\n",
      "trial: 4, iter: 600, curr loss: 1.3861383199691772, avg loss: 1.386589161157608\n",
      "trial: 4, iter: 800, curr loss: 1.3860756158828735, avg loss: 1.3864891225099563\n",
      "trial: 4, iter: 1000, curr loss: 1.384630799293518, avg loss: 1.3864699518680572\n",
      "trial: 4, iter: 1200, curr loss: 1.387123942375183, avg loss: 1.3865473985671997\n",
      "trial: 4, iter: 1400, curr loss: 1.3868666887283325, avg loss: 1.3863167572021484\n",
      "trial: 4, iter: 1600, curr loss: 1.386383295059204, avg loss: 1.3863064098358153\n",
      "trial: 4, iter: 1800, curr loss: 1.386036992073059, avg loss: 1.3863914406299591\n",
      "trial: 4, iter: 2000, curr loss: 1.3857733011245728, avg loss: 1.3863107347488404\n",
      "trial: 4, iter: 2200, curr loss: 1.385671854019165, avg loss: 1.3863408291339874\n",
      "trial: 4, iter: 2400, curr loss: 1.386534333229065, avg loss: 1.3863306045532227\n",
      "trial: 4, iter: 2600, curr loss: 1.3850492238998413, avg loss: 1.3862786853313447\n",
      "trial: 4, iter: 2800, curr loss: 1.3866688013076782, avg loss: 1.386381122469902\n",
      "trial: 4, iter: 3000, curr loss: 1.3859405517578125, avg loss: 1.3863867485523225\n",
      "trial: 4, iter: 3200, curr loss: 1.3863115310668945, avg loss: 1.3862918567657472\n",
      "trial: 4, iter: 3400, curr loss: 1.3864198923110962, avg loss: 1.386287897825241\n",
      "trial: 4, iter: 3600, curr loss: 1.3860185146331787, avg loss: 1.3863483798503875\n",
      "trial: 4, iter: 3800, curr loss: 1.3866080045700073, avg loss: 1.3863357025384904\n",
      "trial: 4, iter: 4000, curr loss: 1.3863301277160645, avg loss: 1.3862862652540207\n",
      "trial: 4, iter: 4200, curr loss: 1.387840986251831, avg loss: 1.3862964832782745\n",
      "trial: 4, iter: 4400, curr loss: 1.3865851163864136, avg loss: 1.3862994945049285\n",
      "trial: 4, iter: 4600, curr loss: 1.3867225646972656, avg loss: 1.3863690131902695\n",
      "trial: 4, iter: 4800, curr loss: 1.3864458799362183, avg loss: 1.3862915563583373\n",
      "trial: 4, iter: 5000, curr loss: 1.3864855766296387, avg loss: 1.386329892873764\n",
      "trial: 4, iter: 5200, curr loss: 1.3858914375305176, avg loss: 1.3863312566280366\n",
      "trial: 4, iter: 5400, curr loss: 1.3864543437957764, avg loss: 1.3863160568475723\n",
      "trial: 4, iter: 5600, curr loss: 1.3867093324661255, avg loss: 1.386294618844986\n",
      "trial: 4, iter: 5800, curr loss: 1.3864409923553467, avg loss: 1.3863138204813004\n",
      "trial: 4, iter: 6000, curr loss: 1.3866277933120728, avg loss: 1.3862771201133728\n",
      "trial: 4, iter: 6200, curr loss: 1.3861831426620483, avg loss: 1.3864658212661742\n",
      "trial: 4, iter: 6400, curr loss: 1.386423110961914, avg loss: 1.3864492589235307\n",
      "trial: 4, iter: 6600, curr loss: 1.3861823081970215, avg loss: 1.3863304471969604\n",
      "trial: 4, iter: 6800, curr loss: 1.386183261871338, avg loss: 1.3863218677043916\n",
      "trial: 4, iter: 7000, curr loss: 1.3868399858474731, avg loss: 1.3863317859172821\n",
      "trial: 4, iter: 7200, curr loss: 1.3863556385040283, avg loss: 1.38634492456913\n",
      "trial: 4, iter: 7400, curr loss: 1.3866710662841797, avg loss: 1.3863664084672929\n",
      "trial: 4, iter: 7600, curr loss: 1.3863542079925537, avg loss: 1.3863009083271027\n",
      "trial: 4, iter: 7800, curr loss: 1.3869372606277466, avg loss: 1.3863065558671952\n",
      "trial: 4, iter: 8000, curr loss: 1.3860750198364258, avg loss: 1.3863346731662751\n",
      "trial: 4, iter: 8200, curr loss: 1.3865796327590942, avg loss: 1.3863102161884309\n",
      "trial: 4, iter: 8400, curr loss: 1.3863496780395508, avg loss: 1.3863126158714294\n",
      "trial: 4, iter: 8600, curr loss: 1.3865915536880493, avg loss: 1.3863223856687545\n",
      "trial: 4, iter: 8800, curr loss: 1.3861364126205444, avg loss: 1.3863175046443938\n",
      "trial: 4, iter: 9000, curr loss: 1.386148452758789, avg loss: 1.386302850842476\n",
      "trial: 4, iter: 9200, curr loss: 1.386294960975647, avg loss: 1.3863130438327789\n",
      "trial: 4, iter: 9400, curr loss: 1.3867477178573608, avg loss: 1.386283633708954\n",
      "trial: 4, iter: 9600, curr loss: 1.386264681816101, avg loss: 1.3863197499513626\n",
      "trial: 4, iter: 9800, curr loss: 1.3864734172821045, avg loss: 1.3863034445047377\n",
      "trial: 4, iter: 10000, curr loss: 1.3861676454544067, avg loss: 1.3862772762775422\n",
      "trial: 4, iter: 10200, curr loss: 1.3864185810089111, avg loss: 1.3863067871332169\n",
      "trial: 4, iter: 10400, curr loss: 1.3863823413848877, avg loss: 1.386281707882881\n",
      "trial: 4, iter: 10600, curr loss: 1.3859165906906128, avg loss: 1.38634604036808\n",
      "trial: 4, iter: 10800, curr loss: 1.3862849473953247, avg loss: 1.3862910217046738\n",
      "trial: 4, iter: 11000, curr loss: 1.3861747980117798, avg loss: 1.3863251304626465\n",
      "trial: 4, iter: 11200, curr loss: 1.386591911315918, avg loss: 1.386301230788231\n",
      "trial: 4, iter: 11400, curr loss: 1.38632071018219, avg loss: 1.3863111925125122\n",
      "trial: 4, iter: 11600, curr loss: 1.3862406015396118, avg loss: 1.3862952870130538\n",
      "trial: 4, iter: 11800, curr loss: 1.3863550424575806, avg loss: 1.3862979674339295\n",
      "trial: 4, iter: 12000, curr loss: 1.3858379125595093, avg loss: 1.3862852799892424\n",
      "trial: 4, iter: 12200, curr loss: 1.3860985040664673, avg loss: 1.3863097524642944\n",
      "trial: 4, iter: 12400, curr loss: 1.3861628770828247, avg loss: 1.3863043922185898\n",
      "trial: 4, iter: 12600, curr loss: 1.3861112594604492, avg loss: 1.386300834417343\n",
      "trial: 4, iter: 12800, curr loss: 1.3862478733062744, avg loss: 1.3863075667619704\n",
      "trial: 4, iter: 13000, curr loss: 1.3864035606384277, avg loss: 1.3863036721944808\n",
      "trial: 4, iter: 13200, curr loss: 1.386254072189331, avg loss: 1.3862981653213502\n",
      "trial: 4, iter: 13400, curr loss: 1.3863348960876465, avg loss: 1.3862953776121139\n",
      "trial: 4, iter: 13600, curr loss: 1.386237621307373, avg loss: 1.3862947916984558\n",
      "trial: 4, iter: 13800, curr loss: 1.3862361907958984, avg loss: 1.3862947350740433\n",
      "trial: 4, iter: 14000, curr loss: 1.3862451314926147, avg loss: 1.3862969201803208\n",
      "trial: 4, iter: 14200, curr loss: 1.386254906654358, avg loss: 1.386295318007469\n",
      "trial: 4, iter: 14400, curr loss: 1.3862384557724, avg loss: 1.3863039058446884\n",
      "trial: 4, iter: 14600, curr loss: 1.3863381147384644, avg loss: 1.3863118118047715\n",
      "trial: 4, iter: 14800, curr loss: 1.3866691589355469, avg loss: 1.3862922781705855\n",
      "trial: 4, iter: 15000, curr loss: 1.3862061500549316, avg loss: 1.3862994706630707\n",
      "trial: 4, iter: 15200, curr loss: 1.3862942457199097, avg loss: 1.3862946838140489\n",
      "trial: 4, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.3862943434715271\n",
      "trial: 4, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3862947404384613\n",
      "trial: 4, ldr: 1.0044684131571557e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3909986019134521, avg loss: 1.3874908220767974\n",
      "trial: 5, iter: 400, curr loss: 1.3877861499786377, avg loss: 1.3868089354038238\n",
      "trial: 5, iter: 600, curr loss: 1.387894868850708, avg loss: 1.386637286543846\n",
      "trial: 5, iter: 800, curr loss: 1.3856521844863892, avg loss: 1.38650547683239\n",
      "trial: 5, iter: 1000, curr loss: 1.3873920440673828, avg loss: 1.3863329160213471\n",
      "trial: 5, iter: 1200, curr loss: 1.3865984678268433, avg loss: 1.3863713133335114\n",
      "trial: 5, iter: 1400, curr loss: 1.3867360353469849, avg loss: 1.386444862484932\n",
      "trial: 5, iter: 1600, curr loss: 1.3870843648910522, avg loss: 1.3863169437646865\n",
      "trial: 5, iter: 1800, curr loss: 1.3863991498947144, avg loss: 1.3864326399564744\n",
      "trial: 5, iter: 2000, curr loss: 1.3860907554626465, avg loss: 1.3863290137052535\n",
      "trial: 5, iter: 2200, curr loss: 1.386553406715393, avg loss: 1.3863317960500716\n",
      "trial: 5, iter: 2400, curr loss: 1.3856250047683716, avg loss: 1.3863549572229386\n",
      "trial: 5, iter: 2600, curr loss: 1.3864227533340454, avg loss: 1.3863375973701477\n",
      "trial: 5, iter: 2800, curr loss: 1.3861329555511475, avg loss: 1.3863112169504166\n",
      "trial: 5, iter: 3000, curr loss: 1.3864922523498535, avg loss: 1.386348122358322\n",
      "trial: 5, iter: 3200, curr loss: 1.3863705396652222, avg loss: 1.3863575953245162\n",
      "trial: 5, iter: 3400, curr loss: 1.3861823081970215, avg loss: 1.3863422006368638\n",
      "trial: 5, iter: 3600, curr loss: 1.3874788284301758, avg loss: 1.386311241388321\n",
      "trial: 5, iter: 3800, curr loss: 1.3870519399642944, avg loss: 1.3863926941156388\n",
      "trial: 5, iter: 4000, curr loss: 1.386791467666626, avg loss: 1.3863823288679122\n",
      "trial: 5, iter: 4200, curr loss: 1.3867812156677246, avg loss: 1.386346962451935\n",
      "trial: 5, iter: 4400, curr loss: 1.3851269483566284, avg loss: 1.3863179934024812\n",
      "trial: 5, iter: 4600, curr loss: 1.38592529296875, avg loss: 1.38635889172554\n",
      "trial: 5, iter: 4800, curr loss: 1.3861547708511353, avg loss: 1.3863861435651779\n",
      "trial: 5, iter: 5000, curr loss: 1.3861781358718872, avg loss: 1.3863082456588744\n",
      "trial: 5, iter: 5200, curr loss: 1.386284589767456, avg loss: 1.3863260245323181\n",
      "trial: 5, iter: 5400, curr loss: 1.38594651222229, avg loss: 1.3862351763248444\n",
      "trial: 5, iter: 5600, curr loss: 1.385932445526123, avg loss: 1.386374791264534\n",
      "trial: 5, iter: 5800, curr loss: 1.3854875564575195, avg loss: 1.386359428167343\n",
      "trial: 5, iter: 6000, curr loss: 1.3858625888824463, avg loss: 1.386363325715065\n",
      "trial: 5, iter: 6200, curr loss: 1.3865984678268433, avg loss: 1.3863183999061583\n",
      "trial: 5, iter: 6400, curr loss: 1.3859509229660034, avg loss: 1.386348432302475\n",
      "trial: 5, iter: 6600, curr loss: 1.3861970901489258, avg loss: 1.3863169091939926\n",
      "trial: 5, iter: 6800, curr loss: 1.3861757516860962, avg loss: 1.3863313990831374\n",
      "trial: 5, iter: 7000, curr loss: 1.386364459991455, avg loss: 1.3862986367940904\n",
      "trial: 5, iter: 7200, curr loss: 1.3862245082855225, avg loss: 1.3863402622938157\n",
      "trial: 5, iter: 7400, curr loss: 1.386204481124878, avg loss: 1.38627332508564\n",
      "trial: 5, iter: 7600, curr loss: 1.3866420984268188, avg loss: 1.38642911195755\n",
      "trial: 5, iter: 7800, curr loss: 1.3861716985702515, avg loss: 1.3863264894485474\n",
      "trial: 5, iter: 8000, curr loss: 1.3860881328582764, avg loss: 1.3863382560014725\n",
      "trial: 5, iter: 8200, curr loss: 1.3865705728530884, avg loss: 1.3863139867782592\n",
      "trial: 5, iter: 8400, curr loss: 1.3863599300384521, avg loss: 1.386295685172081\n",
      "trial: 5, iter: 8600, curr loss: 1.3865128755569458, avg loss: 1.3863178098201752\n",
      "trial: 5, iter: 8800, curr loss: 1.3866318464279175, avg loss: 1.3862941718101502\n",
      "trial: 5, iter: 9000, curr loss: 1.3867664337158203, avg loss: 1.386320126056671\n",
      "trial: 5, iter: 9200, curr loss: 1.386374831199646, avg loss: 1.386306916475296\n",
      "trial: 5, iter: 9400, curr loss: 1.3859081268310547, avg loss: 1.3863539284467696\n",
      "trial: 5, iter: 9600, curr loss: 1.3864338397979736, avg loss: 1.3863383477926254\n",
      "trial: 5, iter: 9800, curr loss: 1.3862403631210327, avg loss: 1.3863096088171005\n",
      "trial: 5, iter: 10000, curr loss: 1.3862026929855347, avg loss: 1.386290312409401\n",
      "trial: 5, iter: 10200, curr loss: 1.3858698606491089, avg loss: 1.3862873846292496\n",
      "trial: 5, iter: 10400, curr loss: 1.3862431049346924, avg loss: 1.3863111907243728\n",
      "trial: 5, iter: 10600, curr loss: 1.386220097541809, avg loss: 1.3863157856464385\n",
      "trial: 5, iter: 10800, curr loss: 1.386014461517334, avg loss: 1.386294636130333\n",
      "trial: 5, iter: 11000, curr loss: 1.386017084121704, avg loss: 1.386279771924019\n",
      "trial: 5, iter: 11200, curr loss: 1.3863579034805298, avg loss: 1.3863241291046142\n",
      "trial: 5, iter: 11400, curr loss: 1.386254072189331, avg loss: 1.3863024294376374\n",
      "trial: 5, iter: 11600, curr loss: 1.3862888813018799, avg loss: 1.3862996125221252\n",
      "trial: 5, iter: 11800, curr loss: 1.3863651752471924, avg loss: 1.386304652094841\n",
      "trial: 5, iter: 12000, curr loss: 1.3863786458969116, avg loss: 1.3862987118959427\n",
      "trial: 5, iter: 12200, curr loss: 1.3863030672073364, avg loss: 1.386297840476036\n",
      "trial: 5, iter: 12400, curr loss: 1.3864439725875854, avg loss: 1.3862975227832794\n",
      "trial: 5, iter: 12600, curr loss: 1.3863482475280762, avg loss: 1.386294935941696\n",
      "trial: 5, iter: 12800, curr loss: 1.386277675628662, avg loss: 1.3862929165363311\n",
      "trial: 5, iter: 13000, curr loss: 1.386340618133545, avg loss: 1.3863019531965255\n",
      "trial: 5, iter: 13200, curr loss: 1.3863428831100464, avg loss: 1.3862946152687072\n",
      "trial: 5, iter: 13400, curr loss: 1.3865017890930176, avg loss: 1.3863037532567979\n",
      "trial: 5, iter: 13600, curr loss: 1.3864002227783203, avg loss: 1.386298342347145\n",
      "trial: 5, iter: 13800, curr loss: 1.3840985298156738, avg loss: 1.3863206815719604\n",
      "trial: 5, iter: 14000, curr loss: 1.3865007162094116, avg loss: 1.386430685520172\n",
      "trial: 5, iter: 14200, curr loss: 1.3862590789794922, avg loss: 1.386317247748375\n",
      "trial: 5, iter: 14400, curr loss: 1.3862488269805908, avg loss: 1.3862900531291962\n",
      "trial: 5, iter: 14600, curr loss: 1.3862829208374023, avg loss: 1.3863295269012452\n",
      "trial: 5, iter: 14800, curr loss: 1.3858181238174438, avg loss: 1.3863314121961594\n",
      "trial: 5, iter: 15000, curr loss: 1.386634349822998, avg loss: 1.386303834915161\n",
      "trial: 5, iter: 15200, curr loss: 1.3864189386367798, avg loss: 1.3863480859994888\n",
      "trial: 5, iter: 15400, curr loss: 1.3862580060958862, avg loss: 1.3862929546833038\n",
      "trial: 5, iter: 15600, curr loss: 1.3863049745559692, avg loss: 1.3863081842660905\n",
      "trial: 5, ldr: -0.0015184868825599551\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00010876515461859526\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.383485198020935, avg loss: 1.3871613758802415\n",
      "trial: 1, iter: 400, curr loss: 1.3868470191955566, avg loss: 1.386672151684761\n",
      "trial: 1, iter: 600, curr loss: 1.3873333930969238, avg loss: 1.3865852916240693\n",
      "trial: 1, iter: 800, curr loss: 1.3854349851608276, avg loss: 1.3865198975801467\n",
      "trial: 1, iter: 1000, curr loss: 1.386656403541565, avg loss: 1.3865159732103347\n",
      "trial: 1, iter: 1200, curr loss: 1.3845181465148926, avg loss: 1.3864410901069641\n",
      "trial: 1, iter: 1400, curr loss: 1.387629508972168, avg loss: 1.3864241009950637\n",
      "trial: 1, iter: 1600, curr loss: 1.3868271112442017, avg loss: 1.3863888943195344\n",
      "trial: 1, iter: 1800, curr loss: 1.3890904188156128, avg loss: 1.3863695174455644\n",
      "trial: 1, iter: 2000, curr loss: 1.3864340782165527, avg loss: 1.3863767898082733\n",
      "trial: 1, iter: 2200, curr loss: 1.38508141040802, avg loss: 1.3863411277532578\n",
      "trial: 1, iter: 2400, curr loss: 1.3864845037460327, avg loss: 1.3864502918720245\n",
      "trial: 1, iter: 2600, curr loss: 1.385605812072754, avg loss: 1.3863894671201706\n",
      "trial: 1, iter: 2800, curr loss: 1.386651635169983, avg loss: 1.3863367187976836\n",
      "trial: 1, iter: 3000, curr loss: 1.3868045806884766, avg loss: 1.38631108045578\n",
      "trial: 1, iter: 3200, curr loss: 1.3863368034362793, avg loss: 1.3863645029067992\n",
      "trial: 1, iter: 3400, curr loss: 1.3866130113601685, avg loss: 1.3863896763324737\n",
      "trial: 1, iter: 3600, curr loss: 1.3870856761932373, avg loss: 1.3863453435897828\n",
      "trial: 1, iter: 3800, curr loss: 1.3862531185150146, avg loss: 1.3863899290561676\n",
      "trial: 1, iter: 4000, curr loss: 1.3862477540969849, avg loss: 1.3863572406768798\n",
      "trial: 1, iter: 4200, curr loss: 1.3862580060958862, avg loss: 1.3863037401437759\n",
      "trial: 1, iter: 4400, curr loss: 1.3865898847579956, avg loss: 1.3863308602571487\n",
      "trial: 1, iter: 4600, curr loss: 1.385506272315979, avg loss: 1.3862789833545686\n",
      "trial: 1, iter: 4800, curr loss: 1.3863650560379028, avg loss: 1.3863548815250397\n",
      "trial: 1, iter: 5000, curr loss: 1.3866853713989258, avg loss: 1.3863129937648773\n",
      "trial: 1, iter: 5200, curr loss: 1.3862248659133911, avg loss: 1.3862975615262985\n",
      "trial: 1, iter: 5400, curr loss: 1.3863435983657837, avg loss: 1.3863099718093872\n",
      "trial: 1, iter: 5600, curr loss: 1.386494755744934, avg loss: 1.3863329601287842\n",
      "trial: 1, iter: 5800, curr loss: 1.3861082792282104, avg loss: 1.386312494277954\n",
      "trial: 1, iter: 6000, curr loss: 1.3863857984542847, avg loss: 1.3863306766748429\n",
      "trial: 1, iter: 6200, curr loss: 1.386863350868225, avg loss: 1.3863143754005431\n",
      "trial: 1, iter: 6400, curr loss: 1.385988712310791, avg loss: 1.3862883907556534\n",
      "trial: 1, iter: 6600, curr loss: 1.386430025100708, avg loss: 1.386313677430153\n",
      "trial: 1, iter: 6800, curr loss: 1.3863871097564697, avg loss: 1.3863721990585327\n",
      "trial: 1, iter: 7000, curr loss: 1.3863630294799805, avg loss: 1.3863258123397828\n",
      "trial: 1, iter: 7200, curr loss: 1.3859189748764038, avg loss: 1.3863603502511979\n",
      "trial: 1, iter: 7400, curr loss: 1.3861792087554932, avg loss: 1.3863103860616683\n",
      "trial: 1, iter: 7600, curr loss: 1.3862859010696411, avg loss: 1.386308535337448\n",
      "trial: 1, iter: 7800, curr loss: 1.386547565460205, avg loss: 1.3863025462627412\n",
      "trial: 1, iter: 8000, curr loss: 1.3863171339035034, avg loss: 1.3863062518835068\n",
      "trial: 1, iter: 8200, curr loss: 1.3859893083572388, avg loss: 1.3862746149301528\n",
      "trial: 1, iter: 8400, curr loss: 1.3862515687942505, avg loss: 1.3863288152217865\n",
      "trial: 1, iter: 8600, curr loss: 1.386102318763733, avg loss: 1.3862930572032928\n",
      "trial: 1, iter: 8800, curr loss: 1.386236548423767, avg loss: 1.3863119637966157\n",
      "trial: 1, iter: 9000, curr loss: 1.3861918449401855, avg loss: 1.3862946128845215\n",
      "trial: 1, iter: 9200, curr loss: 1.3862459659576416, avg loss: 1.3863003849983215\n",
      "trial: 1, iter: 9400, curr loss: 1.3863937854766846, avg loss: 1.3863073921203612\n",
      "trial: 1, iter: 9600, curr loss: 1.3864270448684692, avg loss: 1.3862979906797408\n",
      "trial: 1, iter: 9800, curr loss: 1.3863309621810913, avg loss: 1.3862950539588927\n",
      "trial: 1, iter: 10000, curr loss: 1.3860323429107666, avg loss: 1.386307514309883\n",
      "trial: 1, iter: 10200, curr loss: 1.3867640495300293, avg loss: 1.3863255947828292\n",
      "trial: 1, iter: 10400, curr loss: 1.3869925737380981, avg loss: 1.3863251942396164\n",
      "trial: 1, iter: 10600, curr loss: 1.3862367868423462, avg loss: 1.3863175100088119\n",
      "trial: 1, iter: 10800, curr loss: 1.3863180875778198, avg loss: 1.386300493478775\n",
      "trial: 1, iter: 11000, curr loss: 1.3861560821533203, avg loss: 1.386380809545517\n",
      "trial: 1, iter: 11200, curr loss: 1.3861963748931885, avg loss: 1.3862993103265762\n",
      "trial: 1, iter: 11400, curr loss: 1.3864814043045044, avg loss: 1.3862950229644775\n",
      "trial: 1, iter: 11600, curr loss: 1.386549472808838, avg loss: 1.3863146072626114\n",
      "trial: 1, iter: 11800, curr loss: 1.3866329193115234, avg loss: 1.3863058745861054\n",
      "trial: 1, iter: 12000, curr loss: 1.3861031532287598, avg loss: 1.3862846738100052\n",
      "trial: 1, iter: 12200, curr loss: 1.3860371112823486, avg loss: 1.3863342452049254\n",
      "trial: 1, iter: 12400, curr loss: 1.3865015506744385, avg loss: 1.3863022059202195\n",
      "trial: 1, iter: 12600, curr loss: 1.3859508037567139, avg loss: 1.3862909775972367\n",
      "trial: 1, iter: 12800, curr loss: 1.3864881992340088, avg loss: 1.3863081860542297\n",
      "trial: 1, iter: 13000, curr loss: 1.3861541748046875, avg loss: 1.3862976133823395\n",
      "trial: 1, iter: 13200, curr loss: 1.3861637115478516, avg loss: 1.3863046723604202\n",
      "trial: 1, iter: 13400, curr loss: 1.386216402053833, avg loss: 1.3862996077537537\n",
      "trial: 1, iter: 13600, curr loss: 1.3864412307739258, avg loss: 1.3862868803739548\n",
      "trial: 1, iter: 13800, curr loss: 1.3859915733337402, avg loss: 1.3862532222270965\n",
      "trial: 1, iter: 14000, curr loss: 1.3864630460739136, avg loss: 1.3863246476650237\n",
      "trial: 1, iter: 14200, curr loss: 1.3860481977462769, avg loss: 1.3863059490919114\n",
      "trial: 1, iter: 14400, curr loss: 1.386035442352295, avg loss: 1.3863084977865219\n",
      "trial: 1, iter: 14600, curr loss: 1.3863825798034668, avg loss: 1.386301003098488\n",
      "trial: 1, iter: 14800, curr loss: 1.386269211769104, avg loss: 1.3862878668308258\n",
      "trial: 1, iter: 15000, curr loss: 1.386325716972351, avg loss: 1.3863183361291886\n",
      "trial: 1, iter: 15200, curr loss: 1.3863404989242554, avg loss: 1.386295698285103\n",
      "trial: 1, iter: 15400, curr loss: 1.386347770690918, avg loss: 1.3862918585538864\n",
      "trial: 1, iter: 15600, curr loss: 1.3862608671188354, avg loss: 1.3863018763065338\n",
      "trial: 1, ldr: 0.0004469999694265425\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3870474100112915, avg loss: 1.3874205833673476\n",
      "trial: 2, iter: 400, curr loss: 1.3866761922836304, avg loss: 1.386807649731636\n",
      "trial: 2, iter: 600, curr loss: 1.3861318826675415, avg loss: 1.386523695588112\n",
      "trial: 2, iter: 800, curr loss: 1.3875411748886108, avg loss: 1.3865277081727982\n",
      "trial: 2, iter: 1000, curr loss: 1.3865766525268555, avg loss: 1.3863654339313507\n",
      "trial: 2, iter: 1200, curr loss: 1.3856819868087769, avg loss: 1.386516569852829\n",
      "trial: 2, iter: 1400, curr loss: 1.3863451480865479, avg loss: 1.3863751834630966\n",
      "trial: 2, iter: 1600, curr loss: 1.3863296508789062, avg loss: 1.3864799773693084\n",
      "trial: 2, iter: 1800, curr loss: 1.3859087228775024, avg loss: 1.3863426303863526\n",
      "trial: 2, iter: 2000, curr loss: 1.3862000703811646, avg loss: 1.3863748747110367\n",
      "trial: 2, iter: 2200, curr loss: 1.385483980178833, avg loss: 1.3863829451799392\n",
      "trial: 2, iter: 2400, curr loss: 1.3888858556747437, avg loss: 1.386429277062416\n",
      "trial: 2, iter: 2600, curr loss: 1.3852213621139526, avg loss: 1.3863582992553711\n",
      "trial: 2, iter: 2800, curr loss: 1.3878660202026367, avg loss: 1.386420214176178\n",
      "trial: 2, iter: 3000, curr loss: 1.3874108791351318, avg loss: 1.3864151179790496\n",
      "trial: 2, iter: 3200, curr loss: 1.3874666690826416, avg loss: 1.3863724207878112\n",
      "trial: 2, iter: 3400, curr loss: 1.386345624923706, avg loss: 1.3863603019714354\n",
      "trial: 2, iter: 3600, curr loss: 1.386109471321106, avg loss: 1.386361094713211\n",
      "trial: 2, iter: 3800, curr loss: 1.3858333826065063, avg loss: 1.3863930213451385\n",
      "trial: 2, iter: 4000, curr loss: 1.3871068954467773, avg loss: 1.3863515949249268\n",
      "trial: 2, iter: 4200, curr loss: 1.386325716972351, avg loss: 1.3863027054071426\n",
      "trial: 2, iter: 4400, curr loss: 1.3873286247253418, avg loss: 1.3863008934259415\n",
      "trial: 2, iter: 4600, curr loss: 1.3859078884124756, avg loss: 1.3863541495800018\n",
      "trial: 2, iter: 4800, curr loss: 1.3865690231323242, avg loss: 1.3863340252637864\n",
      "trial: 2, iter: 5000, curr loss: 1.386128544807434, avg loss: 1.3863166445493698\n",
      "trial: 2, iter: 5200, curr loss: 1.386362075805664, avg loss: 1.3863176876306533\n",
      "trial: 2, iter: 5400, curr loss: 1.3863837718963623, avg loss: 1.386309902071953\n",
      "trial: 2, iter: 5600, curr loss: 1.386259913444519, avg loss: 1.3863236236572265\n",
      "trial: 2, iter: 5800, curr loss: 1.386191964149475, avg loss: 1.3863109123706818\n",
      "trial: 2, iter: 6000, curr loss: 1.3864357471466064, avg loss: 1.3863112807273865\n",
      "trial: 2, iter: 6200, curr loss: 1.3862429857254028, avg loss: 1.3863153207302092\n",
      "trial: 2, iter: 6400, curr loss: 1.3861887454986572, avg loss: 1.3863028693199158\n",
      "trial: 2, iter: 6600, curr loss: 1.386033058166504, avg loss: 1.3863094806671143\n",
      "trial: 2, iter: 6800, curr loss: 1.385288953781128, avg loss: 1.3863000458478927\n",
      "trial: 2, iter: 7000, curr loss: 1.3856803178787231, avg loss: 1.3863834220170974\n",
      "trial: 2, iter: 7200, curr loss: 1.38643217086792, avg loss: 1.3863463944196701\n",
      "trial: 2, iter: 7400, curr loss: 1.3865182399749756, avg loss: 1.3863036441802978\n",
      "trial: 2, iter: 7600, curr loss: 1.3865090608596802, avg loss: 1.3862822270393371\n",
      "trial: 2, iter: 7800, curr loss: 1.3862559795379639, avg loss: 1.386332431435585\n",
      "trial: 2, iter: 8000, curr loss: 1.386365294456482, avg loss: 1.3863187021017074\n",
      "trial: 2, iter: 8200, curr loss: 1.3863312005996704, avg loss: 1.386302386522293\n",
      "trial: 2, iter: 8400, curr loss: 1.3860807418823242, avg loss: 1.3863170170783996\n",
      "trial: 2, iter: 8600, curr loss: 1.3862911462783813, avg loss: 1.3863052034378052\n",
      "trial: 2, iter: 8800, curr loss: 1.3862130641937256, avg loss: 1.3863180935382844\n",
      "trial: 2, iter: 9000, curr loss: 1.3862543106079102, avg loss: 1.3863252079486847\n",
      "trial: 2, iter: 9200, curr loss: 1.3864600658416748, avg loss: 1.386292439699173\n",
      "trial: 2, iter: 9400, curr loss: 1.3863904476165771, avg loss: 1.3863259005546569\n",
      "trial: 2, iter: 9600, curr loss: 1.3862419128417969, avg loss: 1.386329682469368\n",
      "trial: 2, iter: 9800, curr loss: 1.386700987815857, avg loss: 1.3863066571950913\n",
      "trial: 2, iter: 10000, curr loss: 1.386141061782837, avg loss: 1.3863113826513291\n",
      "trial: 2, iter: 10200, curr loss: 1.3863439559936523, avg loss: 1.386341781616211\n",
      "trial: 2, iter: 10400, curr loss: 1.3863836526870728, avg loss: 1.3863029438257217\n",
      "trial: 2, iter: 10600, curr loss: 1.3865549564361572, avg loss: 1.3862931817770003\n",
      "trial: 2, iter: 10800, curr loss: 1.386538028717041, avg loss: 1.3863236498832703\n",
      "trial: 2, iter: 11000, curr loss: 1.3849118947982788, avg loss: 1.3862699592113494\n",
      "trial: 2, iter: 11200, curr loss: 1.3861963748931885, avg loss: 1.3863264530897141\n",
      "trial: 2, iter: 11400, curr loss: 1.3862338066101074, avg loss: 1.3863018131256104\n",
      "trial: 2, iter: 11600, curr loss: 1.3862073421478271, avg loss: 1.386325016617775\n",
      "trial: 2, iter: 11800, curr loss: 1.3864721059799194, avg loss: 1.386292980313301\n",
      "trial: 2, iter: 12000, curr loss: 1.3857285976409912, avg loss: 1.3862854009866714\n",
      "trial: 2, iter: 12200, curr loss: 1.386285424232483, avg loss: 1.3863756769895554\n",
      "trial: 2, iter: 12400, curr loss: 1.386245846748352, avg loss: 1.3863299828767777\n",
      "trial: 2, iter: 12600, curr loss: 1.3861831426620483, avg loss: 1.3863216668367386\n",
      "trial: 2, iter: 12800, curr loss: 1.386205792427063, avg loss: 1.3863051217794418\n",
      "trial: 2, iter: 13000, curr loss: 1.3863897323608398, avg loss: 1.3862992453575134\n",
      "trial: 2, iter: 13200, curr loss: 1.3862911462783813, avg loss: 1.3862969225645065\n",
      "trial: 2, iter: 13400, curr loss: 1.3864842653274536, avg loss: 1.3863110733032227\n",
      "trial: 2, iter: 13600, curr loss: 1.3860979080200195, avg loss: 1.386288736462593\n",
      "trial: 2, iter: 13800, curr loss: 1.3862606287002563, avg loss: 1.3863371086120606\n",
      "trial: 2, iter: 14000, curr loss: 1.3862128257751465, avg loss: 1.3863286691904069\n",
      "trial: 2, iter: 14200, curr loss: 1.3863558769226074, avg loss: 1.3863026344776153\n",
      "trial: 2, iter: 14400, curr loss: 1.3864046335220337, avg loss: 1.3862859117984772\n",
      "trial: 2, iter: 14600, curr loss: 1.3860430717468262, avg loss: 1.38631372153759\n",
      "trial: 2, iter: 14800, curr loss: 1.3865810632705688, avg loss: 1.386325865983963\n",
      "trial: 2, iter: 15000, curr loss: 1.3865175247192383, avg loss: 1.3862999838590622\n",
      "trial: 2, iter: 15200, curr loss: 1.3864264488220215, avg loss: 1.386289432644844\n",
      "trial: 2, iter: 15400, curr loss: 1.3862148523330688, avg loss: 1.3863183236122132\n",
      "trial: 2, iter: 15600, curr loss: 1.3862369060516357, avg loss: 1.3863009464740754\n",
      "trial: 2, ldr: -0.0007652279455214739\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3862783908843994, avg loss: 1.3869947373867035\n",
      "trial: 3, iter: 400, curr loss: 1.390519142150879, avg loss: 1.3867238068580627\n",
      "trial: 3, iter: 600, curr loss: 1.3850785493850708, avg loss: 1.3865949147939682\n",
      "trial: 3, iter: 800, curr loss: 1.38560950756073, avg loss: 1.386532485485077\n",
      "trial: 3, iter: 1000, curr loss: 1.3871517181396484, avg loss: 1.386412400007248\n",
      "trial: 3, iter: 1200, curr loss: 1.3869779109954834, avg loss: 1.3863917261362075\n",
      "trial: 3, iter: 1400, curr loss: 1.3865656852722168, avg loss: 1.3865511387586593\n",
      "trial: 3, iter: 1600, curr loss: 1.3864365816116333, avg loss: 1.3864132499694823\n",
      "trial: 3, iter: 1800, curr loss: 1.3874050378799438, avg loss: 1.3864598041772842\n",
      "trial: 3, iter: 2000, curr loss: 1.385652780532837, avg loss: 1.3864076471328735\n",
      "trial: 3, iter: 2200, curr loss: 1.3867511749267578, avg loss: 1.3864083206653595\n",
      "trial: 3, iter: 2400, curr loss: 1.385858178138733, avg loss: 1.386415974497795\n",
      "trial: 3, iter: 2600, curr loss: 1.3859666585922241, avg loss: 1.3863092809915543\n",
      "trial: 3, iter: 2800, curr loss: 1.3869494199752808, avg loss: 1.3864288461208343\n",
      "trial: 3, iter: 3000, curr loss: 1.385831594467163, avg loss: 1.386385664343834\n",
      "trial: 3, iter: 3200, curr loss: 1.3860905170440674, avg loss: 1.3863466733694076\n",
      "trial: 3, iter: 3400, curr loss: 1.3872967958450317, avg loss: 1.3863066029548645\n",
      "trial: 3, iter: 3600, curr loss: 1.3862957954406738, avg loss: 1.3863427734375\n",
      "trial: 3, iter: 3800, curr loss: 1.3854016065597534, avg loss: 1.3863453859090804\n",
      "trial: 3, iter: 4000, curr loss: 1.3858094215393066, avg loss: 1.3862623000144958\n",
      "trial: 3, iter: 4200, curr loss: 1.3864798545837402, avg loss: 1.3863844561576844\n",
      "trial: 3, iter: 4400, curr loss: 1.386258602142334, avg loss: 1.386345809698105\n",
      "trial: 3, iter: 4600, curr loss: 1.386726975440979, avg loss: 1.3863148152828217\n",
      "trial: 3, iter: 4800, curr loss: 1.3871471881866455, avg loss: 1.3863490635156632\n",
      "trial: 3, iter: 5000, curr loss: 1.3864243030548096, avg loss: 1.3862392848730087\n",
      "trial: 3, iter: 5200, curr loss: 1.3862075805664062, avg loss: 1.386392651796341\n",
      "trial: 3, iter: 5400, curr loss: 1.3862708806991577, avg loss: 1.3863301855325698\n",
      "trial: 3, iter: 5600, curr loss: 1.3870819807052612, avg loss: 1.3863295233249664\n",
      "trial: 3, iter: 5800, curr loss: 1.3858896493911743, avg loss: 1.386374636888504\n",
      "trial: 3, iter: 6000, curr loss: 1.3861403465270996, avg loss: 1.386331924200058\n",
      "trial: 3, iter: 6200, curr loss: 1.3860105276107788, avg loss: 1.3863404554128647\n",
      "trial: 3, iter: 6400, curr loss: 1.3857252597808838, avg loss: 1.386365687251091\n",
      "trial: 3, iter: 6600, curr loss: 1.3866654634475708, avg loss: 1.386338775753975\n",
      "trial: 3, iter: 6800, curr loss: 1.3861767053604126, avg loss: 1.3862996703386308\n",
      "trial: 3, iter: 7000, curr loss: 1.3859889507293701, avg loss: 1.3863310670852662\n",
      "trial: 3, iter: 7200, curr loss: 1.3861725330352783, avg loss: 1.3863158935308457\n",
      "trial: 3, iter: 7400, curr loss: 1.3865020275115967, avg loss: 1.386312068104744\n",
      "trial: 3, iter: 7600, curr loss: 1.3863381147384644, avg loss: 1.3863161087036133\n",
      "trial: 3, iter: 7800, curr loss: 1.3865463733673096, avg loss: 1.3863292068243027\n",
      "trial: 3, iter: 8000, curr loss: 1.3865681886672974, avg loss: 1.3862886852025986\n",
      "trial: 3, iter: 8200, curr loss: 1.3859444856643677, avg loss: 1.3863190686702729\n",
      "trial: 3, iter: 8400, curr loss: 1.3866446018218994, avg loss: 1.38630639731884\n",
      "trial: 3, iter: 8600, curr loss: 1.386051058769226, avg loss: 1.386306984424591\n",
      "trial: 3, iter: 8800, curr loss: 1.3862788677215576, avg loss: 1.3862739008665086\n",
      "trial: 3, iter: 9000, curr loss: 1.3863157033920288, avg loss: 1.3863050776720047\n",
      "trial: 3, iter: 9200, curr loss: 1.3862744569778442, avg loss: 1.3862916880846023\n",
      "trial: 3, iter: 9400, curr loss: 1.386375069618225, avg loss: 1.386303299665451\n",
      "trial: 3, iter: 9600, curr loss: 1.3861727714538574, avg loss: 1.3863032746315003\n",
      "trial: 3, iter: 9800, curr loss: 1.3860963582992554, avg loss: 1.3862959605455398\n",
      "trial: 3, iter: 10000, curr loss: 1.3864885568618774, avg loss: 1.3863023072481155\n",
      "trial: 3, iter: 10200, curr loss: 1.3860751390457153, avg loss: 1.3862986147403717\n",
      "trial: 3, iter: 10400, curr loss: 1.386234164237976, avg loss: 1.3862968480587006\n",
      "trial: 3, iter: 10600, curr loss: 1.3861654996871948, avg loss: 1.3862933731079101\n",
      "trial: 3, iter: 10800, curr loss: 1.3863353729248047, avg loss: 1.386293848156929\n",
      "trial: 3, iter: 11000, curr loss: 1.38627290725708, avg loss: 1.3863119250535965\n",
      "trial: 3, iter: 11200, curr loss: 1.3862724304199219, avg loss: 1.3862965351343155\n",
      "trial: 3, iter: 11400, curr loss: 1.386256217956543, avg loss: 1.386299279332161\n",
      "trial: 3, iter: 11600, curr loss: 1.3859540224075317, avg loss: 1.3863149112462998\n",
      "trial: 3, iter: 11800, curr loss: 1.386420726776123, avg loss: 1.3863139832019806\n",
      "trial: 3, iter: 12000, curr loss: 1.3864376544952393, avg loss: 1.3862968868017196\n",
      "trial: 3, iter: 12200, curr loss: 1.3852016925811768, avg loss: 1.386298572421074\n",
      "trial: 3, iter: 12400, curr loss: 1.3866298198699951, avg loss: 1.3863174778223037\n",
      "trial: 3, iter: 12600, curr loss: 1.386155128479004, avg loss: 1.3862654155492782\n",
      "trial: 3, iter: 12800, curr loss: 1.3861453533172607, avg loss: 1.3863287264108657\n",
      "trial: 3, iter: 13000, curr loss: 1.3868647813796997, avg loss: 1.386327644586563\n",
      "trial: 3, iter: 13200, curr loss: 1.3862379789352417, avg loss: 1.3863124734163284\n",
      "trial: 3, iter: 13400, curr loss: 1.3862099647521973, avg loss: 1.3863141345977783\n",
      "trial: 3, iter: 13600, curr loss: 1.3863977193832397, avg loss: 1.3863107812404634\n",
      "trial: 3, iter: 13800, curr loss: 1.3864450454711914, avg loss: 1.3863035893440248\n",
      "trial: 3, iter: 14000, curr loss: 1.3864176273345947, avg loss: 1.3862974816560745\n",
      "trial: 3, iter: 14200, curr loss: 1.3864613771438599, avg loss: 1.386286705136299\n",
      "trial: 3, iter: 14400, curr loss: 1.3864684104919434, avg loss: 1.3862782365083695\n",
      "trial: 3, iter: 14600, curr loss: 1.3863089084625244, avg loss: 1.386323134303093\n",
      "trial: 3, iter: 14800, curr loss: 1.386515736579895, avg loss: 1.3863068062067032\n",
      "trial: 3, iter: 15000, curr loss: 1.3864045143127441, avg loss: 1.3863063424825668\n",
      "trial: 3, iter: 15200, curr loss: 1.3862669467926025, avg loss: 1.38631172478199\n",
      "trial: 3, iter: 15400, curr loss: 1.3864257335662842, avg loss: 1.3862995594739913\n",
      "trial: 3, iter: 15600, curr loss: 1.3862814903259277, avg loss: 1.3863018548488617\n",
      "trial: 3, ldr: 8.955404337029904e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.38955819606781, avg loss: 1.3870783287286759\n",
      "trial: 4, iter: 400, curr loss: 1.3870576620101929, avg loss: 1.386522770524025\n",
      "trial: 4, iter: 600, curr loss: 1.3873077630996704, avg loss: 1.3866171795129776\n",
      "trial: 4, iter: 800, curr loss: 1.3842931985855103, avg loss: 1.3864090412855148\n",
      "trial: 4, iter: 1000, curr loss: 1.3851081132888794, avg loss: 1.3865379863977432\n",
      "trial: 4, iter: 1200, curr loss: 1.386769413948059, avg loss: 1.386520764231682\n",
      "trial: 4, iter: 1400, curr loss: 1.3866740465164185, avg loss: 1.3863186079263687\n",
      "trial: 4, iter: 1600, curr loss: 1.3873450756072998, avg loss: 1.3863090372085571\n",
      "trial: 4, iter: 1800, curr loss: 1.3857358694076538, avg loss: 1.3864833426475525\n",
      "trial: 4, iter: 2000, curr loss: 1.3881723880767822, avg loss: 1.3862768775224685\n",
      "trial: 4, iter: 2200, curr loss: 1.3860725164413452, avg loss: 1.3864136868715287\n",
      "trial: 4, iter: 2400, curr loss: 1.3865230083465576, avg loss: 1.3863423496484757\n",
      "trial: 4, iter: 2600, curr loss: 1.3867175579071045, avg loss: 1.3863659518957139\n",
      "trial: 4, iter: 2800, curr loss: 1.3875017166137695, avg loss: 1.3863402670621872\n",
      "trial: 4, iter: 3000, curr loss: 1.3865668773651123, avg loss: 1.3863826787471771\n",
      "trial: 4, iter: 3200, curr loss: 1.3863526582717896, avg loss: 1.3863510859012604\n",
      "trial: 4, iter: 3400, curr loss: 1.386403203010559, avg loss: 1.3862932789325715\n",
      "trial: 4, iter: 3600, curr loss: 1.3855658769607544, avg loss: 1.3863201850652696\n",
      "trial: 4, iter: 3800, curr loss: 1.386150598526001, avg loss: 1.386354032754898\n",
      "trial: 4, iter: 4000, curr loss: 1.38614821434021, avg loss: 1.3862993514537811\n",
      "trial: 4, iter: 4200, curr loss: 1.3862394094467163, avg loss: 1.3863091903924942\n",
      "trial: 4, iter: 4400, curr loss: 1.3864389657974243, avg loss: 1.3863888901472092\n",
      "trial: 4, iter: 4600, curr loss: 1.3865838050842285, avg loss: 1.3862927281856536\n",
      "trial: 4, iter: 4800, curr loss: 1.3860929012298584, avg loss: 1.3863518232107161\n",
      "trial: 4, iter: 5000, curr loss: 1.385000467300415, avg loss: 1.3862987631559371\n",
      "trial: 4, iter: 5200, curr loss: 1.3866500854492188, avg loss: 1.3863764137029648\n",
      "trial: 4, iter: 5400, curr loss: 1.3863415718078613, avg loss: 1.386305609345436\n",
      "trial: 4, iter: 5600, curr loss: 1.3862123489379883, avg loss: 1.386309649348259\n",
      "trial: 4, iter: 5800, curr loss: 1.3865326642990112, avg loss: 1.3862949901819228\n",
      "trial: 4, iter: 6000, curr loss: 1.3861366510391235, avg loss: 1.3862949514389038\n",
      "trial: 4, iter: 6200, curr loss: 1.3865625858306885, avg loss: 1.3863181018829345\n",
      "trial: 4, iter: 6400, curr loss: 1.3863986730575562, avg loss: 1.3863034385442734\n",
      "trial: 4, iter: 6600, curr loss: 1.3862946033477783, avg loss: 1.3863206475973129\n",
      "trial: 4, iter: 6800, curr loss: 1.386275291442871, avg loss: 1.3863024938106536\n",
      "trial: 4, iter: 7000, curr loss: 1.3866623640060425, avg loss: 1.3862992030382157\n",
      "trial: 4, iter: 7200, curr loss: 1.3866891860961914, avg loss: 1.3863520342111588\n",
      "trial: 4, iter: 7400, curr loss: 1.3864127397537231, avg loss: 1.3862903010845185\n",
      "trial: 4, iter: 7600, curr loss: 1.3866549730300903, avg loss: 1.3862946665287017\n",
      "trial: 4, iter: 7800, curr loss: 1.386281132698059, avg loss: 1.3863141649961472\n",
      "trial: 4, iter: 8000, curr loss: 1.3864651918411255, avg loss: 1.3863215655088426\n",
      "trial: 4, iter: 8200, curr loss: 1.3860998153686523, avg loss: 1.3862936824560166\n",
      "trial: 4, iter: 8400, curr loss: 1.3864974975585938, avg loss: 1.3863241904973984\n",
      "trial: 4, iter: 8600, curr loss: 1.38616943359375, avg loss: 1.3862944930791854\n",
      "trial: 4, iter: 8800, curr loss: 1.3863770961761475, avg loss: 1.3862997442483902\n",
      "trial: 4, iter: 9000, curr loss: 1.3863320350646973, avg loss: 1.3862991601228714\n",
      "trial: 4, iter: 9200, curr loss: 1.3865677118301392, avg loss: 1.3863835644721985\n",
      "trial: 4, iter: 9400, curr loss: 1.3863931894302368, avg loss: 1.3863052529096604\n",
      "trial: 4, iter: 9600, curr loss: 1.3861428499221802, avg loss: 1.3863136345148086\n",
      "trial: 4, iter: 9800, curr loss: 1.3872710466384888, avg loss: 1.386288068294525\n",
      "trial: 4, iter: 10000, curr loss: 1.3850629329681396, avg loss: 1.3862896108627318\n",
      "trial: 4, iter: 10200, curr loss: 1.3857070207595825, avg loss: 1.3863224244117738\n",
      "trial: 4, iter: 10400, curr loss: 1.3854024410247803, avg loss: 1.3862842619419098\n",
      "trial: 4, iter: 10600, curr loss: 1.386797547340393, avg loss: 1.386357558965683\n",
      "trial: 4, iter: 10800, curr loss: 1.385977029800415, avg loss: 1.3863409572839738\n",
      "trial: 4, iter: 11000, curr loss: 1.385959506034851, avg loss: 1.3863156342506409\n",
      "trial: 4, iter: 11200, curr loss: 1.3863164186477661, avg loss: 1.3863530856370927\n",
      "trial: 4, iter: 11400, curr loss: 1.3856000900268555, avg loss: 1.3863029509782792\n",
      "trial: 4, iter: 11600, curr loss: 1.3866016864776611, avg loss: 1.3863856095075606\n",
      "trial: 4, iter: 11800, curr loss: 1.3862621784210205, avg loss: 1.386327766776085\n",
      "trial: 4, iter: 12000, curr loss: 1.3861497640609741, avg loss: 1.3862961202859878\n",
      "trial: 4, iter: 12200, curr loss: 1.3862172365188599, avg loss: 1.3862986624240876\n",
      "trial: 4, iter: 12400, curr loss: 1.3863109350204468, avg loss: 1.3863267821073533\n",
      "trial: 4, iter: 12600, curr loss: 1.3864538669586182, avg loss: 1.386299877166748\n",
      "trial: 4, iter: 12800, curr loss: 1.3863776922225952, avg loss: 1.3862961173057555\n",
      "trial: 4, iter: 13000, curr loss: 1.385989785194397, avg loss: 1.3862847316265106\n",
      "trial: 4, iter: 13200, curr loss: 1.3857139348983765, avg loss: 1.386303972005844\n",
      "trial: 4, iter: 13400, curr loss: 1.3863980770111084, avg loss: 1.386311662197113\n",
      "trial: 4, iter: 13600, curr loss: 1.3862745761871338, avg loss: 1.3863140165805816\n",
      "trial: 4, iter: 13800, curr loss: 1.3862272500991821, avg loss: 1.386303090453148\n",
      "trial: 4, iter: 14000, curr loss: 1.3862866163253784, avg loss: 1.3862981933355332\n",
      "trial: 4, iter: 14200, curr loss: 1.3865281343460083, avg loss: 1.3862865954637527\n",
      "trial: 4, iter: 14400, curr loss: 1.38631010055542, avg loss: 1.386312910914421\n",
      "trial: 4, iter: 14600, curr loss: 1.3862632513046265, avg loss: 1.3862761092185973\n",
      "trial: 4, iter: 14800, curr loss: 1.3862698078155518, avg loss: 1.3863109743595123\n",
      "trial: 4, iter: 15000, curr loss: 1.3863880634307861, avg loss: 1.3863130021095276\n",
      "trial: 4, iter: 15200, curr loss: 1.386204481124878, avg loss: 1.386299256682396\n",
      "trial: 4, iter: 15400, curr loss: 1.386396884918213, avg loss: 1.3863005352020263\n",
      "trial: 4, iter: 15600, curr loss: 1.3863897323608398, avg loss: 1.3862943792343139\n",
      "trial: 4, ldr: 0.00047687574988231063\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3888922929763794, avg loss: 1.3873978316783906\n",
      "trial: 5, iter: 400, curr loss: 1.386756181716919, avg loss: 1.386692506670952\n",
      "trial: 5, iter: 600, curr loss: 1.3894340991973877, avg loss: 1.3865108048915864\n",
      "trial: 5, iter: 800, curr loss: 1.386828899383545, avg loss: 1.3865001142024993\n",
      "trial: 5, iter: 1000, curr loss: 1.3861151933670044, avg loss: 1.386466474533081\n",
      "trial: 5, iter: 1200, curr loss: 1.386076807975769, avg loss: 1.3863973891735077\n",
      "trial: 5, iter: 1400, curr loss: 1.385727882385254, avg loss: 1.3863575464487077\n",
      "trial: 5, iter: 1600, curr loss: 1.3861864805221558, avg loss: 1.3863722449541092\n",
      "trial: 5, iter: 1800, curr loss: 1.3867764472961426, avg loss: 1.3864336544275284\n",
      "trial: 5, iter: 2000, curr loss: 1.386156439781189, avg loss: 1.3863539761304855\n",
      "trial: 5, iter: 2200, curr loss: 1.3872795104980469, avg loss: 1.3863533639907837\n",
      "trial: 5, iter: 2400, curr loss: 1.385789394378662, avg loss: 1.386405604481697\n",
      "trial: 5, iter: 2600, curr loss: 1.388359785079956, avg loss: 1.3862808048725128\n",
      "trial: 5, iter: 2800, curr loss: 1.3890315294265747, avg loss: 1.3864479410648345\n",
      "trial: 5, iter: 3000, curr loss: 1.385106086730957, avg loss: 1.3864707279205322\n",
      "trial: 5, iter: 3200, curr loss: 1.3868379592895508, avg loss: 1.386308246254921\n",
      "trial: 5, iter: 3400, curr loss: 1.38540518283844, avg loss: 1.3863992929458617\n",
      "trial: 5, iter: 3600, curr loss: 1.3858953714370728, avg loss: 1.3864095944166184\n",
      "trial: 5, iter: 3800, curr loss: 1.3855414390563965, avg loss: 1.3863127607107162\n",
      "trial: 5, iter: 4000, curr loss: 1.3866890668869019, avg loss: 1.386332053542137\n",
      "trial: 5, iter: 4200, curr loss: 1.3862018585205078, avg loss: 1.386354265809059\n",
      "trial: 5, iter: 4400, curr loss: 1.3863352537155151, avg loss: 1.3863775396347047\n",
      "trial: 5, iter: 4600, curr loss: 1.3861849308013916, avg loss: 1.3863300985097886\n",
      "trial: 5, iter: 4800, curr loss: 1.386082649230957, avg loss: 1.3863052141666412\n",
      "trial: 5, iter: 5000, curr loss: 1.3864436149597168, avg loss: 1.386332135796547\n",
      "trial: 5, iter: 5200, curr loss: 1.3863532543182373, avg loss: 1.386319681406021\n",
      "trial: 5, iter: 5400, curr loss: 1.3859596252441406, avg loss: 1.3862919199466706\n",
      "trial: 5, iter: 5600, curr loss: 1.3864374160766602, avg loss: 1.3863032805919646\n",
      "trial: 5, iter: 5800, curr loss: 1.3865197896957397, avg loss: 1.3863051003217697\n",
      "trial: 5, iter: 6000, curr loss: 1.3855258226394653, avg loss: 1.3862664496898651\n",
      "trial: 5, iter: 6200, curr loss: 1.3860667943954468, avg loss: 1.386316064596176\n",
      "trial: 5, iter: 6400, curr loss: 1.3862191438674927, avg loss: 1.3862986451387405\n",
      "trial: 5, iter: 6600, curr loss: 1.3864598274230957, avg loss: 1.3863196325302125\n",
      "trial: 5, iter: 6800, curr loss: 1.3861403465270996, avg loss: 1.3863510173559188\n",
      "trial: 5, iter: 7000, curr loss: 1.3860254287719727, avg loss: 1.3863084572553634\n",
      "trial: 5, iter: 7200, curr loss: 1.3861122131347656, avg loss: 1.3863220143318176\n",
      "trial: 5, iter: 7400, curr loss: 1.38612961769104, avg loss: 1.3863136941194534\n",
      "trial: 5, iter: 7600, curr loss: 1.386371374130249, avg loss: 1.3863155955076218\n",
      "trial: 5, iter: 7800, curr loss: 1.3868016004562378, avg loss: 1.386303830742836\n",
      "trial: 5, iter: 8000, curr loss: 1.385032296180725, avg loss: 1.3863103181123733\n",
      "trial: 5, iter: 8200, curr loss: 1.385878562927246, avg loss: 1.3863158696889877\n",
      "trial: 5, iter: 8400, curr loss: 1.386177659034729, avg loss: 1.3863430124521257\n",
      "trial: 5, iter: 8600, curr loss: 1.3866455554962158, avg loss: 1.3863070595264435\n",
      "trial: 5, iter: 8800, curr loss: 1.3861417770385742, avg loss: 1.3863061010837554\n",
      "trial: 5, iter: 9000, curr loss: 1.3863517045974731, avg loss: 1.3863106614351273\n",
      "trial: 5, iter: 9200, curr loss: 1.3865300416946411, avg loss: 1.3863223791122437\n",
      "trial: 5, iter: 9400, curr loss: 1.3863813877105713, avg loss: 1.3862966704368591\n",
      "trial: 5, iter: 9600, curr loss: 1.3864126205444336, avg loss: 1.3863014960289002\n",
      "trial: 5, iter: 9800, curr loss: 1.3858987092971802, avg loss: 1.3862881171703338\n",
      "trial: 5, iter: 10000, curr loss: 1.3864384889602661, avg loss: 1.3863206154108048\n",
      "trial: 5, iter: 10200, curr loss: 1.3859397172927856, avg loss: 1.3863150048255921\n",
      "trial: 5, iter: 10400, curr loss: 1.3858894109725952, avg loss: 1.386330978870392\n",
      "trial: 5, iter: 10600, curr loss: 1.3866124153137207, avg loss: 1.3863121604919433\n",
      "trial: 5, iter: 10800, curr loss: 1.38606858253479, avg loss: 1.38630042552948\n",
      "trial: 5, iter: 11000, curr loss: 1.3860502243041992, avg loss: 1.3863342010974884\n",
      "trial: 5, iter: 11200, curr loss: 1.3861693143844604, avg loss: 1.3863983345031738\n",
      "trial: 5, iter: 11400, curr loss: 1.3867230415344238, avg loss: 1.3862982445955276\n",
      "trial: 5, iter: 11600, curr loss: 1.385896921157837, avg loss: 1.3863028490543365\n",
      "trial: 5, iter: 11800, curr loss: 1.3867683410644531, avg loss: 1.3863596057891845\n",
      "trial: 5, iter: 12000, curr loss: 1.3859869241714478, avg loss: 1.3863174772262574\n",
      "trial: 5, iter: 12200, curr loss: 1.3863576650619507, avg loss: 1.3863129550218583\n",
      "trial: 5, iter: 12400, curr loss: 1.3861455917358398, avg loss: 1.3862885570526122\n",
      "trial: 5, iter: 12600, curr loss: 1.3865139484405518, avg loss: 1.3862987399101256\n",
      "trial: 5, iter: 12800, curr loss: 1.3861268758773804, avg loss: 1.3863091111183166\n",
      "trial: 5, iter: 13000, curr loss: 1.3863461017608643, avg loss: 1.3863158220052718\n",
      "trial: 5, iter: 13200, curr loss: 1.386367678642273, avg loss: 1.3863002675771714\n",
      "trial: 5, iter: 13400, curr loss: 1.3863202333450317, avg loss: 1.386299628019333\n",
      "trial: 5, iter: 13600, curr loss: 1.3862346410751343, avg loss: 1.386284721493721\n",
      "trial: 5, iter: 13800, curr loss: 1.3865002393722534, avg loss: 1.3862802159786225\n",
      "trial: 5, iter: 14000, curr loss: 1.3867113590240479, avg loss: 1.3863163232803344\n",
      "trial: 5, iter: 14200, curr loss: 1.3867894411087036, avg loss: 1.3862989449501038\n",
      "trial: 5, iter: 14400, curr loss: 1.386791706085205, avg loss: 1.3863008153438567\n",
      "trial: 5, iter: 14600, curr loss: 1.3864524364471436, avg loss: 1.3863393396139145\n",
      "trial: 5, iter: 14800, curr loss: 1.387328863143921, avg loss: 1.3862933045625687\n",
      "trial: 5, iter: 15000, curr loss: 1.3871711492538452, avg loss: 1.386310630440712\n",
      "trial: 5, iter: 15200, curr loss: 1.3866808414459229, avg loss: 1.3862835890054703\n",
      "trial: 5, iter: 15400, curr loss: 1.3864117860794067, avg loss: 1.3863649421930313\n",
      "trial: 5, iter: 15600, curr loss: 1.3863177299499512, avg loss: 1.3862881433963776\n",
      "trial: 5, ldr: 0.0001843166392063722\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 8.650369127281011e-05\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.385762095451355, avg loss: 1.3872843998670579\n",
      "trial: 1, iter: 400, curr loss: 1.3858349323272705, avg loss: 1.3867114466428756\n",
      "trial: 1, iter: 600, curr loss: 1.3862311840057373, avg loss: 1.3865989953279496\n",
      "trial: 1, iter: 800, curr loss: 1.3871170282363892, avg loss: 1.3865332287549972\n",
      "trial: 1, iter: 1000, curr loss: 1.387419581413269, avg loss: 1.3865987139940261\n",
      "trial: 1, iter: 1200, curr loss: 1.3870117664337158, avg loss: 1.386620060801506\n",
      "trial: 1, iter: 1400, curr loss: 1.3855719566345215, avg loss: 1.3864559543132782\n",
      "trial: 1, iter: 1600, curr loss: 1.3864152431488037, avg loss: 1.3865244603157043\n",
      "trial: 1, iter: 1800, curr loss: 1.3855305910110474, avg loss: 1.3863719779253005\n",
      "trial: 1, iter: 2000, curr loss: 1.3857841491699219, avg loss: 1.3863573229312898\n",
      "trial: 1, iter: 2200, curr loss: 1.3886905908584595, avg loss: 1.386338123679161\n",
      "trial: 1, iter: 2400, curr loss: 1.3856115341186523, avg loss: 1.3863652569055558\n",
      "trial: 1, iter: 2600, curr loss: 1.384587049484253, avg loss: 1.386290802359581\n",
      "trial: 1, iter: 2800, curr loss: 1.3872283697128296, avg loss: 1.38635655939579\n",
      "trial: 1, iter: 3000, curr loss: 1.385010004043579, avg loss: 1.3863296622037888\n",
      "trial: 1, iter: 3200, curr loss: 1.3869616985321045, avg loss: 1.3863560378551483\n",
      "trial: 1, iter: 3400, curr loss: 1.3860329389572144, avg loss: 1.3863590782880784\n",
      "trial: 1, iter: 3600, curr loss: 1.3854421377182007, avg loss: 1.3863311797380446\n",
      "trial: 1, iter: 3800, curr loss: 1.385904312133789, avg loss: 1.386345574259758\n",
      "trial: 1, iter: 4000, curr loss: 1.3863011598587036, avg loss: 1.3862995874881745\n",
      "trial: 1, iter: 4200, curr loss: 1.3848470449447632, avg loss: 1.386295999288559\n",
      "trial: 1, iter: 4400, curr loss: 1.3867322206497192, avg loss: 1.3863974356651305\n",
      "trial: 1, iter: 4600, curr loss: 1.3861229419708252, avg loss: 1.386336146593094\n",
      "trial: 1, iter: 4800, curr loss: 1.3855838775634766, avg loss: 1.3862995165586471\n",
      "trial: 1, iter: 5000, curr loss: 1.387466549873352, avg loss: 1.3863107639551162\n",
      "trial: 1, iter: 5200, curr loss: 1.3863483667373657, avg loss: 1.3864127999544145\n",
      "trial: 1, iter: 5400, curr loss: 1.3861675262451172, avg loss: 1.3863318747282027\n",
      "trial: 1, iter: 5600, curr loss: 1.3854643106460571, avg loss: 1.386414927840233\n",
      "trial: 1, iter: 5800, curr loss: 1.3871934413909912, avg loss: 1.3864153480529786\n",
      "trial: 1, iter: 6000, curr loss: 1.3860045671463013, avg loss: 1.3863706839084626\n",
      "trial: 1, iter: 6200, curr loss: 1.3857802152633667, avg loss: 1.386294954419136\n",
      "trial: 1, iter: 6400, curr loss: 1.3868905305862427, avg loss: 1.3863556557893753\n",
      "trial: 1, iter: 6600, curr loss: 1.3866899013519287, avg loss: 1.3863117432594299\n",
      "trial: 1, iter: 6800, curr loss: 1.3864638805389404, avg loss: 1.386362288594246\n",
      "trial: 1, iter: 7000, curr loss: 1.3852107524871826, avg loss: 1.3863026773929596\n",
      "trial: 1, iter: 7200, curr loss: 1.3870455026626587, avg loss: 1.3864028346538544\n",
      "trial: 1, iter: 7400, curr loss: 1.3862396478652954, avg loss: 1.3863254016637803\n",
      "trial: 1, iter: 7600, curr loss: 1.3861671686172485, avg loss: 1.3863491004705428\n",
      "trial: 1, iter: 7800, curr loss: 1.3862388134002686, avg loss: 1.3863336479663848\n",
      "trial: 1, iter: 8000, curr loss: 1.3861944675445557, avg loss: 1.386307154893875\n",
      "trial: 1, iter: 8200, curr loss: 1.3860677480697632, avg loss: 1.3863748109340668\n",
      "trial: 1, iter: 8400, curr loss: 1.3862218856811523, avg loss: 1.3863428956270218\n",
      "trial: 1, iter: 8600, curr loss: 1.3862965106964111, avg loss: 1.386306265592575\n",
      "trial: 1, iter: 8800, curr loss: 1.3865560293197632, avg loss: 1.3863039046525956\n",
      "trial: 1, iter: 9000, curr loss: 1.3862890005111694, avg loss: 1.3863030576705933\n",
      "trial: 1, iter: 9200, curr loss: 1.3861424922943115, avg loss: 1.3863043588399888\n",
      "trial: 1, iter: 9400, curr loss: 1.386308193206787, avg loss: 1.3863049817085267\n",
      "trial: 1, iter: 9600, curr loss: 1.386262059211731, avg loss: 1.3862947499752045\n",
      "trial: 1, iter: 9800, curr loss: 1.3862823247909546, avg loss: 1.3863009369373323\n",
      "trial: 1, iter: 10000, curr loss: 1.3862124681472778, avg loss: 1.38629565179348\n",
      "trial: 1, iter: 10200, curr loss: 1.386245608329773, avg loss: 1.3863165122270584\n",
      "trial: 1, iter: 10400, curr loss: 1.3864237070083618, avg loss: 1.386314051747322\n",
      "trial: 1, iter: 10600, curr loss: 1.3866204023361206, avg loss: 1.3862793564796447\n",
      "trial: 1, iter: 10800, curr loss: 1.3868311643600464, avg loss: 1.3862788951396943\n",
      "trial: 1, iter: 11000, curr loss: 1.3863685131072998, avg loss: 1.3863753378391266\n",
      "trial: 1, iter: 11200, curr loss: 1.3863978385925293, avg loss: 1.3863205003738404\n",
      "trial: 1, iter: 11400, curr loss: 1.3861491680145264, avg loss: 1.3862816494703294\n",
      "trial: 1, iter: 11600, curr loss: 1.3862240314483643, avg loss: 1.3862958925962447\n",
      "trial: 1, iter: 11800, curr loss: 1.3863751888275146, avg loss: 1.3863358396291732\n",
      "trial: 1, iter: 12000, curr loss: 1.3859816789627075, avg loss: 1.3862919890880585\n",
      "trial: 1, iter: 12200, curr loss: 1.3863962888717651, avg loss: 1.3863584977388381\n",
      "trial: 1, iter: 12400, curr loss: 1.3858999013900757, avg loss: 1.3862875151634215\n",
      "trial: 1, iter: 12600, curr loss: 1.385582447052002, avg loss: 1.3862783485651016\n",
      "trial: 1, iter: 12800, curr loss: 1.386152744293213, avg loss: 1.3862983417510986\n",
      "trial: 1, iter: 13000, curr loss: 1.3863039016723633, avg loss: 1.38633908867836\n",
      "trial: 1, iter: 13200, curr loss: 1.386551022529602, avg loss: 1.3862910848855972\n",
      "trial: 1, iter: 13400, curr loss: 1.3870468139648438, avg loss: 1.386302134990692\n",
      "trial: 1, iter: 13600, curr loss: 1.3863142728805542, avg loss: 1.3863237071037293\n",
      "trial: 1, iter: 13800, curr loss: 1.3861908912658691, avg loss: 1.3862926119565964\n",
      "trial: 1, iter: 14000, curr loss: 1.386337161064148, avg loss: 1.3863136506080627\n",
      "trial: 1, iter: 14200, curr loss: 1.3862130641937256, avg loss: 1.3862933218479156\n",
      "trial: 1, iter: 14400, curr loss: 1.3864688873291016, avg loss: 1.38628981590271\n",
      "trial: 1, iter: 14600, curr loss: 1.3863838911056519, avg loss: 1.3862968200445176\n",
      "trial: 1, iter: 14800, curr loss: 1.386570692062378, avg loss: 1.3863176614046098\n",
      "trial: 1, iter: 15000, curr loss: 1.3863122463226318, avg loss: 1.3863226783275604\n",
      "trial: 1, iter: 15200, curr loss: 1.386299729347229, avg loss: 1.3862880408763885\n",
      "trial: 1, iter: 15400, curr loss: 1.386167049407959, avg loss: 1.3862836509943008\n",
      "trial: 1, iter: 15600, curr loss: 1.3861745595932007, avg loss: 1.386306156516075\n",
      "trial: 1, ldr: -0.00026011018780991435\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3896498680114746, avg loss: 1.3872241377830505\n",
      "trial: 2, iter: 400, curr loss: 1.3858517408370972, avg loss: 1.386850233078003\n",
      "trial: 2, iter: 600, curr loss: 1.3874127864837646, avg loss: 1.3864380824565887\n",
      "trial: 2, iter: 800, curr loss: 1.3863401412963867, avg loss: 1.3865541410446167\n",
      "trial: 2, iter: 1000, curr loss: 1.3866207599639893, avg loss: 1.3864790391921997\n",
      "trial: 2, iter: 1200, curr loss: 1.3855544328689575, avg loss: 1.386367460489273\n",
      "trial: 2, iter: 1400, curr loss: 1.3852587938308716, avg loss: 1.3864071047306061\n",
      "trial: 2, iter: 1600, curr loss: 1.3862850666046143, avg loss: 1.38635256588459\n",
      "trial: 2, iter: 1800, curr loss: 1.3853570222854614, avg loss: 1.3862891733646392\n",
      "trial: 2, iter: 2000, curr loss: 1.3853484392166138, avg loss: 1.3864091676473618\n",
      "trial: 2, iter: 2200, curr loss: 1.387455940246582, avg loss: 1.386424914598465\n",
      "trial: 2, iter: 2400, curr loss: 1.38617742061615, avg loss: 1.3864764422178268\n",
      "trial: 2, iter: 2600, curr loss: 1.3854575157165527, avg loss: 1.3863297295570374\n",
      "trial: 2, iter: 2800, curr loss: 1.3865511417388916, avg loss: 1.3863193756341934\n",
      "trial: 2, iter: 3000, curr loss: 1.3864340782165527, avg loss: 1.3864029264450073\n",
      "trial: 2, iter: 3200, curr loss: 1.3865652084350586, avg loss: 1.3863021463155747\n",
      "trial: 2, iter: 3400, curr loss: 1.386696457862854, avg loss: 1.3863573575019836\n",
      "trial: 2, iter: 3600, curr loss: 1.386222004890442, avg loss: 1.3862901031970978\n",
      "trial: 2, iter: 3800, curr loss: 1.386246919631958, avg loss: 1.3863992291688918\n",
      "trial: 2, iter: 4000, curr loss: 1.3860341310501099, avg loss: 1.3862639611959457\n",
      "trial: 2, iter: 4200, curr loss: 1.38624906539917, avg loss: 1.3864038652181625\n",
      "trial: 2, iter: 4400, curr loss: 1.3865253925323486, avg loss: 1.3863044917583465\n",
      "trial: 2, iter: 4600, curr loss: 1.3861466646194458, avg loss: 1.386369281411171\n",
      "trial: 2, iter: 4800, curr loss: 1.3862158060073853, avg loss: 1.3863183641433716\n",
      "trial: 2, iter: 5000, curr loss: 1.3860629796981812, avg loss: 1.3863293969631194\n",
      "trial: 2, iter: 5200, curr loss: 1.3874399662017822, avg loss: 1.386215467453003\n",
      "trial: 2, iter: 5400, curr loss: 1.3863821029663086, avg loss: 1.3863719034194946\n",
      "trial: 2, iter: 5600, curr loss: 1.386724829673767, avg loss: 1.3863136488199235\n",
      "trial: 2, iter: 5800, curr loss: 1.3859888315200806, avg loss: 1.386325052380562\n",
      "trial: 2, iter: 6000, curr loss: 1.3872382640838623, avg loss: 1.3863431322574615\n",
      "trial: 2, iter: 6200, curr loss: 1.386406421661377, avg loss: 1.3864392745494842\n",
      "trial: 2, iter: 6400, curr loss: 1.387353539466858, avg loss: 1.3863377821445466\n",
      "trial: 2, iter: 6600, curr loss: 1.3862438201904297, avg loss: 1.3863457185029984\n",
      "trial: 2, iter: 6800, curr loss: 1.3866183757781982, avg loss: 1.3863171273469925\n",
      "trial: 2, iter: 7000, curr loss: 1.3870080709457397, avg loss: 1.3863696324825288\n",
      "trial: 2, iter: 7200, curr loss: 1.3858407735824585, avg loss: 1.3863420075178146\n",
      "trial: 2, iter: 7400, curr loss: 1.3859682083129883, avg loss: 1.386303541660309\n",
      "trial: 2, iter: 7600, curr loss: 1.3863391876220703, avg loss: 1.3863338893651962\n",
      "trial: 2, iter: 7800, curr loss: 1.3863887786865234, avg loss: 1.3863048964738847\n",
      "trial: 2, iter: 8000, curr loss: 1.3861637115478516, avg loss: 1.386315302848816\n",
      "trial: 2, iter: 8200, curr loss: 1.3864588737487793, avg loss: 1.3863126939535142\n",
      "trial: 2, iter: 8400, curr loss: 1.3862344026565552, avg loss: 1.3862962448596954\n",
      "trial: 2, iter: 8600, curr loss: 1.3866523504257202, avg loss: 1.386284312605858\n",
      "trial: 2, iter: 8800, curr loss: 1.3863166570663452, avg loss: 1.3863099640607834\n",
      "trial: 2, iter: 9000, curr loss: 1.3866177797317505, avg loss: 1.3863096153736114\n",
      "trial: 2, iter: 9200, curr loss: 1.386795163154602, avg loss: 1.3863054013252258\n",
      "trial: 2, iter: 9400, curr loss: 1.3862735033035278, avg loss: 1.3863277745246887\n",
      "trial: 2, iter: 9600, curr loss: 1.3862648010253906, avg loss: 1.3863030415773392\n",
      "trial: 2, iter: 9800, curr loss: 1.3864799737930298, avg loss: 1.3862983244657516\n",
      "trial: 2, iter: 10000, curr loss: 1.3863658905029297, avg loss: 1.386306037902832\n",
      "trial: 2, iter: 10200, curr loss: 1.3864165544509888, avg loss: 1.3862984496355057\n",
      "trial: 2, iter: 10400, curr loss: 1.3873447179794312, avg loss: 1.386335114836693\n",
      "trial: 2, iter: 10600, curr loss: 1.3855547904968262, avg loss: 1.386453612446785\n",
      "trial: 2, iter: 10800, curr loss: 1.386725664138794, avg loss: 1.3863655865192412\n",
      "trial: 2, iter: 11000, curr loss: 1.3867502212524414, avg loss: 1.3862949013710022\n",
      "trial: 2, iter: 11200, curr loss: 1.3862866163253784, avg loss: 1.3863388353586197\n",
      "trial: 2, iter: 11400, curr loss: 1.386263132095337, avg loss: 1.3863155341148377\n",
      "trial: 2, iter: 11600, curr loss: 1.3862859010696411, avg loss: 1.3863044106960296\n",
      "trial: 2, iter: 11800, curr loss: 1.3862056732177734, avg loss: 1.3862969446182252\n",
      "trial: 2, iter: 12000, curr loss: 1.3862507343292236, avg loss: 1.3862974274158477\n",
      "trial: 2, iter: 12200, curr loss: 1.386312484741211, avg loss: 1.3863010442256927\n",
      "trial: 2, iter: 12400, curr loss: 1.386390209197998, avg loss: 1.3862700110673905\n",
      "trial: 2, iter: 12600, curr loss: 1.38632071018219, avg loss: 1.3863111066818237\n",
      "trial: 2, iter: 12800, curr loss: 1.386375069618225, avg loss: 1.3863077038526535\n",
      "trial: 2, iter: 13000, curr loss: 1.3863554000854492, avg loss: 1.3863238680362702\n",
      "trial: 2, iter: 13200, curr loss: 1.385941505432129, avg loss: 1.3862889897823334\n",
      "trial: 2, iter: 13400, curr loss: 1.3864004611968994, avg loss: 1.3862868398427963\n",
      "trial: 2, iter: 13600, curr loss: 1.3862814903259277, avg loss: 1.3863026243448258\n",
      "trial: 2, iter: 13800, curr loss: 1.3863035440444946, avg loss: 1.386295136809349\n",
      "trial: 2, iter: 14000, curr loss: 1.3862942457199097, avg loss: 1.38629477083683\n",
      "trial: 2, iter: 14200, curr loss: 1.3862941265106201, avg loss: 1.3862940555810928\n",
      "trial: 2, iter: 14400, curr loss: 1.3863210678100586, avg loss: 1.386307471394539\n",
      "trial: 2, iter: 14600, curr loss: 1.3862898349761963, avg loss: 1.3862943279743194\n",
      "trial: 2, iter: 14800, curr loss: 1.3863071203231812, avg loss: 1.3862946653366088\n",
      "trial: 2, iter: 15000, curr loss: 1.3862943649291992, avg loss: 1.3862954062223434\n",
      "trial: 2, iter: 15200, curr loss: 1.3862942457199097, avg loss: 1.3862943440675735\n",
      "trial: 2, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.3862946873903275\n",
      "trial: 2, iter: 15600, curr loss: 1.3863433599472046, avg loss: 1.3862944024801254\n",
      "trial: 2, ldr: -6.954961918381741e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3871504068374634, avg loss: 1.3874433010816574\n",
      "trial: 3, iter: 400, curr loss: 1.384012222290039, avg loss: 1.3867361396551132\n",
      "trial: 3, iter: 600, curr loss: 1.3868319988250732, avg loss: 1.3865543103218079\n",
      "trial: 3, iter: 800, curr loss: 1.38713800907135, avg loss: 1.386574653983116\n",
      "trial: 3, iter: 1000, curr loss: 1.3862824440002441, avg loss: 1.3865315061807633\n",
      "trial: 3, iter: 1200, curr loss: 1.387169599533081, avg loss: 1.3864732640981674\n",
      "trial: 3, iter: 1400, curr loss: 1.388213872909546, avg loss: 1.3863607406616212\n",
      "trial: 3, iter: 1600, curr loss: 1.386824607849121, avg loss: 1.386448090672493\n",
      "trial: 3, iter: 1800, curr loss: 1.3866357803344727, avg loss: 1.38635589659214\n",
      "trial: 3, iter: 2000, curr loss: 1.3843505382537842, avg loss: 1.3863609147071838\n",
      "trial: 3, iter: 2200, curr loss: 1.387069582939148, avg loss: 1.3863797771930695\n",
      "trial: 3, iter: 2400, curr loss: 1.3888146877288818, avg loss: 1.3864072877168656\n",
      "trial: 3, iter: 2600, curr loss: 1.3862223625183105, avg loss: 1.386405485868454\n",
      "trial: 3, iter: 2800, curr loss: 1.3862017393112183, avg loss: 1.386339035630226\n",
      "trial: 3, iter: 3000, curr loss: 1.3863953351974487, avg loss: 1.386375492811203\n",
      "trial: 3, iter: 3200, curr loss: 1.3862000703811646, avg loss: 1.386354694366455\n",
      "trial: 3, iter: 3400, curr loss: 1.3877787590026855, avg loss: 1.3863619351387024\n",
      "trial: 3, iter: 3600, curr loss: 1.3855342864990234, avg loss: 1.3863540357351303\n",
      "trial: 3, iter: 3800, curr loss: 1.3864341974258423, avg loss: 1.3863395518064499\n",
      "trial: 3, iter: 4000, curr loss: 1.3860896825790405, avg loss: 1.38631722509861\n",
      "trial: 3, iter: 4200, curr loss: 1.3861042261123657, avg loss: 1.3863981974124908\n",
      "trial: 3, iter: 4400, curr loss: 1.3861101865768433, avg loss: 1.3862781083583833\n",
      "trial: 3, iter: 4600, curr loss: 1.386057734489441, avg loss: 1.3863446289300918\n",
      "trial: 3, iter: 4800, curr loss: 1.3867493867874146, avg loss: 1.3864041066169739\n",
      "trial: 3, iter: 5000, curr loss: 1.3858966827392578, avg loss: 1.3863464361429214\n",
      "trial: 3, iter: 5200, curr loss: 1.3858790397644043, avg loss: 1.3864401352405549\n",
      "trial: 3, iter: 5400, curr loss: 1.3860076665878296, avg loss: 1.3863358503580094\n",
      "trial: 3, iter: 5600, curr loss: 1.3861684799194336, avg loss: 1.386364997625351\n",
      "trial: 3, iter: 5800, curr loss: 1.3868083953857422, avg loss: 1.3863093692064286\n",
      "trial: 3, iter: 6000, curr loss: 1.3863425254821777, avg loss: 1.386333938241005\n",
      "trial: 3, iter: 6200, curr loss: 1.3861647844314575, avg loss: 1.3863202184438705\n",
      "trial: 3, iter: 6400, curr loss: 1.3863917589187622, avg loss: 1.3863265305757522\n",
      "trial: 3, iter: 6600, curr loss: 1.3865810632705688, avg loss: 1.386304767727852\n",
      "trial: 3, iter: 6800, curr loss: 1.3863375186920166, avg loss: 1.3863018673658372\n",
      "trial: 3, iter: 7000, curr loss: 1.3857702016830444, avg loss: 1.3863094687461852\n",
      "trial: 3, iter: 7200, curr loss: 1.3862743377685547, avg loss: 1.3863204091787338\n",
      "trial: 3, iter: 7400, curr loss: 1.3860480785369873, avg loss: 1.3862928003072739\n",
      "trial: 3, iter: 7600, curr loss: 1.3864123821258545, avg loss: 1.3863031357526778\n",
      "trial: 3, iter: 7800, curr loss: 1.386174201965332, avg loss: 1.3862927144765853\n",
      "trial: 3, iter: 8000, curr loss: 1.3861695528030396, avg loss: 1.3863100945949554\n",
      "trial: 3, iter: 8200, curr loss: 1.3862189054489136, avg loss: 1.3863205188512802\n",
      "trial: 3, iter: 8400, curr loss: 1.3864141702651978, avg loss: 1.3862935239076615\n",
      "trial: 3, iter: 8600, curr loss: 1.3863022327423096, avg loss: 1.3863220089673995\n",
      "trial: 3, iter: 8800, curr loss: 1.3860148191452026, avg loss: 1.3863427978754044\n",
      "trial: 3, iter: 9000, curr loss: 1.3861792087554932, avg loss: 1.3863053393363953\n",
      "trial: 3, iter: 9200, curr loss: 1.38619863986969, avg loss: 1.386299570798874\n",
      "trial: 3, iter: 9400, curr loss: 1.3862297534942627, avg loss: 1.3863104611635209\n",
      "trial: 3, iter: 9600, curr loss: 1.3860647678375244, avg loss: 1.3863110280036925\n",
      "trial: 3, iter: 9800, curr loss: 1.3868811130523682, avg loss: 1.3863394111394882\n",
      "trial: 3, iter: 10000, curr loss: 1.3867124319076538, avg loss: 1.386397016644478\n",
      "trial: 3, iter: 10200, curr loss: 1.3863332271575928, avg loss: 1.3862948054075241\n",
      "trial: 3, iter: 10400, curr loss: 1.3876762390136719, avg loss: 1.3863227361440658\n",
      "trial: 3, iter: 10600, curr loss: 1.3859161138534546, avg loss: 1.3863363879919053\n",
      "trial: 3, iter: 10800, curr loss: 1.3863012790679932, avg loss: 1.386304002404213\n",
      "trial: 3, iter: 11000, curr loss: 1.3872013092041016, avg loss: 1.386288471221924\n",
      "trial: 3, iter: 11200, curr loss: 1.3861757516860962, avg loss: 1.3863368678092955\n",
      "trial: 3, iter: 11400, curr loss: 1.386904239654541, avg loss: 1.3863327103853225\n",
      "trial: 3, iter: 11600, curr loss: 1.385853886604309, avg loss: 1.3863132834434508\n",
      "trial: 3, iter: 11800, curr loss: 1.3872164487838745, avg loss: 1.3862667787075043\n",
      "trial: 3, iter: 12000, curr loss: 1.386738896369934, avg loss: 1.3863268357515335\n",
      "trial: 3, iter: 12200, curr loss: 1.3861165046691895, avg loss: 1.3863078385591507\n",
      "trial: 3, iter: 12400, curr loss: 1.3862704038619995, avg loss: 1.3863088864088058\n",
      "trial: 3, iter: 12600, curr loss: 1.386199951171875, avg loss: 1.3863054925203324\n",
      "trial: 3, iter: 12800, curr loss: 1.386358618736267, avg loss: 1.3863032639026642\n",
      "trial: 3, iter: 13000, curr loss: 1.3861833810806274, avg loss: 1.386303179860115\n",
      "trial: 3, iter: 13200, curr loss: 1.385959506034851, avg loss: 1.3862710332870483\n",
      "trial: 3, iter: 13400, curr loss: 1.3863182067871094, avg loss: 1.3863983792066574\n",
      "trial: 3, iter: 13600, curr loss: 1.3862367868423462, avg loss: 1.3863094407320022\n",
      "trial: 3, iter: 13800, curr loss: 1.3862361907958984, avg loss: 1.3862927323579788\n",
      "trial: 3, iter: 14000, curr loss: 1.3864892721176147, avg loss: 1.3862885844707489\n",
      "trial: 3, iter: 14200, curr loss: 1.3862786293029785, avg loss: 1.3863168042898177\n",
      "trial: 3, iter: 14400, curr loss: 1.3863905668258667, avg loss: 1.3862809270620347\n",
      "trial: 3, iter: 14600, curr loss: 1.3862196207046509, avg loss: 1.3863215231895447\n",
      "trial: 3, iter: 14800, curr loss: 1.3857327699661255, avg loss: 1.386293893456459\n",
      "trial: 3, iter: 15000, curr loss: 1.3861713409423828, avg loss: 1.3862916004657746\n",
      "trial: 3, iter: 15200, curr loss: 1.3866591453552246, avg loss: 1.386251071691513\n",
      "trial: 3, iter: 15400, curr loss: 1.3863611221313477, avg loss: 1.386334421634674\n",
      "trial: 3, iter: 15600, curr loss: 1.386206865310669, avg loss: 1.3863222670555115\n",
      "trial: 3, ldr: -0.0001289357169298455\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3882417678833008, avg loss: 1.387586283683777\n",
      "trial: 4, iter: 400, curr loss: 1.3846101760864258, avg loss: 1.3866140788793564\n",
      "trial: 4, iter: 600, curr loss: 1.3873348236083984, avg loss: 1.3866338419914246\n",
      "trial: 4, iter: 800, curr loss: 1.387676477432251, avg loss: 1.3864385396242143\n",
      "trial: 4, iter: 1000, curr loss: 1.3856441974639893, avg loss: 1.3863834500312806\n",
      "trial: 4, iter: 1200, curr loss: 1.3866469860076904, avg loss: 1.3864338076114655\n",
      "trial: 4, iter: 1400, curr loss: 1.3861587047576904, avg loss: 1.386394527554512\n",
      "trial: 4, iter: 1600, curr loss: 1.3873395919799805, avg loss: 1.386361789703369\n",
      "trial: 4, iter: 1800, curr loss: 1.388606309890747, avg loss: 1.3864136451482774\n",
      "trial: 4, iter: 2000, curr loss: 1.3868061304092407, avg loss: 1.3864306533336639\n",
      "trial: 4, iter: 2200, curr loss: 1.3865196704864502, avg loss: 1.3863699913024903\n",
      "trial: 4, iter: 2400, curr loss: 1.386062502861023, avg loss: 1.3863403576612472\n",
      "trial: 4, iter: 2600, curr loss: 1.3861124515533447, avg loss: 1.3863423651456832\n",
      "trial: 4, iter: 2800, curr loss: 1.3848865032196045, avg loss: 1.3863389736413956\n",
      "trial: 4, iter: 3000, curr loss: 1.3870164155960083, avg loss: 1.386362533569336\n",
      "trial: 4, iter: 3200, curr loss: 1.3865851163864136, avg loss: 1.3863583081960678\n",
      "trial: 4, iter: 3400, curr loss: 1.3863250017166138, avg loss: 1.3863374865055085\n",
      "trial: 4, iter: 3600, curr loss: 1.3867048025131226, avg loss: 1.3863051062822342\n",
      "trial: 4, iter: 3800, curr loss: 1.3860069513320923, avg loss: 1.3863492906093597\n",
      "trial: 4, iter: 4000, curr loss: 1.387168049812317, avg loss: 1.386363248229027\n",
      "trial: 4, iter: 4200, curr loss: 1.3859584331512451, avg loss: 1.3863553202152252\n",
      "trial: 4, iter: 4400, curr loss: 1.3860448598861694, avg loss: 1.386299540400505\n",
      "trial: 4, iter: 4600, curr loss: 1.3861935138702393, avg loss: 1.3863205462694168\n",
      "trial: 4, iter: 4800, curr loss: 1.3860466480255127, avg loss: 1.3863092064857483\n",
      "trial: 4, iter: 5000, curr loss: 1.385095477104187, avg loss: 1.3863231122493744\n",
      "trial: 4, iter: 5200, curr loss: 1.3854963779449463, avg loss: 1.3864490139484404\n",
      "trial: 4, iter: 5400, curr loss: 1.3862876892089844, avg loss: 1.3863608062267303\n",
      "trial: 4, iter: 5600, curr loss: 1.3863457441329956, avg loss: 1.386391459107399\n",
      "trial: 4, iter: 5800, curr loss: 1.386056661605835, avg loss: 1.3863431423902512\n",
      "trial: 4, iter: 6000, curr loss: 1.3863049745559692, avg loss: 1.3863453549146652\n",
      "trial: 4, iter: 6200, curr loss: 1.3865433931350708, avg loss: 1.3863022112846375\n",
      "trial: 4, iter: 6400, curr loss: 1.3864752054214478, avg loss: 1.3864284378290177\n",
      "trial: 4, iter: 6600, curr loss: 1.3867855072021484, avg loss: 1.3863518059253692\n",
      "trial: 4, iter: 6800, curr loss: 1.3856863975524902, avg loss: 1.3863088089227675\n",
      "trial: 4, iter: 7000, curr loss: 1.3863567113876343, avg loss: 1.3862729066610335\n",
      "trial: 4, iter: 7200, curr loss: 1.3867380619049072, avg loss: 1.386345964074135\n",
      "trial: 4, iter: 7400, curr loss: 1.3857665061950684, avg loss: 1.3862829905748368\n",
      "trial: 4, iter: 7600, curr loss: 1.3865694999694824, avg loss: 1.386316686272621\n",
      "trial: 4, iter: 7800, curr loss: 1.3866007328033447, avg loss: 1.3863587749004365\n",
      "trial: 4, iter: 8000, curr loss: 1.3860059976577759, avg loss: 1.386310396194458\n",
      "trial: 4, iter: 8200, curr loss: 1.3863133192062378, avg loss: 1.3863370025157928\n",
      "trial: 4, iter: 8400, curr loss: 1.3861041069030762, avg loss: 1.3863119781017303\n",
      "trial: 4, iter: 8600, curr loss: 1.3864201307296753, avg loss: 1.3863144618272782\n",
      "trial: 4, iter: 8800, curr loss: 1.3862112760543823, avg loss: 1.3862932205200196\n",
      "trial: 4, iter: 9000, curr loss: 1.3856289386749268, avg loss: 1.3862908780574799\n",
      "trial: 4, iter: 9200, curr loss: 1.38652765750885, avg loss: 1.3863363695144653\n",
      "trial: 4, iter: 9400, curr loss: 1.3861421346664429, avg loss: 1.3863054400682449\n",
      "trial: 4, iter: 9600, curr loss: 1.3864072561264038, avg loss: 1.3862637531757356\n",
      "trial: 4, iter: 9800, curr loss: 1.3858743906021118, avg loss: 1.386324919462204\n",
      "trial: 4, iter: 10000, curr loss: 1.386387825012207, avg loss: 1.3863318598270415\n",
      "trial: 4, iter: 10200, curr loss: 1.3861351013183594, avg loss: 1.3863029938936233\n",
      "trial: 4, iter: 10400, curr loss: 1.3856688737869263, avg loss: 1.3862614822387695\n",
      "trial: 4, iter: 10600, curr loss: 1.3852200508117676, avg loss: 1.3862913513183595\n",
      "trial: 4, iter: 10800, curr loss: 1.3865795135498047, avg loss: 1.3862913757562638\n",
      "trial: 4, iter: 11000, curr loss: 1.3864721059799194, avg loss: 1.3863024646043778\n",
      "trial: 4, iter: 11200, curr loss: 1.3864166736602783, avg loss: 1.3863504415750503\n",
      "trial: 4, iter: 11400, curr loss: 1.3865407705307007, avg loss: 1.3863094586133957\n",
      "trial: 4, iter: 11600, curr loss: 1.3858953714370728, avg loss: 1.3862949925661088\n",
      "trial: 4, iter: 11800, curr loss: 1.3862102031707764, avg loss: 1.3863186556100846\n",
      "trial: 4, iter: 12000, curr loss: 1.386179804801941, avg loss: 1.3863002502918242\n",
      "trial: 4, iter: 12200, curr loss: 1.3861255645751953, avg loss: 1.386295455098152\n",
      "trial: 4, iter: 12400, curr loss: 1.3862136602401733, avg loss: 1.3863021403551101\n",
      "trial: 4, iter: 12600, curr loss: 1.3863188028335571, avg loss: 1.3863000273704529\n",
      "trial: 4, iter: 12800, curr loss: 1.3870996236801147, avg loss: 1.3863081407546998\n",
      "trial: 4, iter: 13000, curr loss: 1.3862193822860718, avg loss: 1.3863359022140502\n",
      "trial: 4, iter: 13200, curr loss: 1.386490821838379, avg loss: 1.386323726773262\n",
      "trial: 4, iter: 13400, curr loss: 1.385403037071228, avg loss: 1.3863152420520783\n",
      "trial: 4, iter: 13600, curr loss: 1.3864011764526367, avg loss: 1.3863040667772293\n",
      "trial: 4, iter: 13800, curr loss: 1.3861613273620605, avg loss: 1.3863190841674804\n",
      "trial: 4, iter: 14000, curr loss: 1.3863142728805542, avg loss: 1.3863164979219436\n",
      "trial: 4, iter: 14200, curr loss: 1.3869284391403198, avg loss: 1.3862844693660736\n",
      "trial: 4, iter: 14400, curr loss: 1.3861362934112549, avg loss: 1.3863012635707854\n",
      "trial: 4, iter: 14600, curr loss: 1.3864257335662842, avg loss: 1.3863662803173065\n",
      "trial: 4, iter: 14800, curr loss: 1.3863422870635986, avg loss: 1.3863271594047546\n",
      "trial: 4, iter: 15000, curr loss: 1.387586236000061, avg loss: 1.3863430106639862\n",
      "trial: 4, iter: 15200, curr loss: 1.3868283033370972, avg loss: 1.386323066353798\n",
      "trial: 4, iter: 15400, curr loss: 1.3867801427841187, avg loss: 1.3863080924749374\n",
      "trial: 4, iter: 15600, curr loss: 1.3865134716033936, avg loss: 1.3863499122858047\n",
      "trial: 4, ldr: -0.0023555364459753036\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860069513320923, avg loss: 1.38732135951519\n",
      "trial: 5, iter: 400, curr loss: 1.38934326171875, avg loss: 1.3868501859903335\n",
      "trial: 5, iter: 600, curr loss: 1.3860268592834473, avg loss: 1.3863928991556167\n",
      "trial: 5, iter: 800, curr loss: 1.386364459991455, avg loss: 1.386483657360077\n",
      "trial: 5, iter: 1000, curr loss: 1.3858036994934082, avg loss: 1.386490194797516\n",
      "trial: 5, iter: 1200, curr loss: 1.3858872652053833, avg loss: 1.3864359092712402\n",
      "trial: 5, iter: 1400, curr loss: 1.3858689069747925, avg loss: 1.3864378750324249\n",
      "trial: 5, iter: 1600, curr loss: 1.3864171504974365, avg loss: 1.386394392848015\n",
      "trial: 5, iter: 1800, curr loss: 1.3859190940856934, avg loss: 1.3863296240568161\n",
      "trial: 5, iter: 2000, curr loss: 1.3865575790405273, avg loss: 1.386411756873131\n",
      "trial: 5, iter: 2200, curr loss: 1.3844696283340454, avg loss: 1.386355527639389\n",
      "trial: 5, iter: 2400, curr loss: 1.3845422267913818, avg loss: 1.3863277059793473\n",
      "trial: 5, iter: 2600, curr loss: 1.3858020305633545, avg loss: 1.386390363574028\n",
      "trial: 5, iter: 2800, curr loss: 1.3854633569717407, avg loss: 1.3863274598121642\n",
      "trial: 5, iter: 3000, curr loss: 1.3883012533187866, avg loss: 1.3862262386083604\n",
      "trial: 5, iter: 3200, curr loss: 1.3858718872070312, avg loss: 1.3865230029821396\n",
      "trial: 5, iter: 3400, curr loss: 1.3869800567626953, avg loss: 1.386387842297554\n",
      "trial: 5, iter: 3600, curr loss: 1.3865910768508911, avg loss: 1.3863649213314055\n",
      "trial: 5, iter: 3800, curr loss: 1.3867480754852295, avg loss: 1.3863478702306749\n",
      "trial: 5, iter: 4000, curr loss: 1.3871092796325684, avg loss: 1.3863283449411392\n",
      "trial: 5, iter: 4200, curr loss: 1.3854341506958008, avg loss: 1.3864063745737076\n",
      "trial: 5, iter: 4400, curr loss: 1.3867508172988892, avg loss: 1.3863833171129227\n",
      "trial: 5, iter: 4600, curr loss: 1.3867172002792358, avg loss: 1.3863119757175446\n",
      "trial: 5, iter: 4800, curr loss: 1.3865995407104492, avg loss: 1.3863090294599534\n",
      "trial: 5, iter: 5000, curr loss: 1.3862677812576294, avg loss: 1.3863343155384065\n",
      "trial: 5, iter: 5200, curr loss: 1.3862583637237549, avg loss: 1.3863292193412782\n",
      "trial: 5, iter: 5400, curr loss: 1.3858338594436646, avg loss: 1.3863309019804\n",
      "trial: 5, iter: 5600, curr loss: 1.3861536979675293, avg loss: 1.3863186037540436\n",
      "trial: 5, iter: 5800, curr loss: 1.3861851692199707, avg loss: 1.386249378323555\n",
      "trial: 5, iter: 6000, curr loss: 1.387075662612915, avg loss: 1.3862669718265535\n",
      "trial: 5, iter: 6200, curr loss: 1.3862004280090332, avg loss: 1.3863634645938874\n",
      "trial: 5, iter: 6400, curr loss: 1.3868682384490967, avg loss: 1.3862705767154693\n",
      "trial: 5, iter: 6600, curr loss: 1.3866493701934814, avg loss: 1.3863258564472198\n",
      "trial: 5, iter: 6800, curr loss: 1.386898159980774, avg loss: 1.3862945926189423\n",
      "trial: 5, iter: 7000, curr loss: 1.3864480257034302, avg loss: 1.3863273078203202\n",
      "trial: 5, iter: 7200, curr loss: 1.3867342472076416, avg loss: 1.386328940987587\n",
      "trial: 5, iter: 7400, curr loss: 1.3867526054382324, avg loss: 1.3863474714756012\n",
      "trial: 5, iter: 7600, curr loss: 1.3860194683074951, avg loss: 1.3863011604547502\n",
      "trial: 5, iter: 7800, curr loss: 1.3872952461242676, avg loss: 1.3863085448741912\n",
      "trial: 5, iter: 8000, curr loss: 1.3861937522888184, avg loss: 1.3863265138864518\n",
      "trial: 5, iter: 8200, curr loss: 1.3864656686782837, avg loss: 1.3863118344545364\n",
      "trial: 5, iter: 8400, curr loss: 1.3861337900161743, avg loss: 1.3863744866847991\n",
      "trial: 5, iter: 8600, curr loss: 1.3860079050064087, avg loss: 1.3863423734903335\n",
      "trial: 5, iter: 8800, curr loss: 1.385674238204956, avg loss: 1.3862847471237183\n",
      "trial: 5, iter: 9000, curr loss: 1.385901927947998, avg loss: 1.3863220030069352\n",
      "trial: 5, iter: 9200, curr loss: 1.3859840631484985, avg loss: 1.3862810158729553\n",
      "trial: 5, iter: 9400, curr loss: 1.386686086654663, avg loss: 1.386343915462494\n",
      "trial: 5, iter: 9600, curr loss: 1.386220932006836, avg loss: 1.3863068169355393\n",
      "trial: 5, iter: 9800, curr loss: 1.3867695331573486, avg loss: 1.3863154637813568\n",
      "trial: 5, iter: 10000, curr loss: 1.3864681720733643, avg loss: 1.3863798236846925\n",
      "trial: 5, iter: 10200, curr loss: 1.3863505125045776, avg loss: 1.3863222175836563\n",
      "trial: 5, iter: 10400, curr loss: 1.3869540691375732, avg loss: 1.386305606365204\n",
      "trial: 5, iter: 10600, curr loss: 1.3864349126815796, avg loss: 1.3863619869947434\n",
      "trial: 5, iter: 10800, curr loss: 1.3862277269363403, avg loss: 1.3863162070512771\n",
      "trial: 5, iter: 11000, curr loss: 1.3863242864608765, avg loss: 1.386298294067383\n",
      "trial: 5, iter: 11200, curr loss: 1.3863128423690796, avg loss: 1.3863107663393022\n",
      "trial: 5, iter: 11400, curr loss: 1.3863474130630493, avg loss: 1.3863033586740494\n",
      "trial: 5, iter: 11600, curr loss: 1.386282205581665, avg loss: 1.3863114154338836\n",
      "trial: 5, iter: 11800, curr loss: 1.386117696762085, avg loss: 1.3862882566452026\n",
      "trial: 5, iter: 12000, curr loss: 1.3860889673233032, avg loss: 1.3862990140914917\n",
      "trial: 5, iter: 12200, curr loss: 1.3863298892974854, avg loss: 1.3863021010160446\n",
      "trial: 5, iter: 12400, curr loss: 1.3868504762649536, avg loss: 1.38632493019104\n",
      "trial: 5, iter: 12600, curr loss: 1.386238932609558, avg loss: 1.3863256150484085\n",
      "trial: 5, iter: 12800, curr loss: 1.3859933614730835, avg loss: 1.386296563744545\n",
      "trial: 5, iter: 13000, curr loss: 1.386142611503601, avg loss: 1.3863258689641953\n",
      "trial: 5, iter: 13200, curr loss: 1.3863409757614136, avg loss: 1.3863070487976075\n",
      "trial: 5, iter: 13400, curr loss: 1.3860678672790527, avg loss: 1.3863001716136933\n",
      "trial: 5, iter: 13600, curr loss: 1.386283040046692, avg loss: 1.3863051152229309\n",
      "trial: 5, iter: 13800, curr loss: 1.3864896297454834, avg loss: 1.3862955176830292\n",
      "trial: 5, iter: 14000, curr loss: 1.3862619400024414, avg loss: 1.3862991344928741\n",
      "trial: 5, iter: 14200, curr loss: 1.3861303329467773, avg loss: 1.3862925440073013\n",
      "trial: 5, iter: 14400, curr loss: 1.3860576152801514, avg loss: 1.3863066500425338\n",
      "trial: 5, iter: 14600, curr loss: 1.3864591121673584, avg loss: 1.3862749499082565\n",
      "trial: 5, iter: 14800, curr loss: 1.3862613439559937, avg loss: 1.386321361064911\n",
      "trial: 5, iter: 15000, curr loss: 1.3864226341247559, avg loss: 1.386311932206154\n",
      "trial: 5, iter: 15200, curr loss: 1.386318564414978, avg loss: 1.3863069635629655\n",
      "trial: 5, iter: 15400, curr loss: 1.3862853050231934, avg loss: 1.3863076376914978\n",
      "trial: 5, iter: 15600, curr loss: 1.3861860036849976, avg loss: 1.3862809866666794\n",
      "trial: 5, ldr: 0.0006363041466102004\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.000423046633204649\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3908861875534058, avg loss: 1.387236493229866\n",
      "trial: 1, iter: 400, curr loss: 1.3891510963439941, avg loss: 1.3870385599136352\n",
      "trial: 1, iter: 600, curr loss: 1.3865371942520142, avg loss: 1.386615771651268\n",
      "trial: 1, iter: 800, curr loss: 1.3857778310775757, avg loss: 1.3865818548202515\n",
      "trial: 1, iter: 1000, curr loss: 1.3854665756225586, avg loss: 1.3865331661701203\n",
      "trial: 1, iter: 1200, curr loss: 1.3867130279541016, avg loss: 1.3864640498161316\n",
      "trial: 1, iter: 1400, curr loss: 1.3864238262176514, avg loss: 1.386341409087181\n",
      "trial: 1, iter: 1600, curr loss: 1.3865306377410889, avg loss: 1.3864306491613387\n",
      "trial: 1, iter: 1800, curr loss: 1.3859238624572754, avg loss: 1.386391859650612\n",
      "trial: 1, iter: 2000, curr loss: 1.386537790298462, avg loss: 1.3863649147748947\n",
      "trial: 1, iter: 2200, curr loss: 1.3850842714309692, avg loss: 1.386326174736023\n",
      "trial: 1, iter: 2400, curr loss: 1.3873590230941772, avg loss: 1.3864379721879958\n",
      "trial: 1, iter: 2600, curr loss: 1.3858174085617065, avg loss: 1.386422764658928\n",
      "trial: 1, iter: 2800, curr loss: 1.3866935968399048, avg loss: 1.3863685137033464\n",
      "trial: 1, iter: 3000, curr loss: 1.3873465061187744, avg loss: 1.386351443529129\n",
      "trial: 1, iter: 3200, curr loss: 1.3864065408706665, avg loss: 1.3863479483127594\n",
      "trial: 1, iter: 3400, curr loss: 1.3863898515701294, avg loss: 1.3863700425624848\n",
      "trial: 1, iter: 3600, curr loss: 1.387586236000061, avg loss: 1.3863300651311874\n",
      "trial: 1, iter: 3800, curr loss: 1.3860163688659668, avg loss: 1.3863415592908859\n",
      "trial: 1, iter: 4000, curr loss: 1.3864331245422363, avg loss: 1.3863322067260742\n",
      "trial: 1, iter: 4200, curr loss: 1.3869905471801758, avg loss: 1.386333835721016\n",
      "trial: 1, iter: 4400, curr loss: 1.3860609531402588, avg loss: 1.3863409358263015\n",
      "trial: 1, iter: 4600, curr loss: 1.3870073556900024, avg loss: 1.3863286292552948\n",
      "trial: 1, iter: 4800, curr loss: 1.3868743181228638, avg loss: 1.3863436299562455\n",
      "trial: 1, iter: 5000, curr loss: 1.3873735666275024, avg loss: 1.3863536190986634\n",
      "trial: 1, iter: 5200, curr loss: 1.3868043422698975, avg loss: 1.3863775736093522\n",
      "trial: 1, iter: 5400, curr loss: 1.38616943359375, avg loss: 1.3863510501384735\n",
      "trial: 1, iter: 5600, curr loss: 1.3864139318466187, avg loss: 1.3863267076015473\n",
      "trial: 1, iter: 5800, curr loss: 1.3870127201080322, avg loss: 1.3863415122032166\n",
      "trial: 1, iter: 6000, curr loss: 1.3872900009155273, avg loss: 1.386294143795967\n",
      "trial: 1, iter: 6200, curr loss: 1.3858017921447754, avg loss: 1.3863545513153077\n",
      "trial: 1, iter: 6400, curr loss: 1.3862711191177368, avg loss: 1.386384829878807\n",
      "trial: 1, iter: 6600, curr loss: 1.38649320602417, avg loss: 1.3863407218456267\n",
      "trial: 1, iter: 6800, curr loss: 1.3860074281692505, avg loss: 1.3863270485401153\n",
      "trial: 1, iter: 7000, curr loss: 1.3864902257919312, avg loss: 1.3863085341453552\n",
      "trial: 1, iter: 7200, curr loss: 1.3857372999191284, avg loss: 1.3862945675849914\n",
      "trial: 1, iter: 7400, curr loss: 1.3858723640441895, avg loss: 1.3863052666187285\n",
      "trial: 1, iter: 7600, curr loss: 1.3869380950927734, avg loss: 1.3863422459363937\n",
      "trial: 1, iter: 7800, curr loss: 1.3862483501434326, avg loss: 1.3863021612167359\n",
      "trial: 1, iter: 8000, curr loss: 1.3865190744400024, avg loss: 1.3863089805841446\n",
      "trial: 1, iter: 8200, curr loss: 1.3865653276443481, avg loss: 1.3863277888298036\n",
      "trial: 1, iter: 8400, curr loss: 1.3858219385147095, avg loss: 1.3862557578086854\n",
      "trial: 1, iter: 8600, curr loss: 1.386023759841919, avg loss: 1.3863387447595596\n",
      "trial: 1, iter: 8800, curr loss: 1.3864763975143433, avg loss: 1.386340097784996\n",
      "trial: 1, iter: 9000, curr loss: 1.3854316473007202, avg loss: 1.3863058871030807\n",
      "trial: 1, iter: 9200, curr loss: 1.3865760564804077, avg loss: 1.386319790482521\n",
      "trial: 1, iter: 9400, curr loss: 1.386618733406067, avg loss: 1.3863245916366578\n",
      "trial: 1, iter: 9600, curr loss: 1.3866000175476074, avg loss: 1.386315143108368\n",
      "trial: 1, iter: 9800, curr loss: 1.385727882385254, avg loss: 1.3863290268182755\n",
      "trial: 1, iter: 10000, curr loss: 1.3860865831375122, avg loss: 1.3863498783111572\n",
      "trial: 1, iter: 10200, curr loss: 1.3859330415725708, avg loss: 1.3863424450159072\n",
      "trial: 1, iter: 10400, curr loss: 1.3860962390899658, avg loss: 1.3863288706541061\n",
      "trial: 1, iter: 10600, curr loss: 1.3868707418441772, avg loss: 1.386353427171707\n",
      "trial: 1, iter: 10800, curr loss: 1.3862043619155884, avg loss: 1.3863116270303726\n",
      "trial: 1, iter: 11000, curr loss: 1.3863921165466309, avg loss: 1.386333693265915\n",
      "trial: 1, iter: 11200, curr loss: 1.3862802982330322, avg loss: 1.386301502585411\n",
      "trial: 1, iter: 11400, curr loss: 1.3862879276275635, avg loss: 1.3862953263521194\n",
      "trial: 1, iter: 11600, curr loss: 1.3862965106964111, avg loss: 1.3863050657510758\n",
      "trial: 1, iter: 11800, curr loss: 1.3860522508621216, avg loss: 1.3863734376430512\n",
      "trial: 1, iter: 12000, curr loss: 1.3865783214569092, avg loss: 1.3863681757450104\n",
      "trial: 1, iter: 12200, curr loss: 1.3860726356506348, avg loss: 1.3862928706407547\n",
      "trial: 1, iter: 12400, curr loss: 1.3861184120178223, avg loss: 1.386314986348152\n",
      "trial: 1, iter: 12600, curr loss: 1.3868963718414307, avg loss: 1.3863404113054276\n",
      "trial: 1, iter: 12800, curr loss: 1.3864551782608032, avg loss: 1.386383879184723\n",
      "trial: 1, iter: 13000, curr loss: 1.3865015506744385, avg loss: 1.3863186717033387\n",
      "trial: 1, iter: 13200, curr loss: 1.386192798614502, avg loss: 1.3863461059331894\n",
      "trial: 1, iter: 13400, curr loss: 1.3864859342575073, avg loss: 1.3863321787118912\n",
      "trial: 1, iter: 13600, curr loss: 1.3862205743789673, avg loss: 1.386327583193779\n",
      "trial: 1, iter: 13800, curr loss: 1.3859719038009644, avg loss: 1.3863009434938431\n",
      "trial: 1, iter: 14000, curr loss: 1.3863390684127808, avg loss: 1.3863042676448822\n",
      "trial: 1, iter: 14200, curr loss: 1.3862063884735107, avg loss: 1.3863100332021714\n",
      "trial: 1, iter: 14400, curr loss: 1.3863400220870972, avg loss: 1.386362048983574\n",
      "trial: 1, iter: 14600, curr loss: 1.3861407041549683, avg loss: 1.3863655787706375\n",
      "trial: 1, iter: 14800, curr loss: 1.3860952854156494, avg loss: 1.3862977397441865\n",
      "trial: 1, iter: 15000, curr loss: 1.3864396810531616, avg loss: 1.3863031804561614\n",
      "trial: 1, iter: 15200, curr loss: 1.3863571882247925, avg loss: 1.3862987357378005\n",
      "trial: 1, iter: 15400, curr loss: 1.386293888092041, avg loss: 1.386300290822983\n",
      "trial: 1, iter: 15600, curr loss: 1.3866044282913208, avg loss: 1.386296542286873\n",
      "trial: 1, ldr: 0.0004824837378691882\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3850908279418945, avg loss: 1.3871683847904206\n",
      "trial: 2, iter: 400, curr loss: 1.384880542755127, avg loss: 1.386684828400612\n",
      "trial: 2, iter: 600, curr loss: 1.3858420848846436, avg loss: 1.3867057603597641\n",
      "trial: 2, iter: 800, curr loss: 1.387465476989746, avg loss: 1.3865878307819366\n",
      "trial: 2, iter: 1000, curr loss: 1.3863255977630615, avg loss: 1.3864787137508392\n",
      "trial: 2, iter: 1200, curr loss: 1.3862069845199585, avg loss: 1.3864744919538499\n",
      "trial: 2, iter: 1400, curr loss: 1.387760043144226, avg loss: 1.3864404451847077\n",
      "trial: 2, iter: 1600, curr loss: 1.3868376016616821, avg loss: 1.3863717079162599\n",
      "trial: 2, iter: 1800, curr loss: 1.3862296342849731, avg loss: 1.3863064336776734\n",
      "trial: 2, iter: 2000, curr loss: 1.3865127563476562, avg loss: 1.3864018964767455\n",
      "trial: 2, iter: 2200, curr loss: 1.3867250680923462, avg loss: 1.3863684433698653\n",
      "trial: 2, iter: 2400, curr loss: 1.3851441144943237, avg loss: 1.38629924595356\n",
      "trial: 2, iter: 2600, curr loss: 1.3861461877822876, avg loss: 1.3863792032003404\n",
      "trial: 2, iter: 2800, curr loss: 1.3869057893753052, avg loss: 1.3863829046487808\n",
      "trial: 2, iter: 3000, curr loss: 1.3864076137542725, avg loss: 1.3863794320821763\n",
      "trial: 2, iter: 3200, curr loss: 1.3862359523773193, avg loss: 1.3863393753767013\n",
      "trial: 2, iter: 3400, curr loss: 1.3851464986801147, avg loss: 1.3863336169719696\n",
      "trial: 2, iter: 3600, curr loss: 1.386544108390808, avg loss: 1.386307207942009\n",
      "trial: 2, iter: 3800, curr loss: 1.3862115144729614, avg loss: 1.3863369691371918\n",
      "trial: 2, iter: 4000, curr loss: 1.3869267702102661, avg loss: 1.3863800513744353\n",
      "trial: 2, iter: 4200, curr loss: 1.3862476348876953, avg loss: 1.3863511556386947\n",
      "trial: 2, iter: 4400, curr loss: 1.3860983848571777, avg loss: 1.3862736988067628\n",
      "trial: 2, iter: 4600, curr loss: 1.3857206106185913, avg loss: 1.386421986222267\n",
      "trial: 2, iter: 4800, curr loss: 1.3865904808044434, avg loss: 1.3863395071029663\n",
      "trial: 2, iter: 5000, curr loss: 1.3860875368118286, avg loss: 1.3863201332092285\n",
      "trial: 2, iter: 5200, curr loss: 1.3868944644927979, avg loss: 1.3863398963212967\n",
      "trial: 2, iter: 5400, curr loss: 1.3867524862289429, avg loss: 1.386282353401184\n",
      "trial: 2, iter: 5600, curr loss: 1.3864250183105469, avg loss: 1.3863098740577697\n",
      "trial: 2, iter: 5800, curr loss: 1.3860716819763184, avg loss: 1.3863225001096726\n",
      "trial: 2, iter: 6000, curr loss: 1.38662588596344, avg loss: 1.3863287049531936\n",
      "trial: 2, iter: 6200, curr loss: 1.3860937356948853, avg loss: 1.3863185358047485\n",
      "trial: 2, iter: 6400, curr loss: 1.385669469833374, avg loss: 1.3863504862785339\n",
      "trial: 2, iter: 6600, curr loss: 1.386629343032837, avg loss: 1.386336874961853\n",
      "trial: 2, iter: 6800, curr loss: 1.3859977722167969, avg loss: 1.3862927538156509\n",
      "trial: 2, iter: 7000, curr loss: 1.3860212564468384, avg loss: 1.3863143491744996\n",
      "trial: 2, iter: 7200, curr loss: 1.3866418600082397, avg loss: 1.386306722164154\n",
      "trial: 2, iter: 7400, curr loss: 1.3871296644210815, avg loss: 1.38633397936821\n",
      "trial: 2, iter: 7600, curr loss: 1.3864750862121582, avg loss: 1.3863042378425598\n",
      "trial: 2, iter: 7800, curr loss: 1.3860392570495605, avg loss: 1.386415999531746\n",
      "trial: 2, iter: 8000, curr loss: 1.3863213062286377, avg loss: 1.3863770544528962\n",
      "trial: 2, iter: 8200, curr loss: 1.3867101669311523, avg loss: 1.3863647949695588\n",
      "trial: 2, iter: 8400, curr loss: 1.3871197700500488, avg loss: 1.386269993185997\n",
      "trial: 2, iter: 8600, curr loss: 1.3867274522781372, avg loss: 1.3863542717695236\n",
      "trial: 2, iter: 8800, curr loss: 1.3860697746276855, avg loss: 1.3863408488035203\n",
      "trial: 2, iter: 9000, curr loss: 1.3862451314926147, avg loss: 1.3862854492664338\n",
      "trial: 2, iter: 9200, curr loss: 1.3862618207931519, avg loss: 1.3863373517990112\n",
      "trial: 2, iter: 9400, curr loss: 1.3863639831542969, avg loss: 1.3863185089826584\n",
      "trial: 2, iter: 9600, curr loss: 1.3862435817718506, avg loss: 1.3862904179096223\n",
      "trial: 2, iter: 9800, curr loss: 1.3865638971328735, avg loss: 1.3862778162956237\n",
      "trial: 2, iter: 10000, curr loss: 1.386132836341858, avg loss: 1.3862940126657486\n",
      "trial: 2, iter: 10200, curr loss: 1.3862404823303223, avg loss: 1.3863162660598756\n",
      "trial: 2, iter: 10400, curr loss: 1.386279582977295, avg loss: 1.3863129490613937\n",
      "trial: 2, iter: 10600, curr loss: 1.3858798742294312, avg loss: 1.386314646601677\n",
      "trial: 2, iter: 10800, curr loss: 1.386783480644226, avg loss: 1.3863407039642335\n",
      "trial: 2, iter: 11000, curr loss: 1.3860445022583008, avg loss: 1.38636511862278\n",
      "trial: 2, iter: 11200, curr loss: 1.386152744293213, avg loss: 1.3863277226686477\n",
      "trial: 2, iter: 11400, curr loss: 1.3863223791122437, avg loss: 1.3863066124916077\n",
      "trial: 2, iter: 11600, curr loss: 1.386569857597351, avg loss: 1.3863154602050782\n",
      "trial: 2, iter: 11800, curr loss: 1.3859955072402954, avg loss: 1.3863068932294846\n",
      "trial: 2, iter: 12000, curr loss: 1.3862619400024414, avg loss: 1.386320470571518\n",
      "trial: 2, iter: 12200, curr loss: 1.3862736225128174, avg loss: 1.386294006705284\n",
      "trial: 2, iter: 12400, curr loss: 1.3863532543182373, avg loss: 1.3863123512268067\n",
      "trial: 2, iter: 12600, curr loss: 1.3862266540527344, avg loss: 1.3863107270002366\n",
      "trial: 2, iter: 12800, curr loss: 1.386254906654358, avg loss: 1.3862908917665482\n",
      "trial: 2, iter: 13000, curr loss: 1.3862464427947998, avg loss: 1.386284340620041\n",
      "trial: 2, iter: 13200, curr loss: 1.386380672454834, avg loss: 1.386291360259056\n",
      "trial: 2, iter: 13400, curr loss: 1.386642575263977, avg loss: 1.3863057279586792\n",
      "trial: 2, iter: 13600, curr loss: 1.3862988948822021, avg loss: 1.386300790309906\n",
      "trial: 2, iter: 13800, curr loss: 1.3865102529525757, avg loss: 1.3862985599040984\n",
      "trial: 2, iter: 14000, curr loss: 1.3864314556121826, avg loss: 1.3862950879335403\n",
      "trial: 2, iter: 14200, curr loss: 1.3864829540252686, avg loss: 1.3863057833909989\n",
      "trial: 2, iter: 14400, curr loss: 1.3865008354187012, avg loss: 1.386292917728424\n",
      "trial: 2, iter: 14600, curr loss: 1.3871904611587524, avg loss: 1.3862870454788208\n",
      "trial: 2, iter: 14800, curr loss: 1.384657621383667, avg loss: 1.3862598985433578\n",
      "trial: 2, iter: 15000, curr loss: 1.387246012687683, avg loss: 1.3863622730970382\n",
      "trial: 2, iter: 15200, curr loss: 1.3864352703094482, avg loss: 1.3863016349077224\n",
      "trial: 2, iter: 15400, curr loss: 1.3859838247299194, avg loss: 1.3863522791862488\n",
      "trial: 2, iter: 15600, curr loss: 1.386298656463623, avg loss: 1.3863037103414535\n",
      "trial: 2, ldr: 0.0014418319333344698\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3834470510482788, avg loss: 1.3872546917200088\n",
      "trial: 3, iter: 400, curr loss: 1.385472297668457, avg loss: 1.3868403571844101\n",
      "trial: 3, iter: 600, curr loss: 1.3871245384216309, avg loss: 1.3865115410089492\n",
      "trial: 3, iter: 800, curr loss: 1.3879741430282593, avg loss: 1.3864634984731674\n",
      "trial: 3, iter: 1000, curr loss: 1.3845553398132324, avg loss: 1.3864422208070755\n",
      "trial: 3, iter: 1200, curr loss: 1.3867822885513306, avg loss: 1.386491369009018\n",
      "trial: 3, iter: 1400, curr loss: 1.3852216005325317, avg loss: 1.3863665425777436\n",
      "trial: 3, iter: 1600, curr loss: 1.3869349956512451, avg loss: 1.386469532251358\n",
      "trial: 3, iter: 1800, curr loss: 1.3866046667099, avg loss: 1.3864156824350358\n",
      "trial: 3, iter: 2000, curr loss: 1.3861514329910278, avg loss: 1.386449733376503\n",
      "trial: 3, iter: 2200, curr loss: 1.3873167037963867, avg loss: 1.3863543164730072\n",
      "trial: 3, iter: 2400, curr loss: 1.3880178928375244, avg loss: 1.386504915356636\n",
      "trial: 3, iter: 2600, curr loss: 1.3869060277938843, avg loss: 1.386414220929146\n",
      "trial: 3, iter: 2800, curr loss: 1.3868893384933472, avg loss: 1.386368595957756\n",
      "trial: 3, iter: 3000, curr loss: 1.385272741317749, avg loss: 1.386279757618904\n",
      "trial: 3, iter: 3200, curr loss: 1.3877443075180054, avg loss: 1.386288423538208\n",
      "trial: 3, iter: 3400, curr loss: 1.3863658905029297, avg loss: 1.3863471257686615\n",
      "trial: 3, iter: 3600, curr loss: 1.3866896629333496, avg loss: 1.3863133174180984\n",
      "trial: 3, iter: 3800, curr loss: 1.386281967163086, avg loss: 1.3863196396827697\n",
      "trial: 3, iter: 4000, curr loss: 1.3865885734558105, avg loss: 1.3862787067890168\n",
      "trial: 3, iter: 4200, curr loss: 1.386197805404663, avg loss: 1.3863588851690292\n",
      "trial: 3, iter: 4400, curr loss: 1.386415958404541, avg loss: 1.3863320881128312\n",
      "trial: 3, iter: 4600, curr loss: 1.3870803117752075, avg loss: 1.3864393800497055\n",
      "trial: 3, iter: 4800, curr loss: 1.3861231803894043, avg loss: 1.3861940914392472\n",
      "trial: 3, iter: 5000, curr loss: 1.3864816427230835, avg loss: 1.3863749569654464\n",
      "trial: 3, iter: 5200, curr loss: 1.3866547346115112, avg loss: 1.3863623052835465\n",
      "trial: 3, iter: 5400, curr loss: 1.3867629766464233, avg loss: 1.3864141619205474\n",
      "trial: 3, iter: 5600, curr loss: 1.3856197595596313, avg loss: 1.3863601636886598\n",
      "trial: 3, iter: 5800, curr loss: 1.3863270282745361, avg loss: 1.3863154536485671\n",
      "trial: 3, iter: 6000, curr loss: 1.3858811855316162, avg loss: 1.386340371966362\n",
      "trial: 3, iter: 6200, curr loss: 1.3867902755737305, avg loss: 1.3863259732723237\n",
      "trial: 3, iter: 6400, curr loss: 1.3860479593276978, avg loss: 1.3863599735498429\n",
      "trial: 3, iter: 6600, curr loss: 1.3862851858139038, avg loss: 1.3863285982608795\n",
      "trial: 3, iter: 6800, curr loss: 1.3858389854431152, avg loss: 1.3862968415021897\n",
      "trial: 3, iter: 7000, curr loss: 1.3860262632369995, avg loss: 1.386321994662285\n",
      "trial: 3, iter: 7200, curr loss: 1.387481451034546, avg loss: 1.3862788790464402\n",
      "trial: 3, iter: 7400, curr loss: 1.3863426446914673, avg loss: 1.3863601171970368\n",
      "trial: 3, iter: 7600, curr loss: 1.3863533735275269, avg loss: 1.386314190030098\n",
      "trial: 3, iter: 7800, curr loss: 1.3864244222640991, avg loss: 1.3863191550970078\n",
      "trial: 3, iter: 8000, curr loss: 1.3864320516586304, avg loss: 1.386286229491234\n",
      "trial: 3, iter: 8200, curr loss: 1.3864535093307495, avg loss: 1.3863100063800813\n",
      "trial: 3, iter: 8400, curr loss: 1.3863545656204224, avg loss: 1.386296655535698\n",
      "trial: 3, iter: 8600, curr loss: 1.386397123336792, avg loss: 1.3863035494089126\n",
      "trial: 3, iter: 8800, curr loss: 1.3861284255981445, avg loss: 1.3863014996051788\n",
      "trial: 3, iter: 9000, curr loss: 1.386325478553772, avg loss: 1.3862995153665543\n",
      "trial: 3, iter: 9200, curr loss: 1.3860688209533691, avg loss: 1.3862989389896392\n",
      "trial: 3, iter: 9400, curr loss: 1.3861597776412964, avg loss: 1.3862948608398438\n",
      "trial: 3, iter: 9600, curr loss: 1.3817236423492432, avg loss: 1.3862631583213807\n",
      "trial: 3, iter: 9800, curr loss: 1.3865621089935303, avg loss: 1.3864561140537262\n",
      "trial: 3, iter: 10000, curr loss: 1.3847793340682983, avg loss: 1.3863891607522965\n",
      "trial: 3, iter: 10200, curr loss: 1.3863554000854492, avg loss: 1.3863588398694993\n",
      "trial: 3, iter: 10400, curr loss: 1.3862112760543823, avg loss: 1.38635496199131\n",
      "trial: 3, iter: 10600, curr loss: 1.3875170946121216, avg loss: 1.3862994420528412\n",
      "trial: 3, iter: 10800, curr loss: 1.3864548206329346, avg loss: 1.3863401395082473\n",
      "trial: 3, iter: 11000, curr loss: 1.386099934577942, avg loss: 1.386318055987358\n",
      "trial: 3, iter: 11200, curr loss: 1.386063814163208, avg loss: 1.3863326215744018\n",
      "trial: 3, iter: 11400, curr loss: 1.386560320854187, avg loss: 1.3863119661808014\n",
      "trial: 3, iter: 11600, curr loss: 1.3862477540969849, avg loss: 1.386308154463768\n",
      "trial: 3, iter: 11800, curr loss: 1.3865081071853638, avg loss: 1.3863120752573013\n",
      "trial: 3, iter: 12000, curr loss: 1.386273980140686, avg loss: 1.3863042253255844\n",
      "trial: 3, iter: 12200, curr loss: 1.3860552310943604, avg loss: 1.3863075935840607\n",
      "trial: 3, iter: 12400, curr loss: 1.3862684965133667, avg loss: 1.3863086277246475\n",
      "trial: 3, iter: 12600, curr loss: 1.3862919807434082, avg loss: 1.3862974709272384\n",
      "trial: 3, iter: 12800, curr loss: 1.3861966133117676, avg loss: 1.386299386024475\n",
      "trial: 3, iter: 13000, curr loss: 1.3863493204116821, avg loss: 1.3863011664152145\n",
      "trial: 3, iter: 13200, curr loss: 1.3863794803619385, avg loss: 1.386299294233322\n",
      "trial: 3, iter: 13400, curr loss: 1.3863463401794434, avg loss: 1.386288206577301\n",
      "trial: 3, iter: 13600, curr loss: 1.386427640914917, avg loss: 1.3863076001405716\n",
      "trial: 3, iter: 13800, curr loss: 1.3862055540084839, avg loss: 1.3862951457500459\n",
      "trial: 3, iter: 14000, curr loss: 1.3865160942077637, avg loss: 1.3862816852331161\n",
      "trial: 3, iter: 14200, curr loss: 1.386455774307251, avg loss: 1.3863074034452438\n",
      "trial: 3, iter: 14400, curr loss: 1.3863255977630615, avg loss: 1.3863019114732742\n",
      "trial: 3, iter: 14600, curr loss: 1.3863781690597534, avg loss: 1.3862988972663879\n",
      "trial: 3, iter: 14800, curr loss: 1.3862913846969604, avg loss: 1.3863113951683044\n",
      "trial: 3, iter: 15000, curr loss: 1.3865087032318115, avg loss: 1.386296061873436\n",
      "trial: 3, iter: 15200, curr loss: 1.386231541633606, avg loss: 1.3863092678785325\n",
      "trial: 3, iter: 15400, curr loss: 1.3864130973815918, avg loss: 1.3862972801923752\n",
      "trial: 3, iter: 15600, curr loss: 1.386335015296936, avg loss: 1.3863014608621598\n",
      "trial: 3, ldr: 0.0010236883535981178\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3852874040603638, avg loss: 1.3873808121681213\n",
      "trial: 4, iter: 400, curr loss: 1.3888906240463257, avg loss: 1.3867308157682419\n",
      "trial: 4, iter: 600, curr loss: 1.3901793956756592, avg loss: 1.3865731513500215\n",
      "trial: 4, iter: 800, curr loss: 1.3864340782165527, avg loss: 1.386608561873436\n",
      "trial: 4, iter: 1000, curr loss: 1.3871434926986694, avg loss: 1.3866513818502426\n",
      "trial: 4, iter: 1200, curr loss: 1.3857518434524536, avg loss: 1.3864639580249787\n",
      "trial: 4, iter: 1400, curr loss: 1.3867456912994385, avg loss: 1.3864636713266372\n",
      "trial: 4, iter: 1600, curr loss: 1.3867744207382202, avg loss: 1.3863704800605774\n",
      "trial: 4, iter: 1800, curr loss: 1.3872132301330566, avg loss: 1.3864339941740036\n",
      "trial: 4, iter: 2000, curr loss: 1.3849892616271973, avg loss: 1.3863504910469056\n",
      "trial: 4, iter: 2200, curr loss: 1.3864052295684814, avg loss: 1.3864218872785568\n",
      "trial: 4, iter: 2400, curr loss: 1.3858988285064697, avg loss: 1.3863934409618377\n",
      "trial: 4, iter: 2600, curr loss: 1.3865199089050293, avg loss: 1.3863992100954057\n",
      "trial: 4, iter: 2800, curr loss: 1.388221263885498, avg loss: 1.3863590335845948\n",
      "trial: 4, iter: 3000, curr loss: 1.3864692449569702, avg loss: 1.3863648408651352\n",
      "trial: 4, iter: 3200, curr loss: 1.3851338624954224, avg loss: 1.3863355839252471\n",
      "trial: 4, iter: 3400, curr loss: 1.3863887786865234, avg loss: 1.38637730717659\n",
      "trial: 4, iter: 3600, curr loss: 1.3866667747497559, avg loss: 1.3863391178846358\n",
      "trial: 4, iter: 3800, curr loss: 1.387374997138977, avg loss: 1.3862973320484162\n",
      "trial: 4, iter: 4000, curr loss: 1.3865748643875122, avg loss: 1.3863433849811555\n",
      "trial: 4, iter: 4200, curr loss: 1.3861610889434814, avg loss: 1.3863108623027802\n",
      "trial: 4, iter: 4400, curr loss: 1.3858420848846436, avg loss: 1.3864065551757812\n",
      "trial: 4, iter: 4600, curr loss: 1.3880351781845093, avg loss: 1.3864540642499923\n",
      "trial: 4, iter: 4800, curr loss: 1.3859118223190308, avg loss: 1.3864221680164337\n",
      "trial: 4, iter: 5000, curr loss: 1.3872846364974976, avg loss: 1.3863440269231797\n",
      "trial: 4, iter: 5200, curr loss: 1.3863242864608765, avg loss: 1.386360503435135\n",
      "trial: 4, iter: 5400, curr loss: 1.3858779668807983, avg loss: 1.3863344967365265\n",
      "trial: 4, iter: 5600, curr loss: 1.3870245218276978, avg loss: 1.386341204047203\n",
      "trial: 4, iter: 5800, curr loss: 1.386728048324585, avg loss: 1.3863416743278503\n",
      "trial: 4, iter: 6000, curr loss: 1.3863887786865234, avg loss: 1.3863470876216888\n",
      "trial: 4, iter: 6200, curr loss: 1.3848484754562378, avg loss: 1.3862879371643066\n",
      "trial: 4, iter: 6400, curr loss: 1.3871445655822754, avg loss: 1.3863293224573134\n",
      "trial: 4, iter: 6600, curr loss: 1.3857835531234741, avg loss: 1.3863370299339295\n",
      "trial: 4, iter: 6800, curr loss: 1.386732816696167, avg loss: 1.3863391530513764\n",
      "trial: 4, iter: 7000, curr loss: 1.3865395784378052, avg loss: 1.3863287383317948\n",
      "trial: 4, iter: 7200, curr loss: 1.3862414360046387, avg loss: 1.3863190817832947\n",
      "trial: 4, iter: 7400, curr loss: 1.3861535787582397, avg loss: 1.3863153964281083\n",
      "trial: 4, iter: 7600, curr loss: 1.3861063718795776, avg loss: 1.386324952840805\n",
      "trial: 4, iter: 7800, curr loss: 1.3864610195159912, avg loss: 1.386328416466713\n",
      "trial: 4, iter: 8000, curr loss: 1.386372685432434, avg loss: 1.386345179080963\n",
      "trial: 4, iter: 8200, curr loss: 1.3865926265716553, avg loss: 1.3863970917463302\n",
      "trial: 4, iter: 8400, curr loss: 1.3856561183929443, avg loss: 1.3863199162483215\n",
      "trial: 4, iter: 8600, curr loss: 1.3859604597091675, avg loss: 1.3863427418470382\n",
      "trial: 4, iter: 8800, curr loss: 1.386743426322937, avg loss: 1.3863256311416625\n",
      "trial: 4, iter: 9000, curr loss: 1.385661005973816, avg loss: 1.386397920846939\n",
      "trial: 4, iter: 9200, curr loss: 1.3862576484680176, avg loss: 1.386345574259758\n",
      "trial: 4, iter: 9400, curr loss: 1.3865773677825928, avg loss: 1.3863236904144287\n",
      "trial: 4, iter: 9600, curr loss: 1.3861013650894165, avg loss: 1.3863520854711533\n",
      "trial: 4, iter: 9800, curr loss: 1.386400818824768, avg loss: 1.3863288938999176\n",
      "trial: 4, iter: 10000, curr loss: 1.3861559629440308, avg loss: 1.3863425481319427\n",
      "trial: 4, iter: 10200, curr loss: 1.3865711688995361, avg loss: 1.3863224595785142\n",
      "trial: 4, iter: 10400, curr loss: 1.3869556188583374, avg loss: 1.386275413632393\n",
      "trial: 4, iter: 10600, curr loss: 1.385457158088684, avg loss: 1.3863303953409194\n",
      "trial: 4, iter: 10800, curr loss: 1.3865504264831543, avg loss: 1.38634850025177\n",
      "trial: 4, iter: 11000, curr loss: 1.3859492540359497, avg loss: 1.3863299602270127\n",
      "trial: 4, iter: 11200, curr loss: 1.3858739137649536, avg loss: 1.3863094758987426\n",
      "trial: 4, iter: 11400, curr loss: 1.385980486869812, avg loss: 1.3863072609901428\n",
      "trial: 4, iter: 11600, curr loss: 1.3874361515045166, avg loss: 1.3863013124465942\n",
      "trial: 4, iter: 11800, curr loss: 1.3862477540969849, avg loss: 1.3863248324394226\n",
      "trial: 4, iter: 12000, curr loss: 1.386065125465393, avg loss: 1.38634123980999\n",
      "trial: 4, iter: 12200, curr loss: 1.3866188526153564, avg loss: 1.3863652819395065\n",
      "trial: 4, iter: 12400, curr loss: 1.386802077293396, avg loss: 1.3863499116897584\n",
      "trial: 4, iter: 12600, curr loss: 1.3861727714538574, avg loss: 1.3863492649793625\n",
      "trial: 4, iter: 12800, curr loss: 1.3861411809921265, avg loss: 1.3862924110889434\n",
      "trial: 4, iter: 13000, curr loss: 1.3864980936050415, avg loss: 1.3863158357143401\n",
      "trial: 4, iter: 13200, curr loss: 1.3861333131790161, avg loss: 1.3863127136230469\n",
      "trial: 4, iter: 13400, curr loss: 1.3863035440444946, avg loss: 1.3863072192668915\n",
      "trial: 4, iter: 13600, curr loss: 1.3866503238677979, avg loss: 1.3862992912530898\n",
      "trial: 4, iter: 13800, curr loss: 1.386215329170227, avg loss: 1.3863201445341111\n",
      "trial: 4, iter: 14000, curr loss: 1.386320948600769, avg loss: 1.3863096624612807\n",
      "trial: 4, iter: 14200, curr loss: 1.3862674236297607, avg loss: 1.386291230916977\n",
      "trial: 4, iter: 14400, curr loss: 1.3863590955734253, avg loss: 1.3862939774990082\n",
      "trial: 4, iter: 14600, curr loss: 1.386269450187683, avg loss: 1.386303528547287\n",
      "trial: 4, iter: 14800, curr loss: 1.3863002061843872, avg loss: 1.3863131666183472\n",
      "trial: 4, iter: 15000, curr loss: 1.3864822387695312, avg loss: 1.3862993252277374\n",
      "trial: 4, iter: 15200, curr loss: 1.3864306211471558, avg loss: 1.3863209301233292\n",
      "trial: 4, iter: 15400, curr loss: 1.3862495422363281, avg loss: 1.386295538544655\n",
      "trial: 4, iter: 15600, curr loss: 1.3863255977630615, avg loss: 1.3863050049543382\n",
      "trial: 4, ldr: 0.0010558718349784613\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3840607404708862, avg loss: 1.3875157296657563\n",
      "trial: 5, iter: 400, curr loss: 1.3849188089370728, avg loss: 1.3865012097358704\n",
      "trial: 5, iter: 600, curr loss: 1.3878895044326782, avg loss: 1.3868072569370269\n",
      "trial: 5, iter: 800, curr loss: 1.3858933448791504, avg loss: 1.3864280831813813\n",
      "trial: 5, iter: 1000, curr loss: 1.3867101669311523, avg loss: 1.3864829516410828\n",
      "trial: 5, iter: 1200, curr loss: 1.387100100517273, avg loss: 1.3864055639505386\n",
      "trial: 5, iter: 1400, curr loss: 1.3884835243225098, avg loss: 1.3863680666685105\n",
      "trial: 5, iter: 1600, curr loss: 1.3857827186584473, avg loss: 1.3864067029953002\n",
      "trial: 5, iter: 1800, curr loss: 1.3869342803955078, avg loss: 1.38643993973732\n",
      "trial: 5, iter: 2000, curr loss: 1.3861552476882935, avg loss: 1.3863519656658172\n",
      "trial: 5, iter: 2200, curr loss: 1.3865106105804443, avg loss: 1.3863956570625304\n",
      "trial: 5, iter: 2400, curr loss: 1.3861743211746216, avg loss: 1.386383081674576\n",
      "trial: 5, iter: 2600, curr loss: 1.3867048025131226, avg loss: 1.3863578814268112\n",
      "trial: 5, iter: 2800, curr loss: 1.3864195346832275, avg loss: 1.3863450467586518\n",
      "trial: 5, iter: 3000, curr loss: 1.3853601217269897, avg loss: 1.386435912847519\n",
      "trial: 5, iter: 3200, curr loss: 1.385925531387329, avg loss: 1.386394791007042\n",
      "trial: 5, iter: 3400, curr loss: 1.3864036798477173, avg loss: 1.3863645058870315\n",
      "trial: 5, iter: 3600, curr loss: 1.3860690593719482, avg loss: 1.3864033639431\n",
      "trial: 5, iter: 3800, curr loss: 1.385389804840088, avg loss: 1.386361162662506\n",
      "trial: 5, iter: 4000, curr loss: 1.3857899904251099, avg loss: 1.3863382285833359\n",
      "trial: 5, iter: 4200, curr loss: 1.3855359554290771, avg loss: 1.386318633556366\n",
      "trial: 5, iter: 4400, curr loss: 1.3865302801132202, avg loss: 1.3863505482673646\n",
      "trial: 5, iter: 4600, curr loss: 1.3860279321670532, avg loss: 1.386317949295044\n",
      "trial: 5, iter: 4800, curr loss: 1.3850067853927612, avg loss: 1.3863610011339187\n",
      "trial: 5, iter: 5000, curr loss: 1.3861846923828125, avg loss: 1.3864227348566056\n",
      "trial: 5, iter: 5200, curr loss: 1.3861333131790161, avg loss: 1.3863160008192061\n",
      "trial: 5, iter: 5400, curr loss: 1.3864027261734009, avg loss: 1.3863660037517547\n",
      "trial: 5, iter: 5600, curr loss: 1.3862907886505127, avg loss: 1.3863451904058457\n",
      "trial: 5, iter: 5800, curr loss: 1.3862426280975342, avg loss: 1.3863065612316132\n",
      "trial: 5, iter: 6000, curr loss: 1.3859366178512573, avg loss: 1.386339362859726\n",
      "trial: 5, iter: 6200, curr loss: 1.3868190050125122, avg loss: 1.3863158589601516\n",
      "trial: 5, iter: 6400, curr loss: 1.3863409757614136, avg loss: 1.3863819295167923\n",
      "trial: 5, iter: 6600, curr loss: 1.386715054512024, avg loss: 1.3863099259138107\n",
      "trial: 5, iter: 6800, curr loss: 1.3857243061065674, avg loss: 1.3863074684143066\n",
      "trial: 5, iter: 7000, curr loss: 1.3861403465270996, avg loss: 1.3863148069381714\n",
      "trial: 5, iter: 7200, curr loss: 1.386507272720337, avg loss: 1.3863357359170914\n",
      "trial: 5, iter: 7400, curr loss: 1.3863584995269775, avg loss: 1.3862966173887252\n",
      "trial: 5, iter: 7600, curr loss: 1.3859624862670898, avg loss: 1.3863076382875443\n",
      "trial: 5, iter: 7800, curr loss: 1.386317253112793, avg loss: 1.3863174837827683\n",
      "trial: 5, iter: 8000, curr loss: 1.3865947723388672, avg loss: 1.3863192933797837\n",
      "trial: 5, iter: 8200, curr loss: 1.38638436794281, avg loss: 1.386316989660263\n",
      "trial: 5, iter: 8400, curr loss: 1.3861334323883057, avg loss: 1.3863056194782257\n",
      "trial: 5, iter: 8600, curr loss: 1.386286735534668, avg loss: 1.3863098621368408\n",
      "trial: 5, iter: 8800, curr loss: 1.3861279487609863, avg loss: 1.3862951481342316\n",
      "trial: 5, iter: 9000, curr loss: 1.3862733840942383, avg loss: 1.3863065493106843\n",
      "trial: 5, iter: 9200, curr loss: 1.3864047527313232, avg loss: 1.386291694045067\n",
      "trial: 5, iter: 9400, curr loss: 1.3863065242767334, avg loss: 1.3863015478849412\n",
      "trial: 5, iter: 9600, curr loss: 1.3864256143569946, avg loss: 1.3863072627782822\n",
      "trial: 5, iter: 9800, curr loss: 1.386331558227539, avg loss: 1.3863124579191208\n",
      "trial: 5, iter: 10000, curr loss: 1.3862282037734985, avg loss: 1.3863088929653167\n",
      "trial: 5, iter: 10200, curr loss: 1.3862905502319336, avg loss: 1.386303957104683\n",
      "trial: 5, iter: 10400, curr loss: 1.3863084316253662, avg loss: 1.3862856125831604\n",
      "trial: 5, iter: 10600, curr loss: 1.3867201805114746, avg loss: 1.3863228523731232\n",
      "trial: 5, iter: 10800, curr loss: 1.3862190246582031, avg loss: 1.3863116651773453\n",
      "trial: 5, iter: 11000, curr loss: 1.3865890502929688, avg loss: 1.3863696563243866\n",
      "trial: 5, iter: 11200, curr loss: 1.3863017559051514, avg loss: 1.3863054478168488\n",
      "trial: 5, iter: 11400, curr loss: 1.3862625360488892, avg loss: 1.3863122886419297\n",
      "trial: 5, iter: 11600, curr loss: 1.386325478553772, avg loss: 1.386331962943077\n",
      "trial: 5, iter: 11800, curr loss: 1.3866721391677856, avg loss: 1.3863172245025634\n",
      "trial: 5, iter: 12000, curr loss: 1.386877417564392, avg loss: 1.3862546241283418\n",
      "trial: 5, iter: 12200, curr loss: 1.3865001201629639, avg loss: 1.3863062119483949\n",
      "trial: 5, iter: 12400, curr loss: 1.3865078687667847, avg loss: 1.3863172018527985\n",
      "trial: 5, iter: 12600, curr loss: 1.3864175081253052, avg loss: 1.3862916314601899\n",
      "trial: 5, iter: 12800, curr loss: 1.3860230445861816, avg loss: 1.386313642859459\n",
      "trial: 5, iter: 13000, curr loss: 1.3863407373428345, avg loss: 1.38632097363472\n",
      "trial: 5, iter: 13200, curr loss: 1.3863085508346558, avg loss: 1.3863085007667542\n",
      "trial: 5, iter: 13400, curr loss: 1.386312484741211, avg loss: 1.3863033175468444\n",
      "trial: 5, iter: 13600, curr loss: 1.386251449584961, avg loss: 1.386297705769539\n",
      "trial: 5, iter: 13800, curr loss: 1.3864037990570068, avg loss: 1.3862988919019699\n",
      "trial: 5, iter: 14000, curr loss: 1.3863427639007568, avg loss: 1.386302067041397\n",
      "trial: 5, iter: 14200, curr loss: 1.3862825632095337, avg loss: 1.3862994718551636\n",
      "trial: 5, iter: 14400, curr loss: 1.3864357471466064, avg loss: 1.3863022875785829\n",
      "trial: 5, iter: 14600, curr loss: 1.3864585161209106, avg loss: 1.3863402205705642\n",
      "trial: 5, iter: 14800, curr loss: 1.3863637447357178, avg loss: 1.38630226790905\n",
      "trial: 5, iter: 15000, curr loss: 1.3863425254821777, avg loss: 1.3863099086284638\n",
      "trial: 5, iter: 15200, curr loss: 1.3863328695297241, avg loss: 1.3863095462322235\n",
      "trial: 5, iter: 15400, curr loss: 1.3861864805221558, avg loss: 1.3863109743595123\n",
      "trial: 5, iter: 15600, curr loss: 1.3860654830932617, avg loss: 1.3862963426113128\n",
      "trial: 5, ldr: -0.001368632772937417\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.000527048617368564\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3829143047332764, avg loss: 1.3873244851827622\n",
      "trial: 1, iter: 400, curr loss: 1.3893465995788574, avg loss: 1.3867106223106385\n",
      "trial: 1, iter: 600, curr loss: 1.3851271867752075, avg loss: 1.3865905106067657\n",
      "trial: 1, iter: 800, curr loss: 1.3861647844314575, avg loss: 1.3865106356143952\n",
      "trial: 1, iter: 1000, curr loss: 1.3855371475219727, avg loss: 1.3865154021978379\n",
      "trial: 1, iter: 1200, curr loss: 1.3871995210647583, avg loss: 1.3864148777723313\n",
      "trial: 1, iter: 1400, curr loss: 1.3859813213348389, avg loss: 1.3864191728830337\n",
      "trial: 1, iter: 1600, curr loss: 1.3855924606323242, avg loss: 1.3864129769802094\n",
      "trial: 1, iter: 1800, curr loss: 1.3863167762756348, avg loss: 1.3864093673229219\n",
      "trial: 1, iter: 2000, curr loss: 1.386800765991211, avg loss: 1.386297060251236\n",
      "trial: 1, iter: 2200, curr loss: 1.3866983652114868, avg loss: 1.3863463485240937\n",
      "trial: 1, iter: 2400, curr loss: 1.3871465921401978, avg loss: 1.3863878417015076\n",
      "trial: 1, iter: 2600, curr loss: 1.3854821920394897, avg loss: 1.38632530272007\n",
      "trial: 1, iter: 2800, curr loss: 1.3860831260681152, avg loss: 1.3863937312364578\n",
      "trial: 1, iter: 3000, curr loss: 1.3866366147994995, avg loss: 1.3863315397500993\n",
      "trial: 1, iter: 3200, curr loss: 1.3862009048461914, avg loss: 1.386382324695587\n",
      "trial: 1, iter: 3400, curr loss: 1.386440396308899, avg loss: 1.3863663119077683\n",
      "trial: 1, iter: 3600, curr loss: 1.386448860168457, avg loss: 1.3863088357448579\n",
      "trial: 1, iter: 3800, curr loss: 1.38565194606781, avg loss: 1.386319340467453\n",
      "trial: 1, iter: 4000, curr loss: 1.3860690593719482, avg loss: 1.3863807088136673\n",
      "trial: 1, iter: 4200, curr loss: 1.3864480257034302, avg loss: 1.3863722932338716\n",
      "trial: 1, iter: 4400, curr loss: 1.3868144750595093, avg loss: 1.3863462704420089\n",
      "trial: 1, iter: 4600, curr loss: 1.386824131011963, avg loss: 1.3863491249084472\n",
      "trial: 1, iter: 4800, curr loss: 1.3863812685012817, avg loss: 1.3863001018762589\n",
      "trial: 1, iter: 5000, curr loss: 1.38676917552948, avg loss: 1.386333146095276\n",
      "trial: 1, iter: 5200, curr loss: 1.3841924667358398, avg loss: 1.3863196384906769\n",
      "trial: 1, iter: 5400, curr loss: 1.3862292766571045, avg loss: 1.3864628225564957\n",
      "trial: 1, iter: 5600, curr loss: 1.3864376544952393, avg loss: 1.3862690997123719\n",
      "trial: 1, iter: 5800, curr loss: 1.3868682384490967, avg loss: 1.3863778525590897\n",
      "trial: 1, iter: 6000, curr loss: 1.3864235877990723, avg loss: 1.3863357067108155\n",
      "trial: 1, iter: 6200, curr loss: 1.3862478733062744, avg loss: 1.3863380646705628\n",
      "trial: 1, iter: 6400, curr loss: 1.3862224817276, avg loss: 1.3863269585371016\n",
      "trial: 1, iter: 6600, curr loss: 1.3864279985427856, avg loss: 1.38631028175354\n",
      "trial: 1, iter: 6800, curr loss: 1.3860976696014404, avg loss: 1.3863014060258865\n",
      "trial: 1, iter: 7000, curr loss: 1.3860785961151123, avg loss: 1.3863059604167938\n",
      "trial: 1, iter: 7200, curr loss: 1.386126160621643, avg loss: 1.3862980258464814\n",
      "trial: 1, iter: 7400, curr loss: 1.386373519897461, avg loss: 1.3863215482234954\n",
      "trial: 1, iter: 7600, curr loss: 1.3861004114151, avg loss: 1.3863194423913956\n",
      "trial: 1, iter: 7800, curr loss: 1.3865382671356201, avg loss: 1.3863049525022506\n",
      "trial: 1, iter: 8000, curr loss: 1.3861987590789795, avg loss: 1.3862935072183609\n",
      "trial: 1, iter: 8200, curr loss: 1.3862990140914917, avg loss: 1.3863260495662688\n",
      "trial: 1, iter: 8400, curr loss: 1.3861581087112427, avg loss: 1.3863046580553056\n",
      "trial: 1, iter: 8600, curr loss: 1.3862942457199097, avg loss: 1.386296735405922\n",
      "trial: 1, iter: 8800, curr loss: 1.386474609375, avg loss: 1.3863535922765733\n",
      "trial: 1, iter: 9000, curr loss: 1.386903166770935, avg loss: 1.3863241755962372\n",
      "trial: 1, iter: 9200, curr loss: 1.3866239786148071, avg loss: 1.3863013780117035\n",
      "trial: 1, iter: 9400, curr loss: 1.3856362104415894, avg loss: 1.386311381459236\n",
      "trial: 1, iter: 9600, curr loss: 1.3864840269088745, avg loss: 1.3863187479972838\n",
      "trial: 1, iter: 9800, curr loss: 1.386250376701355, avg loss: 1.3862989497184754\n",
      "trial: 1, iter: 10000, curr loss: 1.3864163160324097, avg loss: 1.386326435804367\n",
      "trial: 1, iter: 10200, curr loss: 1.386130452156067, avg loss: 1.386304302215576\n",
      "trial: 1, iter: 10400, curr loss: 1.386223554611206, avg loss: 1.3862888485193252\n",
      "trial: 1, iter: 10600, curr loss: 1.3865742683410645, avg loss: 1.3862730860710144\n",
      "trial: 1, iter: 10800, curr loss: 1.386988639831543, avg loss: 1.3863306879997253\n",
      "trial: 1, iter: 11000, curr loss: 1.386048436164856, avg loss: 1.3862638372182845\n",
      "trial: 1, iter: 11200, curr loss: 1.3864747285842896, avg loss: 1.3863576698303222\n",
      "trial: 1, iter: 11400, curr loss: 1.387725591659546, avg loss: 1.3863357985019684\n",
      "trial: 1, iter: 11600, curr loss: 1.3863325119018555, avg loss: 1.3863836246728898\n",
      "trial: 1, iter: 11800, curr loss: 1.3859314918518066, avg loss: 1.3863112092018128\n",
      "trial: 1, iter: 12000, curr loss: 1.3862417936325073, avg loss: 1.3863164114952087\n",
      "trial: 1, iter: 12200, curr loss: 1.3858857154846191, avg loss: 1.3862874174118043\n",
      "trial: 1, iter: 12400, curr loss: 1.3859702348709106, avg loss: 1.3863687282800674\n",
      "trial: 1, iter: 12600, curr loss: 1.3856627941131592, avg loss: 1.3862916398048402\n",
      "trial: 1, iter: 12800, curr loss: 1.3863885402679443, avg loss: 1.3863350296020507\n",
      "trial: 1, iter: 13000, curr loss: 1.3860780000686646, avg loss: 1.3862998497486114\n",
      "trial: 1, iter: 13200, curr loss: 1.386592984199524, avg loss: 1.3863079893589019\n",
      "trial: 1, iter: 13400, curr loss: 1.3863379955291748, avg loss: 1.3863211005926133\n",
      "trial: 1, iter: 13600, curr loss: 1.3859344720840454, avg loss: 1.386291868686676\n",
      "trial: 1, iter: 13800, curr loss: 1.3854122161865234, avg loss: 1.386279247403145\n",
      "trial: 1, iter: 14000, curr loss: 1.3863482475280762, avg loss: 1.3863330668210982\n",
      "trial: 1, iter: 14200, curr loss: 1.3862545490264893, avg loss: 1.3863101255893708\n",
      "trial: 1, iter: 14400, curr loss: 1.3863729238510132, avg loss: 1.386302936077118\n",
      "trial: 1, iter: 14600, curr loss: 1.3865686655044556, avg loss: 1.3862980902194977\n",
      "trial: 1, iter: 14800, curr loss: 1.3861849308013916, avg loss: 1.3862919956445694\n",
      "trial: 1, iter: 15000, curr loss: 1.3865116834640503, avg loss: 1.3862988156080247\n",
      "trial: 1, iter: 15200, curr loss: 1.3862160444259644, avg loss: 1.3863015460968018\n",
      "trial: 1, iter: 15400, curr loss: 1.386292576789856, avg loss: 1.3863018810749055\n",
      "trial: 1, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3862952768802643\n",
      "trial: 1, ldr: 3.693442295116256e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.384717583656311, avg loss: 1.387424891591072\n",
      "trial: 2, iter: 400, curr loss: 1.3873558044433594, avg loss: 1.386786442399025\n",
      "trial: 2, iter: 600, curr loss: 1.3879019021987915, avg loss: 1.3866277307271957\n",
      "trial: 2, iter: 800, curr loss: 1.3863681554794312, avg loss: 1.3865939408540726\n",
      "trial: 2, iter: 1000, curr loss: 1.3862913846969604, avg loss: 1.3863988542556762\n",
      "trial: 2, iter: 1200, curr loss: 1.3865529298782349, avg loss: 1.3862286859750748\n",
      "trial: 2, iter: 1400, curr loss: 1.3873299360275269, avg loss: 1.3865474081039428\n",
      "trial: 2, iter: 1600, curr loss: 1.3864381313323975, avg loss: 1.386427465081215\n",
      "trial: 2, iter: 1800, curr loss: 1.3871822357177734, avg loss: 1.386387016773224\n",
      "trial: 2, iter: 2000, curr loss: 1.3876813650131226, avg loss: 1.3864662700891495\n",
      "trial: 2, iter: 2200, curr loss: 1.3861784934997559, avg loss: 1.38637635409832\n",
      "trial: 2, iter: 2400, curr loss: 1.3868632316589355, avg loss: 1.3863321113586426\n",
      "trial: 2, iter: 2600, curr loss: 1.3861991167068481, avg loss: 1.3863511741161347\n",
      "trial: 2, iter: 2800, curr loss: 1.3877971172332764, avg loss: 1.386407389640808\n",
      "trial: 2, iter: 3000, curr loss: 1.3860775232315063, avg loss: 1.3863428848981858\n",
      "trial: 2, iter: 3200, curr loss: 1.3854625225067139, avg loss: 1.3863886737823485\n",
      "trial: 2, iter: 3400, curr loss: 1.3869694471359253, avg loss: 1.3863236129283905\n",
      "trial: 2, iter: 3600, curr loss: 1.386205792427063, avg loss: 1.3863062870502472\n",
      "trial: 2, iter: 3800, curr loss: 1.3865314722061157, avg loss: 1.3863499581813812\n",
      "trial: 2, iter: 4000, curr loss: 1.3868992328643799, avg loss: 1.3863246220350265\n",
      "trial: 2, iter: 4200, curr loss: 1.386883020401001, avg loss: 1.3863240557909011\n",
      "trial: 2, iter: 4400, curr loss: 1.3867968320846558, avg loss: 1.3863396447896958\n",
      "trial: 2, iter: 4600, curr loss: 1.387035846710205, avg loss: 1.386348066329956\n",
      "trial: 2, iter: 4800, curr loss: 1.3864437341690063, avg loss: 1.3862989407777786\n",
      "trial: 2, iter: 5000, curr loss: 1.3870468139648438, avg loss: 1.3863156646490098\n",
      "trial: 2, iter: 5200, curr loss: 1.385555624961853, avg loss: 1.386395919919014\n",
      "trial: 2, iter: 5400, curr loss: 1.3861087560653687, avg loss: 1.386364158987999\n",
      "trial: 2, iter: 5600, curr loss: 1.386349081993103, avg loss: 1.3863169091939926\n",
      "trial: 2, iter: 5800, curr loss: 1.3858124017715454, avg loss: 1.3863208776712417\n",
      "trial: 2, iter: 6000, curr loss: 1.3859798908233643, avg loss: 1.3863119971752167\n",
      "trial: 2, iter: 6200, curr loss: 1.386278748512268, avg loss: 1.3863276219367981\n",
      "trial: 2, iter: 6400, curr loss: 1.3861593008041382, avg loss: 1.3863271045684815\n",
      "trial: 2, iter: 6600, curr loss: 1.3868604898452759, avg loss: 1.3863397789001466\n",
      "trial: 2, iter: 6800, curr loss: 1.3866747617721558, avg loss: 1.3862976819276809\n",
      "trial: 2, iter: 7000, curr loss: 1.3872687816619873, avg loss: 1.386283342242241\n",
      "trial: 2, iter: 7200, curr loss: 1.386934757232666, avg loss: 1.3864105588197708\n",
      "trial: 2, iter: 7400, curr loss: 1.386720061302185, avg loss: 1.3863379126787185\n",
      "trial: 2, iter: 7600, curr loss: 1.3861660957336426, avg loss: 1.3863420832157134\n",
      "trial: 2, iter: 7800, curr loss: 1.3873176574707031, avg loss: 1.3863493347167968\n",
      "trial: 2, iter: 8000, curr loss: 1.386433482170105, avg loss: 1.3863843673467635\n",
      "trial: 2, iter: 8200, curr loss: 1.3860167264938354, avg loss: 1.3863339000940322\n",
      "trial: 2, iter: 8400, curr loss: 1.3858915567398071, avg loss: 1.3863460564613341\n",
      "trial: 2, iter: 8600, curr loss: 1.3866479396820068, avg loss: 1.3863291591405869\n",
      "trial: 2, iter: 8800, curr loss: 1.386021375656128, avg loss: 1.38630852162838\n",
      "trial: 2, iter: 9000, curr loss: 1.386020302772522, avg loss: 1.3862976002693177\n",
      "trial: 2, iter: 9200, curr loss: 1.3864734172821045, avg loss: 1.38631587266922\n",
      "trial: 2, iter: 9400, curr loss: 1.3862385749816895, avg loss: 1.386334888935089\n",
      "trial: 2, iter: 9600, curr loss: 1.3861809968948364, avg loss: 1.3862815535068511\n",
      "trial: 2, iter: 9800, curr loss: 1.3862080574035645, avg loss: 1.3863889569044112\n",
      "trial: 2, iter: 10000, curr loss: 1.3856627941131592, avg loss: 1.3863372921943664\n",
      "trial: 2, iter: 10200, curr loss: 1.3865814208984375, avg loss: 1.3863523817062378\n",
      "trial: 2, iter: 10400, curr loss: 1.3862433433532715, avg loss: 1.3863327264785767\n",
      "trial: 2, iter: 10600, curr loss: 1.3861117362976074, avg loss: 1.3863270163536072\n",
      "trial: 2, iter: 10800, curr loss: 1.386299967765808, avg loss: 1.3863101410865784\n",
      "trial: 2, iter: 11000, curr loss: 1.3860769271850586, avg loss: 1.3863325065374374\n",
      "trial: 2, iter: 11200, curr loss: 1.3865172863006592, avg loss: 1.3863193315267563\n",
      "trial: 2, iter: 11400, curr loss: 1.3861993551254272, avg loss: 1.3863119477033614\n",
      "trial: 2, iter: 11600, curr loss: 1.3862274885177612, avg loss: 1.386303250193596\n",
      "trial: 2, iter: 11800, curr loss: 1.3865633010864258, avg loss: 1.3862792253494263\n",
      "trial: 2, iter: 12000, curr loss: 1.3872029781341553, avg loss: 1.3862731140851974\n",
      "trial: 2, iter: 12200, curr loss: 1.3874930143356323, avg loss: 1.386315867304802\n",
      "trial: 2, iter: 12400, curr loss: 1.3863904476165771, avg loss: 1.386320520043373\n",
      "trial: 2, iter: 12600, curr loss: 1.3863188028335571, avg loss: 1.3863075625896455\n",
      "trial: 2, iter: 12800, curr loss: 1.3863905668258667, avg loss: 1.3863072460889816\n",
      "trial: 2, iter: 13000, curr loss: 1.3864229917526245, avg loss: 1.386296928524971\n",
      "trial: 2, iter: 13200, curr loss: 1.386439561843872, avg loss: 1.3863133537769317\n",
      "trial: 2, iter: 13400, curr loss: 1.3862919807434082, avg loss: 1.3862979370355606\n",
      "trial: 2, iter: 13600, curr loss: 1.3862802982330322, avg loss: 1.3862922120094299\n",
      "trial: 2, iter: 13800, curr loss: 1.3863074779510498, avg loss: 1.3863633757829665\n",
      "trial: 2, iter: 14000, curr loss: 1.3850305080413818, avg loss: 1.3862702578306199\n",
      "trial: 2, iter: 14200, curr loss: 1.386597752571106, avg loss: 1.3863101619482041\n",
      "trial: 2, iter: 14400, curr loss: 1.3860646486282349, avg loss: 1.3863205099105835\n",
      "trial: 2, iter: 14600, curr loss: 1.3862143754959106, avg loss: 1.3862893706560135\n",
      "trial: 2, iter: 14800, curr loss: 1.386946201324463, avg loss: 1.3863176357746125\n",
      "trial: 2, iter: 15000, curr loss: 1.3862942457199097, avg loss: 1.3863244622945785\n",
      "trial: 2, iter: 15200, curr loss: 1.3862656354904175, avg loss: 1.386297146677971\n",
      "trial: 2, iter: 15400, curr loss: 1.3862779140472412, avg loss: 1.386306221485138\n",
      "trial: 2, iter: 15600, curr loss: 1.3861767053604126, avg loss: 1.3862847590446472\n",
      "trial: 2, ldr: 0.0006231308216229081\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873766660690308, avg loss: 1.3871745163202285\n",
      "trial: 3, iter: 400, curr loss: 1.386745572090149, avg loss: 1.3866306549310685\n",
      "trial: 3, iter: 600, curr loss: 1.3857879638671875, avg loss: 1.386552328467369\n",
      "trial: 3, iter: 800, curr loss: 1.3865382671356201, avg loss: 1.3865332645177841\n",
      "trial: 3, iter: 1000, curr loss: 1.3846864700317383, avg loss: 1.386442351937294\n",
      "trial: 3, iter: 1200, curr loss: 1.3873999118804932, avg loss: 1.3865488946437836\n",
      "trial: 3, iter: 1400, curr loss: 1.3863648176193237, avg loss: 1.3864012205600738\n",
      "trial: 3, iter: 1600, curr loss: 1.3869143724441528, avg loss: 1.386451569199562\n",
      "trial: 3, iter: 1800, curr loss: 1.3865915536880493, avg loss: 1.3864159125089646\n",
      "trial: 3, iter: 2000, curr loss: 1.3872082233428955, avg loss: 1.386440926194191\n",
      "trial: 3, iter: 2200, curr loss: 1.3858364820480347, avg loss: 1.3863689088821411\n",
      "trial: 3, iter: 2400, curr loss: 1.3856641054153442, avg loss: 1.3863669580221176\n",
      "trial: 3, iter: 2600, curr loss: 1.38601815700531, avg loss: 1.3863644623756408\n",
      "trial: 3, iter: 2800, curr loss: 1.3862640857696533, avg loss: 1.3863289242982864\n",
      "trial: 3, iter: 3000, curr loss: 1.3864836692810059, avg loss: 1.3864040404558182\n",
      "trial: 3, iter: 3200, curr loss: 1.3862298727035522, avg loss: 1.3863213074207306\n",
      "trial: 3, iter: 3400, curr loss: 1.386426568031311, avg loss: 1.3863403469324111\n",
      "trial: 3, iter: 3600, curr loss: 1.386677861213684, avg loss: 1.3863339298963546\n",
      "trial: 3, iter: 3800, curr loss: 1.386249303817749, avg loss: 1.3863153642416\n",
      "trial: 3, iter: 4000, curr loss: 1.3865717649459839, avg loss: 1.386341460943222\n",
      "trial: 3, iter: 4200, curr loss: 1.3861000537872314, avg loss: 1.386328866481781\n",
      "trial: 3, iter: 4400, curr loss: 1.3863946199417114, avg loss: 1.3863052541017533\n",
      "trial: 3, iter: 4600, curr loss: 1.3860573768615723, avg loss: 1.3862777119874954\n",
      "trial: 3, iter: 4800, curr loss: 1.3863348960876465, avg loss: 1.3863119083642959\n",
      "trial: 3, iter: 5000, curr loss: 1.3872268199920654, avg loss: 1.386326608657837\n",
      "trial: 3, iter: 5200, curr loss: 1.386570930480957, avg loss: 1.3863162046670914\n",
      "trial: 3, iter: 5400, curr loss: 1.3870980739593506, avg loss: 1.3863302075862884\n",
      "trial: 3, iter: 5600, curr loss: 1.3856518268585205, avg loss: 1.3863429749011993\n",
      "trial: 3, iter: 5800, curr loss: 1.3867298364639282, avg loss: 1.3863006752729417\n",
      "trial: 3, iter: 6000, curr loss: 1.3865896463394165, avg loss: 1.3863479882478713\n",
      "trial: 3, iter: 6200, curr loss: 1.3864402770996094, avg loss: 1.3862942886352538\n",
      "trial: 3, iter: 6400, curr loss: 1.3865371942520142, avg loss: 1.3863284140825272\n",
      "trial: 3, iter: 6600, curr loss: 1.3861637115478516, avg loss: 1.3863376265764236\n",
      "trial: 3, iter: 6800, curr loss: 1.3864524364471436, avg loss: 1.386321268081665\n",
      "trial: 3, iter: 7000, curr loss: 1.3879624605178833, avg loss: 1.3863254523277282\n",
      "trial: 3, iter: 7200, curr loss: 1.3860130310058594, avg loss: 1.3863416546583176\n",
      "trial: 3, iter: 7400, curr loss: 1.3864474296569824, avg loss: 1.3863930702209473\n",
      "trial: 3, iter: 7600, curr loss: 1.3866065740585327, avg loss: 1.3863059979677201\n",
      "trial: 3, iter: 7800, curr loss: 1.3869988918304443, avg loss: 1.3862850791215897\n",
      "trial: 3, iter: 8000, curr loss: 1.3866759538650513, avg loss: 1.3862992471456528\n",
      "trial: 3, iter: 8200, curr loss: 1.3867015838623047, avg loss: 1.386321845650673\n",
      "trial: 3, iter: 8400, curr loss: 1.3867425918579102, avg loss: 1.3863280600309371\n",
      "trial: 3, iter: 8600, curr loss: 1.3862717151641846, avg loss: 1.386335928440094\n",
      "trial: 3, iter: 8800, curr loss: 1.3865728378295898, avg loss: 1.3863149559497834\n",
      "trial: 3, iter: 9000, curr loss: 1.3862051963806152, avg loss: 1.386304476261139\n",
      "trial: 3, iter: 9200, curr loss: 1.3861234188079834, avg loss: 1.3863044595718383\n",
      "trial: 3, iter: 9400, curr loss: 1.3863112926483154, avg loss: 1.3863112992048263\n",
      "trial: 3, iter: 9600, curr loss: 1.386301875114441, avg loss: 1.3863163954019546\n",
      "trial: 3, iter: 9800, curr loss: 1.386222243309021, avg loss: 1.3863056230545043\n",
      "trial: 3, iter: 10000, curr loss: 1.3862664699554443, avg loss: 1.3862986224889755\n",
      "trial: 3, iter: 10200, curr loss: 1.386470079421997, avg loss: 1.3862929940223694\n",
      "trial: 3, iter: 10400, curr loss: 1.3862465620040894, avg loss: 1.3863132536411285\n",
      "trial: 3, iter: 10600, curr loss: 1.3864662647247314, avg loss: 1.3862916618585586\n",
      "trial: 3, iter: 10800, curr loss: 1.3862621784210205, avg loss: 1.3863171440362931\n",
      "trial: 3, iter: 11000, curr loss: 1.3861544132232666, avg loss: 1.3863315868377686\n",
      "trial: 3, iter: 11200, curr loss: 1.3859837055206299, avg loss: 1.386294328570366\n",
      "trial: 3, iter: 11400, curr loss: 1.3862464427947998, avg loss: 1.386320236325264\n",
      "trial: 3, iter: 11600, curr loss: 1.386324405670166, avg loss: 1.3863060426712037\n",
      "trial: 3, iter: 11800, curr loss: 1.386293888092041, avg loss: 1.3862951934337615\n",
      "trial: 3, iter: 12000, curr loss: 1.3862944841384888, avg loss: 1.3862947124242782\n",
      "trial: 3, iter: 12200, curr loss: 1.3862947225570679, avg loss: 1.3862947911024093\n",
      "trial: 3, iter: 12400, curr loss: 1.386294960975647, avg loss: 1.3862947416305542\n",
      "trial: 3, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.3862947225570679\n",
      "trial: 3, iter: 12800, curr loss: 1.3862947225570679, avg loss: 1.386294839978218\n",
      "trial: 3, iter: 13000, curr loss: 1.3862943649291992, avg loss: 1.3862947195768356\n",
      "trial: 3, iter: 13200, curr loss: 1.3862948417663574, avg loss: 1.3862946915626526\n",
      "trial: 3, iter: 13400, curr loss: 1.3862944841384888, avg loss: 1.3862945520877838\n",
      "trial: 3, iter: 13600, curr loss: 1.3862946033477783, avg loss: 1.3862946194410324\n",
      "trial: 3, iter: 13800, curr loss: 1.3862948417663574, avg loss: 1.386294614672661\n",
      "trial: 3, iter: 14000, curr loss: 1.386295199394226, avg loss: 1.386294710636139\n",
      "trial: 3, iter: 14200, curr loss: 1.386297345161438, avg loss: 1.3862947726249695\n",
      "trial: 3, iter: 14400, curr loss: 1.3862944841384888, avg loss: 1.3862946498394013\n",
      "trial: 3, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.3862946969270706\n",
      "trial: 3, iter: 14800, curr loss: 1.3862947225570679, avg loss: 1.3862947630882263\n",
      "trial: 3, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.3862948685884475\n",
      "trial: 3, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386294954419136\n",
      "trial: 3, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.3862949573993684\n",
      "trial: 3, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 3, ldr: -5.960464477539063e-08\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3867758512496948, avg loss: 1.3875288987159728\n",
      "trial: 4, iter: 400, curr loss: 1.3842129707336426, avg loss: 1.3867529761791229\n",
      "trial: 4, iter: 600, curr loss: 1.3901538848876953, avg loss: 1.3865229052305221\n",
      "trial: 4, iter: 800, curr loss: 1.3872995376586914, avg loss: 1.3866675698757172\n",
      "trial: 4, iter: 1000, curr loss: 1.3867945671081543, avg loss: 1.3864838373661041\n",
      "trial: 4, iter: 1200, curr loss: 1.385539174079895, avg loss: 1.3864079636335374\n",
      "trial: 4, iter: 1400, curr loss: 1.3857923746109009, avg loss: 1.3863898134231567\n",
      "trial: 4, iter: 1600, curr loss: 1.3876618146896362, avg loss: 1.386407408118248\n",
      "trial: 4, iter: 1800, curr loss: 1.3852860927581787, avg loss: 1.3863999563455582\n",
      "trial: 4, iter: 2000, curr loss: 1.3879990577697754, avg loss: 1.3862288564443588\n",
      "trial: 4, iter: 2200, curr loss: 1.3864213228225708, avg loss: 1.386410660147667\n",
      "trial: 4, iter: 2400, curr loss: 1.386248230934143, avg loss: 1.3863615250587464\n",
      "trial: 4, iter: 2600, curr loss: 1.3858615159988403, avg loss: 1.3863370245695115\n",
      "trial: 4, iter: 2800, curr loss: 1.3856732845306396, avg loss: 1.3863053047657012\n",
      "trial: 4, iter: 3000, curr loss: 1.385921597480774, avg loss: 1.386342556476593\n",
      "trial: 4, iter: 3200, curr loss: 1.386329174041748, avg loss: 1.386295275092125\n",
      "trial: 4, iter: 3400, curr loss: 1.3852488994598389, avg loss: 1.3863754957914352\n",
      "trial: 4, iter: 3600, curr loss: 1.3865238428115845, avg loss: 1.3864076137542725\n",
      "trial: 4, iter: 3800, curr loss: 1.3864351511001587, avg loss: 1.3864234459400178\n",
      "trial: 4, iter: 4000, curr loss: 1.3858449459075928, avg loss: 1.3863482856750489\n",
      "trial: 4, iter: 4200, curr loss: 1.3859840631484985, avg loss: 1.3863396310806275\n",
      "trial: 4, iter: 4400, curr loss: 1.384863257408142, avg loss: 1.3862130391597747\n",
      "trial: 4, iter: 4600, curr loss: 1.3855232000350952, avg loss: 1.3863978070020675\n",
      "trial: 4, iter: 4800, curr loss: 1.3860373497009277, avg loss: 1.3863046270608903\n",
      "trial: 4, iter: 5000, curr loss: 1.3868967294692993, avg loss: 1.3863493460416794\n",
      "trial: 4, iter: 5200, curr loss: 1.3870986700057983, avg loss: 1.386314162015915\n",
      "trial: 4, iter: 5400, curr loss: 1.386662244796753, avg loss: 1.3862965667247773\n",
      "trial: 4, iter: 5600, curr loss: 1.3863825798034668, avg loss: 1.3862874948978423\n",
      "trial: 4, iter: 5800, curr loss: 1.386452078819275, avg loss: 1.3863312655687332\n",
      "trial: 4, iter: 6000, curr loss: 1.3869154453277588, avg loss: 1.3862953722476958\n",
      "trial: 4, iter: 6200, curr loss: 1.386573314666748, avg loss: 1.3863180524110794\n",
      "trial: 4, iter: 6400, curr loss: 1.3869549036026, avg loss: 1.3862995612621307\n",
      "trial: 4, iter: 6600, curr loss: 1.3865212202072144, avg loss: 1.3863263875246048\n",
      "trial: 4, iter: 6800, curr loss: 1.3871009349822998, avg loss: 1.3863001209497452\n",
      "trial: 4, iter: 7000, curr loss: 1.3860514163970947, avg loss: 1.3863042098283769\n",
      "trial: 4, iter: 7200, curr loss: 1.3864948749542236, avg loss: 1.386344360113144\n",
      "trial: 4, iter: 7400, curr loss: 1.3869373798370361, avg loss: 1.3862747985124588\n",
      "trial: 4, iter: 7600, curr loss: 1.3863556385040283, avg loss: 1.3863550329208374\n",
      "trial: 4, iter: 7800, curr loss: 1.386423110961914, avg loss: 1.3863140255212785\n",
      "trial: 4, iter: 8000, curr loss: 1.386154055595398, avg loss: 1.3863040345907212\n",
      "trial: 4, iter: 8200, curr loss: 1.3863924741744995, avg loss: 1.3863055205345154\n",
      "trial: 4, iter: 8400, curr loss: 1.3863036632537842, avg loss: 1.3863111239671708\n",
      "trial: 4, iter: 8600, curr loss: 1.386225700378418, avg loss: 1.3863764482736587\n",
      "trial: 4, iter: 8800, curr loss: 1.3863248825073242, avg loss: 1.3862839758396148\n",
      "trial: 4, iter: 9000, curr loss: 1.3868080377578735, avg loss: 1.3863099932670593\n",
      "trial: 4, iter: 9200, curr loss: 1.3863571882247925, avg loss: 1.3863109701871872\n",
      "trial: 4, iter: 9400, curr loss: 1.386110782623291, avg loss: 1.3863044172525405\n",
      "trial: 4, iter: 9600, curr loss: 1.3864778280258179, avg loss: 1.3862947034835815\n",
      "trial: 4, iter: 9800, curr loss: 1.38601553440094, avg loss: 1.3863212370872497\n",
      "trial: 4, iter: 10000, curr loss: 1.38640558719635, avg loss: 1.3863002181053161\n",
      "trial: 4, iter: 10200, curr loss: 1.3863332271575928, avg loss: 1.3862980949878692\n",
      "trial: 4, iter: 10400, curr loss: 1.3865426778793335, avg loss: 1.38630091547966\n",
      "trial: 4, iter: 10600, curr loss: 1.3863035440444946, avg loss: 1.3862958341836928\n",
      "trial: 4, iter: 10800, curr loss: 1.386298418045044, avg loss: 1.3863250571489334\n",
      "trial: 4, iter: 11000, curr loss: 1.3863219022750854, avg loss: 1.3863048195838927\n",
      "trial: 4, iter: 11200, curr loss: 1.3866392374038696, avg loss: 1.3862934547662735\n",
      "trial: 4, iter: 11400, curr loss: 1.3861907720565796, avg loss: 1.3863179188966752\n",
      "trial: 4, iter: 11600, curr loss: 1.3862005472183228, avg loss: 1.3863074886798858\n",
      "trial: 4, iter: 11800, curr loss: 1.386165738105774, avg loss: 1.386278955936432\n",
      "trial: 4, iter: 12000, curr loss: 1.3865853548049927, avg loss: 1.386289405822754\n",
      "trial: 4, iter: 12200, curr loss: 1.386577844619751, avg loss: 1.3862950164079666\n",
      "trial: 4, iter: 12400, curr loss: 1.3866521120071411, avg loss: 1.3863125705718995\n",
      "trial: 4, iter: 12600, curr loss: 1.3863935470581055, avg loss: 1.386326208114624\n",
      "trial: 4, iter: 12800, curr loss: 1.3862438201904297, avg loss: 1.386291424036026\n",
      "trial: 4, iter: 13000, curr loss: 1.3862295150756836, avg loss: 1.3863079112768173\n",
      "trial: 4, iter: 13200, curr loss: 1.3863276243209839, avg loss: 1.3863049691915512\n",
      "trial: 4, iter: 13400, curr loss: 1.3869636058807373, avg loss: 1.3863015180826188\n",
      "trial: 4, iter: 13600, curr loss: 1.386474609375, avg loss: 1.386299457550049\n",
      "trial: 4, iter: 13800, curr loss: 1.3864705562591553, avg loss: 1.3862905955314637\n",
      "trial: 4, iter: 14000, curr loss: 1.3860499858856201, avg loss: 1.3863120090961456\n",
      "trial: 4, iter: 14200, curr loss: 1.3865678310394287, avg loss: 1.3863042718172074\n",
      "trial: 4, iter: 14400, curr loss: 1.3864259719848633, avg loss: 1.3863070291280746\n",
      "trial: 4, iter: 14600, curr loss: 1.386161208152771, avg loss: 1.386301121711731\n",
      "trial: 4, iter: 14800, curr loss: 1.3861916065216064, avg loss: 1.3863135182857513\n",
      "trial: 4, iter: 15000, curr loss: 1.3864108324050903, avg loss: 1.3862887769937515\n",
      "trial: 4, iter: 15200, curr loss: 1.3862861394882202, avg loss: 1.386316688656807\n",
      "trial: 4, iter: 15400, curr loss: 1.3862566947937012, avg loss: 1.386296534538269\n",
      "trial: 4, iter: 15600, curr loss: 1.3862665891647339, avg loss: 1.3862924921512603\n",
      "trial: 4, ldr: 0.0016060961643233895\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3869946002960205, avg loss: 1.3872635161876679\n",
      "trial: 5, iter: 400, curr loss: 1.3872840404510498, avg loss: 1.3865669655799866\n",
      "trial: 5, iter: 600, curr loss: 1.3863661289215088, avg loss: 1.3865348172187806\n",
      "trial: 5, iter: 800, curr loss: 1.3851553201675415, avg loss: 1.3863351660966874\n",
      "trial: 5, iter: 1000, curr loss: 1.3857685327529907, avg loss: 1.3864348423480988\n",
      "trial: 5, iter: 1200, curr loss: 1.3868379592895508, avg loss: 1.3864514815807343\n",
      "trial: 5, iter: 1400, curr loss: 1.3863087892532349, avg loss: 1.3864731347560884\n",
      "trial: 5, iter: 1600, curr loss: 1.3875352144241333, avg loss: 1.386521919965744\n",
      "trial: 5, iter: 1800, curr loss: 1.3848570585250854, avg loss: 1.386430428624153\n",
      "trial: 5, iter: 2000, curr loss: 1.386812686920166, avg loss: 1.3864251732826234\n",
      "trial: 5, iter: 2200, curr loss: 1.3856216669082642, avg loss: 1.3863814783096313\n",
      "trial: 5, iter: 2400, curr loss: 1.3863919973373413, avg loss: 1.3864192825555801\n",
      "trial: 5, iter: 2600, curr loss: 1.3861502408981323, avg loss: 1.3863378155231476\n",
      "trial: 5, iter: 2800, curr loss: 1.3856606483459473, avg loss: 1.3863800644874573\n",
      "trial: 5, iter: 3000, curr loss: 1.3860710859298706, avg loss: 1.3863557910919189\n",
      "trial: 5, iter: 3200, curr loss: 1.3863078355789185, avg loss: 1.386379110813141\n",
      "trial: 5, iter: 3400, curr loss: 1.3860912322998047, avg loss: 1.3863344949483871\n",
      "trial: 5, iter: 3600, curr loss: 1.385039210319519, avg loss: 1.3863729882240294\n",
      "trial: 5, iter: 3800, curr loss: 1.3850051164627075, avg loss: 1.3863412320613862\n",
      "trial: 5, iter: 4000, curr loss: 1.3859282732009888, avg loss: 1.3863485497236252\n",
      "trial: 5, iter: 4200, curr loss: 1.386377215385437, avg loss: 1.386334165930748\n",
      "trial: 5, iter: 4400, curr loss: 1.3866244554519653, avg loss: 1.3863464087247848\n",
      "trial: 5, iter: 4600, curr loss: 1.3859297037124634, avg loss: 1.3863500547409058\n",
      "trial: 5, iter: 4800, curr loss: 1.3864057064056396, avg loss: 1.3862926149368286\n",
      "trial: 5, iter: 5000, curr loss: 1.3864244222640991, avg loss: 1.386329444050789\n",
      "trial: 5, iter: 5200, curr loss: 1.3862111568450928, avg loss: 1.386342743039131\n",
      "trial: 5, iter: 5400, curr loss: 1.3863531351089478, avg loss: 1.3863235664367677\n",
      "trial: 5, iter: 5600, curr loss: 1.3868478536605835, avg loss: 1.3863252717256547\n",
      "trial: 5, iter: 5800, curr loss: 1.3863164186477661, avg loss: 1.3862990987300874\n",
      "trial: 5, iter: 6000, curr loss: 1.3863338232040405, avg loss: 1.3863125157356262\n",
      "trial: 5, iter: 6200, curr loss: 1.3864847421646118, avg loss: 1.3863150453567505\n",
      "trial: 5, iter: 6400, curr loss: 1.386404037475586, avg loss: 1.3863229215145112\n",
      "trial: 5, iter: 6600, curr loss: 1.38566255569458, avg loss: 1.3863134914636612\n",
      "trial: 5, iter: 6800, curr loss: 1.3853263854980469, avg loss: 1.386287865638733\n",
      "trial: 5, iter: 7000, curr loss: 1.3867731094360352, avg loss: 1.3864222800731658\n",
      "trial: 5, iter: 7200, curr loss: 1.3861255645751953, avg loss: 1.3863317716121673\n",
      "trial: 5, iter: 7400, curr loss: 1.3865071535110474, avg loss: 1.3863161516189575\n",
      "trial: 5, iter: 7600, curr loss: 1.3863177299499512, avg loss: 1.3863080775737762\n",
      "trial: 5, iter: 7800, curr loss: 1.3867065906524658, avg loss: 1.386292787194252\n",
      "trial: 5, iter: 8000, curr loss: 1.3852251768112183, avg loss: 1.3863190919160844\n",
      "trial: 5, iter: 8200, curr loss: 1.3864344358444214, avg loss: 1.3863350385427475\n",
      "trial: 5, iter: 8400, curr loss: 1.3866233825683594, avg loss: 1.3863205659389495\n",
      "trial: 5, iter: 8600, curr loss: 1.386342167854309, avg loss: 1.38628038585186\n",
      "trial: 5, iter: 8800, curr loss: 1.3863972425460815, avg loss: 1.386312865614891\n",
      "trial: 5, iter: 9000, curr loss: 1.3864697217941284, avg loss: 1.3862921285629273\n",
      "trial: 5, iter: 9200, curr loss: 1.3865020275115967, avg loss: 1.3863174307346344\n",
      "trial: 5, iter: 9400, curr loss: 1.3863564729690552, avg loss: 1.3862926185131073\n",
      "trial: 5, iter: 9600, curr loss: 1.3863078355789185, avg loss: 1.386302900314331\n",
      "trial: 5, iter: 9800, curr loss: 1.386386513710022, avg loss: 1.3862975811958314\n",
      "trial: 5, iter: 10000, curr loss: 1.3866807222366333, avg loss: 1.3862885916233063\n",
      "trial: 5, iter: 10200, curr loss: 1.3865543603897095, avg loss: 1.386362910270691\n",
      "trial: 5, iter: 10400, curr loss: 1.385962963104248, avg loss: 1.3863311249017716\n",
      "trial: 5, iter: 10600, curr loss: 1.3857083320617676, avg loss: 1.386305667757988\n",
      "trial: 5, iter: 10800, curr loss: 1.3867220878601074, avg loss: 1.3863171726465224\n",
      "trial: 5, iter: 11000, curr loss: 1.3865046501159668, avg loss: 1.3862995767593385\n",
      "trial: 5, iter: 11200, curr loss: 1.3862617015838623, avg loss: 1.3863798415660857\n",
      "trial: 5, iter: 11400, curr loss: 1.386130690574646, avg loss: 1.386302433013916\n",
      "trial: 5, iter: 11600, curr loss: 1.3862693309783936, avg loss: 1.3863315039873123\n",
      "trial: 5, iter: 11800, curr loss: 1.3853535652160645, avg loss: 1.386290808916092\n",
      "trial: 5, iter: 12000, curr loss: 1.3863333463668823, avg loss: 1.3863182747364045\n",
      "trial: 5, iter: 12200, curr loss: 1.386621356010437, avg loss: 1.3862878930568696\n",
      "trial: 5, iter: 12400, curr loss: 1.3864428997039795, avg loss: 1.3863248020410537\n",
      "trial: 5, iter: 12600, curr loss: 1.3861820697784424, avg loss: 1.3863075548410415\n",
      "trial: 5, iter: 12800, curr loss: 1.3863656520843506, avg loss: 1.3863214367628098\n",
      "trial: 5, iter: 13000, curr loss: 1.3862704038619995, avg loss: 1.3863034355640411\n",
      "trial: 5, iter: 13200, curr loss: 1.3862096071243286, avg loss: 1.3862924551963807\n",
      "trial: 5, iter: 13400, curr loss: 1.3864729404449463, avg loss: 1.3863256859779358\n",
      "trial: 5, iter: 13600, curr loss: 1.386717677116394, avg loss: 1.3863078135251998\n",
      "trial: 5, iter: 13800, curr loss: 1.3870301246643066, avg loss: 1.3863513046503066\n",
      "trial: 5, iter: 14000, curr loss: 1.3862441778182983, avg loss: 1.3863326787948609\n",
      "trial: 5, iter: 14200, curr loss: 1.3857190608978271, avg loss: 1.3863033312559128\n",
      "trial: 5, iter: 14400, curr loss: 1.3858147859573364, avg loss: 1.386358349919319\n",
      "trial: 5, iter: 14600, curr loss: 1.3860559463500977, avg loss: 1.3863598412275315\n",
      "trial: 5, iter: 14800, curr loss: 1.3862894773483276, avg loss: 1.3863073313236236\n",
      "trial: 5, iter: 15000, curr loss: 1.3860607147216797, avg loss: 1.386286204457283\n",
      "trial: 5, iter: 15200, curr loss: 1.3861663341522217, avg loss: 1.3862989258766174\n",
      "trial: 5, iter: 15400, curr loss: 1.3867108821868896, avg loss: 1.3863028532266617\n",
      "trial: 5, iter: 15600, curr loss: 1.3862498998641968, avg loss: 1.386316967010498\n",
      "trial: 5, ldr: -0.0008812843589112163\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00027031529293708445\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3879121541976929, avg loss: 1.3870485258102416\n",
      "trial: 1, iter: 400, curr loss: 1.3862720727920532, avg loss: 1.386753888130188\n",
      "trial: 1, iter: 600, curr loss: 1.3879706859588623, avg loss: 1.3863928306102753\n",
      "trial: 1, iter: 800, curr loss: 1.387663722038269, avg loss: 1.3864138001203536\n",
      "trial: 1, iter: 1000, curr loss: 1.3865811824798584, avg loss: 1.3864941132068633\n",
      "trial: 1, iter: 1200, curr loss: 1.3874974250793457, avg loss: 1.3863324415683747\n",
      "trial: 1, iter: 1400, curr loss: 1.386993646621704, avg loss: 1.3863215166330338\n",
      "trial: 1, iter: 1600, curr loss: 1.3863351345062256, avg loss: 1.3863775885105134\n",
      "trial: 1, iter: 1800, curr loss: 1.3860507011413574, avg loss: 1.386321918964386\n",
      "trial: 1, iter: 2000, curr loss: 1.3875263929367065, avg loss: 1.3864006793498993\n",
      "trial: 1, iter: 2200, curr loss: 1.3872185945510864, avg loss: 1.3864247626066208\n",
      "trial: 1, iter: 2400, curr loss: 1.3866677284240723, avg loss: 1.3863558888435363\n",
      "trial: 1, iter: 2600, curr loss: 1.3865524530410767, avg loss: 1.3863744169473649\n",
      "trial: 1, iter: 2800, curr loss: 1.3847811222076416, avg loss: 1.3863834422826766\n",
      "trial: 1, iter: 3000, curr loss: 1.3864165544509888, avg loss: 1.3863674318790435\n",
      "trial: 1, iter: 3200, curr loss: 1.3864846229553223, avg loss: 1.3863867980241775\n",
      "trial: 1, iter: 3400, curr loss: 1.3865795135498047, avg loss: 1.386296490430832\n",
      "trial: 1, iter: 3600, curr loss: 1.3865517377853394, avg loss: 1.386398104429245\n",
      "trial: 1, iter: 3800, curr loss: 1.3859808444976807, avg loss: 1.3863240605592728\n",
      "trial: 1, iter: 4000, curr loss: 1.385322093963623, avg loss: 1.3862782162427902\n",
      "trial: 1, iter: 4200, curr loss: 1.386590600013733, avg loss: 1.3863510125875473\n",
      "trial: 1, iter: 4400, curr loss: 1.3860877752304077, avg loss: 1.3862874948978423\n",
      "trial: 1, iter: 4600, curr loss: 1.386552333831787, avg loss: 1.3863946568965912\n",
      "trial: 1, iter: 4800, curr loss: 1.3867709636688232, avg loss: 1.3863099122047424\n",
      "trial: 1, iter: 5000, curr loss: 1.385636329650879, avg loss: 1.386300716996193\n",
      "trial: 1, iter: 5200, curr loss: 1.386185884475708, avg loss: 1.3863071024417877\n",
      "trial: 1, iter: 5400, curr loss: 1.386271595954895, avg loss: 1.3863258016109468\n",
      "trial: 1, iter: 5600, curr loss: 1.3862303495407104, avg loss: 1.386303323507309\n",
      "trial: 1, iter: 5800, curr loss: 1.3863747119903564, avg loss: 1.3863163322210312\n",
      "trial: 1, iter: 6000, curr loss: 1.385694146156311, avg loss: 1.3863049918413162\n",
      "trial: 1, iter: 6200, curr loss: 1.3860875368118286, avg loss: 1.3862854272127152\n",
      "trial: 1, iter: 6400, curr loss: 1.3864825963974, avg loss: 1.386320366859436\n",
      "trial: 1, iter: 6600, curr loss: 1.3869446516036987, avg loss: 1.3862946707010269\n",
      "trial: 1, iter: 6800, curr loss: 1.386312484741211, avg loss: 1.3863545477390289\n",
      "trial: 1, iter: 7000, curr loss: 1.3856232166290283, avg loss: 1.386335181593895\n",
      "trial: 1, iter: 7200, curr loss: 1.386869192123413, avg loss: 1.3863591873645782\n",
      "trial: 1, iter: 7400, curr loss: 1.3871433734893799, avg loss: 1.386331350207329\n",
      "trial: 1, iter: 7600, curr loss: 1.3864850997924805, avg loss: 1.3863744777441025\n",
      "trial: 1, iter: 7800, curr loss: 1.3861552476882935, avg loss: 1.3863790613412856\n",
      "trial: 1, iter: 8000, curr loss: 1.3859837055206299, avg loss: 1.3863855183124543\n",
      "trial: 1, iter: 8200, curr loss: 1.3865947723388672, avg loss: 1.386359260082245\n",
      "trial: 1, iter: 8400, curr loss: 1.3865119218826294, avg loss: 1.3863236767053604\n",
      "trial: 1, iter: 8600, curr loss: 1.3869436979293823, avg loss: 1.386313014626503\n",
      "trial: 1, iter: 8800, curr loss: 1.3866513967514038, avg loss: 1.386313064098358\n",
      "trial: 1, iter: 9000, curr loss: 1.3864634037017822, avg loss: 1.3863197994232177\n",
      "trial: 1, iter: 9200, curr loss: 1.3862682580947876, avg loss: 1.386309978365898\n",
      "trial: 1, iter: 9400, curr loss: 1.387149691581726, avg loss: 1.3863122725486756\n",
      "trial: 1, iter: 9600, curr loss: 1.386439561843872, avg loss: 1.386394744515419\n",
      "trial: 1, iter: 9800, curr loss: 1.386196255683899, avg loss: 1.3862725961208344\n",
      "trial: 1, iter: 10000, curr loss: 1.3863158226013184, avg loss: 1.3863204288482667\n",
      "trial: 1, iter: 10200, curr loss: 1.3861929178237915, avg loss: 1.3863149070739746\n",
      "trial: 1, iter: 10400, curr loss: 1.3857879638671875, avg loss: 1.3862900936603546\n",
      "trial: 1, iter: 10600, curr loss: 1.3860654830932617, avg loss: 1.386281585097313\n",
      "trial: 1, iter: 10800, curr loss: 1.3866075277328491, avg loss: 1.3863074600696563\n",
      "trial: 1, iter: 11000, curr loss: 1.3863543272018433, avg loss: 1.386298453807831\n",
      "trial: 1, iter: 11200, curr loss: 1.3863002061843872, avg loss: 1.386297451853752\n",
      "trial: 1, iter: 11400, curr loss: 1.3863815069198608, avg loss: 1.3863060611486435\n",
      "trial: 1, iter: 11600, curr loss: 1.3863533735275269, avg loss: 1.3862964540719986\n",
      "trial: 1, iter: 11800, curr loss: 1.386472225189209, avg loss: 1.3862938022613525\n",
      "trial: 1, iter: 12000, curr loss: 1.3861191272735596, avg loss: 1.3862920486927033\n",
      "trial: 1, iter: 12200, curr loss: 1.3858275413513184, avg loss: 1.3862809872627258\n",
      "trial: 1, iter: 12400, curr loss: 1.3859890699386597, avg loss: 1.38635513484478\n",
      "trial: 1, iter: 12600, curr loss: 1.3862417936325073, avg loss: 1.3863101774454116\n",
      "trial: 1, iter: 12800, curr loss: 1.3862792253494263, avg loss: 1.3863666689395904\n",
      "trial: 1, iter: 13000, curr loss: 1.3864036798477173, avg loss: 1.3864054203033447\n",
      "trial: 1, iter: 13200, curr loss: 1.3862062692642212, avg loss: 1.3863091057538985\n",
      "trial: 1, iter: 13400, curr loss: 1.3862864971160889, avg loss: 1.3863029676675795\n",
      "trial: 1, iter: 13600, curr loss: 1.3863030672073364, avg loss: 1.3863044428825377\n",
      "trial: 1, iter: 13800, curr loss: 1.386293888092041, avg loss: 1.386305381655693\n",
      "trial: 1, iter: 14000, curr loss: 1.386128306388855, avg loss: 1.3862910515069962\n",
      "trial: 1, iter: 14200, curr loss: 1.3864185810089111, avg loss: 1.3863037979602815\n",
      "trial: 1, iter: 14400, curr loss: 1.3846832513809204, avg loss: 1.3862397080659867\n",
      "trial: 1, iter: 14600, curr loss: 1.3863565921783447, avg loss: 1.386415139436722\n",
      "trial: 1, iter: 14800, curr loss: 1.3856927156448364, avg loss: 1.38638745367527\n",
      "trial: 1, iter: 15000, curr loss: 1.3869330883026123, avg loss: 1.3864635086059571\n",
      "trial: 1, iter: 15200, curr loss: 1.3866043090820312, avg loss: 1.3863700532913208\n",
      "trial: 1, iter: 15400, curr loss: 1.3864704370498657, avg loss: 1.3864015901088715\n",
      "trial: 1, iter: 15600, curr loss: 1.3870360851287842, avg loss: 1.3862860560417176\n",
      "trial: 1, ldr: -0.009714720770716667\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3905932903289795, avg loss: 1.3872019934654236\n",
      "trial: 2, iter: 400, curr loss: 1.3855451345443726, avg loss: 1.386751452088356\n",
      "trial: 2, iter: 600, curr loss: 1.386080026626587, avg loss: 1.3866605651378632\n",
      "trial: 2, iter: 800, curr loss: 1.385603666305542, avg loss: 1.3864702767133712\n",
      "trial: 2, iter: 1000, curr loss: 1.387121558189392, avg loss: 1.386411616206169\n",
      "trial: 2, iter: 1200, curr loss: 1.3877475261688232, avg loss: 1.3864004385471345\n",
      "trial: 2, iter: 1400, curr loss: 1.3855098485946655, avg loss: 1.386432345509529\n",
      "trial: 2, iter: 1600, curr loss: 1.386646032333374, avg loss: 1.3863633161783218\n",
      "trial: 2, iter: 1800, curr loss: 1.3860582113265991, avg loss: 1.3864520335197448\n",
      "trial: 2, iter: 2000, curr loss: 1.386143684387207, avg loss: 1.3864497917890548\n",
      "trial: 2, iter: 2200, curr loss: 1.3878915309906006, avg loss: 1.3863714343309403\n",
      "trial: 2, iter: 2400, curr loss: 1.387970209121704, avg loss: 1.3863615483045577\n",
      "trial: 2, iter: 2600, curr loss: 1.3869638442993164, avg loss: 1.3863205516338348\n",
      "trial: 2, iter: 2800, curr loss: 1.38686203956604, avg loss: 1.3863499629497529\n",
      "trial: 2, iter: 3000, curr loss: 1.3862146139144897, avg loss: 1.3863774013519288\n",
      "trial: 2, iter: 3200, curr loss: 1.3863208293914795, avg loss: 1.3863345992565155\n",
      "trial: 2, iter: 3400, curr loss: 1.3865466117858887, avg loss: 1.386333178281784\n",
      "trial: 2, iter: 3600, curr loss: 1.385928750038147, avg loss: 1.3863352888822555\n",
      "trial: 2, iter: 3800, curr loss: 1.386138916015625, avg loss: 1.3863056021928788\n",
      "trial: 2, iter: 4000, curr loss: 1.3861552476882935, avg loss: 1.3863286620378494\n",
      "trial: 2, iter: 4200, curr loss: 1.3864753246307373, avg loss: 1.3863666826486587\n",
      "trial: 2, iter: 4400, curr loss: 1.3856287002563477, avg loss: 1.3863837510347365\n",
      "trial: 2, iter: 4600, curr loss: 1.38640558719635, avg loss: 1.3863300442695619\n",
      "trial: 2, iter: 4800, curr loss: 1.3872934579849243, avg loss: 1.3863479852676392\n",
      "trial: 2, iter: 5000, curr loss: 1.3862637281417847, avg loss: 1.3863040113449097\n",
      "trial: 2, iter: 5200, curr loss: 1.3861792087554932, avg loss: 1.3863265430927276\n",
      "trial: 2, iter: 5400, curr loss: 1.3861699104309082, avg loss: 1.3864053070545197\n",
      "trial: 2, iter: 5600, curr loss: 1.3859009742736816, avg loss: 1.3863755589723588\n",
      "trial: 2, iter: 5800, curr loss: 1.3864140510559082, avg loss: 1.3863625121116638\n",
      "trial: 2, iter: 6000, curr loss: 1.386102557182312, avg loss: 1.3863371074199677\n",
      "trial: 2, iter: 6200, curr loss: 1.3865145444869995, avg loss: 1.3863152486085892\n",
      "trial: 2, iter: 6400, curr loss: 1.3862601518630981, avg loss: 1.3863326317071916\n",
      "trial: 2, iter: 6600, curr loss: 1.3859260082244873, avg loss: 1.3863165217638016\n",
      "trial: 2, iter: 6800, curr loss: 1.3865703344345093, avg loss: 1.3863394451141358\n",
      "trial: 2, iter: 7000, curr loss: 1.3865197896957397, avg loss: 1.3863203352689744\n",
      "trial: 2, iter: 7200, curr loss: 1.385901689529419, avg loss: 1.3862790769338609\n",
      "trial: 2, iter: 7400, curr loss: 1.3861370086669922, avg loss: 1.3863179802894592\n",
      "trial: 2, iter: 7600, curr loss: 1.386094331741333, avg loss: 1.3863301932811738\n",
      "trial: 2, iter: 7800, curr loss: 1.3863489627838135, avg loss: 1.3863177359104157\n",
      "trial: 2, iter: 8000, curr loss: 1.3865015506744385, avg loss: 1.3863132125139237\n",
      "trial: 2, iter: 8200, curr loss: 1.3864344358444214, avg loss: 1.386322147846222\n",
      "trial: 2, iter: 8400, curr loss: 1.38633394241333, avg loss: 1.3863353806734084\n",
      "trial: 2, iter: 8600, curr loss: 1.3876770734786987, avg loss: 1.386323214173317\n",
      "trial: 2, iter: 8800, curr loss: 1.3865090608596802, avg loss: 1.3864150494337082\n",
      "trial: 2, iter: 9000, curr loss: 1.3866957426071167, avg loss: 1.3864220809936523\n",
      "trial: 2, iter: 9200, curr loss: 1.3853967189788818, avg loss: 1.3863816463947296\n",
      "trial: 2, iter: 9400, curr loss: 1.3851407766342163, avg loss: 1.3863348823785782\n",
      "trial: 2, iter: 9600, curr loss: 1.385683298110962, avg loss: 1.3863357895612716\n",
      "trial: 2, iter: 9800, curr loss: 1.3861968517303467, avg loss: 1.3863257282972337\n",
      "trial: 2, iter: 10000, curr loss: 1.386115550994873, avg loss: 1.3863327795267104\n",
      "trial: 2, iter: 10200, curr loss: 1.386247158050537, avg loss: 1.3862867861986161\n",
      "trial: 2, iter: 10400, curr loss: 1.3860864639282227, avg loss: 1.3863452702760697\n",
      "trial: 2, iter: 10600, curr loss: 1.3866755962371826, avg loss: 1.386311530470848\n",
      "trial: 2, iter: 10800, curr loss: 1.3859786987304688, avg loss: 1.3862907415628434\n",
      "trial: 2, iter: 11000, curr loss: 1.3866243362426758, avg loss: 1.38632359623909\n",
      "trial: 2, iter: 11200, curr loss: 1.386690378189087, avg loss: 1.3862945127487183\n",
      "trial: 2, iter: 11400, curr loss: 1.3873032331466675, avg loss: 1.3864146852493286\n",
      "trial: 2, iter: 11600, curr loss: 1.3861852884292603, avg loss: 1.386349425315857\n",
      "trial: 2, iter: 11800, curr loss: 1.3859297037124634, avg loss: 1.386319026350975\n",
      "trial: 2, iter: 12000, curr loss: 1.3861502408981323, avg loss: 1.3863100081682205\n",
      "trial: 2, iter: 12200, curr loss: 1.3859742879867554, avg loss: 1.3863149619102477\n",
      "trial: 2, iter: 12400, curr loss: 1.3862159252166748, avg loss: 1.3862859749794005\n",
      "trial: 2, iter: 12600, curr loss: 1.3860892057418823, avg loss: 1.3863035428524018\n",
      "trial: 2, iter: 12800, curr loss: 1.3864502906799316, avg loss: 1.3862844520807267\n",
      "trial: 2, iter: 13000, curr loss: 1.386670708656311, avg loss: 1.386330559849739\n",
      "trial: 2, iter: 13200, curr loss: 1.3865175247192383, avg loss: 1.3863196188211442\n",
      "trial: 2, iter: 13400, curr loss: 1.3864493370056152, avg loss: 1.3863115954399108\n",
      "trial: 2, iter: 13600, curr loss: 1.3860291242599487, avg loss: 1.3863024431467057\n",
      "trial: 2, iter: 13800, curr loss: 1.3864984512329102, avg loss: 1.3863006913661957\n",
      "trial: 2, iter: 14000, curr loss: 1.3861722946166992, avg loss: 1.3863104820251464\n",
      "trial: 2, iter: 14200, curr loss: 1.3865331411361694, avg loss: 1.3862791669368744\n",
      "trial: 2, iter: 14400, curr loss: 1.3860810995101929, avg loss: 1.386310269832611\n",
      "trial: 2, iter: 14600, curr loss: 1.3865333795547485, avg loss: 1.3863138967752457\n",
      "trial: 2, iter: 14800, curr loss: 1.3860187530517578, avg loss: 1.386277866959572\n",
      "trial: 2, iter: 15000, curr loss: 1.3860323429107666, avg loss: 1.3863111162185668\n",
      "trial: 2, iter: 15200, curr loss: 1.3862546682357788, avg loss: 1.3863328570127487\n",
      "trial: 2, iter: 15400, curr loss: 1.386373519897461, avg loss: 1.3862920516729356\n",
      "trial: 2, iter: 15600, curr loss: 1.3863415718078613, avg loss: 1.3862878793478013\n",
      "trial: 2, ldr: 0.0010041658533737063\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3874337673187256, avg loss: 1.387471115589142\n",
      "trial: 3, iter: 400, curr loss: 1.3843488693237305, avg loss: 1.3865607100725175\n",
      "trial: 3, iter: 600, curr loss: 1.3876014947891235, avg loss: 1.3865288865566254\n",
      "trial: 3, iter: 800, curr loss: 1.3847227096557617, avg loss: 1.3865616196393966\n",
      "trial: 3, iter: 1000, curr loss: 1.388980746269226, avg loss: 1.3864926886558533\n",
      "trial: 3, iter: 1200, curr loss: 1.386289358139038, avg loss: 1.3864435464143754\n",
      "trial: 3, iter: 1400, curr loss: 1.3861933946609497, avg loss: 1.3863739722967148\n",
      "trial: 3, iter: 1600, curr loss: 1.385219693183899, avg loss: 1.3863015115261077\n",
      "trial: 3, iter: 1800, curr loss: 1.3856267929077148, avg loss: 1.3863564497232437\n",
      "trial: 3, iter: 2000, curr loss: 1.3862894773483276, avg loss: 1.38633151948452\n",
      "trial: 3, iter: 2200, curr loss: 1.3863627910614014, avg loss: 1.386344759464264\n",
      "trial: 3, iter: 2400, curr loss: 1.386687159538269, avg loss: 1.386347907781601\n",
      "trial: 3, iter: 2600, curr loss: 1.3862582445144653, avg loss: 1.3864086985588073\n",
      "trial: 3, iter: 2800, curr loss: 1.3867900371551514, avg loss: 1.3863726061582566\n",
      "trial: 3, iter: 3000, curr loss: 1.3853552341461182, avg loss: 1.3863024151325225\n",
      "trial: 3, iter: 3200, curr loss: 1.385716438293457, avg loss: 1.386355756521225\n",
      "trial: 3, iter: 3400, curr loss: 1.385558009147644, avg loss: 1.3863443696498872\n",
      "trial: 3, iter: 3600, curr loss: 1.3865822553634644, avg loss: 1.3863233315944672\n",
      "trial: 3, iter: 3800, curr loss: 1.386278748512268, avg loss: 1.3863378477096557\n",
      "trial: 3, iter: 4000, curr loss: 1.3863577842712402, avg loss: 1.3863390409946441\n",
      "trial: 3, iter: 4200, curr loss: 1.3861632347106934, avg loss: 1.3863110148906708\n",
      "trial: 3, iter: 4400, curr loss: 1.386110544204712, avg loss: 1.3863031154870986\n",
      "trial: 3, iter: 4600, curr loss: 1.3855959177017212, avg loss: 1.3862858825922013\n",
      "trial: 3, iter: 4800, curr loss: 1.3867062330245972, avg loss: 1.3863205474615097\n",
      "trial: 3, iter: 5000, curr loss: 1.3859502077102661, avg loss: 1.3863331919908524\n",
      "trial: 3, iter: 5200, curr loss: 1.3862134218215942, avg loss: 1.3863197463750838\n",
      "trial: 3, iter: 5400, curr loss: 1.386047601699829, avg loss: 1.3863171577453612\n",
      "trial: 3, iter: 5600, curr loss: 1.386660099029541, avg loss: 1.3863402670621872\n",
      "trial: 3, iter: 5800, curr loss: 1.3865923881530762, avg loss: 1.386325306892395\n",
      "trial: 3, iter: 6000, curr loss: 1.3858962059020996, avg loss: 1.3862967151403427\n",
      "trial: 3, iter: 6200, curr loss: 1.3861573934555054, avg loss: 1.3863225489854814\n",
      "trial: 3, iter: 6400, curr loss: 1.3865770101547241, avg loss: 1.3863212871551513\n",
      "trial: 3, iter: 6600, curr loss: 1.3862991333007812, avg loss: 1.386323134303093\n",
      "trial: 3, iter: 6800, curr loss: 1.3866441249847412, avg loss: 1.386301294565201\n",
      "trial: 3, iter: 7000, curr loss: 1.3863521814346313, avg loss: 1.3863025623559952\n",
      "trial: 3, iter: 7200, curr loss: 1.386267900466919, avg loss: 1.386307390332222\n",
      "trial: 3, iter: 7400, curr loss: 1.3859925270080566, avg loss: 1.3864028531312942\n",
      "trial: 3, iter: 7600, curr loss: 1.3866866827011108, avg loss: 1.3863631677627564\n",
      "trial: 3, iter: 7800, curr loss: 1.3860695362091064, avg loss: 1.3863055485486984\n",
      "trial: 3, iter: 8000, curr loss: 1.385719895362854, avg loss: 1.3862734711170197\n",
      "trial: 3, iter: 8200, curr loss: 1.3859937191009521, avg loss: 1.3863440185785294\n",
      "trial: 3, iter: 8400, curr loss: 1.3867169618606567, avg loss: 1.3863080126047134\n",
      "trial: 3, iter: 8600, curr loss: 1.3865081071853638, avg loss: 1.386330059170723\n",
      "trial: 3, iter: 8800, curr loss: 1.3863248825073242, avg loss: 1.3863219791650772\n",
      "trial: 3, iter: 9000, curr loss: 1.3863346576690674, avg loss: 1.386312673687935\n",
      "trial: 3, iter: 9200, curr loss: 1.3862062692642212, avg loss: 1.3863038355112076\n",
      "trial: 3, iter: 9400, curr loss: 1.3862379789352417, avg loss: 1.3863304018974305\n",
      "trial: 3, iter: 9600, curr loss: 1.3862206935882568, avg loss: 1.386291121840477\n",
      "trial: 3, iter: 9800, curr loss: 1.3867205381393433, avg loss: 1.386334201693535\n",
      "trial: 3, iter: 10000, curr loss: 1.3859641551971436, avg loss: 1.3862912666797638\n",
      "trial: 3, iter: 10200, curr loss: 1.3863558769226074, avg loss: 1.3863272380828857\n",
      "trial: 3, iter: 10400, curr loss: 1.386431336402893, avg loss: 1.3863113111257552\n",
      "trial: 3, iter: 10600, curr loss: 1.386470913887024, avg loss: 1.386308672428131\n",
      "trial: 3, iter: 10800, curr loss: 1.3863611221313477, avg loss: 1.3863014382123948\n",
      "trial: 3, iter: 11000, curr loss: 1.3861017227172852, avg loss: 1.3862823575735093\n",
      "trial: 3, iter: 11200, curr loss: 1.3862284421920776, avg loss: 1.3863092333078384\n",
      "trial: 3, iter: 11400, curr loss: 1.3859957456588745, avg loss: 1.3863006448745727\n",
      "trial: 3, iter: 11600, curr loss: 1.3863540887832642, avg loss: 1.386286654472351\n",
      "trial: 3, iter: 11800, curr loss: 1.3863155841827393, avg loss: 1.386314544081688\n",
      "trial: 3, iter: 12000, curr loss: 1.386238694190979, avg loss: 1.3863003301620482\n",
      "trial: 3, iter: 12200, curr loss: 1.3863615989685059, avg loss: 1.3862869071960449\n",
      "trial: 3, iter: 12400, curr loss: 1.3860880136489868, avg loss: 1.3863099992275238\n",
      "trial: 3, iter: 12600, curr loss: 1.3862650394439697, avg loss: 1.3862944960594177\n",
      "trial: 3, iter: 12800, curr loss: 1.38633131980896, avg loss: 1.3863121807575225\n",
      "trial: 3, iter: 13000, curr loss: 1.3862946033477783, avg loss: 1.3863038593530654\n",
      "trial: 3, iter: 13200, curr loss: 1.3862929344177246, avg loss: 1.3862947970628738\n",
      "trial: 3, iter: 13400, curr loss: 1.386297583580017, avg loss: 1.3862945765256882\n",
      "trial: 3, iter: 13600, curr loss: 1.3862947225570679, avg loss: 1.3862943691015244\n",
      "trial: 3, iter: 13800, curr loss: 1.3862944841384888, avg loss: 1.3862948876619339\n",
      "trial: 3, iter: 14000, curr loss: 1.3862942457199097, avg loss: 1.3862945550680161\n",
      "trial: 3, iter: 14200, curr loss: 1.3862943649291992, avg loss: 1.3862948524951935\n",
      "trial: 3, iter: 14400, curr loss: 1.3862943649291992, avg loss: 1.3862944382429123\n",
      "trial: 3, iter: 14600, curr loss: 1.3862839937210083, avg loss: 1.3862977182865144\n",
      "trial: 3, iter: 14800, curr loss: 1.386296272277832, avg loss: 1.3862946027517318\n",
      "trial: 3, iter: 15000, curr loss: 1.3862948417663574, avg loss: 1.3862946540117265\n",
      "trial: 3, iter: 15200, curr loss: 1.3862953186035156, avg loss: 1.3862945055961609\n",
      "trial: 3, iter: 15400, curr loss: 1.3862940073013306, avg loss: 1.3862945252656937\n",
      "trial: 3, iter: 15600, curr loss: 1.3862943649291992, avg loss: 1.38629458963871\n",
      "trial: 3, ldr: 8.505608093400951e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3855141401290894, avg loss: 1.3873737472295762\n",
      "trial: 4, iter: 400, curr loss: 1.38703453540802, avg loss: 1.3867602688074112\n",
      "trial: 4, iter: 600, curr loss: 1.386338710784912, avg loss: 1.386643499135971\n",
      "trial: 4, iter: 800, curr loss: 1.3851209878921509, avg loss: 1.3863859713077544\n",
      "trial: 4, iter: 1000, curr loss: 1.3866186141967773, avg loss: 1.3864792436361313\n",
      "trial: 4, iter: 1200, curr loss: 1.3859026432037354, avg loss: 1.3863353097438813\n",
      "trial: 4, iter: 1400, curr loss: 1.3860228061676025, avg loss: 1.3864144206047058\n",
      "trial: 4, iter: 1600, curr loss: 1.3864469528198242, avg loss: 1.3864102602005004\n",
      "trial: 4, iter: 1800, curr loss: 1.3868749141693115, avg loss: 1.386488569378853\n",
      "trial: 4, iter: 2000, curr loss: 1.3870271444320679, avg loss: 1.3864442485570907\n",
      "trial: 4, iter: 2200, curr loss: 1.3863506317138672, avg loss: 1.3864635133743286\n",
      "trial: 4, iter: 2400, curr loss: 1.3862123489379883, avg loss: 1.3864154589176179\n",
      "trial: 4, iter: 2600, curr loss: 1.3869065046310425, avg loss: 1.3863663971424103\n",
      "trial: 4, iter: 2800, curr loss: 1.3884944915771484, avg loss: 1.386379531621933\n",
      "trial: 4, iter: 3000, curr loss: 1.3873395919799805, avg loss: 1.386375430226326\n",
      "trial: 4, iter: 3200, curr loss: 1.3866043090820312, avg loss: 1.3863756686449051\n",
      "trial: 4, iter: 3400, curr loss: 1.3858911991119385, avg loss: 1.3863622099161148\n",
      "trial: 4, iter: 3600, curr loss: 1.3866419792175293, avg loss: 1.386369298696518\n",
      "trial: 4, iter: 3800, curr loss: 1.3867160081863403, avg loss: 1.386323451399803\n",
      "trial: 4, iter: 4000, curr loss: 1.3856016397476196, avg loss: 1.3863642638921738\n",
      "trial: 4, iter: 4200, curr loss: 1.3859919309616089, avg loss: 1.386341973543167\n",
      "trial: 4, iter: 4400, curr loss: 1.3865028619766235, avg loss: 1.3863129049539566\n",
      "trial: 4, iter: 4600, curr loss: 1.386905312538147, avg loss: 1.3863562446832658\n",
      "trial: 4, iter: 4800, curr loss: 1.3860424757003784, avg loss: 1.3863260680437088\n",
      "trial: 4, iter: 5000, curr loss: 1.3869210481643677, avg loss: 1.3863039064407348\n",
      "trial: 4, iter: 5200, curr loss: 1.38534414768219, avg loss: 1.3863054478168488\n",
      "trial: 4, iter: 5400, curr loss: 1.3862923383712769, avg loss: 1.3863528883457183\n",
      "trial: 4, iter: 5600, curr loss: 1.3862212896347046, avg loss: 1.3863456010818482\n",
      "trial: 4, iter: 5800, curr loss: 1.3867907524108887, avg loss: 1.3863025969266891\n",
      "trial: 4, iter: 6000, curr loss: 1.3857762813568115, avg loss: 1.3863879758119584\n",
      "trial: 4, iter: 6200, curr loss: 1.3862102031707764, avg loss: 1.386365334391594\n",
      "trial: 4, iter: 6400, curr loss: 1.3863465785980225, avg loss: 1.3863117986917495\n",
      "trial: 4, iter: 6600, curr loss: 1.3864161968231201, avg loss: 1.386311287879944\n",
      "trial: 4, iter: 6800, curr loss: 1.3875346183776855, avg loss: 1.3864270663261413\n",
      "trial: 4, iter: 7000, curr loss: 1.3875683546066284, avg loss: 1.3863650941848755\n",
      "trial: 4, iter: 7200, curr loss: 1.385986328125, avg loss: 1.386341362595558\n",
      "trial: 4, iter: 7400, curr loss: 1.3879363536834717, avg loss: 1.38625411093235\n",
      "trial: 4, iter: 7600, curr loss: 1.387144684791565, avg loss: 1.3862973749637604\n",
      "trial: 4, iter: 7800, curr loss: 1.386620044708252, avg loss: 1.3863480204343797\n",
      "trial: 4, iter: 8000, curr loss: 1.3871532678604126, avg loss: 1.3863295698165894\n",
      "trial: 4, iter: 8200, curr loss: 1.3867708444595337, avg loss: 1.386311845779419\n",
      "trial: 4, iter: 8400, curr loss: 1.3864741325378418, avg loss: 1.3863249391317367\n",
      "trial: 4, iter: 8600, curr loss: 1.3860901594161987, avg loss: 1.3862879133224488\n",
      "trial: 4, iter: 8800, curr loss: 1.3860809803009033, avg loss: 1.3863457614183425\n",
      "trial: 4, iter: 9000, curr loss: 1.3863942623138428, avg loss: 1.3863143521547316\n",
      "trial: 4, iter: 9200, curr loss: 1.3863316774368286, avg loss: 1.3863002896308898\n",
      "trial: 4, iter: 9400, curr loss: 1.3861891031265259, avg loss: 1.3862947344779968\n",
      "trial: 4, iter: 9600, curr loss: 1.3862844705581665, avg loss: 1.3862929439544678\n",
      "trial: 4, iter: 9800, curr loss: 1.3863046169281006, avg loss: 1.386312854886055\n",
      "trial: 4, iter: 10000, curr loss: 1.3864378929138184, avg loss: 1.3862952768802643\n",
      "trial: 4, iter: 10200, curr loss: 1.3863581418991089, avg loss: 1.3863105434179306\n",
      "trial: 4, iter: 10400, curr loss: 1.3861336708068848, avg loss: 1.3863094937801361\n",
      "trial: 4, iter: 10600, curr loss: 1.3854503631591797, avg loss: 1.3862871646881103\n",
      "trial: 4, iter: 10800, curr loss: 1.3859318494796753, avg loss: 1.3863082647323608\n",
      "trial: 4, iter: 11000, curr loss: 1.3865506649017334, avg loss: 1.3863000565767287\n",
      "trial: 4, iter: 11200, curr loss: 1.3867336511611938, avg loss: 1.3862725591659546\n",
      "trial: 4, iter: 11400, curr loss: 1.3862413167953491, avg loss: 1.3863033598661423\n",
      "trial: 4, iter: 11600, curr loss: 1.3859771490097046, avg loss: 1.3863065701723098\n",
      "trial: 4, iter: 11800, curr loss: 1.3863087892532349, avg loss: 1.3863054877519607\n",
      "trial: 4, iter: 12000, curr loss: 1.3864285945892334, avg loss: 1.386323037147522\n",
      "trial: 4, iter: 12200, curr loss: 1.386190414428711, avg loss: 1.386337287425995\n",
      "trial: 4, iter: 12400, curr loss: 1.386284351348877, avg loss: 1.3863058066368104\n",
      "trial: 4, iter: 12600, curr loss: 1.3863121271133423, avg loss: 1.3863547164201737\n",
      "trial: 4, iter: 12800, curr loss: 1.3862377405166626, avg loss: 1.3863194674253463\n",
      "trial: 4, iter: 13000, curr loss: 1.3862754106521606, avg loss: 1.3863075125217437\n",
      "trial: 4, iter: 13200, curr loss: 1.3863846063613892, avg loss: 1.386266477704048\n",
      "trial: 4, iter: 13400, curr loss: 1.3863089084625244, avg loss: 1.3863281869888306\n",
      "trial: 4, iter: 13600, curr loss: 1.3861619234085083, avg loss: 1.3863069838285447\n",
      "trial: 4, iter: 13800, curr loss: 1.3863370418548584, avg loss: 1.3862829887866974\n",
      "trial: 4, iter: 14000, curr loss: 1.3871036767959595, avg loss: 1.3863321232795716\n",
      "trial: 4, iter: 14200, curr loss: 1.3860855102539062, avg loss: 1.3863161134719848\n",
      "trial: 4, iter: 14400, curr loss: 1.386415958404541, avg loss: 1.3862828457355498\n",
      "trial: 4, iter: 14600, curr loss: 1.3862217664718628, avg loss: 1.3863148021697997\n",
      "trial: 4, iter: 14800, curr loss: 1.3865582942962646, avg loss: 1.3862962287664413\n",
      "trial: 4, iter: 15000, curr loss: 1.3862569332122803, avg loss: 1.3863149708509446\n",
      "trial: 4, iter: 15200, curr loss: 1.3862793445587158, avg loss: 1.3863153541088105\n",
      "trial: 4, iter: 15400, curr loss: 1.3863117694854736, avg loss: 1.3862946969270706\n",
      "trial: 4, iter: 15600, curr loss: 1.3862427473068237, avg loss: 1.3863041830062866\n",
      "trial: 4, ldr: -0.004485211335122585\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3870211839675903, avg loss: 1.3873283767700195\n",
      "trial: 5, iter: 400, curr loss: 1.387864351272583, avg loss: 1.3868301701545716\n",
      "trial: 5, iter: 600, curr loss: 1.3903334140777588, avg loss: 1.3866047662496568\n",
      "trial: 5, iter: 800, curr loss: 1.3865348100662231, avg loss: 1.3864898824691771\n",
      "trial: 5, iter: 1000, curr loss: 1.3874415159225464, avg loss: 1.3863927394151687\n",
      "trial: 5, iter: 1200, curr loss: 1.3868962526321411, avg loss: 1.3863530248403548\n",
      "trial: 5, iter: 1400, curr loss: 1.3859199285507202, avg loss: 1.3863651442527771\n",
      "trial: 5, iter: 1600, curr loss: 1.3866921663284302, avg loss: 1.3863735258579255\n",
      "trial: 5, iter: 1800, curr loss: 1.3848252296447754, avg loss: 1.386308178305626\n",
      "trial: 5, iter: 2000, curr loss: 1.3874534368515015, avg loss: 1.386370881795883\n",
      "trial: 5, iter: 2200, curr loss: 1.38619863986969, avg loss: 1.3863742524385452\n",
      "trial: 5, iter: 2400, curr loss: 1.386974811553955, avg loss: 1.386342778801918\n",
      "trial: 5, iter: 2600, curr loss: 1.3861851692199707, avg loss: 1.3864164358377458\n",
      "trial: 5, iter: 2800, curr loss: 1.3859013319015503, avg loss: 1.3863058400154114\n",
      "trial: 5, iter: 3000, curr loss: 1.386074423789978, avg loss: 1.3864049905538558\n",
      "trial: 5, iter: 3200, curr loss: 1.386458158493042, avg loss: 1.3863424026966096\n",
      "trial: 5, iter: 3400, curr loss: 1.38644278049469, avg loss: 1.3862964487075806\n",
      "trial: 5, iter: 3600, curr loss: 1.3872169256210327, avg loss: 1.3862656509876252\n",
      "trial: 5, iter: 3800, curr loss: 1.3864388465881348, avg loss: 1.3864029121398926\n",
      "trial: 5, iter: 4000, curr loss: 1.386502981185913, avg loss: 1.3863556969165802\n",
      "trial: 5, iter: 4200, curr loss: 1.386965274810791, avg loss: 1.3863699406385421\n",
      "trial: 5, iter: 4400, curr loss: 1.3861701488494873, avg loss: 1.3863548332452773\n",
      "trial: 5, iter: 4600, curr loss: 1.385655403137207, avg loss: 1.3863176822662353\n",
      "trial: 5, iter: 4800, curr loss: 1.3858188390731812, avg loss: 1.3863324749469756\n",
      "trial: 5, iter: 5000, curr loss: 1.3867039680480957, avg loss: 1.38635096013546\n",
      "trial: 5, iter: 5200, curr loss: 1.3863776922225952, avg loss: 1.38628246486187\n",
      "trial: 5, iter: 5400, curr loss: 1.3858599662780762, avg loss: 1.3863083326816559\n",
      "trial: 5, iter: 5600, curr loss: 1.3863033056259155, avg loss: 1.3863745945692063\n",
      "trial: 5, iter: 5800, curr loss: 1.3865429162979126, avg loss: 1.3863399964571\n",
      "trial: 5, iter: 6000, curr loss: 1.3863810300827026, avg loss: 1.3863322842121124\n",
      "trial: 5, iter: 6200, curr loss: 1.3860782384872437, avg loss: 1.3862794846296311\n",
      "trial: 5, iter: 6400, curr loss: 1.386646032333374, avg loss: 1.386316904425621\n",
      "trial: 5, iter: 6600, curr loss: 1.38589346408844, avg loss: 1.3863068968057632\n",
      "trial: 5, iter: 6800, curr loss: 1.3864153623580933, avg loss: 1.3863464456796646\n",
      "trial: 5, iter: 7000, curr loss: 1.3863887786865234, avg loss: 1.386336858868599\n",
      "trial: 5, iter: 7200, curr loss: 1.3869459629058838, avg loss: 1.386317263841629\n",
      "trial: 5, iter: 7400, curr loss: 1.3866205215454102, avg loss: 1.3863496005535125\n",
      "trial: 5, iter: 7600, curr loss: 1.3862553834915161, avg loss: 1.3862870901823043\n",
      "trial: 5, iter: 7800, curr loss: 1.3861751556396484, avg loss: 1.3863207870721816\n",
      "trial: 5, iter: 8000, curr loss: 1.3862577676773071, avg loss: 1.3863219434022904\n",
      "trial: 5, iter: 8200, curr loss: 1.3864483833312988, avg loss: 1.3862974780797959\n",
      "trial: 5, iter: 8400, curr loss: 1.3863719701766968, avg loss: 1.3862955725193025\n",
      "trial: 5, iter: 8600, curr loss: 1.386549949645996, avg loss: 1.3863342642784118\n",
      "trial: 5, iter: 8800, curr loss: 1.3862810134887695, avg loss: 1.3863082402944564\n",
      "trial: 5, iter: 9000, curr loss: 1.3864787817001343, avg loss: 1.3862704092264175\n",
      "trial: 5, iter: 9200, curr loss: 1.3862780332565308, avg loss: 1.3863478922843933\n",
      "trial: 5, iter: 9400, curr loss: 1.3863946199417114, avg loss: 1.3862974214553834\n",
      "trial: 5, iter: 9600, curr loss: 1.3860145807266235, avg loss: 1.3863019275665283\n",
      "trial: 5, iter: 9800, curr loss: 1.386289119720459, avg loss: 1.3863032162189484\n",
      "trial: 5, iter: 10000, curr loss: 1.3867093324661255, avg loss: 1.3863149327039719\n",
      "trial: 5, iter: 10200, curr loss: 1.3861947059631348, avg loss: 1.3863059198856353\n",
      "trial: 5, iter: 10400, curr loss: 1.3860790729522705, avg loss: 1.386285770535469\n",
      "trial: 5, iter: 10600, curr loss: 1.3862271308898926, avg loss: 1.386328176856041\n",
      "trial: 5, iter: 10800, curr loss: 1.386264443397522, avg loss: 1.3863120037317276\n",
      "trial: 5, iter: 11000, curr loss: 1.386244773864746, avg loss: 1.3863087385892867\n",
      "trial: 5, iter: 11200, curr loss: 1.3856781721115112, avg loss: 1.3862603634595871\n",
      "trial: 5, iter: 11400, curr loss: 1.3865559101104736, avg loss: 1.3863183927536011\n",
      "trial: 5, iter: 11600, curr loss: 1.3864543437957764, avg loss: 1.386303170323372\n",
      "trial: 5, iter: 11800, curr loss: 1.3864948749542236, avg loss: 1.3862792176008225\n",
      "trial: 5, iter: 12000, curr loss: 1.3864562511444092, avg loss: 1.3862854063510894\n",
      "trial: 5, iter: 12200, curr loss: 1.385648488998413, avg loss: 1.3862690514326095\n",
      "trial: 5, iter: 12400, curr loss: 1.3860795497894287, avg loss: 1.3863734859228134\n",
      "trial: 5, iter: 12600, curr loss: 1.3860992193222046, avg loss: 1.386304880976677\n",
      "trial: 5, iter: 12800, curr loss: 1.3863908052444458, avg loss: 1.3863015002012253\n",
      "trial: 5, iter: 13000, curr loss: 1.386383056640625, avg loss: 1.3863015151023865\n",
      "trial: 5, iter: 13200, curr loss: 1.3861863613128662, avg loss: 1.386291688680649\n",
      "trial: 5, iter: 13400, curr loss: 1.3865948915481567, avg loss: 1.3863037985563278\n",
      "trial: 5, iter: 13600, curr loss: 1.3860135078430176, avg loss: 1.3862838494777678\n",
      "trial: 5, iter: 13800, curr loss: 1.3863548040390015, avg loss: 1.3863165932893753\n",
      "trial: 5, iter: 14000, curr loss: 1.3865759372711182, avg loss: 1.3863086026906968\n",
      "trial: 5, iter: 14200, curr loss: 1.386479377746582, avg loss: 1.3863125538825989\n",
      "trial: 5, iter: 14400, curr loss: 1.3865140676498413, avg loss: 1.3863184493780136\n",
      "trial: 5, iter: 14600, curr loss: 1.3854295015335083, avg loss: 1.3862974494695663\n",
      "trial: 5, iter: 14800, curr loss: 1.3866770267486572, avg loss: 1.3863445317745209\n",
      "trial: 5, iter: 15000, curr loss: 1.3862828016281128, avg loss: 1.3863137477636338\n",
      "trial: 5, iter: 15200, curr loss: 1.3857094049453735, avg loss: 1.3863180178403853\n",
      "trial: 5, iter: 15400, curr loss: 1.3856322765350342, avg loss: 1.3862808257341386\n",
      "trial: 5, iter: 15600, curr loss: 1.3860571384429932, avg loss: 1.3862888354063034\n",
      "trial: 5, ldr: 0.0005579408025369048\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.002525863968367048\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.387678861618042, avg loss: 1.3874067109823227\n",
      "trial: 1, iter: 400, curr loss: 1.3865348100662231, avg loss: 1.38658697783947\n",
      "trial: 1, iter: 600, curr loss: 1.385828971862793, avg loss: 1.3866006630659102\n",
      "trial: 1, iter: 800, curr loss: 1.3870635032653809, avg loss: 1.3865420293807984\n",
      "trial: 1, iter: 1000, curr loss: 1.388253927230835, avg loss: 1.3865626895427703\n",
      "trial: 1, iter: 1200, curr loss: 1.3858938217163086, avg loss: 1.3864962750673293\n",
      "trial: 1, iter: 1400, curr loss: 1.3860328197479248, avg loss: 1.3863969182968139\n",
      "trial: 1, iter: 1600, curr loss: 1.3873077630996704, avg loss: 1.38640683054924\n",
      "trial: 1, iter: 1800, curr loss: 1.386799931526184, avg loss: 1.3863431686162948\n",
      "trial: 1, iter: 2000, curr loss: 1.3868932723999023, avg loss: 1.3864463633298874\n",
      "trial: 1, iter: 2200, curr loss: 1.385156512260437, avg loss: 1.3863423269987107\n",
      "trial: 1, iter: 2400, curr loss: 1.3858850002288818, avg loss: 1.3863668370246887\n",
      "trial: 1, iter: 2600, curr loss: 1.3870408535003662, avg loss: 1.386369006037712\n",
      "trial: 1, iter: 2800, curr loss: 1.3867942094802856, avg loss: 1.3863667756319047\n",
      "trial: 1, iter: 3000, curr loss: 1.385625958442688, avg loss: 1.3862925040721894\n",
      "trial: 1, iter: 3200, curr loss: 1.3861982822418213, avg loss: 1.3863418263196945\n",
      "trial: 1, iter: 3400, curr loss: 1.3872976303100586, avg loss: 1.3864402425289155\n",
      "trial: 1, iter: 3600, curr loss: 1.3857073783874512, avg loss: 1.386334862112999\n",
      "trial: 1, iter: 3800, curr loss: 1.3865970373153687, avg loss: 1.3863926017284394\n",
      "trial: 1, iter: 4000, curr loss: 1.385995626449585, avg loss: 1.3863492250442504\n",
      "trial: 1, iter: 4200, curr loss: 1.38639497756958, avg loss: 1.3862923860549927\n",
      "trial: 1, iter: 4400, curr loss: 1.3876726627349854, avg loss: 1.386388328075409\n",
      "trial: 1, iter: 4600, curr loss: 1.3865560293197632, avg loss: 1.3863655030727386\n",
      "trial: 1, iter: 4800, curr loss: 1.3873786926269531, avg loss: 1.386287631392479\n",
      "trial: 1, iter: 5000, curr loss: 1.3870537281036377, avg loss: 1.3863006800413131\n",
      "trial: 1, iter: 5200, curr loss: 1.3860952854156494, avg loss: 1.3863570523262023\n",
      "trial: 1, iter: 5400, curr loss: 1.386332631111145, avg loss: 1.3863296592235566\n",
      "trial: 1, iter: 5600, curr loss: 1.3862642049789429, avg loss: 1.386321603655815\n",
      "trial: 1, iter: 5800, curr loss: 1.3855842351913452, avg loss: 1.3863561153411865\n",
      "trial: 1, iter: 6000, curr loss: 1.3867632150650024, avg loss: 1.3863064575195312\n",
      "trial: 1, iter: 6200, curr loss: 1.3869855403900146, avg loss: 1.3863360142707826\n",
      "trial: 1, iter: 6400, curr loss: 1.3869023323059082, avg loss: 1.386379337310791\n",
      "trial: 1, iter: 6600, curr loss: 1.3858534097671509, avg loss: 1.38633194565773\n",
      "trial: 1, iter: 6800, curr loss: 1.3866630792617798, avg loss: 1.3863157308101655\n",
      "trial: 1, iter: 7000, curr loss: 1.3879835605621338, avg loss: 1.3863210737705232\n",
      "trial: 1, iter: 7200, curr loss: 1.3858814239501953, avg loss: 1.3863763284683228\n",
      "trial: 1, iter: 7400, curr loss: 1.3859385251998901, avg loss: 1.3863105583190918\n",
      "trial: 1, iter: 7600, curr loss: 1.3862825632095337, avg loss: 1.3863134014606475\n",
      "trial: 1, iter: 7800, curr loss: 1.386243462562561, avg loss: 1.3862824231386184\n",
      "trial: 1, iter: 8000, curr loss: 1.386652946472168, avg loss: 1.3863048499822617\n",
      "trial: 1, iter: 8200, curr loss: 1.3863871097564697, avg loss: 1.3863104075193404\n",
      "trial: 1, iter: 8400, curr loss: 1.3864997625350952, avg loss: 1.386320959329605\n",
      "trial: 1, iter: 8600, curr loss: 1.3863033056259155, avg loss: 1.3862992966175078\n",
      "trial: 1, iter: 8800, curr loss: 1.3867931365966797, avg loss: 1.3862781202793122\n",
      "trial: 1, iter: 9000, curr loss: 1.3863581418991089, avg loss: 1.386299234032631\n",
      "trial: 1, iter: 9200, curr loss: 1.3861082792282104, avg loss: 1.3862994968891145\n",
      "trial: 1, iter: 9400, curr loss: 1.3871917724609375, avg loss: 1.3863125145435333\n",
      "trial: 1, iter: 9600, curr loss: 1.386656641960144, avg loss: 1.3863287526369095\n",
      "trial: 1, iter: 9800, curr loss: 1.3850651979446411, avg loss: 1.3862870883941651\n",
      "trial: 1, iter: 10000, curr loss: 1.3871691226959229, avg loss: 1.3864416700601578\n",
      "trial: 1, iter: 10200, curr loss: 1.3856964111328125, avg loss: 1.3864255964756012\n",
      "trial: 1, iter: 10400, curr loss: 1.385991096496582, avg loss: 1.3864064419269562\n",
      "trial: 1, iter: 10600, curr loss: 1.3854039907455444, avg loss: 1.3863116616010667\n",
      "trial: 1, iter: 10800, curr loss: 1.3859481811523438, avg loss: 1.3863870871067048\n",
      "trial: 1, iter: 11000, curr loss: 1.386357307434082, avg loss: 1.3863033336400985\n",
      "trial: 1, iter: 11200, curr loss: 1.386975884437561, avg loss: 1.3863884973526002\n",
      "trial: 1, iter: 11400, curr loss: 1.386444091796875, avg loss: 1.3863889569044112\n",
      "trial: 1, iter: 11600, curr loss: 1.385935664176941, avg loss: 1.3863420432806015\n",
      "trial: 1, iter: 11800, curr loss: 1.3865015506744385, avg loss: 1.3862977123260498\n",
      "trial: 1, iter: 12000, curr loss: 1.3878986835479736, avg loss: 1.3863113164901733\n",
      "trial: 1, iter: 12200, curr loss: 1.3863821029663086, avg loss: 1.386365755200386\n",
      "trial: 1, iter: 12400, curr loss: 1.3863327503204346, avg loss: 1.3863494569063186\n",
      "trial: 1, iter: 12600, curr loss: 1.386417031288147, avg loss: 1.3863192063570022\n",
      "trial: 1, iter: 12800, curr loss: 1.3862284421920776, avg loss: 1.386299734711647\n",
      "trial: 1, iter: 13000, curr loss: 1.3862555027008057, avg loss: 1.3863132214546203\n",
      "trial: 1, iter: 13200, curr loss: 1.386258602142334, avg loss: 1.3863056987524032\n",
      "trial: 1, iter: 13400, curr loss: 1.3862121105194092, avg loss: 1.3863028782606124\n",
      "trial: 1, iter: 13600, curr loss: 1.3863906860351562, avg loss: 1.3862950044870377\n",
      "trial: 1, iter: 13800, curr loss: 1.3861923217773438, avg loss: 1.386283888220787\n",
      "trial: 1, iter: 14000, curr loss: 1.386691927909851, avg loss: 1.3863065934181213\n",
      "trial: 1, iter: 14200, curr loss: 1.3862963914871216, avg loss: 1.3862540513277053\n",
      "trial: 1, iter: 14400, curr loss: 1.3859513998031616, avg loss: 1.386363258957863\n",
      "trial: 1, iter: 14600, curr loss: 1.38638174533844, avg loss: 1.3863162004947662\n",
      "trial: 1, iter: 14800, curr loss: 1.3863039016723633, avg loss: 1.3863031762838363\n",
      "trial: 1, iter: 15000, curr loss: 1.386299729347229, avg loss: 1.3863015258312226\n",
      "trial: 1, iter: 15200, curr loss: 1.3862701654434204, avg loss: 1.3862965834140777\n",
      "trial: 1, iter: 15400, curr loss: 1.3862967491149902, avg loss: 1.3863003623485566\n",
      "trial: 1, iter: 15600, curr loss: 1.386298656463623, avg loss: 1.3862972873449326\n",
      "trial: 1, ldr: -0.000200910129933618\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3867173194885254, avg loss: 1.3871161556243896\n",
      "trial: 2, iter: 400, curr loss: 1.3872679471969604, avg loss: 1.386846851706505\n",
      "trial: 2, iter: 600, curr loss: 1.386050820350647, avg loss: 1.3866515618562698\n",
      "trial: 2, iter: 800, curr loss: 1.3860161304473877, avg loss: 1.3866242730617524\n",
      "trial: 2, iter: 1000, curr loss: 1.3846567869186401, avg loss: 1.3865627986192703\n",
      "trial: 2, iter: 1200, curr loss: 1.3867610692977905, avg loss: 1.3864095687866211\n",
      "trial: 2, iter: 1400, curr loss: 1.3886300325393677, avg loss: 1.3864764809608459\n",
      "trial: 2, iter: 1600, curr loss: 1.3852527141571045, avg loss: 1.386369891166687\n",
      "trial: 2, iter: 1800, curr loss: 1.3854066133499146, avg loss: 1.3864609324932098\n",
      "trial: 2, iter: 2000, curr loss: 1.3875426054000854, avg loss: 1.3863679695129394\n",
      "trial: 2, iter: 2200, curr loss: 1.3854529857635498, avg loss: 1.3863742971420288\n",
      "trial: 2, iter: 2400, curr loss: 1.3874238729476929, avg loss: 1.3864587944746019\n",
      "trial: 2, iter: 2600, curr loss: 1.386327862739563, avg loss: 1.3863845759630202\n",
      "trial: 2, iter: 2800, curr loss: 1.386964201927185, avg loss: 1.386333841085434\n",
      "trial: 2, iter: 3000, curr loss: 1.385777235031128, avg loss: 1.3864216524362565\n",
      "trial: 2, iter: 3200, curr loss: 1.3860082626342773, avg loss: 1.3864799058437347\n",
      "trial: 2, iter: 3400, curr loss: 1.3870874643325806, avg loss: 1.386449826359749\n",
      "trial: 2, iter: 3600, curr loss: 1.3858567476272583, avg loss: 1.386401383280754\n",
      "trial: 2, iter: 3800, curr loss: 1.3864063024520874, avg loss: 1.386486524939537\n",
      "trial: 2, iter: 4000, curr loss: 1.385251760482788, avg loss: 1.3863983303308487\n",
      "trial: 2, iter: 4200, curr loss: 1.386124849319458, avg loss: 1.3863821160793304\n",
      "trial: 2, iter: 4400, curr loss: 1.3863539695739746, avg loss: 1.3864668363332748\n",
      "trial: 2, iter: 4600, curr loss: 1.3864400386810303, avg loss: 1.386390078663826\n",
      "trial: 2, iter: 4800, curr loss: 1.3869073390960693, avg loss: 1.3863278031349182\n",
      "trial: 2, iter: 5000, curr loss: 1.386765480041504, avg loss: 1.3862772989273071\n",
      "trial: 2, iter: 5200, curr loss: 1.3866066932678223, avg loss: 1.3862901747226715\n",
      "trial: 2, iter: 5400, curr loss: 1.3866331577301025, avg loss: 1.3863096976280211\n",
      "trial: 2, iter: 5600, curr loss: 1.386476755142212, avg loss: 1.3863306891918183\n",
      "trial: 2, iter: 5800, curr loss: 1.3862121105194092, avg loss: 1.3863300985097886\n",
      "trial: 2, iter: 6000, curr loss: 1.3865944147109985, avg loss: 1.3863308417797089\n",
      "trial: 2, iter: 6200, curr loss: 1.3864240646362305, avg loss: 1.3863041293621063\n",
      "trial: 2, iter: 6400, curr loss: 1.3858743906021118, avg loss: 1.3863155210018159\n",
      "trial: 2, iter: 6600, curr loss: 1.386614441871643, avg loss: 1.3863119548559188\n",
      "trial: 2, iter: 6800, curr loss: 1.3864173889160156, avg loss: 1.3862975752353668\n",
      "trial: 2, iter: 7000, curr loss: 1.3860914707183838, avg loss: 1.386327617764473\n",
      "trial: 2, iter: 7200, curr loss: 1.3864078521728516, avg loss: 1.3863211399316788\n",
      "trial: 2, iter: 7400, curr loss: 1.3862597942352295, avg loss: 1.3863017141819\n",
      "trial: 2, iter: 7600, curr loss: 1.3865514993667603, avg loss: 1.3862887138128281\n",
      "trial: 2, iter: 7800, curr loss: 1.3864980936050415, avg loss: 1.3863378250598908\n",
      "trial: 2, iter: 8000, curr loss: 1.3861068487167358, avg loss: 1.3863205832242966\n",
      "trial: 2, iter: 8200, curr loss: 1.3865939378738403, avg loss: 1.3863334411382675\n",
      "trial: 2, iter: 8400, curr loss: 1.3862179517745972, avg loss: 1.3863386505842208\n",
      "trial: 2, iter: 8600, curr loss: 1.386053204536438, avg loss: 1.3863110637664795\n",
      "trial: 2, iter: 8800, curr loss: 1.3862559795379639, avg loss: 1.386291697025299\n",
      "trial: 2, iter: 9000, curr loss: 1.3864668607711792, avg loss: 1.3863271874189378\n",
      "trial: 2, iter: 9200, curr loss: 1.3858489990234375, avg loss: 1.3863314557075501\n",
      "trial: 2, iter: 9400, curr loss: 1.3859273195266724, avg loss: 1.3862930947542191\n",
      "trial: 2, iter: 9600, curr loss: 1.3861521482467651, avg loss: 1.386352269053459\n",
      "trial: 2, iter: 9800, curr loss: 1.3856958150863647, avg loss: 1.3863395690917968\n",
      "trial: 2, iter: 10000, curr loss: 1.3862495422363281, avg loss: 1.3863089382648468\n",
      "trial: 2, iter: 10200, curr loss: 1.3855804204940796, avg loss: 1.3862907201051713\n",
      "trial: 2, iter: 10400, curr loss: 1.3861322402954102, avg loss: 1.386345482468605\n",
      "trial: 2, iter: 10600, curr loss: 1.3871238231658936, avg loss: 1.3863289374113084\n",
      "trial: 2, iter: 10800, curr loss: 1.3864611387252808, avg loss: 1.3863485443592072\n",
      "trial: 2, iter: 11000, curr loss: 1.3860317468643188, avg loss: 1.3863067561388016\n",
      "trial: 2, iter: 11200, curr loss: 1.3862967491149902, avg loss: 1.386279307603836\n",
      "trial: 2, iter: 11400, curr loss: 1.386069416999817, avg loss: 1.3863057959079743\n",
      "trial: 2, iter: 11600, curr loss: 1.3860877752304077, avg loss: 1.3863291621208191\n",
      "trial: 2, iter: 11800, curr loss: 1.3864964246749878, avg loss: 1.386315034031868\n",
      "trial: 2, iter: 12000, curr loss: 1.3864935636520386, avg loss: 1.3863640183210373\n",
      "trial: 2, iter: 12200, curr loss: 1.3865536451339722, avg loss: 1.386341497898102\n",
      "trial: 2, iter: 12400, curr loss: 1.3861472606658936, avg loss: 1.3862868237495423\n",
      "trial: 2, iter: 12600, curr loss: 1.3856838941574097, avg loss: 1.3862934279441834\n",
      "trial: 2, iter: 12800, curr loss: 1.3861110210418701, avg loss: 1.3863331192731858\n",
      "trial: 2, iter: 13000, curr loss: 1.3863400220870972, avg loss: 1.3863160747289658\n",
      "trial: 2, iter: 13200, curr loss: 1.3861232995986938, avg loss: 1.3862992137670518\n",
      "trial: 2, iter: 13400, curr loss: 1.3864006996154785, avg loss: 1.3862982016801835\n",
      "trial: 2, iter: 13600, curr loss: 1.386334776878357, avg loss: 1.3862985509634018\n",
      "trial: 2, iter: 13800, curr loss: 1.3861733675003052, avg loss: 1.3862959319353103\n",
      "trial: 2, iter: 14000, curr loss: 1.3864573240280151, avg loss: 1.386308603286743\n",
      "trial: 2, iter: 14200, curr loss: 1.3863534927368164, avg loss: 1.3862974017858505\n",
      "trial: 2, iter: 14400, curr loss: 1.386284589767456, avg loss: 1.3863033539056777\n",
      "trial: 2, iter: 14600, curr loss: 1.3860846757888794, avg loss: 1.3862733626365662\n",
      "trial: 2, iter: 14800, curr loss: 1.3863738775253296, avg loss: 1.3862896806001663\n",
      "trial: 2, iter: 15000, curr loss: 1.3865246772766113, avg loss: 1.38631502866745\n",
      "trial: 2, iter: 15200, curr loss: 1.3864306211471558, avg loss: 1.3863048255443573\n",
      "trial: 2, iter: 15400, curr loss: 1.386320948600769, avg loss: 1.3863034945726396\n",
      "trial: 2, iter: 15600, curr loss: 1.3863054513931274, avg loss: 1.386300477385521\n",
      "trial: 2, ldr: 7.709143392276019e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3882726430892944, avg loss: 1.3872243428230286\n",
      "trial: 3, iter: 400, curr loss: 1.3838958740234375, avg loss: 1.3866431188583375\n",
      "trial: 3, iter: 600, curr loss: 1.3902924060821533, avg loss: 1.386626502275467\n",
      "trial: 3, iter: 800, curr loss: 1.3866848945617676, avg loss: 1.3865054315328598\n",
      "trial: 3, iter: 1000, curr loss: 1.3879448175430298, avg loss: 1.3863983887434006\n",
      "trial: 3, iter: 1200, curr loss: 1.3864136934280396, avg loss: 1.3864872831106185\n",
      "trial: 3, iter: 1400, curr loss: 1.3870497941970825, avg loss: 1.3864189821481705\n",
      "trial: 3, iter: 1600, curr loss: 1.3860726356506348, avg loss: 1.38631656229496\n",
      "trial: 3, iter: 1800, curr loss: 1.385703206062317, avg loss: 1.3863745468854904\n",
      "trial: 3, iter: 2000, curr loss: 1.3867511749267578, avg loss: 1.3864875435829163\n",
      "trial: 3, iter: 2200, curr loss: 1.3862855434417725, avg loss: 1.3863294643163682\n",
      "trial: 3, iter: 2400, curr loss: 1.3844093084335327, avg loss: 1.3863136625289918\n",
      "trial: 3, iter: 2600, curr loss: 1.3865493535995483, avg loss: 1.3863039141893387\n",
      "trial: 3, iter: 2800, curr loss: 1.3858702182769775, avg loss: 1.3864021003246307\n",
      "trial: 3, iter: 3000, curr loss: 1.3855369091033936, avg loss: 1.3863014793395996\n",
      "trial: 3, iter: 3200, curr loss: 1.3862321376800537, avg loss: 1.3863658970594406\n",
      "trial: 3, iter: 3400, curr loss: 1.385545253753662, avg loss: 1.3863094460964203\n",
      "trial: 3, iter: 3600, curr loss: 1.3863483667373657, avg loss: 1.3863932067155837\n",
      "trial: 3, iter: 3800, curr loss: 1.3863502740859985, avg loss: 1.3864276951551437\n",
      "trial: 3, iter: 4000, curr loss: 1.3870246410369873, avg loss: 1.386382104754448\n",
      "trial: 3, iter: 4200, curr loss: 1.3859055042266846, avg loss: 1.3863831168413163\n",
      "trial: 3, iter: 4400, curr loss: 1.3864562511444092, avg loss: 1.3863320779800414\n",
      "trial: 3, iter: 4600, curr loss: 1.3864961862564087, avg loss: 1.3863193744421005\n",
      "trial: 3, iter: 4800, curr loss: 1.3856784105300903, avg loss: 1.3863665503263474\n",
      "trial: 3, iter: 5000, curr loss: 1.3859628438949585, avg loss: 1.386343496441841\n",
      "trial: 3, iter: 5200, curr loss: 1.3861123323440552, avg loss: 1.386348922252655\n",
      "trial: 3, iter: 5400, curr loss: 1.3863214254379272, avg loss: 1.3863186836242676\n",
      "trial: 3, iter: 5600, curr loss: 1.3861970901489258, avg loss: 1.3863324064016342\n",
      "trial: 3, iter: 5800, curr loss: 1.3865430355072021, avg loss: 1.3863100105524062\n",
      "trial: 3, iter: 6000, curr loss: 1.386486291885376, avg loss: 1.3862679266929627\n",
      "trial: 3, iter: 6200, curr loss: 1.3855621814727783, avg loss: 1.3863169449567794\n",
      "trial: 3, iter: 6400, curr loss: 1.385998249053955, avg loss: 1.3863320302963258\n",
      "trial: 3, iter: 6600, curr loss: 1.3866374492645264, avg loss: 1.3863506346940995\n",
      "trial: 3, iter: 6800, curr loss: 1.3865654468536377, avg loss: 1.3863392025232315\n",
      "trial: 3, iter: 7000, curr loss: 1.3858312368392944, avg loss: 1.3863073390722276\n",
      "trial: 3, iter: 7200, curr loss: 1.3863996267318726, avg loss: 1.3863141852617265\n",
      "trial: 3, iter: 7400, curr loss: 1.3865220546722412, avg loss: 1.386311285495758\n",
      "trial: 3, iter: 7600, curr loss: 1.3862988948822021, avg loss: 1.386331415772438\n",
      "trial: 3, iter: 7800, curr loss: 1.3862426280975342, avg loss: 1.3863310718536377\n",
      "trial: 3, iter: 8000, curr loss: 1.3862063884735107, avg loss: 1.3862911742925643\n",
      "trial: 3, iter: 8200, curr loss: 1.386624813079834, avg loss: 1.3863205587863923\n",
      "trial: 3, iter: 8400, curr loss: 1.386090874671936, avg loss: 1.3863071477413178\n",
      "trial: 3, iter: 8600, curr loss: 1.3862484693527222, avg loss: 1.3862969172000885\n",
      "trial: 3, iter: 8800, curr loss: 1.3861300945281982, avg loss: 1.386309968829155\n",
      "trial: 3, iter: 9000, curr loss: 1.3862943649291992, avg loss: 1.386313693523407\n",
      "trial: 3, iter: 9200, curr loss: 1.3862289190292358, avg loss: 1.3863003271818162\n",
      "trial: 3, iter: 9400, curr loss: 1.3863804340362549, avg loss: 1.3863103997707367\n",
      "trial: 3, iter: 9600, curr loss: 1.3862260580062866, avg loss: 1.3862931895256043\n",
      "trial: 3, iter: 9800, curr loss: 1.3859819173812866, avg loss: 1.3863054931163787\n",
      "trial: 3, iter: 10000, curr loss: 1.386240005493164, avg loss: 1.386320634484291\n",
      "trial: 3, iter: 10200, curr loss: 1.3860987424850464, avg loss: 1.3863052451610565\n",
      "trial: 3, iter: 10400, curr loss: 1.3864800930023193, avg loss: 1.3863234287500381\n",
      "trial: 3, iter: 10600, curr loss: 1.3861362934112549, avg loss: 1.3863127249479295\n",
      "trial: 3, iter: 10800, curr loss: 1.3862849473953247, avg loss: 1.386281092762947\n",
      "trial: 3, iter: 11000, curr loss: 1.3852859735488892, avg loss: 1.386418097615242\n",
      "trial: 3, iter: 11200, curr loss: 1.3865176439285278, avg loss: 1.3863428682088852\n",
      "trial: 3, iter: 11400, curr loss: 1.3866053819656372, avg loss: 1.3863173294067384\n",
      "trial: 3, iter: 11600, curr loss: 1.3866496086120605, avg loss: 1.3863192200660706\n",
      "trial: 3, iter: 11800, curr loss: 1.385141372680664, avg loss: 1.3862886214256287\n",
      "trial: 3, iter: 12000, curr loss: 1.3861284255981445, avg loss: 1.3863384538888932\n",
      "trial: 3, iter: 12200, curr loss: 1.386327862739563, avg loss: 1.3863246822357178\n",
      "trial: 3, iter: 12400, curr loss: 1.3853671550750732, avg loss: 1.386327958703041\n",
      "trial: 3, iter: 12600, curr loss: 1.3861747980117798, avg loss: 1.3863396775722503\n",
      "trial: 3, iter: 12800, curr loss: 1.3861891031265259, avg loss: 1.38632987678051\n",
      "trial: 3, iter: 13000, curr loss: 1.3864246606826782, avg loss: 1.3863165247440339\n",
      "trial: 3, iter: 13200, curr loss: 1.3866674900054932, avg loss: 1.3863095039129256\n",
      "trial: 3, iter: 13400, curr loss: 1.3862640857696533, avg loss: 1.3863195812702178\n",
      "trial: 3, iter: 13600, curr loss: 1.3860400915145874, avg loss: 1.3863013565540314\n",
      "trial: 3, iter: 13800, curr loss: 1.3861616849899292, avg loss: 1.386303142309189\n",
      "trial: 3, iter: 14000, curr loss: 1.386365532875061, avg loss: 1.3863132816553116\n",
      "trial: 3, iter: 14200, curr loss: 1.386537790298462, avg loss: 1.3862874138355255\n",
      "trial: 3, iter: 14400, curr loss: 1.3857648372650146, avg loss: 1.386308093070984\n",
      "trial: 3, iter: 14600, curr loss: 1.3858810663223267, avg loss: 1.3863060998916625\n",
      "trial: 3, iter: 14800, curr loss: 1.386609673500061, avg loss: 1.3863327997922896\n",
      "trial: 3, iter: 15000, curr loss: 1.3863446712493896, avg loss: 1.3862829202413558\n",
      "trial: 3, iter: 15200, curr loss: 1.3863604068756104, avg loss: 1.3863230395317077\n",
      "trial: 3, iter: 15400, curr loss: 1.3869073390960693, avg loss: 1.3863015407323838\n",
      "trial: 3, iter: 15600, curr loss: 1.3862086534500122, avg loss: 1.3863150954246521\n",
      "trial: 3, ldr: -0.003030897816643119\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386587142944336, avg loss: 1.387586495280266\n",
      "trial: 4, iter: 400, curr loss: 1.3871312141418457, avg loss: 1.3867623555660247\n",
      "trial: 4, iter: 600, curr loss: 1.3852629661560059, avg loss: 1.386615280508995\n",
      "trial: 4, iter: 800, curr loss: 1.3851213455200195, avg loss: 1.3865161937475206\n",
      "trial: 4, iter: 1000, curr loss: 1.3863838911056519, avg loss: 1.386491259932518\n",
      "trial: 4, iter: 1200, curr loss: 1.3862234354019165, avg loss: 1.386366378068924\n",
      "trial: 4, iter: 1400, curr loss: 1.3873324394226074, avg loss: 1.3863486498594284\n",
      "trial: 4, iter: 1600, curr loss: 1.3858579397201538, avg loss: 1.3864467906951905\n",
      "trial: 4, iter: 1800, curr loss: 1.3864161968231201, avg loss: 1.3864119124412537\n",
      "trial: 4, iter: 2000, curr loss: 1.3878002166748047, avg loss: 1.3863547158241272\n",
      "trial: 4, iter: 2200, curr loss: 1.3862825632095337, avg loss: 1.3864920514822006\n",
      "trial: 4, iter: 2400, curr loss: 1.3871769905090332, avg loss: 1.3863196367025374\n",
      "trial: 4, iter: 2600, curr loss: 1.3865748643875122, avg loss: 1.3862249130010604\n",
      "trial: 4, iter: 2800, curr loss: 1.3860946893692017, avg loss: 1.3863509798049927\n",
      "trial: 4, iter: 3000, curr loss: 1.3865411281585693, avg loss: 1.3863640201091767\n",
      "trial: 4, iter: 3200, curr loss: 1.3857601881027222, avg loss: 1.386347822546959\n",
      "trial: 4, iter: 3400, curr loss: 1.3867266178131104, avg loss: 1.3863287836313247\n",
      "trial: 4, iter: 3600, curr loss: 1.3862488269805908, avg loss: 1.3863778179883957\n",
      "trial: 4, iter: 3800, curr loss: 1.3859282732009888, avg loss: 1.3863136744499207\n",
      "trial: 4, iter: 4000, curr loss: 1.3865476846694946, avg loss: 1.3863332897424698\n",
      "trial: 4, iter: 4200, curr loss: 1.3873652219772339, avg loss: 1.3863114815950395\n",
      "trial: 4, iter: 4400, curr loss: 1.3865996599197388, avg loss: 1.3863179558515548\n",
      "trial: 4, iter: 4600, curr loss: 1.386886715888977, avg loss: 1.3863255846500397\n",
      "trial: 4, iter: 4800, curr loss: 1.385728359222412, avg loss: 1.386256164908409\n",
      "trial: 4, iter: 5000, curr loss: 1.3874704837799072, avg loss: 1.3863599330186844\n",
      "trial: 4, iter: 5200, curr loss: 1.3865745067596436, avg loss: 1.386309267282486\n",
      "trial: 4, iter: 5400, curr loss: 1.3860909938812256, avg loss: 1.386344814300537\n",
      "trial: 4, iter: 5600, curr loss: 1.3866479396820068, avg loss: 1.386317450404167\n",
      "trial: 4, iter: 5800, curr loss: 1.386715054512024, avg loss: 1.3863157045841217\n",
      "trial: 4, iter: 6000, curr loss: 1.3859469890594482, avg loss: 1.3863440012931825\n",
      "trial: 4, iter: 6200, curr loss: 1.386239767074585, avg loss: 1.386375526189804\n",
      "trial: 4, iter: 6400, curr loss: 1.3862029314041138, avg loss: 1.3863074910640716\n",
      "trial: 4, iter: 6600, curr loss: 1.3863766193389893, avg loss: 1.386278291940689\n",
      "trial: 4, iter: 6800, curr loss: 1.38596510887146, avg loss: 1.3863348561525344\n",
      "trial: 4, iter: 7000, curr loss: 1.3865375518798828, avg loss: 1.3863134878873824\n",
      "trial: 4, iter: 7200, curr loss: 1.3862509727478027, avg loss: 1.3863201141357422\n",
      "trial: 4, iter: 7400, curr loss: 1.3864766359329224, avg loss: 1.3863093066215515\n",
      "trial: 4, iter: 7600, curr loss: 1.3863017559051514, avg loss: 1.3863237524032592\n",
      "trial: 4, iter: 7800, curr loss: 1.3861268758773804, avg loss: 1.3863068956136704\n",
      "trial: 4, iter: 8000, curr loss: 1.3863929510116577, avg loss: 1.3863111007213593\n",
      "trial: 4, iter: 8200, curr loss: 1.3862264156341553, avg loss: 1.386305298805237\n",
      "trial: 4, iter: 8400, curr loss: 1.3866353034973145, avg loss: 1.3862867349386214\n",
      "trial: 4, iter: 8600, curr loss: 1.3859121799468994, avg loss: 1.3862978965044022\n",
      "trial: 4, iter: 8800, curr loss: 1.386338233947754, avg loss: 1.38632215321064\n",
      "trial: 4, iter: 9000, curr loss: 1.3864446878433228, avg loss: 1.3863011038303374\n",
      "trial: 4, iter: 9200, curr loss: 1.386369228363037, avg loss: 1.386298878788948\n",
      "trial: 4, iter: 9400, curr loss: 1.386483907699585, avg loss: 1.3862946850061417\n",
      "trial: 4, iter: 9600, curr loss: 1.3864904642105103, avg loss: 1.386299329996109\n",
      "trial: 4, iter: 9800, curr loss: 1.3862050771713257, avg loss: 1.3863001680374145\n",
      "trial: 4, iter: 10000, curr loss: 1.3862468004226685, avg loss: 1.3862965857982636\n",
      "trial: 4, iter: 10200, curr loss: 1.3863372802734375, avg loss: 1.386294388771057\n",
      "trial: 4, iter: 10400, curr loss: 1.3862736225128174, avg loss: 1.3863036900758743\n",
      "trial: 4, iter: 10600, curr loss: 1.386279582977295, avg loss: 1.3863499623537063\n",
      "trial: 4, iter: 10800, curr loss: 1.3871740102767944, avg loss: 1.3863438612222672\n",
      "trial: 4, iter: 11000, curr loss: 1.3861770629882812, avg loss: 1.3863687580823898\n",
      "trial: 4, iter: 11200, curr loss: 1.386043906211853, avg loss: 1.3863159316778182\n",
      "trial: 4, iter: 11400, curr loss: 1.3866225481033325, avg loss: 1.3862825375795365\n",
      "trial: 4, iter: 11600, curr loss: 1.386561632156372, avg loss: 1.3863665169477464\n",
      "trial: 4, iter: 11800, curr loss: 1.3852800130844116, avg loss: 1.386258038878441\n",
      "trial: 4, iter: 12000, curr loss: 1.387166976928711, avg loss: 1.3863286834955215\n",
      "trial: 4, iter: 12200, curr loss: 1.385741114616394, avg loss: 1.3863200223445893\n",
      "trial: 4, iter: 12400, curr loss: 1.3866760730743408, avg loss: 1.3863405340909958\n",
      "trial: 4, iter: 12600, curr loss: 1.3853520154953003, avg loss: 1.3862974232435226\n",
      "trial: 4, iter: 12800, curr loss: 1.3869898319244385, avg loss: 1.3863306552171708\n",
      "trial: 4, iter: 13000, curr loss: 1.3863903284072876, avg loss: 1.386313949227333\n",
      "trial: 4, iter: 13200, curr loss: 1.3864976167678833, avg loss: 1.3863003581762314\n",
      "trial: 4, iter: 13400, curr loss: 1.38649320602417, avg loss: 1.3862943387031554\n",
      "trial: 4, iter: 13600, curr loss: 1.3860619068145752, avg loss: 1.386296390891075\n",
      "trial: 4, iter: 13800, curr loss: 1.3866208791732788, avg loss: 1.3862862718105315\n",
      "trial: 4, iter: 14000, curr loss: 1.3862330913543701, avg loss: 1.3863138937950135\n",
      "trial: 4, iter: 14200, curr loss: 1.3862065076828003, avg loss: 1.386297146677971\n",
      "trial: 4, iter: 14400, curr loss: 1.3863579034805298, avg loss: 1.3862937623262406\n",
      "trial: 4, iter: 14600, curr loss: 1.3862192630767822, avg loss: 1.3863017469644547\n",
      "trial: 4, iter: 14800, curr loss: 1.3863122463226318, avg loss: 1.3862963277101517\n",
      "trial: 4, iter: 15000, curr loss: 1.3864786624908447, avg loss: 1.3862873303890229\n",
      "trial: 4, iter: 15200, curr loss: 1.386021375656128, avg loss: 1.3862976664304734\n",
      "trial: 4, iter: 15400, curr loss: 1.3862559795379639, avg loss: 1.386308890581131\n",
      "trial: 4, iter: 15600, curr loss: 1.3861887454986572, avg loss: 1.3863019520044326\n",
      "trial: 4, ldr: -0.0002484233118593693\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3886215686798096, avg loss: 1.387613509297371\n",
      "trial: 5, iter: 400, curr loss: 1.3879570960998535, avg loss: 1.3867663663625718\n",
      "trial: 5, iter: 600, curr loss: 1.382737636566162, avg loss: 1.3865855753421783\n",
      "trial: 5, iter: 800, curr loss: 1.387370228767395, avg loss: 1.3863562846183777\n",
      "trial: 5, iter: 1000, curr loss: 1.3878971338272095, avg loss: 1.3864614582061767\n",
      "trial: 5, iter: 1200, curr loss: 1.3889191150665283, avg loss: 1.3863985925912856\n",
      "trial: 5, iter: 1400, curr loss: 1.3870770931243896, avg loss: 1.3864059144258498\n",
      "trial: 5, iter: 1600, curr loss: 1.3876808881759644, avg loss: 1.3864973378181458\n",
      "trial: 5, iter: 1800, curr loss: 1.3857275247573853, avg loss: 1.3863770604133605\n",
      "trial: 5, iter: 2000, curr loss: 1.3857065439224243, avg loss: 1.3864816123247146\n",
      "trial: 5, iter: 2200, curr loss: 1.3870761394500732, avg loss: 1.386545838713646\n",
      "trial: 5, iter: 2400, curr loss: 1.3865315914154053, avg loss: 1.3863893783092498\n",
      "trial: 5, iter: 2600, curr loss: 1.3877031803131104, avg loss: 1.3863633227348329\n",
      "trial: 5, iter: 2800, curr loss: 1.3850852251052856, avg loss: 1.3863517880439757\n",
      "trial: 5, iter: 3000, curr loss: 1.3867744207382202, avg loss: 1.3863151943683625\n",
      "trial: 5, iter: 3200, curr loss: 1.3862041234970093, avg loss: 1.3863821697235108\n",
      "trial: 5, iter: 3400, curr loss: 1.3865374326705933, avg loss: 1.3863141548633575\n",
      "trial: 5, iter: 3600, curr loss: 1.3864262104034424, avg loss: 1.3863448733091355\n",
      "trial: 5, iter: 3800, curr loss: 1.3870747089385986, avg loss: 1.3863358044624328\n",
      "trial: 5, iter: 4000, curr loss: 1.3861039876937866, avg loss: 1.3863509517908097\n",
      "trial: 5, iter: 4200, curr loss: 1.386907696723938, avg loss: 1.38630242228508\n",
      "trial: 5, iter: 4400, curr loss: 1.3869519233703613, avg loss: 1.3862743598222733\n",
      "trial: 5, iter: 4600, curr loss: 1.3874194622039795, avg loss: 1.3863324344158172\n",
      "trial: 5, iter: 4800, curr loss: 1.3863223791122437, avg loss: 1.386411756873131\n",
      "trial: 5, iter: 5000, curr loss: 1.3868727684020996, avg loss: 1.3863481026887894\n",
      "trial: 5, iter: 5200, curr loss: 1.3856525421142578, avg loss: 1.3863092082738877\n",
      "trial: 5, iter: 5400, curr loss: 1.385778784751892, avg loss: 1.3863292175531388\n",
      "trial: 5, iter: 5600, curr loss: 1.3859221935272217, avg loss: 1.3863329702615739\n",
      "trial: 5, iter: 5800, curr loss: 1.3876928091049194, avg loss: 1.3863675302267076\n",
      "trial: 5, iter: 6000, curr loss: 1.3864277601242065, avg loss: 1.3863596946001053\n",
      "trial: 5, iter: 6200, curr loss: 1.3861677646636963, avg loss: 1.3863076734542847\n",
      "trial: 5, iter: 6400, curr loss: 1.386729121208191, avg loss: 1.386341797709465\n",
      "trial: 5, iter: 6600, curr loss: 1.3865972757339478, avg loss: 1.3862946647405625\n",
      "trial: 5, iter: 6800, curr loss: 1.386304497718811, avg loss: 1.3863114923238755\n",
      "trial: 5, iter: 7000, curr loss: 1.3860242366790771, avg loss: 1.3862928885221482\n",
      "trial: 5, iter: 7200, curr loss: 1.3857859373092651, avg loss: 1.386286746263504\n",
      "trial: 5, iter: 7400, curr loss: 1.387154459953308, avg loss: 1.3862926697731017\n",
      "trial: 5, iter: 7600, curr loss: 1.3860812187194824, avg loss: 1.3863711583614349\n",
      "trial: 5, iter: 7800, curr loss: 1.385767936706543, avg loss: 1.3863226622343063\n",
      "trial: 5, iter: 8000, curr loss: 1.3862887620925903, avg loss: 1.3863412457704545\n",
      "trial: 5, iter: 8200, curr loss: 1.386415958404541, avg loss: 1.3863518953323364\n",
      "trial: 5, iter: 8400, curr loss: 1.3865423202514648, avg loss: 1.3862993288040162\n",
      "trial: 5, iter: 8600, curr loss: 1.385928750038147, avg loss: 1.38632179915905\n",
      "trial: 5, iter: 8800, curr loss: 1.3863402605056763, avg loss: 1.3863759261369706\n",
      "trial: 5, iter: 9000, curr loss: 1.386404037475586, avg loss: 1.38635478079319\n",
      "trial: 5, iter: 9200, curr loss: 1.3863483667373657, avg loss: 1.3862958395481109\n",
      "trial: 5, iter: 9400, curr loss: 1.385941743850708, avg loss: 1.3862936168909072\n",
      "trial: 5, iter: 9600, curr loss: 1.3856143951416016, avg loss: 1.386321460008621\n",
      "trial: 5, iter: 9800, curr loss: 1.3860985040664673, avg loss: 1.3862812113761902\n",
      "trial: 5, iter: 10000, curr loss: 1.3858287334442139, avg loss: 1.3863098865747452\n",
      "trial: 5, iter: 10200, curr loss: 1.3864465951919556, avg loss: 1.3863328433036803\n",
      "trial: 5, iter: 10400, curr loss: 1.3863357305526733, avg loss: 1.3863070952892302\n",
      "trial: 5, iter: 10600, curr loss: 1.3866902589797974, avg loss: 1.3863141095638276\n",
      "trial: 5, iter: 10800, curr loss: 1.3859626054763794, avg loss: 1.3862893134355545\n",
      "trial: 5, iter: 11000, curr loss: 1.3862727880477905, avg loss: 1.3863174712657929\n",
      "trial: 5, iter: 11200, curr loss: 1.3863004446029663, avg loss: 1.3863158529996873\n",
      "trial: 5, iter: 11400, curr loss: 1.3861737251281738, avg loss: 1.3863044321537017\n",
      "trial: 5, iter: 11600, curr loss: 1.3863164186477661, avg loss: 1.3863073462247848\n",
      "trial: 5, iter: 11800, curr loss: 1.3858726024627686, avg loss: 1.3862942689657212\n",
      "trial: 5, iter: 12000, curr loss: 1.3864325284957886, avg loss: 1.386319224834442\n",
      "trial: 5, iter: 12200, curr loss: 1.3864591121673584, avg loss: 1.386311691403389\n",
      "trial: 5, iter: 12400, curr loss: 1.386433720588684, avg loss: 1.386304465532303\n",
      "trial: 5, iter: 12600, curr loss: 1.3862208127975464, avg loss: 1.3862909573316573\n",
      "trial: 5, iter: 12800, curr loss: 1.3864165544509888, avg loss: 1.3863110494613649\n",
      "trial: 5, iter: 13000, curr loss: 1.3865602016448975, avg loss: 1.3862881666421891\n",
      "trial: 5, iter: 13200, curr loss: 1.386260747909546, avg loss: 1.3863149029016495\n",
      "trial: 5, iter: 13400, curr loss: 1.386298418045044, avg loss: 1.3863024216890336\n",
      "trial: 5, iter: 13600, curr loss: 1.3863065242767334, avg loss: 1.386298263669014\n",
      "trial: 5, iter: 13800, curr loss: 1.386297345161438, avg loss: 1.3863010054826737\n",
      "trial: 5, iter: 14000, curr loss: 1.38625168800354, avg loss: 1.3862975913286208\n",
      "trial: 5, iter: 14200, curr loss: 1.3863143920898438, avg loss: 1.3862969368696212\n",
      "trial: 5, iter: 14400, curr loss: 1.3862841129302979, avg loss: 1.386296660900116\n",
      "trial: 5, iter: 14600, curr loss: 1.386042833328247, avg loss: 1.3863017386198044\n",
      "trial: 5, iter: 14800, curr loss: 1.3862698078155518, avg loss: 1.3863245803117752\n",
      "trial: 5, iter: 15000, curr loss: 1.386279582977295, avg loss: 1.3862966305017472\n",
      "trial: 5, iter: 15200, curr loss: 1.3862416744232178, avg loss: 1.386302639245987\n",
      "trial: 5, iter: 15400, curr loss: 1.3862524032592773, avg loss: 1.3862868273258209\n",
      "trial: 5, iter: 15600, curr loss: 1.386474370956421, avg loss: 1.3862963873147964\n",
      "trial: 5, ldr: 0.00027244858210906386\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0006261382484808564\n",
      "Experiment done with data path: ./data/catNon-lin-NI_16/data.50k.dz100.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_12/data.50k.dz50.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.388998031616211, avg loss: 1.3872716528177262\n",
      "trial: 1, iter: 400, curr loss: 1.3835526704788208, avg loss: 1.3866086500883101\n",
      "trial: 1, iter: 600, curr loss: 1.3862403631210327, avg loss: 1.386679260134697\n",
      "trial: 1, iter: 800, curr loss: 1.3860646486282349, avg loss: 1.3864066970348359\n",
      "trial: 1, iter: 1000, curr loss: 1.3846153020858765, avg loss: 1.3863477379083633\n",
      "trial: 1, iter: 1200, curr loss: 1.3863312005996704, avg loss: 1.386471546292305\n",
      "trial: 1, iter: 1400, curr loss: 1.385516881942749, avg loss: 1.3863982599973679\n",
      "trial: 1, iter: 1600, curr loss: 1.3853815793991089, avg loss: 1.3864706444740296\n",
      "trial: 1, iter: 1800, curr loss: 1.3859323263168335, avg loss: 1.386414669752121\n",
      "trial: 1, iter: 2000, curr loss: 1.3859301805496216, avg loss: 1.3863734585046767\n",
      "trial: 1, iter: 2200, curr loss: 1.3865458965301514, avg loss: 1.386393336057663\n",
      "trial: 1, iter: 2400, curr loss: 1.3861968517303467, avg loss: 1.3864380902051925\n",
      "trial: 1, iter: 2600, curr loss: 1.38455069065094, avg loss: 1.3862334948778152\n",
      "trial: 1, iter: 2800, curr loss: 1.3861801624298096, avg loss: 1.386357980966568\n",
      "trial: 1, iter: 3000, curr loss: 1.3870396614074707, avg loss: 1.3863113766908646\n",
      "trial: 1, iter: 3200, curr loss: 1.386805534362793, avg loss: 1.3863271987438202\n",
      "trial: 1, iter: 3400, curr loss: 1.3862439393997192, avg loss: 1.3863431131839752\n",
      "trial: 1, iter: 3600, curr loss: 1.3868532180786133, avg loss: 1.3862988531589509\n",
      "trial: 1, iter: 3800, curr loss: 1.38616943359375, avg loss: 1.3863847434520722\n",
      "trial: 1, iter: 4000, curr loss: 1.3862276077270508, avg loss: 1.386307846903801\n",
      "trial: 1, iter: 4200, curr loss: 1.3861525058746338, avg loss: 1.386334177851677\n",
      "trial: 1, iter: 4400, curr loss: 1.3860535621643066, avg loss: 1.3863069325685502\n",
      "trial: 1, iter: 4600, curr loss: 1.3864986896514893, avg loss: 1.3863239115476609\n",
      "trial: 1, iter: 4800, curr loss: 1.3863152265548706, avg loss: 1.3863202166557311\n",
      "trial: 1, iter: 5000, curr loss: 1.386328101158142, avg loss: 1.386275070309639\n",
      "trial: 1, iter: 5200, curr loss: 1.3874056339263916, avg loss: 1.3863318645954132\n",
      "trial: 1, iter: 5400, curr loss: 1.386412501335144, avg loss: 1.3863188362121581\n",
      "trial: 1, iter: 5600, curr loss: 1.3867675065994263, avg loss: 1.38639657497406\n",
      "trial: 1, iter: 5800, curr loss: 1.386568307876587, avg loss: 1.3862871205806733\n",
      "trial: 1, iter: 6000, curr loss: 1.38602876663208, avg loss: 1.3863151121139525\n",
      "trial: 1, iter: 6200, curr loss: 1.3865574598312378, avg loss: 1.3863619470596313\n",
      "trial: 1, iter: 6400, curr loss: 1.3862069845199585, avg loss: 1.3862843316793443\n",
      "trial: 1, iter: 6600, curr loss: 1.3870428800582886, avg loss: 1.386295301914215\n",
      "trial: 1, iter: 6800, curr loss: 1.3865296840667725, avg loss: 1.3863105446100235\n",
      "trial: 1, iter: 7000, curr loss: 1.3863245248794556, avg loss: 1.386286952495575\n",
      "trial: 1, iter: 7200, curr loss: 1.3864264488220215, avg loss: 1.3863127464056015\n",
      "trial: 1, iter: 7400, curr loss: 1.3863059282302856, avg loss: 1.386315233707428\n",
      "trial: 1, iter: 7600, curr loss: 1.3862758874893188, avg loss: 1.3862936675548554\n",
      "trial: 1, iter: 7800, curr loss: 1.3862791061401367, avg loss: 1.3863074833154678\n",
      "trial: 1, iter: 8000, curr loss: 1.3863000869750977, avg loss: 1.3862982040643692\n",
      "trial: 1, iter: 8200, curr loss: 1.3864222764968872, avg loss: 1.3863055717945099\n",
      "trial: 1, iter: 8400, curr loss: 1.3861840963363647, avg loss: 1.3862970870733262\n",
      "trial: 1, iter: 8600, curr loss: 1.3863943815231323, avg loss: 1.3862926107645035\n",
      "trial: 1, iter: 8800, curr loss: 1.3863271474838257, avg loss: 1.3863032972812652\n",
      "trial: 1, iter: 9000, curr loss: 1.3862320184707642, avg loss: 1.3862951934337615\n",
      "trial: 1, iter: 9200, curr loss: 1.3863420486450195, avg loss: 1.3863023668527603\n",
      "trial: 1, iter: 9400, curr loss: 1.3862977027893066, avg loss: 1.3863031518459321\n",
      "trial: 1, iter: 9600, curr loss: 1.3865209817886353, avg loss: 1.3864077073335648\n",
      "trial: 1, iter: 9800, curr loss: 1.3862199783325195, avg loss: 1.3863697290420531\n",
      "trial: 1, iter: 10000, curr loss: 1.386151671409607, avg loss: 1.3862923222780228\n",
      "trial: 1, iter: 10200, curr loss: 1.3863284587860107, avg loss: 1.3863220643997192\n",
      "trial: 1, iter: 10400, curr loss: 1.3863072395324707, avg loss: 1.3863099414110183\n",
      "trial: 1, iter: 10600, curr loss: 1.3863269090652466, avg loss: 1.3862941801548003\n",
      "trial: 1, iter: 10800, curr loss: 1.3863160610198975, avg loss: 1.3862905192375183\n",
      "trial: 1, iter: 11000, curr loss: 1.3866569995880127, avg loss: 1.3862854009866714\n",
      "trial: 1, iter: 11200, curr loss: 1.3861058950424194, avg loss: 1.3863056027889251\n",
      "trial: 1, iter: 11400, curr loss: 1.385783076286316, avg loss: 1.3862783151865006\n",
      "trial: 1, iter: 11600, curr loss: 1.3860132694244385, avg loss: 1.386316295862198\n",
      "trial: 1, iter: 11800, curr loss: 1.3862172365188599, avg loss: 1.386294966340065\n",
      "trial: 1, iter: 12000, curr loss: 1.3862742185592651, avg loss: 1.3863158404827118\n",
      "trial: 1, iter: 12200, curr loss: 1.385786533355713, avg loss: 1.3863170713186264\n",
      "trial: 1, iter: 12400, curr loss: 1.3860434293746948, avg loss: 1.3863342148065567\n",
      "trial: 1, iter: 12600, curr loss: 1.3864264488220215, avg loss: 1.3863327407836914\n",
      "trial: 1, iter: 12800, curr loss: 1.3868160247802734, avg loss: 1.3862982541322708\n",
      "trial: 1, iter: 13000, curr loss: 1.386056661605835, avg loss: 1.386309158205986\n",
      "trial: 1, iter: 13200, curr loss: 1.386318325996399, avg loss: 1.3863125944137573\n",
      "trial: 1, iter: 13400, curr loss: 1.3862435817718506, avg loss: 1.3863042467832565\n",
      "trial: 1, iter: 13600, curr loss: 1.3862487077713013, avg loss: 1.3863179641962051\n",
      "trial: 1, iter: 13800, curr loss: 1.3861629962921143, avg loss: 1.3862999618053435\n",
      "trial: 1, iter: 14000, curr loss: 1.3863626718521118, avg loss: 1.3862964659929276\n",
      "trial: 1, iter: 14200, curr loss: 1.3864318132400513, avg loss: 1.3862969398498535\n",
      "trial: 1, iter: 14400, curr loss: 1.3860975503921509, avg loss: 1.3863312143087387\n",
      "trial: 1, iter: 14600, curr loss: 1.3854942321777344, avg loss: 1.3862957793474198\n",
      "trial: 1, iter: 14800, curr loss: 1.3857258558273315, avg loss: 1.386356474161148\n",
      "trial: 1, iter: 15000, curr loss: 1.386225938796997, avg loss: 1.3863215738534926\n",
      "trial: 1, iter: 15200, curr loss: 1.3863253593444824, avg loss: 1.3862996971607209\n",
      "trial: 1, iter: 15400, curr loss: 1.3865652084350586, avg loss: 1.386305422782898\n",
      "trial: 1, iter: 15600, curr loss: 1.3860453367233276, avg loss: 1.386372939348221\n",
      "trial: 1, ldr: -0.00036734307650476694\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3881124258041382, avg loss: 1.3874746876955033\n",
      "trial: 2, iter: 400, curr loss: 1.3863946199417114, avg loss: 1.386511778831482\n",
      "trial: 2, iter: 600, curr loss: 1.3872178792953491, avg loss: 1.3866791063547135\n",
      "trial: 2, iter: 800, curr loss: 1.3879691362380981, avg loss: 1.3865132784843446\n",
      "trial: 2, iter: 1000, curr loss: 1.38559889793396, avg loss: 1.3865363144874572\n",
      "trial: 2, iter: 1200, curr loss: 1.3871030807495117, avg loss: 1.3864039367437362\n",
      "trial: 2, iter: 1400, curr loss: 1.387244462966919, avg loss: 1.3864342665672302\n",
      "trial: 2, iter: 1600, curr loss: 1.3873093128204346, avg loss: 1.3864409643411637\n",
      "trial: 2, iter: 1800, curr loss: 1.3852815628051758, avg loss: 1.3863531512022018\n",
      "trial: 2, iter: 2000, curr loss: 1.3870515823364258, avg loss: 1.3864652627706529\n",
      "trial: 2, iter: 2200, curr loss: 1.3864079713821411, avg loss: 1.3863746267557144\n",
      "trial: 2, iter: 2400, curr loss: 1.3862818479537964, avg loss: 1.3863193219900132\n",
      "trial: 2, iter: 2600, curr loss: 1.3863202333450317, avg loss: 1.386356742978096\n",
      "trial: 2, iter: 2800, curr loss: 1.3862355947494507, avg loss: 1.3863445210456848\n",
      "trial: 2, iter: 3000, curr loss: 1.3862515687942505, avg loss: 1.3863154304027558\n",
      "trial: 2, iter: 3200, curr loss: 1.3858751058578491, avg loss: 1.3863425481319427\n",
      "trial: 2, iter: 3400, curr loss: 1.3843698501586914, avg loss: 1.3862650698423387\n",
      "trial: 2, iter: 3600, curr loss: 1.386244773864746, avg loss: 1.3863834458589555\n",
      "trial: 2, iter: 3800, curr loss: 1.3862969875335693, avg loss: 1.386360101699829\n",
      "trial: 2, iter: 4000, curr loss: 1.3863694667816162, avg loss: 1.3863389050960542\n",
      "trial: 2, iter: 4200, curr loss: 1.3867058753967285, avg loss: 1.3863053846359252\n",
      "trial: 2, iter: 4400, curr loss: 1.386014699935913, avg loss: 1.3863059502840043\n",
      "trial: 2, iter: 4600, curr loss: 1.386337399482727, avg loss: 1.3863087338209152\n",
      "trial: 2, iter: 4800, curr loss: 1.3863091468811035, avg loss: 1.3862858021259308\n",
      "trial: 2, iter: 5000, curr loss: 1.3867045640945435, avg loss: 1.386356113553047\n",
      "trial: 2, iter: 5200, curr loss: 1.3867107629776, avg loss: 1.386331222653389\n",
      "trial: 2, iter: 5400, curr loss: 1.3867292404174805, avg loss: 1.3863243293762206\n",
      "trial: 2, iter: 5600, curr loss: 1.3865230083465576, avg loss: 1.3863310492038727\n",
      "trial: 2, iter: 5800, curr loss: 1.386587381362915, avg loss: 1.3863831961154938\n",
      "trial: 2, iter: 6000, curr loss: 1.3856886625289917, avg loss: 1.3863559728860855\n",
      "trial: 2, iter: 6200, curr loss: 1.3861405849456787, avg loss: 1.386295943260193\n",
      "trial: 2, iter: 6400, curr loss: 1.3866292238235474, avg loss: 1.3863276952505112\n",
      "trial: 2, iter: 6600, curr loss: 1.3867017030715942, avg loss: 1.3863141298294068\n",
      "trial: 2, iter: 6800, curr loss: 1.3859838247299194, avg loss: 1.386305300593376\n",
      "trial: 2, iter: 7000, curr loss: 1.386379361152649, avg loss: 1.3863339924812317\n",
      "trial: 2, iter: 7200, curr loss: 1.3857123851776123, avg loss: 1.3862899559736253\n",
      "trial: 2, iter: 7400, curr loss: 1.386204481124878, avg loss: 1.386340001821518\n",
      "trial: 2, iter: 7600, curr loss: 1.386436939239502, avg loss: 1.386314496397972\n",
      "trial: 2, iter: 7800, curr loss: 1.3860373497009277, avg loss: 1.3863421124219895\n",
      "trial: 2, iter: 8000, curr loss: 1.3862533569335938, avg loss: 1.3863809621334076\n",
      "trial: 2, iter: 8200, curr loss: 1.3863496780395508, avg loss: 1.386325519680977\n",
      "trial: 2, iter: 8400, curr loss: 1.3862704038619995, avg loss: 1.386313920021057\n",
      "trial: 2, iter: 8600, curr loss: 1.3863945007324219, avg loss: 1.3863151055574416\n",
      "trial: 2, iter: 8800, curr loss: 1.3860900402069092, avg loss: 1.3863093024492263\n",
      "trial: 2, iter: 9000, curr loss: 1.3862844705581665, avg loss: 1.3863074797391892\n",
      "trial: 2, iter: 9200, curr loss: 1.3863941431045532, avg loss: 1.3863192903995514\n",
      "trial: 2, iter: 9400, curr loss: 1.3862948417663574, avg loss: 1.386293904185295\n",
      "trial: 2, iter: 9600, curr loss: 1.3863838911056519, avg loss: 1.386295321583748\n",
      "trial: 2, iter: 9800, curr loss: 1.3862924575805664, avg loss: 1.3863082951307297\n",
      "trial: 2, iter: 10000, curr loss: 1.3858144283294678, avg loss: 1.3862895500659942\n",
      "trial: 2, iter: 10200, curr loss: 1.3862097263336182, avg loss: 1.386335666179657\n",
      "trial: 2, iter: 10400, curr loss: 1.38633131980896, avg loss: 1.3863096678256988\n",
      "trial: 2, iter: 10600, curr loss: 1.3862026929855347, avg loss: 1.3863049739599227\n",
      "trial: 2, iter: 10800, curr loss: 1.386309266090393, avg loss: 1.386299701333046\n",
      "trial: 2, iter: 11000, curr loss: 1.3863615989685059, avg loss: 1.3863024246692657\n",
      "trial: 2, iter: 11200, curr loss: 1.3862746953964233, avg loss: 1.3863041692972182\n",
      "trial: 2, iter: 11400, curr loss: 1.3862659931182861, avg loss: 1.3862995421886444\n",
      "trial: 2, iter: 11600, curr loss: 1.3862965106964111, avg loss: 1.386294270157814\n",
      "trial: 2, iter: 11800, curr loss: 1.3862924575805664, avg loss: 1.3863040256500243\n",
      "trial: 2, iter: 12000, curr loss: 1.3857566118240356, avg loss: 1.3862711715698242\n",
      "trial: 2, iter: 12200, curr loss: 1.3857792615890503, avg loss: 1.3863291120529175\n",
      "trial: 2, iter: 12400, curr loss: 1.3860914707183838, avg loss: 1.386291446685791\n",
      "trial: 2, iter: 12600, curr loss: 1.3866912126541138, avg loss: 1.3863709896802903\n",
      "trial: 2, iter: 12800, curr loss: 1.3859690427780151, avg loss: 1.3862999653816224\n",
      "trial: 2, iter: 13000, curr loss: 1.3862255811691284, avg loss: 1.3863004040718079\n",
      "trial: 2, iter: 13200, curr loss: 1.3862066268920898, avg loss: 1.3862886440753937\n",
      "trial: 2, iter: 13400, curr loss: 1.3860794305801392, avg loss: 1.3863079226016999\n",
      "trial: 2, iter: 13600, curr loss: 1.3862347602844238, avg loss: 1.386308900117874\n",
      "trial: 2, iter: 13800, curr loss: 1.3861337900161743, avg loss: 1.3862952393293382\n",
      "trial: 2, iter: 14000, curr loss: 1.386483073234558, avg loss: 1.3862970227003097\n",
      "trial: 2, iter: 14200, curr loss: 1.3866440057754517, avg loss: 1.3863075929880142\n",
      "trial: 2, iter: 14400, curr loss: 1.3862053155899048, avg loss: 1.3862954199314117\n",
      "trial: 2, iter: 14600, curr loss: 1.3861979246139526, avg loss: 1.3862922924757004\n",
      "trial: 2, iter: 14800, curr loss: 1.3861331939697266, avg loss: 1.3863098299503327\n",
      "trial: 2, iter: 15000, curr loss: 1.3862559795379639, avg loss: 1.386296283006668\n",
      "trial: 2, iter: 15200, curr loss: 1.3863691091537476, avg loss: 1.386303014755249\n",
      "trial: 2, iter: 15400, curr loss: 1.3864445686340332, avg loss: 1.3862847840785981\n",
      "trial: 2, iter: 15600, curr loss: 1.386344313621521, avg loss: 1.38631290435791\n",
      "trial: 2, ldr: -0.0012732086470350623\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3860465288162231, avg loss: 1.3873353427648545\n",
      "trial: 3, iter: 400, curr loss: 1.3884985446929932, avg loss: 1.3867222064733504\n",
      "trial: 3, iter: 600, curr loss: 1.388817548751831, avg loss: 1.3866330683231354\n",
      "trial: 3, iter: 800, curr loss: 1.3863470554351807, avg loss: 1.3864776974916457\n",
      "trial: 3, iter: 1000, curr loss: 1.38534414768219, avg loss: 1.3864903259277344\n",
      "trial: 3, iter: 1200, curr loss: 1.3875502347946167, avg loss: 1.386388453245163\n",
      "trial: 3, iter: 1400, curr loss: 1.3870725631713867, avg loss: 1.3864208751916884\n",
      "trial: 3, iter: 1600, curr loss: 1.3861461877822876, avg loss: 1.3864302515983582\n",
      "trial: 3, iter: 1800, curr loss: 1.3869094848632812, avg loss: 1.3863630121946335\n",
      "trial: 3, iter: 2000, curr loss: 1.3870046138763428, avg loss: 1.386371167898178\n",
      "trial: 3, iter: 2200, curr loss: 1.3858363628387451, avg loss: 1.3863250029087066\n",
      "trial: 3, iter: 2400, curr loss: 1.385606050491333, avg loss: 1.3863257384300232\n",
      "trial: 3, iter: 2600, curr loss: 1.386004090309143, avg loss: 1.3863912731409074\n",
      "trial: 3, iter: 2800, curr loss: 1.3860337734222412, avg loss: 1.386357204914093\n",
      "trial: 3, iter: 3000, curr loss: 1.3858426809310913, avg loss: 1.3862935590744019\n",
      "trial: 3, iter: 3200, curr loss: 1.3871419429779053, avg loss: 1.3863519543409348\n",
      "trial: 3, iter: 3400, curr loss: 1.3862643241882324, avg loss: 1.3864063179492951\n",
      "trial: 3, iter: 3600, curr loss: 1.3869003057479858, avg loss: 1.3863304197788238\n",
      "trial: 3, iter: 3800, curr loss: 1.385571002960205, avg loss: 1.3863429963588714\n",
      "trial: 3, iter: 4000, curr loss: 1.3861267566680908, avg loss: 1.3863235938549041\n",
      "trial: 3, iter: 4200, curr loss: 1.3864996433258057, avg loss: 1.3863349962234497\n",
      "trial: 3, iter: 4400, curr loss: 1.3856829404830933, avg loss: 1.3862905561923982\n",
      "trial: 3, iter: 4600, curr loss: 1.3862484693527222, avg loss: 1.3863285756111146\n",
      "trial: 3, iter: 4800, curr loss: 1.3852404356002808, avg loss: 1.386303424835205\n",
      "trial: 3, iter: 5000, curr loss: 1.3869000673294067, avg loss: 1.3863430869579316\n",
      "trial: 3, iter: 5200, curr loss: 1.3860448598861694, avg loss: 1.3863487720489502\n",
      "trial: 3, iter: 5400, curr loss: 1.3859635591506958, avg loss: 1.3863026362657547\n",
      "trial: 3, iter: 5600, curr loss: 1.3861881494522095, avg loss: 1.3863908070325852\n",
      "trial: 3, iter: 5800, curr loss: 1.3866769075393677, avg loss: 1.3863323962688445\n",
      "trial: 3, iter: 6000, curr loss: 1.3862682580947876, avg loss: 1.3863060241937637\n",
      "trial: 3, iter: 6200, curr loss: 1.3863835334777832, avg loss: 1.3863229358196258\n",
      "trial: 3, iter: 6400, curr loss: 1.3863587379455566, avg loss: 1.386327274441719\n",
      "trial: 3, iter: 6600, curr loss: 1.3863972425460815, avg loss: 1.3863107073307037\n",
      "trial: 3, iter: 6800, curr loss: 1.3862453699111938, avg loss: 1.3863360399007798\n",
      "trial: 3, iter: 7000, curr loss: 1.3864972591400146, avg loss: 1.3863087421655655\n",
      "trial: 3, iter: 7200, curr loss: 1.3860613107681274, avg loss: 1.3862996947765351\n",
      "trial: 3, iter: 7400, curr loss: 1.3866703510284424, avg loss: 1.386293973326683\n",
      "trial: 3, iter: 7600, curr loss: 1.3862195014953613, avg loss: 1.3863303911685945\n",
      "trial: 3, iter: 7800, curr loss: 1.3861721754074097, avg loss: 1.3863066560029984\n",
      "trial: 3, iter: 8000, curr loss: 1.386030673980713, avg loss: 1.3862903332710266\n",
      "trial: 3, iter: 8200, curr loss: 1.3870465755462646, avg loss: 1.386315659880638\n",
      "trial: 3, iter: 8400, curr loss: 1.3870768547058105, avg loss: 1.3863276129961013\n",
      "trial: 3, iter: 8600, curr loss: 1.3866093158721924, avg loss: 1.3864034175872804\n",
      "trial: 3, iter: 8800, curr loss: 1.3850544691085815, avg loss: 1.38643829703331\n",
      "trial: 3, iter: 9000, curr loss: 1.38640296459198, avg loss: 1.3863564836978912\n",
      "trial: 3, iter: 9200, curr loss: 1.3867955207824707, avg loss: 1.3863964033126832\n",
      "trial: 3, iter: 9400, curr loss: 1.387264370918274, avg loss: 1.386288519501686\n",
      "trial: 3, iter: 9600, curr loss: 1.3862909078598022, avg loss: 1.3863248294591903\n",
      "trial: 3, iter: 9800, curr loss: 1.3869878053665161, avg loss: 1.3862956374883653\n",
      "trial: 3, iter: 10000, curr loss: 1.387366771697998, avg loss: 1.3863157761096954\n",
      "trial: 3, iter: 10200, curr loss: 1.3865983486175537, avg loss: 1.3863064116239547\n",
      "trial: 3, iter: 10400, curr loss: 1.3864597082138062, avg loss: 1.3863037377595901\n",
      "trial: 3, iter: 10600, curr loss: 1.385873794555664, avg loss: 1.386316450238228\n",
      "trial: 3, iter: 10800, curr loss: 1.3856334686279297, avg loss: 1.3863082814216614\n",
      "trial: 3, iter: 11000, curr loss: 1.3865180015563965, avg loss: 1.3863033908605575\n",
      "trial: 3, iter: 11200, curr loss: 1.3863028287887573, avg loss: 1.386310470700264\n",
      "trial: 3, iter: 11400, curr loss: 1.3865656852722168, avg loss: 1.3863178342580795\n",
      "trial: 3, iter: 11600, curr loss: 1.386257529258728, avg loss: 1.3863051098585129\n",
      "trial: 3, iter: 11800, curr loss: 1.3863439559936523, avg loss: 1.386308057308197\n",
      "trial: 3, iter: 12000, curr loss: 1.3861112594604492, avg loss: 1.3863018703460694\n",
      "trial: 3, iter: 12200, curr loss: 1.3864448070526123, avg loss: 1.3863092851638794\n",
      "trial: 3, iter: 12400, curr loss: 1.3864176273345947, avg loss: 1.3863124293088913\n",
      "trial: 3, iter: 12600, curr loss: 1.3863273859024048, avg loss: 1.38629093170166\n",
      "trial: 3, iter: 12800, curr loss: 1.386635661125183, avg loss: 1.386284499168396\n",
      "trial: 3, iter: 13000, curr loss: 1.3862298727035522, avg loss: 1.3863217782974244\n",
      "trial: 3, iter: 13200, curr loss: 1.386235237121582, avg loss: 1.3863185077905655\n",
      "trial: 3, iter: 13400, curr loss: 1.3863154649734497, avg loss: 1.386298475265503\n",
      "trial: 3, iter: 13600, curr loss: 1.3859630823135376, avg loss: 1.38631051838398\n",
      "trial: 3, iter: 13800, curr loss: 1.385209321975708, avg loss: 1.3863485115766525\n",
      "trial: 3, iter: 14000, curr loss: 1.3865208625793457, avg loss: 1.3864027738571167\n",
      "trial: 3, iter: 14200, curr loss: 1.3860565423965454, avg loss: 1.3863394451141358\n",
      "trial: 3, iter: 14400, curr loss: 1.3866386413574219, avg loss: 1.386325581073761\n",
      "trial: 3, iter: 14600, curr loss: 1.3859952688217163, avg loss: 1.3862997502088548\n",
      "trial: 3, iter: 14800, curr loss: 1.386121153831482, avg loss: 1.386289622783661\n",
      "trial: 3, iter: 15000, curr loss: 1.3864471912384033, avg loss: 1.3863552343845367\n",
      "trial: 3, iter: 15200, curr loss: 1.3856487274169922, avg loss: 1.3862938755750656\n",
      "trial: 3, iter: 15400, curr loss: 1.3867411613464355, avg loss: 1.3863007932901383\n",
      "trial: 3, iter: 15600, curr loss: 1.3867278099060059, avg loss: 1.3863331329822541\n",
      "trial: 3, ldr: -0.0040670097805559635\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.389169454574585, avg loss: 1.387638988494873\n",
      "trial: 4, iter: 400, curr loss: 1.386542797088623, avg loss: 1.3865953648090363\n",
      "trial: 4, iter: 600, curr loss: 1.3845980167388916, avg loss: 1.3865763020515443\n",
      "trial: 4, iter: 800, curr loss: 1.3857927322387695, avg loss: 1.3864243930578233\n",
      "trial: 4, iter: 1000, curr loss: 1.388170838356018, avg loss: 1.3864895117282867\n",
      "trial: 4, iter: 1200, curr loss: 1.385358452796936, avg loss: 1.386268780231476\n",
      "trial: 4, iter: 1400, curr loss: 1.3873975276947021, avg loss: 1.3864726048707963\n",
      "trial: 4, iter: 1600, curr loss: 1.3865134716033936, avg loss: 1.3865036463737488\n",
      "trial: 4, iter: 1800, curr loss: 1.3857545852661133, avg loss: 1.3863335645198822\n",
      "trial: 4, iter: 2000, curr loss: 1.3868352174758911, avg loss: 1.386373873949051\n",
      "trial: 4, iter: 2200, curr loss: 1.3848313093185425, avg loss: 1.3863844138383865\n",
      "trial: 4, iter: 2400, curr loss: 1.3860834836959839, avg loss: 1.3864506411552429\n",
      "trial: 4, iter: 2600, curr loss: 1.3861345052719116, avg loss: 1.386340833902359\n",
      "trial: 4, iter: 2800, curr loss: 1.386048436164856, avg loss: 1.3863742297887802\n",
      "trial: 4, iter: 3000, curr loss: 1.3867303133010864, avg loss: 1.3863476568460464\n",
      "trial: 4, iter: 3200, curr loss: 1.3856319189071655, avg loss: 1.3862990802526474\n",
      "trial: 4, iter: 3400, curr loss: 1.3858144283294678, avg loss: 1.3863387876749038\n",
      "trial: 4, iter: 3600, curr loss: 1.386122226715088, avg loss: 1.3863314390182495\n",
      "trial: 4, iter: 3800, curr loss: 1.3868049383163452, avg loss: 1.3863512289524078\n",
      "trial: 4, iter: 4000, curr loss: 1.3867182731628418, avg loss: 1.386361881494522\n",
      "trial: 4, iter: 4200, curr loss: 1.3863872289657593, avg loss: 1.3863304179906846\n",
      "trial: 4, iter: 4400, curr loss: 1.3865073919296265, avg loss: 1.3863069713115692\n",
      "trial: 4, iter: 4600, curr loss: 1.3859261274337769, avg loss: 1.3863350450992584\n",
      "trial: 4, iter: 4800, curr loss: 1.3864550590515137, avg loss: 1.386330824494362\n",
      "trial: 4, iter: 5000, curr loss: 1.3861982822418213, avg loss: 1.3863706451654434\n",
      "trial: 4, iter: 5200, curr loss: 1.3865573406219482, avg loss: 1.386291407942772\n",
      "trial: 4, iter: 5400, curr loss: 1.386304259300232, avg loss: 1.3863524675369263\n",
      "trial: 4, iter: 5600, curr loss: 1.3864271640777588, avg loss: 1.3863134109973907\n",
      "trial: 4, iter: 5800, curr loss: 1.3863775730133057, avg loss: 1.3862930476665496\n",
      "trial: 4, iter: 6000, curr loss: 1.3859388828277588, avg loss: 1.3863988322019578\n",
      "trial: 4, iter: 6200, curr loss: 1.3865151405334473, avg loss: 1.3863264280557632\n",
      "trial: 4, iter: 6400, curr loss: 1.3866724967956543, avg loss: 1.386301539540291\n",
      "trial: 4, iter: 6600, curr loss: 1.3873025178909302, avg loss: 1.386323292851448\n",
      "trial: 4, iter: 6800, curr loss: 1.386979579925537, avg loss: 1.3863031023740768\n",
      "trial: 4, iter: 7000, curr loss: 1.3862264156341553, avg loss: 1.386368373632431\n",
      "trial: 4, iter: 7200, curr loss: 1.3866723775863647, avg loss: 1.3862918084859848\n",
      "trial: 4, iter: 7400, curr loss: 1.3865537643432617, avg loss: 1.3863102227449418\n",
      "trial: 4, iter: 7600, curr loss: 1.3860459327697754, avg loss: 1.3862950652837753\n",
      "trial: 4, iter: 7800, curr loss: 1.386594533920288, avg loss: 1.3863087874650954\n",
      "trial: 4, iter: 8000, curr loss: 1.3860608339309692, avg loss: 1.3863237881660462\n",
      "trial: 4, iter: 8200, curr loss: 1.3856669664382935, avg loss: 1.3862980592250824\n",
      "trial: 4, iter: 8400, curr loss: 1.3859121799468994, avg loss: 1.3863441175222397\n",
      "trial: 4, iter: 8600, curr loss: 1.3863415718078613, avg loss: 1.3863060420751572\n",
      "trial: 4, iter: 8800, curr loss: 1.3868879079818726, avg loss: 1.3863131546974181\n",
      "trial: 4, iter: 9000, curr loss: 1.3864338397979736, avg loss: 1.3863230526447297\n",
      "trial: 4, iter: 9200, curr loss: 1.3867396116256714, avg loss: 1.3862985348701478\n",
      "trial: 4, iter: 9400, curr loss: 1.3866008520126343, avg loss: 1.3862681084871291\n",
      "trial: 4, iter: 9600, curr loss: 1.386101245880127, avg loss: 1.3863305306434632\n",
      "trial: 4, iter: 9800, curr loss: 1.3865430355072021, avg loss: 1.386294053196907\n",
      "trial: 4, iter: 10000, curr loss: 1.3859976530075073, avg loss: 1.3863140368461608\n",
      "trial: 4, iter: 10200, curr loss: 1.3864531517028809, avg loss: 1.3863138335943221\n",
      "trial: 4, iter: 10400, curr loss: 1.3863651752471924, avg loss: 1.38631651699543\n",
      "trial: 4, iter: 10600, curr loss: 1.3865594863891602, avg loss: 1.386315456032753\n",
      "trial: 4, iter: 10800, curr loss: 1.3861608505249023, avg loss: 1.3863147342205047\n",
      "trial: 4, iter: 11000, curr loss: 1.3868772983551025, avg loss: 1.3862660133838653\n",
      "trial: 4, iter: 11200, curr loss: 1.386972188949585, avg loss: 1.3863018190860747\n",
      "trial: 4, iter: 11400, curr loss: 1.3855751752853394, avg loss: 1.3862970727682113\n",
      "trial: 4, iter: 11600, curr loss: 1.3863502740859985, avg loss: 1.386308224797249\n",
      "trial: 4, iter: 11800, curr loss: 1.3860177993774414, avg loss: 1.3862958586215972\n",
      "trial: 4, iter: 12000, curr loss: 1.3862982988357544, avg loss: 1.386289729475975\n",
      "trial: 4, iter: 12200, curr loss: 1.385512351989746, avg loss: 1.3862747818231582\n",
      "trial: 4, iter: 12400, curr loss: 1.384964108467102, avg loss: 1.3863233095407486\n",
      "trial: 4, iter: 12600, curr loss: 1.3865041732788086, avg loss: 1.3863152742385865\n",
      "trial: 4, iter: 12800, curr loss: 1.3864810466766357, avg loss: 1.3863577073812485\n",
      "trial: 4, iter: 13000, curr loss: 1.3862121105194092, avg loss: 1.386295948624611\n",
      "trial: 4, iter: 13200, curr loss: 1.3865588903427124, avg loss: 1.386322540640831\n",
      "trial: 4, iter: 13400, curr loss: 1.386034369468689, avg loss: 1.3863069170713425\n",
      "trial: 4, iter: 13600, curr loss: 1.3865681886672974, avg loss: 1.3863207525014878\n",
      "trial: 4, iter: 13800, curr loss: 1.3863800764083862, avg loss: 1.3863102960586549\n",
      "trial: 4, iter: 14000, curr loss: 1.3860056400299072, avg loss: 1.3863488537073136\n",
      "trial: 4, iter: 14200, curr loss: 1.386279821395874, avg loss: 1.3863083136081695\n",
      "trial: 4, iter: 14400, curr loss: 1.386259913444519, avg loss: 1.3863082450628281\n",
      "trial: 4, iter: 14600, curr loss: 1.3863176107406616, avg loss: 1.3862983387708665\n",
      "trial: 4, iter: 14800, curr loss: 1.3865869045257568, avg loss: 1.386303271651268\n",
      "trial: 4, iter: 15000, curr loss: 1.386103630065918, avg loss: 1.3863048887252807\n",
      "trial: 4, iter: 15200, curr loss: 1.3862864971160889, avg loss: 1.3863002055883407\n",
      "trial: 4, iter: 15400, curr loss: 1.386380672454834, avg loss: 1.3863349825143814\n",
      "trial: 4, iter: 15600, curr loss: 1.3863259553909302, avg loss: 1.3863047367334367\n",
      "trial: 4, ldr: 9.508340008324012e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3907030820846558, avg loss: 1.387047747373581\n",
      "trial: 5, iter: 400, curr loss: 1.3885750770568848, avg loss: 1.3866160058975219\n",
      "trial: 5, iter: 600, curr loss: 1.3853458166122437, avg loss: 1.386484957933426\n",
      "trial: 5, iter: 800, curr loss: 1.3867744207382202, avg loss: 1.3865298110246658\n",
      "trial: 5, iter: 1000, curr loss: 1.3858598470687866, avg loss: 1.386423043012619\n",
      "trial: 5, iter: 1200, curr loss: 1.386029839515686, avg loss: 1.3863209253549575\n",
      "trial: 5, iter: 1400, curr loss: 1.3860554695129395, avg loss: 1.386345129609108\n",
      "trial: 5, iter: 1600, curr loss: 1.385337471961975, avg loss: 1.3863113844394683\n",
      "trial: 5, iter: 1800, curr loss: 1.3858356475830078, avg loss: 1.3863203221559524\n",
      "trial: 5, iter: 2000, curr loss: 1.3863606452941895, avg loss: 1.386354137659073\n",
      "trial: 5, iter: 2200, curr loss: 1.3850692510604858, avg loss: 1.3863479214906693\n",
      "trial: 5, iter: 2400, curr loss: 1.386103868484497, avg loss: 1.386412309408188\n",
      "trial: 5, iter: 2600, curr loss: 1.387991189956665, avg loss: 1.3863703215122223\n",
      "trial: 5, iter: 2800, curr loss: 1.3863601684570312, avg loss: 1.386314646601677\n",
      "trial: 5, iter: 3000, curr loss: 1.386103630065918, avg loss: 1.3864266979694366\n",
      "trial: 5, iter: 3200, curr loss: 1.386621117591858, avg loss: 1.3863341057300567\n",
      "trial: 5, iter: 3400, curr loss: 1.3858619928359985, avg loss: 1.3863191390037537\n",
      "trial: 5, iter: 3600, curr loss: 1.386301875114441, avg loss: 1.3863583105802535\n",
      "trial: 5, iter: 3800, curr loss: 1.3868716955184937, avg loss: 1.3863252860307693\n",
      "trial: 5, iter: 4000, curr loss: 1.3860100507736206, avg loss: 1.3863628870248794\n",
      "trial: 5, iter: 4200, curr loss: 1.3861428499221802, avg loss: 1.3863106471300126\n",
      "trial: 5, iter: 4400, curr loss: 1.386837363243103, avg loss: 1.3863082683086396\n",
      "trial: 5, iter: 4600, curr loss: 1.3859444856643677, avg loss: 1.3863011968135834\n",
      "trial: 5, iter: 4800, curr loss: 1.3858015537261963, avg loss: 1.3863309615850448\n",
      "trial: 5, iter: 5000, curr loss: 1.3862860202789307, avg loss: 1.3863390839099885\n",
      "trial: 5, iter: 5200, curr loss: 1.386536955833435, avg loss: 1.3863100999593734\n",
      "trial: 5, iter: 5400, curr loss: 1.3870387077331543, avg loss: 1.3862926638126374\n",
      "trial: 5, iter: 5600, curr loss: 1.3867367506027222, avg loss: 1.3862454050779343\n",
      "trial: 5, iter: 5800, curr loss: 1.386752963066101, avg loss: 1.3864135396480561\n",
      "trial: 5, iter: 6000, curr loss: 1.3852577209472656, avg loss: 1.386312748193741\n",
      "trial: 5, iter: 6200, curr loss: 1.3885962963104248, avg loss: 1.3862992066144944\n",
      "trial: 5, iter: 6400, curr loss: 1.3862826824188232, avg loss: 1.386268920302391\n",
      "trial: 5, iter: 6600, curr loss: 1.3862615823745728, avg loss: 1.3863343751430512\n",
      "trial: 5, iter: 6800, curr loss: 1.386580228805542, avg loss: 1.3862666666507721\n",
      "trial: 5, iter: 7000, curr loss: 1.38554048538208, avg loss: 1.386310344338417\n",
      "trial: 5, iter: 7200, curr loss: 1.386428713798523, avg loss: 1.3863225156068801\n",
      "trial: 5, iter: 7400, curr loss: 1.3864364624023438, avg loss: 1.3863260811567306\n",
      "trial: 5, iter: 7600, curr loss: 1.3864970207214355, avg loss: 1.3862857574224472\n",
      "trial: 5, iter: 7800, curr loss: 1.3867132663726807, avg loss: 1.3863097780942917\n",
      "trial: 5, iter: 8000, curr loss: 1.3863002061843872, avg loss: 1.3863127487897873\n",
      "trial: 5, iter: 8200, curr loss: 1.3860896825790405, avg loss: 1.3863032120466232\n",
      "trial: 5, iter: 8400, curr loss: 1.3865621089935303, avg loss: 1.3863136047124862\n",
      "trial: 5, iter: 8600, curr loss: 1.3864059448242188, avg loss: 1.3862889462709427\n",
      "trial: 5, iter: 8800, curr loss: 1.3860951662063599, avg loss: 1.3862915974855423\n",
      "trial: 5, iter: 9000, curr loss: 1.38633394241333, avg loss: 1.3863094717264175\n",
      "trial: 5, iter: 9200, curr loss: 1.3863040208816528, avg loss: 1.3863008350133896\n",
      "trial: 5, iter: 9400, curr loss: 1.3863009214401245, avg loss: 1.3862932080030441\n",
      "trial: 5, iter: 9600, curr loss: 1.3841737508773804, avg loss: 1.3862416058778764\n",
      "trial: 5, iter: 9800, curr loss: 1.3866074085235596, avg loss: 1.3864416360855103\n",
      "trial: 5, iter: 10000, curr loss: 1.3864625692367554, avg loss: 1.386327177286148\n",
      "trial: 5, iter: 10200, curr loss: 1.386088252067566, avg loss: 1.3862831264734268\n",
      "trial: 5, iter: 10400, curr loss: 1.385594129562378, avg loss: 1.3862916415929794\n",
      "trial: 5, iter: 10600, curr loss: 1.3860028982162476, avg loss: 1.3863701689243317\n",
      "trial: 5, iter: 10800, curr loss: 1.3861346244812012, avg loss: 1.3863202667236327\n",
      "trial: 5, iter: 11000, curr loss: 1.3863410949707031, avg loss: 1.3863115298748017\n",
      "trial: 5, iter: 11200, curr loss: 1.3866263628005981, avg loss: 1.386302218437195\n",
      "trial: 5, iter: 11400, curr loss: 1.3865888118743896, avg loss: 1.3863075578212738\n",
      "trial: 5, iter: 11600, curr loss: 1.3861935138702393, avg loss: 1.3864145958423615\n",
      "trial: 5, iter: 11800, curr loss: 1.3860934972763062, avg loss: 1.3863229382038116\n",
      "trial: 5, iter: 12000, curr loss: 1.3866013288497925, avg loss: 1.3862888091802597\n",
      "trial: 5, iter: 12200, curr loss: 1.3866090774536133, avg loss: 1.386311154961586\n",
      "trial: 5, iter: 12400, curr loss: 1.3858593702316284, avg loss: 1.3863086533546447\n",
      "trial: 5, iter: 12600, curr loss: 1.3860293626785278, avg loss: 1.3863342213630676\n",
      "trial: 5, iter: 12800, curr loss: 1.3859204053878784, avg loss: 1.386280819773674\n",
      "trial: 5, iter: 13000, curr loss: 1.386248230934143, avg loss: 1.3863285315036773\n",
      "trial: 5, iter: 13200, curr loss: 1.3864424228668213, avg loss: 1.3863219487667084\n",
      "trial: 5, iter: 13400, curr loss: 1.3861624002456665, avg loss: 1.3862992644309997\n",
      "trial: 5, iter: 13600, curr loss: 1.3861138820648193, avg loss: 1.3862898463010789\n",
      "trial: 5, iter: 13800, curr loss: 1.3862054347991943, avg loss: 1.3862996065616608\n",
      "trial: 5, iter: 14000, curr loss: 1.3863288164138794, avg loss: 1.386335590481758\n",
      "trial: 5, iter: 14200, curr loss: 1.386136770248413, avg loss: 1.3863708770275116\n",
      "trial: 5, iter: 14400, curr loss: 1.386352777481079, avg loss: 1.3863416677713394\n",
      "trial: 5, iter: 14600, curr loss: 1.3863908052444458, avg loss: 1.386310688853264\n",
      "trial: 5, iter: 14800, curr loss: 1.3864225149154663, avg loss: 1.3863057076931\n",
      "trial: 5, iter: 15000, curr loss: 1.3869205713272095, avg loss: 1.3863617080450057\n",
      "trial: 5, iter: 15200, curr loss: 1.3868412971496582, avg loss: 1.386293299794197\n",
      "trial: 5, iter: 15400, curr loss: 1.3865035772323608, avg loss: 1.3863092845678329\n",
      "trial: 5, iter: 15600, curr loss: 1.385968565940857, avg loss: 1.3863292878866196\n",
      "trial: 5, ldr: -0.0007684070733375847\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0012761770354700274\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3822888135910034, avg loss: 1.3873425114154816\n",
      "trial: 1, iter: 400, curr loss: 1.3884861469268799, avg loss: 1.386890007853508\n",
      "trial: 1, iter: 600, curr loss: 1.3863381147384644, avg loss: 1.3865979570150375\n",
      "trial: 1, iter: 800, curr loss: 1.3851011991500854, avg loss: 1.3864699882268905\n",
      "trial: 1, iter: 1000, curr loss: 1.3862354755401611, avg loss: 1.3863510942459107\n",
      "trial: 1, iter: 1200, curr loss: 1.3864614963531494, avg loss: 1.3863836926221849\n",
      "trial: 1, iter: 1400, curr loss: 1.3869552612304688, avg loss: 1.3863989561796188\n",
      "trial: 1, iter: 1600, curr loss: 1.3859394788742065, avg loss: 1.3864273142814636\n",
      "trial: 1, iter: 1800, curr loss: 1.3864408731460571, avg loss: 1.3863737004995347\n",
      "trial: 1, iter: 2000, curr loss: 1.3871546983718872, avg loss: 1.3863406199216843\n",
      "trial: 1, iter: 2200, curr loss: 1.38571298122406, avg loss: 1.386335350871086\n",
      "trial: 1, iter: 2400, curr loss: 1.3868802785873413, avg loss: 1.38637242436409\n",
      "trial: 1, iter: 2600, curr loss: 1.386178970336914, avg loss: 1.3863655263185501\n",
      "trial: 1, iter: 2800, curr loss: 1.38686203956604, avg loss: 1.3863947248458863\n",
      "trial: 1, iter: 3000, curr loss: 1.3862146139144897, avg loss: 1.3864281302690507\n",
      "trial: 1, iter: 3200, curr loss: 1.3874348402023315, avg loss: 1.3863051271438598\n",
      "trial: 1, iter: 3400, curr loss: 1.3858685493469238, avg loss: 1.3862718421220779\n",
      "trial: 1, iter: 3600, curr loss: 1.385632038116455, avg loss: 1.3863624840974809\n",
      "trial: 1, iter: 3800, curr loss: 1.386460542678833, avg loss: 1.3863729989528657\n",
      "trial: 1, iter: 4000, curr loss: 1.3857522010803223, avg loss: 1.386284732222557\n",
      "trial: 1, iter: 4200, curr loss: 1.3864690065383911, avg loss: 1.3862348091602326\n",
      "trial: 1, iter: 4400, curr loss: 1.3868093490600586, avg loss: 1.38643083691597\n",
      "trial: 1, iter: 4600, curr loss: 1.3864109516143799, avg loss: 1.3863652330636977\n",
      "trial: 1, iter: 4800, curr loss: 1.3870478868484497, avg loss: 1.3863229233026504\n",
      "trial: 1, iter: 5000, curr loss: 1.3871452808380127, avg loss: 1.3863318955898285\n",
      "trial: 1, iter: 5200, curr loss: 1.3864891529083252, avg loss: 1.3863123214244844\n",
      "trial: 1, iter: 5400, curr loss: 1.3869099617004395, avg loss: 1.3862896943092347\n",
      "trial: 1, iter: 5600, curr loss: 1.3863823413848877, avg loss: 1.38633760035038\n",
      "trial: 1, iter: 5800, curr loss: 1.3864624500274658, avg loss: 1.386304088830948\n",
      "trial: 1, iter: 6000, curr loss: 1.3861141204833984, avg loss: 1.3863549900054932\n",
      "trial: 1, iter: 6200, curr loss: 1.3866685628890991, avg loss: 1.386322835087776\n",
      "trial: 1, iter: 6400, curr loss: 1.386557698249817, avg loss: 1.3863072389364242\n",
      "trial: 1, iter: 6600, curr loss: 1.3855955600738525, avg loss: 1.3862973189353942\n",
      "trial: 1, iter: 6800, curr loss: 1.3856918811798096, avg loss: 1.3863075113296508\n",
      "trial: 1, iter: 7000, curr loss: 1.3855512142181396, avg loss: 1.3863183188438415\n",
      "trial: 1, iter: 7200, curr loss: 1.3852545022964478, avg loss: 1.3864177268743516\n",
      "trial: 1, iter: 7400, curr loss: 1.3859460353851318, avg loss: 1.3863581782579422\n",
      "trial: 1, iter: 7600, curr loss: 1.3867034912109375, avg loss: 1.386345672607422\n",
      "trial: 1, iter: 7800, curr loss: 1.3865702152252197, avg loss: 1.386294106245041\n",
      "trial: 1, iter: 8000, curr loss: 1.3868112564086914, avg loss: 1.386379435658455\n",
      "trial: 1, iter: 8200, curr loss: 1.3865845203399658, avg loss: 1.386316801905632\n",
      "trial: 1, iter: 8400, curr loss: 1.386418342590332, avg loss: 1.3863073408603668\n",
      "trial: 1, iter: 8600, curr loss: 1.3861727714538574, avg loss: 1.3863406348228455\n",
      "trial: 1, iter: 8800, curr loss: 1.3861171007156372, avg loss: 1.386312118768692\n",
      "trial: 1, iter: 9000, curr loss: 1.3867217302322388, avg loss: 1.3863061499595641\n",
      "trial: 1, iter: 9200, curr loss: 1.3866021633148193, avg loss: 1.3863142836093902\n",
      "trial: 1, iter: 9400, curr loss: 1.3864169120788574, avg loss: 1.3863427758216857\n",
      "trial: 1, iter: 9600, curr loss: 1.3862583637237549, avg loss: 1.38630477309227\n",
      "trial: 1, iter: 9800, curr loss: 1.3861076831817627, avg loss: 1.3863093614578248\n",
      "trial: 1, iter: 10000, curr loss: 1.386423110961914, avg loss: 1.386344731450081\n",
      "trial: 1, iter: 10200, curr loss: 1.3855873346328735, avg loss: 1.3862946486473084\n",
      "trial: 1, iter: 10400, curr loss: 1.3866386413574219, avg loss: 1.3863143575191499\n",
      "trial: 1, iter: 10600, curr loss: 1.3862932920455933, avg loss: 1.386335619688034\n",
      "trial: 1, iter: 10800, curr loss: 1.3863962888717651, avg loss: 1.3862876188755036\n",
      "trial: 1, iter: 11000, curr loss: 1.3863266706466675, avg loss: 1.386294332742691\n",
      "trial: 1, iter: 11200, curr loss: 1.3862652778625488, avg loss: 1.3862953418493271\n",
      "trial: 1, iter: 11400, curr loss: 1.3862974643707275, avg loss: 1.386294248700142\n",
      "trial: 1, iter: 11600, curr loss: 1.3862947225570679, avg loss: 1.3862932294607162\n",
      "trial: 1, iter: 11800, curr loss: 1.3862659931182861, avg loss: 1.386293351650238\n",
      "trial: 1, iter: 12000, curr loss: 1.3863625526428223, avg loss: 1.3862957882881164\n",
      "trial: 1, iter: 12200, curr loss: 1.3862923383712769, avg loss: 1.3862930810451508\n",
      "trial: 1, iter: 12400, curr loss: 1.3862943649291992, avg loss: 1.3862952589988708\n",
      "trial: 1, iter: 12600, curr loss: 1.3862942457199097, avg loss: 1.3862953162193299\n",
      "trial: 1, iter: 12800, curr loss: 1.3862946033477783, avg loss: 1.3862947273254393\n",
      "trial: 1, iter: 13000, curr loss: 1.3862941265106201, avg loss: 1.3862943649291992\n",
      "trial: 1, iter: 13200, curr loss: 1.3862946033477783, avg loss: 1.3862950485944747\n",
      "trial: 1, iter: 13400, curr loss: 1.3862943649291992, avg loss: 1.3862944900989533\n",
      "trial: 1, iter: 13600, curr loss: 1.3862906694412231, avg loss: 1.3862947422266005\n",
      "trial: 1, iter: 13800, curr loss: 1.3862946033477783, avg loss: 1.3862947487831117\n",
      "trial: 1, iter: 14000, curr loss: 1.3862947225570679, avg loss: 1.386294749379158\n",
      "trial: 1, iter: 14200, curr loss: 1.3862946033477783, avg loss: 1.3862944930791854\n",
      "trial: 1, iter: 14400, curr loss: 1.3862944841384888, avg loss: 1.3862947607040406\n",
      "trial: 1, iter: 14600, curr loss: 1.3862944841384888, avg loss: 1.3862944620847701\n",
      "trial: 1, iter: 14800, curr loss: 1.3862946033477783, avg loss: 1.3862951612472534\n",
      "trial: 1, iter: 15000, curr loss: 1.3862955570220947, avg loss: 1.3862944155931474\n",
      "trial: 1, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862944912910462\n",
      "trial: 1, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294545531273\n",
      "trial: 1, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3862947177886964\n",
      "trial: 1, ldr: 1.817562292671937e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3885587453842163, avg loss: 1.3871032679080963\n",
      "trial: 2, iter: 400, curr loss: 1.3868824243545532, avg loss: 1.3866105103492736\n",
      "trial: 2, iter: 600, curr loss: 1.3852603435516357, avg loss: 1.3864369440078734\n",
      "trial: 2, iter: 800, curr loss: 1.388535976409912, avg loss: 1.3864614176750183\n",
      "trial: 2, iter: 1000, curr loss: 1.3871378898620605, avg loss: 1.3863894510269166\n",
      "trial: 2, iter: 1200, curr loss: 1.386939287185669, avg loss: 1.386433072090149\n",
      "trial: 2, iter: 1400, curr loss: 1.3852646350860596, avg loss: 1.3864105969667435\n",
      "trial: 2, iter: 1600, curr loss: 1.3862195014953613, avg loss: 1.3864737623929977\n",
      "trial: 2, iter: 1800, curr loss: 1.3864396810531616, avg loss: 1.3863657814264299\n",
      "trial: 2, iter: 2000, curr loss: 1.3865336179733276, avg loss: 1.3863544327020645\n",
      "trial: 2, iter: 2200, curr loss: 1.3866177797317505, avg loss: 1.3862652099132537\n",
      "trial: 2, iter: 2400, curr loss: 1.3853545188903809, avg loss: 1.3863257741928101\n",
      "trial: 2, iter: 2600, curr loss: 1.3859742879867554, avg loss: 1.3863738030195236\n",
      "trial: 2, iter: 2800, curr loss: 1.3862091302871704, avg loss: 1.3863558316230773\n",
      "trial: 2, iter: 3000, curr loss: 1.3867638111114502, avg loss: 1.3863615983724593\n",
      "trial: 2, iter: 3200, curr loss: 1.3864773511886597, avg loss: 1.386310960650444\n",
      "trial: 2, iter: 3400, curr loss: 1.3854293823242188, avg loss: 1.3862826550006866\n",
      "trial: 2, iter: 3600, curr loss: 1.3858330249786377, avg loss: 1.386317697763443\n",
      "trial: 2, iter: 3800, curr loss: 1.3865447044372559, avg loss: 1.3863176226615905\n",
      "trial: 2, iter: 4000, curr loss: 1.3867051601409912, avg loss: 1.386370386481285\n",
      "trial: 2, iter: 4200, curr loss: 1.3863097429275513, avg loss: 1.3863633847236634\n",
      "trial: 2, iter: 4400, curr loss: 1.3863611221313477, avg loss: 1.3863101851940156\n",
      "trial: 2, iter: 4600, curr loss: 1.386118769645691, avg loss: 1.3863364207744597\n",
      "trial: 2, iter: 4800, curr loss: 1.3866206407546997, avg loss: 1.386318883895874\n",
      "trial: 2, iter: 5000, curr loss: 1.386602520942688, avg loss: 1.3863454085588456\n",
      "trial: 2, iter: 5200, curr loss: 1.3856754302978516, avg loss: 1.38636314868927\n",
      "trial: 2, iter: 5400, curr loss: 1.3876765966415405, avg loss: 1.3863236427307128\n",
      "trial: 2, iter: 5600, curr loss: 1.3863548040390015, avg loss: 1.3863833969831467\n",
      "trial: 2, iter: 5800, curr loss: 1.3863917589187622, avg loss: 1.386346925497055\n",
      "trial: 2, iter: 6000, curr loss: 1.3865032196044922, avg loss: 1.3863353216648102\n",
      "trial: 2, iter: 6200, curr loss: 1.38607656955719, avg loss: 1.3863395297527312\n",
      "trial: 2, iter: 6400, curr loss: 1.3854836225509644, avg loss: 1.3862196093797683\n",
      "trial: 2, iter: 6600, curr loss: 1.38739013671875, avg loss: 1.386454519033432\n",
      "trial: 2, iter: 6800, curr loss: 1.3865314722061157, avg loss: 1.3863112282752992\n",
      "trial: 2, iter: 7000, curr loss: 1.3857282400131226, avg loss: 1.386341455578804\n",
      "trial: 2, iter: 7200, curr loss: 1.386223316192627, avg loss: 1.386364694237709\n",
      "trial: 2, iter: 7400, curr loss: 1.3866807222366333, avg loss: 1.3863407337665559\n",
      "trial: 2, iter: 7600, curr loss: 1.385488748550415, avg loss: 1.3863387352228165\n",
      "trial: 2, iter: 7800, curr loss: 1.3859553337097168, avg loss: 1.3863045650720596\n",
      "trial: 2, iter: 8000, curr loss: 1.3869322538375854, avg loss: 1.3863242703676224\n",
      "trial: 2, iter: 8200, curr loss: 1.3868056535720825, avg loss: 1.386324361562729\n",
      "trial: 2, iter: 8400, curr loss: 1.3853952884674072, avg loss: 1.3863090151548385\n",
      "trial: 2, iter: 8600, curr loss: 1.386179804801941, avg loss: 1.3863423883914947\n",
      "trial: 2, iter: 8800, curr loss: 1.3866978883743286, avg loss: 1.3862979322671891\n",
      "trial: 2, iter: 9000, curr loss: 1.3863424062728882, avg loss: 1.386300658583641\n",
      "trial: 2, iter: 9200, curr loss: 1.3864527940750122, avg loss: 1.386329847574234\n",
      "trial: 2, iter: 9400, curr loss: 1.3862805366516113, avg loss: 1.3863066273927689\n",
      "trial: 2, iter: 9600, curr loss: 1.3862543106079102, avg loss: 1.386295943260193\n",
      "trial: 2, iter: 9800, curr loss: 1.385857343673706, avg loss: 1.38629234790802\n",
      "trial: 2, iter: 10000, curr loss: 1.3864673376083374, avg loss: 1.3863026744127274\n",
      "trial: 2, iter: 10200, curr loss: 1.3864374160766602, avg loss: 1.3863409173488617\n",
      "trial: 2, iter: 10400, curr loss: 1.3864094018936157, avg loss: 1.386305969953537\n",
      "trial: 2, iter: 10600, curr loss: 1.3862109184265137, avg loss: 1.3862860536575317\n",
      "trial: 2, iter: 10800, curr loss: 1.3861379623413086, avg loss: 1.3863131153583526\n",
      "trial: 2, iter: 11000, curr loss: 1.385712742805481, avg loss: 1.3863845378160478\n",
      "trial: 2, iter: 11200, curr loss: 1.3860082626342773, avg loss: 1.3863176435232163\n",
      "trial: 2, iter: 11400, curr loss: 1.387017011642456, avg loss: 1.3863105231523514\n",
      "trial: 2, iter: 11600, curr loss: 1.3864425420761108, avg loss: 1.3863109648227692\n",
      "trial: 2, iter: 11800, curr loss: 1.3862344026565552, avg loss: 1.3862935018539428\n",
      "trial: 2, iter: 12000, curr loss: 1.3860563039779663, avg loss: 1.3863057267665864\n",
      "trial: 2, iter: 12200, curr loss: 1.3854540586471558, avg loss: 1.3862769317626953\n",
      "trial: 2, iter: 12400, curr loss: 1.3861620426177979, avg loss: 1.3863284581899642\n",
      "trial: 2, iter: 12600, curr loss: 1.3861098289489746, avg loss: 1.3863049668073655\n",
      "trial: 2, iter: 12800, curr loss: 1.3865466117858887, avg loss: 1.3863089454174042\n",
      "trial: 2, iter: 13000, curr loss: 1.386301040649414, avg loss: 1.3863442021608352\n",
      "trial: 2, iter: 13200, curr loss: 1.386367678642273, avg loss: 1.386329345703125\n",
      "trial: 2, iter: 13400, curr loss: 1.3862872123718262, avg loss: 1.3862985450029373\n",
      "trial: 2, iter: 13600, curr loss: 1.3863277435302734, avg loss: 1.3862979006767273\n",
      "trial: 2, iter: 13800, curr loss: 1.3868911266326904, avg loss: 1.386314572095871\n",
      "trial: 2, iter: 14000, curr loss: 1.3859877586364746, avg loss: 1.3863320606946945\n",
      "trial: 2, iter: 14200, curr loss: 1.3863028287887573, avg loss: 1.3863002198934555\n",
      "trial: 2, iter: 14400, curr loss: 1.386012077331543, avg loss: 1.3862793964147568\n",
      "trial: 2, iter: 14600, curr loss: 1.3862615823745728, avg loss: 1.386383571624756\n",
      "trial: 2, iter: 14800, curr loss: 1.386365294456482, avg loss: 1.38631871342659\n",
      "trial: 2, iter: 15000, curr loss: 1.3870277404785156, avg loss: 1.386294620037079\n",
      "trial: 2, iter: 15200, curr loss: 1.3862510919570923, avg loss: 1.3863009411096572\n",
      "trial: 2, iter: 15400, curr loss: 1.3863468170166016, avg loss: 1.3863066601753236\n",
      "trial: 2, iter: 15600, curr loss: 1.3862780332565308, avg loss: 1.3862967365980148\n",
      "trial: 2, ldr: -1.1492212252051104e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3853602409362793, avg loss: 1.3874914956092834\n",
      "trial: 3, iter: 400, curr loss: 1.3878018856048584, avg loss: 1.3867064023017883\n",
      "trial: 3, iter: 600, curr loss: 1.386116623878479, avg loss: 1.3866450840234756\n",
      "trial: 3, iter: 800, curr loss: 1.386516809463501, avg loss: 1.3864328950643539\n",
      "trial: 3, iter: 1000, curr loss: 1.3859974145889282, avg loss: 1.3864492660760879\n",
      "trial: 3, iter: 1200, curr loss: 1.3870774507522583, avg loss: 1.3864713340997696\n",
      "trial: 3, iter: 1400, curr loss: 1.3870325088500977, avg loss: 1.3864114028215409\n",
      "trial: 3, iter: 1600, curr loss: 1.3865331411361694, avg loss: 1.386366038918495\n",
      "trial: 3, iter: 1800, curr loss: 1.385824203491211, avg loss: 1.3862474554777144\n",
      "trial: 3, iter: 2000, curr loss: 1.3864614963531494, avg loss: 1.386393157839775\n",
      "trial: 3, iter: 2200, curr loss: 1.3859410285949707, avg loss: 1.3864056080579759\n",
      "trial: 3, iter: 2400, curr loss: 1.3855576515197754, avg loss: 1.3863066995143891\n",
      "trial: 3, iter: 2600, curr loss: 1.3867218494415283, avg loss: 1.3863678121566771\n",
      "trial: 3, iter: 2800, curr loss: 1.3858929872512817, avg loss: 1.3863826286792755\n",
      "trial: 3, iter: 3000, curr loss: 1.3863019943237305, avg loss: 1.3863140553236009\n",
      "trial: 3, iter: 3200, curr loss: 1.387956976890564, avg loss: 1.3863401287794113\n",
      "trial: 3, iter: 3400, curr loss: 1.387347936630249, avg loss: 1.386360102891922\n",
      "trial: 3, iter: 3600, curr loss: 1.3862905502319336, avg loss: 1.3863170564174652\n",
      "trial: 3, iter: 3800, curr loss: 1.3849356174468994, avg loss: 1.3863479989767074\n",
      "trial: 3, iter: 4000, curr loss: 1.3867547512054443, avg loss: 1.386337280869484\n",
      "trial: 3, iter: 4200, curr loss: 1.3872418403625488, avg loss: 1.3863305234909058\n",
      "trial: 3, iter: 4400, curr loss: 1.386432409286499, avg loss: 1.3863775354623795\n",
      "trial: 3, iter: 4600, curr loss: 1.3864997625350952, avg loss: 1.3863162457942964\n",
      "trial: 3, iter: 4800, curr loss: 1.3859262466430664, avg loss: 1.3863423514366149\n",
      "trial: 3, iter: 5000, curr loss: 1.3866006135940552, avg loss: 1.386330823302269\n",
      "trial: 3, iter: 5200, curr loss: 1.3871320486068726, avg loss: 1.3863317263126373\n",
      "trial: 3, iter: 5400, curr loss: 1.3866212368011475, avg loss: 1.3863438403606414\n",
      "trial: 3, iter: 5600, curr loss: 1.3863418102264404, avg loss: 1.38632532954216\n",
      "trial: 3, iter: 5800, curr loss: 1.3862360715866089, avg loss: 1.3863627570867538\n",
      "trial: 3, iter: 6000, curr loss: 1.3861618041992188, avg loss: 1.3863109481334686\n",
      "trial: 3, iter: 6200, curr loss: 1.386446237564087, avg loss: 1.3863539326190948\n",
      "trial: 3, iter: 6400, curr loss: 1.3849527835845947, avg loss: 1.3862978506088257\n",
      "trial: 3, iter: 6600, curr loss: 1.387548804283142, avg loss: 1.3862375324964524\n",
      "trial: 3, iter: 6800, curr loss: 1.3860617876052856, avg loss: 1.3863668888807297\n",
      "trial: 3, iter: 7000, curr loss: 1.3862977027893066, avg loss: 1.3863059216737748\n",
      "trial: 3, iter: 7200, curr loss: 1.3869963884353638, avg loss: 1.3862995272874832\n",
      "trial: 3, iter: 7400, curr loss: 1.3858095407485962, avg loss: 1.3864128625392913\n",
      "trial: 3, iter: 7600, curr loss: 1.3862972259521484, avg loss: 1.3863217973709105\n",
      "trial: 3, iter: 7800, curr loss: 1.3889929056167603, avg loss: 1.386261333823204\n",
      "trial: 3, iter: 8000, curr loss: 1.3867841958999634, avg loss: 1.3863340038061143\n",
      "trial: 3, iter: 8200, curr loss: 1.3862029314041138, avg loss: 1.3863181501626969\n",
      "trial: 3, iter: 8400, curr loss: 1.3860965967178345, avg loss: 1.3863316506147385\n",
      "trial: 3, iter: 8600, curr loss: 1.3863612413406372, avg loss: 1.3863551461696624\n",
      "trial: 3, iter: 8800, curr loss: 1.3859591484069824, avg loss: 1.386299033164978\n",
      "trial: 3, iter: 9000, curr loss: 1.3861645460128784, avg loss: 1.386297082901001\n",
      "trial: 3, iter: 9200, curr loss: 1.386167287826538, avg loss: 1.3863179171085358\n",
      "trial: 3, iter: 9400, curr loss: 1.3864268064498901, avg loss: 1.3863292890787124\n",
      "trial: 3, iter: 9600, curr loss: 1.3863924741744995, avg loss: 1.386318336725235\n",
      "trial: 3, iter: 9800, curr loss: 1.3865740299224854, avg loss: 1.3862940227985383\n",
      "trial: 3, iter: 10000, curr loss: 1.38643217086792, avg loss: 1.3863115805387496\n",
      "trial: 3, iter: 10200, curr loss: 1.3863524198532104, avg loss: 1.386307874917984\n",
      "trial: 3, iter: 10400, curr loss: 1.3865025043487549, avg loss: 1.3863041770458222\n",
      "trial: 3, iter: 10600, curr loss: 1.3861188888549805, avg loss: 1.3862871259450913\n",
      "trial: 3, iter: 10800, curr loss: 1.3862653970718384, avg loss: 1.3863301473855971\n",
      "trial: 3, iter: 11000, curr loss: 1.38627028465271, avg loss: 1.3862900984287263\n",
      "trial: 3, iter: 11200, curr loss: 1.3862484693527222, avg loss: 1.3862886428833008\n",
      "trial: 3, iter: 11400, curr loss: 1.3862558603286743, avg loss: 1.386293836236\n",
      "trial: 3, iter: 11600, curr loss: 1.3863036632537842, avg loss: 1.3862900745868683\n",
      "trial: 3, iter: 11800, curr loss: 1.3864034414291382, avg loss: 1.386309134364128\n",
      "trial: 3, iter: 12000, curr loss: 1.3865256309509277, avg loss: 1.3862804192304612\n",
      "trial: 3, iter: 12200, curr loss: 1.3872756958007812, avg loss: 1.3863563960790635\n",
      "trial: 3, iter: 12400, curr loss: 1.3864785432815552, avg loss: 1.386353059411049\n",
      "trial: 3, iter: 12600, curr loss: 1.3868979215621948, avg loss: 1.3863521093130111\n",
      "trial: 3, iter: 12800, curr loss: 1.3864604234695435, avg loss: 1.3863033252954482\n",
      "trial: 3, iter: 13000, curr loss: 1.385720133781433, avg loss: 1.3863497990369797\n",
      "trial: 3, iter: 13200, curr loss: 1.3869528770446777, avg loss: 1.3863718777894973\n",
      "trial: 3, iter: 13400, curr loss: 1.3863284587860107, avg loss: 1.386345100402832\n",
      "trial: 3, iter: 13600, curr loss: 1.3863011598587036, avg loss: 1.386367872953415\n",
      "trial: 3, iter: 13800, curr loss: 1.386193037033081, avg loss: 1.3863186925649642\n",
      "trial: 3, iter: 14000, curr loss: 1.386129379272461, avg loss: 1.3863472712039948\n",
      "trial: 3, iter: 14200, curr loss: 1.3863401412963867, avg loss: 1.3863065397739411\n",
      "trial: 3, iter: 14400, curr loss: 1.3863755464553833, avg loss: 1.3862969028949736\n",
      "trial: 3, iter: 14600, curr loss: 1.3863255977630615, avg loss: 1.3863899207115173\n",
      "trial: 3, iter: 14800, curr loss: 1.3862388134002686, avg loss: 1.3863435280323029\n",
      "trial: 3, iter: 15000, curr loss: 1.3860825300216675, avg loss: 1.3863215196132659\n",
      "trial: 3, iter: 15200, curr loss: 1.3864061832427979, avg loss: 1.386268515586853\n",
      "trial: 3, iter: 15400, curr loss: 1.3864402770996094, avg loss: 1.3863075739145279\n",
      "trial: 3, iter: 15600, curr loss: 1.3865952491760254, avg loss: 1.386320602297783\n",
      "trial: 3, ldr: -0.0005706914234906435\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3871541023254395, avg loss: 1.3870622938871384\n",
      "trial: 4, iter: 400, curr loss: 1.386650562286377, avg loss: 1.3868682515621185\n",
      "trial: 4, iter: 600, curr loss: 1.384342908859253, avg loss: 1.3866969507932663\n",
      "trial: 4, iter: 800, curr loss: 1.3867592811584473, avg loss: 1.3864892715215682\n",
      "trial: 4, iter: 1000, curr loss: 1.3878487348556519, avg loss: 1.3864682447910308\n",
      "trial: 4, iter: 1200, curr loss: 1.386242151260376, avg loss: 1.3864942735433579\n",
      "trial: 4, iter: 1400, curr loss: 1.388070821762085, avg loss: 1.3863590586185455\n",
      "trial: 4, iter: 1600, curr loss: 1.385740041732788, avg loss: 1.3865347284078597\n",
      "trial: 4, iter: 1800, curr loss: 1.3876280784606934, avg loss: 1.3863522380590438\n",
      "trial: 4, iter: 2000, curr loss: 1.3863813877105713, avg loss: 1.3863915926218033\n",
      "trial: 4, iter: 2200, curr loss: 1.3870763778686523, avg loss: 1.3863395661115647\n",
      "trial: 4, iter: 2400, curr loss: 1.3863329887390137, avg loss: 1.3863447409868241\n",
      "trial: 4, iter: 2600, curr loss: 1.3866968154907227, avg loss: 1.3863247901201248\n",
      "trial: 4, iter: 2800, curr loss: 1.3860013484954834, avg loss: 1.3862992125749587\n",
      "trial: 4, iter: 3000, curr loss: 1.3864718675613403, avg loss: 1.386390226483345\n",
      "trial: 4, iter: 3200, curr loss: 1.3865666389465332, avg loss: 1.3863364243507386\n",
      "trial: 4, iter: 3400, curr loss: 1.3859323263168335, avg loss: 1.3863234585523605\n",
      "trial: 4, iter: 3600, curr loss: 1.3860658407211304, avg loss: 1.3863991069793702\n",
      "trial: 4, iter: 3800, curr loss: 1.386152982711792, avg loss: 1.3863407135009767\n",
      "trial: 4, iter: 4000, curr loss: 1.3855043649673462, avg loss: 1.3863328057527542\n",
      "trial: 4, iter: 4200, curr loss: 1.3863751888275146, avg loss: 1.3862955820560456\n",
      "trial: 4, iter: 4400, curr loss: 1.386519432067871, avg loss: 1.3863321655988694\n",
      "trial: 4, iter: 4600, curr loss: 1.3867943286895752, avg loss: 1.38635577917099\n",
      "trial: 4, iter: 4800, curr loss: 1.3863812685012817, avg loss: 1.3863004755973816\n",
      "trial: 4, iter: 5000, curr loss: 1.386641502380371, avg loss: 1.3863357180356979\n",
      "trial: 4, iter: 5200, curr loss: 1.386425495147705, avg loss: 1.386312222480774\n",
      "trial: 4, iter: 5400, curr loss: 1.3850244283676147, avg loss: 1.386329271197319\n",
      "trial: 4, iter: 5600, curr loss: 1.386780858039856, avg loss: 1.3862819182872772\n",
      "trial: 4, iter: 5800, curr loss: 1.3855758905410767, avg loss: 1.3863153868913651\n",
      "trial: 4, iter: 6000, curr loss: 1.3860597610473633, avg loss: 1.3863551723957062\n",
      "trial: 4, iter: 6200, curr loss: 1.3856518268585205, avg loss: 1.3864004975557327\n",
      "trial: 4, iter: 6400, curr loss: 1.386655330657959, avg loss: 1.386387050151825\n",
      "trial: 4, iter: 6600, curr loss: 1.3867343664169312, avg loss: 1.3863360738754273\n",
      "trial: 4, iter: 6800, curr loss: 1.3862674236297607, avg loss: 1.3863456046581268\n",
      "trial: 4, iter: 7000, curr loss: 1.3857501745224, avg loss: 1.3862965124845505\n",
      "trial: 4, iter: 7200, curr loss: 1.3866682052612305, avg loss: 1.3864434170722961\n",
      "trial: 4, iter: 7400, curr loss: 1.385791301727295, avg loss: 1.3863131713867187\n",
      "trial: 4, iter: 7600, curr loss: 1.3866522312164307, avg loss: 1.3863350850343705\n",
      "trial: 4, iter: 7800, curr loss: 1.3863770961761475, avg loss: 1.3863032495975494\n",
      "trial: 4, iter: 8000, curr loss: 1.3862828016281128, avg loss: 1.3863031393289567\n",
      "trial: 4, iter: 8200, curr loss: 1.3864058256149292, avg loss: 1.3863073199987412\n",
      "trial: 4, iter: 8400, curr loss: 1.386232614517212, avg loss: 1.3863030207157134\n",
      "trial: 4, iter: 8600, curr loss: 1.3859745264053345, avg loss: 1.3862710636854172\n",
      "trial: 4, iter: 8800, curr loss: 1.3863946199417114, avg loss: 1.3862774556875228\n",
      "trial: 4, iter: 9000, curr loss: 1.3864623308181763, avg loss: 1.3863453632593155\n",
      "trial: 4, iter: 9200, curr loss: 1.3860231637954712, avg loss: 1.3862857437133789\n",
      "trial: 4, iter: 9400, curr loss: 1.3862011432647705, avg loss: 1.3863154810667038\n",
      "trial: 4, iter: 9600, curr loss: 1.3862221240997314, avg loss: 1.3863112723827362\n",
      "trial: 4, iter: 9800, curr loss: 1.386380910873413, avg loss: 1.3862932926416398\n",
      "trial: 4, iter: 10000, curr loss: 1.386240005493164, avg loss: 1.3863142889738083\n",
      "trial: 4, iter: 10200, curr loss: 1.3869571685791016, avg loss: 1.3863209235668181\n",
      "trial: 4, iter: 10400, curr loss: 1.386679768562317, avg loss: 1.3863250780105592\n",
      "trial: 4, iter: 10600, curr loss: 1.3863691091537476, avg loss: 1.3863356906175612\n",
      "trial: 4, iter: 10800, curr loss: 1.3862988948822021, avg loss: 1.3863163024187088\n",
      "trial: 4, iter: 11000, curr loss: 1.386260986328125, avg loss: 1.3863132697343827\n",
      "trial: 4, iter: 11200, curr loss: 1.3861316442489624, avg loss: 1.3863085359334946\n",
      "trial: 4, iter: 11400, curr loss: 1.3860225677490234, avg loss: 1.3862686616182327\n",
      "trial: 4, iter: 11600, curr loss: 1.386042833328247, avg loss: 1.3862980550527573\n",
      "trial: 4, iter: 11800, curr loss: 1.3864401578903198, avg loss: 1.3863015884160996\n",
      "trial: 4, iter: 12000, curr loss: 1.386369228363037, avg loss: 1.3863033413887025\n",
      "trial: 4, iter: 12200, curr loss: 1.3863105773925781, avg loss: 1.386306237578392\n",
      "trial: 4, iter: 12400, curr loss: 1.386143684387207, avg loss: 1.3863003873825073\n",
      "trial: 4, iter: 12600, curr loss: 1.3861414194107056, avg loss: 1.386297595500946\n",
      "trial: 4, iter: 12800, curr loss: 1.386303186416626, avg loss: 1.3862938141822816\n",
      "trial: 4, iter: 13000, curr loss: 1.3863497972488403, avg loss: 1.3863065230846405\n",
      "trial: 4, iter: 13200, curr loss: 1.3865886926651, avg loss: 1.3863029503822326\n",
      "trial: 4, iter: 13400, curr loss: 1.3863712549209595, avg loss: 1.3863285756111146\n",
      "trial: 4, iter: 13600, curr loss: 1.3861440420150757, avg loss: 1.3863157123327254\n",
      "trial: 4, iter: 13800, curr loss: 1.3862632513046265, avg loss: 1.3863100188970565\n",
      "trial: 4, iter: 14000, curr loss: 1.386268973350525, avg loss: 1.3862846684455872\n",
      "trial: 4, iter: 14200, curr loss: 1.3866934776306152, avg loss: 1.3863148003816606\n",
      "trial: 4, iter: 14400, curr loss: 1.3865944147109985, avg loss: 1.386338431239128\n",
      "trial: 4, iter: 14600, curr loss: 1.3866934776306152, avg loss: 1.3862736964225768\n",
      "trial: 4, iter: 14800, curr loss: 1.3862848281860352, avg loss: 1.3863146525621415\n",
      "trial: 4, iter: 15000, curr loss: 1.3865623474121094, avg loss: 1.386288423538208\n",
      "trial: 4, iter: 15200, curr loss: 1.3865476846694946, avg loss: 1.3863097006082534\n",
      "trial: 4, iter: 15400, curr loss: 1.3865867853164673, avg loss: 1.3863070982694625\n",
      "trial: 4, iter: 15600, curr loss: 1.386098027229309, avg loss: 1.386284090280533\n",
      "trial: 4, ldr: -0.000778289744630456\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3861539363861084, avg loss: 1.3872405701875687\n",
      "trial: 5, iter: 400, curr loss: 1.3868333101272583, avg loss: 1.386872091293335\n",
      "trial: 5, iter: 600, curr loss: 1.3849159479141235, avg loss: 1.38648461997509\n",
      "trial: 5, iter: 800, curr loss: 1.3887940645217896, avg loss: 1.386537988781929\n",
      "trial: 5, iter: 1000, curr loss: 1.3844027519226074, avg loss: 1.3863022720813751\n",
      "trial: 5, iter: 1200, curr loss: 1.3862320184707642, avg loss: 1.386500932574272\n",
      "trial: 5, iter: 1400, curr loss: 1.3850830793380737, avg loss: 1.3865385460853576\n",
      "trial: 5, iter: 1600, curr loss: 1.3880387544631958, avg loss: 1.386357032060623\n",
      "trial: 5, iter: 1800, curr loss: 1.3865580558776855, avg loss: 1.3863393539190292\n",
      "trial: 5, iter: 2000, curr loss: 1.385838508605957, avg loss: 1.386349131464958\n",
      "trial: 5, iter: 2200, curr loss: 1.386476993560791, avg loss: 1.386377723813057\n",
      "trial: 5, iter: 2400, curr loss: 1.3860197067260742, avg loss: 1.3863579738140106\n",
      "trial: 5, iter: 2600, curr loss: 1.386061429977417, avg loss: 1.3863103419542313\n",
      "trial: 5, iter: 2800, curr loss: 1.3875725269317627, avg loss: 1.3863476222753526\n",
      "trial: 5, iter: 3000, curr loss: 1.3862749338150024, avg loss: 1.3863482290506364\n",
      "trial: 5, iter: 3200, curr loss: 1.3871546983718872, avg loss: 1.3863195312023162\n",
      "trial: 5, iter: 3400, curr loss: 1.3866052627563477, avg loss: 1.3863669019937515\n",
      "trial: 5, iter: 3600, curr loss: 1.3864121437072754, avg loss: 1.3863363301753997\n",
      "trial: 5, iter: 3800, curr loss: 1.386376976966858, avg loss: 1.3863148909807206\n",
      "trial: 5, iter: 4000, curr loss: 1.386649489402771, avg loss: 1.3863077360391616\n",
      "trial: 5, iter: 4200, curr loss: 1.3860702514648438, avg loss: 1.3863268214464188\n",
      "trial: 5, iter: 4400, curr loss: 1.386199951171875, avg loss: 1.3862891644239426\n",
      "trial: 5, iter: 4600, curr loss: 1.3864725828170776, avg loss: 1.3863103806972503\n",
      "trial: 5, iter: 4800, curr loss: 1.3871082067489624, avg loss: 1.3863069289922714\n",
      "trial: 5, iter: 5000, curr loss: 1.3859584331512451, avg loss: 1.386340924501419\n",
      "trial: 5, iter: 5200, curr loss: 1.386603593826294, avg loss: 1.386330783367157\n",
      "trial: 5, iter: 5400, curr loss: 1.386179804801941, avg loss: 1.3862875187397004\n",
      "trial: 5, iter: 5600, curr loss: 1.3860491514205933, avg loss: 1.386376411318779\n",
      "trial: 5, iter: 5800, curr loss: 1.3861985206604004, avg loss: 1.3863147407770158\n",
      "trial: 5, iter: 6000, curr loss: 1.38681960105896, avg loss: 1.3863189488649368\n",
      "trial: 5, iter: 6200, curr loss: 1.386263132095337, avg loss: 1.3863087093830109\n",
      "trial: 5, iter: 6400, curr loss: 1.3862777948379517, avg loss: 1.3862962865829467\n",
      "trial: 5, iter: 6600, curr loss: 1.3859351873397827, avg loss: 1.3863337069749833\n",
      "trial: 5, iter: 6800, curr loss: 1.3875256776809692, avg loss: 1.3863351517915725\n",
      "trial: 5, iter: 7000, curr loss: 1.3868128061294556, avg loss: 1.3862823420763015\n",
      "trial: 5, iter: 7200, curr loss: 1.3860479593276978, avg loss: 1.386412768959999\n",
      "trial: 5, iter: 7400, curr loss: 1.3868016004562378, avg loss: 1.3863517105579377\n",
      "trial: 5, iter: 7600, curr loss: 1.386461615562439, avg loss: 1.3863302212953568\n",
      "trial: 5, iter: 7800, curr loss: 1.386023759841919, avg loss: 1.3863308584690095\n",
      "trial: 5, iter: 8000, curr loss: 1.3864630460739136, avg loss: 1.3863156867027282\n",
      "trial: 5, iter: 8200, curr loss: 1.3865042924880981, avg loss: 1.3862954622507095\n",
      "trial: 5, iter: 8400, curr loss: 1.3860259056091309, avg loss: 1.3863080275058746\n",
      "trial: 5, iter: 8600, curr loss: 1.386509656906128, avg loss: 1.386305393576622\n",
      "trial: 5, iter: 8800, curr loss: 1.3866790533065796, avg loss: 1.386296039223671\n",
      "trial: 5, iter: 9000, curr loss: 1.3860737085342407, avg loss: 1.3863291096687318\n",
      "trial: 5, iter: 9200, curr loss: 1.386199712753296, avg loss: 1.3862990546226501\n",
      "trial: 5, iter: 9400, curr loss: 1.386225700378418, avg loss: 1.3863024699687958\n",
      "trial: 5, iter: 9600, curr loss: 1.3864152431488037, avg loss: 1.386287708878517\n",
      "trial: 5, iter: 9800, curr loss: 1.385601282119751, avg loss: 1.3862836897373199\n",
      "trial: 5, iter: 10000, curr loss: 1.386376142501831, avg loss: 1.3863174325227738\n",
      "trial: 5, iter: 10200, curr loss: 1.38631010055542, avg loss: 1.3863219761848449\n",
      "trial: 5, iter: 10400, curr loss: 1.3862301111221313, avg loss: 1.3863136839866639\n",
      "trial: 5, iter: 10600, curr loss: 1.3863084316253662, avg loss: 1.3862946528196334\n",
      "trial: 5, iter: 10800, curr loss: 1.38641357421875, avg loss: 1.3862952548265457\n",
      "trial: 5, iter: 11000, curr loss: 1.3862842321395874, avg loss: 1.3863048678636551\n",
      "trial: 5, iter: 11200, curr loss: 1.386300802230835, avg loss: 1.3862934988737106\n",
      "trial: 5, iter: 11400, curr loss: 1.3863097429275513, avg loss: 1.3862965577840805\n",
      "trial: 5, iter: 11600, curr loss: 1.3862944841384888, avg loss: 1.3862942457199097\n",
      "trial: 5, iter: 11800, curr loss: 1.3862941265106201, avg loss: 1.386294292807579\n",
      "trial: 5, iter: 12000, curr loss: 1.3862968683242798, avg loss: 1.386294088959694\n",
      "trial: 5, iter: 12200, curr loss: 1.3863062858581543, avg loss: 1.3862940347194672\n",
      "trial: 5, iter: 12400, curr loss: 1.3862934112548828, avg loss: 1.3862976950407029\n",
      "trial: 5, iter: 12600, curr loss: 1.3864597082138062, avg loss: 1.3863858771324158\n",
      "trial: 5, iter: 12800, curr loss: 1.3863471746444702, avg loss: 1.3863562232255935\n",
      "trial: 5, iter: 13000, curr loss: 1.3862439393997192, avg loss: 1.3863181853294373\n",
      "trial: 5, iter: 13200, curr loss: 1.3859468698501587, avg loss: 1.3863121712207793\n",
      "trial: 5, iter: 13400, curr loss: 1.3861616849899292, avg loss: 1.3863145434856414\n",
      "trial: 5, iter: 13600, curr loss: 1.386173963546753, avg loss: 1.3863050335645675\n",
      "trial: 5, iter: 13800, curr loss: 1.385440707206726, avg loss: 1.3862804597616196\n",
      "trial: 5, iter: 14000, curr loss: 1.3865177631378174, avg loss: 1.3863536071777345\n",
      "trial: 5, iter: 14200, curr loss: 1.3863391876220703, avg loss: 1.3863318288326263\n",
      "trial: 5, iter: 14400, curr loss: 1.386216640472412, avg loss: 1.3862992906570435\n",
      "trial: 5, iter: 14600, curr loss: 1.3863840103149414, avg loss: 1.3863014113903045\n",
      "trial: 5, iter: 14800, curr loss: 1.3865963220596313, avg loss: 1.3863014715909958\n",
      "trial: 5, iter: 15000, curr loss: 1.3866474628448486, avg loss: 1.3862863224744797\n",
      "trial: 5, iter: 15200, curr loss: 1.3866641521453857, avg loss: 1.3863170057535172\n",
      "trial: 5, iter: 15400, curr loss: 1.38590669631958, avg loss: 1.3862820452451705\n",
      "trial: 5, iter: 15600, curr loss: 1.3864192962646484, avg loss: 1.3863184607028962\n",
      "trial: 5, ldr: 0.00045781058724969625\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00018016904616615647\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3854202032089233, avg loss: 1.387538496851921\n",
      "trial: 1, iter: 400, curr loss: 1.3869407176971436, avg loss: 1.386777669787407\n",
      "trial: 1, iter: 600, curr loss: 1.3854644298553467, avg loss: 1.3867058742046356\n",
      "trial: 1, iter: 800, curr loss: 1.3865525722503662, avg loss: 1.386458268761635\n",
      "trial: 1, iter: 1000, curr loss: 1.388665795326233, avg loss: 1.3864263224601745\n",
      "trial: 1, iter: 1200, curr loss: 1.3872171640396118, avg loss: 1.386406797170639\n",
      "trial: 1, iter: 1400, curr loss: 1.3868765830993652, avg loss: 1.3864071297645568\n",
      "trial: 1, iter: 1600, curr loss: 1.3852683305740356, avg loss: 1.3863615423440934\n",
      "trial: 1, iter: 1800, curr loss: 1.3866578340530396, avg loss: 1.3863382744789123\n",
      "trial: 1, iter: 2000, curr loss: 1.3849364519119263, avg loss: 1.3862916076183318\n",
      "trial: 1, iter: 2200, curr loss: 1.3871047496795654, avg loss: 1.386349225640297\n",
      "trial: 1, iter: 2400, curr loss: 1.3868498802185059, avg loss: 1.3864503794908523\n",
      "trial: 1, iter: 2600, curr loss: 1.38642418384552, avg loss: 1.3862947034835815\n",
      "trial: 1, iter: 2800, curr loss: 1.386044979095459, avg loss: 1.3863401585817337\n",
      "trial: 1, iter: 3000, curr loss: 1.3861368894577026, avg loss: 1.386365168094635\n",
      "trial: 1, iter: 3200, curr loss: 1.386009931564331, avg loss: 1.3863510978221893\n",
      "trial: 1, iter: 3400, curr loss: 1.3843693733215332, avg loss: 1.3862460750341414\n",
      "trial: 1, iter: 3600, curr loss: 1.3871946334838867, avg loss: 1.386379550099373\n",
      "trial: 1, iter: 3800, curr loss: 1.38776433467865, avg loss: 1.386347845196724\n",
      "trial: 1, iter: 4000, curr loss: 1.3864424228668213, avg loss: 1.3863666170835496\n",
      "trial: 1, iter: 4200, curr loss: 1.386261224746704, avg loss: 1.3863131165504456\n",
      "trial: 1, iter: 4400, curr loss: 1.3866745233535767, avg loss: 1.3863345026969909\n",
      "trial: 1, iter: 4600, curr loss: 1.3868435621261597, avg loss: 1.3863339447975158\n",
      "trial: 1, iter: 4800, curr loss: 1.3865026235580444, avg loss: 1.386303185224533\n",
      "trial: 1, iter: 5000, curr loss: 1.3861044645309448, avg loss: 1.386309345960617\n",
      "trial: 1, iter: 5200, curr loss: 1.3858342170715332, avg loss: 1.3862862437963486\n",
      "trial: 1, iter: 5400, curr loss: 1.3863780498504639, avg loss: 1.3863191783428193\n",
      "trial: 1, iter: 5600, curr loss: 1.3861736059188843, avg loss: 1.386391972899437\n",
      "trial: 1, iter: 5800, curr loss: 1.3865327835083008, avg loss: 1.3863227117061614\n",
      "trial: 1, iter: 6000, curr loss: 1.3864561319351196, avg loss: 1.3863407123088836\n",
      "trial: 1, iter: 6200, curr loss: 1.3860385417938232, avg loss: 1.3862988120317459\n",
      "trial: 1, iter: 6400, curr loss: 1.386569857597351, avg loss: 1.3863017523288728\n",
      "trial: 1, iter: 6600, curr loss: 1.3855005502700806, avg loss: 1.3863368529081344\n",
      "trial: 1, iter: 6800, curr loss: 1.3863346576690674, avg loss: 1.3863717687129975\n",
      "trial: 1, iter: 7000, curr loss: 1.3864778280258179, avg loss: 1.3862871783971786\n",
      "trial: 1, iter: 7200, curr loss: 1.3862919807434082, avg loss: 1.3863512617349625\n",
      "trial: 1, iter: 7400, curr loss: 1.3857580423355103, avg loss: 1.3863166242837905\n",
      "trial: 1, iter: 7600, curr loss: 1.386399269104004, avg loss: 1.3863189512491225\n",
      "trial: 1, iter: 7800, curr loss: 1.3864086866378784, avg loss: 1.3863422393798828\n",
      "trial: 1, iter: 8000, curr loss: 1.3863859176635742, avg loss: 1.386313356757164\n",
      "trial: 1, iter: 8200, curr loss: 1.386379599571228, avg loss: 1.3862944698333741\n",
      "trial: 1, iter: 8400, curr loss: 1.3863152265548706, avg loss: 1.3863075804710387\n",
      "trial: 1, iter: 8600, curr loss: 1.3866660594940186, avg loss: 1.3862977725267411\n",
      "trial: 1, iter: 8800, curr loss: 1.3850711584091187, avg loss: 1.3863047009706497\n",
      "trial: 1, iter: 9000, curr loss: 1.3869640827178955, avg loss: 1.38635072350502\n",
      "trial: 1, iter: 9200, curr loss: 1.3862290382385254, avg loss: 1.386331872344017\n",
      "trial: 1, iter: 9400, curr loss: 1.386240839958191, avg loss: 1.3863035506010055\n",
      "trial: 1, iter: 9600, curr loss: 1.3862437009811401, avg loss: 1.386293452978134\n",
      "trial: 1, iter: 9800, curr loss: 1.3864444494247437, avg loss: 1.386309665441513\n",
      "trial: 1, iter: 10000, curr loss: 1.3861273527145386, avg loss: 1.3862928754091264\n",
      "trial: 1, iter: 10200, curr loss: 1.3863080739974976, avg loss: 1.3862999778985978\n",
      "trial: 1, iter: 10400, curr loss: 1.386234164237976, avg loss: 1.3863029652833938\n",
      "trial: 1, iter: 10600, curr loss: 1.386407494544983, avg loss: 1.3863011223077775\n",
      "trial: 1, iter: 10800, curr loss: 1.3863310813903809, avg loss: 1.3863060247898102\n",
      "trial: 1, iter: 11000, curr loss: 1.386185646057129, avg loss: 1.3862951117753983\n",
      "trial: 1, iter: 11200, curr loss: 1.3862699270248413, avg loss: 1.3863048714399338\n",
      "trial: 1, iter: 11400, curr loss: 1.386397361755371, avg loss: 1.386288930773735\n",
      "trial: 1, iter: 11600, curr loss: 1.3862437009811401, avg loss: 1.3863075870275496\n",
      "trial: 1, iter: 11800, curr loss: 1.3863636255264282, avg loss: 1.3863017851114272\n",
      "trial: 1, iter: 12000, curr loss: 1.3863391876220703, avg loss: 1.3862984371185303\n",
      "trial: 1, iter: 12200, curr loss: 1.3862744569778442, avg loss: 1.3862917983531953\n",
      "trial: 1, iter: 12400, curr loss: 1.3862062692642212, avg loss: 1.3862925297021866\n",
      "trial: 1, iter: 12600, curr loss: 1.3862448930740356, avg loss: 1.386306414604187\n",
      "trial: 1, iter: 12800, curr loss: 1.3861268758773804, avg loss: 1.3862956136465072\n",
      "trial: 1, iter: 13000, curr loss: 1.386296033859253, avg loss: 1.3863032245635987\n",
      "trial: 1, iter: 13200, curr loss: 1.385598063468933, avg loss: 1.3863404262065888\n",
      "trial: 1, iter: 13400, curr loss: 1.3852906227111816, avg loss: 1.3863296604156494\n",
      "trial: 1, iter: 13600, curr loss: 1.3874973058700562, avg loss: 1.3864406687021256\n",
      "trial: 1, iter: 13800, curr loss: 1.3860512971878052, avg loss: 1.3863485431671143\n",
      "trial: 1, iter: 14000, curr loss: 1.386107325553894, avg loss: 1.3863340091705323\n",
      "trial: 1, iter: 14200, curr loss: 1.3863366842269897, avg loss: 1.3863200455904008\n",
      "trial: 1, iter: 14400, curr loss: 1.386283040046692, avg loss: 1.3863063871860504\n",
      "trial: 1, iter: 14600, curr loss: 1.3862415552139282, avg loss: 1.3863032621145248\n",
      "trial: 1, iter: 14800, curr loss: 1.3863341808319092, avg loss: 1.3862975811958314\n",
      "trial: 1, iter: 15000, curr loss: 1.3859362602233887, avg loss: 1.3862921732664109\n",
      "trial: 1, iter: 15200, curr loss: 1.386529564857483, avg loss: 1.3863095301389694\n",
      "trial: 1, iter: 15400, curr loss: 1.3864009380340576, avg loss: 1.3863017398118973\n",
      "trial: 1, iter: 15600, curr loss: 1.3863856792449951, avg loss: 1.386332716345787\n",
      "trial: 1, ldr: -0.001950491452589631\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.389235258102417, avg loss: 1.3872848618030549\n",
      "trial: 2, iter: 400, curr loss: 1.3853498697280884, avg loss: 1.3868543326854705\n",
      "trial: 2, iter: 600, curr loss: 1.3868275880813599, avg loss: 1.386490023136139\n",
      "trial: 2, iter: 800, curr loss: 1.3877538442611694, avg loss: 1.386489251255989\n",
      "trial: 2, iter: 1000, curr loss: 1.385033369064331, avg loss: 1.386381688117981\n",
      "trial: 2, iter: 1200, curr loss: 1.3848376274108887, avg loss: 1.3864478248357772\n",
      "trial: 2, iter: 1400, curr loss: 1.3856008052825928, avg loss: 1.3864283108711242\n",
      "trial: 2, iter: 1600, curr loss: 1.3876973390579224, avg loss: 1.3863470888137817\n",
      "trial: 2, iter: 1800, curr loss: 1.3875770568847656, avg loss: 1.386408417224884\n",
      "trial: 2, iter: 2000, curr loss: 1.3863310813903809, avg loss: 1.386310471892357\n",
      "trial: 2, iter: 2200, curr loss: 1.3862038850784302, avg loss: 1.3863132059574128\n",
      "trial: 2, iter: 2400, curr loss: 1.3874667882919312, avg loss: 1.3863390707969665\n",
      "trial: 2, iter: 2600, curr loss: 1.3863801956176758, avg loss: 1.3863359653949738\n",
      "trial: 2, iter: 2800, curr loss: 1.3858773708343506, avg loss: 1.3863416385650635\n",
      "trial: 2, iter: 3000, curr loss: 1.386866807937622, avg loss: 1.3863704961538315\n",
      "trial: 2, iter: 3200, curr loss: 1.3864701986312866, avg loss: 1.386358261704445\n",
      "trial: 2, iter: 3400, curr loss: 1.3863294124603271, avg loss: 1.3863010942935943\n",
      "trial: 2, iter: 3600, curr loss: 1.3864448070526123, avg loss: 1.3863850516080856\n",
      "trial: 2, iter: 3800, curr loss: 1.3853092193603516, avg loss: 1.386290738582611\n",
      "trial: 2, iter: 4000, curr loss: 1.3870264291763306, avg loss: 1.386304846405983\n",
      "trial: 2, iter: 4200, curr loss: 1.3860200643539429, avg loss: 1.3863334184885026\n",
      "trial: 2, iter: 4400, curr loss: 1.3863953351974487, avg loss: 1.3863190549612046\n",
      "trial: 2, iter: 4600, curr loss: 1.3863388299942017, avg loss: 1.3863482069969177\n",
      "trial: 2, iter: 4800, curr loss: 1.3870636224746704, avg loss: 1.3863232934474945\n",
      "trial: 2, iter: 5000, curr loss: 1.3885575532913208, avg loss: 1.3863373184204102\n",
      "trial: 2, iter: 5200, curr loss: 1.3866593837738037, avg loss: 1.3864137268066405\n",
      "trial: 2, iter: 5400, curr loss: 1.3868759870529175, avg loss: 1.3862889206409454\n",
      "trial: 2, iter: 5600, curr loss: 1.3857417106628418, avg loss: 1.3863902753591537\n",
      "trial: 2, iter: 5800, curr loss: 1.3855055570602417, avg loss: 1.386328985095024\n",
      "trial: 2, iter: 6000, curr loss: 1.386246919631958, avg loss: 1.3863246166706085\n",
      "trial: 2, iter: 6200, curr loss: 1.3860632181167603, avg loss: 1.3863569569587708\n",
      "trial: 2, iter: 6400, curr loss: 1.385240077972412, avg loss: 1.3862838917970657\n",
      "trial: 2, iter: 6600, curr loss: 1.3874284029006958, avg loss: 1.386361911892891\n",
      "trial: 2, iter: 6800, curr loss: 1.3854900598526, avg loss: 1.3862919038534165\n",
      "trial: 2, iter: 7000, curr loss: 1.3859957456588745, avg loss: 1.3863132065534591\n",
      "trial: 2, iter: 7200, curr loss: 1.3859635591506958, avg loss: 1.3863045513629912\n",
      "trial: 2, iter: 7400, curr loss: 1.385123372077942, avg loss: 1.3863271981477738\n",
      "trial: 2, iter: 7600, curr loss: 1.3863242864608765, avg loss: 1.3863343465328217\n",
      "trial: 2, iter: 7800, curr loss: 1.3865091800689697, avg loss: 1.3863384991884231\n",
      "trial: 2, iter: 8000, curr loss: 1.3867863416671753, avg loss: 1.3862980300188064\n",
      "trial: 2, iter: 8200, curr loss: 1.3867802619934082, avg loss: 1.386280627846718\n",
      "trial: 2, iter: 8400, curr loss: 1.3866833448410034, avg loss: 1.3863303554058075\n",
      "trial: 2, iter: 8600, curr loss: 1.3866024017333984, avg loss: 1.3863483780622483\n",
      "trial: 2, iter: 8800, curr loss: 1.3863377571105957, avg loss: 1.3862997418642045\n",
      "trial: 2, iter: 9000, curr loss: 1.38564133644104, avg loss: 1.3862530994415283\n",
      "trial: 2, iter: 9200, curr loss: 1.3864387273788452, avg loss: 1.3862728363275527\n",
      "trial: 2, iter: 9400, curr loss: 1.3869266510009766, avg loss: 1.3863547432422638\n",
      "trial: 2, iter: 9600, curr loss: 1.3861303329467773, avg loss: 1.3863576364517212\n",
      "trial: 2, iter: 9800, curr loss: 1.3859888315200806, avg loss: 1.3863343071937562\n",
      "trial: 2, iter: 10000, curr loss: 1.3865437507629395, avg loss: 1.3863286530971528\n",
      "trial: 2, iter: 10200, curr loss: 1.3867619037628174, avg loss: 1.3863048374652862\n",
      "trial: 2, iter: 10400, curr loss: 1.3859083652496338, avg loss: 1.3863107270002366\n",
      "trial: 2, iter: 10600, curr loss: 1.3869614601135254, avg loss: 1.3862992417812348\n",
      "trial: 2, iter: 10800, curr loss: 1.3862241506576538, avg loss: 1.3863257956504822\n",
      "trial: 2, iter: 11000, curr loss: 1.3863197565078735, avg loss: 1.3862746530771255\n",
      "trial: 2, iter: 11200, curr loss: 1.386484980583191, avg loss: 1.3862999004125596\n",
      "trial: 2, iter: 11400, curr loss: 1.386165738105774, avg loss: 1.3863165509700774\n",
      "trial: 2, iter: 11600, curr loss: 1.3863952159881592, avg loss: 1.3863283437490463\n",
      "trial: 2, iter: 11800, curr loss: 1.3858928680419922, avg loss: 1.386359430551529\n",
      "trial: 2, iter: 12000, curr loss: 1.3857567310333252, avg loss: 1.38623636841774\n",
      "trial: 2, iter: 12200, curr loss: 1.386345624923706, avg loss: 1.386342597603798\n",
      "trial: 2, iter: 12400, curr loss: 1.386730432510376, avg loss: 1.386331946849823\n",
      "trial: 2, iter: 12600, curr loss: 1.385897159576416, avg loss: 1.3863139653205871\n",
      "trial: 2, iter: 12800, curr loss: 1.386397361755371, avg loss: 1.386300340294838\n",
      "trial: 2, iter: 13000, curr loss: 1.3866288661956787, avg loss: 1.386278755068779\n",
      "trial: 2, iter: 13200, curr loss: 1.3864502906799316, avg loss: 1.3863107961416246\n",
      "trial: 2, iter: 13400, curr loss: 1.3864333629608154, avg loss: 1.3862986940145492\n",
      "trial: 2, iter: 13600, curr loss: 1.3859065771102905, avg loss: 1.3862780702114106\n",
      "trial: 2, iter: 13800, curr loss: 1.3863614797592163, avg loss: 1.3863059848546981\n",
      "trial: 2, iter: 14000, curr loss: 1.385961651802063, avg loss: 1.3863097417354584\n",
      "trial: 2, iter: 14200, curr loss: 1.3863279819488525, avg loss: 1.3862967842817306\n",
      "trial: 2, iter: 14400, curr loss: 1.3864738941192627, avg loss: 1.3863842940330506\n",
      "trial: 2, iter: 14600, curr loss: 1.3866174221038818, avg loss: 1.386345036625862\n",
      "trial: 2, iter: 14800, curr loss: 1.385952353477478, avg loss: 1.3863064867258073\n",
      "trial: 2, iter: 15000, curr loss: 1.3859387636184692, avg loss: 1.3862858510017395\n",
      "trial: 2, iter: 15200, curr loss: 1.3864076137542725, avg loss: 1.3863186091184616\n",
      "trial: 2, iter: 15400, curr loss: 1.3862533569335938, avg loss: 1.3863007950782775\n",
      "trial: 2, iter: 15600, curr loss: 1.38629949092865, avg loss: 1.3863056498765944\n",
      "trial: 2, ldr: 0.0016119638457894325\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3856408596038818, avg loss: 1.3875601667165756\n",
      "trial: 3, iter: 400, curr loss: 1.3867002725601196, avg loss: 1.3867095613479614\n",
      "trial: 3, iter: 600, curr loss: 1.3901625871658325, avg loss: 1.3868906289339065\n",
      "trial: 3, iter: 800, curr loss: 1.3850387334823608, avg loss: 1.3865464210510254\n",
      "trial: 3, iter: 1000, curr loss: 1.384888768196106, avg loss: 1.3863336837291718\n",
      "trial: 3, iter: 1200, curr loss: 1.3863178491592407, avg loss: 1.3864679676294327\n",
      "trial: 3, iter: 1400, curr loss: 1.3869075775146484, avg loss: 1.38643963098526\n",
      "trial: 3, iter: 1600, curr loss: 1.3867415189743042, avg loss: 1.3863737308979034\n",
      "trial: 3, iter: 1800, curr loss: 1.387669563293457, avg loss: 1.3863411355018616\n",
      "trial: 3, iter: 2000, curr loss: 1.3881232738494873, avg loss: 1.3864033246040344\n",
      "trial: 3, iter: 2200, curr loss: 1.3874061107635498, avg loss: 1.3863778418302537\n",
      "trial: 3, iter: 2400, curr loss: 1.3858329057693481, avg loss: 1.386343166232109\n",
      "trial: 3, iter: 2600, curr loss: 1.3873400688171387, avg loss: 1.3863388234376908\n",
      "trial: 3, iter: 2800, curr loss: 1.3846796751022339, avg loss: 1.3862814289331435\n",
      "trial: 3, iter: 3000, curr loss: 1.385772466659546, avg loss: 1.3864866083860397\n",
      "trial: 3, iter: 3200, curr loss: 1.3872864246368408, avg loss: 1.3863134503364563\n",
      "trial: 3, iter: 3400, curr loss: 1.3857715129852295, avg loss: 1.3864541816711426\n",
      "trial: 3, iter: 3600, curr loss: 1.3874199390411377, avg loss: 1.3863496083021163\n",
      "trial: 3, iter: 3800, curr loss: 1.38686203956604, avg loss: 1.3863600540161132\n",
      "trial: 3, iter: 4000, curr loss: 1.3858532905578613, avg loss: 1.3863237971067428\n",
      "trial: 3, iter: 4200, curr loss: 1.3862587213516235, avg loss: 1.386333018541336\n",
      "trial: 3, iter: 4400, curr loss: 1.3861091136932373, avg loss: 1.3863803458213806\n",
      "trial: 3, iter: 4600, curr loss: 1.3867067098617554, avg loss: 1.3863309967517852\n",
      "trial: 3, iter: 4800, curr loss: 1.386170506477356, avg loss: 1.386296814084053\n",
      "trial: 3, iter: 5000, curr loss: 1.3856745958328247, avg loss: 1.3862941443920136\n",
      "trial: 3, iter: 5200, curr loss: 1.3869110345840454, avg loss: 1.3863671028614044\n",
      "trial: 3, iter: 5400, curr loss: 1.3865549564361572, avg loss: 1.3863699024915694\n",
      "trial: 3, iter: 5600, curr loss: 1.3870126008987427, avg loss: 1.3864291542768479\n",
      "trial: 3, iter: 5800, curr loss: 1.3862934112548828, avg loss: 1.386401377916336\n",
      "trial: 3, iter: 6000, curr loss: 1.3861063718795776, avg loss: 1.3863458275794982\n",
      "trial: 3, iter: 6200, curr loss: 1.385856032371521, avg loss: 1.3863770514726639\n",
      "trial: 3, iter: 6400, curr loss: 1.3858649730682373, avg loss: 1.3863380879163743\n",
      "trial: 3, iter: 6600, curr loss: 1.3868951797485352, avg loss: 1.3863360196352006\n",
      "trial: 3, iter: 6800, curr loss: 1.3863848447799683, avg loss: 1.38631691634655\n",
      "trial: 3, iter: 7000, curr loss: 1.3859782218933105, avg loss: 1.3863084620237351\n",
      "trial: 3, iter: 7200, curr loss: 1.3872971534729004, avg loss: 1.386302793622017\n",
      "trial: 3, iter: 7400, curr loss: 1.3863275051116943, avg loss: 1.386344866156578\n",
      "trial: 3, iter: 7600, curr loss: 1.3861080408096313, avg loss: 1.3863576406240463\n",
      "trial: 3, iter: 7800, curr loss: 1.386103630065918, avg loss: 1.3862870264053344\n",
      "trial: 3, iter: 8000, curr loss: 1.3861788511276245, avg loss: 1.3863060355186463\n",
      "trial: 3, iter: 8200, curr loss: 1.386797308921814, avg loss: 1.3863238543272018\n",
      "trial: 3, iter: 8400, curr loss: 1.3869166374206543, avg loss: 1.3862992799282075\n",
      "trial: 3, iter: 8600, curr loss: 1.3858261108398438, avg loss: 1.386334872841835\n",
      "trial: 3, iter: 8800, curr loss: 1.3855453729629517, avg loss: 1.386295023560524\n",
      "trial: 3, iter: 9000, curr loss: 1.386387825012207, avg loss: 1.3863261121511459\n",
      "trial: 3, iter: 9200, curr loss: 1.3866503238677979, avg loss: 1.3863064873218536\n",
      "trial: 3, iter: 9400, curr loss: 1.3862584829330444, avg loss: 1.3863212847709656\n",
      "trial: 3, iter: 9600, curr loss: 1.3862338066101074, avg loss: 1.3862992471456528\n",
      "trial: 3, iter: 9800, curr loss: 1.3864983320236206, avg loss: 1.3863074898719787\n",
      "trial: 3, iter: 10000, curr loss: 1.3861279487609863, avg loss: 1.386307293176651\n",
      "trial: 3, iter: 10200, curr loss: 1.3861931562423706, avg loss: 1.3863158684968948\n",
      "trial: 3, iter: 10400, curr loss: 1.386173129081726, avg loss: 1.3863064563274383\n",
      "trial: 3, iter: 10600, curr loss: 1.3863416910171509, avg loss: 1.386321788430214\n",
      "trial: 3, iter: 10800, curr loss: 1.386046051979065, avg loss: 1.3862981712818145\n",
      "trial: 3, iter: 11000, curr loss: 1.3863838911056519, avg loss: 1.3863190710544586\n",
      "trial: 3, iter: 11200, curr loss: 1.3866809606552124, avg loss: 1.3863100308179854\n",
      "trial: 3, iter: 11400, curr loss: 1.3860242366790771, avg loss: 1.3862993377447128\n",
      "trial: 3, iter: 11600, curr loss: 1.3860673904418945, avg loss: 1.3863047832250595\n",
      "trial: 3, iter: 11800, curr loss: 1.386419653892517, avg loss: 1.386297579407692\n",
      "trial: 3, iter: 12000, curr loss: 1.385852575302124, avg loss: 1.3863288778066636\n",
      "trial: 3, iter: 12200, curr loss: 1.3867710828781128, avg loss: 1.3863583534955979\n",
      "trial: 3, iter: 12400, curr loss: 1.3860341310501099, avg loss: 1.3863794481754304\n",
      "trial: 3, iter: 12600, curr loss: 1.385617971420288, avg loss: 1.3863701230287553\n",
      "trial: 3, iter: 12800, curr loss: 1.3862324953079224, avg loss: 1.3863806414604187\n",
      "trial: 3, iter: 13000, curr loss: 1.3867748975753784, avg loss: 1.3863393449783326\n",
      "trial: 3, iter: 13200, curr loss: 1.386283278465271, avg loss: 1.3863319957256317\n",
      "trial: 3, iter: 13400, curr loss: 1.385980248451233, avg loss: 1.3863158309459687\n",
      "trial: 3, iter: 13600, curr loss: 1.3863399028778076, avg loss: 1.3863112741708756\n",
      "trial: 3, iter: 13800, curr loss: 1.3863693475723267, avg loss: 1.3863112115859986\n",
      "trial: 3, iter: 14000, curr loss: 1.3858442306518555, avg loss: 1.386347737312317\n",
      "trial: 3, iter: 14200, curr loss: 1.3868796825408936, avg loss: 1.386323753595352\n",
      "trial: 3, iter: 14400, curr loss: 1.386265754699707, avg loss: 1.386309145092964\n",
      "trial: 3, iter: 14600, curr loss: 1.3866015672683716, avg loss: 1.386307265162468\n",
      "trial: 3, iter: 14800, curr loss: 1.386742115020752, avg loss: 1.386260621547699\n",
      "trial: 3, iter: 15000, curr loss: 1.386165738105774, avg loss: 1.3863619601726531\n",
      "trial: 3, iter: 15200, curr loss: 1.385947585105896, avg loss: 1.38632974922657\n",
      "trial: 3, iter: 15400, curr loss: 1.3862334489822388, avg loss: 1.3863336169719696\n",
      "trial: 3, iter: 15600, curr loss: 1.386261224746704, avg loss: 1.386292741894722\n",
      "trial: 3, ldr: -0.0009612927096895874\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3859902620315552, avg loss: 1.387645661830902\n",
      "trial: 4, iter: 400, curr loss: 1.3840597867965698, avg loss: 1.3868764412403107\n",
      "trial: 4, iter: 600, curr loss: 1.3847229480743408, avg loss: 1.3865608859062195\n",
      "trial: 4, iter: 800, curr loss: 1.3857835531234741, avg loss: 1.3865635412931443\n",
      "trial: 4, iter: 1000, curr loss: 1.386922001838684, avg loss: 1.3864961624145509\n",
      "trial: 4, iter: 1200, curr loss: 1.3883174657821655, avg loss: 1.3865235722064972\n",
      "trial: 4, iter: 1400, curr loss: 1.3861477375030518, avg loss: 1.3863446974754334\n",
      "trial: 4, iter: 1600, curr loss: 1.3876539468765259, avg loss: 1.3864185690879822\n",
      "trial: 4, iter: 1800, curr loss: 1.385805606842041, avg loss: 1.3864152491092683\n",
      "trial: 4, iter: 2000, curr loss: 1.3859916925430298, avg loss: 1.386430339217186\n",
      "trial: 4, iter: 2200, curr loss: 1.3860924243927002, avg loss: 1.3863673895597457\n",
      "trial: 4, iter: 2400, curr loss: 1.3865348100662231, avg loss: 1.386328934431076\n",
      "trial: 4, iter: 2600, curr loss: 1.3857002258300781, avg loss: 1.3863518637418748\n",
      "trial: 4, iter: 2800, curr loss: 1.386315107345581, avg loss: 1.386381853222847\n",
      "trial: 4, iter: 3000, curr loss: 1.3859766721725464, avg loss: 1.3863015365600586\n",
      "trial: 4, iter: 3200, curr loss: 1.3852505683898926, avg loss: 1.3863330698013305\n",
      "trial: 4, iter: 3400, curr loss: 1.3869168758392334, avg loss: 1.386311917901039\n",
      "trial: 4, iter: 3600, curr loss: 1.3874139785766602, avg loss: 1.3863386422395707\n",
      "trial: 4, iter: 3800, curr loss: 1.3866933584213257, avg loss: 1.3863908272981644\n",
      "trial: 4, iter: 4000, curr loss: 1.3860766887664795, avg loss: 1.3863446420431138\n",
      "trial: 4, iter: 4200, curr loss: 1.386480689048767, avg loss: 1.3863028168678284\n",
      "trial: 4, iter: 4400, curr loss: 1.3869279623031616, avg loss: 1.3863461327552795\n",
      "trial: 4, iter: 4600, curr loss: 1.386641263961792, avg loss: 1.3863336908817292\n",
      "trial: 4, iter: 4800, curr loss: 1.3875129222869873, avg loss: 1.3863188296556472\n",
      "trial: 4, iter: 5000, curr loss: 1.3862401247024536, avg loss: 1.386315776705742\n",
      "trial: 4, iter: 5200, curr loss: 1.386752724647522, avg loss: 1.386315696835518\n",
      "trial: 4, iter: 5400, curr loss: 1.3860012292861938, avg loss: 1.3863939779996872\n",
      "trial: 4, iter: 5600, curr loss: 1.3867137432098389, avg loss: 1.3862936651706697\n",
      "trial: 4, iter: 5800, curr loss: 1.3859291076660156, avg loss: 1.3863587534427644\n",
      "trial: 4, iter: 6000, curr loss: 1.386563777923584, avg loss: 1.3863533127307892\n",
      "trial: 4, iter: 6200, curr loss: 1.3863210678100586, avg loss: 1.3863157111406326\n",
      "trial: 4, iter: 6400, curr loss: 1.3862696886062622, avg loss: 1.3862963223457336\n",
      "trial: 4, iter: 6600, curr loss: 1.3861840963363647, avg loss: 1.386294471025467\n",
      "trial: 4, iter: 6800, curr loss: 1.3862979412078857, avg loss: 1.3863225382566453\n",
      "trial: 4, iter: 7000, curr loss: 1.3863314390182495, avg loss: 1.386348263025284\n",
      "trial: 4, iter: 7200, curr loss: 1.3863753080368042, avg loss: 1.3862949156761168\n",
      "trial: 4, iter: 7400, curr loss: 1.3860352039337158, avg loss: 1.3863172781467439\n",
      "trial: 4, iter: 7600, curr loss: 1.386613368988037, avg loss: 1.3863267290592194\n",
      "trial: 4, iter: 7800, curr loss: 1.3858253955841064, avg loss: 1.3863102412223816\n",
      "trial: 4, iter: 8000, curr loss: 1.3861545324325562, avg loss: 1.386336772441864\n",
      "trial: 4, iter: 8200, curr loss: 1.386214017868042, avg loss: 1.386328593492508\n",
      "trial: 4, iter: 8400, curr loss: 1.3857954740524292, avg loss: 1.386289540529251\n",
      "trial: 4, iter: 8600, curr loss: 1.3877782821655273, avg loss: 1.386276074051857\n",
      "trial: 4, iter: 8800, curr loss: 1.3859328031539917, avg loss: 1.3863392794132232\n",
      "trial: 4, iter: 9000, curr loss: 1.3862136602401733, avg loss: 1.3862948894500733\n",
      "trial: 4, iter: 9200, curr loss: 1.3858412504196167, avg loss: 1.3862974494695663\n",
      "trial: 4, iter: 9400, curr loss: 1.3863797187805176, avg loss: 1.3863319873809814\n",
      "trial: 4, iter: 9600, curr loss: 1.3863317966461182, avg loss: 1.3863116490840912\n",
      "trial: 4, iter: 9800, curr loss: 1.38612699508667, avg loss: 1.3862770503759385\n",
      "trial: 4, iter: 10000, curr loss: 1.386297583580017, avg loss: 1.3862799340486527\n",
      "trial: 4, iter: 10200, curr loss: 1.386522650718689, avg loss: 1.3863283795118333\n",
      "trial: 4, iter: 10400, curr loss: 1.3866145610809326, avg loss: 1.3863198339939118\n",
      "trial: 4, iter: 10600, curr loss: 1.3859103918075562, avg loss: 1.3862947463989257\n",
      "trial: 4, iter: 10800, curr loss: 1.3863201141357422, avg loss: 1.3863000464439392\n",
      "trial: 4, iter: 11000, curr loss: 1.3862650394439697, avg loss: 1.3863044089078904\n",
      "trial: 4, iter: 11200, curr loss: 1.386525273323059, avg loss: 1.3863134813308715\n",
      "trial: 4, iter: 11400, curr loss: 1.3867560625076294, avg loss: 1.3863913786411286\n",
      "trial: 4, iter: 11600, curr loss: 1.387265920639038, avg loss: 1.3863479375839234\n",
      "trial: 4, iter: 11800, curr loss: 1.3861654996871948, avg loss: 1.3863485848903656\n",
      "trial: 4, iter: 12000, curr loss: 1.3863579034805298, avg loss: 1.3863140588998795\n",
      "trial: 4, iter: 12200, curr loss: 1.3864367008209229, avg loss: 1.3863253980875014\n",
      "trial: 4, iter: 12400, curr loss: 1.3869823217391968, avg loss: 1.3862972611188888\n",
      "trial: 4, iter: 12600, curr loss: 1.3863791227340698, avg loss: 1.3863039964437485\n",
      "trial: 4, iter: 12800, curr loss: 1.385661005973816, avg loss: 1.3862756234407425\n",
      "trial: 4, iter: 13000, curr loss: 1.3869491815567017, avg loss: 1.386311548948288\n",
      "trial: 4, iter: 13200, curr loss: 1.3860089778900146, avg loss: 1.3863740915060043\n",
      "trial: 4, iter: 13400, curr loss: 1.3867559432983398, avg loss: 1.3863188987970352\n",
      "trial: 4, iter: 13600, curr loss: 1.3857367038726807, avg loss: 1.386330988407135\n",
      "trial: 4, iter: 13800, curr loss: 1.3860116004943848, avg loss: 1.3863040739297867\n",
      "trial: 4, iter: 14000, curr loss: 1.386275291442871, avg loss: 1.3863426315784455\n",
      "trial: 4, iter: 14200, curr loss: 1.3863517045974731, avg loss: 1.3863231891393661\n",
      "trial: 4, iter: 14400, curr loss: 1.3862842321395874, avg loss: 1.3862908279895783\n",
      "trial: 4, iter: 14600, curr loss: 1.3862329721450806, avg loss: 1.3863120484352112\n",
      "trial: 4, iter: 14800, curr loss: 1.3863273859024048, avg loss: 1.3863117229938506\n",
      "trial: 4, iter: 15000, curr loss: 1.3866548538208008, avg loss: 1.386291987299919\n",
      "trial: 4, iter: 15200, curr loss: 1.386446237564087, avg loss: 1.386321839094162\n",
      "trial: 4, iter: 15400, curr loss: 1.3862642049789429, avg loss: 1.3863177132606506\n",
      "trial: 4, iter: 15600, curr loss: 1.3858565092086792, avg loss: 1.3862886649370194\n",
      "trial: 4, ldr: -0.0029883929528295994\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.39013671875, avg loss: 1.3874180191755294\n",
      "trial: 5, iter: 400, curr loss: 1.3869373798370361, avg loss: 1.38685533285141\n",
      "trial: 5, iter: 600, curr loss: 1.3868603706359863, avg loss: 1.3866341882944107\n",
      "trial: 5, iter: 800, curr loss: 1.3860441446304321, avg loss: 1.3864527451992035\n",
      "trial: 5, iter: 1000, curr loss: 1.3884533643722534, avg loss: 1.3862981343269347\n",
      "trial: 5, iter: 1200, curr loss: 1.3865268230438232, avg loss: 1.3863641464710235\n",
      "trial: 5, iter: 1400, curr loss: 1.3859134912490845, avg loss: 1.3865606421232224\n",
      "trial: 5, iter: 1600, curr loss: 1.3881551027297974, avg loss: 1.3863214027881623\n",
      "trial: 5, iter: 1800, curr loss: 1.3865689039230347, avg loss: 1.386467186808586\n",
      "trial: 5, iter: 2000, curr loss: 1.3884392976760864, avg loss: 1.3863185733556747\n",
      "trial: 5, iter: 2200, curr loss: 1.3872661590576172, avg loss: 1.386399651169777\n",
      "trial: 5, iter: 2400, curr loss: 1.3880609273910522, avg loss: 1.3863435751199722\n",
      "trial: 5, iter: 2600, curr loss: 1.3871304988861084, avg loss: 1.3863943755626678\n",
      "trial: 5, iter: 2800, curr loss: 1.385618805885315, avg loss: 1.3864180934429169\n",
      "trial: 5, iter: 3000, curr loss: 1.3863162994384766, avg loss: 1.3863318431377412\n",
      "trial: 5, iter: 3200, curr loss: 1.3857125043869019, avg loss: 1.3863667607307435\n",
      "trial: 5, iter: 3400, curr loss: 1.3873695135116577, avg loss: 1.3863936752080916\n",
      "trial: 5, iter: 3600, curr loss: 1.3859498500823975, avg loss: 1.386313067674637\n",
      "trial: 5, iter: 3800, curr loss: 1.387318730354309, avg loss: 1.3863759434223175\n",
      "trial: 5, iter: 4000, curr loss: 1.3858189582824707, avg loss: 1.3863357871770858\n",
      "trial: 5, iter: 4200, curr loss: 1.3863270282745361, avg loss: 1.3862805539369583\n",
      "trial: 5, iter: 4400, curr loss: 1.3855737447738647, avg loss: 1.3862997353076936\n",
      "trial: 5, iter: 4600, curr loss: 1.3856840133666992, avg loss: 1.386309221982956\n",
      "trial: 5, iter: 4800, curr loss: 1.3862923383712769, avg loss: 1.3864574790000916\n",
      "trial: 5, iter: 5000, curr loss: 1.3862075805664062, avg loss: 1.3863581639528275\n",
      "trial: 5, iter: 5200, curr loss: 1.3860365152359009, avg loss: 1.3862872910499573\n",
      "trial: 5, iter: 5400, curr loss: 1.38582444190979, avg loss: 1.38631143450737\n",
      "trial: 5, iter: 5600, curr loss: 1.3858906030654907, avg loss: 1.386380162835121\n",
      "trial: 5, iter: 5800, curr loss: 1.386957049369812, avg loss: 1.386301822066307\n",
      "trial: 5, iter: 6000, curr loss: 1.3865381479263306, avg loss: 1.3863170564174652\n",
      "trial: 5, iter: 6200, curr loss: 1.386383056640625, avg loss: 1.3863164705038071\n",
      "trial: 5, iter: 6400, curr loss: 1.385717511177063, avg loss: 1.3862993127107621\n",
      "trial: 5, iter: 6600, curr loss: 1.3861706256866455, avg loss: 1.386300754547119\n",
      "trial: 5, iter: 6800, curr loss: 1.3864995241165161, avg loss: 1.386319909095764\n",
      "trial: 5, iter: 7000, curr loss: 1.386015772819519, avg loss: 1.3863471090793609\n",
      "trial: 5, iter: 7200, curr loss: 1.3860503435134888, avg loss: 1.3863002544641494\n",
      "trial: 5, iter: 7400, curr loss: 1.3861165046691895, avg loss: 1.3863328421115875\n",
      "trial: 5, iter: 7600, curr loss: 1.3868720531463623, avg loss: 1.3863086378574372\n",
      "trial: 5, iter: 7800, curr loss: 1.3861281871795654, avg loss: 1.3863489723205566\n",
      "trial: 5, iter: 8000, curr loss: 1.3865634202957153, avg loss: 1.386275456547737\n",
      "trial: 5, iter: 8200, curr loss: 1.3857289552688599, avg loss: 1.386308776140213\n",
      "trial: 5, iter: 8400, curr loss: 1.3868094682693481, avg loss: 1.3863093054294586\n",
      "trial: 5, iter: 8600, curr loss: 1.3859349489212036, avg loss: 1.3863406533002853\n",
      "trial: 5, iter: 8800, curr loss: 1.386364221572876, avg loss: 1.3863271433115005\n",
      "trial: 5, iter: 9000, curr loss: 1.3863470554351807, avg loss: 1.386309288740158\n",
      "trial: 5, iter: 9200, curr loss: 1.3862355947494507, avg loss: 1.3862536895275115\n",
      "trial: 5, iter: 9400, curr loss: 1.3854384422302246, avg loss: 1.38633524954319\n",
      "trial: 5, iter: 9600, curr loss: 1.3857828378677368, avg loss: 1.3862608915567398\n",
      "trial: 5, iter: 9800, curr loss: 1.3862107992172241, avg loss: 1.3863688373565675\n",
      "trial: 5, iter: 10000, curr loss: 1.386474847793579, avg loss: 1.3863553076982498\n",
      "trial: 5, iter: 10200, curr loss: 1.3866145610809326, avg loss: 1.3863334941864014\n",
      "trial: 5, iter: 10400, curr loss: 1.3862367868423462, avg loss: 1.3863294357061386\n",
      "trial: 5, iter: 10600, curr loss: 1.3860143423080444, avg loss: 1.386279736161232\n",
      "trial: 5, iter: 10800, curr loss: 1.3863059282302856, avg loss: 1.3863009983301162\n",
      "trial: 5, iter: 11000, curr loss: 1.3869673013687134, avg loss: 1.3863040113449097\n",
      "trial: 5, iter: 11200, curr loss: 1.386053442955017, avg loss: 1.386299919486046\n",
      "trial: 5, iter: 11400, curr loss: 1.3865535259246826, avg loss: 1.3863166666030884\n",
      "trial: 5, iter: 11600, curr loss: 1.3862065076828003, avg loss: 1.3863051837682725\n",
      "trial: 5, iter: 11800, curr loss: 1.3863718509674072, avg loss: 1.3863085806369781\n",
      "trial: 5, iter: 12000, curr loss: 1.386328935623169, avg loss: 1.3862977159023284\n",
      "trial: 5, iter: 12200, curr loss: 1.3867042064666748, avg loss: 1.386297881603241\n",
      "trial: 5, iter: 12400, curr loss: 1.3864177465438843, avg loss: 1.3863110399246217\n",
      "trial: 5, iter: 12600, curr loss: 1.386091947555542, avg loss: 1.3862835896015167\n",
      "trial: 5, iter: 12800, curr loss: 1.3863757848739624, avg loss: 1.386316048502922\n",
      "trial: 5, iter: 13000, curr loss: 1.386328101158142, avg loss: 1.3862980580329896\n",
      "trial: 5, iter: 13200, curr loss: 1.3863292932510376, avg loss: 1.386296101808548\n",
      "trial: 5, iter: 13400, curr loss: 1.386410117149353, avg loss: 1.386289108991623\n",
      "trial: 5, iter: 13600, curr loss: 1.3863381147384644, avg loss: 1.3863030660152436\n",
      "trial: 5, iter: 13800, curr loss: 1.386303186416626, avg loss: 1.3862885797023774\n",
      "trial: 5, iter: 14000, curr loss: 1.3862922191619873, avg loss: 1.3862948006391524\n",
      "trial: 5, iter: 14200, curr loss: 1.3862943649291992, avg loss: 1.386294138431549\n",
      "trial: 5, iter: 14400, curr loss: 1.3862946033477783, avg loss: 1.3862941807508469\n",
      "trial: 5, iter: 14600, curr loss: 1.3863744735717773, avg loss: 1.386312147974968\n",
      "trial: 5, iter: 14800, curr loss: 1.3862907886505127, avg loss: 1.386297801733017\n",
      "trial: 5, iter: 15000, curr loss: 1.3862990140914917, avg loss: 1.3862980967760086\n",
      "trial: 5, iter: 15200, curr loss: 1.3863089084625244, avg loss: 1.3863018435239791\n",
      "trial: 5, iter: 15400, curr loss: 1.386052131652832, avg loss: 1.3862933683395386\n",
      "trial: 5, iter: 15600, curr loss: 1.3863102197647095, avg loss: 1.3863028019666672\n",
      "trial: 5, ldr: -0.00019882901688106358\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0008974084572400898\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3901211023330688, avg loss: 1.387376908659935\n",
      "trial: 1, iter: 400, curr loss: 1.3847445249557495, avg loss: 1.3868156373500824\n",
      "trial: 1, iter: 600, curr loss: 1.3867353200912476, avg loss: 1.3866191029548645\n",
      "trial: 1, iter: 800, curr loss: 1.3856040239334106, avg loss: 1.3865731739997864\n",
      "trial: 1, iter: 1000, curr loss: 1.3866029977798462, avg loss: 1.3864507150650025\n",
      "trial: 1, iter: 1200, curr loss: 1.3845919370651245, avg loss: 1.3864278256893159\n",
      "trial: 1, iter: 1400, curr loss: 1.386276364326477, avg loss: 1.386432437300682\n",
      "trial: 1, iter: 1600, curr loss: 1.3866063356399536, avg loss: 1.3864249378442763\n",
      "trial: 1, iter: 1800, curr loss: 1.3867295980453491, avg loss: 1.386321981549263\n",
      "trial: 1, iter: 2000, curr loss: 1.3857297897338867, avg loss: 1.3864307457208633\n",
      "trial: 1, iter: 2200, curr loss: 1.3877217769622803, avg loss: 1.3862686204910277\n",
      "trial: 1, iter: 2400, curr loss: 1.387361764907837, avg loss: 1.3864274352788926\n",
      "trial: 1, iter: 2600, curr loss: 1.3850568532943726, avg loss: 1.3864002567529679\n",
      "trial: 1, iter: 2800, curr loss: 1.3855808973312378, avg loss: 1.3863674640655517\n",
      "trial: 1, iter: 3000, curr loss: 1.3862643241882324, avg loss: 1.3864384078979493\n",
      "trial: 1, iter: 3200, curr loss: 1.3856825828552246, avg loss: 1.3863122797012328\n",
      "trial: 1, iter: 3400, curr loss: 1.3857232332229614, avg loss: 1.3863502061367035\n",
      "trial: 1, iter: 3600, curr loss: 1.3866568803787231, avg loss: 1.3863738232851028\n",
      "trial: 1, iter: 3800, curr loss: 1.3868262767791748, avg loss: 1.3863152366876603\n",
      "trial: 1, iter: 4000, curr loss: 1.3862390518188477, avg loss: 1.3863132452964784\n",
      "trial: 1, iter: 4200, curr loss: 1.3867378234863281, avg loss: 1.3863309508562087\n",
      "trial: 1, iter: 4400, curr loss: 1.3859519958496094, avg loss: 1.386276358962059\n",
      "trial: 1, iter: 4600, curr loss: 1.3860808610916138, avg loss: 1.3863584345579147\n",
      "trial: 1, iter: 4800, curr loss: 1.386498212814331, avg loss: 1.3863037902116775\n",
      "trial: 1, iter: 5000, curr loss: 1.3855259418487549, avg loss: 1.3862908053398133\n",
      "trial: 1, iter: 5200, curr loss: 1.3866091966629028, avg loss: 1.3863360399007798\n",
      "trial: 1, iter: 5400, curr loss: 1.3858915567398071, avg loss: 1.3863220512866974\n",
      "trial: 1, iter: 5600, curr loss: 1.385495662689209, avg loss: 1.386283231973648\n",
      "trial: 1, iter: 5800, curr loss: 1.386172890663147, avg loss: 1.3863494628667832\n",
      "trial: 1, iter: 6000, curr loss: 1.386231541633606, avg loss: 1.3863548439741136\n",
      "trial: 1, iter: 6200, curr loss: 1.387074589729309, avg loss: 1.3863149160146713\n",
      "trial: 1, iter: 6400, curr loss: 1.3873392343521118, avg loss: 1.386389610171318\n",
      "trial: 1, iter: 6600, curr loss: 1.3864895105361938, avg loss: 1.3863350856304169\n",
      "trial: 1, iter: 6800, curr loss: 1.3858453035354614, avg loss: 1.3863839107751845\n",
      "trial: 1, iter: 7000, curr loss: 1.3863414525985718, avg loss: 1.3862976628541945\n",
      "trial: 1, iter: 7200, curr loss: 1.385630488395691, avg loss: 1.386319681406021\n",
      "trial: 1, iter: 7400, curr loss: 1.3871454000473022, avg loss: 1.386299689412117\n",
      "trial: 1, iter: 7600, curr loss: 1.386989712715149, avg loss: 1.386338975429535\n",
      "trial: 1, iter: 7800, curr loss: 1.386025071144104, avg loss: 1.3863156467676163\n",
      "trial: 1, iter: 8000, curr loss: 1.3865982294082642, avg loss: 1.3863112783432008\n",
      "trial: 1, iter: 8200, curr loss: 1.3862818479537964, avg loss: 1.3863139593601226\n",
      "trial: 1, iter: 8400, curr loss: 1.3863821029663086, avg loss: 1.3862949323654175\n",
      "trial: 1, iter: 8600, curr loss: 1.386285662651062, avg loss: 1.3863006550073624\n",
      "trial: 1, iter: 8800, curr loss: 1.3859702348709106, avg loss: 1.3862866681814194\n",
      "trial: 1, iter: 9000, curr loss: 1.385999321937561, avg loss: 1.3863508379459382\n",
      "trial: 1, iter: 9200, curr loss: 1.3866239786148071, avg loss: 1.3863103485107422\n",
      "trial: 1, iter: 9400, curr loss: 1.386064052581787, avg loss: 1.38631054520607\n",
      "trial: 1, iter: 9600, curr loss: 1.386279821395874, avg loss: 1.3863181155920028\n",
      "trial: 1, iter: 9800, curr loss: 1.3864822387695312, avg loss: 1.3863065552711487\n",
      "trial: 1, iter: 10000, curr loss: 1.385839581489563, avg loss: 1.3863007420301436\n",
      "trial: 1, iter: 10200, curr loss: 1.3859949111938477, avg loss: 1.386314400434494\n",
      "trial: 1, iter: 10400, curr loss: 1.3857650756835938, avg loss: 1.3863319444656372\n",
      "trial: 1, iter: 10600, curr loss: 1.3862857818603516, avg loss: 1.3863010400533675\n",
      "trial: 1, iter: 10800, curr loss: 1.3867212533950806, avg loss: 1.3862837874889373\n",
      "trial: 1, iter: 11000, curr loss: 1.3870807886123657, avg loss: 1.3862684339284896\n",
      "trial: 1, iter: 11200, curr loss: 1.3857098817825317, avg loss: 1.3862692832946777\n",
      "trial: 1, iter: 11400, curr loss: 1.3855291604995728, avg loss: 1.3863412445783616\n",
      "trial: 1, iter: 11600, curr loss: 1.3882380723953247, avg loss: 1.3862779188156127\n",
      "trial: 1, iter: 11800, curr loss: 1.38568913936615, avg loss: 1.3864804500341414\n",
      "trial: 1, iter: 12000, curr loss: 1.3866710662841797, avg loss: 1.386280055642128\n",
      "trial: 1, iter: 12200, curr loss: 1.3857471942901611, avg loss: 1.3863278710842133\n",
      "trial: 1, iter: 12400, curr loss: 1.3868377208709717, avg loss: 1.3863689070940017\n",
      "trial: 1, iter: 12600, curr loss: 1.385635256767273, avg loss: 1.3862923347949982\n",
      "trial: 1, iter: 12800, curr loss: 1.3868379592895508, avg loss: 1.3863068610429763\n",
      "trial: 1, iter: 13000, curr loss: 1.385892629623413, avg loss: 1.3863538229465484\n",
      "trial: 1, iter: 13200, curr loss: 1.3860710859298706, avg loss: 1.3863141602277755\n",
      "trial: 1, iter: 13400, curr loss: 1.3865478038787842, avg loss: 1.3862573462724685\n",
      "trial: 1, iter: 13600, curr loss: 1.3860437870025635, avg loss: 1.3863635390996933\n",
      "trial: 1, iter: 13800, curr loss: 1.3865091800689697, avg loss: 1.3863185405731202\n",
      "trial: 1, iter: 14000, curr loss: 1.3857688903808594, avg loss: 1.3863088077306747\n",
      "trial: 1, iter: 14200, curr loss: 1.3864574432373047, avg loss: 1.3863145643472672\n",
      "trial: 1, iter: 14400, curr loss: 1.38631272315979, avg loss: 1.386281942129135\n",
      "trial: 1, iter: 14600, curr loss: 1.3862714767456055, avg loss: 1.3862768322229386\n",
      "trial: 1, iter: 14800, curr loss: 1.3861591815948486, avg loss: 1.3863094413280488\n",
      "trial: 1, iter: 15000, curr loss: 1.3864021301269531, avg loss: 1.386302765607834\n",
      "trial: 1, iter: 15200, curr loss: 1.3870148658752441, avg loss: 1.3863230901956558\n",
      "trial: 1, iter: 15400, curr loss: 1.385512113571167, avg loss: 1.3862899935245514\n",
      "trial: 1, iter: 15600, curr loss: 1.3865599632263184, avg loss: 1.386300076842308\n",
      "trial: 1, ldr: -0.002880260581150651\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3870218992233276, avg loss: 1.3871913200616837\n",
      "trial: 2, iter: 400, curr loss: 1.3866721391677856, avg loss: 1.3869259357452393\n",
      "trial: 2, iter: 600, curr loss: 1.3875302076339722, avg loss: 1.3865975111722946\n",
      "trial: 2, iter: 800, curr loss: 1.384308934211731, avg loss: 1.3865501189231872\n",
      "trial: 2, iter: 1000, curr loss: 1.385237216949463, avg loss: 1.3864539539813996\n",
      "trial: 2, iter: 1200, curr loss: 1.3895258903503418, avg loss: 1.3864371901750565\n",
      "trial: 2, iter: 1400, curr loss: 1.386031985282898, avg loss: 1.3864423799514771\n",
      "trial: 2, iter: 1600, curr loss: 1.3867243528366089, avg loss: 1.3864244800806045\n",
      "trial: 2, iter: 1800, curr loss: 1.3872766494750977, avg loss: 1.3863977944850923\n",
      "trial: 2, iter: 2000, curr loss: 1.386520266532898, avg loss: 1.386382418870926\n",
      "trial: 2, iter: 2200, curr loss: 1.3858356475830078, avg loss: 1.3863051253557206\n",
      "trial: 2, iter: 2400, curr loss: 1.3861068487167358, avg loss: 1.3864015799760818\n",
      "trial: 2, iter: 2600, curr loss: 1.3862171173095703, avg loss: 1.3863373613357544\n",
      "trial: 2, iter: 2800, curr loss: 1.386955738067627, avg loss: 1.3863342887163161\n",
      "trial: 2, iter: 3000, curr loss: 1.3865230083465576, avg loss: 1.3863416385650635\n",
      "trial: 2, iter: 3200, curr loss: 1.3856968879699707, avg loss: 1.3863067537546159\n",
      "trial: 2, iter: 3400, curr loss: 1.3848885297775269, avg loss: 1.3863321590423583\n",
      "trial: 2, iter: 3600, curr loss: 1.3863332271575928, avg loss: 1.3863856792449951\n",
      "trial: 2, iter: 3800, curr loss: 1.3862507343292236, avg loss: 1.3863567942380906\n",
      "trial: 2, iter: 4000, curr loss: 1.3858373165130615, avg loss: 1.386308953166008\n",
      "trial: 2, iter: 4200, curr loss: 1.3861638307571411, avg loss: 1.3863280832767486\n",
      "trial: 2, iter: 4400, curr loss: 1.386263132095337, avg loss: 1.3863033938407898\n",
      "trial: 2, iter: 4600, curr loss: 1.3858988285064697, avg loss: 1.3863080936670302\n",
      "trial: 2, iter: 4800, curr loss: 1.3890224695205688, avg loss: 1.3863529562950134\n",
      "trial: 2, iter: 5000, curr loss: 1.3869132995605469, avg loss: 1.3863191866874696\n",
      "trial: 2, iter: 5200, curr loss: 1.3862355947494507, avg loss: 1.3863455158472062\n",
      "trial: 2, iter: 5400, curr loss: 1.387313723564148, avg loss: 1.3863007837533952\n",
      "trial: 2, iter: 5600, curr loss: 1.386326789855957, avg loss: 1.3863208901882171\n",
      "trial: 2, iter: 5800, curr loss: 1.3863084316253662, avg loss: 1.38631396651268\n",
      "trial: 2, iter: 6000, curr loss: 1.3862969875335693, avg loss: 1.3863038605451583\n",
      "trial: 2, iter: 6200, curr loss: 1.3862910270690918, avg loss: 1.3863014751672744\n",
      "trial: 2, iter: 6400, curr loss: 1.386243224143982, avg loss: 1.386326459646225\n",
      "trial: 2, iter: 6600, curr loss: 1.3864728212356567, avg loss: 1.3863101077079774\n",
      "trial: 2, iter: 6800, curr loss: 1.3858803510665894, avg loss: 1.386281322836876\n",
      "trial: 2, iter: 7000, curr loss: 1.3864617347717285, avg loss: 1.3863714230060578\n",
      "trial: 2, iter: 7200, curr loss: 1.3858288526535034, avg loss: 1.3863082033395768\n",
      "trial: 2, iter: 7400, curr loss: 1.3864548206329346, avg loss: 1.386316378712654\n",
      "trial: 2, iter: 7600, curr loss: 1.3864209651947021, avg loss: 1.3862711930274962\n",
      "trial: 2, iter: 7800, curr loss: 1.3863635063171387, avg loss: 1.3863382315635682\n",
      "trial: 2, iter: 8000, curr loss: 1.3861470222473145, avg loss: 1.3863372153043747\n",
      "trial: 2, iter: 8200, curr loss: 1.386712670326233, avg loss: 1.3863047385215759\n",
      "trial: 2, iter: 8400, curr loss: 1.386298656463623, avg loss: 1.386314895749092\n",
      "trial: 2, iter: 8600, curr loss: 1.386181354522705, avg loss: 1.3862695103883744\n",
      "trial: 2, iter: 8800, curr loss: 1.3858193159103394, avg loss: 1.3863154578208923\n",
      "trial: 2, iter: 9000, curr loss: 1.3863247632980347, avg loss: 1.3863304263353349\n",
      "trial: 2, iter: 9200, curr loss: 1.3855406045913696, avg loss: 1.3862874239683152\n",
      "trial: 2, iter: 9400, curr loss: 1.3862719535827637, avg loss: 1.3863256126642227\n",
      "trial: 2, iter: 9600, curr loss: 1.3867131471633911, avg loss: 1.3863463926315307\n",
      "trial: 2, iter: 9800, curr loss: 1.3865238428115845, avg loss: 1.3863120836019516\n",
      "trial: 2, iter: 10000, curr loss: 1.3866081237792969, avg loss: 1.3863189339637756\n",
      "trial: 2, iter: 10200, curr loss: 1.3859556913375854, avg loss: 1.3863065040111542\n",
      "trial: 2, iter: 10400, curr loss: 1.3864701986312866, avg loss: 1.3863053983449936\n",
      "trial: 2, iter: 10600, curr loss: 1.3866873979568481, avg loss: 1.3863368928432465\n",
      "trial: 2, iter: 10800, curr loss: 1.3864555358886719, avg loss: 1.3863346922397612\n",
      "trial: 2, iter: 11000, curr loss: 1.3864260911941528, avg loss: 1.3862988936901093\n",
      "trial: 2, iter: 11200, curr loss: 1.3864355087280273, avg loss: 1.3863080430030823\n",
      "trial: 2, iter: 11400, curr loss: 1.3862807750701904, avg loss: 1.3863009905815125\n",
      "trial: 2, iter: 11600, curr loss: 1.386921763420105, avg loss: 1.3862974494695663\n",
      "trial: 2, iter: 11800, curr loss: 1.3863290548324585, avg loss: 1.3862926352024079\n",
      "trial: 2, iter: 12000, curr loss: 1.3864134550094604, avg loss: 1.386321291923523\n",
      "trial: 2, iter: 12200, curr loss: 1.3861852884292603, avg loss: 1.3862875097990035\n",
      "trial: 2, iter: 12400, curr loss: 1.3863739967346191, avg loss: 1.3863109731674195\n",
      "trial: 2, iter: 12600, curr loss: 1.3862675428390503, avg loss: 1.3862976044416429\n",
      "trial: 2, iter: 12800, curr loss: 1.3862555027008057, avg loss: 1.3863013398647308\n",
      "trial: 2, iter: 13000, curr loss: 1.3863143920898438, avg loss: 1.3863056069612503\n",
      "trial: 2, iter: 13200, curr loss: 1.3862719535827637, avg loss: 1.3862984573841095\n",
      "trial: 2, iter: 13400, curr loss: 1.3863227367401123, avg loss: 1.386296803355217\n",
      "trial: 2, iter: 13600, curr loss: 1.3862817287445068, avg loss: 1.3862980836629868\n",
      "trial: 2, iter: 13800, curr loss: 1.386259913444519, avg loss: 1.386295714378357\n",
      "trial: 2, iter: 14000, curr loss: 1.3864237070083618, avg loss: 1.3862917506694794\n",
      "trial: 2, iter: 14200, curr loss: 1.3863475322723389, avg loss: 1.3863005328178406\n",
      "trial: 2, iter: 14400, curr loss: 1.385970950126648, avg loss: 1.3862954741716385\n",
      "trial: 2, iter: 14600, curr loss: 1.3863798379898071, avg loss: 1.3862991333007812\n",
      "trial: 2, iter: 14800, curr loss: 1.386340618133545, avg loss: 1.386301715373993\n",
      "trial: 2, iter: 15000, curr loss: 1.3866842985153198, avg loss: 1.3862904834747314\n",
      "trial: 2, iter: 15200, curr loss: 1.387311577796936, avg loss: 1.3862784433364868\n",
      "trial: 2, iter: 15400, curr loss: 1.386993646621704, avg loss: 1.386334457397461\n",
      "trial: 2, iter: 15600, curr loss: 1.3863494396209717, avg loss: 1.386416940689087\n",
      "trial: 2, ldr: 0.0005468085873872042\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389790415763855, avg loss: 1.3874333560466767\n",
      "trial: 3, iter: 400, curr loss: 1.3855793476104736, avg loss: 1.3868373918533325\n",
      "trial: 3, iter: 600, curr loss: 1.3896409273147583, avg loss: 1.3866443574428557\n",
      "trial: 3, iter: 800, curr loss: 1.3863433599472046, avg loss: 1.3865036743879318\n",
      "trial: 3, iter: 1000, curr loss: 1.385979175567627, avg loss: 1.3864376878738403\n",
      "trial: 3, iter: 1200, curr loss: 1.3857135772705078, avg loss: 1.3863963675498963\n",
      "trial: 3, iter: 1400, curr loss: 1.3873993158340454, avg loss: 1.386548907160759\n",
      "trial: 3, iter: 1600, curr loss: 1.386666178703308, avg loss: 1.3864332449436187\n",
      "trial: 3, iter: 1800, curr loss: 1.3868168592453003, avg loss: 1.3863720911741257\n",
      "trial: 3, iter: 2000, curr loss: 1.3853892087936401, avg loss: 1.3864230817556382\n",
      "trial: 3, iter: 2200, curr loss: 1.386616587638855, avg loss: 1.3863919216394425\n",
      "trial: 3, iter: 2400, curr loss: 1.3865851163864136, avg loss: 1.3863385915756226\n",
      "trial: 3, iter: 2600, curr loss: 1.3861019611358643, avg loss: 1.3863425987958908\n",
      "trial: 3, iter: 2800, curr loss: 1.3859285116195679, avg loss: 1.38637331366539\n",
      "trial: 3, iter: 3000, curr loss: 1.3860095739364624, avg loss: 1.3862999987602234\n",
      "trial: 3, iter: 3200, curr loss: 1.386064052581787, avg loss: 1.3863560062646867\n",
      "trial: 3, iter: 3400, curr loss: 1.3863660097122192, avg loss: 1.386334474682808\n",
      "trial: 3, iter: 3600, curr loss: 1.3869589567184448, avg loss: 1.3863536632061004\n",
      "trial: 3, iter: 3800, curr loss: 1.3865833282470703, avg loss: 1.3863396698236465\n",
      "trial: 3, iter: 4000, curr loss: 1.3859267234802246, avg loss: 1.386341677904129\n",
      "trial: 3, iter: 4200, curr loss: 1.3863378763198853, avg loss: 1.3863661205768585\n",
      "trial: 3, iter: 4400, curr loss: 1.3867946863174438, avg loss: 1.3863202470541\n",
      "trial: 3, iter: 4600, curr loss: 1.3862760066986084, avg loss: 1.3863703960180283\n",
      "trial: 3, iter: 4800, curr loss: 1.3862227201461792, avg loss: 1.386326020359993\n",
      "trial: 3, iter: 5000, curr loss: 1.386400818824768, avg loss: 1.3862884491682053\n",
      "trial: 3, iter: 5200, curr loss: 1.3860440254211426, avg loss: 1.386311689019203\n",
      "trial: 3, iter: 5400, curr loss: 1.3861695528030396, avg loss: 1.386295318007469\n",
      "trial: 3, iter: 5600, curr loss: 1.3863328695297241, avg loss: 1.3863703691959381\n",
      "trial: 3, iter: 5800, curr loss: 1.3864425420761108, avg loss: 1.386374182701111\n",
      "trial: 3, iter: 6000, curr loss: 1.3863226175308228, avg loss: 1.3863088285923004\n",
      "trial: 3, iter: 6200, curr loss: 1.3860273361206055, avg loss: 1.3863074320554734\n",
      "trial: 3, iter: 6400, curr loss: 1.3861578702926636, avg loss: 1.3863168954849243\n",
      "trial: 3, iter: 6600, curr loss: 1.3864814043045044, avg loss: 1.3863207930326462\n",
      "trial: 3, iter: 6800, curr loss: 1.3874386548995972, avg loss: 1.3862901246547699\n",
      "trial: 3, iter: 7000, curr loss: 1.3863688707351685, avg loss: 1.3863387268781662\n",
      "trial: 3, iter: 7200, curr loss: 1.3867181539535522, avg loss: 1.386314662694931\n",
      "trial: 3, iter: 7400, curr loss: 1.3866708278656006, avg loss: 1.3863025838136673\n",
      "trial: 3, iter: 7600, curr loss: 1.3858492374420166, avg loss: 1.3862948715686798\n",
      "trial: 3, iter: 7800, curr loss: 1.3862035274505615, avg loss: 1.386312558054924\n",
      "trial: 3, iter: 8000, curr loss: 1.3862264156341553, avg loss: 1.3863141924142837\n",
      "trial: 3, iter: 8200, curr loss: 1.3862894773483276, avg loss: 1.3862774592638016\n",
      "trial: 3, iter: 8400, curr loss: 1.38663649559021, avg loss: 1.3863319832086562\n",
      "trial: 3, iter: 8600, curr loss: 1.3867765665054321, avg loss: 1.3862841111421584\n",
      "trial: 3, iter: 8800, curr loss: 1.3866058588027954, avg loss: 1.3863854336738586\n",
      "trial: 3, iter: 9000, curr loss: 1.3862905502319336, avg loss: 1.3863299202919006\n",
      "trial: 3, iter: 9200, curr loss: 1.386484980583191, avg loss: 1.3862880289554596\n",
      "trial: 3, iter: 9400, curr loss: 1.3865532875061035, avg loss: 1.3863050937652588\n",
      "trial: 3, iter: 9600, curr loss: 1.386080026626587, avg loss: 1.386355676651001\n",
      "trial: 3, iter: 9800, curr loss: 1.3863784074783325, avg loss: 1.3863337260484696\n",
      "trial: 3, iter: 10000, curr loss: 1.3865385055541992, avg loss: 1.3863063961267472\n",
      "trial: 3, iter: 10200, curr loss: 1.3859539031982422, avg loss: 1.3863240158557892\n",
      "trial: 3, iter: 10400, curr loss: 1.3864643573760986, avg loss: 1.386324577331543\n",
      "trial: 3, iter: 10600, curr loss: 1.386358380317688, avg loss: 1.3863110238313674\n",
      "trial: 3, iter: 10800, curr loss: 1.3863660097122192, avg loss: 1.3863111490011215\n",
      "trial: 3, iter: 11000, curr loss: 1.3861569166183472, avg loss: 1.3863006323575973\n",
      "trial: 3, iter: 11200, curr loss: 1.386258602142334, avg loss: 1.386323002576828\n",
      "trial: 3, iter: 11400, curr loss: 1.386208415031433, avg loss: 1.3862959629297256\n",
      "trial: 3, iter: 11600, curr loss: 1.3861713409423828, avg loss: 1.3863091492652893\n",
      "trial: 3, iter: 11800, curr loss: 1.3862392902374268, avg loss: 1.3863057899475097\n",
      "trial: 3, iter: 12000, curr loss: 1.3862072229385376, avg loss: 1.3863045901060105\n",
      "trial: 3, iter: 12200, curr loss: 1.386062741279602, avg loss: 1.3863097250461578\n",
      "trial: 3, iter: 12400, curr loss: 1.3863779306411743, avg loss: 1.386307000517845\n",
      "trial: 3, iter: 12600, curr loss: 1.3863308429718018, avg loss: 1.3863181048631668\n",
      "trial: 3, iter: 12800, curr loss: 1.3862946033477783, avg loss: 1.3862974113225937\n",
      "trial: 3, iter: 13000, curr loss: 1.3862016201019287, avg loss: 1.3863016974925995\n",
      "trial: 3, iter: 13200, curr loss: 1.386343240737915, avg loss: 1.3863084536790848\n",
      "trial: 3, iter: 13400, curr loss: 1.3863812685012817, avg loss: 1.3863046151399612\n",
      "trial: 3, iter: 13600, curr loss: 1.3862558603286743, avg loss: 1.3863098168373107\n",
      "trial: 3, iter: 13800, curr loss: 1.3863630294799805, avg loss: 1.3863071817159653\n",
      "trial: 3, iter: 14000, curr loss: 1.3864002227783203, avg loss: 1.3863078832626343\n",
      "trial: 3, iter: 14200, curr loss: 1.386249303817749, avg loss: 1.386328451037407\n",
      "trial: 3, iter: 14400, curr loss: 1.3863393068313599, avg loss: 1.386298263669014\n",
      "trial: 3, iter: 14600, curr loss: 1.3861421346664429, avg loss: 1.386298747062683\n",
      "trial: 3, iter: 14800, curr loss: 1.3862873315811157, avg loss: 1.3863050425052643\n",
      "trial: 3, iter: 15000, curr loss: 1.3862717151641846, avg loss: 1.386296973824501\n",
      "trial: 3, iter: 15200, curr loss: 1.3863005638122559, avg loss: 1.3862944453954698\n",
      "trial: 3, iter: 15400, curr loss: 1.3862950801849365, avg loss: 1.3862911957502364\n",
      "trial: 3, iter: 15600, curr loss: 1.3862942457199097, avg loss: 1.386296373605728\n",
      "trial: 3, ldr: -1.8512285748784052e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3870880603790283, avg loss: 1.3876350378990174\n",
      "trial: 4, iter: 400, curr loss: 1.3893485069274902, avg loss: 1.3866067570447922\n",
      "trial: 4, iter: 600, curr loss: 1.3872056007385254, avg loss: 1.386737003326416\n",
      "trial: 4, iter: 800, curr loss: 1.3853644132614136, avg loss: 1.3865018033981322\n",
      "trial: 4, iter: 1000, curr loss: 1.387476921081543, avg loss: 1.3866639184951781\n",
      "trial: 4, iter: 1200, curr loss: 1.3840211629867554, avg loss: 1.3864139580726624\n",
      "trial: 4, iter: 1400, curr loss: 1.3871582746505737, avg loss: 1.3864448487758636\n",
      "trial: 4, iter: 1600, curr loss: 1.3858630657196045, avg loss: 1.3864750868082047\n",
      "trial: 4, iter: 1800, curr loss: 1.386235237121582, avg loss: 1.3863244956731797\n",
      "trial: 4, iter: 2000, curr loss: 1.3876075744628906, avg loss: 1.3863907420635224\n",
      "trial: 4, iter: 2200, curr loss: 1.386399745941162, avg loss: 1.3863297563791275\n",
      "trial: 4, iter: 2400, curr loss: 1.3875573873519897, avg loss: 1.3863351494073868\n",
      "trial: 4, iter: 2600, curr loss: 1.3863818645477295, avg loss: 1.3864513218402863\n",
      "trial: 4, iter: 2800, curr loss: 1.3877663612365723, avg loss: 1.3863478326797485\n",
      "trial: 4, iter: 3000, curr loss: 1.3855265378952026, avg loss: 1.386329802274704\n",
      "trial: 4, iter: 3200, curr loss: 1.386596441268921, avg loss: 1.3864526128768921\n",
      "trial: 4, iter: 3400, curr loss: 1.386430025100708, avg loss: 1.3863394361734391\n",
      "trial: 4, iter: 3600, curr loss: 1.3860183954238892, avg loss: 1.386326329112053\n",
      "trial: 4, iter: 3800, curr loss: 1.385923147201538, avg loss: 1.3863858598470689\n",
      "trial: 4, iter: 4000, curr loss: 1.385824203491211, avg loss: 1.3863021194934846\n",
      "trial: 4, iter: 4200, curr loss: 1.3870527744293213, avg loss: 1.3863214075565338\n",
      "trial: 4, iter: 4400, curr loss: 1.38703453540802, avg loss: 1.3863536268472672\n",
      "trial: 4, iter: 4600, curr loss: 1.386785864830017, avg loss: 1.3863421046733857\n",
      "trial: 4, iter: 4800, curr loss: 1.3856626749038696, avg loss: 1.3863098579645157\n",
      "trial: 4, iter: 5000, curr loss: 1.3869465589523315, avg loss: 1.3863350516557693\n",
      "trial: 4, iter: 5200, curr loss: 1.3860384225845337, avg loss: 1.3863224744796754\n",
      "trial: 4, iter: 5400, curr loss: 1.3862004280090332, avg loss: 1.3863442790508271\n",
      "trial: 4, iter: 5600, curr loss: 1.3868069648742676, avg loss: 1.386317390203476\n",
      "trial: 4, iter: 5800, curr loss: 1.3869878053665161, avg loss: 1.386272679567337\n",
      "trial: 4, iter: 6000, curr loss: 1.387381911277771, avg loss: 1.38632275223732\n",
      "trial: 4, iter: 6200, curr loss: 1.3868887424468994, avg loss: 1.3863308942317962\n",
      "trial: 4, iter: 6400, curr loss: 1.3860827684402466, avg loss: 1.3863385313749312\n",
      "trial: 4, iter: 6600, curr loss: 1.3862435817718506, avg loss: 1.3863010948896408\n",
      "trial: 4, iter: 6800, curr loss: 1.3861618041992188, avg loss: 1.3863363480567932\n",
      "trial: 4, iter: 7000, curr loss: 1.3868277072906494, avg loss: 1.3863031911849975\n",
      "trial: 4, iter: 7200, curr loss: 1.387241005897522, avg loss: 1.3862779283523559\n",
      "trial: 4, iter: 7400, curr loss: 1.3867955207824707, avg loss: 1.3863918054103852\n",
      "trial: 4, iter: 7600, curr loss: 1.3878270387649536, avg loss: 1.386380199790001\n",
      "trial: 4, iter: 7800, curr loss: 1.386296272277832, avg loss: 1.3863800543546676\n",
      "trial: 4, iter: 8000, curr loss: 1.3866690397262573, avg loss: 1.3863340717554093\n",
      "trial: 4, iter: 8200, curr loss: 1.3867403268814087, avg loss: 1.38635657787323\n",
      "trial: 4, iter: 8400, curr loss: 1.3863588571548462, avg loss: 1.3863313865661622\n",
      "trial: 4, iter: 8600, curr loss: 1.3861563205718994, avg loss: 1.386310754418373\n",
      "trial: 4, iter: 8800, curr loss: 1.3860723972320557, avg loss: 1.386312074661255\n",
      "trial: 4, iter: 9000, curr loss: 1.3868129253387451, avg loss: 1.3863723248243331\n",
      "trial: 4, iter: 9200, curr loss: 1.3868112564086914, avg loss: 1.386290681362152\n",
      "trial: 4, iter: 9400, curr loss: 1.385873556137085, avg loss: 1.386336514353752\n",
      "trial: 4, iter: 9600, curr loss: 1.3871734142303467, avg loss: 1.3863295590877533\n",
      "trial: 4, iter: 9800, curr loss: 1.3864132165908813, avg loss: 1.386325535774231\n",
      "trial: 4, iter: 10000, curr loss: 1.3866384029388428, avg loss: 1.386348437666893\n",
      "trial: 4, iter: 10200, curr loss: 1.3862227201461792, avg loss: 1.3863033151626587\n",
      "trial: 4, iter: 10400, curr loss: 1.3864864110946655, avg loss: 1.3863211560249329\n",
      "trial: 4, iter: 10600, curr loss: 1.3867300748825073, avg loss: 1.386337495446205\n",
      "trial: 4, iter: 10800, curr loss: 1.3862417936325073, avg loss: 1.3863412022590638\n",
      "trial: 4, iter: 11000, curr loss: 1.3864399194717407, avg loss: 1.3862944227457046\n",
      "trial: 4, iter: 11200, curr loss: 1.3862011432647705, avg loss: 1.3863145703077315\n",
      "trial: 4, iter: 11400, curr loss: 1.3862226009368896, avg loss: 1.3862965643405913\n",
      "trial: 4, iter: 11600, curr loss: 1.3868941068649292, avg loss: 1.386329466700554\n",
      "trial: 4, iter: 11800, curr loss: 1.3863390684127808, avg loss: 1.3863161873817444\n",
      "trial: 4, iter: 12000, curr loss: 1.3863964080810547, avg loss: 1.3863108837604523\n",
      "trial: 4, iter: 12200, curr loss: 1.3862371444702148, avg loss: 1.386298788189888\n",
      "trial: 4, iter: 12400, curr loss: 1.386112093925476, avg loss: 1.3862910330295564\n",
      "trial: 4, iter: 12600, curr loss: 1.3863216638565063, avg loss: 1.3863223850727082\n",
      "trial: 4, iter: 12800, curr loss: 1.3865481615066528, avg loss: 1.386316248178482\n",
      "trial: 4, iter: 13000, curr loss: 1.3865240812301636, avg loss: 1.3863054436445237\n",
      "trial: 4, iter: 13200, curr loss: 1.3862091302871704, avg loss: 1.3863151556253432\n",
      "trial: 4, iter: 13400, curr loss: 1.3862756490707397, avg loss: 1.3862995982170105\n",
      "trial: 4, iter: 13600, curr loss: 1.3864002227783203, avg loss: 1.3862961500883102\n",
      "trial: 4, iter: 13800, curr loss: 1.386380672454834, avg loss: 1.3862925398349761\n",
      "trial: 4, iter: 14000, curr loss: 1.386292576789856, avg loss: 1.386296140551567\n",
      "trial: 4, iter: 14200, curr loss: 1.3863035440444946, avg loss: 1.3862944322824478\n",
      "trial: 4, iter: 14400, curr loss: 1.3862943649291992, avg loss: 1.3862951904535294\n",
      "trial: 4, iter: 14600, curr loss: 1.3862838745117188, avg loss: 1.3862942498922348\n",
      "trial: 4, iter: 14800, curr loss: 1.3862864971160889, avg loss: 1.3862945127487183\n",
      "trial: 4, iter: 15000, curr loss: 1.386300802230835, avg loss: 1.3862938016653061\n",
      "trial: 4, iter: 15200, curr loss: 1.3862948417663574, avg loss: 1.3862953138351441\n",
      "trial: 4, iter: 15400, curr loss: 1.386526107788086, avg loss: 1.3863277411460877\n",
      "trial: 4, iter: 15600, curr loss: 1.3862828016281128, avg loss: 1.386322596669197\n",
      "trial: 4, ldr: 0.00020989959011785686\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.388366937637329, avg loss: 1.3870835375785828\n",
      "trial: 5, iter: 400, curr loss: 1.3882899284362793, avg loss: 1.3867794102430344\n",
      "trial: 5, iter: 600, curr loss: 1.3870354890823364, avg loss: 1.386607459783554\n",
      "trial: 5, iter: 800, curr loss: 1.3871874809265137, avg loss: 1.3865744435787202\n",
      "trial: 5, iter: 1000, curr loss: 1.3858540058135986, avg loss: 1.3864688885211944\n",
      "trial: 5, iter: 1200, curr loss: 1.38554847240448, avg loss: 1.3863567537069321\n",
      "trial: 5, iter: 1400, curr loss: 1.3872543573379517, avg loss: 1.3864139717817308\n",
      "trial: 5, iter: 1600, curr loss: 1.3854506015777588, avg loss: 1.3864541852474213\n",
      "trial: 5, iter: 1800, curr loss: 1.3879563808441162, avg loss: 1.3864274573326112\n",
      "trial: 5, iter: 2000, curr loss: 1.3860782384872437, avg loss: 1.3863904964923859\n",
      "trial: 5, iter: 2200, curr loss: 1.3864827156066895, avg loss: 1.3864111423492431\n",
      "trial: 5, iter: 2400, curr loss: 1.3866947889328003, avg loss: 1.386366758942604\n",
      "trial: 5, iter: 2600, curr loss: 1.3861593008041382, avg loss: 1.3863560158014296\n",
      "trial: 5, iter: 2800, curr loss: 1.386250376701355, avg loss: 1.3863027048110963\n",
      "trial: 5, iter: 3000, curr loss: 1.3865660429000854, avg loss: 1.386348584294319\n",
      "trial: 5, iter: 3200, curr loss: 1.3861424922943115, avg loss: 1.3863446974754334\n",
      "trial: 5, iter: 3400, curr loss: 1.3859721422195435, avg loss: 1.3862930113077163\n",
      "trial: 5, iter: 3600, curr loss: 1.3862385749816895, avg loss: 1.3863587033748628\n",
      "trial: 5, iter: 3800, curr loss: 1.3867887258529663, avg loss: 1.3863761830329895\n",
      "trial: 5, iter: 4000, curr loss: 1.3857735395431519, avg loss: 1.386334428191185\n",
      "trial: 5, iter: 4200, curr loss: 1.3861485719680786, avg loss: 1.3863892447948456\n",
      "trial: 5, iter: 4400, curr loss: 1.3862128257751465, avg loss: 1.386327338218689\n",
      "trial: 5, iter: 4600, curr loss: 1.386385202407837, avg loss: 1.3863292610645295\n",
      "trial: 5, iter: 4800, curr loss: 1.3865385055541992, avg loss: 1.3862961721420288\n",
      "trial: 5, iter: 5000, curr loss: 1.3860081434249878, avg loss: 1.3862949568033218\n",
      "trial: 5, iter: 5200, curr loss: 1.3868211507797241, avg loss: 1.3863513964414595\n",
      "trial: 5, iter: 5400, curr loss: 1.3864824771881104, avg loss: 1.3863211727142335\n",
      "trial: 5, iter: 5600, curr loss: 1.3862413167953491, avg loss: 1.3862860625982285\n",
      "trial: 5, iter: 5800, curr loss: 1.3865101337432861, avg loss: 1.386346043944359\n",
      "trial: 5, iter: 6000, curr loss: 1.3861273527145386, avg loss: 1.3862960880994797\n",
      "trial: 5, iter: 6200, curr loss: 1.3865175247192383, avg loss: 1.386295758485794\n",
      "trial: 5, iter: 6400, curr loss: 1.3862898349761963, avg loss: 1.3863094937801361\n",
      "trial: 5, iter: 6600, curr loss: 1.3862398862838745, avg loss: 1.386331668496132\n",
      "trial: 5, iter: 6800, curr loss: 1.3869802951812744, avg loss: 1.386314321756363\n",
      "trial: 5, iter: 7000, curr loss: 1.386410117149353, avg loss: 1.386343919634819\n",
      "trial: 5, iter: 7200, curr loss: 1.3864320516586304, avg loss: 1.3863567233085632\n",
      "trial: 5, iter: 7400, curr loss: 1.3860752582550049, avg loss: 1.3863059318065643\n",
      "trial: 5, iter: 7600, curr loss: 1.3863507509231567, avg loss: 1.3863230270147324\n",
      "trial: 5, iter: 7800, curr loss: 1.3857203722000122, avg loss: 1.3862254351377488\n",
      "trial: 5, iter: 8000, curr loss: 1.3861931562423706, avg loss: 1.3863839203119277\n",
      "trial: 5, iter: 8200, curr loss: 1.3858033418655396, avg loss: 1.3862798714637756\n",
      "trial: 5, iter: 8400, curr loss: 1.3861324787139893, avg loss: 1.3863423055410384\n",
      "trial: 5, iter: 8600, curr loss: 1.3868534564971924, avg loss: 1.3863208627700805\n",
      "trial: 5, iter: 8800, curr loss: 1.3871108293533325, avg loss: 1.386329887509346\n",
      "trial: 5, iter: 9000, curr loss: 1.3863824605941772, avg loss: 1.3863167196512223\n",
      "trial: 5, iter: 9200, curr loss: 1.3861416578292847, avg loss: 1.3863288104534148\n",
      "trial: 5, iter: 9400, curr loss: 1.386141061782837, avg loss: 1.3862995541095733\n",
      "trial: 5, iter: 9600, curr loss: 1.3863956928253174, avg loss: 1.3863150650262832\n",
      "trial: 5, iter: 9800, curr loss: 1.3860905170440674, avg loss: 1.386295673251152\n",
      "trial: 5, iter: 10000, curr loss: 1.3864519596099854, avg loss: 1.3863096612691879\n",
      "trial: 5, iter: 10200, curr loss: 1.3862805366516113, avg loss: 1.3863149970769881\n",
      "trial: 5, iter: 10400, curr loss: 1.3871080875396729, avg loss: 1.3863377767801284\n",
      "trial: 5, iter: 10600, curr loss: 1.3858275413513184, avg loss: 1.3864728778600692\n",
      "trial: 5, iter: 10800, curr loss: 1.3861668109893799, avg loss: 1.3863871085643769\n",
      "trial: 5, iter: 11000, curr loss: 1.3866939544677734, avg loss: 1.3863682478666306\n",
      "trial: 5, iter: 11200, curr loss: 1.3860867023468018, avg loss: 1.3863087475299836\n",
      "trial: 5, iter: 11400, curr loss: 1.3868536949157715, avg loss: 1.3863033169507981\n",
      "trial: 5, iter: 11600, curr loss: 1.3866201639175415, avg loss: 1.3863210433721542\n",
      "trial: 5, iter: 11800, curr loss: 1.3861939907073975, avg loss: 1.3863125282526017\n",
      "trial: 5, iter: 12000, curr loss: 1.3864972591400146, avg loss: 1.3862934547662735\n",
      "trial: 5, iter: 12200, curr loss: 1.3860963582992554, avg loss: 1.3863154250383376\n",
      "trial: 5, iter: 12400, curr loss: 1.3859138488769531, avg loss: 1.3862227404117584\n",
      "trial: 5, iter: 12600, curr loss: 1.3858027458190918, avg loss: 1.3863050049543382\n",
      "trial: 5, iter: 12800, curr loss: 1.3860124349594116, avg loss: 1.3863263195753097\n",
      "trial: 5, iter: 13000, curr loss: 1.3862720727920532, avg loss: 1.3862989413738251\n",
      "trial: 5, iter: 13200, curr loss: 1.3861514329910278, avg loss: 1.38632086455822\n",
      "trial: 5, iter: 13400, curr loss: 1.3864144086837769, avg loss: 1.386324469447136\n",
      "trial: 5, iter: 13600, curr loss: 1.386271357536316, avg loss: 1.3863054835796356\n",
      "trial: 5, iter: 13800, curr loss: 1.386365532875061, avg loss: 1.3862898683547973\n",
      "trial: 5, iter: 14000, curr loss: 1.3862535953521729, avg loss: 1.3863085329532623\n",
      "trial: 5, iter: 14200, curr loss: 1.38613760471344, avg loss: 1.3863486647605896\n",
      "trial: 5, iter: 14400, curr loss: 1.3860560655593872, avg loss: 1.3863117402791978\n",
      "trial: 5, iter: 14600, curr loss: 1.3863699436187744, avg loss: 1.3862984430789949\n",
      "trial: 5, iter: 14800, curr loss: 1.3865286111831665, avg loss: 1.386340342760086\n",
      "trial: 5, iter: 15000, curr loss: 1.385982632637024, avg loss: 1.3863018143177033\n",
      "trial: 5, iter: 15200, curr loss: 1.3865158557891846, avg loss: 1.3863019859790802\n",
      "trial: 5, iter: 15400, curr loss: 1.38645339012146, avg loss: 1.386310219168663\n",
      "trial: 5, iter: 15600, curr loss: 1.386122703552246, avg loss: 1.3863154870271683\n",
      "trial: 5, ldr: 7.891921086411458e-06\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0004231691210833333\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3903825283050537, avg loss: 1.387687793970108\n",
      "trial: 1, iter: 400, curr loss: 1.3878616094589233, avg loss: 1.38691470682621\n",
      "trial: 1, iter: 600, curr loss: 1.3871556520462036, avg loss: 1.3867679643630981\n",
      "trial: 1, iter: 800, curr loss: 1.3873076438903809, avg loss: 1.3864530193805695\n",
      "trial: 1, iter: 1000, curr loss: 1.3859435319900513, avg loss: 1.386633347272873\n",
      "trial: 1, iter: 1200, curr loss: 1.3875908851623535, avg loss: 1.386523111462593\n",
      "trial: 1, iter: 1400, curr loss: 1.3869494199752808, avg loss: 1.3864609444141387\n",
      "trial: 1, iter: 1600, curr loss: 1.3856264352798462, avg loss: 1.3864355689287187\n",
      "trial: 1, iter: 1800, curr loss: 1.3864991664886475, avg loss: 1.3864398699998857\n",
      "trial: 1, iter: 2000, curr loss: 1.3862239122390747, avg loss: 1.3864016157388688\n",
      "trial: 1, iter: 2200, curr loss: 1.3864620923995972, avg loss: 1.3863782805204392\n",
      "trial: 1, iter: 2400, curr loss: 1.3852870464324951, avg loss: 1.3863496375083924\n",
      "trial: 1, iter: 2600, curr loss: 1.3868848085403442, avg loss: 1.386402792930603\n",
      "trial: 1, iter: 2800, curr loss: 1.3864953517913818, avg loss: 1.3863265246152878\n",
      "trial: 1, iter: 3000, curr loss: 1.3867510557174683, avg loss: 1.3863972210884095\n",
      "trial: 1, iter: 3200, curr loss: 1.386494517326355, avg loss: 1.3863340628147125\n",
      "trial: 1, iter: 3400, curr loss: 1.3865978717803955, avg loss: 1.3863177317380906\n",
      "trial: 1, iter: 3600, curr loss: 1.3861066102981567, avg loss: 1.3863517034053803\n",
      "trial: 1, iter: 3800, curr loss: 1.3863484859466553, avg loss: 1.3862892669439315\n",
      "trial: 1, iter: 4000, curr loss: 1.386215090751648, avg loss: 1.386310566663742\n",
      "trial: 1, iter: 4200, curr loss: 1.3860325813293457, avg loss: 1.3863047862052917\n",
      "trial: 1, iter: 4400, curr loss: 1.3860726356506348, avg loss: 1.3863013201951981\n",
      "trial: 1, iter: 4600, curr loss: 1.3863221406936646, avg loss: 1.3863312518596649\n",
      "trial: 1, iter: 4800, curr loss: 1.3869187831878662, avg loss: 1.3863007628917694\n",
      "trial: 1, iter: 5000, curr loss: 1.3859602212905884, avg loss: 1.3863087338209152\n",
      "trial: 1, iter: 5200, curr loss: 1.3867555856704712, avg loss: 1.3863343411684037\n",
      "trial: 1, iter: 5400, curr loss: 1.38681161403656, avg loss: 1.3862853479385375\n",
      "trial: 1, iter: 5600, curr loss: 1.3856889009475708, avg loss: 1.3863225716352463\n",
      "trial: 1, iter: 5800, curr loss: 1.3862017393112183, avg loss: 1.3863111001253128\n",
      "trial: 1, iter: 6000, curr loss: 1.386742353439331, avg loss: 1.3864068841934205\n",
      "trial: 1, iter: 6200, curr loss: 1.3863259553909302, avg loss: 1.3863878905773164\n",
      "trial: 1, iter: 6400, curr loss: 1.3858851194381714, avg loss: 1.3863822305202484\n",
      "trial: 1, iter: 6600, curr loss: 1.3860605955123901, avg loss: 1.3863137608766556\n",
      "trial: 1, iter: 6800, curr loss: 1.386067271232605, avg loss: 1.3864134126901626\n",
      "trial: 1, iter: 7000, curr loss: 1.386087417602539, avg loss: 1.386331351995468\n",
      "trial: 1, iter: 7200, curr loss: 1.386508822441101, avg loss: 1.3863682556152344\n",
      "trial: 1, iter: 7400, curr loss: 1.386636734008789, avg loss: 1.3864055013656615\n",
      "trial: 1, iter: 7600, curr loss: 1.386777400970459, avg loss: 1.386309130191803\n",
      "trial: 1, iter: 7800, curr loss: 1.386763095855713, avg loss: 1.3863710737228394\n",
      "trial: 1, iter: 8000, curr loss: 1.3864760398864746, avg loss: 1.386332306265831\n",
      "trial: 1, iter: 8200, curr loss: 1.386557936668396, avg loss: 1.3863120102882385\n",
      "trial: 1, iter: 8400, curr loss: 1.3858749866485596, avg loss: 1.3862870520353316\n",
      "trial: 1, iter: 8600, curr loss: 1.385973334312439, avg loss: 1.3863178944587708\n",
      "trial: 1, iter: 8800, curr loss: 1.3860396146774292, avg loss: 1.3863243925571442\n",
      "trial: 1, iter: 9000, curr loss: 1.386414647102356, avg loss: 1.3862943363189697\n",
      "trial: 1, iter: 9200, curr loss: 1.3866671323776245, avg loss: 1.3863868814706803\n",
      "trial: 1, iter: 9400, curr loss: 1.3860286474227905, avg loss: 1.38632115483284\n",
      "trial: 1, iter: 9600, curr loss: 1.38650381565094, avg loss: 1.3864075982570647\n",
      "trial: 1, iter: 9800, curr loss: 1.3865866661071777, avg loss: 1.386303637623787\n",
      "trial: 1, iter: 10000, curr loss: 1.3865528106689453, avg loss: 1.3863246566057206\n",
      "trial: 1, iter: 10200, curr loss: 1.3867944478988647, avg loss: 1.3863186126947402\n",
      "trial: 1, iter: 10400, curr loss: 1.3859883546829224, avg loss: 1.3863632094860077\n",
      "trial: 1, iter: 10600, curr loss: 1.386169672012329, avg loss: 1.386365162730217\n",
      "trial: 1, iter: 10800, curr loss: 1.386098861694336, avg loss: 1.3863042908906937\n",
      "trial: 1, iter: 11000, curr loss: 1.386478304862976, avg loss: 1.386333641409874\n",
      "trial: 1, iter: 11200, curr loss: 1.38661789894104, avg loss: 1.3862891733646392\n",
      "trial: 1, iter: 11400, curr loss: 1.3866796493530273, avg loss: 1.3863082504272461\n",
      "trial: 1, iter: 11600, curr loss: 1.3861807584762573, avg loss: 1.3863298195600509\n",
      "trial: 1, iter: 11800, curr loss: 1.386417031288147, avg loss: 1.3863171881437302\n",
      "trial: 1, iter: 12000, curr loss: 1.3868381977081299, avg loss: 1.386292200088501\n",
      "trial: 1, iter: 12200, curr loss: 1.386603832244873, avg loss: 1.3863265985250472\n",
      "trial: 1, iter: 12400, curr loss: 1.3862895965576172, avg loss: 1.3863007068634032\n",
      "trial: 1, iter: 12600, curr loss: 1.3868910074234009, avg loss: 1.3863140338659286\n",
      "trial: 1, iter: 12800, curr loss: 1.3857917785644531, avg loss: 1.3862896955013275\n",
      "trial: 1, iter: 13000, curr loss: 1.386583685874939, avg loss: 1.386348922252655\n",
      "trial: 1, iter: 13200, curr loss: 1.3862420320510864, avg loss: 1.386294532418251\n",
      "trial: 1, iter: 13400, curr loss: 1.3863011598587036, avg loss: 1.3863184893131255\n",
      "trial: 1, iter: 13600, curr loss: 1.3863990306854248, avg loss: 1.3862968933582307\n",
      "trial: 1, iter: 13800, curr loss: 1.3869640827178955, avg loss: 1.3862955355644226\n",
      "trial: 1, iter: 14000, curr loss: 1.3872572183609009, avg loss: 1.3863184332847596\n",
      "trial: 1, iter: 14200, curr loss: 1.385919451713562, avg loss: 1.3863060730695724\n",
      "trial: 1, iter: 14400, curr loss: 1.3861511945724487, avg loss: 1.3863230270147324\n",
      "trial: 1, iter: 14600, curr loss: 1.3861547708511353, avg loss: 1.386301365494728\n",
      "trial: 1, iter: 14800, curr loss: 1.386527419090271, avg loss: 1.3863067144155503\n",
      "trial: 1, iter: 15000, curr loss: 1.3861647844314575, avg loss: 1.3862992715835571\n",
      "trial: 1, iter: 15200, curr loss: 1.3859786987304688, avg loss: 1.3863171362876892\n",
      "trial: 1, iter: 15400, curr loss: 1.386263132095337, avg loss: 1.3862887793779373\n",
      "trial: 1, iter: 15600, curr loss: 1.3863213062286377, avg loss: 1.3863183051347732\n",
      "trial: 1, ldr: 0.000425742327934131\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3846148252487183, avg loss: 1.3870931077003479\n",
      "trial: 2, iter: 400, curr loss: 1.3860327005386353, avg loss: 1.3866867566108703\n",
      "trial: 2, iter: 600, curr loss: 1.3849238157272339, avg loss: 1.386551072001457\n",
      "trial: 2, iter: 800, curr loss: 1.3874750137329102, avg loss: 1.3864347845315934\n",
      "trial: 2, iter: 1000, curr loss: 1.3872016668319702, avg loss: 1.3863883805274964\n",
      "trial: 2, iter: 1200, curr loss: 1.3869434595108032, avg loss: 1.3864125925302506\n",
      "trial: 2, iter: 1400, curr loss: 1.3861202001571655, avg loss: 1.3864482808113099\n",
      "trial: 2, iter: 1600, curr loss: 1.3860485553741455, avg loss: 1.3863523495197296\n",
      "trial: 2, iter: 1800, curr loss: 1.385591983795166, avg loss: 1.386424155831337\n",
      "trial: 2, iter: 2000, curr loss: 1.3863831758499146, avg loss: 1.386319419145584\n",
      "trial: 2, iter: 2200, curr loss: 1.3866174221038818, avg loss: 1.3863445061445236\n",
      "trial: 2, iter: 2400, curr loss: 1.386267900466919, avg loss: 1.386378771662712\n",
      "trial: 2, iter: 2600, curr loss: 1.386154055595398, avg loss: 1.3863827639818191\n",
      "trial: 2, iter: 2800, curr loss: 1.3863921165466309, avg loss: 1.3863011765480042\n",
      "trial: 2, iter: 3000, curr loss: 1.386910080909729, avg loss: 1.3863191509246826\n",
      "trial: 2, iter: 3200, curr loss: 1.3863487243652344, avg loss: 1.3863405233621597\n",
      "trial: 2, iter: 3400, curr loss: 1.3870878219604492, avg loss: 1.3863888186216355\n",
      "trial: 2, iter: 3600, curr loss: 1.386385440826416, avg loss: 1.3863437116146087\n",
      "trial: 2, iter: 3800, curr loss: 1.3865078687667847, avg loss: 1.386337639093399\n",
      "trial: 2, iter: 4000, curr loss: 1.386383056640625, avg loss: 1.386298656463623\n",
      "trial: 2, iter: 4200, curr loss: 1.3864399194717407, avg loss: 1.3863944798707961\n",
      "trial: 2, iter: 4400, curr loss: 1.3859554529190063, avg loss: 1.3863566410541535\n",
      "trial: 2, iter: 4600, curr loss: 1.386540412902832, avg loss: 1.3863330256938935\n",
      "trial: 2, iter: 4800, curr loss: 1.3870652914047241, avg loss: 1.3862947922945024\n",
      "trial: 2, iter: 5000, curr loss: 1.3867145776748657, avg loss: 1.3863420498371124\n",
      "trial: 2, iter: 5200, curr loss: 1.3855071067810059, avg loss: 1.3863493049144744\n",
      "trial: 2, iter: 5400, curr loss: 1.386937141418457, avg loss: 1.3863473278284073\n",
      "trial: 2, iter: 5600, curr loss: 1.385561227798462, avg loss: 1.3863038176298141\n",
      "trial: 2, iter: 5800, curr loss: 1.386427640914917, avg loss: 1.386326423883438\n",
      "trial: 2, iter: 6000, curr loss: 1.385928750038147, avg loss: 1.3863110727071761\n",
      "trial: 2, iter: 6200, curr loss: 1.3860822916030884, avg loss: 1.3863407742977143\n",
      "trial: 2, iter: 6400, curr loss: 1.3859063386917114, avg loss: 1.3863093358278276\n",
      "trial: 2, iter: 6600, curr loss: 1.3861266374588013, avg loss: 1.3863228678703308\n",
      "trial: 2, iter: 6800, curr loss: 1.3863873481750488, avg loss: 1.3863128489255905\n",
      "trial: 2, iter: 7000, curr loss: 1.386634349822998, avg loss: 1.386318962574005\n",
      "trial: 2, iter: 7200, curr loss: 1.3856472969055176, avg loss: 1.3863225501775742\n",
      "trial: 2, iter: 7400, curr loss: 1.3867665529251099, avg loss: 1.386347114443779\n",
      "trial: 2, iter: 7600, curr loss: 1.3863555192947388, avg loss: 1.386300983428955\n",
      "trial: 2, iter: 7800, curr loss: 1.3868283033370972, avg loss: 1.386309918165207\n",
      "trial: 2, iter: 8000, curr loss: 1.386438250541687, avg loss: 1.3863039463758469\n",
      "trial: 2, iter: 8200, curr loss: 1.386098027229309, avg loss: 1.3862847918272019\n",
      "trial: 2, iter: 8400, curr loss: 1.3858799934387207, avg loss: 1.3863010895252228\n",
      "trial: 2, iter: 8600, curr loss: 1.3861867189407349, avg loss: 1.3863272029161453\n",
      "trial: 2, iter: 8800, curr loss: 1.3860831260681152, avg loss: 1.3862905579805374\n",
      "trial: 2, iter: 9000, curr loss: 1.3862099647521973, avg loss: 1.3862943083047867\n",
      "trial: 2, iter: 9200, curr loss: 1.3860782384872437, avg loss: 1.3862902599573135\n",
      "trial: 2, iter: 9400, curr loss: 1.3863009214401245, avg loss: 1.3863363480567932\n",
      "trial: 2, iter: 9600, curr loss: 1.3859834671020508, avg loss: 1.386322483420372\n",
      "trial: 2, iter: 9800, curr loss: 1.3861346244812012, avg loss: 1.3863306403160096\n",
      "trial: 2, iter: 10000, curr loss: 1.3859866857528687, avg loss: 1.3863229691982268\n",
      "trial: 2, iter: 10200, curr loss: 1.385956883430481, avg loss: 1.3862980037927628\n",
      "trial: 2, iter: 10400, curr loss: 1.3865160942077637, avg loss: 1.3862384629249573\n",
      "trial: 2, iter: 10600, curr loss: 1.3860379457473755, avg loss: 1.3863919389247894\n",
      "trial: 2, iter: 10800, curr loss: 1.386722445487976, avg loss: 1.3862907439470291\n",
      "trial: 2, iter: 11000, curr loss: 1.3861805200576782, avg loss: 1.386319220662117\n",
      "trial: 2, iter: 11200, curr loss: 1.386693000793457, avg loss: 1.3863284331560135\n",
      "trial: 2, iter: 11400, curr loss: 1.3859450817108154, avg loss: 1.3862998974323273\n",
      "trial: 2, iter: 11600, curr loss: 1.3859858512878418, avg loss: 1.3863068753480912\n",
      "trial: 2, iter: 11800, curr loss: 1.3864322900772095, avg loss: 1.3863276571035386\n",
      "trial: 2, iter: 12000, curr loss: 1.3863846063613892, avg loss: 1.3862716937065125\n",
      "trial: 2, iter: 12200, curr loss: 1.3867863416671753, avg loss: 1.3862958538532257\n",
      "trial: 2, iter: 12400, curr loss: 1.3868963718414307, avg loss: 1.3862963289022445\n",
      "trial: 2, iter: 12600, curr loss: 1.3858494758605957, avg loss: 1.3863120049238205\n",
      "trial: 2, iter: 12800, curr loss: 1.3860653638839722, avg loss: 1.386323613524437\n",
      "trial: 2, iter: 13000, curr loss: 1.3861229419708252, avg loss: 1.3863230735063552\n",
      "trial: 2, iter: 13200, curr loss: 1.3866612911224365, avg loss: 1.3863134825229644\n",
      "trial: 2, iter: 13400, curr loss: 1.3858823776245117, avg loss: 1.386306535601616\n",
      "trial: 2, iter: 13600, curr loss: 1.3861924409866333, avg loss: 1.3863146817684173\n",
      "trial: 2, iter: 13800, curr loss: 1.386315941810608, avg loss: 1.386312102675438\n",
      "trial: 2, iter: 14000, curr loss: 1.3862899541854858, avg loss: 1.386324091553688\n",
      "trial: 2, iter: 14200, curr loss: 1.3862707614898682, avg loss: 1.3863237369060517\n",
      "trial: 2, iter: 14400, curr loss: 1.3861756324768066, avg loss: 1.3863012236356735\n",
      "trial: 2, iter: 14600, curr loss: 1.3863235712051392, avg loss: 1.3862944775819779\n",
      "trial: 2, iter: 14800, curr loss: 1.3863584995269775, avg loss: 1.3862837159633636\n",
      "trial: 2, iter: 15000, curr loss: 1.386504054069519, avg loss: 1.386316003203392\n",
      "trial: 2, iter: 15200, curr loss: 1.3862184286117554, avg loss: 1.38631662607193\n",
      "trial: 2, iter: 15400, curr loss: 1.3861624002456665, avg loss: 1.38628331720829\n",
      "trial: 2, iter: 15600, curr loss: 1.3862110376358032, avg loss: 1.3863081485033035\n",
      "trial: 2, ldr: -0.0015427785692736506\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3891559839248657, avg loss: 1.3872467309236527\n",
      "trial: 3, iter: 400, curr loss: 1.3842525482177734, avg loss: 1.386733683347702\n",
      "trial: 3, iter: 600, curr loss: 1.3822946548461914, avg loss: 1.386664076447487\n",
      "trial: 3, iter: 800, curr loss: 1.3842570781707764, avg loss: 1.386427365541458\n",
      "trial: 3, iter: 1000, curr loss: 1.3871803283691406, avg loss: 1.386574954390526\n",
      "trial: 3, iter: 1200, curr loss: 1.3874902725219727, avg loss: 1.386511822938919\n",
      "trial: 3, iter: 1400, curr loss: 1.385407567024231, avg loss: 1.3862597417831422\n",
      "trial: 3, iter: 1600, curr loss: 1.3856977224349976, avg loss: 1.3863837713003158\n",
      "trial: 3, iter: 1800, curr loss: 1.3855770826339722, avg loss: 1.3862850177288055\n",
      "trial: 3, iter: 2000, curr loss: 1.3871064186096191, avg loss: 1.3864436143636703\n",
      "trial: 3, iter: 2200, curr loss: 1.3861457109451294, avg loss: 1.3863284713029862\n",
      "trial: 3, iter: 2400, curr loss: 1.386467456817627, avg loss: 1.3863533425331116\n",
      "trial: 3, iter: 2600, curr loss: 1.3861385583877563, avg loss: 1.386303983926773\n",
      "trial: 3, iter: 2800, curr loss: 1.386500597000122, avg loss: 1.3863273483514786\n",
      "trial: 3, iter: 3000, curr loss: 1.3872978687286377, avg loss: 1.3863135832548141\n",
      "trial: 3, iter: 3200, curr loss: 1.3867371082305908, avg loss: 1.3864443612098694\n",
      "trial: 3, iter: 3400, curr loss: 1.3855596780776978, avg loss: 1.3862983584403992\n",
      "trial: 3, iter: 3600, curr loss: 1.386348843574524, avg loss: 1.386337235569954\n",
      "trial: 3, iter: 3800, curr loss: 1.3866946697235107, avg loss: 1.3863228678703308\n",
      "trial: 3, iter: 4000, curr loss: 1.3860338926315308, avg loss: 1.386308336853981\n",
      "trial: 3, iter: 4200, curr loss: 1.38653564453125, avg loss: 1.3863620871305466\n",
      "trial: 3, iter: 4400, curr loss: 1.3864161968231201, avg loss: 1.3863437175750732\n",
      "trial: 3, iter: 4600, curr loss: 1.3862491846084595, avg loss: 1.3862990444898606\n",
      "trial: 3, iter: 4800, curr loss: 1.3861613273620605, avg loss: 1.3863038009405135\n",
      "trial: 3, iter: 5000, curr loss: 1.3868517875671387, avg loss: 1.386291162967682\n",
      "trial: 3, iter: 5200, curr loss: 1.38645601272583, avg loss: 1.386314138174057\n",
      "trial: 3, iter: 5400, curr loss: 1.3864797353744507, avg loss: 1.386345660686493\n",
      "trial: 3, iter: 5600, curr loss: 1.386330246925354, avg loss: 1.3863292938470841\n",
      "trial: 3, iter: 5800, curr loss: 1.3865468502044678, avg loss: 1.3863084298372268\n",
      "trial: 3, iter: 6000, curr loss: 1.3860324621200562, avg loss: 1.3862996304035187\n",
      "trial: 3, iter: 6200, curr loss: 1.3864787817001343, avg loss: 1.386297157406807\n",
      "trial: 3, iter: 6400, curr loss: 1.3863682746887207, avg loss: 1.3863100898265839\n",
      "trial: 3, iter: 6600, curr loss: 1.386452317237854, avg loss: 1.386306221485138\n",
      "trial: 3, iter: 6800, curr loss: 1.3865875005722046, avg loss: 1.3863050693273544\n",
      "trial: 3, iter: 7000, curr loss: 1.3862152099609375, avg loss: 1.3862973582744598\n",
      "trial: 3, iter: 7200, curr loss: 1.3868303298950195, avg loss: 1.3863072139024735\n",
      "trial: 3, iter: 7400, curr loss: 1.3863563537597656, avg loss: 1.3863196474313737\n",
      "trial: 3, iter: 7600, curr loss: 1.3860989809036255, avg loss: 1.386286397576332\n",
      "trial: 3, iter: 7800, curr loss: 1.386191964149475, avg loss: 1.3863215976953507\n",
      "trial: 3, iter: 8000, curr loss: 1.3863567113876343, avg loss: 1.3862911289930344\n",
      "trial: 3, iter: 8200, curr loss: 1.3862555027008057, avg loss: 1.3862930715084076\n",
      "trial: 3, iter: 8400, curr loss: 1.3862290382385254, avg loss: 1.3862988972663879\n",
      "trial: 3, iter: 8600, curr loss: 1.386305570602417, avg loss: 1.3863050013780593\n",
      "trial: 3, iter: 8800, curr loss: 1.3861973285675049, avg loss: 1.3862873440980912\n",
      "trial: 3, iter: 9000, curr loss: 1.3866004943847656, avg loss: 1.3863167208433151\n",
      "trial: 3, iter: 9200, curr loss: 1.3863028287887573, avg loss: 1.3863401317596435\n",
      "trial: 3, iter: 9400, curr loss: 1.3864855766296387, avg loss: 1.386307663321495\n",
      "trial: 3, iter: 9600, curr loss: 1.3863015174865723, avg loss: 1.3863128513097762\n",
      "trial: 3, iter: 9800, curr loss: 1.3864272832870483, avg loss: 1.3863214761018754\n",
      "trial: 3, iter: 10000, curr loss: 1.386358618736267, avg loss: 1.3862919795513153\n",
      "trial: 3, iter: 10200, curr loss: 1.3862435817718506, avg loss: 1.3863372778892518\n",
      "trial: 3, iter: 10400, curr loss: 1.3862714767456055, avg loss: 1.386312062740326\n",
      "trial: 3, iter: 10600, curr loss: 1.3863873481750488, avg loss: 1.3863031846284866\n",
      "trial: 3, iter: 10800, curr loss: 1.3866206407546997, avg loss: 1.3862989270687103\n",
      "trial: 3, iter: 11000, curr loss: 1.3862923383712769, avg loss: 1.3862976098060609\n",
      "trial: 3, iter: 11200, curr loss: 1.3860719203948975, avg loss: 1.3863061672449113\n",
      "trial: 3, iter: 11400, curr loss: 1.3874821662902832, avg loss: 1.3862693804502486\n",
      "trial: 3, iter: 11600, curr loss: 1.3862932920455933, avg loss: 1.3863457703590394\n",
      "trial: 3, iter: 11800, curr loss: 1.38637375831604, avg loss: 1.3863266760110855\n",
      "trial: 3, iter: 12000, curr loss: 1.3862584829330444, avg loss: 1.3863123947381972\n",
      "trial: 3, iter: 12200, curr loss: 1.3865617513656616, avg loss: 1.386297133564949\n",
      "trial: 3, iter: 12400, curr loss: 1.3863071203231812, avg loss: 1.3862920302152633\n",
      "trial: 3, iter: 12600, curr loss: 1.3862851858139038, avg loss: 1.386295444369316\n",
      "trial: 3, iter: 12800, curr loss: 1.3862910270690918, avg loss: 1.3862947261333465\n",
      "trial: 3, iter: 13000, curr loss: 1.3862922191619873, avg loss: 1.3862952107191087\n",
      "trial: 3, iter: 13200, curr loss: 1.3862941265106201, avg loss: 1.3862945371866227\n",
      "trial: 3, iter: 13400, curr loss: 1.3862944841384888, avg loss: 1.3862950658798219\n",
      "trial: 3, iter: 13600, curr loss: 1.3862944841384888, avg loss: 1.3862947911024093\n",
      "trial: 3, iter: 13800, curr loss: 1.3862947225570679, avg loss: 1.3862947434186936\n",
      "trial: 3, iter: 14000, curr loss: 1.3862946033477783, avg loss: 1.3862948036193847\n",
      "trial: 3, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.3862943404912949\n",
      "trial: 3, iter: 14400, curr loss: 1.3862943649291992, avg loss: 1.3862933480739594\n",
      "trial: 3, iter: 14600, curr loss: 1.3862944841384888, avg loss: 1.3862938725948333\n",
      "trial: 3, iter: 14800, curr loss: 1.3862926959991455, avg loss: 1.386294545531273\n",
      "trial: 3, iter: 15000, curr loss: 1.3862978219985962, avg loss: 1.3862931102514267\n",
      "trial: 3, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862935900688171\n",
      "trial: 3, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.3862906414270402\n",
      "trial: 3, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.386291081905365\n",
      "trial: 3, ldr: 2.8859534722869284e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3861145973205566, avg loss: 1.3872759079933166\n",
      "trial: 4, iter: 400, curr loss: 1.3871036767959595, avg loss: 1.3868288016319275\n",
      "trial: 4, iter: 600, curr loss: 1.385999083518982, avg loss: 1.3866790860891343\n",
      "trial: 4, iter: 800, curr loss: 1.3869632482528687, avg loss: 1.386510437130928\n",
      "trial: 4, iter: 1000, curr loss: 1.3865938186645508, avg loss: 1.3865054547786713\n",
      "trial: 4, iter: 1200, curr loss: 1.3866863250732422, avg loss: 1.3864397859573365\n",
      "trial: 4, iter: 1400, curr loss: 1.385025143623352, avg loss: 1.3863801813125611\n",
      "trial: 4, iter: 1600, curr loss: 1.3855937719345093, avg loss: 1.3864390408992768\n",
      "trial: 4, iter: 1800, curr loss: 1.3879731893539429, avg loss: 1.386359254717827\n",
      "trial: 4, iter: 2000, curr loss: 1.3858256340026855, avg loss: 1.3863897824287414\n",
      "trial: 4, iter: 2200, curr loss: 1.3865962028503418, avg loss: 1.3863906610012053\n",
      "trial: 4, iter: 2400, curr loss: 1.3869768381118774, avg loss: 1.3863607507944107\n",
      "trial: 4, iter: 2600, curr loss: 1.3861632347106934, avg loss: 1.3862762707471847\n",
      "trial: 4, iter: 2800, curr loss: 1.3873491287231445, avg loss: 1.3863637775182724\n",
      "trial: 4, iter: 3000, curr loss: 1.387147068977356, avg loss: 1.386332476735115\n",
      "trial: 4, iter: 3200, curr loss: 1.3863098621368408, avg loss: 1.3862837904691696\n",
      "trial: 4, iter: 3400, curr loss: 1.386460781097412, avg loss: 1.386373175382614\n",
      "trial: 4, iter: 3600, curr loss: 1.3865370750427246, avg loss: 1.386372276544571\n",
      "trial: 4, iter: 3800, curr loss: 1.3861055374145508, avg loss: 1.38633466899395\n",
      "trial: 4, iter: 4000, curr loss: 1.3862792253494263, avg loss: 1.3863234889507294\n",
      "trial: 4, iter: 4200, curr loss: 1.3866961002349854, avg loss: 1.3863099592924117\n",
      "trial: 4, iter: 4400, curr loss: 1.3855012655258179, avg loss: 1.3862900191545486\n",
      "trial: 4, iter: 4600, curr loss: 1.386174201965332, avg loss: 1.3863530772924424\n",
      "trial: 4, iter: 4800, curr loss: 1.38655686378479, avg loss: 1.3863587653636933\n",
      "trial: 4, iter: 5000, curr loss: 1.3852558135986328, avg loss: 1.3863090389966966\n",
      "trial: 4, iter: 5200, curr loss: 1.385828971862793, avg loss: 1.3863135123252868\n",
      "trial: 4, iter: 5400, curr loss: 1.3866071701049805, avg loss: 1.3863167345523835\n",
      "trial: 4, iter: 5600, curr loss: 1.3864171504974365, avg loss: 1.386318278312683\n",
      "trial: 4, iter: 5800, curr loss: 1.3860629796981812, avg loss: 1.3863180661201477\n",
      "trial: 4, iter: 6000, curr loss: 1.3865736722946167, avg loss: 1.3863017416000367\n",
      "trial: 4, iter: 6200, curr loss: 1.3866229057312012, avg loss: 1.3862664693593978\n",
      "trial: 4, iter: 6400, curr loss: 1.3867157697677612, avg loss: 1.3863321936130524\n",
      "trial: 4, iter: 6600, curr loss: 1.3863128423690796, avg loss: 1.3862859719991685\n",
      "trial: 4, iter: 6800, curr loss: 1.3859684467315674, avg loss: 1.3862808853387834\n",
      "trial: 4, iter: 7000, curr loss: 1.38603675365448, avg loss: 1.3863513058423995\n",
      "trial: 4, iter: 7200, curr loss: 1.3858351707458496, avg loss: 1.386278333067894\n",
      "trial: 4, iter: 7400, curr loss: 1.3861408233642578, avg loss: 1.3863344132900237\n",
      "trial: 4, iter: 7600, curr loss: 1.3862029314041138, avg loss: 1.386308364868164\n",
      "trial: 4, iter: 7800, curr loss: 1.3866550922393799, avg loss: 1.3862775480747223\n",
      "trial: 4, iter: 8000, curr loss: 1.3859151601791382, avg loss: 1.3863421374559401\n",
      "trial: 4, iter: 8200, curr loss: 1.385960340499878, avg loss: 1.3863674974441529\n",
      "trial: 4, iter: 8400, curr loss: 1.3877921104431152, avg loss: 1.386278936266899\n",
      "trial: 4, iter: 8600, curr loss: 1.3863874673843384, avg loss: 1.3863313263654709\n",
      "trial: 4, iter: 8800, curr loss: 1.3862512111663818, avg loss: 1.3863498771190643\n",
      "trial: 4, iter: 9000, curr loss: 1.3863487243652344, avg loss: 1.3863044732809067\n",
      "trial: 4, iter: 9200, curr loss: 1.3859882354736328, avg loss: 1.3863046616315842\n",
      "trial: 4, iter: 9400, curr loss: 1.3862782716751099, avg loss: 1.3863151913881302\n",
      "trial: 4, iter: 9600, curr loss: 1.3863211870193481, avg loss: 1.3863027131557464\n",
      "trial: 4, iter: 9800, curr loss: 1.3864634037017822, avg loss: 1.3862998104095459\n",
      "trial: 4, iter: 10000, curr loss: 1.3866466283798218, avg loss: 1.3863050371408463\n",
      "trial: 4, iter: 10200, curr loss: 1.386309027671814, avg loss: 1.386313383579254\n",
      "trial: 4, iter: 10400, curr loss: 1.386600375175476, avg loss: 1.3863186126947402\n",
      "trial: 4, iter: 10600, curr loss: 1.3854455947875977, avg loss: 1.386346474289894\n",
      "trial: 4, iter: 10800, curr loss: 1.3862797021865845, avg loss: 1.3863316750526429\n",
      "trial: 4, iter: 11000, curr loss: 1.3867627382278442, avg loss: 1.3863478982448578\n",
      "trial: 4, iter: 11200, curr loss: 1.3862242698669434, avg loss: 1.3863340431451798\n",
      "trial: 4, iter: 11400, curr loss: 1.3862731456756592, avg loss: 1.3863114976882935\n",
      "trial: 4, iter: 11600, curr loss: 1.3865878582000732, avg loss: 1.3863330256938935\n",
      "trial: 4, iter: 11800, curr loss: 1.3863753080368042, avg loss: 1.386292152404785\n",
      "trial: 4, iter: 12000, curr loss: 1.3861967325210571, avg loss: 1.3863233155012131\n",
      "trial: 4, iter: 12200, curr loss: 1.3864107131958008, avg loss: 1.3863072746992111\n",
      "trial: 4, iter: 12400, curr loss: 1.3863693475723267, avg loss: 1.3863052546977996\n",
      "trial: 4, iter: 12600, curr loss: 1.3864495754241943, avg loss: 1.3862944859266282\n",
      "trial: 4, iter: 12800, curr loss: 1.3863781690597534, avg loss: 1.386315513253212\n",
      "trial: 4, iter: 13000, curr loss: 1.3862138986587524, avg loss: 1.3863055229187011\n",
      "trial: 4, iter: 13200, curr loss: 1.3863189220428467, avg loss: 1.3862972146272659\n",
      "trial: 4, iter: 13400, curr loss: 1.3861839771270752, avg loss: 1.386301342844963\n",
      "trial: 4, iter: 13600, curr loss: 1.386173129081726, avg loss: 1.3863075494766235\n",
      "trial: 4, iter: 13800, curr loss: 1.38624107837677, avg loss: 1.386297737956047\n",
      "trial: 4, iter: 14000, curr loss: 1.3863767385482788, avg loss: 1.3862956404685973\n",
      "trial: 4, iter: 14200, curr loss: 1.3863357305526733, avg loss: 1.3863059765100478\n",
      "trial: 4, iter: 14400, curr loss: 1.3863286972045898, avg loss: 1.3862950903177262\n",
      "trial: 4, iter: 14600, curr loss: 1.3862947225570679, avg loss: 1.3863015592098236\n",
      "trial: 4, iter: 14800, curr loss: 1.3862931728363037, avg loss: 1.386295686364174\n",
      "trial: 4, iter: 15000, curr loss: 1.3862954378128052, avg loss: 1.3862952029705047\n",
      "trial: 4, iter: 15200, curr loss: 1.3862801790237427, avg loss: 1.3862954097986222\n",
      "trial: 4, iter: 15400, curr loss: 1.386291265487671, avg loss: 1.3862951678037643\n",
      "trial: 4, iter: 15600, curr loss: 1.3862251043319702, avg loss: 1.3862978982925416\n",
      "trial: 4, ldr: 0.0001364132622256875\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385907530784607, avg loss: 1.3875740313529967\n",
      "trial: 5, iter: 400, curr loss: 1.3860918283462524, avg loss: 1.3867170083522797\n",
      "trial: 5, iter: 600, curr loss: 1.3839685916900635, avg loss: 1.3865529823303222\n",
      "trial: 5, iter: 800, curr loss: 1.3848652839660645, avg loss: 1.3865528571605683\n",
      "trial: 5, iter: 1000, curr loss: 1.3866217136383057, avg loss: 1.3864209485054015\n",
      "trial: 5, iter: 1200, curr loss: 1.3861801624298096, avg loss: 1.386480714082718\n",
      "trial: 5, iter: 1400, curr loss: 1.3864591121673584, avg loss: 1.3863465690612793\n",
      "trial: 5, iter: 1600, curr loss: 1.3874059915542603, avg loss: 1.386363956928253\n",
      "trial: 5, iter: 1800, curr loss: 1.3870341777801514, avg loss: 1.3863838386535645\n",
      "trial: 5, iter: 2000, curr loss: 1.3857194185256958, avg loss: 1.3864004284143447\n",
      "trial: 5, iter: 2200, curr loss: 1.3869189023971558, avg loss: 1.3863997197151183\n",
      "trial: 5, iter: 2400, curr loss: 1.3853152990341187, avg loss: 1.386412614583969\n",
      "trial: 5, iter: 2600, curr loss: 1.3866891860961914, avg loss: 1.386394767165184\n",
      "trial: 5, iter: 2800, curr loss: 1.3874953985214233, avg loss: 1.3863458371162414\n",
      "trial: 5, iter: 3000, curr loss: 1.386159896850586, avg loss: 1.386407683491707\n",
      "trial: 5, iter: 3200, curr loss: 1.386364221572876, avg loss: 1.3863047748804092\n",
      "trial: 5, iter: 3400, curr loss: 1.3876144886016846, avg loss: 1.3863080739974976\n",
      "trial: 5, iter: 3600, curr loss: 1.386319875717163, avg loss: 1.3863327634334563\n",
      "trial: 5, iter: 3800, curr loss: 1.3867841958999634, avg loss: 1.3863217920064925\n",
      "trial: 5, iter: 4000, curr loss: 1.3865092992782593, avg loss: 1.3863073217868804\n",
      "trial: 5, iter: 4200, curr loss: 1.3867865800857544, avg loss: 1.3863992595672607\n",
      "trial: 5, iter: 4400, curr loss: 1.386169195175171, avg loss: 1.3863768142461776\n",
      "trial: 5, iter: 4600, curr loss: 1.385832667350769, avg loss: 1.3863197481632232\n",
      "trial: 5, iter: 4800, curr loss: 1.3871524333953857, avg loss: 1.3863727456331254\n",
      "trial: 5, iter: 5000, curr loss: 1.3875423669815063, avg loss: 1.3863591432571412\n",
      "trial: 5, iter: 5200, curr loss: 1.3856537342071533, avg loss: 1.3863648533821107\n",
      "trial: 5, iter: 5400, curr loss: 1.3854283094406128, avg loss: 1.3863377875089646\n",
      "trial: 5, iter: 5600, curr loss: 1.3867453336715698, avg loss: 1.3863235360383988\n",
      "trial: 5, iter: 5800, curr loss: 1.3874889612197876, avg loss: 1.3863255751132966\n",
      "trial: 5, iter: 6000, curr loss: 1.3863568305969238, avg loss: 1.3862999767065047\n",
      "trial: 5, iter: 6200, curr loss: 1.385852575302124, avg loss: 1.386308848261833\n",
      "trial: 5, iter: 6400, curr loss: 1.386020541191101, avg loss: 1.3863391751050949\n",
      "trial: 5, iter: 6600, curr loss: 1.3865584135055542, avg loss: 1.386287676692009\n",
      "trial: 5, iter: 6800, curr loss: 1.3859119415283203, avg loss: 1.3863086992502212\n",
      "trial: 5, iter: 7000, curr loss: 1.386470079421997, avg loss: 1.38633369743824\n",
      "trial: 5, iter: 7200, curr loss: 1.386091709136963, avg loss: 1.386309084892273\n",
      "trial: 5, iter: 7400, curr loss: 1.386510968208313, avg loss: 1.3864140290021896\n",
      "trial: 5, iter: 7600, curr loss: 1.386512041091919, avg loss: 1.3863192421197892\n",
      "trial: 5, iter: 7800, curr loss: 1.3868073225021362, avg loss: 1.3863212978839874\n",
      "trial: 5, iter: 8000, curr loss: 1.3860667943954468, avg loss: 1.386337902545929\n",
      "trial: 5, iter: 8200, curr loss: 1.3862842321395874, avg loss: 1.3863303196430206\n",
      "trial: 5, iter: 8400, curr loss: 1.3858731985092163, avg loss: 1.3862794154882432\n",
      "trial: 5, iter: 8600, curr loss: 1.3862731456756592, avg loss: 1.386282393336296\n",
      "trial: 5, iter: 8800, curr loss: 1.386206030845642, avg loss: 1.3863357824087144\n",
      "trial: 5, iter: 9000, curr loss: 1.3859522342681885, avg loss: 1.38630776822567\n",
      "trial: 5, iter: 9200, curr loss: 1.386353850364685, avg loss: 1.3863304007053374\n",
      "trial: 5, iter: 9400, curr loss: 1.386521816253662, avg loss: 1.3863157272338866\n",
      "trial: 5, iter: 9600, curr loss: 1.3859800100326538, avg loss: 1.3863264745473862\n",
      "trial: 5, iter: 9800, curr loss: 1.3849596977233887, avg loss: 1.3863134878873824\n",
      "trial: 5, iter: 10000, curr loss: 1.3862570524215698, avg loss: 1.3863734322786332\n",
      "trial: 5, iter: 10200, curr loss: 1.3852757215499878, avg loss: 1.3863080906867982\n",
      "trial: 5, iter: 10400, curr loss: 1.3863903284072876, avg loss: 1.386361256837845\n",
      "trial: 5, iter: 10600, curr loss: 1.3852044343948364, avg loss: 1.3862647449970245\n",
      "trial: 5, iter: 10800, curr loss: 1.387064814567566, avg loss: 1.3863822275400162\n",
      "trial: 5, iter: 11000, curr loss: 1.3859113454818726, avg loss: 1.3863112378120421\n",
      "trial: 5, iter: 11200, curr loss: 1.3862578868865967, avg loss: 1.3863267427682877\n",
      "trial: 5, iter: 11400, curr loss: 1.386321783065796, avg loss: 1.386305867433548\n",
      "trial: 5, iter: 11600, curr loss: 1.3862398862838745, avg loss: 1.3863041532039642\n",
      "trial: 5, iter: 11800, curr loss: 1.3867061138153076, avg loss: 1.3863034331798554\n",
      "trial: 5, iter: 12000, curr loss: 1.3865365982055664, avg loss: 1.386277602314949\n",
      "trial: 5, iter: 12200, curr loss: 1.3869043588638306, avg loss: 1.3863159292936325\n",
      "trial: 5, iter: 12400, curr loss: 1.3861254453659058, avg loss: 1.3862352257966994\n",
      "trial: 5, iter: 12600, curr loss: 1.3862007856369019, avg loss: 1.3863757437467574\n",
      "trial: 5, iter: 12800, curr loss: 1.3864262104034424, avg loss: 1.386301800608635\n",
      "trial: 5, iter: 13000, curr loss: 1.386411428451538, avg loss: 1.386323674917221\n",
      "trial: 5, iter: 13200, curr loss: 1.386461615562439, avg loss: 1.3863026571273804\n",
      "trial: 5, iter: 13400, curr loss: 1.386521577835083, avg loss: 1.386300067305565\n",
      "trial: 5, iter: 13600, curr loss: 1.3864085674285889, avg loss: 1.3862987732887269\n",
      "trial: 5, iter: 13800, curr loss: 1.386155366897583, avg loss: 1.3863200974464416\n",
      "trial: 5, iter: 14000, curr loss: 1.3862683773040771, avg loss: 1.3863086986541748\n",
      "trial: 5, iter: 14200, curr loss: 1.3862842321395874, avg loss: 1.3863065367937089\n",
      "trial: 5, iter: 14400, curr loss: 1.386412501335144, avg loss: 1.3863011574745179\n",
      "trial: 5, iter: 14600, curr loss: 1.3862535953521729, avg loss: 1.3863026136159897\n",
      "trial: 5, iter: 14800, curr loss: 1.386329174041748, avg loss: 1.3863008314371108\n",
      "trial: 5, iter: 15000, curr loss: 1.3861706256866455, avg loss: 1.386288731098175\n",
      "trial: 5, iter: 15200, curr loss: 1.386662244796753, avg loss: 1.3862853276729583\n",
      "trial: 5, iter: 15400, curr loss: 1.3862996101379395, avg loss: 1.3863120383024217\n",
      "trial: 5, iter: 15600, curr loss: 1.3864331245422363, avg loss: 1.3862962329387665\n",
      "trial: 5, ldr: 0.0002419978700345382\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00014195311487128493\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3851484060287476, avg loss: 1.3873907512426376\n",
      "trial: 1, iter: 400, curr loss: 1.3839260339736938, avg loss: 1.3869004702568055\n",
      "trial: 1, iter: 600, curr loss: 1.3862537145614624, avg loss: 1.386684874892235\n",
      "trial: 1, iter: 800, curr loss: 1.3875230550765991, avg loss: 1.3865951466560364\n",
      "trial: 1, iter: 1000, curr loss: 1.3866472244262695, avg loss: 1.386381368637085\n",
      "trial: 1, iter: 1200, curr loss: 1.3869110345840454, avg loss: 1.3863774120807648\n",
      "trial: 1, iter: 1400, curr loss: 1.3840361833572388, avg loss: 1.3864420598745346\n",
      "trial: 1, iter: 1600, curr loss: 1.3858122825622559, avg loss: 1.3863963961601258\n",
      "trial: 1, iter: 1800, curr loss: 1.3867782354354858, avg loss: 1.3863359493017198\n",
      "trial: 1, iter: 2000, curr loss: 1.3855513334274292, avg loss: 1.3864498603343964\n",
      "trial: 1, iter: 2200, curr loss: 1.3866479396820068, avg loss: 1.3863517874479294\n",
      "trial: 1, iter: 2400, curr loss: 1.3855743408203125, avg loss: 1.3863840562105179\n",
      "trial: 1, iter: 2600, curr loss: 1.3872181177139282, avg loss: 1.3863999235630036\n",
      "trial: 1, iter: 2800, curr loss: 1.386018991470337, avg loss: 1.386378951072693\n",
      "trial: 1, iter: 3000, curr loss: 1.3866264820098877, avg loss: 1.3863204526901245\n",
      "trial: 1, iter: 3200, curr loss: 1.3866567611694336, avg loss: 1.3863574856519698\n",
      "trial: 1, iter: 3400, curr loss: 1.3869414329528809, avg loss: 1.3863342493772506\n",
      "trial: 1, iter: 3600, curr loss: 1.38682222366333, avg loss: 1.3864104050397872\n",
      "trial: 1, iter: 3800, curr loss: 1.3867197036743164, avg loss: 1.3863350391387939\n",
      "trial: 1, iter: 4000, curr loss: 1.3858853578567505, avg loss: 1.386325021982193\n",
      "trial: 1, iter: 4200, curr loss: 1.386205792427063, avg loss: 1.3863301360607148\n",
      "trial: 1, iter: 4400, curr loss: 1.386237382888794, avg loss: 1.386332625746727\n",
      "trial: 1, iter: 4600, curr loss: 1.3864264488220215, avg loss: 1.386330252289772\n",
      "trial: 1, iter: 4800, curr loss: 1.3869669437408447, avg loss: 1.3863115781545639\n",
      "trial: 1, iter: 5000, curr loss: 1.3864537477493286, avg loss: 1.386289548277855\n",
      "trial: 1, iter: 5200, curr loss: 1.3870421648025513, avg loss: 1.386330863237381\n",
      "trial: 1, iter: 5400, curr loss: 1.3864948749542236, avg loss: 1.3863421779870988\n",
      "trial: 1, iter: 5600, curr loss: 1.3867570161819458, avg loss: 1.386336452960968\n",
      "trial: 1, iter: 5800, curr loss: 1.386851191520691, avg loss: 1.3863237231969834\n",
      "trial: 1, iter: 6000, curr loss: 1.3857009410858154, avg loss: 1.3863241988420487\n",
      "trial: 1, iter: 6200, curr loss: 1.3881261348724365, avg loss: 1.3862386077642441\n",
      "trial: 1, iter: 6400, curr loss: 1.3856613636016846, avg loss: 1.3864521378278731\n",
      "trial: 1, iter: 6600, curr loss: 1.386542797088623, avg loss: 1.3864172738790512\n",
      "trial: 1, iter: 6800, curr loss: 1.3867172002792358, avg loss: 1.386373726129532\n",
      "trial: 1, iter: 7000, curr loss: 1.386502981185913, avg loss: 1.3863089436292648\n",
      "trial: 1, iter: 7200, curr loss: 1.386343002319336, avg loss: 1.38630175113678\n",
      "trial: 1, iter: 7400, curr loss: 1.3859806060791016, avg loss: 1.3863112312555312\n",
      "trial: 1, iter: 7600, curr loss: 1.3876303434371948, avg loss: 1.386333304643631\n",
      "trial: 1, iter: 7800, curr loss: 1.3860418796539307, avg loss: 1.3863059729337692\n",
      "trial: 1, iter: 8000, curr loss: 1.386208176612854, avg loss: 1.3863290679454803\n",
      "trial: 1, iter: 8200, curr loss: 1.3859179019927979, avg loss: 1.386298315525055\n",
      "trial: 1, iter: 8400, curr loss: 1.386298418045044, avg loss: 1.3863058626651763\n",
      "trial: 1, iter: 8600, curr loss: 1.3862648010253906, avg loss: 1.3863463521003723\n",
      "trial: 1, iter: 8800, curr loss: 1.3861911296844482, avg loss: 1.386299512386322\n",
      "trial: 1, iter: 9000, curr loss: 1.3864827156066895, avg loss: 1.3863076341152192\n",
      "trial: 1, iter: 9200, curr loss: 1.3861879110336304, avg loss: 1.3863070297241211\n",
      "trial: 1, iter: 9400, curr loss: 1.3873405456542969, avg loss: 1.3862931710481643\n",
      "trial: 1, iter: 9600, curr loss: 1.3868911266326904, avg loss: 1.3863512659072876\n",
      "trial: 1, iter: 9800, curr loss: 1.3864892721176147, avg loss: 1.3863425636291504\n",
      "trial: 1, iter: 10000, curr loss: 1.3866081237792969, avg loss: 1.386315659880638\n",
      "trial: 1, iter: 10200, curr loss: 1.3864394426345825, avg loss: 1.3863191497325897\n",
      "trial: 1, iter: 10400, curr loss: 1.3869866132736206, avg loss: 1.3863299280405044\n",
      "trial: 1, iter: 10600, curr loss: 1.3862066268920898, avg loss: 1.3863054299354554\n",
      "trial: 1, iter: 10800, curr loss: 1.3864539861679077, avg loss: 1.3863376873731612\n",
      "trial: 1, iter: 11000, curr loss: 1.3866146802902222, avg loss: 1.3863428521156311\n",
      "trial: 1, iter: 11200, curr loss: 1.3858901262283325, avg loss: 1.386308988928795\n",
      "trial: 1, iter: 11400, curr loss: 1.3864909410476685, avg loss: 1.3863165581226349\n",
      "trial: 1, iter: 11600, curr loss: 1.3860703706741333, avg loss: 1.386314188838005\n",
      "trial: 1, iter: 11800, curr loss: 1.386309027671814, avg loss: 1.3863449984788894\n",
      "trial: 1, iter: 12000, curr loss: 1.3865065574645996, avg loss: 1.3863253420591355\n",
      "trial: 1, iter: 12200, curr loss: 1.386352300643921, avg loss: 1.3862854886054992\n",
      "trial: 1, iter: 12400, curr loss: 1.3864045143127441, avg loss: 1.3863452792167663\n",
      "trial: 1, iter: 12600, curr loss: 1.3862382173538208, avg loss: 1.3863020473718644\n",
      "trial: 1, iter: 12800, curr loss: 1.3860373497009277, avg loss: 1.3863141876459122\n",
      "trial: 1, iter: 13000, curr loss: 1.3866137266159058, avg loss: 1.3863117289543152\n",
      "trial: 1, iter: 13200, curr loss: 1.386278510093689, avg loss: 1.386307110786438\n",
      "trial: 1, iter: 13400, curr loss: 1.3860622644424438, avg loss: 1.3863065397739411\n",
      "trial: 1, iter: 13600, curr loss: 1.386454701423645, avg loss: 1.386304726600647\n",
      "trial: 1, iter: 13800, curr loss: 1.3864812850952148, avg loss: 1.3863009363412857\n",
      "trial: 1, iter: 14000, curr loss: 1.3862851858139038, avg loss: 1.3863065898418427\n",
      "trial: 1, iter: 14200, curr loss: 1.3862578868865967, avg loss: 1.3862959867715836\n",
      "trial: 1, iter: 14400, curr loss: 1.386240839958191, avg loss: 1.3862922942638398\n",
      "trial: 1, iter: 14600, curr loss: 1.3863787651062012, avg loss: 1.3863036960363389\n",
      "trial: 1, iter: 14800, curr loss: 1.3862781524658203, avg loss: 1.3862970864772797\n",
      "trial: 1, iter: 15000, curr loss: 1.3860793113708496, avg loss: 1.386301999092102\n",
      "trial: 1, iter: 15200, curr loss: 1.3860418796539307, avg loss: 1.386305542588234\n",
      "trial: 1, iter: 15400, curr loss: 1.3867098093032837, avg loss: 1.3863706630468369\n",
      "trial: 1, iter: 15600, curr loss: 1.3860578536987305, avg loss: 1.386320767402649\n",
      "trial: 1, ldr: -0.0015614957083016634\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3853302001953125, avg loss: 1.3872956097126008\n",
      "trial: 2, iter: 400, curr loss: 1.3878512382507324, avg loss: 1.386637295484543\n",
      "trial: 2, iter: 600, curr loss: 1.3872548341751099, avg loss: 1.3867725503444672\n",
      "trial: 2, iter: 800, curr loss: 1.386576533317566, avg loss: 1.3866309529542924\n",
      "trial: 2, iter: 1000, curr loss: 1.3880786895751953, avg loss: 1.3863856720924377\n",
      "trial: 2, iter: 1200, curr loss: 1.3862149715423584, avg loss: 1.386473861336708\n",
      "trial: 2, iter: 1400, curr loss: 1.3851535320281982, avg loss: 1.3863732671737672\n",
      "trial: 2, iter: 1600, curr loss: 1.3866313695907593, avg loss: 1.3864293152093887\n",
      "trial: 2, iter: 1800, curr loss: 1.386364221572876, avg loss: 1.3864014774560929\n",
      "trial: 2, iter: 2000, curr loss: 1.3873610496520996, avg loss: 1.3863665705919266\n",
      "trial: 2, iter: 2200, curr loss: 1.386023998260498, avg loss: 1.3864036571979523\n",
      "trial: 2, iter: 2400, curr loss: 1.38642156124115, avg loss: 1.3863910496234895\n",
      "trial: 2, iter: 2600, curr loss: 1.38694429397583, avg loss: 1.3863232815265656\n",
      "trial: 2, iter: 2800, curr loss: 1.3866690397262573, avg loss: 1.386342042684555\n",
      "trial: 2, iter: 3000, curr loss: 1.3844923973083496, avg loss: 1.3862530881166457\n",
      "trial: 2, iter: 3200, curr loss: 1.3859437704086304, avg loss: 1.3863679361343384\n",
      "trial: 2, iter: 3400, curr loss: 1.3863286972045898, avg loss: 1.3863684397935867\n",
      "trial: 2, iter: 3600, curr loss: 1.3864822387695312, avg loss: 1.3863086688518524\n",
      "trial: 2, iter: 3800, curr loss: 1.3860050439834595, avg loss: 1.386337358355522\n",
      "trial: 2, iter: 4000, curr loss: 1.3871172666549683, avg loss: 1.3863716268539428\n",
      "trial: 2, iter: 4200, curr loss: 1.3859556913375854, avg loss: 1.3863390415906907\n",
      "trial: 2, iter: 4400, curr loss: 1.387303352355957, avg loss: 1.3862556648254394\n",
      "trial: 2, iter: 4600, curr loss: 1.3870307207107544, avg loss: 1.3863087338209152\n",
      "trial: 2, iter: 4800, curr loss: 1.3859955072402954, avg loss: 1.386328861117363\n",
      "trial: 2, iter: 5000, curr loss: 1.3856102228164673, avg loss: 1.3862639582157135\n",
      "trial: 2, iter: 5200, curr loss: 1.3867090940475464, avg loss: 1.386401200890541\n",
      "trial: 2, iter: 5400, curr loss: 1.386224627494812, avg loss: 1.3863402146100998\n",
      "trial: 2, iter: 5600, curr loss: 1.3865175247192383, avg loss: 1.3863303416967392\n",
      "trial: 2, iter: 5800, curr loss: 1.385782241821289, avg loss: 1.386316215991974\n",
      "trial: 2, iter: 6000, curr loss: 1.3868129253387451, avg loss: 1.3863152933120728\n",
      "trial: 2, iter: 6200, curr loss: 1.3860135078430176, avg loss: 1.3863132280111312\n",
      "trial: 2, iter: 6400, curr loss: 1.386579155921936, avg loss: 1.3863712167739868\n",
      "trial: 2, iter: 6600, curr loss: 1.3861887454986572, avg loss: 1.3863247430324555\n",
      "trial: 2, iter: 6800, curr loss: 1.3872108459472656, avg loss: 1.386305839419365\n",
      "trial: 2, iter: 7000, curr loss: 1.3863376379013062, avg loss: 1.3863062477111816\n",
      "trial: 2, iter: 7200, curr loss: 1.3867735862731934, avg loss: 1.3862699449062348\n",
      "trial: 2, iter: 7400, curr loss: 1.3863328695297241, avg loss: 1.386410870552063\n",
      "trial: 2, iter: 7600, curr loss: 1.3861873149871826, avg loss: 1.3863381624221802\n",
      "trial: 2, iter: 7800, curr loss: 1.3863879442214966, avg loss: 1.386321827173233\n",
      "trial: 2, iter: 8000, curr loss: 1.3862240314483643, avg loss: 1.3862890219688415\n",
      "trial: 2, iter: 8200, curr loss: 1.3866891860961914, avg loss: 1.386350190639496\n",
      "trial: 2, iter: 8400, curr loss: 1.3851832151412964, avg loss: 1.386257495880127\n",
      "trial: 2, iter: 8600, curr loss: 1.3860605955123901, avg loss: 1.386335933804512\n",
      "trial: 2, iter: 8800, curr loss: 1.3863719701766968, avg loss: 1.386297886967659\n",
      "trial: 2, iter: 9000, curr loss: 1.386683464050293, avg loss: 1.386301742196083\n",
      "trial: 2, iter: 9200, curr loss: 1.3859689235687256, avg loss: 1.386313435435295\n",
      "trial: 2, iter: 9400, curr loss: 1.3861647844314575, avg loss: 1.3863421618938445\n",
      "trial: 2, iter: 9600, curr loss: 1.386022925376892, avg loss: 1.3863663721084594\n",
      "trial: 2, iter: 9800, curr loss: 1.386792540550232, avg loss: 1.3863128352165222\n",
      "trial: 2, iter: 10000, curr loss: 1.386305809020996, avg loss: 1.3863298571109772\n",
      "trial: 2, iter: 10200, curr loss: 1.386292576789856, avg loss: 1.3863231390714645\n",
      "trial: 2, iter: 10400, curr loss: 1.386080026626587, avg loss: 1.3863029128313065\n",
      "trial: 2, iter: 10600, curr loss: 1.3865809440612793, avg loss: 1.3863112193346023\n",
      "trial: 2, iter: 10800, curr loss: 1.386783242225647, avg loss: 1.3863146489858627\n",
      "trial: 2, iter: 11000, curr loss: 1.386454701423645, avg loss: 1.386318324804306\n",
      "trial: 2, iter: 11200, curr loss: 1.3867965936660767, avg loss: 1.3862861216068267\n",
      "trial: 2, iter: 11400, curr loss: 1.3862615823745728, avg loss: 1.3863256818056107\n",
      "trial: 2, iter: 11600, curr loss: 1.3865245580673218, avg loss: 1.3863123899698258\n",
      "trial: 2, iter: 11800, curr loss: 1.3863035440444946, avg loss: 1.3863025414943695\n",
      "trial: 2, iter: 12000, curr loss: 1.3862851858139038, avg loss: 1.38629667699337\n",
      "trial: 2, iter: 12200, curr loss: 1.3863247632980347, avg loss: 1.38629936337471\n",
      "trial: 2, iter: 12400, curr loss: 1.3861134052276611, avg loss: 1.386288167834282\n",
      "trial: 2, iter: 12600, curr loss: 1.3864346742630005, avg loss: 1.3862767511606215\n",
      "trial: 2, iter: 12800, curr loss: 1.3858381509780884, avg loss: 1.3863153952360152\n",
      "trial: 2, iter: 13000, curr loss: 1.3864758014678955, avg loss: 1.3863158625364305\n",
      "trial: 2, iter: 13200, curr loss: 1.3861690759658813, avg loss: 1.3863344967365265\n",
      "trial: 2, iter: 13400, curr loss: 1.386366844177246, avg loss: 1.3863024342060088\n",
      "trial: 2, iter: 13600, curr loss: 1.3861404657363892, avg loss: 1.386306579709053\n",
      "trial: 2, iter: 13800, curr loss: 1.3862601518630981, avg loss: 1.3863051807880402\n",
      "trial: 2, iter: 14000, curr loss: 1.3864696025848389, avg loss: 1.3862944388389586\n",
      "trial: 2, iter: 14200, curr loss: 1.3860968351364136, avg loss: 1.3863037556409836\n",
      "trial: 2, iter: 14400, curr loss: 1.386737585067749, avg loss: 1.3863586962223053\n",
      "trial: 2, iter: 14600, curr loss: 1.3864721059799194, avg loss: 1.3863438385725022\n",
      "trial: 2, iter: 14800, curr loss: 1.3859654664993286, avg loss: 1.386275781393051\n",
      "trial: 2, iter: 15000, curr loss: 1.3866888284683228, avg loss: 1.3862849986553192\n",
      "trial: 2, iter: 15200, curr loss: 1.3861637115478516, avg loss: 1.386366133093834\n",
      "trial: 2, iter: 15400, curr loss: 1.3863095045089722, avg loss: 1.3863676178455353\n",
      "trial: 2, iter: 15600, curr loss: 1.3863469362258911, avg loss: 1.3863130742311478\n",
      "trial: 2, ldr: -0.0006607428076677024\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3853691816329956, avg loss: 1.3873265397548675\n",
      "trial: 3, iter: 400, curr loss: 1.3892631530761719, avg loss: 1.386690154671669\n",
      "trial: 3, iter: 600, curr loss: 1.3882274627685547, avg loss: 1.386600018143654\n",
      "trial: 3, iter: 800, curr loss: 1.3892878293991089, avg loss: 1.3863949221372605\n",
      "trial: 3, iter: 1000, curr loss: 1.386865258216858, avg loss: 1.3864700973033905\n",
      "trial: 3, iter: 1200, curr loss: 1.3883121013641357, avg loss: 1.3863597732782365\n",
      "trial: 3, iter: 1400, curr loss: 1.3858633041381836, avg loss: 1.3864456713199615\n",
      "trial: 3, iter: 1600, curr loss: 1.3844376802444458, avg loss: 1.3863600236177445\n",
      "trial: 3, iter: 1800, curr loss: 1.3862800598144531, avg loss: 1.3864204740524293\n",
      "trial: 3, iter: 2000, curr loss: 1.3874704837799072, avg loss: 1.386325865983963\n",
      "trial: 3, iter: 2200, curr loss: 1.387113332748413, avg loss: 1.3863986092805862\n",
      "trial: 3, iter: 2400, curr loss: 1.3858681917190552, avg loss: 1.386310983300209\n",
      "trial: 3, iter: 2600, curr loss: 1.3859517574310303, avg loss: 1.3863541835546493\n",
      "trial: 3, iter: 2800, curr loss: 1.386580228805542, avg loss: 1.3863619488477708\n",
      "trial: 3, iter: 3000, curr loss: 1.3863279819488525, avg loss: 1.3864104169607163\n",
      "trial: 3, iter: 3200, curr loss: 1.3865107297897339, avg loss: 1.386319918036461\n",
      "trial: 3, iter: 3400, curr loss: 1.38638174533844, avg loss: 1.386409534215927\n",
      "trial: 3, iter: 3600, curr loss: 1.386904239654541, avg loss: 1.386350091099739\n",
      "trial: 3, iter: 3800, curr loss: 1.3858752250671387, avg loss: 1.3863498985767364\n",
      "trial: 3, iter: 4000, curr loss: 1.3867934942245483, avg loss: 1.3863574212789536\n",
      "trial: 3, iter: 4200, curr loss: 1.3865009546279907, avg loss: 1.3863370019197463\n",
      "trial: 3, iter: 4400, curr loss: 1.3853398561477661, avg loss: 1.3863086575269699\n",
      "trial: 3, iter: 4600, curr loss: 1.3864154815673828, avg loss: 1.3863699918985366\n",
      "trial: 3, iter: 4800, curr loss: 1.3849642276763916, avg loss: 1.386280723810196\n",
      "trial: 3, iter: 5000, curr loss: 1.3864928483963013, avg loss: 1.386374745965004\n",
      "trial: 3, iter: 5200, curr loss: 1.385915756225586, avg loss: 1.3863392186164856\n",
      "trial: 3, iter: 5400, curr loss: 1.3863943815231323, avg loss: 1.3863284426927567\n",
      "trial: 3, iter: 5600, curr loss: 1.3864094018936157, avg loss: 1.386342842578888\n",
      "trial: 3, iter: 5800, curr loss: 1.3862740993499756, avg loss: 1.3863854491710663\n",
      "trial: 3, iter: 6000, curr loss: 1.386160135269165, avg loss: 1.3862944859266282\n",
      "trial: 3, iter: 6200, curr loss: 1.3862792253494263, avg loss: 1.386321053504944\n",
      "trial: 3, iter: 6400, curr loss: 1.386229395866394, avg loss: 1.3863092976808549\n",
      "trial: 3, iter: 6600, curr loss: 1.386409878730774, avg loss: 1.3862597823143006\n",
      "trial: 3, iter: 6800, curr loss: 1.385697841644287, avg loss: 1.3863943666219711\n",
      "trial: 3, iter: 7000, curr loss: 1.386183738708496, avg loss: 1.3863094872236252\n",
      "trial: 3, iter: 7200, curr loss: 1.3864127397537231, avg loss: 1.386334907412529\n",
      "trial: 3, iter: 7400, curr loss: 1.386406421661377, avg loss: 1.3863173407316207\n",
      "trial: 3, iter: 7600, curr loss: 1.3865282535552979, avg loss: 1.3862941163778304\n",
      "trial: 3, iter: 7800, curr loss: 1.3867753744125366, avg loss: 1.3863509285449982\n",
      "trial: 3, iter: 8000, curr loss: 1.385901927947998, avg loss: 1.3862981367111207\n",
      "trial: 3, iter: 8200, curr loss: 1.3868027925491333, avg loss: 1.386288052201271\n",
      "trial: 3, iter: 8400, curr loss: 1.3857874870300293, avg loss: 1.386301302909851\n",
      "trial: 3, iter: 8600, curr loss: 1.3860161304473877, avg loss: 1.3863179934024812\n",
      "trial: 3, iter: 8800, curr loss: 1.3859825134277344, avg loss: 1.386298822760582\n",
      "trial: 3, iter: 9000, curr loss: 1.386505365371704, avg loss: 1.3863178950548172\n",
      "trial: 3, iter: 9200, curr loss: 1.386733889579773, avg loss: 1.3863387179374695\n",
      "trial: 3, iter: 9400, curr loss: 1.3864537477493286, avg loss: 1.386356241106987\n",
      "trial: 3, iter: 9600, curr loss: 1.3865259885787964, avg loss: 1.3863244593143462\n",
      "trial: 3, iter: 9800, curr loss: 1.3861618041992188, avg loss: 1.386287591457367\n",
      "trial: 3, iter: 10000, curr loss: 1.3862621784210205, avg loss: 1.386302251815796\n",
      "trial: 3, iter: 10200, curr loss: 1.386122226715088, avg loss: 1.3862941962480546\n",
      "trial: 3, iter: 10400, curr loss: 1.3857413530349731, avg loss: 1.3863052701950074\n",
      "trial: 3, iter: 10600, curr loss: 1.3860681056976318, avg loss: 1.3863426303863526\n",
      "trial: 3, iter: 10800, curr loss: 1.3862117528915405, avg loss: 1.3863026028871537\n",
      "trial: 3, iter: 11000, curr loss: 1.386338472366333, avg loss: 1.386334649324417\n",
      "trial: 3, iter: 11200, curr loss: 1.3864550590515137, avg loss: 1.3863112181425095\n",
      "trial: 3, iter: 11400, curr loss: 1.386103868484497, avg loss: 1.3862976711988448\n",
      "trial: 3, iter: 11600, curr loss: 1.3860920667648315, avg loss: 1.386330273747444\n",
      "trial: 3, iter: 11800, curr loss: 1.3862582445144653, avg loss: 1.386295397877693\n",
      "trial: 3, iter: 12000, curr loss: 1.3869322538375854, avg loss: 1.3862991470098496\n",
      "trial: 3, iter: 12200, curr loss: 1.386335015296936, avg loss: 1.3863269096612931\n",
      "trial: 3, iter: 12400, curr loss: 1.3866127729415894, avg loss: 1.3862838554382324\n",
      "trial: 3, iter: 12600, curr loss: 1.3864567279815674, avg loss: 1.386308983564377\n",
      "trial: 3, iter: 12800, curr loss: 1.3866207599639893, avg loss: 1.3863022440671922\n",
      "trial: 3, iter: 13000, curr loss: 1.3851372003555298, avg loss: 1.3863269084692\n",
      "trial: 3, iter: 13200, curr loss: 1.3862639665603638, avg loss: 1.3863278025388717\n",
      "trial: 3, iter: 13400, curr loss: 1.3863661289215088, avg loss: 1.386372526884079\n",
      "trial: 3, iter: 13600, curr loss: 1.3860901594161987, avg loss: 1.3863177251815797\n",
      "trial: 3, iter: 13800, curr loss: 1.3863872289657593, avg loss: 1.3863347852230072\n",
      "trial: 3, iter: 14000, curr loss: 1.3861351013183594, avg loss: 1.3863070452213286\n",
      "trial: 3, iter: 14200, curr loss: 1.3857755661010742, avg loss: 1.386293557882309\n",
      "trial: 3, iter: 14400, curr loss: 1.3860116004943848, avg loss: 1.3863139742612838\n",
      "trial: 3, iter: 14600, curr loss: 1.3865344524383545, avg loss: 1.3863219380378724\n",
      "trial: 3, iter: 14800, curr loss: 1.3868025541305542, avg loss: 1.3863130080699921\n",
      "trial: 3, iter: 15000, curr loss: 1.38644540309906, avg loss: 1.3863020539283752\n",
      "trial: 3, iter: 15200, curr loss: 1.3862382173538208, avg loss: 1.3863248652219773\n",
      "trial: 3, iter: 15400, curr loss: 1.3862178325653076, avg loss: 1.3863077384233475\n",
      "trial: 3, iter: 15600, curr loss: 1.3862457275390625, avg loss: 1.386308832168579\n",
      "trial: 3, ldr: -0.0008982239523902535\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3844144344329834, avg loss: 1.3875774896144868\n",
      "trial: 4, iter: 400, curr loss: 1.3846780061721802, avg loss: 1.3867590832710266\n",
      "trial: 4, iter: 600, curr loss: 1.383847713470459, avg loss: 1.3866170889139176\n",
      "trial: 4, iter: 800, curr loss: 1.3889847993850708, avg loss: 1.3866521090269088\n",
      "trial: 4, iter: 1000, curr loss: 1.3883867263793945, avg loss: 1.3864723604917526\n",
      "trial: 4, iter: 1200, curr loss: 1.385517954826355, avg loss: 1.3864298832416535\n",
      "trial: 4, iter: 1400, curr loss: 1.38798189163208, avg loss: 1.386454006433487\n",
      "trial: 4, iter: 1600, curr loss: 1.3848294019699097, avg loss: 1.3864011669158935\n",
      "trial: 4, iter: 1800, curr loss: 1.3854844570159912, avg loss: 1.3864300972223282\n",
      "trial: 4, iter: 2000, curr loss: 1.386731505393982, avg loss: 1.3864152365922928\n",
      "trial: 4, iter: 2200, curr loss: 1.3859362602233887, avg loss: 1.38641807615757\n",
      "trial: 4, iter: 2400, curr loss: 1.3863847255706787, avg loss: 1.3863739347457886\n",
      "trial: 4, iter: 2600, curr loss: 1.386365532875061, avg loss: 1.386340108513832\n",
      "trial: 4, iter: 2800, curr loss: 1.3853641748428345, avg loss: 1.3864108228683472\n",
      "trial: 4, iter: 3000, curr loss: 1.3858388662338257, avg loss: 1.386365343928337\n",
      "trial: 4, iter: 3200, curr loss: 1.3857277631759644, avg loss: 1.3863099294900894\n",
      "trial: 4, iter: 3400, curr loss: 1.3859411478042603, avg loss: 1.3863181483745575\n",
      "trial: 4, iter: 3600, curr loss: 1.3864483833312988, avg loss: 1.3863408374786377\n",
      "trial: 4, iter: 3800, curr loss: 1.3864167928695679, avg loss: 1.3863164925575255\n",
      "trial: 4, iter: 4000, curr loss: 1.3864436149597168, avg loss: 1.3863537842035294\n",
      "trial: 4, iter: 4200, curr loss: 1.386396884918213, avg loss: 1.3863194942474366\n",
      "trial: 4, iter: 4400, curr loss: 1.386409878730774, avg loss: 1.386331685781479\n",
      "trial: 4, iter: 4600, curr loss: 1.3859186172485352, avg loss: 1.3863016444444656\n",
      "trial: 4, iter: 4800, curr loss: 1.3865675926208496, avg loss: 1.3862854290008544\n",
      "trial: 4, iter: 5000, curr loss: 1.3852092027664185, avg loss: 1.3863122940063477\n",
      "trial: 4, iter: 5200, curr loss: 1.3862193822860718, avg loss: 1.386432101726532\n",
      "trial: 4, iter: 5400, curr loss: 1.3852499723434448, avg loss: 1.3863644111156463\n",
      "trial: 4, iter: 5600, curr loss: 1.3868714570999146, avg loss: 1.386369960308075\n",
      "trial: 4, iter: 5800, curr loss: 1.3860262632369995, avg loss: 1.38639506816864\n",
      "trial: 4, iter: 6000, curr loss: 1.3859727382659912, avg loss: 1.3863637363910675\n",
      "trial: 4, iter: 6200, curr loss: 1.386354923248291, avg loss: 1.38634963452816\n",
      "trial: 4, iter: 6400, curr loss: 1.3861104249954224, avg loss: 1.3863014644384384\n",
      "trial: 4, iter: 6600, curr loss: 1.3860551118850708, avg loss: 1.3862783068418503\n",
      "trial: 4, iter: 6800, curr loss: 1.3864550590515137, avg loss: 1.3863137489557267\n",
      "trial: 4, iter: 7000, curr loss: 1.3860516548156738, avg loss: 1.3862920594215393\n",
      "trial: 4, iter: 7200, curr loss: 1.386824131011963, avg loss: 1.3863116902112962\n",
      "trial: 4, iter: 7400, curr loss: 1.3863085508346558, avg loss: 1.3863622653484344\n",
      "trial: 4, iter: 7600, curr loss: 1.3864896297454834, avg loss: 1.3863288712501527\n",
      "trial: 4, iter: 7800, curr loss: 1.3861874341964722, avg loss: 1.3863282507658006\n",
      "trial: 4, iter: 8000, curr loss: 1.3853713274002075, avg loss: 1.3862802827358245\n",
      "trial: 4, iter: 8200, curr loss: 1.385898232460022, avg loss: 1.3863670033216478\n",
      "trial: 4, iter: 8400, curr loss: 1.3867933750152588, avg loss: 1.3862636947631837\n",
      "trial: 4, iter: 8600, curr loss: 1.386394739151001, avg loss: 1.3862977975606918\n",
      "trial: 4, iter: 8800, curr loss: 1.3851464986801147, avg loss: 1.3863309890031814\n",
      "trial: 4, iter: 9000, curr loss: 1.3850867748260498, avg loss: 1.3863359600305558\n",
      "trial: 4, iter: 9200, curr loss: 1.38594388961792, avg loss: 1.3863324064016342\n",
      "trial: 4, iter: 9400, curr loss: 1.3862926959991455, avg loss: 1.386300733089447\n",
      "trial: 4, iter: 9600, curr loss: 1.3862941265106201, avg loss: 1.3863118779659271\n",
      "trial: 4, iter: 9800, curr loss: 1.3864374160766602, avg loss: 1.386305009126663\n",
      "trial: 4, iter: 10000, curr loss: 1.3862903118133545, avg loss: 1.3862949746847153\n",
      "trial: 4, iter: 10200, curr loss: 1.3860963582992554, avg loss: 1.386303147673607\n",
      "trial: 4, iter: 10400, curr loss: 1.3859773874282837, avg loss: 1.3863088876008987\n",
      "trial: 4, iter: 10600, curr loss: 1.3867504596710205, avg loss: 1.3863108575344085\n",
      "trial: 4, iter: 10800, curr loss: 1.3863308429718018, avg loss: 1.3863046288490295\n",
      "trial: 4, iter: 11000, curr loss: 1.3861829042434692, avg loss: 1.3862769663333894\n",
      "trial: 4, iter: 11200, curr loss: 1.3865346908569336, avg loss: 1.386302992105484\n",
      "trial: 4, iter: 11400, curr loss: 1.3863896131515503, avg loss: 1.3863113355636596\n",
      "trial: 4, iter: 11600, curr loss: 1.3867768049240112, avg loss: 1.386299707889557\n",
      "trial: 4, iter: 11800, curr loss: 1.3862415552139282, avg loss: 1.3863112193346023\n",
      "trial: 4, iter: 12000, curr loss: 1.3862793445587158, avg loss: 1.3862973868846893\n",
      "trial: 4, iter: 12200, curr loss: 1.3862906694412231, avg loss: 1.3862941652536391\n",
      "trial: 4, iter: 12400, curr loss: 1.3862942457199097, avg loss: 1.3862947636842728\n",
      "trial: 4, iter: 12600, curr loss: 1.3862946033477783, avg loss: 1.3862940239906312\n",
      "trial: 4, iter: 12800, curr loss: 1.3862946033477783, avg loss: 1.3862950921058654\n",
      "trial: 4, iter: 13000, curr loss: 1.3862943649291992, avg loss: 1.3862939196825028\n",
      "trial: 4, iter: 13200, curr loss: 1.3862946033477783, avg loss: 1.3862951749563217\n",
      "trial: 4, iter: 13400, curr loss: 1.3862941265106201, avg loss: 1.386294754743576\n",
      "trial: 4, iter: 13600, curr loss: 1.3862941265106201, avg loss: 1.3862945795059205\n",
      "trial: 4, iter: 13800, curr loss: 1.3862943649291992, avg loss: 1.3862950140237809\n",
      "trial: 4, iter: 14000, curr loss: 1.3862946033477783, avg loss: 1.3862943387031554\n",
      "trial: 4, iter: 14200, curr loss: 1.3862946033477783, avg loss: 1.3862946289777756\n",
      "trial: 4, iter: 14400, curr loss: 1.3862942457199097, avg loss: 1.3862946456670762\n",
      "trial: 4, iter: 14600, curr loss: 1.3862943649291992, avg loss: 1.386294441819191\n",
      "trial: 4, iter: 14800, curr loss: 1.3862947225570679, avg loss: 1.3862942743301392\n",
      "trial: 4, iter: 15000, curr loss: 1.386282205581665, avg loss: 1.3863034564256669\n",
      "trial: 4, iter: 15200, curr loss: 1.3862885236740112, avg loss: 1.3863043230772019\n",
      "trial: 4, iter: 15400, curr loss: 1.3862944841384888, avg loss: 1.3862949007749557\n",
      "trial: 4, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3862946826219558\n",
      "trial: 4, ldr: 1.3355445844354108e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385918378829956, avg loss: 1.387413671016693\n",
      "trial: 5, iter: 400, curr loss: 1.386009931564331, avg loss: 1.3868361645936966\n",
      "trial: 5, iter: 600, curr loss: 1.3843891620635986, avg loss: 1.386631583571434\n",
      "trial: 5, iter: 800, curr loss: 1.3882731199264526, avg loss: 1.3865201181173326\n",
      "trial: 5, iter: 1000, curr loss: 1.3871493339538574, avg loss: 1.3863767671585083\n",
      "trial: 5, iter: 1200, curr loss: 1.3861193656921387, avg loss: 1.3863983803987503\n",
      "trial: 5, iter: 1400, curr loss: 1.3890249729156494, avg loss: 1.386358019709587\n",
      "trial: 5, iter: 1600, curr loss: 1.3857367038726807, avg loss: 1.3864243948459625\n",
      "trial: 5, iter: 1800, curr loss: 1.3871548175811768, avg loss: 1.386362743973732\n",
      "trial: 5, iter: 2000, curr loss: 1.386613130569458, avg loss: 1.3863830912113189\n",
      "trial: 5, iter: 2200, curr loss: 1.3866099119186401, avg loss: 1.386445518732071\n",
      "trial: 5, iter: 2400, curr loss: 1.3865619897842407, avg loss: 1.3863138490915299\n",
      "trial: 5, iter: 2600, curr loss: 1.3876830339431763, avg loss: 1.3863569456338882\n",
      "trial: 5, iter: 2800, curr loss: 1.3860911130905151, avg loss: 1.3862754613161088\n",
      "trial: 5, iter: 3000, curr loss: 1.3857438564300537, avg loss: 1.386399194598198\n",
      "trial: 5, iter: 3200, curr loss: 1.3861347436904907, avg loss: 1.3863130295276642\n",
      "trial: 5, iter: 3400, curr loss: 1.3864513635635376, avg loss: 1.3863654899597169\n",
      "trial: 5, iter: 3600, curr loss: 1.3858002424240112, avg loss: 1.3863350826501846\n",
      "trial: 5, iter: 3800, curr loss: 1.3861677646636963, avg loss: 1.3863180994987487\n",
      "trial: 5, iter: 4000, curr loss: 1.3859463930130005, avg loss: 1.3863172340393066\n",
      "trial: 5, iter: 4200, curr loss: 1.3864216804504395, avg loss: 1.3863304978609086\n",
      "trial: 5, iter: 4400, curr loss: 1.3862829208374023, avg loss: 1.3863130205869674\n",
      "trial: 5, iter: 4600, curr loss: 1.3867127895355225, avg loss: 1.386305469274521\n",
      "trial: 5, iter: 4800, curr loss: 1.3859065771102905, avg loss: 1.3863091975450517\n",
      "trial: 5, iter: 5000, curr loss: 1.386478066444397, avg loss: 1.3863438844680787\n",
      "trial: 5, iter: 5200, curr loss: 1.386202096939087, avg loss: 1.3863103473186493\n",
      "trial: 5, iter: 5400, curr loss: 1.386999487876892, avg loss: 1.3863372027873992\n",
      "trial: 5, iter: 5600, curr loss: 1.3865679502487183, avg loss: 1.386290050148964\n",
      "trial: 5, iter: 5800, curr loss: 1.385826826095581, avg loss: 1.3863041758537293\n",
      "trial: 5, iter: 6000, curr loss: 1.3860121965408325, avg loss: 1.3863341003656386\n",
      "trial: 5, iter: 6200, curr loss: 1.3863142728805542, avg loss: 1.3863202553987504\n",
      "trial: 5, iter: 6400, curr loss: 1.3863166570663452, avg loss: 1.3863078927993775\n",
      "trial: 5, iter: 6600, curr loss: 1.386440396308899, avg loss: 1.3862982124090195\n",
      "trial: 5, iter: 6800, curr loss: 1.3863880634307861, avg loss: 1.3863190668821335\n",
      "trial: 5, iter: 7000, curr loss: 1.3860752582550049, avg loss: 1.386284481883049\n",
      "trial: 5, iter: 7200, curr loss: 1.3863883018493652, avg loss: 1.3863192188739777\n",
      "trial: 5, iter: 7400, curr loss: 1.3864973783493042, avg loss: 1.3863099467754365\n",
      "trial: 5, iter: 7600, curr loss: 1.3864022493362427, avg loss: 1.386313863992691\n",
      "trial: 5, iter: 7800, curr loss: 1.3866075277328491, avg loss: 1.3863013768196106\n",
      "trial: 5, iter: 8000, curr loss: 1.3863656520843506, avg loss: 1.3863181298971177\n",
      "trial: 5, iter: 8200, curr loss: 1.3863136768341064, avg loss: 1.3862983322143554\n",
      "trial: 5, iter: 8400, curr loss: 1.3863115310668945, avg loss: 1.3862994313240051\n",
      "trial: 5, iter: 8600, curr loss: 1.3863435983657837, avg loss: 1.3863526701927185\n",
      "trial: 5, iter: 8800, curr loss: 1.3867908716201782, avg loss: 1.3862935531139373\n",
      "trial: 5, iter: 9000, curr loss: 1.3866928815841675, avg loss: 1.386331495642662\n",
      "trial: 5, iter: 9200, curr loss: 1.3859797716140747, avg loss: 1.3863275861740112\n",
      "trial: 5, iter: 9400, curr loss: 1.386254906654358, avg loss: 1.386320369243622\n",
      "trial: 5, iter: 9600, curr loss: 1.3860626220703125, avg loss: 1.3862850922346115\n",
      "trial: 5, iter: 9800, curr loss: 1.3870248794555664, avg loss: 1.386309473514557\n",
      "trial: 5, iter: 10000, curr loss: 1.3860241174697876, avg loss: 1.3863049256801605\n",
      "trial: 5, iter: 10200, curr loss: 1.3870973587036133, avg loss: 1.3863238632678985\n",
      "trial: 5, iter: 10400, curr loss: 1.3861489295959473, avg loss: 1.3862812358140946\n",
      "trial: 5, iter: 10600, curr loss: 1.3864060640335083, avg loss: 1.3863136887550354\n",
      "trial: 5, iter: 10800, curr loss: 1.3862228393554688, avg loss: 1.3863227951526642\n",
      "trial: 5, iter: 11000, curr loss: 1.387050747871399, avg loss: 1.3862903583049775\n",
      "trial: 5, iter: 11200, curr loss: 1.3860055208206177, avg loss: 1.3862867945432662\n",
      "trial: 5, iter: 11400, curr loss: 1.3865488767623901, avg loss: 1.3863118624687194\n",
      "trial: 5, iter: 11600, curr loss: 1.3858839273452759, avg loss: 1.3863683706521988\n",
      "trial: 5, iter: 11800, curr loss: 1.3865610361099243, avg loss: 1.3863515001535416\n",
      "trial: 5, iter: 12000, curr loss: 1.3863602876663208, avg loss: 1.3863267868757247\n",
      "trial: 5, iter: 12200, curr loss: 1.3860900402069092, avg loss: 1.3862883919477462\n",
      "trial: 5, iter: 12400, curr loss: 1.3864092826843262, avg loss: 1.3862874549627304\n",
      "trial: 5, iter: 12600, curr loss: 1.3862383365631104, avg loss: 1.3863072746992111\n",
      "trial: 5, iter: 12800, curr loss: 1.3865870237350464, avg loss: 1.3862848645448684\n",
      "trial: 5, iter: 13000, curr loss: 1.386786699295044, avg loss: 1.3863003832101821\n",
      "trial: 5, iter: 13200, curr loss: 1.3859165906906128, avg loss: 1.3862882578372955\n",
      "trial: 5, iter: 13400, curr loss: 1.3860807418823242, avg loss: 1.386276136636734\n",
      "trial: 5, iter: 13600, curr loss: 1.3870368003845215, avg loss: 1.3862897741794586\n",
      "trial: 5, iter: 13800, curr loss: 1.3860903978347778, avg loss: 1.386348650455475\n",
      "trial: 5, iter: 14000, curr loss: 1.3864461183547974, avg loss: 1.3863099175691604\n",
      "trial: 5, iter: 14200, curr loss: 1.3851171731948853, avg loss: 1.3862642431259156\n",
      "trial: 5, iter: 14400, curr loss: 1.385727047920227, avg loss: 1.3863577491044998\n",
      "trial: 5, iter: 14600, curr loss: 1.3859268426895142, avg loss: 1.3863678777217865\n",
      "trial: 5, iter: 14800, curr loss: 1.3858779668807983, avg loss: 1.386305233836174\n",
      "trial: 5, iter: 15000, curr loss: 1.386221170425415, avg loss: 1.3863167107105254\n",
      "trial: 5, iter: 15200, curr loss: 1.3864250183105469, avg loss: 1.3863024014234542\n",
      "trial: 5, iter: 15400, curr loss: 1.3861045837402344, avg loss: 1.386329372525215\n",
      "trial: 5, iter: 15600, curr loss: 1.385461688041687, avg loss: 1.386333217024803\n",
      "trial: 5, ldr: 0.005724193062633276\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0005234172080236021\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3872438669204712, avg loss: 1.3872029268741608\n",
      "trial: 1, iter: 400, curr loss: 1.3884469270706177, avg loss: 1.3867292749881743\n",
      "trial: 1, iter: 600, curr loss: 1.3884966373443604, avg loss: 1.3867528134584426\n",
      "trial: 1, iter: 800, curr loss: 1.3870714902877808, avg loss: 1.3865353697538376\n",
      "trial: 1, iter: 1000, curr loss: 1.3873932361602783, avg loss: 1.3864333963394164\n",
      "trial: 1, iter: 1200, curr loss: 1.3865312337875366, avg loss: 1.3865060925483703\n",
      "trial: 1, iter: 1400, curr loss: 1.3869495391845703, avg loss: 1.38639619410038\n",
      "trial: 1, iter: 1600, curr loss: 1.3857861757278442, avg loss: 1.3864332503080368\n",
      "trial: 1, iter: 1800, curr loss: 1.387062907218933, avg loss: 1.386345586180687\n",
      "trial: 1, iter: 2000, curr loss: 1.3869622945785522, avg loss: 1.3863987201452255\n",
      "trial: 1, iter: 2200, curr loss: 1.3860929012298584, avg loss: 1.3863358354568482\n",
      "trial: 1, iter: 2400, curr loss: 1.385825276374817, avg loss: 1.386308441758156\n",
      "trial: 1, iter: 2600, curr loss: 1.3868346214294434, avg loss: 1.386348051428795\n",
      "trial: 1, iter: 2800, curr loss: 1.3867340087890625, avg loss: 1.3863491839170456\n",
      "trial: 1, iter: 3000, curr loss: 1.3860793113708496, avg loss: 1.386309441924095\n",
      "trial: 1, iter: 3200, curr loss: 1.3861885070800781, avg loss: 1.3863225013017655\n",
      "trial: 1, iter: 3400, curr loss: 1.38641357421875, avg loss: 1.3862682557106019\n",
      "trial: 1, iter: 3600, curr loss: 1.386114239692688, avg loss: 1.3863014966249465\n",
      "trial: 1, iter: 3800, curr loss: 1.3853837251663208, avg loss: 1.386325907111168\n",
      "trial: 1, iter: 4000, curr loss: 1.385498285293579, avg loss: 1.3862942898273467\n",
      "trial: 1, iter: 4200, curr loss: 1.3867013454437256, avg loss: 1.3863359606266021\n",
      "trial: 1, iter: 4400, curr loss: 1.3860483169555664, avg loss: 1.3863299250602723\n",
      "trial: 1, iter: 4600, curr loss: 1.3870971202850342, avg loss: 1.3862960785627365\n",
      "trial: 1, iter: 4800, curr loss: 1.3864256143569946, avg loss: 1.3863305181264878\n",
      "trial: 1, iter: 5000, curr loss: 1.3865875005722046, avg loss: 1.3862643843889237\n",
      "trial: 1, iter: 5200, curr loss: 1.3864831924438477, avg loss: 1.3863417100906372\n",
      "trial: 1, iter: 5400, curr loss: 1.3861196041107178, avg loss: 1.3863157993555069\n",
      "trial: 1, iter: 5600, curr loss: 1.3871595859527588, avg loss: 1.3864179795980454\n",
      "trial: 1, iter: 5800, curr loss: 1.3864047527313232, avg loss: 1.3863714575767516\n",
      "trial: 1, iter: 6000, curr loss: 1.3863576650619507, avg loss: 1.386331812143326\n",
      "trial: 1, iter: 6200, curr loss: 1.3862301111221313, avg loss: 1.3862959635257721\n",
      "trial: 1, iter: 6400, curr loss: 1.3860048055648804, avg loss: 1.386302845478058\n",
      "trial: 1, iter: 6600, curr loss: 1.3863818645477295, avg loss: 1.3863418453931808\n",
      "trial: 1, iter: 6800, curr loss: 1.385379672050476, avg loss: 1.3863203823566437\n",
      "trial: 1, iter: 7000, curr loss: 1.3861578702926636, avg loss: 1.3863517528772353\n",
      "trial: 1, iter: 7200, curr loss: 1.386284351348877, avg loss: 1.386358278989792\n",
      "trial: 1, iter: 7400, curr loss: 1.3862590789794922, avg loss: 1.3863669836521149\n",
      "trial: 1, iter: 7600, curr loss: 1.3863381147384644, avg loss: 1.3863413286209108\n",
      "trial: 1, iter: 7800, curr loss: 1.385877251625061, avg loss: 1.3862890243530273\n",
      "trial: 1, iter: 8000, curr loss: 1.3862378597259521, avg loss: 1.386323751807213\n",
      "trial: 1, iter: 8200, curr loss: 1.386584758758545, avg loss: 1.3863627374172212\n",
      "trial: 1, iter: 8400, curr loss: 1.3860158920288086, avg loss: 1.3862972909212112\n",
      "trial: 1, iter: 8600, curr loss: 1.3856569528579712, avg loss: 1.3862790066003798\n",
      "trial: 1, iter: 8800, curr loss: 1.38594388961792, avg loss: 1.386338323354721\n",
      "trial: 1, iter: 9000, curr loss: 1.3863551616668701, avg loss: 1.386315267086029\n",
      "trial: 1, iter: 9200, curr loss: 1.386082410812378, avg loss: 1.3863096690177918\n",
      "trial: 1, iter: 9400, curr loss: 1.3863162994384766, avg loss: 1.3863043564558029\n",
      "trial: 1, iter: 9600, curr loss: 1.3863227367401123, avg loss: 1.3862948179244996\n",
      "trial: 1, iter: 9800, curr loss: 1.386246919631958, avg loss: 1.3862922418117523\n",
      "trial: 1, iter: 10000, curr loss: 1.386215329170227, avg loss: 1.3863044148683548\n",
      "trial: 1, iter: 10200, curr loss: 1.3863515853881836, avg loss: 1.386296610236168\n",
      "trial: 1, iter: 10400, curr loss: 1.386077642440796, avg loss: 1.3862733048200608\n",
      "trial: 1, iter: 10600, curr loss: 1.3864105939865112, avg loss: 1.386327766776085\n",
      "trial: 1, iter: 10800, curr loss: 1.386346459388733, avg loss: 1.3863044971227645\n",
      "trial: 1, iter: 11000, curr loss: 1.3863831758499146, avg loss: 1.3862983340024948\n",
      "trial: 1, iter: 11200, curr loss: 1.3863580226898193, avg loss: 1.3863011002540588\n",
      "trial: 1, iter: 11400, curr loss: 1.3866502046585083, avg loss: 1.3863158476352693\n",
      "trial: 1, iter: 11600, curr loss: 1.3868476152420044, avg loss: 1.3863162153959274\n",
      "trial: 1, iter: 11800, curr loss: 1.3868324756622314, avg loss: 1.3863454723358155\n",
      "trial: 1, iter: 12000, curr loss: 1.3869513273239136, avg loss: 1.3862786680459975\n",
      "trial: 1, iter: 12200, curr loss: 1.3861958980560303, avg loss: 1.3863475519418715\n",
      "trial: 1, iter: 12400, curr loss: 1.386820912361145, avg loss: 1.3863069480657577\n",
      "trial: 1, iter: 12600, curr loss: 1.386839747428894, avg loss: 1.3862564992904662\n",
      "trial: 1, iter: 12800, curr loss: 1.3859041929244995, avg loss: 1.3863467979431152\n",
      "trial: 1, iter: 13000, curr loss: 1.386046051979065, avg loss: 1.3863404029607773\n",
      "trial: 1, iter: 13200, curr loss: 1.3864452838897705, avg loss: 1.386296734213829\n",
      "trial: 1, iter: 13400, curr loss: 1.3858048915863037, avg loss: 1.3862389886379243\n",
      "trial: 1, iter: 13600, curr loss: 1.386371374130249, avg loss: 1.3863788366317749\n",
      "trial: 1, iter: 13800, curr loss: 1.3866392374038696, avg loss: 1.3862928104400636\n",
      "trial: 1, iter: 14000, curr loss: 1.3860435485839844, avg loss: 1.3862973797321319\n",
      "trial: 1, iter: 14200, curr loss: 1.3860465288162231, avg loss: 1.3863353896141053\n",
      "trial: 1, iter: 14400, curr loss: 1.3861051797866821, avg loss: 1.3863085597753524\n",
      "trial: 1, iter: 14600, curr loss: 1.3861051797866821, avg loss: 1.3862759792804717\n",
      "trial: 1, iter: 14800, curr loss: 1.3856112957000732, avg loss: 1.386314684152603\n",
      "trial: 1, iter: 15000, curr loss: 1.3860983848571777, avg loss: 1.38632506608963\n",
      "trial: 1, iter: 15200, curr loss: 1.3863162994384766, avg loss: 1.386299610733986\n",
      "trial: 1, iter: 15400, curr loss: 1.3862923383712769, avg loss: 1.3863062715530396\n",
      "trial: 1, iter: 15600, curr loss: 1.3864552974700928, avg loss: 1.3863085860013962\n",
      "trial: 1, ldr: 0.0019666114822030067\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3856632709503174, avg loss: 1.3875305515527725\n",
      "trial: 2, iter: 400, curr loss: 1.3853275775909424, avg loss: 1.38677605509758\n",
      "trial: 2, iter: 600, curr loss: 1.3893606662750244, avg loss: 1.3864790564775467\n",
      "trial: 2, iter: 800, curr loss: 1.3872255086898804, avg loss: 1.3864691883325577\n",
      "trial: 2, iter: 1000, curr loss: 1.3878203630447388, avg loss: 1.3864351469278335\n",
      "trial: 2, iter: 1200, curr loss: 1.386258840560913, avg loss: 1.3864454823732375\n",
      "trial: 2, iter: 1400, curr loss: 1.386317253112793, avg loss: 1.3863694453239441\n",
      "trial: 2, iter: 1600, curr loss: 1.3864556550979614, avg loss: 1.3863741534948348\n",
      "trial: 2, iter: 1800, curr loss: 1.3854037523269653, avg loss: 1.3863690835237503\n",
      "trial: 2, iter: 2000, curr loss: 1.3859189748764038, avg loss: 1.386287242770195\n",
      "trial: 2, iter: 2200, curr loss: 1.3852784633636475, avg loss: 1.386373575925827\n",
      "trial: 2, iter: 2400, curr loss: 1.3862920999526978, avg loss: 1.3863635212182999\n",
      "trial: 2, iter: 2600, curr loss: 1.3865243196487427, avg loss: 1.386315240263939\n",
      "trial: 2, iter: 2800, curr loss: 1.386703610420227, avg loss: 1.3863287717103958\n",
      "trial: 2, iter: 3000, curr loss: 1.3872663974761963, avg loss: 1.3863108372688293\n",
      "trial: 2, iter: 3200, curr loss: 1.3864458799362183, avg loss: 1.3863383615016938\n",
      "trial: 2, iter: 3400, curr loss: 1.385683536529541, avg loss: 1.3863085776567459\n",
      "trial: 2, iter: 3600, curr loss: 1.3867182731628418, avg loss: 1.3863667660951615\n",
      "trial: 2, iter: 3800, curr loss: 1.3872658014297485, avg loss: 1.3863579851388932\n",
      "trial: 2, iter: 4000, curr loss: 1.3862783908843994, avg loss: 1.3863280111551284\n",
      "trial: 2, iter: 4200, curr loss: 1.386319875717163, avg loss: 1.3863036745786668\n",
      "trial: 2, iter: 4400, curr loss: 1.3862825632095337, avg loss: 1.3862842476367951\n",
      "trial: 2, iter: 4600, curr loss: 1.3863084316253662, avg loss: 1.3863055664300918\n",
      "trial: 2, iter: 4800, curr loss: 1.3857660293579102, avg loss: 1.3863235300779342\n",
      "trial: 2, iter: 5000, curr loss: 1.3876001834869385, avg loss: 1.3863965690135955\n",
      "trial: 2, iter: 5200, curr loss: 1.3865175247192383, avg loss: 1.386401275396347\n",
      "trial: 2, iter: 5400, curr loss: 1.386122465133667, avg loss: 1.3863254272937775\n",
      "trial: 2, iter: 5600, curr loss: 1.3865717649459839, avg loss: 1.3863564032316207\n",
      "trial: 2, iter: 5800, curr loss: 1.3864176273345947, avg loss: 1.3863487964868546\n",
      "trial: 2, iter: 6000, curr loss: 1.386210560798645, avg loss: 1.3863057321310044\n",
      "trial: 2, iter: 6200, curr loss: 1.3861980438232422, avg loss: 1.3863003665208817\n",
      "trial: 2, iter: 6400, curr loss: 1.3868626356124878, avg loss: 1.3863791280984878\n",
      "trial: 2, iter: 6600, curr loss: 1.386306881904602, avg loss: 1.3863116943836211\n",
      "trial: 2, iter: 6800, curr loss: 1.3867217302322388, avg loss: 1.3862895268201827\n",
      "trial: 2, iter: 7000, curr loss: 1.3863362073898315, avg loss: 1.3863018691539764\n",
      "trial: 2, iter: 7200, curr loss: 1.3858627080917358, avg loss: 1.3862994801998139\n",
      "trial: 2, iter: 7400, curr loss: 1.3856014013290405, avg loss: 1.3862906962633132\n",
      "trial: 2, iter: 7600, curr loss: 1.386608600616455, avg loss: 1.3863440155982971\n",
      "trial: 2, iter: 7800, curr loss: 1.386356234550476, avg loss: 1.3863276010751724\n",
      "trial: 2, iter: 8000, curr loss: 1.3863718509674072, avg loss: 1.3863102185726166\n",
      "trial: 2, iter: 8200, curr loss: 1.3860888481140137, avg loss: 1.3862931579351425\n",
      "trial: 2, iter: 8400, curr loss: 1.3862651586532593, avg loss: 1.386329437494278\n",
      "trial: 2, iter: 8600, curr loss: 1.386447548866272, avg loss: 1.3863054990768433\n",
      "trial: 2, iter: 8800, curr loss: 1.3862560987472534, avg loss: 1.3863116735219956\n",
      "trial: 2, iter: 9000, curr loss: 1.3863210678100586, avg loss: 1.3862973469495774\n",
      "trial: 2, iter: 9200, curr loss: 1.3868584632873535, avg loss: 1.3862822049856185\n",
      "trial: 2, iter: 9400, curr loss: 1.3857667446136475, avg loss: 1.3862926000356675\n",
      "trial: 2, iter: 9600, curr loss: 1.3861123323440552, avg loss: 1.386330698132515\n",
      "trial: 2, iter: 9800, curr loss: 1.3858871459960938, avg loss: 1.3862844091653823\n",
      "trial: 2, iter: 10000, curr loss: 1.3863232135772705, avg loss: 1.3863481175899506\n",
      "trial: 2, iter: 10200, curr loss: 1.3862985372543335, avg loss: 1.3863029783964158\n",
      "trial: 2, iter: 10400, curr loss: 1.386572241783142, avg loss: 1.386273439526558\n",
      "trial: 2, iter: 10600, curr loss: 1.3861057758331299, avg loss: 1.3863181954622268\n",
      "trial: 2, iter: 10800, curr loss: 1.3864160776138306, avg loss: 1.3863083666563034\n",
      "trial: 2, iter: 11000, curr loss: 1.3865463733673096, avg loss: 1.386314236521721\n",
      "trial: 2, iter: 11200, curr loss: 1.3862144947052002, avg loss: 1.38629978120327\n",
      "trial: 2, iter: 11400, curr loss: 1.3863831758499146, avg loss: 1.3862999469041823\n",
      "trial: 2, iter: 11600, curr loss: 1.3863515853881836, avg loss: 1.3863040435314178\n",
      "trial: 2, iter: 11800, curr loss: 1.3863296508789062, avg loss: 1.386295902132988\n",
      "trial: 2, iter: 12000, curr loss: 1.3863178491592407, avg loss: 1.3862942969799041\n",
      "trial: 2, iter: 12200, curr loss: 1.3864036798477173, avg loss: 1.3862957352399825\n",
      "trial: 2, iter: 12400, curr loss: 1.3864376544952393, avg loss: 1.3863054716587067\n",
      "trial: 2, iter: 12600, curr loss: 1.3863916397094727, avg loss: 1.3863222366571426\n",
      "trial: 2, iter: 12800, curr loss: 1.3863424062728882, avg loss: 1.3863254225254058\n",
      "trial: 2, iter: 13000, curr loss: 1.3861632347106934, avg loss: 1.3862994241714477\n",
      "trial: 2, iter: 13200, curr loss: 1.3862626552581787, avg loss: 1.3863018125295639\n",
      "trial: 2, iter: 13400, curr loss: 1.3862448930740356, avg loss: 1.3863023519515991\n",
      "trial: 2, iter: 13600, curr loss: 1.3860739469528198, avg loss: 1.3862741106748582\n",
      "trial: 2, iter: 13800, curr loss: 1.3859996795654297, avg loss: 1.3863161635398864\n",
      "trial: 2, iter: 14000, curr loss: 1.3865680694580078, avg loss: 1.3863429176807402\n",
      "trial: 2, iter: 14200, curr loss: 1.3867186307907104, avg loss: 1.3862839430570602\n",
      "trial: 2, iter: 14400, curr loss: 1.3864105939865112, avg loss: 1.3863248807191848\n",
      "trial: 2, iter: 14600, curr loss: 1.3861790895462036, avg loss: 1.3862951159477235\n",
      "trial: 2, iter: 14800, curr loss: 1.3863880634307861, avg loss: 1.3862982100248338\n",
      "trial: 2, iter: 15000, curr loss: 1.386397361755371, avg loss: 1.386290225982666\n",
      "trial: 2, iter: 15200, curr loss: 1.3865026235580444, avg loss: 1.3863095194101334\n",
      "trial: 2, iter: 15400, curr loss: 1.3863099813461304, avg loss: 1.3863106322288514\n",
      "trial: 2, iter: 15600, curr loss: 1.3862566947937012, avg loss: 1.3863081115484237\n",
      "trial: 2, ldr: -0.0013772067613899708\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3897138833999634, avg loss: 1.3872796291112899\n",
      "trial: 3, iter: 400, curr loss: 1.3894950151443481, avg loss: 1.3868756926059722\n",
      "trial: 3, iter: 600, curr loss: 1.3893153667449951, avg loss: 1.3866712921857833\n",
      "trial: 3, iter: 800, curr loss: 1.3869740962982178, avg loss: 1.3864682632684708\n",
      "trial: 3, iter: 1000, curr loss: 1.3860056400299072, avg loss: 1.3864767718315125\n",
      "trial: 3, iter: 1200, curr loss: 1.3870199918746948, avg loss: 1.3863995778560638\n",
      "trial: 3, iter: 1400, curr loss: 1.3879369497299194, avg loss: 1.3863881367444992\n",
      "trial: 3, iter: 1600, curr loss: 1.3868085145950317, avg loss: 1.3864585310220718\n",
      "trial: 3, iter: 1800, curr loss: 1.3870012760162354, avg loss: 1.3863416945934295\n",
      "trial: 3, iter: 2000, curr loss: 1.3867136240005493, avg loss: 1.3863854962587356\n",
      "trial: 3, iter: 2200, curr loss: 1.3866262435913086, avg loss: 1.3863542354106904\n",
      "trial: 3, iter: 2400, curr loss: 1.385727047920227, avg loss: 1.3863651639223098\n",
      "trial: 3, iter: 2600, curr loss: 1.3855335712432861, avg loss: 1.3863427406549453\n",
      "trial: 3, iter: 2800, curr loss: 1.3869431018829346, avg loss: 1.386318203806877\n",
      "trial: 3, iter: 3000, curr loss: 1.3859279155731201, avg loss: 1.3863516068458557\n",
      "trial: 3, iter: 3200, curr loss: 1.3860763311386108, avg loss: 1.3863750833272934\n",
      "trial: 3, iter: 3400, curr loss: 1.386011004447937, avg loss: 1.3863543909788132\n",
      "trial: 3, iter: 3600, curr loss: 1.3861629962921143, avg loss: 1.386347319483757\n",
      "trial: 3, iter: 3800, curr loss: 1.38601553440094, avg loss: 1.3863545817136764\n",
      "trial: 3, iter: 4000, curr loss: 1.3868662118911743, avg loss: 1.3863107925653457\n",
      "trial: 3, iter: 4200, curr loss: 1.3857924938201904, avg loss: 1.3863708454370498\n",
      "trial: 3, iter: 4400, curr loss: 1.3861421346664429, avg loss: 1.3863567078113557\n",
      "trial: 3, iter: 4600, curr loss: 1.3862277269363403, avg loss: 1.3863157254457474\n",
      "trial: 3, iter: 4800, curr loss: 1.3865604400634766, avg loss: 1.386351728439331\n",
      "trial: 3, iter: 5000, curr loss: 1.3860499858856201, avg loss: 1.386300887465477\n",
      "trial: 3, iter: 5200, curr loss: 1.386351227760315, avg loss: 1.3863151097297668\n",
      "trial: 3, iter: 5400, curr loss: 1.385899305343628, avg loss: 1.3862855845689774\n",
      "trial: 3, iter: 5600, curr loss: 1.3858217000961304, avg loss: 1.3862884014844894\n",
      "trial: 3, iter: 5800, curr loss: 1.386548638343811, avg loss: 1.3863280630111694\n",
      "trial: 3, iter: 6000, curr loss: 1.386638879776001, avg loss: 1.3863172292709351\n",
      "trial: 3, iter: 6200, curr loss: 1.3865034580230713, avg loss: 1.3863359957933425\n",
      "trial: 3, iter: 6400, curr loss: 1.3862611055374146, avg loss: 1.386306032538414\n",
      "trial: 3, iter: 6600, curr loss: 1.3862345218658447, avg loss: 1.386299467086792\n",
      "trial: 3, iter: 6800, curr loss: 1.3860794305801392, avg loss: 1.3863026815652848\n",
      "trial: 3, iter: 7000, curr loss: 1.386134386062622, avg loss: 1.386306414604187\n",
      "trial: 3, iter: 7200, curr loss: 1.3863673210144043, avg loss: 1.3863076019287108\n",
      "trial: 3, iter: 7400, curr loss: 1.3861262798309326, avg loss: 1.3863224214315415\n",
      "trial: 3, iter: 7600, curr loss: 1.3863420486450195, avg loss: 1.3862997156381607\n",
      "trial: 3, iter: 7800, curr loss: 1.3866783380508423, avg loss: 1.386329025030136\n",
      "trial: 3, iter: 8000, curr loss: 1.3858953714370728, avg loss: 1.386398759484291\n",
      "trial: 3, iter: 8200, curr loss: 1.3853802680969238, avg loss: 1.3863021713495254\n",
      "trial: 3, iter: 8400, curr loss: 1.3864951133728027, avg loss: 1.3863733345270157\n",
      "trial: 3, iter: 8600, curr loss: 1.3862439393997192, avg loss: 1.386353812813759\n",
      "trial: 3, iter: 8800, curr loss: 1.3861353397369385, avg loss: 1.3863264685869217\n",
      "trial: 3, iter: 9000, curr loss: 1.3862929344177246, avg loss: 1.386299592256546\n",
      "trial: 3, iter: 9200, curr loss: 1.3866333961486816, avg loss: 1.3863168567419053\n",
      "trial: 3, iter: 9400, curr loss: 1.386431097984314, avg loss: 1.3863410133123397\n",
      "trial: 3, iter: 9600, curr loss: 1.386116862297058, avg loss: 1.3863444602489472\n",
      "trial: 3, iter: 9800, curr loss: 1.38582181930542, avg loss: 1.3862988984584808\n",
      "trial: 3, iter: 10000, curr loss: 1.386098027229309, avg loss: 1.3863118475675582\n",
      "trial: 3, iter: 10200, curr loss: 1.3861939907073975, avg loss: 1.386320742368698\n",
      "trial: 3, iter: 10400, curr loss: 1.3865625858306885, avg loss: 1.3863107281923295\n",
      "trial: 3, iter: 10600, curr loss: 1.386440634727478, avg loss: 1.386313492655754\n",
      "trial: 3, iter: 10800, curr loss: 1.3861418962478638, avg loss: 1.3863342148065567\n",
      "trial: 3, iter: 11000, curr loss: 1.3865056037902832, avg loss: 1.386337435245514\n",
      "trial: 3, iter: 11200, curr loss: 1.3862544298171997, avg loss: 1.3863149505853654\n",
      "trial: 3, iter: 11400, curr loss: 1.386277675628662, avg loss: 1.3863144904375075\n",
      "trial: 3, iter: 11600, curr loss: 1.3861923217773438, avg loss: 1.3862983083724976\n",
      "trial: 3, iter: 11800, curr loss: 1.3863810300827026, avg loss: 1.3863002115488052\n",
      "trial: 3, iter: 12000, curr loss: 1.3862472772598267, avg loss: 1.3863055539131164\n",
      "trial: 3, iter: 12200, curr loss: 1.3864169120788574, avg loss: 1.3863116824626922\n",
      "trial: 3, iter: 12400, curr loss: 1.3858250379562378, avg loss: 1.3862699800729752\n",
      "trial: 3, iter: 12600, curr loss: 1.3858269453048706, avg loss: 1.386267336010933\n",
      "trial: 3, iter: 12800, curr loss: 1.3862920999526978, avg loss: 1.3863486540317536\n",
      "trial: 3, iter: 13000, curr loss: 1.386383056640625, avg loss: 1.3863130116462707\n",
      "trial: 3, iter: 13200, curr loss: 1.3863391876220703, avg loss: 1.386294566988945\n",
      "trial: 3, iter: 13400, curr loss: 1.3864434957504272, avg loss: 1.3863052994012832\n",
      "trial: 3, iter: 13600, curr loss: 1.3861764669418335, avg loss: 1.3862658417224885\n",
      "trial: 3, iter: 13800, curr loss: 1.3863227367401123, avg loss: 1.386321415901184\n",
      "trial: 3, iter: 14000, curr loss: 1.3864953517913818, avg loss: 1.3863092476129533\n",
      "trial: 3, iter: 14200, curr loss: 1.3862698078155518, avg loss: 1.3863391262292861\n",
      "trial: 3, iter: 14400, curr loss: 1.3864160776138306, avg loss: 1.3863043129444121\n",
      "trial: 3, iter: 14600, curr loss: 1.3863811492919922, avg loss: 1.386297270655632\n",
      "trial: 3, iter: 14800, curr loss: 1.3864659070968628, avg loss: 1.3862957048416138\n",
      "trial: 3, iter: 15000, curr loss: 1.386243462562561, avg loss: 1.3863533127307892\n",
      "trial: 3, iter: 15200, curr loss: 1.3862919807434082, avg loss: 1.3862670075893402\n",
      "trial: 3, iter: 15400, curr loss: 1.3862659931182861, avg loss: 1.3862941718101502\n",
      "trial: 3, iter: 15600, curr loss: 1.3863297700881958, avg loss: 1.3863014578819275\n",
      "trial: 3, ldr: -0.00013134776963852346\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3902480602264404, avg loss: 1.3873414653539657\n",
      "trial: 4, iter: 400, curr loss: 1.3901921510696411, avg loss: 1.3866868835687638\n",
      "trial: 4, iter: 600, curr loss: 1.3859463930130005, avg loss: 1.3868552267551422\n",
      "trial: 4, iter: 800, curr loss: 1.3863790035247803, avg loss: 1.386336326599121\n",
      "trial: 4, iter: 1000, curr loss: 1.388118028640747, avg loss: 1.3865296357870103\n",
      "trial: 4, iter: 1200, curr loss: 1.3873541355133057, avg loss: 1.3864086854457855\n",
      "trial: 4, iter: 1400, curr loss: 1.3858637809753418, avg loss: 1.3863857448101045\n",
      "trial: 4, iter: 1600, curr loss: 1.3862779140472412, avg loss: 1.3864417934417725\n",
      "trial: 4, iter: 1800, curr loss: 1.3867650032043457, avg loss: 1.3863929295539856\n",
      "trial: 4, iter: 2000, curr loss: 1.3849741220474243, avg loss: 1.3863120025396347\n",
      "trial: 4, iter: 2200, curr loss: 1.386844515800476, avg loss: 1.3864101481437683\n",
      "trial: 4, iter: 2400, curr loss: 1.3870471715927124, avg loss: 1.386382765173912\n",
      "trial: 4, iter: 2600, curr loss: 1.38673734664917, avg loss: 1.386359246969223\n",
      "trial: 4, iter: 2800, curr loss: 1.3859543800354004, avg loss: 1.3863661563396454\n",
      "trial: 4, iter: 3000, curr loss: 1.3869603872299194, avg loss: 1.3863531869649888\n",
      "trial: 4, iter: 3200, curr loss: 1.3865216970443726, avg loss: 1.3863397938013078\n",
      "trial: 4, iter: 3400, curr loss: 1.3864976167678833, avg loss: 1.3863739669322968\n",
      "trial: 4, iter: 3600, curr loss: 1.3871296644210815, avg loss: 1.386319277882576\n",
      "trial: 4, iter: 3800, curr loss: 1.38687264919281, avg loss: 1.3863236373662948\n",
      "trial: 4, iter: 4000, curr loss: 1.3864097595214844, avg loss: 1.3863369578123093\n",
      "trial: 4, iter: 4200, curr loss: 1.3853569030761719, avg loss: 1.386303785443306\n",
      "trial: 4, iter: 4400, curr loss: 1.3865687847137451, avg loss: 1.386360263824463\n",
      "trial: 4, iter: 4600, curr loss: 1.3867958784103394, avg loss: 1.3863373667001724\n",
      "trial: 4, iter: 4800, curr loss: 1.3859171867370605, avg loss: 1.3863485425710678\n",
      "trial: 4, iter: 5000, curr loss: 1.3867069482803345, avg loss: 1.3863258373737335\n",
      "trial: 4, iter: 5200, curr loss: 1.387255072593689, avg loss: 1.3863292557001115\n",
      "trial: 4, iter: 5400, curr loss: 1.386132001876831, avg loss: 1.3863533544540405\n",
      "trial: 4, iter: 5600, curr loss: 1.3861100673675537, avg loss: 1.3863453733921052\n",
      "trial: 4, iter: 5800, curr loss: 1.3861178159713745, avg loss: 1.386296494603157\n",
      "trial: 4, iter: 6000, curr loss: 1.3859570026397705, avg loss: 1.3862801223993302\n",
      "trial: 4, iter: 6200, curr loss: 1.3867545127868652, avg loss: 1.3863231700658798\n",
      "trial: 4, iter: 6400, curr loss: 1.3864039182662964, avg loss: 1.3863128000497817\n",
      "trial: 4, iter: 6600, curr loss: 1.3857074975967407, avg loss: 1.3862837451696395\n",
      "trial: 4, iter: 6800, curr loss: 1.386504054069519, avg loss: 1.386347680091858\n",
      "trial: 4, iter: 7000, curr loss: 1.3865966796875, avg loss: 1.3863360053300857\n",
      "trial: 4, iter: 7200, curr loss: 1.3863228559494019, avg loss: 1.3863198953866958\n",
      "trial: 4, iter: 7400, curr loss: 1.386737585067749, avg loss: 1.3863335585594176\n",
      "trial: 4, iter: 7600, curr loss: 1.3862879276275635, avg loss: 1.3863028657436371\n",
      "trial: 4, iter: 7800, curr loss: 1.386295199394226, avg loss: 1.386295616030693\n",
      "trial: 4, iter: 8000, curr loss: 1.386089563369751, avg loss: 1.3863516610860824\n",
      "trial: 4, iter: 8200, curr loss: 1.3861889839172363, avg loss: 1.386301093697548\n",
      "trial: 4, iter: 8400, curr loss: 1.3849958181381226, avg loss: 1.3862858837842942\n",
      "trial: 4, iter: 8600, curr loss: 1.3859431743621826, avg loss: 1.3863176548480987\n",
      "trial: 4, iter: 8800, curr loss: 1.3854438066482544, avg loss: 1.3863393998146056\n",
      "trial: 4, iter: 9000, curr loss: 1.3860770463943481, avg loss: 1.3863326102495193\n",
      "trial: 4, iter: 9200, curr loss: 1.3865951299667358, avg loss: 1.3863532078266143\n",
      "trial: 4, iter: 9400, curr loss: 1.3863269090652466, avg loss: 1.3864281713962554\n",
      "trial: 4, iter: 9600, curr loss: 1.3860019445419312, avg loss: 1.3863001435995101\n",
      "trial: 4, iter: 9800, curr loss: 1.3864383697509766, avg loss: 1.3863183784484863\n",
      "trial: 4, iter: 10000, curr loss: 1.3860727548599243, avg loss: 1.3863105303049088\n",
      "trial: 4, iter: 10200, curr loss: 1.3866472244262695, avg loss: 1.386301491856575\n",
      "trial: 4, iter: 10400, curr loss: 1.3862186670303345, avg loss: 1.3862906378507613\n",
      "trial: 4, iter: 10600, curr loss: 1.3861826658248901, avg loss: 1.3863133716583251\n",
      "trial: 4, iter: 10800, curr loss: 1.3860160112380981, avg loss: 1.3862876856327058\n",
      "trial: 4, iter: 11000, curr loss: 1.3849127292633057, avg loss: 1.386268350481987\n",
      "trial: 4, iter: 11200, curr loss: 1.3862203359603882, avg loss: 1.3863694208860398\n",
      "trial: 4, iter: 11400, curr loss: 1.3861005306243896, avg loss: 1.3863107919692994\n",
      "trial: 4, iter: 11600, curr loss: 1.3873261213302612, avg loss: 1.386314992904663\n",
      "trial: 4, iter: 11800, curr loss: 1.3860796689987183, avg loss: 1.3863349121809005\n",
      "trial: 4, iter: 12000, curr loss: 1.3851150274276733, avg loss: 1.3863528180122375\n",
      "trial: 4, iter: 12200, curr loss: 1.3860135078430176, avg loss: 1.3863304901123046\n",
      "trial: 4, iter: 12400, curr loss: 1.3863681554794312, avg loss: 1.3862904781103134\n",
      "trial: 4, iter: 12600, curr loss: 1.3862284421920776, avg loss: 1.3863556891679765\n",
      "trial: 4, iter: 12800, curr loss: 1.3861018419265747, avg loss: 1.3863251465559006\n",
      "trial: 4, iter: 13000, curr loss: 1.3864693641662598, avg loss: 1.386328176856041\n",
      "trial: 4, iter: 13200, curr loss: 1.3864953517913818, avg loss: 1.386367889046669\n",
      "trial: 4, iter: 13400, curr loss: 1.3862813711166382, avg loss: 1.3863179171085358\n",
      "trial: 4, iter: 13600, curr loss: 1.3863203525543213, avg loss: 1.386300710439682\n",
      "trial: 4, iter: 13800, curr loss: 1.3876419067382812, avg loss: 1.3863318765163422\n",
      "trial: 4, iter: 14000, curr loss: 1.3863226175308228, avg loss: 1.386323666572571\n",
      "trial: 4, iter: 14200, curr loss: 1.3862788677215576, avg loss: 1.3862972313165665\n",
      "trial: 4, iter: 14400, curr loss: 1.3863961696624756, avg loss: 1.3862849164009095\n",
      "trial: 4, iter: 14600, curr loss: 1.3867149353027344, avg loss: 1.3863594037294389\n",
      "trial: 4, iter: 14800, curr loss: 1.386094570159912, avg loss: 1.3863053870201112\n",
      "trial: 4, iter: 15000, curr loss: 1.38615083694458, avg loss: 1.386299624443054\n",
      "trial: 4, iter: 15200, curr loss: 1.38609778881073, avg loss: 1.3862990087270737\n",
      "trial: 4, iter: 15400, curr loss: 1.3866117000579834, avg loss: 1.3863164657354354\n",
      "trial: 4, iter: 15600, curr loss: 1.3864352703094482, avg loss: 1.3863175493478774\n",
      "trial: 4, ldr: -0.0004512944142334163\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3902146816253662, avg loss: 1.3874963545799255\n",
      "trial: 5, iter: 400, curr loss: 1.388906717300415, avg loss: 1.3866603255271912\n",
      "trial: 5, iter: 600, curr loss: 1.3889291286468506, avg loss: 1.386605933904648\n",
      "trial: 5, iter: 800, curr loss: 1.3876566886901855, avg loss: 1.3865709871053695\n",
      "trial: 5, iter: 1000, curr loss: 1.3862334489822388, avg loss: 1.3865159338712691\n",
      "trial: 5, iter: 1200, curr loss: 1.3865331411361694, avg loss: 1.3862495344877244\n",
      "trial: 5, iter: 1400, curr loss: 1.385491132736206, avg loss: 1.386378979086876\n",
      "trial: 5, iter: 1600, curr loss: 1.386395812034607, avg loss: 1.3864053726196288\n",
      "trial: 5, iter: 1800, curr loss: 1.3865872621536255, avg loss: 1.386295835375786\n",
      "trial: 5, iter: 2000, curr loss: 1.3859131336212158, avg loss: 1.3863837337493896\n",
      "trial: 5, iter: 2200, curr loss: 1.3861905336380005, avg loss: 1.3863858193159104\n",
      "trial: 5, iter: 2400, curr loss: 1.3858757019042969, avg loss: 1.386406734585762\n",
      "trial: 5, iter: 2600, curr loss: 1.3868916034698486, avg loss: 1.38634146630764\n",
      "trial: 5, iter: 2800, curr loss: 1.3848954439163208, avg loss: 1.3863805562257767\n",
      "trial: 5, iter: 3000, curr loss: 1.3863122463226318, avg loss: 1.3864832365512847\n",
      "trial: 5, iter: 3200, curr loss: 1.3862683773040771, avg loss: 1.3863767796754838\n",
      "trial: 5, iter: 3400, curr loss: 1.3859567642211914, avg loss: 1.3863174700737\n",
      "trial: 5, iter: 3600, curr loss: 1.3861886262893677, avg loss: 1.3863680785894394\n",
      "trial: 5, iter: 3800, curr loss: 1.386385440826416, avg loss: 1.3863266897201538\n",
      "trial: 5, iter: 4000, curr loss: 1.3866064548492432, avg loss: 1.3863071805238725\n",
      "trial: 5, iter: 4200, curr loss: 1.3872253894805908, avg loss: 1.3863194113969803\n",
      "trial: 5, iter: 4400, curr loss: 1.386247158050537, avg loss: 1.3863255155086518\n",
      "trial: 5, iter: 4600, curr loss: 1.3866528272628784, avg loss: 1.3863107985258103\n",
      "trial: 5, iter: 4800, curr loss: 1.3864370584487915, avg loss: 1.3863334971666337\n",
      "trial: 5, iter: 5000, curr loss: 1.3862807750701904, avg loss: 1.386318580508232\n",
      "trial: 5, iter: 5200, curr loss: 1.386265754699707, avg loss: 1.3863127666711808\n",
      "trial: 5, iter: 5400, curr loss: 1.3858927488327026, avg loss: 1.3863024538755417\n",
      "trial: 5, iter: 5600, curr loss: 1.3868577480316162, avg loss: 1.3863167476654052\n",
      "trial: 5, iter: 5800, curr loss: 1.3861557245254517, avg loss: 1.386335290670395\n",
      "trial: 5, iter: 6000, curr loss: 1.3862252235412598, avg loss: 1.3863215935230255\n",
      "trial: 5, iter: 6200, curr loss: 1.3864712715148926, avg loss: 1.3862950092554092\n",
      "trial: 5, iter: 6400, curr loss: 1.386318325996399, avg loss: 1.3863216131925582\n",
      "trial: 5, iter: 6600, curr loss: 1.3861840963363647, avg loss: 1.3863238400220872\n",
      "trial: 5, iter: 6800, curr loss: 1.3867160081863403, avg loss: 1.386358026266098\n",
      "trial: 5, iter: 7000, curr loss: 1.3859846591949463, avg loss: 1.3863489466905594\n",
      "trial: 5, iter: 7200, curr loss: 1.385344386100769, avg loss: 1.3862562268972396\n",
      "trial: 5, iter: 7400, curr loss: 1.386432409286499, avg loss: 1.3863325697183608\n",
      "trial: 5, iter: 7600, curr loss: 1.3862757682800293, avg loss: 1.386310710310936\n",
      "trial: 5, iter: 7800, curr loss: 1.3861263990402222, avg loss: 1.386305751800537\n",
      "trial: 5, iter: 8000, curr loss: 1.3860485553741455, avg loss: 1.3863460147380828\n",
      "trial: 5, iter: 8200, curr loss: 1.3863283395767212, avg loss: 1.386301775574684\n",
      "trial: 5, iter: 8400, curr loss: 1.3863810300827026, avg loss: 1.386311925649643\n",
      "trial: 5, iter: 8600, curr loss: 1.3857293128967285, avg loss: 1.3862920486927033\n",
      "trial: 5, iter: 8800, curr loss: 1.3857430219650269, avg loss: 1.3863261610269546\n",
      "trial: 5, iter: 9000, curr loss: 1.3860337734222412, avg loss: 1.3863527530431747\n",
      "trial: 5, iter: 9200, curr loss: 1.386075496673584, avg loss: 1.3863004791736602\n",
      "trial: 5, iter: 9400, curr loss: 1.3859970569610596, avg loss: 1.3863034683465958\n",
      "trial: 5, iter: 9600, curr loss: 1.3861026763916016, avg loss: 1.3863254117965698\n",
      "trial: 5, iter: 9800, curr loss: 1.386152744293213, avg loss: 1.3863227677345276\n",
      "trial: 5, iter: 10000, curr loss: 1.3864436149597168, avg loss: 1.3863088744878769\n",
      "trial: 5, iter: 10200, curr loss: 1.3864362239837646, avg loss: 1.3863021916151046\n",
      "trial: 5, iter: 10400, curr loss: 1.386573076248169, avg loss: 1.3863136613368987\n",
      "trial: 5, iter: 10600, curr loss: 1.386377215385437, avg loss: 1.3863128209114075\n",
      "trial: 5, iter: 10800, curr loss: 1.3864158391952515, avg loss: 1.3862987607717514\n",
      "trial: 5, iter: 11000, curr loss: 1.3864227533340454, avg loss: 1.3863028961420059\n",
      "trial: 5, iter: 11200, curr loss: 1.3864498138427734, avg loss: 1.3862986719608308\n",
      "trial: 5, iter: 11400, curr loss: 1.3862501382827759, avg loss: 1.3862691420316695\n",
      "trial: 5, iter: 11600, curr loss: 1.3857576847076416, avg loss: 1.3862518328428268\n",
      "trial: 5, iter: 11800, curr loss: 1.3870394229888916, avg loss: 1.386357722878456\n",
      "trial: 5, iter: 12000, curr loss: 1.3865002393722534, avg loss: 1.3863480544090272\n",
      "trial: 5, iter: 12200, curr loss: 1.3866016864776611, avg loss: 1.3863052248954773\n",
      "trial: 5, iter: 12400, curr loss: 1.387014627456665, avg loss: 1.3862798094749451\n",
      "trial: 5, iter: 12600, curr loss: 1.3860714435577393, avg loss: 1.3863250261545181\n",
      "trial: 5, iter: 12800, curr loss: 1.3861972093582153, avg loss: 1.3863094758987426\n",
      "trial: 5, iter: 13000, curr loss: 1.3863937854766846, avg loss: 1.3863008683919906\n",
      "trial: 5, iter: 13200, curr loss: 1.3862323760986328, avg loss: 1.3863135039806367\n",
      "trial: 5, iter: 13400, curr loss: 1.3862890005111694, avg loss: 1.3863004088401794\n",
      "trial: 5, iter: 13600, curr loss: 1.386574625968933, avg loss: 1.3862975162267686\n",
      "trial: 5, iter: 13800, curr loss: 1.386688232421875, avg loss: 1.3862997251749039\n",
      "trial: 5, iter: 14000, curr loss: 1.3859137296676636, avg loss: 1.3863154524564743\n",
      "trial: 5, iter: 14200, curr loss: 1.386499047279358, avg loss: 1.3863149547576905\n",
      "trial: 5, iter: 14400, curr loss: 1.3862061500549316, avg loss: 1.3862901800870895\n",
      "trial: 5, iter: 14600, curr loss: 1.3857178688049316, avg loss: 1.386375817656517\n",
      "trial: 5, iter: 14800, curr loss: 1.3865585327148438, avg loss: 1.3863423550128937\n",
      "trial: 5, iter: 15000, curr loss: 1.3863978385925293, avg loss: 1.386330857872963\n",
      "trial: 5, iter: 15200, curr loss: 1.3862940073013306, avg loss: 1.3862810546159745\n",
      "trial: 5, iter: 15400, curr loss: 1.3859851360321045, avg loss: 1.3863117164373397\n",
      "trial: 5, iter: 15600, curr loss: 1.3862545490264893, avg loss: 1.3862995672225953\n",
      "trial: 5, ldr: -0.00023012082965578884\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -4.467165854293853e-05\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386003017425537, avg loss: 1.3876187193393708\n",
      "trial: 1, iter: 400, curr loss: 1.3872474431991577, avg loss: 1.3869142204523086\n",
      "trial: 1, iter: 600, curr loss: 1.3862988948822021, avg loss: 1.386537719964981\n",
      "trial: 1, iter: 800, curr loss: 1.3862427473068237, avg loss: 1.3865158081054687\n",
      "trial: 1, iter: 1000, curr loss: 1.387149453163147, avg loss: 1.3864263492822646\n",
      "trial: 1, iter: 1200, curr loss: 1.3873823881149292, avg loss: 1.3864992946386336\n",
      "trial: 1, iter: 1400, curr loss: 1.3865163326263428, avg loss: 1.3863381659984588\n",
      "trial: 1, iter: 1600, curr loss: 1.3874480724334717, avg loss: 1.3864371520280838\n",
      "trial: 1, iter: 1800, curr loss: 1.3860318660736084, avg loss: 1.3863893783092498\n",
      "trial: 1, iter: 2000, curr loss: 1.3860070705413818, avg loss: 1.386379953622818\n",
      "trial: 1, iter: 2200, curr loss: 1.3865302801132202, avg loss: 1.386352362036705\n",
      "trial: 1, iter: 2400, curr loss: 1.3868662118911743, avg loss: 1.3863422238826753\n",
      "trial: 1, iter: 2600, curr loss: 1.3866980075836182, avg loss: 1.3863296735286712\n",
      "trial: 1, iter: 2800, curr loss: 1.3865830898284912, avg loss: 1.3863583809137345\n",
      "trial: 1, iter: 3000, curr loss: 1.3864552974700928, avg loss: 1.3863365614414216\n",
      "trial: 1, iter: 3200, curr loss: 1.3867104053497314, avg loss: 1.38634153008461\n",
      "trial: 1, iter: 3400, curr loss: 1.3841514587402344, avg loss: 1.3862216168642043\n",
      "trial: 1, iter: 3600, curr loss: 1.3867448568344116, avg loss: 1.38645623087883\n",
      "trial: 1, iter: 3800, curr loss: 1.3858681917190552, avg loss: 1.3863369381427766\n",
      "trial: 1, iter: 4000, curr loss: 1.3863327503204346, avg loss: 1.3863395524024964\n",
      "trial: 1, iter: 4200, curr loss: 1.3863190412521362, avg loss: 1.386347422003746\n",
      "trial: 1, iter: 4400, curr loss: 1.3864697217941284, avg loss: 1.3863561809062959\n",
      "trial: 1, iter: 4600, curr loss: 1.3859822750091553, avg loss: 1.3863003087043761\n",
      "trial: 1, iter: 4800, curr loss: 1.3867563009262085, avg loss: 1.3863268572092056\n",
      "trial: 1, iter: 5000, curr loss: 1.3859312534332275, avg loss: 1.386343132853508\n",
      "trial: 1, iter: 5200, curr loss: 1.3861956596374512, avg loss: 1.3863335913419723\n",
      "trial: 1, iter: 5400, curr loss: 1.386588215827942, avg loss: 1.3862964433431626\n",
      "trial: 1, iter: 5600, curr loss: 1.3866655826568604, avg loss: 1.3863694524765016\n",
      "trial: 1, iter: 5800, curr loss: 1.386759877204895, avg loss: 1.386368951201439\n",
      "trial: 1, iter: 6000, curr loss: 1.3860293626785278, avg loss: 1.3863201475143432\n",
      "trial: 1, iter: 6200, curr loss: 1.3859140872955322, avg loss: 1.386313949227333\n",
      "trial: 1, iter: 6400, curr loss: 1.3871853351593018, avg loss: 1.3863881450891495\n",
      "trial: 1, iter: 6600, curr loss: 1.3858187198638916, avg loss: 1.3863085150718688\n",
      "trial: 1, iter: 6800, curr loss: 1.3856565952301025, avg loss: 1.3863292068243027\n",
      "trial: 1, iter: 7000, curr loss: 1.3867443799972534, avg loss: 1.386452460885048\n",
      "trial: 1, iter: 7200, curr loss: 1.385615587234497, avg loss: 1.3862980204820632\n",
      "trial: 1, iter: 7400, curr loss: 1.3865844011306763, avg loss: 1.3863487267494201\n",
      "trial: 1, iter: 7600, curr loss: 1.3861678838729858, avg loss: 1.3863008034229278\n",
      "trial: 1, iter: 7800, curr loss: 1.3865898847579956, avg loss: 1.3862891817092895\n",
      "trial: 1, iter: 8000, curr loss: 1.3861128091812134, avg loss: 1.3862858659029007\n",
      "trial: 1, iter: 8200, curr loss: 1.386505365371704, avg loss: 1.3863622272014617\n",
      "trial: 1, iter: 8400, curr loss: 1.3865615129470825, avg loss: 1.3863318371772766\n",
      "trial: 1, iter: 8600, curr loss: 1.3863954544067383, avg loss: 1.3863085693120956\n",
      "trial: 1, iter: 8800, curr loss: 1.3862519264221191, avg loss: 1.386312978863716\n",
      "trial: 1, iter: 9000, curr loss: 1.3860498666763306, avg loss: 1.3863123708963394\n",
      "trial: 1, iter: 9200, curr loss: 1.3864597082138062, avg loss: 1.3863155329227448\n",
      "trial: 1, iter: 9400, curr loss: 1.3862552642822266, avg loss: 1.3863032740354537\n",
      "trial: 1, iter: 9600, curr loss: 1.3864426612854004, avg loss: 1.3863006103038789\n",
      "trial: 1, iter: 9800, curr loss: 1.386291742324829, avg loss: 1.3863099813461304\n",
      "trial: 1, iter: 10000, curr loss: 1.3862019777297974, avg loss: 1.3862920963764191\n",
      "trial: 1, iter: 10200, curr loss: 1.3862797021865845, avg loss: 1.3863141721487044\n",
      "trial: 1, iter: 10400, curr loss: 1.3861603736877441, avg loss: 1.3862924057245254\n",
      "trial: 1, iter: 10600, curr loss: 1.3861184120178223, avg loss: 1.3863247698545456\n",
      "trial: 1, iter: 10800, curr loss: 1.3870365619659424, avg loss: 1.3862928825616836\n",
      "trial: 1, iter: 11000, curr loss: 1.3864459991455078, avg loss: 1.3863057309389115\n",
      "trial: 1, iter: 11200, curr loss: 1.3862415552139282, avg loss: 1.386303922533989\n",
      "trial: 1, iter: 11400, curr loss: 1.3867433071136475, avg loss: 1.3863439017534256\n",
      "trial: 1, iter: 11600, curr loss: 1.3866454362869263, avg loss: 1.3863264614343642\n",
      "trial: 1, iter: 11800, curr loss: 1.3862627744674683, avg loss: 1.386311936378479\n",
      "trial: 1, iter: 12000, curr loss: 1.386179804801941, avg loss: 1.3863069701194763\n",
      "trial: 1, iter: 12200, curr loss: 1.3859819173812866, avg loss: 1.3862808817625045\n",
      "trial: 1, iter: 12400, curr loss: 1.386492371559143, avg loss: 1.3863249653577805\n",
      "trial: 1, iter: 12600, curr loss: 1.3866443634033203, avg loss: 1.3863347101211547\n",
      "trial: 1, iter: 12800, curr loss: 1.3869538307189941, avg loss: 1.3862901973724364\n",
      "trial: 1, iter: 13000, curr loss: 1.3861072063446045, avg loss: 1.3863313287496566\n",
      "trial: 1, iter: 13200, curr loss: 1.386395812034607, avg loss: 1.3863113898038864\n",
      "trial: 1, iter: 13400, curr loss: 1.3864963054656982, avg loss: 1.3863032323122024\n",
      "trial: 1, iter: 13600, curr loss: 1.3862826824188232, avg loss: 1.38630461871624\n",
      "trial: 1, iter: 13800, curr loss: 1.3862310647964478, avg loss: 1.386320675611496\n",
      "trial: 1, iter: 14000, curr loss: 1.3866782188415527, avg loss: 1.386350652575493\n",
      "trial: 1, iter: 14200, curr loss: 1.3863511085510254, avg loss: 1.3863200235366822\n",
      "trial: 1, iter: 14400, curr loss: 1.386344075202942, avg loss: 1.3862896424531936\n",
      "trial: 1, iter: 14600, curr loss: 1.3866223096847534, avg loss: 1.3863218760490417\n",
      "trial: 1, iter: 14800, curr loss: 1.3865187168121338, avg loss: 1.386308342218399\n",
      "trial: 1, iter: 15000, curr loss: 1.3864916563034058, avg loss: 1.3863015758991242\n",
      "trial: 1, iter: 15200, curr loss: 1.3865299224853516, avg loss: 1.3862974578142166\n",
      "trial: 1, iter: 15400, curr loss: 1.38624906539917, avg loss: 1.386296904683113\n",
      "trial: 1, iter: 15600, curr loss: 1.3863224983215332, avg loss: 1.3862953901290893\n",
      "trial: 1, ldr: -0.0003465182089712471\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3892673254013062, avg loss: 1.3873770397901535\n",
      "trial: 2, iter: 400, curr loss: 1.3841224908828735, avg loss: 1.3867736035585403\n",
      "trial: 2, iter: 600, curr loss: 1.3872746229171753, avg loss: 1.3867068165540695\n",
      "trial: 2, iter: 800, curr loss: 1.3868088722229004, avg loss: 1.386586270928383\n",
      "trial: 2, iter: 1000, curr loss: 1.3872771263122559, avg loss: 1.3864762842655183\n",
      "trial: 2, iter: 1200, curr loss: 1.38654363155365, avg loss: 1.3864427441358567\n",
      "trial: 2, iter: 1400, curr loss: 1.385646104812622, avg loss: 1.3863761818408966\n",
      "trial: 2, iter: 1600, curr loss: 1.3867672681808472, avg loss: 1.386469783782959\n",
      "trial: 2, iter: 1800, curr loss: 1.3858866691589355, avg loss: 1.386360206604004\n",
      "trial: 2, iter: 2000, curr loss: 1.3862028121948242, avg loss: 1.3862883913517\n",
      "trial: 2, iter: 2200, curr loss: 1.3867464065551758, avg loss: 1.3863787513971328\n",
      "trial: 2, iter: 2400, curr loss: 1.387343406677246, avg loss: 1.386278738975525\n",
      "trial: 2, iter: 2600, curr loss: 1.3855596780776978, avg loss: 1.3864479130506515\n",
      "trial: 2, iter: 2800, curr loss: 1.3855772018432617, avg loss: 1.3863560771942138\n",
      "trial: 2, iter: 3000, curr loss: 1.3858201503753662, avg loss: 1.3863221603631972\n",
      "trial: 2, iter: 3200, curr loss: 1.3861746788024902, avg loss: 1.3863613629341125\n",
      "trial: 2, iter: 3400, curr loss: 1.3862154483795166, avg loss: 1.3863272231817245\n",
      "trial: 2, iter: 3600, curr loss: 1.3863831758499146, avg loss: 1.3863022935390472\n",
      "trial: 2, iter: 3800, curr loss: 1.3863853216171265, avg loss: 1.3863371902704238\n",
      "trial: 2, iter: 4000, curr loss: 1.3868536949157715, avg loss: 1.3863384783267976\n",
      "trial: 2, iter: 4200, curr loss: 1.3859161138534546, avg loss: 1.3863389104604722\n",
      "trial: 2, iter: 4400, curr loss: 1.3861818313598633, avg loss: 1.3863602447509766\n",
      "trial: 2, iter: 4600, curr loss: 1.3862924575805664, avg loss: 1.3863261795043946\n",
      "trial: 2, iter: 4800, curr loss: 1.3882241249084473, avg loss: 1.3863454055786133\n",
      "trial: 2, iter: 5000, curr loss: 1.3857812881469727, avg loss: 1.3863883483409882\n",
      "trial: 2, iter: 5200, curr loss: 1.3866348266601562, avg loss: 1.3863240832090378\n",
      "trial: 2, iter: 5400, curr loss: 1.3863989114761353, avg loss: 1.3863083231449127\n",
      "trial: 2, iter: 5600, curr loss: 1.3857167959213257, avg loss: 1.3862793719768525\n",
      "trial: 2, iter: 5800, curr loss: 1.3862379789352417, avg loss: 1.3863148808479309\n",
      "trial: 2, iter: 6000, curr loss: 1.3865593671798706, avg loss: 1.386331602334976\n",
      "trial: 2, iter: 6200, curr loss: 1.3865387439727783, avg loss: 1.3862937593460083\n",
      "trial: 2, iter: 6400, curr loss: 1.3859845399856567, avg loss: 1.386314918398857\n",
      "trial: 2, iter: 6600, curr loss: 1.3862812519073486, avg loss: 1.386325984597206\n",
      "trial: 2, iter: 6800, curr loss: 1.385827898979187, avg loss: 1.3863665688037872\n",
      "trial: 2, iter: 7000, curr loss: 1.38701331615448, avg loss: 1.386353039741516\n",
      "trial: 2, iter: 7200, curr loss: 1.3868045806884766, avg loss: 1.386334292292595\n",
      "trial: 2, iter: 7400, curr loss: 1.3876168727874756, avg loss: 1.3862953287363053\n",
      "trial: 2, iter: 7600, curr loss: 1.3863130807876587, avg loss: 1.3863228124380111\n",
      "trial: 2, iter: 7800, curr loss: 1.386407732963562, avg loss: 1.386360258460045\n",
      "trial: 2, iter: 8000, curr loss: 1.3866474628448486, avg loss: 1.3862931591272354\n",
      "trial: 2, iter: 8200, curr loss: 1.386315107345581, avg loss: 1.3863148123025895\n",
      "trial: 2, iter: 8400, curr loss: 1.3861079216003418, avg loss: 1.3863135188817979\n",
      "trial: 2, iter: 8600, curr loss: 1.3864089250564575, avg loss: 1.3863040256500243\n",
      "trial: 2, iter: 8800, curr loss: 1.3865487575531006, avg loss: 1.3863070023059845\n",
      "trial: 2, iter: 9000, curr loss: 1.386243224143982, avg loss: 1.3862884455919267\n",
      "trial: 2, iter: 9200, curr loss: 1.386350154876709, avg loss: 1.3863128328323364\n",
      "trial: 2, iter: 9400, curr loss: 1.3857877254486084, avg loss: 1.3862620133161545\n",
      "trial: 2, iter: 9600, curr loss: 1.3867267370224, avg loss: 1.3863191318511963\n",
      "trial: 2, iter: 9800, curr loss: 1.3864920139312744, avg loss: 1.386305460333824\n",
      "trial: 2, iter: 10000, curr loss: 1.3859879970550537, avg loss: 1.386422910094261\n",
      "trial: 2, iter: 10200, curr loss: 1.3862687349319458, avg loss: 1.3863704580068588\n",
      "trial: 2, iter: 10400, curr loss: 1.3864452838897705, avg loss: 1.38631975710392\n",
      "trial: 2, iter: 10600, curr loss: 1.3862833976745605, avg loss: 1.3863201439380646\n",
      "trial: 2, iter: 10800, curr loss: 1.3863959312438965, avg loss: 1.3863382011651992\n",
      "trial: 2, iter: 11000, curr loss: 1.3864941596984863, avg loss: 1.386311321258545\n",
      "trial: 2, iter: 11200, curr loss: 1.38655424118042, avg loss: 1.386293644309044\n",
      "trial: 2, iter: 11400, curr loss: 1.3863879442214966, avg loss: 1.386338632106781\n",
      "trial: 2, iter: 11600, curr loss: 1.3864638805389404, avg loss: 1.3863065546751023\n",
      "trial: 2, iter: 11800, curr loss: 1.3862385749816895, avg loss: 1.3863036674261093\n",
      "trial: 2, iter: 12000, curr loss: 1.386346459388733, avg loss: 1.3863095438480377\n",
      "trial: 2, iter: 12200, curr loss: 1.3862897157669067, avg loss: 1.386297026872635\n",
      "trial: 2, iter: 12400, curr loss: 1.386500358581543, avg loss: 1.3863016915321351\n",
      "trial: 2, iter: 12600, curr loss: 1.3861923217773438, avg loss: 1.386309963464737\n",
      "trial: 2, iter: 12800, curr loss: 1.3860753774642944, avg loss: 1.386308848261833\n",
      "trial: 2, iter: 13000, curr loss: 1.3863584995269775, avg loss: 1.3862981629371642\n",
      "trial: 2, iter: 13200, curr loss: 1.3865522146224976, avg loss: 1.3862963634729386\n",
      "trial: 2, iter: 13400, curr loss: 1.386468768119812, avg loss: 1.3863744223117829\n",
      "trial: 2, iter: 13600, curr loss: 1.387054681777954, avg loss: 1.3863026291131972\n",
      "trial: 2, iter: 13800, curr loss: 1.3857839107513428, avg loss: 1.3863150537014008\n",
      "trial: 2, iter: 14000, curr loss: 1.3863990306854248, avg loss: 1.3863139069080352\n",
      "trial: 2, iter: 14200, curr loss: 1.386574387550354, avg loss: 1.3863109171390533\n",
      "trial: 2, iter: 14400, curr loss: 1.3862966299057007, avg loss: 1.3863585364818574\n",
      "trial: 2, iter: 14600, curr loss: 1.3862969875335693, avg loss: 1.3863004440069198\n",
      "trial: 2, iter: 14800, curr loss: 1.3864470720291138, avg loss: 1.3862897336483002\n",
      "trial: 2, iter: 15000, curr loss: 1.3865346908569336, avg loss: 1.386296074986458\n",
      "trial: 2, iter: 15200, curr loss: 1.3865283727645874, avg loss: 1.38630242228508\n",
      "trial: 2, iter: 15400, curr loss: 1.3862489461898804, avg loss: 1.3862931603193283\n",
      "trial: 2, iter: 15600, curr loss: 1.386236310005188, avg loss: 1.3863181781768799\n",
      "trial: 2, ldr: -0.014238037168979645\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389207124710083, avg loss: 1.3872330230474472\n",
      "trial: 3, iter: 400, curr loss: 1.3845689296722412, avg loss: 1.3866073513031005\n",
      "trial: 3, iter: 600, curr loss: 1.384676218032837, avg loss: 1.386484631896019\n",
      "trial: 3, iter: 800, curr loss: 1.3846869468688965, avg loss: 1.386352653503418\n",
      "trial: 3, iter: 1000, curr loss: 1.386336088180542, avg loss: 1.386458259820938\n",
      "trial: 3, iter: 1200, curr loss: 1.3858208656311035, avg loss: 1.3864462953805923\n",
      "trial: 3, iter: 1400, curr loss: 1.3859646320343018, avg loss: 1.386374580860138\n",
      "trial: 3, iter: 1600, curr loss: 1.3871990442276, avg loss: 1.386340481042862\n",
      "trial: 3, iter: 1800, curr loss: 1.3851039409637451, avg loss: 1.386353526711464\n",
      "trial: 3, iter: 2000, curr loss: 1.3855137825012207, avg loss: 1.3863222366571426\n",
      "trial: 3, iter: 2200, curr loss: 1.3870117664337158, avg loss: 1.3863563269376755\n",
      "trial: 3, iter: 2400, curr loss: 1.3848745822906494, avg loss: 1.386382489800453\n",
      "trial: 3, iter: 2600, curr loss: 1.3864704370498657, avg loss: 1.3863664257526398\n",
      "trial: 3, iter: 2800, curr loss: 1.3860176801681519, avg loss: 1.3863256853818893\n",
      "trial: 3, iter: 3000, curr loss: 1.3864854574203491, avg loss: 1.3863117694854736\n",
      "trial: 3, iter: 3200, curr loss: 1.3863424062728882, avg loss: 1.3862878447771072\n",
      "trial: 3, iter: 3400, curr loss: 1.386175274848938, avg loss: 1.3863405501842498\n",
      "trial: 3, iter: 3600, curr loss: 1.386190414428711, avg loss: 1.3863537627458573\n",
      "trial: 3, iter: 3800, curr loss: 1.3869127035140991, avg loss: 1.3863225555419922\n",
      "trial: 3, iter: 4000, curr loss: 1.386472463607788, avg loss: 1.3863553023338318\n",
      "trial: 3, iter: 4200, curr loss: 1.386344313621521, avg loss: 1.38635094165802\n",
      "trial: 3, iter: 4400, curr loss: 1.3854877948760986, avg loss: 1.3863288480043412\n",
      "trial: 3, iter: 4600, curr loss: 1.3855092525482178, avg loss: 1.3863524609804154\n",
      "trial: 3, iter: 4800, curr loss: 1.38612961769104, avg loss: 1.3864141923189164\n",
      "trial: 3, iter: 5000, curr loss: 1.3869237899780273, avg loss: 1.3863468194007873\n",
      "trial: 3, iter: 5200, curr loss: 1.3863061666488647, avg loss: 1.386321417093277\n",
      "trial: 3, iter: 5400, curr loss: 1.386659860610962, avg loss: 1.3863301348686219\n",
      "trial: 3, iter: 5600, curr loss: 1.3856879472732544, avg loss: 1.3862827962636948\n",
      "trial: 3, iter: 5800, curr loss: 1.3867441415786743, avg loss: 1.386307371854782\n",
      "trial: 3, iter: 6000, curr loss: 1.3854860067367554, avg loss: 1.386277956366539\n",
      "trial: 3, iter: 6200, curr loss: 1.388136386871338, avg loss: 1.3862663954496384\n",
      "trial: 3, iter: 6400, curr loss: 1.3870052099227905, avg loss: 1.3863684779405594\n",
      "trial: 3, iter: 6600, curr loss: 1.3866366147994995, avg loss: 1.3864083075523377\n",
      "trial: 3, iter: 6800, curr loss: 1.3862323760986328, avg loss: 1.3863520121574402\n",
      "trial: 3, iter: 7000, curr loss: 1.3865646123886108, avg loss: 1.3863477861881257\n",
      "trial: 3, iter: 7200, curr loss: 1.3861291408538818, avg loss: 1.3863329362869263\n",
      "trial: 3, iter: 7400, curr loss: 1.3869171142578125, avg loss: 1.386261341571808\n",
      "trial: 3, iter: 7600, curr loss: 1.3892714977264404, avg loss: 1.3862886011600495\n",
      "trial: 3, iter: 7800, curr loss: 1.3865370750427246, avg loss: 1.3864373749494552\n",
      "trial: 3, iter: 8000, curr loss: 1.3864799737930298, avg loss: 1.3863695764541626\n",
      "trial: 3, iter: 8200, curr loss: 1.3859771490097046, avg loss: 1.386341318488121\n",
      "trial: 3, iter: 8400, curr loss: 1.3862395286560059, avg loss: 1.3862866514921188\n",
      "trial: 3, iter: 8600, curr loss: 1.3865748643875122, avg loss: 1.3862964993715285\n",
      "trial: 3, iter: 8800, curr loss: 1.3865731954574585, avg loss: 1.3862202495336533\n",
      "trial: 3, iter: 9000, curr loss: 1.3856388330459595, avg loss: 1.3863429427146912\n",
      "trial: 3, iter: 9200, curr loss: 1.386176347732544, avg loss: 1.3862764477729796\n",
      "trial: 3, iter: 9400, curr loss: 1.3863122463226318, avg loss: 1.386300372481346\n",
      "trial: 3, iter: 9600, curr loss: 1.3860270977020264, avg loss: 1.3862899130582809\n",
      "trial: 3, iter: 9800, curr loss: 1.385972023010254, avg loss: 1.3863045316934586\n",
      "trial: 3, iter: 10000, curr loss: 1.3864526748657227, avg loss: 1.3863233983516694\n",
      "trial: 3, iter: 10200, curr loss: 1.3862662315368652, avg loss: 1.3863023376464845\n",
      "trial: 3, iter: 10400, curr loss: 1.3863292932510376, avg loss: 1.3862993210554122\n",
      "trial: 3, iter: 10600, curr loss: 1.3864611387252808, avg loss: 1.386299990415573\n",
      "trial: 3, iter: 10800, curr loss: 1.386353850364685, avg loss: 1.3863003033399581\n",
      "trial: 3, iter: 11000, curr loss: 1.3867335319519043, avg loss: 1.3863082611560822\n",
      "trial: 3, iter: 11200, curr loss: 1.386453628540039, avg loss: 1.3862625235319137\n",
      "trial: 3, iter: 11400, curr loss: 1.3860951662063599, avg loss: 1.3863549411296845\n",
      "trial: 3, iter: 11600, curr loss: 1.38612961769104, avg loss: 1.3863053178787232\n",
      "trial: 3, iter: 11800, curr loss: 1.3865593671798706, avg loss: 1.3862903696298599\n",
      "trial: 3, iter: 12000, curr loss: 1.3863669633865356, avg loss: 1.386309677362442\n",
      "trial: 3, iter: 12200, curr loss: 1.3862054347991943, avg loss: 1.386287853717804\n",
      "trial: 3, iter: 12400, curr loss: 1.3865197896957397, avg loss: 1.3863054758310318\n",
      "trial: 3, iter: 12600, curr loss: 1.386291742324829, avg loss: 1.386273158788681\n",
      "trial: 3, iter: 12800, curr loss: 1.3863905668258667, avg loss: 1.386317698955536\n",
      "trial: 3, iter: 13000, curr loss: 1.3860920667648315, avg loss: 1.3863449841737747\n",
      "trial: 3, iter: 13200, curr loss: 1.3856858015060425, avg loss: 1.3863249921798706\n",
      "trial: 3, iter: 13400, curr loss: 1.3860050439834595, avg loss: 1.3863450735807419\n",
      "trial: 3, iter: 13600, curr loss: 1.3867254257202148, avg loss: 1.3862946653366088\n",
      "trial: 3, iter: 13800, curr loss: 1.3862169981002808, avg loss: 1.3862995433807372\n",
      "trial: 3, iter: 14000, curr loss: 1.3866066932678223, avg loss: 1.386310663819313\n",
      "trial: 3, iter: 14200, curr loss: 1.3862124681472778, avg loss: 1.3862956768274308\n",
      "trial: 3, iter: 14400, curr loss: 1.386356234550476, avg loss: 1.3863079363107682\n",
      "trial: 3, iter: 14600, curr loss: 1.3862550258636475, avg loss: 1.3862985527515412\n",
      "trial: 3, iter: 14800, curr loss: 1.3860536813735962, avg loss: 1.386297880411148\n",
      "trial: 3, iter: 15000, curr loss: 1.3862484693527222, avg loss: 1.3863018935918807\n",
      "trial: 3, iter: 15200, curr loss: 1.3863484859466553, avg loss: 1.3863030129671097\n",
      "trial: 3, iter: 15400, curr loss: 1.3863073587417603, avg loss: 1.3863001018762589\n",
      "trial: 3, iter: 15600, curr loss: 1.3862766027450562, avg loss: 1.3862999123334885\n",
      "trial: 3, ldr: 0.00023721095931250602\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3888990879058838, avg loss: 1.387458273768425\n",
      "trial: 4, iter: 400, curr loss: 1.385837435722351, avg loss: 1.3866059637069703\n",
      "trial: 4, iter: 600, curr loss: 1.3854418992996216, avg loss: 1.3865229004621507\n",
      "trial: 4, iter: 800, curr loss: 1.3898506164550781, avg loss: 1.386578422188759\n",
      "trial: 4, iter: 1000, curr loss: 1.3874160051345825, avg loss: 1.386487089395523\n",
      "trial: 4, iter: 1200, curr loss: 1.3848106861114502, avg loss: 1.3864398002624512\n",
      "trial: 4, iter: 1400, curr loss: 1.3860223293304443, avg loss: 1.3862997478246688\n",
      "trial: 4, iter: 1600, curr loss: 1.387360692024231, avg loss: 1.3864223504066466\n",
      "trial: 4, iter: 1800, curr loss: 1.3863259553909302, avg loss: 1.386366246342659\n",
      "trial: 4, iter: 2000, curr loss: 1.3857516050338745, avg loss: 1.3864066976308822\n",
      "trial: 4, iter: 2200, curr loss: 1.3857351541519165, avg loss: 1.3863354605436324\n",
      "trial: 4, iter: 2400, curr loss: 1.3865653276443481, avg loss: 1.3864290308952332\n",
      "trial: 4, iter: 2600, curr loss: 1.3876348733901978, avg loss: 1.3864097195863723\n",
      "trial: 4, iter: 2800, curr loss: 1.3873897790908813, avg loss: 1.3863729882240294\n",
      "trial: 4, iter: 3000, curr loss: 1.3857542276382446, avg loss: 1.3863535767793655\n",
      "trial: 4, iter: 3200, curr loss: 1.3869354724884033, avg loss: 1.3863424676656724\n",
      "trial: 4, iter: 3400, curr loss: 1.385876178741455, avg loss: 1.386345140337944\n",
      "trial: 4, iter: 3600, curr loss: 1.3859670162200928, avg loss: 1.3863183557987213\n",
      "trial: 4, iter: 3800, curr loss: 1.38544762134552, avg loss: 1.3863076573610307\n",
      "trial: 4, iter: 4000, curr loss: 1.3858078718185425, avg loss: 1.3863214313983918\n",
      "trial: 4, iter: 4200, curr loss: 1.3856136798858643, avg loss: 1.3863829523324966\n",
      "trial: 4, iter: 4400, curr loss: 1.3867723941802979, avg loss: 1.3863099086284638\n",
      "trial: 4, iter: 4600, curr loss: 1.385825514793396, avg loss: 1.3863896465301513\n",
      "trial: 4, iter: 4800, curr loss: 1.3868763446807861, avg loss: 1.3863533914089203\n",
      "trial: 4, iter: 5000, curr loss: 1.3860633373260498, avg loss: 1.3863203328847886\n",
      "trial: 4, iter: 5200, curr loss: 1.3864182233810425, avg loss: 1.3863265490531922\n",
      "trial: 4, iter: 5400, curr loss: 1.3856643438339233, avg loss: 1.3862694185972213\n",
      "trial: 4, iter: 5600, curr loss: 1.3858654499053955, avg loss: 1.386347845196724\n",
      "trial: 4, iter: 5800, curr loss: 1.3867194652557373, avg loss: 1.386314213871956\n",
      "trial: 4, iter: 6000, curr loss: 1.3857426643371582, avg loss: 1.3863422626256943\n",
      "trial: 4, iter: 6200, curr loss: 1.3861470222473145, avg loss: 1.3863391697406768\n",
      "trial: 4, iter: 6400, curr loss: 1.3853963613510132, avg loss: 1.3863135600090026\n",
      "trial: 4, iter: 6600, curr loss: 1.385879635810852, avg loss: 1.3863394725322724\n",
      "trial: 4, iter: 6800, curr loss: 1.3867061138153076, avg loss: 1.386289404630661\n",
      "trial: 4, iter: 7000, curr loss: 1.3857052326202393, avg loss: 1.3863092845678329\n",
      "trial: 4, iter: 7200, curr loss: 1.3867580890655518, avg loss: 1.3863163906335831\n",
      "trial: 4, iter: 7400, curr loss: 1.3866064548492432, avg loss: 1.3863351356983185\n",
      "trial: 4, iter: 7600, curr loss: 1.3861370086669922, avg loss: 1.3863161182403565\n",
      "trial: 4, iter: 7800, curr loss: 1.3861985206604004, avg loss: 1.3863197630643844\n",
      "trial: 4, iter: 8000, curr loss: 1.3861230611801147, avg loss: 1.386298828125\n",
      "trial: 4, iter: 8200, curr loss: 1.386521339416504, avg loss: 1.3863294589519501\n",
      "trial: 4, iter: 8400, curr loss: 1.3864191770553589, avg loss: 1.3863814055919648\n",
      "trial: 4, iter: 8600, curr loss: 1.386013388633728, avg loss: 1.3863166290521622\n",
      "trial: 4, iter: 8800, curr loss: 1.386671781539917, avg loss: 1.386355041861534\n",
      "trial: 4, iter: 9000, curr loss: 1.3865717649459839, avg loss: 1.3863232278823852\n",
      "trial: 4, iter: 9200, curr loss: 1.3853763341903687, avg loss: 1.3863380587100982\n",
      "trial: 4, iter: 9400, curr loss: 1.387117862701416, avg loss: 1.3863010758161545\n",
      "trial: 4, iter: 9600, curr loss: 1.3853976726531982, avg loss: 1.3861662578582763\n",
      "trial: 4, iter: 9800, curr loss: 1.386995553970337, avg loss: 1.3863458341360093\n",
      "trial: 4, iter: 10000, curr loss: 1.3866519927978516, avg loss: 1.3863513332605362\n",
      "trial: 4, iter: 10200, curr loss: 1.3868069648742676, avg loss: 1.3862825238704681\n",
      "trial: 4, iter: 10400, curr loss: 1.3864152431488037, avg loss: 1.3863378715515138\n",
      "trial: 4, iter: 10600, curr loss: 1.3865712881088257, avg loss: 1.386343284845352\n",
      "trial: 4, iter: 10800, curr loss: 1.3860043287277222, avg loss: 1.3863056951761246\n",
      "trial: 4, iter: 11000, curr loss: 1.3864456415176392, avg loss: 1.3863256323337554\n",
      "trial: 4, iter: 11200, curr loss: 1.38649320602417, avg loss: 1.3862832444906235\n",
      "trial: 4, iter: 11400, curr loss: 1.386415958404541, avg loss: 1.38632692694664\n",
      "trial: 4, iter: 11600, curr loss: 1.386529564857483, avg loss: 1.386318974494934\n",
      "trial: 4, iter: 11800, curr loss: 1.386183738708496, avg loss: 1.3862992751598358\n",
      "trial: 4, iter: 12000, curr loss: 1.3865761756896973, avg loss: 1.3862867230176925\n",
      "trial: 4, iter: 12200, curr loss: 1.3866733312606812, avg loss: 1.3862900090217591\n",
      "trial: 4, iter: 12400, curr loss: 1.386238932609558, avg loss: 1.3862895148992538\n",
      "trial: 4, iter: 12600, curr loss: 1.386433482170105, avg loss: 1.386307590007782\n",
      "trial: 4, iter: 12800, curr loss: 1.3861069679260254, avg loss: 1.3863057047128677\n",
      "trial: 4, iter: 13000, curr loss: 1.3860464096069336, avg loss: 1.38629727602005\n",
      "trial: 4, iter: 13200, curr loss: 1.386336326599121, avg loss: 1.386339278817177\n",
      "trial: 4, iter: 13400, curr loss: 1.3865691423416138, avg loss: 1.3862728244066238\n",
      "trial: 4, iter: 13600, curr loss: 1.3857489824295044, avg loss: 1.3863046973943711\n",
      "trial: 4, iter: 13800, curr loss: 1.3857263326644897, avg loss: 1.3863114112615584\n",
      "trial: 4, iter: 14000, curr loss: 1.3867361545562744, avg loss: 1.3863095211982728\n",
      "trial: 4, iter: 14200, curr loss: 1.3871196508407593, avg loss: 1.386289991736412\n",
      "trial: 4, iter: 14400, curr loss: 1.3858174085617065, avg loss: 1.3863273400068283\n",
      "trial: 4, iter: 14600, curr loss: 1.3862419128417969, avg loss: 1.386318446993828\n",
      "trial: 4, iter: 14800, curr loss: 1.3863600492477417, avg loss: 1.386290385723114\n",
      "trial: 4, iter: 15000, curr loss: 1.3864279985427856, avg loss: 1.3862984257936477\n",
      "trial: 4, iter: 15200, curr loss: 1.386082649230957, avg loss: 1.3862998569011689\n",
      "trial: 4, iter: 15400, curr loss: 1.386185646057129, avg loss: 1.3863075971603394\n",
      "trial: 4, iter: 15600, curr loss: 1.3861159086227417, avg loss: 1.3862822484970092\n",
      "trial: 4, ldr: 0.006405103951692581\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3868759870529175, avg loss: 1.387250185608864\n",
      "trial: 5, iter: 400, curr loss: 1.3867906332015991, avg loss: 1.3867688232660293\n",
      "trial: 5, iter: 600, curr loss: 1.3886667490005493, avg loss: 1.386550297141075\n",
      "trial: 5, iter: 800, curr loss: 1.3875848054885864, avg loss: 1.386479139328003\n",
      "trial: 5, iter: 1000, curr loss: 1.3857276439666748, avg loss: 1.3865523076057433\n",
      "trial: 5, iter: 1200, curr loss: 1.3872745037078857, avg loss: 1.3864440709352492\n",
      "trial: 5, iter: 1400, curr loss: 1.3855520486831665, avg loss: 1.386385647058487\n",
      "trial: 5, iter: 1600, curr loss: 1.3862632513046265, avg loss: 1.3863170158863067\n",
      "trial: 5, iter: 1800, curr loss: 1.387024164199829, avg loss: 1.3864787888526917\n",
      "trial: 5, iter: 2000, curr loss: 1.38540780544281, avg loss: 1.3863873732089997\n",
      "trial: 5, iter: 2200, curr loss: 1.385519027709961, avg loss: 1.3863327342271805\n",
      "trial: 5, iter: 2400, curr loss: 1.384861946105957, avg loss: 1.3863248920440674\n",
      "trial: 5, iter: 2600, curr loss: 1.3857084512710571, avg loss: 1.3864183139801025\n",
      "trial: 5, iter: 2800, curr loss: 1.3872219324111938, avg loss: 1.3863127291202546\n",
      "trial: 5, iter: 3000, curr loss: 1.3863940238952637, avg loss: 1.3863829171657562\n",
      "trial: 5, iter: 3200, curr loss: 1.3868255615234375, avg loss: 1.3863978731632232\n",
      "trial: 5, iter: 3400, curr loss: 1.3862065076828003, avg loss: 1.386301075220108\n",
      "trial: 5, iter: 3600, curr loss: 1.3868176937103271, avg loss: 1.3863377892971038\n",
      "trial: 5, iter: 3800, curr loss: 1.3881875276565552, avg loss: 1.3863176345825194\n",
      "trial: 5, iter: 4000, curr loss: 1.3859963417053223, avg loss: 1.3863648515939713\n",
      "trial: 5, iter: 4200, curr loss: 1.3855162858963013, avg loss: 1.3863959401845931\n",
      "trial: 5, iter: 4400, curr loss: 1.3880491256713867, avg loss: 1.3862502300739288\n",
      "trial: 5, iter: 4600, curr loss: 1.3865522146224976, avg loss: 1.3863936597108841\n",
      "trial: 5, iter: 4800, curr loss: 1.3866029977798462, avg loss: 1.3863190269470216\n",
      "trial: 5, iter: 5000, curr loss: 1.386595606803894, avg loss: 1.3863509839773178\n",
      "trial: 5, iter: 5200, curr loss: 1.3865461349487305, avg loss: 1.3863279962539672\n",
      "trial: 5, iter: 5400, curr loss: 1.3862452507019043, avg loss: 1.3862844997644423\n",
      "trial: 5, iter: 5600, curr loss: 1.386920690536499, avg loss: 1.386294749379158\n",
      "trial: 5, iter: 5800, curr loss: 1.3867003917694092, avg loss: 1.3863456010818482\n",
      "trial: 5, iter: 6000, curr loss: 1.3862863779067993, avg loss: 1.3863123011589051\n",
      "trial: 5, iter: 6200, curr loss: 1.3864030838012695, avg loss: 1.386306079030037\n",
      "trial: 5, iter: 6400, curr loss: 1.386076807975769, avg loss: 1.3863109260797501\n",
      "trial: 5, iter: 6600, curr loss: 1.3866842985153198, avg loss: 1.3863078141212464\n",
      "trial: 5, iter: 6800, curr loss: 1.386590838432312, avg loss: 1.3862869399785995\n",
      "trial: 5, iter: 7000, curr loss: 1.3863013982772827, avg loss: 1.3863444060087204\n",
      "trial: 5, iter: 7200, curr loss: 1.3858749866485596, avg loss: 1.386335899233818\n",
      "trial: 5, iter: 7400, curr loss: 1.386352777481079, avg loss: 1.386377723813057\n",
      "trial: 5, iter: 7600, curr loss: 1.3849432468414307, avg loss: 1.3863210153579713\n",
      "trial: 5, iter: 7800, curr loss: 1.3871681690216064, avg loss: 1.3862936568260193\n",
      "trial: 5, iter: 8000, curr loss: 1.3862199783325195, avg loss: 1.386334679722786\n",
      "trial: 5, iter: 8200, curr loss: 1.3860163688659668, avg loss: 1.3862674474716186\n",
      "trial: 5, iter: 8400, curr loss: 1.3876010179519653, avg loss: 1.3863097327947616\n",
      "trial: 5, iter: 8600, curr loss: 1.3864213228225708, avg loss: 1.3863513666391372\n",
      "trial: 5, iter: 8800, curr loss: 1.386208176612854, avg loss: 1.3863087445497513\n",
      "trial: 5, iter: 9000, curr loss: 1.3863328695297241, avg loss: 1.3863017547130585\n",
      "trial: 5, iter: 9200, curr loss: 1.3861175775527954, avg loss: 1.3863157296180726\n",
      "trial: 5, iter: 9400, curr loss: 1.3862065076828003, avg loss: 1.3862751704454421\n",
      "trial: 5, iter: 9600, curr loss: 1.3861348628997803, avg loss: 1.3862944221496583\n",
      "trial: 5, iter: 9800, curr loss: 1.3863855600357056, avg loss: 1.386306681036949\n",
      "trial: 5, iter: 10000, curr loss: 1.386255145072937, avg loss: 1.386303923726082\n",
      "trial: 5, iter: 10200, curr loss: 1.3863685131072998, avg loss: 1.3862917459011077\n",
      "trial: 5, iter: 10400, curr loss: 1.3860619068145752, avg loss: 1.3863008636236192\n",
      "trial: 5, iter: 10600, curr loss: 1.3862274885177612, avg loss: 1.3863007736206054\n",
      "trial: 5, iter: 10800, curr loss: 1.3862848281860352, avg loss: 1.3862970960140228\n",
      "trial: 5, iter: 11000, curr loss: 1.3862981796264648, avg loss: 1.3862973690032958\n",
      "trial: 5, iter: 11200, curr loss: 1.3862857818603516, avg loss: 1.3862934643030167\n",
      "trial: 5, iter: 11400, curr loss: 1.3862944841384888, avg loss: 1.3862949711084367\n",
      "trial: 5, iter: 11600, curr loss: 1.385870337486267, avg loss: 1.3863002055883407\n",
      "trial: 5, iter: 11800, curr loss: 1.3863445520401, avg loss: 1.386302610039711\n",
      "trial: 5, iter: 12000, curr loss: 1.386271357536316, avg loss: 1.386295816898346\n",
      "trial: 5, iter: 12200, curr loss: 1.38648521900177, avg loss: 1.3862906056642532\n",
      "trial: 5, iter: 12400, curr loss: 1.3859267234802246, avg loss: 1.386281381249428\n",
      "trial: 5, iter: 12600, curr loss: 1.3866071701049805, avg loss: 1.386321141719818\n",
      "trial: 5, iter: 12800, curr loss: 1.386284589767456, avg loss: 1.386304910182953\n",
      "trial: 5, iter: 13000, curr loss: 1.3863067626953125, avg loss: 1.3863016277551652\n",
      "trial: 5, iter: 13200, curr loss: 1.3863059282302856, avg loss: 1.3862988847494124\n",
      "trial: 5, iter: 13400, curr loss: 1.386259913444519, avg loss: 1.3862948715686798\n",
      "trial: 5, iter: 13600, curr loss: 1.3862898349761963, avg loss: 1.3862957042455673\n",
      "trial: 5, iter: 13800, curr loss: 1.386297345161438, avg loss: 1.3862948554754257\n",
      "trial: 5, iter: 14000, curr loss: 1.3862727880477905, avg loss: 1.3862930762767791\n",
      "trial: 5, iter: 14200, curr loss: 1.3862944841384888, avg loss: 1.3862921637296677\n",
      "trial: 5, iter: 14400, curr loss: 1.386290192604065, avg loss: 1.386293175816536\n",
      "trial: 5, iter: 14600, curr loss: 1.3862943649291992, avg loss: 1.386291543841362\n",
      "trial: 5, iter: 14800, curr loss: 1.3862942457199097, avg loss: 1.3862954437732697\n",
      "trial: 5, iter: 15000, curr loss: 1.3862948417663574, avg loss: 1.3862938022613525\n",
      "trial: 5, iter: 15200, curr loss: 1.3862942457199097, avg loss: 1.3862943261861802\n",
      "trial: 5, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.3862951338291167\n",
      "trial: 5, iter: 15600, curr loss: 1.3862946033477783, avg loss: 1.386295200586319\n",
      "trial: 5, ldr: -1.9720304408110678e-05\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.001592392154270783\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3864548206329346, avg loss: 1.3872406208515167\n",
      "trial: 1, iter: 400, curr loss: 1.3876845836639404, avg loss: 1.3867279547452926\n",
      "trial: 1, iter: 600, curr loss: 1.3869922161102295, avg loss: 1.3865457129478456\n",
      "trial: 1, iter: 800, curr loss: 1.386671543121338, avg loss: 1.3865252608060836\n",
      "trial: 1, iter: 1000, curr loss: 1.3868366479873657, avg loss: 1.3863801103830338\n",
      "trial: 1, iter: 1200, curr loss: 1.3861241340637207, avg loss: 1.3864528971910477\n",
      "trial: 1, iter: 1400, curr loss: 1.385280728340149, avg loss: 1.3863837522268296\n",
      "trial: 1, iter: 1600, curr loss: 1.386436104774475, avg loss: 1.3863086718320847\n",
      "trial: 1, iter: 1800, curr loss: 1.3864918947219849, avg loss: 1.386334697008133\n",
      "trial: 1, iter: 2000, curr loss: 1.3855375051498413, avg loss: 1.3864109247922898\n",
      "trial: 1, iter: 2200, curr loss: 1.3866883516311646, avg loss: 1.386388862133026\n",
      "trial: 1, iter: 2400, curr loss: 1.38640296459198, avg loss: 1.3863425201177597\n",
      "trial: 1, iter: 2600, curr loss: 1.3863670825958252, avg loss: 1.3863546055555345\n",
      "trial: 1, iter: 2800, curr loss: 1.386106014251709, avg loss: 1.3863894718885421\n",
      "trial: 1, iter: 3000, curr loss: 1.385828971862793, avg loss: 1.3862870728969574\n",
      "trial: 1, iter: 3200, curr loss: 1.386452317237854, avg loss: 1.3863302928209305\n",
      "trial: 1, iter: 3400, curr loss: 1.3858990669250488, avg loss: 1.3862995165586471\n",
      "trial: 1, iter: 3600, curr loss: 1.385239601135254, avg loss: 1.3862137860059738\n",
      "trial: 1, iter: 3800, curr loss: 1.3865183591842651, avg loss: 1.3864070653915406\n",
      "trial: 1, iter: 4000, curr loss: 1.385982871055603, avg loss: 1.3863863670825958\n",
      "trial: 1, iter: 4200, curr loss: 1.3860561847686768, avg loss: 1.3863592952489854\n",
      "trial: 1, iter: 4400, curr loss: 1.3858647346496582, avg loss: 1.3863266539573669\n",
      "trial: 1, iter: 4600, curr loss: 1.3871474266052246, avg loss: 1.386325142979622\n",
      "trial: 1, iter: 4800, curr loss: 1.386817455291748, avg loss: 1.386320470571518\n",
      "trial: 1, iter: 5000, curr loss: 1.3879690170288086, avg loss: 1.386307914853096\n",
      "trial: 1, iter: 5200, curr loss: 1.3856873512268066, avg loss: 1.3863008850812912\n",
      "trial: 1, iter: 5400, curr loss: 1.3865412473678589, avg loss: 1.386381523013115\n",
      "trial: 1, iter: 5600, curr loss: 1.385706901550293, avg loss: 1.386314549446106\n",
      "trial: 1, iter: 5800, curr loss: 1.3859363794326782, avg loss: 1.3863211685419083\n",
      "trial: 1, iter: 6000, curr loss: 1.3867835998535156, avg loss: 1.386326521039009\n",
      "trial: 1, iter: 6200, curr loss: 1.3866333961486816, avg loss: 1.3863541573286056\n",
      "trial: 1, iter: 6400, curr loss: 1.3874245882034302, avg loss: 1.3863360357284547\n",
      "trial: 1, iter: 6600, curr loss: 1.3864880800247192, avg loss: 1.3863032376766204\n",
      "trial: 1, iter: 6800, curr loss: 1.3868181705474854, avg loss: 1.3863522428274155\n",
      "trial: 1, iter: 7000, curr loss: 1.3862706422805786, avg loss: 1.3863260573148728\n",
      "trial: 1, iter: 7200, curr loss: 1.3860267400741577, avg loss: 1.3863253837823868\n",
      "trial: 1, iter: 7400, curr loss: 1.3865101337432861, avg loss: 1.3863182592391967\n",
      "trial: 1, iter: 7600, curr loss: 1.3860617876052856, avg loss: 1.3863133382797241\n",
      "trial: 1, iter: 7800, curr loss: 1.3861569166183472, avg loss: 1.3863189816474915\n",
      "trial: 1, iter: 8000, curr loss: 1.3864376544952393, avg loss: 1.3863092631101608\n",
      "trial: 1, iter: 8200, curr loss: 1.3863590955734253, avg loss: 1.3862981897592546\n",
      "trial: 1, iter: 8400, curr loss: 1.3862106800079346, avg loss: 1.38631929397583\n",
      "trial: 1, iter: 8600, curr loss: 1.3868175745010376, avg loss: 1.386294419169426\n",
      "trial: 1, iter: 8800, curr loss: 1.3860657215118408, avg loss: 1.386315824985504\n",
      "trial: 1, iter: 9000, curr loss: 1.386289358139038, avg loss: 1.3863153046369552\n",
      "trial: 1, iter: 9200, curr loss: 1.3863531351089478, avg loss: 1.3863037133216858\n",
      "trial: 1, iter: 9400, curr loss: 1.386441946029663, avg loss: 1.386293950676918\n",
      "trial: 1, iter: 9600, curr loss: 1.386413812637329, avg loss: 1.386284196972847\n",
      "trial: 1, iter: 9800, curr loss: 1.3860058784484863, avg loss: 1.3863234347105027\n",
      "trial: 1, iter: 10000, curr loss: 1.386246919631958, avg loss: 1.3863111340999603\n",
      "trial: 1, iter: 10200, curr loss: 1.3862186670303345, avg loss: 1.3863252514600755\n",
      "trial: 1, iter: 10400, curr loss: 1.3863619565963745, avg loss: 1.386295456290245\n",
      "trial: 1, iter: 10600, curr loss: 1.3861770629882812, avg loss: 1.3863274747133254\n",
      "trial: 1, iter: 10800, curr loss: 1.386338710784912, avg loss: 1.3863116282224655\n",
      "trial: 1, iter: 11000, curr loss: 1.3861536979675293, avg loss: 1.3862948602437972\n",
      "trial: 1, iter: 11200, curr loss: 1.386427640914917, avg loss: 1.3862989979982376\n",
      "trial: 1, iter: 11400, curr loss: 1.3862574100494385, avg loss: 1.38630797624588\n",
      "trial: 1, iter: 11600, curr loss: 1.3863481283187866, avg loss: 1.3863050603866578\n",
      "trial: 1, iter: 11800, curr loss: 1.3863924741744995, avg loss: 1.3863101530075073\n",
      "trial: 1, iter: 12000, curr loss: 1.3862409591674805, avg loss: 1.3863076251745223\n",
      "trial: 1, iter: 12200, curr loss: 1.3863452672958374, avg loss: 1.3863003963232041\n",
      "trial: 1, iter: 12400, curr loss: 1.3863539695739746, avg loss: 1.3862950432300567\n",
      "trial: 1, iter: 12600, curr loss: 1.3865512609481812, avg loss: 1.3862975388765335\n",
      "trial: 1, iter: 12800, curr loss: 1.3861684799194336, avg loss: 1.386312604546547\n",
      "trial: 1, iter: 13000, curr loss: 1.3862979412078857, avg loss: 1.3863076573610307\n",
      "trial: 1, iter: 13200, curr loss: 1.3862568140029907, avg loss: 1.3863001185655595\n",
      "trial: 1, iter: 13400, curr loss: 1.3862481117248535, avg loss: 1.3862980884313583\n",
      "trial: 1, iter: 13600, curr loss: 1.386340856552124, avg loss: 1.3862974160909654\n",
      "trial: 1, iter: 13800, curr loss: 1.3863002061843872, avg loss: 1.386296169757843\n",
      "trial: 1, iter: 14000, curr loss: 1.386291742324829, avg loss: 1.3862942045927047\n",
      "trial: 1, iter: 14200, curr loss: 1.3863065242767334, avg loss: 1.3863018691539764\n",
      "trial: 1, iter: 14400, curr loss: 1.3863314390182495, avg loss: 1.3862960559129716\n",
      "trial: 1, iter: 14600, curr loss: 1.386292576789856, avg loss: 1.3862938898801804\n",
      "trial: 1, iter: 14800, curr loss: 1.3863214254379272, avg loss: 1.3862762874364853\n",
      "trial: 1, iter: 15000, curr loss: 1.3869085311889648, avg loss: 1.3862801796197892\n",
      "trial: 1, iter: 15200, curr loss: 1.3861905336380005, avg loss: 1.3862864100933074\n",
      "trial: 1, iter: 15400, curr loss: 1.385740876197815, avg loss: 1.3863332927227021\n",
      "trial: 1, iter: 15600, curr loss: 1.3866740465164185, avg loss: 1.3862727415561675\n",
      "trial: 1, ldr: -0.00348965753801167\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3874481916427612, avg loss: 1.3876749432086946\n",
      "trial: 2, iter: 400, curr loss: 1.386798620223999, avg loss: 1.38667781829834\n",
      "trial: 2, iter: 600, curr loss: 1.3873720169067383, avg loss: 1.386470011472702\n",
      "trial: 2, iter: 800, curr loss: 1.3848861455917358, avg loss: 1.3864532786607742\n",
      "trial: 2, iter: 1000, curr loss: 1.385587453842163, avg loss: 1.3866737979650496\n",
      "trial: 2, iter: 1200, curr loss: 1.3871769905090332, avg loss: 1.386301497220993\n",
      "trial: 2, iter: 1400, curr loss: 1.3851884603500366, avg loss: 1.3862903559207915\n",
      "trial: 2, iter: 1600, curr loss: 1.3874006271362305, avg loss: 1.3864123010635376\n",
      "trial: 2, iter: 1800, curr loss: 1.3860000371932983, avg loss: 1.386414464712143\n",
      "trial: 2, iter: 2000, curr loss: 1.3869918584823608, avg loss: 1.3864022475481033\n",
      "trial: 2, iter: 2200, curr loss: 1.3864243030548096, avg loss: 1.3863103753328323\n",
      "trial: 2, iter: 2400, curr loss: 1.3866060972213745, avg loss: 1.3863107341527938\n",
      "trial: 2, iter: 2600, curr loss: 1.3868162631988525, avg loss: 1.3864265316724778\n",
      "trial: 2, iter: 2800, curr loss: 1.3867107629776, avg loss: 1.3863084071874618\n",
      "trial: 2, iter: 3000, curr loss: 1.386889100074768, avg loss: 1.386480028629303\n",
      "trial: 2, iter: 3200, curr loss: 1.3860899209976196, avg loss: 1.3864028978347778\n",
      "trial: 2, iter: 3400, curr loss: 1.386335849761963, avg loss: 1.3863539451360702\n",
      "trial: 2, iter: 3600, curr loss: 1.3859772682189941, avg loss: 1.3863572573661804\n",
      "trial: 2, iter: 3800, curr loss: 1.387380599975586, avg loss: 1.3863650220632553\n",
      "trial: 2, iter: 4000, curr loss: 1.386144757270813, avg loss: 1.386309324502945\n",
      "trial: 2, iter: 4200, curr loss: 1.3865363597869873, avg loss: 1.3863841569423676\n",
      "trial: 2, iter: 4400, curr loss: 1.3864362239837646, avg loss: 1.386314560174942\n",
      "trial: 2, iter: 4600, curr loss: 1.3868111371994019, avg loss: 1.386347500681877\n",
      "trial: 2, iter: 4800, curr loss: 1.3863543272018433, avg loss: 1.3863342243433\n",
      "trial: 2, iter: 5000, curr loss: 1.3866363763809204, avg loss: 1.386320618391037\n",
      "trial: 2, iter: 5200, curr loss: 1.386648178100586, avg loss: 1.3863068854808807\n",
      "trial: 2, iter: 5400, curr loss: 1.3859026432037354, avg loss: 1.3863264155387878\n",
      "trial: 2, iter: 5600, curr loss: 1.3869503736495972, avg loss: 1.386388663649559\n",
      "trial: 2, iter: 5800, curr loss: 1.3854578733444214, avg loss: 1.386399701833725\n",
      "trial: 2, iter: 6000, curr loss: 1.3865514993667603, avg loss: 1.386420298218727\n",
      "trial: 2, iter: 6200, curr loss: 1.3869304656982422, avg loss: 1.3863768595457078\n",
      "trial: 2, iter: 6400, curr loss: 1.3869587182998657, avg loss: 1.3863775330781936\n",
      "trial: 2, iter: 6600, curr loss: 1.3858299255371094, avg loss: 1.3864469575881957\n",
      "trial: 2, iter: 6800, curr loss: 1.3862322568893433, avg loss: 1.386317013502121\n",
      "trial: 2, iter: 7000, curr loss: 1.3867628574371338, avg loss: 1.3864045959711075\n",
      "trial: 2, iter: 7200, curr loss: 1.3872288465499878, avg loss: 1.3863147789239882\n",
      "trial: 2, iter: 7400, curr loss: 1.3871036767959595, avg loss: 1.3863248169422149\n",
      "trial: 2, iter: 7600, curr loss: 1.3859344720840454, avg loss: 1.3863806521892548\n",
      "trial: 2, iter: 7800, curr loss: 1.3858062028884888, avg loss: 1.3862681370973586\n",
      "trial: 2, iter: 8000, curr loss: 1.3857688903808594, avg loss: 1.3863379740715027\n",
      "trial: 2, iter: 8200, curr loss: 1.3872414827346802, avg loss: 1.3863070380687714\n",
      "trial: 2, iter: 8400, curr loss: 1.386368989944458, avg loss: 1.386312366127968\n",
      "trial: 2, iter: 8600, curr loss: 1.3868581056594849, avg loss: 1.386324588060379\n",
      "trial: 2, iter: 8800, curr loss: 1.3865344524383545, avg loss: 1.3863060998916625\n",
      "trial: 2, iter: 9000, curr loss: 1.3865370750427246, avg loss: 1.386327776312828\n",
      "trial: 2, iter: 9200, curr loss: 1.385534644126892, avg loss: 1.3862940657138825\n",
      "trial: 2, iter: 9400, curr loss: 1.3864283561706543, avg loss: 1.386361100077629\n",
      "trial: 2, iter: 9600, curr loss: 1.3866407871246338, avg loss: 1.3863101357221603\n",
      "trial: 2, iter: 9800, curr loss: 1.3858404159545898, avg loss: 1.3862895441055298\n",
      "trial: 2, iter: 10000, curr loss: 1.3862276077270508, avg loss: 1.3863041204214097\n",
      "trial: 2, iter: 10200, curr loss: 1.3861799240112305, avg loss: 1.3862887448072434\n",
      "trial: 2, iter: 10400, curr loss: 1.3853503465652466, avg loss: 1.3863285052776337\n",
      "trial: 2, iter: 10600, curr loss: 1.3867937326431274, avg loss: 1.3863226521015166\n",
      "trial: 2, iter: 10800, curr loss: 1.3859437704086304, avg loss: 1.3863205140829087\n",
      "trial: 2, iter: 11000, curr loss: 1.3862391710281372, avg loss: 1.3862709933519364\n",
      "trial: 2, iter: 11200, curr loss: 1.3873051404953003, avg loss: 1.386328930258751\n",
      "trial: 2, iter: 11400, curr loss: 1.3867930173873901, avg loss: 1.386340109705925\n",
      "trial: 2, iter: 11600, curr loss: 1.3864750862121582, avg loss: 1.3863122165203094\n",
      "trial: 2, iter: 11800, curr loss: 1.3866710662841797, avg loss: 1.3863505721092224\n",
      "trial: 2, iter: 12000, curr loss: 1.3865745067596436, avg loss: 1.386326875090599\n",
      "trial: 2, iter: 12200, curr loss: 1.3860443830490112, avg loss: 1.3863013565540314\n",
      "trial: 2, iter: 12400, curr loss: 1.385883092880249, avg loss: 1.3862961119413375\n",
      "trial: 2, iter: 12600, curr loss: 1.3876112699508667, avg loss: 1.3863746058940887\n",
      "trial: 2, iter: 12800, curr loss: 1.3858187198638916, avg loss: 1.3863452923297883\n",
      "trial: 2, iter: 13000, curr loss: 1.3863931894302368, avg loss: 1.3863141441345215\n",
      "trial: 2, iter: 13200, curr loss: 1.3863165378570557, avg loss: 1.3863645547628403\n",
      "trial: 2, iter: 13400, curr loss: 1.3862698078155518, avg loss: 1.38630510866642\n",
      "trial: 2, iter: 13600, curr loss: 1.385656714439392, avg loss: 1.3863470816612244\n",
      "trial: 2, iter: 13800, curr loss: 1.3864660263061523, avg loss: 1.3863015872240068\n",
      "trial: 2, iter: 14000, curr loss: 1.3865249156951904, avg loss: 1.386324257850647\n",
      "trial: 2, iter: 14200, curr loss: 1.3857901096343994, avg loss: 1.386319763660431\n",
      "trial: 2, iter: 14400, curr loss: 1.387146234512329, avg loss: 1.3862890106439592\n",
      "trial: 2, iter: 14600, curr loss: 1.3853492736816406, avg loss: 1.3862943154573442\n",
      "trial: 2, iter: 14800, curr loss: 1.385412335395813, avg loss: 1.386394065618515\n",
      "trial: 2, iter: 15000, curr loss: 1.3862196207046509, avg loss: 1.3863569241762161\n",
      "trial: 2, iter: 15200, curr loss: 1.3858016729354858, avg loss: 1.3862887823581695\n",
      "trial: 2, iter: 15400, curr loss: 1.3856295347213745, avg loss: 1.3863290077447892\n",
      "trial: 2, iter: 15600, curr loss: 1.3857526779174805, avg loss: 1.38633635699749\n",
      "trial: 2, ldr: 0.0063126045279204845\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3910304307937622, avg loss: 1.3872364944219588\n",
      "trial: 3, iter: 400, curr loss: 1.3900302648544312, avg loss: 1.3866252779960633\n",
      "trial: 3, iter: 600, curr loss: 1.3867266178131104, avg loss: 1.3865903896093368\n",
      "trial: 3, iter: 800, curr loss: 1.3841125965118408, avg loss: 1.3865813702344894\n",
      "trial: 3, iter: 1000, curr loss: 1.3861093521118164, avg loss: 1.3864678144454956\n",
      "trial: 3, iter: 1200, curr loss: 1.3852416276931763, avg loss: 1.3863778722286224\n",
      "trial: 3, iter: 1400, curr loss: 1.386694073677063, avg loss: 1.3864469641447068\n",
      "trial: 3, iter: 1600, curr loss: 1.3848565816879272, avg loss: 1.3864478743076325\n",
      "trial: 3, iter: 1800, curr loss: 1.385584831237793, avg loss: 1.3864235430955887\n",
      "trial: 3, iter: 2000, curr loss: 1.3864309787750244, avg loss: 1.3864212572574615\n",
      "trial: 3, iter: 2200, curr loss: 1.387597680091858, avg loss: 1.3863173854351043\n",
      "trial: 3, iter: 2400, curr loss: 1.3861664533615112, avg loss: 1.386433221101761\n",
      "trial: 3, iter: 2600, curr loss: 1.3852834701538086, avg loss: 1.3863494515419006\n",
      "trial: 3, iter: 2800, curr loss: 1.3861560821533203, avg loss: 1.3863180446624757\n",
      "trial: 3, iter: 3000, curr loss: 1.3867340087890625, avg loss: 1.3862594503164292\n",
      "trial: 3, iter: 3200, curr loss: 1.385506272315979, avg loss: 1.3863379710912704\n",
      "trial: 3, iter: 3400, curr loss: 1.3865677118301392, avg loss: 1.3864237427711488\n",
      "trial: 3, iter: 3600, curr loss: 1.3865697383880615, avg loss: 1.386309232711792\n",
      "trial: 3, iter: 3800, curr loss: 1.386336088180542, avg loss: 1.3863182330131532\n",
      "trial: 3, iter: 4000, curr loss: 1.386522650718689, avg loss: 1.3862947773933412\n",
      "trial: 3, iter: 4200, curr loss: 1.3868736028671265, avg loss: 1.3863088047504426\n",
      "trial: 3, iter: 4400, curr loss: 1.3862080574035645, avg loss: 1.3863249236345292\n",
      "trial: 3, iter: 4600, curr loss: 1.3864420652389526, avg loss: 1.386299028992653\n",
      "trial: 3, iter: 4800, curr loss: 1.3867130279541016, avg loss: 1.3862968009710313\n",
      "trial: 3, iter: 5000, curr loss: 1.3866056203842163, avg loss: 1.3863466781377793\n",
      "trial: 3, iter: 5200, curr loss: 1.3862088918685913, avg loss: 1.3863235574960708\n",
      "trial: 3, iter: 5400, curr loss: 1.3866229057312012, avg loss: 1.3863154900074006\n",
      "trial: 3, iter: 5600, curr loss: 1.386203646659851, avg loss: 1.3863120698928832\n",
      "trial: 3, iter: 5800, curr loss: 1.3867155313491821, avg loss: 1.3862929081916808\n",
      "trial: 3, iter: 6000, curr loss: 1.3863022327423096, avg loss: 1.386302760243416\n",
      "trial: 3, iter: 6200, curr loss: 1.3868067264556885, avg loss: 1.386266673207283\n",
      "trial: 3, iter: 6400, curr loss: 1.386797547340393, avg loss: 1.3863609325885773\n",
      "trial: 3, iter: 6600, curr loss: 1.3860267400741577, avg loss: 1.3863728713989258\n",
      "trial: 3, iter: 6800, curr loss: 1.3864420652389526, avg loss: 1.3863228458166121\n",
      "trial: 3, iter: 7000, curr loss: 1.3858023881912231, avg loss: 1.3863047385215759\n",
      "trial: 3, iter: 7200, curr loss: 1.386138916015625, avg loss: 1.3863050818443299\n",
      "trial: 3, iter: 7400, curr loss: 1.386160969734192, avg loss: 1.3863556027412414\n",
      "trial: 3, iter: 7600, curr loss: 1.3846021890640259, avg loss: 1.3862971657514571\n",
      "trial: 3, iter: 7800, curr loss: 1.3863874673843384, avg loss: 1.386346331834793\n",
      "trial: 3, iter: 8000, curr loss: 1.3863561153411865, avg loss: 1.3863479924201965\n",
      "trial: 3, iter: 8200, curr loss: 1.3863325119018555, avg loss: 1.3862503749132156\n",
      "trial: 3, iter: 8400, curr loss: 1.385651707649231, avg loss: 1.386347582936287\n",
      "trial: 3, iter: 8600, curr loss: 1.3862272500991821, avg loss: 1.3863473951816558\n",
      "trial: 3, iter: 8800, curr loss: 1.3863344192504883, avg loss: 1.3863135892152787\n",
      "trial: 3, iter: 9000, curr loss: 1.386337161064148, avg loss: 1.386320788860321\n",
      "trial: 3, iter: 9200, curr loss: 1.3862361907958984, avg loss: 1.3863025563955307\n",
      "trial: 3, iter: 9400, curr loss: 1.3864915370941162, avg loss: 1.386307669878006\n",
      "trial: 3, iter: 9600, curr loss: 1.3865677118301392, avg loss: 1.3863080161809922\n",
      "trial: 3, iter: 9800, curr loss: 1.38655686378479, avg loss: 1.3863076728582382\n",
      "trial: 3, iter: 10000, curr loss: 1.3867712020874023, avg loss: 1.3863516223430634\n",
      "trial: 3, iter: 10200, curr loss: 1.3858474493026733, avg loss: 1.386321787238121\n",
      "trial: 3, iter: 10400, curr loss: 1.3858797550201416, avg loss: 1.3863561809062959\n",
      "trial: 3, iter: 10600, curr loss: 1.3856937885284424, avg loss: 1.3863533610105514\n",
      "trial: 3, iter: 10800, curr loss: 1.3862642049789429, avg loss: 1.3863220643997192\n",
      "trial: 3, iter: 11000, curr loss: 1.3862919807434082, avg loss: 1.3863324534893036\n",
      "trial: 3, iter: 11200, curr loss: 1.3862954378128052, avg loss: 1.3862946456670762\n",
      "trial: 3, iter: 11400, curr loss: 1.3865307569503784, avg loss: 1.3863068515062331\n",
      "trial: 3, iter: 11600, curr loss: 1.3863929510116577, avg loss: 1.3863114088773727\n",
      "trial: 3, iter: 11800, curr loss: 1.386338472366333, avg loss: 1.3863084179162979\n",
      "trial: 3, iter: 12000, curr loss: 1.3862009048461914, avg loss: 1.3862939816713333\n",
      "trial: 3, iter: 12200, curr loss: 1.386604905128479, avg loss: 1.3863038462400437\n",
      "trial: 3, iter: 12400, curr loss: 1.3863409757614136, avg loss: 1.3863085716962815\n",
      "trial: 3, iter: 12600, curr loss: 1.3863255977630615, avg loss: 1.386298327445984\n",
      "trial: 3, iter: 12800, curr loss: 1.386448621749878, avg loss: 1.3862983363866805\n",
      "trial: 3, iter: 13000, curr loss: 1.3863651752471924, avg loss: 1.386298313140869\n",
      "trial: 3, iter: 13200, curr loss: 1.38631272315979, avg loss: 1.386283473968506\n",
      "trial: 3, iter: 13400, curr loss: 1.386629581451416, avg loss: 1.386306324005127\n",
      "trial: 3, iter: 13600, curr loss: 1.3861035108566284, avg loss: 1.3863051813840865\n",
      "trial: 3, iter: 13800, curr loss: 1.38577139377594, avg loss: 1.3862803602218627\n",
      "trial: 3, iter: 14000, curr loss: 1.3859741687774658, avg loss: 1.386330645084381\n",
      "trial: 3, iter: 14200, curr loss: 1.3863650560379028, avg loss: 1.386344423890114\n",
      "trial: 3, iter: 14400, curr loss: 1.3863394260406494, avg loss: 1.386304085254669\n",
      "trial: 3, iter: 14600, curr loss: 1.3862820863723755, avg loss: 1.3862963128089905\n",
      "trial: 3, iter: 14800, curr loss: 1.386198878288269, avg loss: 1.3862871235609056\n",
      "trial: 3, iter: 15000, curr loss: 1.3864041566848755, avg loss: 1.386326302886009\n",
      "trial: 3, iter: 15200, curr loss: 1.3863154649734497, avg loss: 1.3863034099340439\n",
      "trial: 3, iter: 15400, curr loss: 1.3863816261291504, avg loss: 1.3862987214326858\n",
      "trial: 3, iter: 15600, curr loss: 1.3863098621368408, avg loss: 1.3863063073158264\n",
      "trial: 3, ldr: -0.0012537151342257857\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3884540796279907, avg loss: 1.387380212545395\n",
      "trial: 4, iter: 400, curr loss: 1.3870749473571777, avg loss: 1.3867367470264436\n",
      "trial: 4, iter: 600, curr loss: 1.3862844705581665, avg loss: 1.3866507291793824\n",
      "trial: 4, iter: 800, curr loss: 1.387048602104187, avg loss: 1.386458929181099\n",
      "trial: 4, iter: 1000, curr loss: 1.3874627351760864, avg loss: 1.3864907151460648\n",
      "trial: 4, iter: 1200, curr loss: 1.3858833312988281, avg loss: 1.3864173805713653\n",
      "trial: 4, iter: 1400, curr loss: 1.3865286111831665, avg loss: 1.38631136238575\n",
      "trial: 4, iter: 1600, curr loss: 1.3863849639892578, avg loss: 1.3863569819927215\n",
      "trial: 4, iter: 1800, curr loss: 1.3862704038619995, avg loss: 1.386313528418541\n",
      "trial: 4, iter: 2000, curr loss: 1.387024164199829, avg loss: 1.3862999296188354\n",
      "trial: 4, iter: 2200, curr loss: 1.386413812637329, avg loss: 1.3863327008485795\n",
      "trial: 4, iter: 2400, curr loss: 1.3876049518585205, avg loss: 1.3863789916038514\n",
      "trial: 4, iter: 2600, curr loss: 1.3875967264175415, avg loss: 1.386338078379631\n",
      "trial: 4, iter: 2800, curr loss: 1.3859676122665405, avg loss: 1.3863279616832733\n",
      "trial: 4, iter: 3000, curr loss: 1.386613368988037, avg loss: 1.3863813710212707\n",
      "trial: 4, iter: 3200, curr loss: 1.386291742324829, avg loss: 1.3863068252801896\n",
      "trial: 4, iter: 3400, curr loss: 1.3865355253219604, avg loss: 1.38632049202919\n",
      "trial: 4, iter: 3600, curr loss: 1.3862823247909546, avg loss: 1.3863291639089583\n",
      "trial: 4, iter: 3800, curr loss: 1.3858050107955933, avg loss: 1.3862852597236632\n",
      "trial: 4, iter: 4000, curr loss: 1.387566089630127, avg loss: 1.3863596868515016\n",
      "trial: 4, iter: 4200, curr loss: 1.3861889839172363, avg loss: 1.386262217760086\n",
      "trial: 4, iter: 4400, curr loss: 1.3865262269973755, avg loss: 1.3862530136108397\n",
      "trial: 4, iter: 4600, curr loss: 1.3863301277160645, avg loss: 1.3863803660869598\n",
      "trial: 4, iter: 4800, curr loss: 1.386499285697937, avg loss: 1.3863477510213853\n",
      "trial: 4, iter: 5000, curr loss: 1.3862651586532593, avg loss: 1.3863306140899658\n",
      "trial: 4, iter: 5200, curr loss: 1.3862078189849854, avg loss: 1.3863013523817063\n",
      "trial: 4, iter: 5400, curr loss: 1.3863322734832764, avg loss: 1.3863207018375396\n",
      "trial: 4, iter: 5600, curr loss: 1.385013222694397, avg loss: 1.386262719631195\n",
      "trial: 4, iter: 5800, curr loss: 1.3861209154129028, avg loss: 1.3863776367902756\n",
      "trial: 4, iter: 6000, curr loss: 1.3854804039001465, avg loss: 1.3862811094522476\n",
      "trial: 4, iter: 6200, curr loss: 1.385184645652771, avg loss: 1.38631556391716\n",
      "trial: 4, iter: 6400, curr loss: 1.3858048915863037, avg loss: 1.3863613027334214\n",
      "trial: 4, iter: 6600, curr loss: 1.3862614631652832, avg loss: 1.3863189750909806\n",
      "trial: 4, iter: 6800, curr loss: 1.3863952159881592, avg loss: 1.3863063180446624\n",
      "trial: 4, iter: 7000, curr loss: 1.3860647678375244, avg loss: 1.3862907087802887\n",
      "trial: 4, iter: 7200, curr loss: 1.3860845565795898, avg loss: 1.3863299369812012\n",
      "trial: 4, iter: 7400, curr loss: 1.386347770690918, avg loss: 1.386285800933838\n",
      "trial: 4, iter: 7600, curr loss: 1.386284589767456, avg loss: 1.3863222700357438\n",
      "trial: 4, iter: 7800, curr loss: 1.3862203359603882, avg loss: 1.3863063794374466\n",
      "trial: 4, iter: 8000, curr loss: 1.386298656463623, avg loss: 1.3862975025177002\n",
      "trial: 4, iter: 8200, curr loss: 1.3861923217773438, avg loss: 1.3862932407855988\n",
      "trial: 4, iter: 8400, curr loss: 1.3859730958938599, avg loss: 1.3863284283876418\n",
      "trial: 4, iter: 8600, curr loss: 1.3861466646194458, avg loss: 1.3863101410865784\n",
      "trial: 4, iter: 8800, curr loss: 1.3862996101379395, avg loss: 1.3863060051202774\n",
      "trial: 4, iter: 9000, curr loss: 1.3862152099609375, avg loss: 1.3862904781103134\n",
      "trial: 4, iter: 9200, curr loss: 1.3860831260681152, avg loss: 1.3862812608480453\n",
      "trial: 4, iter: 9400, curr loss: 1.3869599103927612, avg loss: 1.3863390648365022\n",
      "trial: 4, iter: 9600, curr loss: 1.3864407539367676, avg loss: 1.3863136440515518\n",
      "trial: 4, iter: 9800, curr loss: 1.3862667083740234, avg loss: 1.386307482123375\n",
      "trial: 4, iter: 10000, curr loss: 1.3861140012741089, avg loss: 1.3862519937753677\n",
      "trial: 4, iter: 10200, curr loss: 1.3861464262008667, avg loss: 1.3863379949331283\n",
      "trial: 4, iter: 10400, curr loss: 1.38638436794281, avg loss: 1.38632976770401\n",
      "trial: 4, iter: 10600, curr loss: 1.386286735534668, avg loss: 1.3863134562969208\n",
      "trial: 4, iter: 10800, curr loss: 1.386263132095337, avg loss: 1.3863235586881637\n",
      "trial: 4, iter: 11000, curr loss: 1.3861454725265503, avg loss: 1.3862942147254944\n",
      "trial: 4, iter: 11200, curr loss: 1.3864498138427734, avg loss: 1.386320361495018\n",
      "trial: 4, iter: 11400, curr loss: 1.3861370086669922, avg loss: 1.386298981308937\n",
      "trial: 4, iter: 11600, curr loss: 1.3862863779067993, avg loss: 1.3863109010457992\n",
      "trial: 4, iter: 11800, curr loss: 1.3862638473510742, avg loss: 1.386298161149025\n",
      "trial: 4, iter: 12000, curr loss: 1.3864248991012573, avg loss: 1.3862855941057206\n",
      "trial: 4, iter: 12200, curr loss: 1.385961890220642, avg loss: 1.386281903386116\n",
      "trial: 4, iter: 12400, curr loss: 1.3863309621810913, avg loss: 1.3863137304782867\n",
      "trial: 4, iter: 12600, curr loss: 1.3863749504089355, avg loss: 1.386300328373909\n",
      "trial: 4, iter: 12800, curr loss: 1.3862837553024292, avg loss: 1.3863109588623046\n",
      "trial: 4, iter: 13000, curr loss: 1.3862431049346924, avg loss: 1.38629749417305\n",
      "trial: 4, iter: 13200, curr loss: 1.3862178325653076, avg loss: 1.3863035017251968\n",
      "trial: 4, iter: 13400, curr loss: 1.3864432573318481, avg loss: 1.3862968325614928\n",
      "trial: 4, iter: 13600, curr loss: 1.3862853050231934, avg loss: 1.386300654411316\n",
      "trial: 4, iter: 13800, curr loss: 1.3863786458969116, avg loss: 1.3862972366809845\n",
      "trial: 4, iter: 14000, curr loss: 1.3862991333007812, avg loss: 1.38630062520504\n",
      "trial: 4, iter: 14200, curr loss: 1.3862595558166504, avg loss: 1.3862943577766418\n",
      "trial: 4, iter: 14400, curr loss: 1.3863496780395508, avg loss: 1.3862907510995865\n",
      "trial: 4, iter: 14600, curr loss: 1.386212944984436, avg loss: 1.38630011677742\n",
      "trial: 4, iter: 14800, curr loss: 1.3862698078155518, avg loss: 1.3862997269630433\n",
      "trial: 4, iter: 15000, curr loss: 1.3856525421142578, avg loss: 1.3863175177574159\n",
      "trial: 4, iter: 15200, curr loss: 1.386007308959961, avg loss: 1.3863257437944412\n",
      "trial: 4, iter: 15400, curr loss: 1.3862123489379883, avg loss: 1.3863416230678558\n",
      "trial: 4, iter: 15600, curr loss: 1.3864456415176392, avg loss: 1.3862954843044282\n",
      "trial: 4, ldr: -0.0010392101248726249\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3876689672470093, avg loss: 1.3873555290699005\n",
      "trial: 5, iter: 400, curr loss: 1.3871864080429077, avg loss: 1.3866890412569046\n",
      "trial: 5, iter: 600, curr loss: 1.38754403591156, avg loss: 1.3866731983423233\n",
      "trial: 5, iter: 800, curr loss: 1.3868037462234497, avg loss: 1.3865096712112426\n",
      "trial: 5, iter: 1000, curr loss: 1.3871005773544312, avg loss: 1.3864122766256333\n",
      "trial: 5, iter: 1200, curr loss: 1.386000156402588, avg loss: 1.3863468146324158\n",
      "trial: 5, iter: 1400, curr loss: 1.38626229763031, avg loss: 1.3863823020458221\n",
      "trial: 5, iter: 1600, curr loss: 1.3869613409042358, avg loss: 1.3863025599718093\n",
      "trial: 5, iter: 1800, curr loss: 1.3866922855377197, avg loss: 1.3863622999191285\n",
      "trial: 5, iter: 2000, curr loss: 1.3865751028060913, avg loss: 1.3862945425510407\n",
      "trial: 5, iter: 2200, curr loss: 1.3867474794387817, avg loss: 1.3863127225637435\n",
      "trial: 5, iter: 2400, curr loss: 1.3864257335662842, avg loss: 1.386325599551201\n",
      "trial: 5, iter: 2600, curr loss: 1.3863060474395752, avg loss: 1.3863503962755204\n",
      "trial: 5, iter: 2800, curr loss: 1.3864953517913818, avg loss: 1.3862916630506517\n",
      "trial: 5, iter: 3000, curr loss: 1.3858360052108765, avg loss: 1.386345216035843\n",
      "trial: 5, iter: 3200, curr loss: 1.3848474025726318, avg loss: 1.3862896329164505\n",
      "trial: 5, iter: 3400, curr loss: 1.38619863986969, avg loss: 1.3863509267568588\n",
      "trial: 5, iter: 3600, curr loss: 1.3860429525375366, avg loss: 1.3863313698768616\n",
      "trial: 5, iter: 3800, curr loss: 1.3864043951034546, avg loss: 1.3863129204511642\n",
      "trial: 5, iter: 4000, curr loss: 1.386205792427063, avg loss: 1.3863245499134065\n",
      "trial: 5, iter: 4200, curr loss: 1.3862686157226562, avg loss: 1.3862912088632584\n",
      "trial: 5, iter: 4400, curr loss: 1.3858380317687988, avg loss: 1.386296039223671\n",
      "trial: 5, iter: 4600, curr loss: 1.3863681554794312, avg loss: 1.3863934755325318\n",
      "trial: 5, iter: 4800, curr loss: 1.3862745761871338, avg loss: 1.3863067138195038\n",
      "trial: 5, iter: 5000, curr loss: 1.386387825012207, avg loss: 1.3862868243455886\n",
      "trial: 5, iter: 5200, curr loss: 1.385998010635376, avg loss: 1.386336778998375\n",
      "trial: 5, iter: 5400, curr loss: 1.3864200115203857, avg loss: 1.3863134229183196\n",
      "trial: 5, iter: 5600, curr loss: 1.3862487077713013, avg loss: 1.3863176554441452\n",
      "trial: 5, iter: 5800, curr loss: 1.3861578702926636, avg loss: 1.3863831746578217\n",
      "trial: 5, iter: 6000, curr loss: 1.3855769634246826, avg loss: 1.3862905079126357\n",
      "trial: 5, iter: 6200, curr loss: 1.3874642848968506, avg loss: 1.38625695168972\n",
      "trial: 5, iter: 6400, curr loss: 1.3878560066223145, avg loss: 1.3863594681024551\n",
      "trial: 5, iter: 6600, curr loss: 1.3879573345184326, avg loss: 1.3864242655038834\n",
      "trial: 5, iter: 6800, curr loss: 1.3873076438903809, avg loss: 1.386361535191536\n",
      "trial: 5, iter: 7000, curr loss: 1.3865668773651123, avg loss: 1.3864039427042008\n",
      "trial: 5, iter: 7200, curr loss: 1.3862942457199097, avg loss: 1.3863434320688248\n",
      "trial: 5, iter: 7400, curr loss: 1.3864003419876099, avg loss: 1.3863289892673492\n",
      "trial: 5, iter: 7600, curr loss: 1.386634349822998, avg loss: 1.386301845908165\n",
      "trial: 5, iter: 7800, curr loss: 1.3866713047027588, avg loss: 1.3863310045003892\n",
      "trial: 5, iter: 8000, curr loss: 1.3859553337097168, avg loss: 1.386293756365776\n",
      "trial: 5, iter: 8200, curr loss: 1.3864775896072388, avg loss: 1.3863356876373292\n",
      "trial: 5, iter: 8400, curr loss: 1.3861515522003174, avg loss: 1.3862779438495636\n",
      "trial: 5, iter: 8600, curr loss: 1.3864446878433228, avg loss: 1.38636175096035\n",
      "trial: 5, iter: 8800, curr loss: 1.3860604763031006, avg loss: 1.3863085222244262\n",
      "trial: 5, iter: 9000, curr loss: 1.3864212036132812, avg loss: 1.38631789624691\n",
      "trial: 5, iter: 9200, curr loss: 1.3864384889602661, avg loss: 1.386292580962181\n",
      "trial: 5, iter: 9400, curr loss: 1.3863393068313599, avg loss: 1.3863085412979126\n",
      "trial: 5, iter: 9600, curr loss: 1.3865560293197632, avg loss: 1.386317982673645\n",
      "trial: 5, iter: 9800, curr loss: 1.386474847793579, avg loss: 1.386339522600174\n",
      "trial: 5, iter: 10000, curr loss: 1.3861726522445679, avg loss: 1.3862972515821457\n",
      "trial: 5, iter: 10200, curr loss: 1.3862276077270508, avg loss: 1.3862907409667968\n",
      "trial: 5, iter: 10400, curr loss: 1.3864312171936035, avg loss: 1.386328679919243\n",
      "trial: 5, iter: 10600, curr loss: 1.3861254453659058, avg loss: 1.3863007700443268\n",
      "trial: 5, iter: 10800, curr loss: 1.3862756490707397, avg loss: 1.386304242014885\n",
      "trial: 5, iter: 11000, curr loss: 1.3864309787750244, avg loss: 1.3862782984972\n",
      "trial: 5, iter: 11200, curr loss: 1.3864158391952515, avg loss: 1.386287390589714\n",
      "trial: 5, iter: 11400, curr loss: 1.3861355781555176, avg loss: 1.3863167136907577\n",
      "trial: 5, iter: 11600, curr loss: 1.3864694833755493, avg loss: 1.3862998741865158\n",
      "trial: 5, iter: 11800, curr loss: 1.3858940601348877, avg loss: 1.3863035839796067\n",
      "trial: 5, iter: 12000, curr loss: 1.3868403434753418, avg loss: 1.3863109284639359\n",
      "trial: 5, iter: 12200, curr loss: 1.3862781524658203, avg loss: 1.386305683851242\n",
      "trial: 5, iter: 12400, curr loss: 1.3863955736160278, avg loss: 1.3863019561767578\n",
      "trial: 5, iter: 12600, curr loss: 1.3861160278320312, avg loss: 1.3862977415323257\n",
      "trial: 5, iter: 12800, curr loss: 1.386291742324829, avg loss: 1.3863025331497192\n",
      "trial: 5, iter: 13000, curr loss: 1.386185884475708, avg loss: 1.3862984371185303\n",
      "trial: 5, iter: 13200, curr loss: 1.3861346244812012, avg loss: 1.3862998181581496\n",
      "trial: 5, iter: 13400, curr loss: 1.3865269422531128, avg loss: 1.386289067864418\n",
      "trial: 5, iter: 13600, curr loss: 1.3854751586914062, avg loss: 1.386276803612709\n",
      "trial: 5, iter: 13800, curr loss: 1.3863073587417603, avg loss: 1.3863265365362167\n",
      "trial: 5, iter: 14000, curr loss: 1.3862173557281494, avg loss: 1.3862960875034331\n",
      "trial: 5, iter: 14200, curr loss: 1.387770414352417, avg loss: 1.3863510745763779\n",
      "trial: 5, iter: 14400, curr loss: 1.3870002031326294, avg loss: 1.3863409739732742\n",
      "trial: 5, iter: 14600, curr loss: 1.3864855766296387, avg loss: 1.3863233882188797\n",
      "trial: 5, iter: 14800, curr loss: 1.3868210315704346, avg loss: 1.3862965649366379\n",
      "trial: 5, iter: 15000, curr loss: 1.3862829208374023, avg loss: 1.3863531011343002\n",
      "trial: 5, iter: 15200, curr loss: 1.3863478899002075, avg loss: 1.3863048434257508\n",
      "trial: 5, iter: 15400, curr loss: 1.3861638307571411, avg loss: 1.386275851726532\n",
      "trial: 5, iter: 15600, curr loss: 1.3861918449401855, avg loss: 1.3862987565994263\n",
      "trial: 5, ldr: 4.99774469062686e-05\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00011599983554333448\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862125873565674, avg loss: 1.3872688597440719\n",
      "trial: 1, iter: 400, curr loss: 1.3876703977584839, avg loss: 1.386630224585533\n",
      "trial: 1, iter: 600, curr loss: 1.3857351541519165, avg loss: 1.386450526714325\n",
      "trial: 1, iter: 800, curr loss: 1.3868962526321411, avg loss: 1.3865949177742005\n",
      "trial: 1, iter: 1000, curr loss: 1.3878167867660522, avg loss: 1.3863975048065185\n",
      "trial: 1, iter: 1200, curr loss: 1.3861747980117798, avg loss: 1.3864316165447235\n",
      "trial: 1, iter: 1400, curr loss: 1.3863048553466797, avg loss: 1.3863332730531692\n",
      "trial: 1, iter: 1600, curr loss: 1.3863626718521118, avg loss: 1.3862938541173935\n",
      "trial: 1, iter: 1800, curr loss: 1.3845837116241455, avg loss: 1.3863223052024842\n",
      "trial: 1, iter: 2000, curr loss: 1.386267900466919, avg loss: 1.3863837587833405\n",
      "trial: 1, iter: 2200, curr loss: 1.3865790367126465, avg loss: 1.386349648833275\n",
      "trial: 1, iter: 2400, curr loss: 1.386457085609436, avg loss: 1.3863754957914352\n",
      "trial: 1, iter: 2600, curr loss: 1.3859853744506836, avg loss: 1.3863418459892274\n",
      "trial: 1, iter: 2800, curr loss: 1.387385368347168, avg loss: 1.3863444244861602\n",
      "trial: 1, iter: 3000, curr loss: 1.3864006996154785, avg loss: 1.386393010020256\n",
      "trial: 1, iter: 3200, curr loss: 1.3861639499664307, avg loss: 1.3863278925418854\n",
      "trial: 1, iter: 3400, curr loss: 1.3866239786148071, avg loss: 1.3863156175613403\n",
      "trial: 1, iter: 3600, curr loss: 1.3870329856872559, avg loss: 1.386325579881668\n",
      "trial: 1, iter: 3800, curr loss: 1.3862271308898926, avg loss: 1.3863468015193938\n",
      "trial: 1, iter: 4000, curr loss: 1.3858805894851685, avg loss: 1.3862947171926499\n",
      "trial: 1, iter: 4200, curr loss: 1.3870484828948975, avg loss: 1.386307080388069\n",
      "trial: 1, iter: 4400, curr loss: 1.385955810546875, avg loss: 1.3862895596027374\n",
      "trial: 1, iter: 4600, curr loss: 1.3863059282302856, avg loss: 1.3863491654396056\n",
      "trial: 1, iter: 4800, curr loss: 1.3861721754074097, avg loss: 1.3863344675302505\n",
      "trial: 1, iter: 5000, curr loss: 1.3857747316360474, avg loss: 1.386334645152092\n",
      "trial: 1, iter: 5200, curr loss: 1.3865056037902832, avg loss: 1.3862977796792983\n",
      "trial: 1, iter: 5400, curr loss: 1.3864514827728271, avg loss: 1.3863605439662934\n",
      "trial: 1, iter: 5600, curr loss: 1.3865164518356323, avg loss: 1.386326966881752\n",
      "trial: 1, iter: 5800, curr loss: 1.3863505125045776, avg loss: 1.386301035284996\n",
      "trial: 1, iter: 6000, curr loss: 1.3864130973815918, avg loss: 1.3863199466466904\n",
      "trial: 1, iter: 6200, curr loss: 1.3863804340362549, avg loss: 1.3863044822216033\n",
      "trial: 1, iter: 6400, curr loss: 1.3864253759384155, avg loss: 1.3862946718931197\n",
      "trial: 1, iter: 6600, curr loss: 1.385759949684143, avg loss: 1.386258478164673\n",
      "trial: 1, iter: 6800, curr loss: 1.38797128200531, avg loss: 1.386577587723732\n",
      "trial: 1, iter: 7000, curr loss: 1.3861167430877686, avg loss: 1.3863215684890746\n",
      "trial: 1, iter: 7200, curr loss: 1.3864145278930664, avg loss: 1.3863618272542952\n",
      "trial: 1, iter: 7400, curr loss: 1.3847811222076416, avg loss: 1.386348975300789\n",
      "trial: 1, iter: 7600, curr loss: 1.3847252130508423, avg loss: 1.386396672129631\n",
      "trial: 1, iter: 7800, curr loss: 1.3865691423416138, avg loss: 1.386350250840187\n",
      "trial: 1, iter: 8000, curr loss: 1.386797308921814, avg loss: 1.3863317066431045\n",
      "trial: 1, iter: 8200, curr loss: 1.385928750038147, avg loss: 1.3863038152456284\n",
      "trial: 1, iter: 8400, curr loss: 1.386618971824646, avg loss: 1.3863182830810548\n",
      "trial: 1, iter: 8600, curr loss: 1.3864665031433105, avg loss: 1.386289866566658\n",
      "trial: 1, iter: 8800, curr loss: 1.3863704204559326, avg loss: 1.386335997581482\n",
      "trial: 1, iter: 9000, curr loss: 1.3870816230773926, avg loss: 1.386295843720436\n",
      "trial: 1, iter: 9200, curr loss: 1.3857492208480835, avg loss: 1.3863434249162674\n",
      "trial: 1, iter: 9400, curr loss: 1.3865052461624146, avg loss: 1.386299358010292\n",
      "trial: 1, iter: 9600, curr loss: 1.386501669883728, avg loss: 1.3863165307044982\n",
      "trial: 1, iter: 9800, curr loss: 1.3860615491867065, avg loss: 1.386302717924118\n",
      "trial: 1, iter: 10000, curr loss: 1.3862756490707397, avg loss: 1.3862906628847123\n",
      "trial: 1, iter: 10200, curr loss: 1.3866493701934814, avg loss: 1.3863064169883728\n",
      "trial: 1, iter: 10400, curr loss: 1.3863558769226074, avg loss: 1.3863336116075515\n",
      "trial: 1, iter: 10600, curr loss: 1.386969804763794, avg loss: 1.3862998902797699\n",
      "trial: 1, iter: 10800, curr loss: 1.38651442527771, avg loss: 1.3863186007738113\n",
      "trial: 1, iter: 11000, curr loss: 1.386229157447815, avg loss: 1.3863025134801865\n",
      "trial: 1, iter: 11200, curr loss: 1.3857836723327637, avg loss: 1.3862771594524383\n",
      "trial: 1, iter: 11400, curr loss: 1.3860527276992798, avg loss: 1.3863093823194503\n",
      "trial: 1, iter: 11600, curr loss: 1.386398434638977, avg loss: 1.38631707072258\n",
      "trial: 1, iter: 11800, curr loss: 1.3873283863067627, avg loss: 1.3863236540555954\n",
      "trial: 1, iter: 12000, curr loss: 1.385840654373169, avg loss: 1.386343293786049\n",
      "trial: 1, iter: 12200, curr loss: 1.3859469890594482, avg loss: 1.3863132613897324\n",
      "trial: 1, iter: 12400, curr loss: 1.385989785194397, avg loss: 1.3863448333740234\n",
      "trial: 1, iter: 12600, curr loss: 1.385730266571045, avg loss: 1.3862956440448762\n",
      "trial: 1, iter: 12800, curr loss: 1.3860517740249634, avg loss: 1.3862997859716415\n",
      "trial: 1, iter: 13000, curr loss: 1.3861695528030396, avg loss: 1.3862948358058929\n",
      "trial: 1, iter: 13200, curr loss: 1.3861855268478394, avg loss: 1.3863132095336914\n",
      "trial: 1, iter: 13400, curr loss: 1.3861815929412842, avg loss: 1.386320211291313\n",
      "trial: 1, iter: 13600, curr loss: 1.3863346576690674, avg loss: 1.3862984609603881\n",
      "trial: 1, iter: 13800, curr loss: 1.3862500190734863, avg loss: 1.3862930923700332\n",
      "trial: 1, iter: 14000, curr loss: 1.3863826990127563, avg loss: 1.3863054502010346\n",
      "trial: 1, iter: 14200, curr loss: 1.38655686378479, avg loss: 1.3863094478845597\n",
      "trial: 1, iter: 14400, curr loss: 1.3859307765960693, avg loss: 1.3863184428215027\n",
      "trial: 1, iter: 14600, curr loss: 1.386352777481079, avg loss: 1.3862885326147079\n",
      "trial: 1, iter: 14800, curr loss: 1.3866243362426758, avg loss: 1.3863107377290727\n",
      "trial: 1, iter: 15000, curr loss: 1.38607656955719, avg loss: 1.3862577766180038\n",
      "trial: 1, iter: 15200, curr loss: 1.3872733116149902, avg loss: 1.3863377171754836\n",
      "trial: 1, iter: 15400, curr loss: 1.386080026626587, avg loss: 1.3863104504346848\n",
      "trial: 1, iter: 15600, curr loss: 1.386457085609436, avg loss: 1.3863037729263306\n",
      "trial: 1, ldr: 0.0013344049220904708\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849196434020996, avg loss: 1.3875230264663696\n",
      "trial: 2, iter: 400, curr loss: 1.3856966495513916, avg loss: 1.3866930514574052\n",
      "trial: 2, iter: 600, curr loss: 1.387573003768921, avg loss: 1.3867215865850449\n",
      "trial: 2, iter: 800, curr loss: 1.3872828483581543, avg loss: 1.3864357960224152\n",
      "trial: 2, iter: 1000, curr loss: 1.386155366897583, avg loss: 1.3864957976341248\n",
      "trial: 2, iter: 1200, curr loss: 1.386797308921814, avg loss: 1.3864546394348145\n",
      "trial: 2, iter: 1400, curr loss: 1.3863948583602905, avg loss: 1.38642917573452\n",
      "trial: 2, iter: 1600, curr loss: 1.3864364624023438, avg loss: 1.386441357731819\n",
      "trial: 2, iter: 1800, curr loss: 1.387141466140747, avg loss: 1.3863012385368347\n",
      "trial: 2, iter: 2000, curr loss: 1.3861167430877686, avg loss: 1.3863715547323228\n",
      "trial: 2, iter: 2200, curr loss: 1.3863211870193481, avg loss: 1.3864132589101792\n",
      "trial: 2, iter: 2400, curr loss: 1.3859825134277344, avg loss: 1.3863765305280686\n",
      "trial: 2, iter: 2600, curr loss: 1.386147141456604, avg loss: 1.3863859003782273\n",
      "trial: 2, iter: 2800, curr loss: 1.38735032081604, avg loss: 1.386505317091942\n",
      "trial: 2, iter: 3000, curr loss: 1.3881334066390991, avg loss: 1.3864066296815871\n",
      "trial: 2, iter: 3200, curr loss: 1.3859716653823853, avg loss: 1.386373940706253\n",
      "trial: 2, iter: 3400, curr loss: 1.3846683502197266, avg loss: 1.3862996530532836\n",
      "trial: 2, iter: 3600, curr loss: 1.3857654333114624, avg loss: 1.3864062762260436\n",
      "trial: 2, iter: 3800, curr loss: 1.385624647140503, avg loss: 1.3864067471027375\n",
      "trial: 2, iter: 4000, curr loss: 1.3859144449234009, avg loss: 1.3863804548978806\n",
      "trial: 2, iter: 4200, curr loss: 1.386730670928955, avg loss: 1.3863448637723923\n",
      "trial: 2, iter: 4400, curr loss: 1.3860496282577515, avg loss: 1.3863375473022461\n",
      "trial: 2, iter: 4600, curr loss: 1.3850839138031006, avg loss: 1.3863000059127808\n",
      "trial: 2, iter: 4800, curr loss: 1.3859535455703735, avg loss: 1.3863344419002532\n",
      "trial: 2, iter: 5000, curr loss: 1.3863580226898193, avg loss: 1.3863291972875595\n",
      "trial: 2, iter: 5200, curr loss: 1.3860034942626953, avg loss: 1.3863328325748443\n",
      "trial: 2, iter: 5400, curr loss: 1.385817527770996, avg loss: 1.3863002640008926\n",
      "trial: 2, iter: 5600, curr loss: 1.3863574266433716, avg loss: 1.3863127583265304\n",
      "trial: 2, iter: 5800, curr loss: 1.386171817779541, avg loss: 1.386334034204483\n",
      "trial: 2, iter: 6000, curr loss: 1.3863614797592163, avg loss: 1.3863321882486344\n",
      "trial: 2, iter: 6200, curr loss: 1.3864812850952148, avg loss: 1.3863024419546128\n",
      "trial: 2, iter: 6400, curr loss: 1.3865222930908203, avg loss: 1.3863259005546569\n",
      "trial: 2, iter: 6600, curr loss: 1.3859416246414185, avg loss: 1.3862919056415557\n",
      "trial: 2, iter: 6800, curr loss: 1.3868129253387451, avg loss: 1.3863072407245636\n",
      "trial: 2, iter: 7000, curr loss: 1.3864227533340454, avg loss: 1.3863203382492066\n",
      "trial: 2, iter: 7200, curr loss: 1.3861554861068726, avg loss: 1.386308383345604\n",
      "trial: 2, iter: 7400, curr loss: 1.3854525089263916, avg loss: 1.38629791200161\n",
      "trial: 2, iter: 7600, curr loss: 1.38563072681427, avg loss: 1.3863865464925766\n",
      "trial: 2, iter: 7800, curr loss: 1.3850932121276855, avg loss: 1.386281008720398\n",
      "trial: 2, iter: 8000, curr loss: 1.3860812187194824, avg loss: 1.386343279480934\n",
      "trial: 2, iter: 8200, curr loss: 1.386378288269043, avg loss: 1.3863337314128876\n",
      "trial: 2, iter: 8400, curr loss: 1.3864316940307617, avg loss: 1.3862899565696716\n",
      "trial: 2, iter: 8600, curr loss: 1.3863602876663208, avg loss: 1.3863088810443878\n",
      "trial: 2, iter: 8800, curr loss: 1.3865528106689453, avg loss: 1.3862990218400955\n",
      "trial: 2, iter: 9000, curr loss: 1.3863142728805542, avg loss: 1.3863245218992233\n",
      "trial: 2, iter: 9200, curr loss: 1.3857247829437256, avg loss: 1.386450492143631\n",
      "trial: 2, iter: 9400, curr loss: 1.3854758739471436, avg loss: 1.3863537180423737\n",
      "trial: 2, iter: 9600, curr loss: 1.3865164518356323, avg loss: 1.3863616281747817\n",
      "trial: 2, iter: 9800, curr loss: 1.3863956928253174, avg loss: 1.3863367682695389\n",
      "trial: 2, iter: 10000, curr loss: 1.385871171951294, avg loss: 1.3863131022453308\n",
      "trial: 2, iter: 10200, curr loss: 1.3863760232925415, avg loss: 1.3863173639774322\n",
      "trial: 2, iter: 10400, curr loss: 1.3863489627838135, avg loss: 1.3863155752420426\n",
      "trial: 2, iter: 10600, curr loss: 1.3861796855926514, avg loss: 1.386297977566719\n",
      "trial: 2, iter: 10800, curr loss: 1.386353850364685, avg loss: 1.3862835121154786\n",
      "trial: 2, iter: 11000, curr loss: 1.38607919216156, avg loss: 1.3862914425134658\n",
      "trial: 2, iter: 11200, curr loss: 1.386610984802246, avg loss: 1.3863031512498856\n",
      "trial: 2, iter: 11400, curr loss: 1.3864269256591797, avg loss: 1.3863332796096801\n",
      "trial: 2, iter: 11600, curr loss: 1.3862193822860718, avg loss: 1.3862550765275956\n",
      "trial: 2, iter: 11800, curr loss: 1.3864156007766724, avg loss: 1.386335615515709\n",
      "trial: 2, iter: 12000, curr loss: 1.3863071203231812, avg loss: 1.3862645465135575\n",
      "trial: 2, iter: 12200, curr loss: 1.3854711055755615, avg loss: 1.386297292113304\n",
      "trial: 2, iter: 12400, curr loss: 1.3859305381774902, avg loss: 1.3863465422391892\n",
      "trial: 2, iter: 12600, curr loss: 1.386284589767456, avg loss: 1.3863158118724823\n",
      "trial: 2, iter: 12800, curr loss: 1.3862290382385254, avg loss: 1.386313732266426\n",
      "trial: 2, iter: 13000, curr loss: 1.3865166902542114, avg loss: 1.3862748950719834\n",
      "trial: 2, iter: 13200, curr loss: 1.3861347436904907, avg loss: 1.38638633787632\n",
      "trial: 2, iter: 13400, curr loss: 1.3863401412963867, avg loss: 1.3864054942131043\n",
      "trial: 2, iter: 13600, curr loss: 1.3867305517196655, avg loss: 1.3863020044565202\n",
      "trial: 2, iter: 13800, curr loss: 1.386698603630066, avg loss: 1.3862950855493545\n",
      "trial: 2, iter: 14000, curr loss: 1.3862069845199585, avg loss: 1.3863284146785737\n",
      "trial: 2, iter: 14200, curr loss: 1.3867120742797852, avg loss: 1.386302198767662\n",
      "trial: 2, iter: 14400, curr loss: 1.3864521980285645, avg loss: 1.386312524676323\n",
      "trial: 2, iter: 14600, curr loss: 1.386073112487793, avg loss: 1.3862853258848191\n",
      "trial: 2, iter: 14800, curr loss: 1.386348843574524, avg loss: 1.38630217730999\n",
      "trial: 2, iter: 15000, curr loss: 1.3876843452453613, avg loss: 1.3863012498617173\n",
      "trial: 2, iter: 15200, curr loss: 1.3862833976745605, avg loss: 1.3863326013088226\n",
      "trial: 2, iter: 15400, curr loss: 1.386393666267395, avg loss: 1.3863069355487823\n",
      "trial: 2, iter: 15600, curr loss: 1.3867372274398804, avg loss: 1.3862844043970108\n",
      "trial: 2, ldr: 0.0005758695770055056\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3883211612701416, avg loss: 1.3873572021722793\n",
      "trial: 3, iter: 400, curr loss: 1.3884437084197998, avg loss: 1.3866331332921982\n",
      "trial: 3, iter: 600, curr loss: 1.3862522840499878, avg loss: 1.3865071773529052\n",
      "trial: 3, iter: 800, curr loss: 1.3855693340301514, avg loss: 1.3864892399311066\n",
      "trial: 3, iter: 1000, curr loss: 1.3866422176361084, avg loss: 1.3864868015050889\n",
      "trial: 3, iter: 1200, curr loss: 1.3886973857879639, avg loss: 1.3864627301692962\n",
      "trial: 3, iter: 1400, curr loss: 1.38596773147583, avg loss: 1.3863428676128386\n",
      "trial: 3, iter: 1600, curr loss: 1.3880255222320557, avg loss: 1.386352168917656\n",
      "trial: 3, iter: 1800, curr loss: 1.385500431060791, avg loss: 1.3865780067443847\n",
      "trial: 3, iter: 2000, curr loss: 1.3862289190292358, avg loss: 1.3864036267995834\n",
      "trial: 3, iter: 2200, curr loss: 1.3856761455535889, avg loss: 1.3863804262876511\n",
      "trial: 3, iter: 2400, curr loss: 1.3855949640274048, avg loss: 1.3863721358776093\n",
      "trial: 3, iter: 2600, curr loss: 1.3852864503860474, avg loss: 1.3863782322406768\n",
      "trial: 3, iter: 2800, curr loss: 1.3859360218048096, avg loss: 1.386326619386673\n",
      "trial: 3, iter: 3000, curr loss: 1.3872233629226685, avg loss: 1.38636989235878\n",
      "trial: 3, iter: 3200, curr loss: 1.3863112926483154, avg loss: 1.3864004814624786\n",
      "trial: 3, iter: 3400, curr loss: 1.3865511417388916, avg loss: 1.386424326300621\n",
      "trial: 3, iter: 3600, curr loss: 1.3854148387908936, avg loss: 1.3863691222667693\n",
      "trial: 3, iter: 3800, curr loss: 1.38675057888031, avg loss: 1.386361511349678\n",
      "trial: 3, iter: 4000, curr loss: 1.386231780052185, avg loss: 1.386340538263321\n",
      "trial: 3, iter: 4200, curr loss: 1.386130928993225, avg loss: 1.386373382806778\n",
      "trial: 3, iter: 4400, curr loss: 1.3865413665771484, avg loss: 1.3863075989484788\n",
      "trial: 3, iter: 4600, curr loss: 1.3862154483795166, avg loss: 1.3863505285978317\n",
      "trial: 3, iter: 4800, curr loss: 1.3860434293746948, avg loss: 1.3863293296098709\n",
      "trial: 3, iter: 5000, curr loss: 1.386438012123108, avg loss: 1.3862990510463715\n",
      "trial: 3, iter: 5200, curr loss: 1.386637568473816, avg loss: 1.386323674917221\n",
      "trial: 3, iter: 5400, curr loss: 1.3870171308517456, avg loss: 1.3863380640745162\n",
      "trial: 3, iter: 5600, curr loss: 1.386153221130371, avg loss: 1.3863289439678192\n",
      "trial: 3, iter: 5800, curr loss: 1.3863905668258667, avg loss: 1.3862983947992324\n",
      "trial: 3, iter: 6000, curr loss: 1.3863669633865356, avg loss: 1.3863383024930953\n",
      "trial: 3, iter: 6200, curr loss: 1.386087417602539, avg loss: 1.3863335293531418\n",
      "trial: 3, iter: 6400, curr loss: 1.3856313228607178, avg loss: 1.3862864309549332\n",
      "trial: 3, iter: 6600, curr loss: 1.3851631879806519, avg loss: 1.3863692289590837\n",
      "trial: 3, iter: 6800, curr loss: 1.3867192268371582, avg loss: 1.3863288158178328\n",
      "trial: 3, iter: 7000, curr loss: 1.3863571882247925, avg loss: 1.3862804573774339\n",
      "trial: 3, iter: 7200, curr loss: 1.3858028650283813, avg loss: 1.3863554692268372\n",
      "trial: 3, iter: 7400, curr loss: 1.3856326341629028, avg loss: 1.3863461065292357\n",
      "trial: 3, iter: 7600, curr loss: 1.3868663311004639, avg loss: 1.3863720679283142\n",
      "trial: 3, iter: 7800, curr loss: 1.386009931564331, avg loss: 1.386327395439148\n",
      "trial: 3, iter: 8000, curr loss: 1.3859916925430298, avg loss: 1.3863069707155227\n",
      "trial: 3, iter: 8200, curr loss: 1.3862497806549072, avg loss: 1.3863274019956588\n",
      "trial: 3, iter: 8400, curr loss: 1.3862193822860718, avg loss: 1.3862910854816437\n",
      "trial: 3, iter: 8600, curr loss: 1.3868156671524048, avg loss: 1.3862878096103668\n",
      "trial: 3, iter: 8800, curr loss: 1.3859895467758179, avg loss: 1.3863246208429336\n",
      "trial: 3, iter: 9000, curr loss: 1.3861349821090698, avg loss: 1.386287618279457\n",
      "trial: 3, iter: 9200, curr loss: 1.3862051963806152, avg loss: 1.3863172537088395\n",
      "trial: 3, iter: 9400, curr loss: 1.3862226009368896, avg loss: 1.38638270676136\n",
      "trial: 3, iter: 9600, curr loss: 1.3863123655319214, avg loss: 1.386294726729393\n",
      "trial: 3, iter: 9800, curr loss: 1.3863486051559448, avg loss: 1.3863046431541444\n",
      "trial: 3, iter: 10000, curr loss: 1.3862487077713013, avg loss: 1.3863023591041566\n",
      "trial: 3, iter: 10200, curr loss: 1.3864365816116333, avg loss: 1.3862967681884766\n",
      "trial: 3, iter: 10400, curr loss: 1.3862133026123047, avg loss: 1.386304467320442\n",
      "trial: 3, iter: 10600, curr loss: 1.3861135244369507, avg loss: 1.386300232410431\n",
      "trial: 3, iter: 10800, curr loss: 1.3863506317138672, avg loss: 1.386299533843994\n",
      "trial: 3, iter: 11000, curr loss: 1.3863344192504883, avg loss: 1.3863118749856949\n",
      "trial: 3, iter: 11200, curr loss: 1.3862985372543335, avg loss: 1.3862976813316346\n",
      "trial: 3, iter: 11400, curr loss: 1.386286735534668, avg loss: 1.3862930560112\n",
      "trial: 3, iter: 11600, curr loss: 1.3863130807876587, avg loss: 1.3862954270839691\n",
      "trial: 3, iter: 11800, curr loss: 1.3863002061843872, avg loss: 1.3862946492433548\n",
      "trial: 3, iter: 12000, curr loss: 1.3860708475112915, avg loss: 1.3862962692975997\n",
      "trial: 3, iter: 12200, curr loss: 1.3862943649291992, avg loss: 1.3862955391407012\n",
      "trial: 3, iter: 12400, curr loss: 1.3862932920455933, avg loss: 1.3862983912229538\n",
      "trial: 3, iter: 12600, curr loss: 1.3862873315811157, avg loss: 1.3862954795360565\n",
      "trial: 3, iter: 12800, curr loss: 1.3862955570220947, avg loss: 1.3862943947315216\n",
      "trial: 3, iter: 13000, curr loss: 1.3862946033477783, avg loss: 1.3862949246168137\n",
      "trial: 3, iter: 13200, curr loss: 1.3862944841384888, avg loss: 1.3862948197126388\n",
      "trial: 3, iter: 13400, curr loss: 1.3862942457199097, avg loss: 1.3862947195768356\n",
      "trial: 3, iter: 13600, curr loss: 1.3862946033477783, avg loss: 1.3862945973873138\n",
      "trial: 3, iter: 13800, curr loss: 1.3862944841384888, avg loss: 1.3862947207689285\n",
      "trial: 3, iter: 14000, curr loss: 1.3862944841384888, avg loss: 1.3862944757938385\n",
      "trial: 3, iter: 14200, curr loss: 1.3862955570220947, avg loss: 1.3862945127487183\n",
      "trial: 3, iter: 14400, curr loss: 1.3862870931625366, avg loss: 1.3862940347194672\n",
      "trial: 3, iter: 14600, curr loss: 1.3862961530685425, avg loss: 1.386295776963234\n",
      "trial: 3, iter: 14800, curr loss: 1.3862948417663574, avg loss: 1.3862949073314668\n",
      "trial: 3, iter: 15000, curr loss: 1.3862946033477783, avg loss: 1.386294657588005\n",
      "trial: 3, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862946772575377\n",
      "trial: 3, iter: 15400, curr loss: 1.3866188526153564, avg loss: 1.3863159894943238\n",
      "trial: 3, iter: 15600, curr loss: 1.3860880136489868, avg loss: 1.386362396478653\n",
      "trial: 3, ldr: 0.0004189362225588411\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3908183574676514, avg loss: 1.3873567950725556\n",
      "trial: 4, iter: 400, curr loss: 1.3828575611114502, avg loss: 1.3865915751457214\n",
      "trial: 4, iter: 600, curr loss: 1.3882529735565186, avg loss: 1.3867353039979935\n",
      "trial: 4, iter: 800, curr loss: 1.387758731842041, avg loss: 1.3865511792898177\n",
      "trial: 4, iter: 1000, curr loss: 1.3864834308624268, avg loss: 1.3864017862081528\n",
      "trial: 4, iter: 1200, curr loss: 1.3863153457641602, avg loss: 1.3864961117506027\n",
      "trial: 4, iter: 1400, curr loss: 1.3879390954971313, avg loss: 1.386352640390396\n",
      "trial: 4, iter: 1600, curr loss: 1.3858208656311035, avg loss: 1.3864939206838607\n",
      "trial: 4, iter: 1800, curr loss: 1.3865628242492676, avg loss: 1.3865310889482498\n",
      "trial: 4, iter: 2000, curr loss: 1.38704252243042, avg loss: 1.3863793820142747\n",
      "trial: 4, iter: 2200, curr loss: 1.3861435651779175, avg loss: 1.3864187461137771\n",
      "trial: 4, iter: 2400, curr loss: 1.3860156536102295, avg loss: 1.3863842970132827\n",
      "trial: 4, iter: 2600, curr loss: 1.386711597442627, avg loss: 1.3863098698854446\n",
      "trial: 4, iter: 2800, curr loss: 1.3857029676437378, avg loss: 1.3863780933618546\n",
      "trial: 4, iter: 3000, curr loss: 1.3858470916748047, avg loss: 1.3863819390535355\n",
      "trial: 4, iter: 3200, curr loss: 1.3858020305633545, avg loss: 1.3863321590423583\n",
      "trial: 4, iter: 3400, curr loss: 1.3865320682525635, avg loss: 1.3864040440320968\n",
      "trial: 4, iter: 3600, curr loss: 1.3865107297897339, avg loss: 1.3862945955991746\n",
      "trial: 4, iter: 3800, curr loss: 1.3866163492202759, avg loss: 1.3863596165180205\n",
      "trial: 4, iter: 4000, curr loss: 1.38583505153656, avg loss: 1.3863319301605224\n",
      "trial: 4, iter: 4200, curr loss: 1.3865574598312378, avg loss: 1.3863213443756104\n",
      "trial: 4, iter: 4400, curr loss: 1.3864808082580566, avg loss: 1.386333819627762\n",
      "trial: 4, iter: 4600, curr loss: 1.3862799406051636, avg loss: 1.3863224542140962\n",
      "trial: 4, iter: 4800, curr loss: 1.3862019777297974, avg loss: 1.386339511871338\n",
      "trial: 4, iter: 5000, curr loss: 1.3861048221588135, avg loss: 1.3863501411676407\n",
      "trial: 4, iter: 5200, curr loss: 1.386511206626892, avg loss: 1.3863846892118454\n",
      "trial: 4, iter: 5400, curr loss: 1.3863468170166016, avg loss: 1.386350748538971\n",
      "trial: 4, iter: 5600, curr loss: 1.386555552482605, avg loss: 1.38632958650589\n",
      "trial: 4, iter: 5800, curr loss: 1.3861892223358154, avg loss: 1.3863687473535538\n",
      "trial: 4, iter: 6000, curr loss: 1.3868236541748047, avg loss: 1.386314136981964\n",
      "trial: 4, iter: 6200, curr loss: 1.3865596055984497, avg loss: 1.3863343268632888\n",
      "trial: 4, iter: 6400, curr loss: 1.3861589431762695, avg loss: 1.38629203915596\n",
      "trial: 4, iter: 6600, curr loss: 1.3864132165908813, avg loss: 1.386316083073616\n",
      "trial: 4, iter: 6800, curr loss: 1.387710690498352, avg loss: 1.3862945330142975\n",
      "trial: 4, iter: 7000, curr loss: 1.3859597444534302, avg loss: 1.3863661921024322\n",
      "trial: 4, iter: 7200, curr loss: 1.386399269104004, avg loss: 1.3863177382946015\n",
      "trial: 4, iter: 7400, curr loss: 1.3862316608428955, avg loss: 1.3863183522224427\n",
      "trial: 4, iter: 7600, curr loss: 1.3869678974151611, avg loss: 1.386302011013031\n",
      "trial: 4, iter: 7800, curr loss: 1.3860859870910645, avg loss: 1.3863435178995132\n",
      "trial: 4, iter: 8000, curr loss: 1.3861271142959595, avg loss: 1.3863035595417024\n",
      "trial: 4, iter: 8200, curr loss: 1.3862011432647705, avg loss: 1.3863512337207795\n",
      "trial: 4, iter: 8400, curr loss: 1.3858833312988281, avg loss: 1.386321941614151\n",
      "trial: 4, iter: 8600, curr loss: 1.386800765991211, avg loss: 1.386319220662117\n",
      "trial: 4, iter: 8800, curr loss: 1.3864142894744873, avg loss: 1.3863316482305528\n",
      "trial: 4, iter: 9000, curr loss: 1.386904001235962, avg loss: 1.3862996065616608\n",
      "trial: 4, iter: 9200, curr loss: 1.387506127357483, avg loss: 1.386450505256653\n",
      "trial: 4, iter: 9400, curr loss: 1.386443853378296, avg loss: 1.3863418781757355\n",
      "trial: 4, iter: 9600, curr loss: 1.3859511613845825, avg loss: 1.3862990176677703\n",
      "trial: 4, iter: 9800, curr loss: 1.3860676288604736, avg loss: 1.3863278990983963\n",
      "trial: 4, iter: 10000, curr loss: 1.3858202695846558, avg loss: 1.3862386327981948\n",
      "trial: 4, iter: 10200, curr loss: 1.3860262632369995, avg loss: 1.3863741904497147\n",
      "trial: 4, iter: 10400, curr loss: 1.3861634731292725, avg loss: 1.3863124930858612\n",
      "trial: 4, iter: 10600, curr loss: 1.3860529661178589, avg loss: 1.3863156896829605\n",
      "trial: 4, iter: 10800, curr loss: 1.3865175247192383, avg loss: 1.38631223320961\n",
      "trial: 4, iter: 11000, curr loss: 1.3864872455596924, avg loss: 1.3863107991218566\n",
      "trial: 4, iter: 11200, curr loss: 1.3864609003067017, avg loss: 1.3862994188070297\n",
      "trial: 4, iter: 11400, curr loss: 1.3863266706466675, avg loss: 1.3863051319122315\n",
      "trial: 4, iter: 11600, curr loss: 1.386346459388733, avg loss: 1.3863008403778077\n",
      "trial: 4, iter: 11800, curr loss: 1.386293649673462, avg loss: 1.3863081514835358\n",
      "trial: 4, iter: 12000, curr loss: 1.3864667415618896, avg loss: 1.3862920397520064\n",
      "trial: 4, iter: 12200, curr loss: 1.3855845928192139, avg loss: 1.3862632369995118\n",
      "trial: 4, iter: 12400, curr loss: 1.3860136270523071, avg loss: 1.3863289600610733\n",
      "trial: 4, iter: 12600, curr loss: 1.3868210315704346, avg loss: 1.3864088690280914\n",
      "trial: 4, iter: 12800, curr loss: 1.3862820863723755, avg loss: 1.38632195353508\n",
      "trial: 4, iter: 13000, curr loss: 1.3867324590682983, avg loss: 1.3863026577234268\n",
      "trial: 4, iter: 13200, curr loss: 1.3857334852218628, avg loss: 1.3862647169828415\n",
      "trial: 4, iter: 13400, curr loss: 1.3865771293640137, avg loss: 1.3863405799865722\n",
      "trial: 4, iter: 13600, curr loss: 1.3860623836517334, avg loss: 1.3863690263032913\n",
      "trial: 4, iter: 13800, curr loss: 1.3863284587860107, avg loss: 1.3863092201948166\n",
      "trial: 4, iter: 14000, curr loss: 1.3856459856033325, avg loss: 1.386279592514038\n",
      "trial: 4, iter: 14200, curr loss: 1.3860541582107544, avg loss: 1.386362246274948\n",
      "trial: 4, iter: 14400, curr loss: 1.3866254091262817, avg loss: 1.3863071829080582\n",
      "trial: 4, iter: 14600, curr loss: 1.3861634731292725, avg loss: 1.3862890160083772\n",
      "trial: 4, iter: 14800, curr loss: 1.3864423036575317, avg loss: 1.3863067638874054\n",
      "trial: 4, iter: 15000, curr loss: 1.3863823413848877, avg loss: 1.3863239985704423\n",
      "trial: 4, iter: 15200, curr loss: 1.3862154483795166, avg loss: 1.386314527988434\n",
      "trial: 4, iter: 15400, curr loss: 1.3865718841552734, avg loss: 1.3862887692451478\n",
      "trial: 4, iter: 15600, curr loss: 1.3857717514038086, avg loss: 1.3862916910648346\n",
      "trial: 4, ldr: -0.010565824806690216\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3855434656143188, avg loss: 1.3875319099426269\n",
      "trial: 5, iter: 400, curr loss: 1.3836294412612915, avg loss: 1.3867046415805817\n",
      "trial: 5, iter: 600, curr loss: 1.3853199481964111, avg loss: 1.3867069619894028\n",
      "trial: 5, iter: 800, curr loss: 1.3876423835754395, avg loss: 1.3865886968374252\n",
      "trial: 5, iter: 1000, curr loss: 1.3852590322494507, avg loss: 1.3864851433038712\n",
      "trial: 5, iter: 1200, curr loss: 1.3864866495132446, avg loss: 1.3865256768465042\n",
      "trial: 5, iter: 1400, curr loss: 1.3865344524383545, avg loss: 1.3864926880598067\n",
      "trial: 5, iter: 1600, curr loss: 1.3860417604446411, avg loss: 1.3863329845666885\n",
      "trial: 5, iter: 1800, curr loss: 1.386898398399353, avg loss: 1.3863837444782257\n",
      "trial: 5, iter: 2000, curr loss: 1.3873085975646973, avg loss: 1.386307366490364\n",
      "trial: 5, iter: 2200, curr loss: 1.3857823610305786, avg loss: 1.3864111810922624\n",
      "trial: 5, iter: 2400, curr loss: 1.3862413167953491, avg loss: 1.3863619881868363\n",
      "trial: 5, iter: 2600, curr loss: 1.3862595558166504, avg loss: 1.3863024020195007\n",
      "trial: 5, iter: 2800, curr loss: 1.3868638277053833, avg loss: 1.3864404094219207\n",
      "trial: 5, iter: 3000, curr loss: 1.3864939212799072, avg loss: 1.386369875073433\n",
      "trial: 5, iter: 3200, curr loss: 1.3843977451324463, avg loss: 1.3862906849384309\n",
      "trial: 5, iter: 3400, curr loss: 1.3864189386367798, avg loss: 1.386326944231987\n",
      "trial: 5, iter: 3600, curr loss: 1.3862571716308594, avg loss: 1.386357085108757\n",
      "trial: 5, iter: 3800, curr loss: 1.3866357803344727, avg loss: 1.386364523768425\n",
      "trial: 5, iter: 4000, curr loss: 1.3858023881912231, avg loss: 1.386307151913643\n",
      "trial: 5, iter: 4200, curr loss: 1.3860896825790405, avg loss: 1.3863707387447357\n",
      "trial: 5, iter: 4400, curr loss: 1.385843276977539, avg loss: 1.3863168954849243\n",
      "trial: 5, iter: 4600, curr loss: 1.385586142539978, avg loss: 1.386353189945221\n",
      "trial: 5, iter: 4800, curr loss: 1.3866710662841797, avg loss: 1.3863561046123505\n",
      "trial: 5, iter: 5000, curr loss: 1.387193202972412, avg loss: 1.3863095206022262\n",
      "trial: 5, iter: 5200, curr loss: 1.3868274688720703, avg loss: 1.3863414770364761\n",
      "trial: 5, iter: 5400, curr loss: 1.3863383531570435, avg loss: 1.3863129764795303\n",
      "trial: 5, iter: 5600, curr loss: 1.385990858078003, avg loss: 1.3863803625106812\n",
      "trial: 5, iter: 5800, curr loss: 1.3871349096298218, avg loss: 1.386337941288948\n",
      "trial: 5, iter: 6000, curr loss: 1.3856632709503174, avg loss: 1.3863493531942368\n",
      "trial: 5, iter: 6200, curr loss: 1.3861565589904785, avg loss: 1.3863172382116318\n",
      "trial: 5, iter: 6400, curr loss: 1.3859139680862427, avg loss: 1.3863646602630615\n",
      "trial: 5, iter: 6600, curr loss: 1.3860564231872559, avg loss: 1.3864284133911133\n",
      "trial: 5, iter: 6800, curr loss: 1.3857864141464233, avg loss: 1.3863102775812148\n",
      "trial: 5, iter: 7000, curr loss: 1.386415719985962, avg loss: 1.3864054757356643\n",
      "trial: 5, iter: 7200, curr loss: 1.3864706754684448, avg loss: 1.3862994295358657\n",
      "trial: 5, iter: 7400, curr loss: 1.3867350816726685, avg loss: 1.386310248374939\n",
      "trial: 5, iter: 7600, curr loss: 1.3857311010360718, avg loss: 1.386481847167015\n",
      "trial: 5, iter: 7800, curr loss: 1.3871238231658936, avg loss: 1.3863991314172746\n",
      "trial: 5, iter: 8000, curr loss: 1.3872548341751099, avg loss: 1.3863646054267884\n",
      "trial: 5, iter: 8200, curr loss: 1.385252833366394, avg loss: 1.386320624947548\n",
      "trial: 5, iter: 8400, curr loss: 1.3859727382659912, avg loss: 1.38635213971138\n",
      "trial: 5, iter: 8600, curr loss: 1.3860424757003784, avg loss: 1.3862433886528016\n",
      "trial: 5, iter: 8800, curr loss: 1.3854832649230957, avg loss: 1.386366376876831\n",
      "trial: 5, iter: 9000, curr loss: 1.3866052627563477, avg loss: 1.386363561153412\n",
      "trial: 5, iter: 9200, curr loss: 1.3864545822143555, avg loss: 1.3863178265094758\n",
      "trial: 5, iter: 9400, curr loss: 1.3868080377578735, avg loss: 1.386332728266716\n",
      "trial: 5, iter: 9600, curr loss: 1.3863170146942139, avg loss: 1.3863404679298401\n",
      "trial: 5, iter: 9800, curr loss: 1.3861420154571533, avg loss: 1.386310418844223\n",
      "trial: 5, iter: 10000, curr loss: 1.3857965469360352, avg loss: 1.3862908720970153\n",
      "trial: 5, iter: 10200, curr loss: 1.3861093521118164, avg loss: 1.3862908947467805\n",
      "trial: 5, iter: 10400, curr loss: 1.3867899179458618, avg loss: 1.38632344186306\n",
      "trial: 5, iter: 10600, curr loss: 1.386575698852539, avg loss: 1.386311161518097\n",
      "trial: 5, iter: 10800, curr loss: 1.3863976001739502, avg loss: 1.3863258647918701\n",
      "trial: 5, iter: 11000, curr loss: 1.385989785194397, avg loss: 1.386292072534561\n",
      "trial: 5, iter: 11200, curr loss: 1.386216640472412, avg loss: 1.3863638883829117\n",
      "trial: 5, iter: 11400, curr loss: 1.3866243362426758, avg loss: 1.3862919741868973\n",
      "trial: 5, iter: 11600, curr loss: 1.3869975805282593, avg loss: 1.3863299477100373\n",
      "trial: 5, iter: 11800, curr loss: 1.3861501216888428, avg loss: 1.3862972831726075\n",
      "trial: 5, iter: 12000, curr loss: 1.3861252069473267, avg loss: 1.3863233536481858\n",
      "trial: 5, iter: 12200, curr loss: 1.386323094367981, avg loss: 1.3863210159540176\n",
      "trial: 5, iter: 12400, curr loss: 1.3862247467041016, avg loss: 1.3863057446479798\n",
      "trial: 5, iter: 12600, curr loss: 1.3863959312438965, avg loss: 1.3863274836540223\n",
      "trial: 5, iter: 12800, curr loss: 1.3863425254821777, avg loss: 1.3863298326730729\n",
      "trial: 5, iter: 13000, curr loss: 1.3864209651947021, avg loss: 1.386290265917778\n",
      "trial: 5, iter: 13200, curr loss: 1.3863391876220703, avg loss: 1.3863539814949035\n",
      "trial: 5, iter: 13400, curr loss: 1.3859330415725708, avg loss: 1.3862831205129624\n",
      "trial: 5, iter: 13600, curr loss: 1.3862969875335693, avg loss: 1.3863188701868057\n",
      "trial: 5, iter: 13800, curr loss: 1.3861870765686035, avg loss: 1.386300864815712\n",
      "trial: 5, iter: 14000, curr loss: 1.3862098455429077, avg loss: 1.386307668685913\n",
      "trial: 5, iter: 14200, curr loss: 1.3863601684570312, avg loss: 1.3863040566444398\n",
      "trial: 5, iter: 14400, curr loss: 1.3861737251281738, avg loss: 1.3863048267364502\n",
      "trial: 5, iter: 14600, curr loss: 1.3862749338150024, avg loss: 1.3863064992427825\n",
      "trial: 5, iter: 14800, curr loss: 1.3861639499664307, avg loss: 1.3862943172454834\n",
      "trial: 5, iter: 15000, curr loss: 1.3863787651062012, avg loss: 1.386289239525795\n",
      "trial: 5, iter: 15200, curr loss: 1.3862066268920898, avg loss: 1.3863154673576354\n",
      "trial: 5, iter: 15400, curr loss: 1.3862498998641968, avg loss: 1.3863123041391372\n",
      "trial: 5, iter: 15600, curr loss: 1.386214017868042, avg loss: 1.3862973672151566\n",
      "trial: 5, ldr: -0.004050916526466608\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0024575061223004015\n",
      "Experiment done with data path: ./data/catNon-lin-NI_12/data.50k.dz50.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_15/data.20k.dz100.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3847490549087524, avg loss: 1.387308259010315\n",
      "trial: 1, iter: 400, curr loss: 1.3864381313323975, avg loss: 1.3867618763446807\n",
      "trial: 1, iter: 600, curr loss: 1.3862204551696777, avg loss: 1.386409083008766\n",
      "trial: 1, iter: 800, curr loss: 1.3865286111831665, avg loss: 1.3866451853513717\n",
      "trial: 1, iter: 1000, curr loss: 1.3902790546417236, avg loss: 1.3864319694042206\n",
      "trial: 1, iter: 1200, curr loss: 1.3857479095458984, avg loss: 1.3864104998111726\n",
      "trial: 1, iter: 1400, curr loss: 1.3857707977294922, avg loss: 1.3864792144298554\n",
      "trial: 1, iter: 1600, curr loss: 1.3869136571884155, avg loss: 1.3863571226596831\n",
      "trial: 1, iter: 1800, curr loss: 1.3872697353363037, avg loss: 1.3863725781440734\n",
      "trial: 1, iter: 2000, curr loss: 1.3850207328796387, avg loss: 1.386361945271492\n",
      "trial: 1, iter: 2200, curr loss: 1.3875243663787842, avg loss: 1.3862871271371842\n",
      "trial: 1, iter: 2400, curr loss: 1.3863965272903442, avg loss: 1.3864096188545227\n",
      "trial: 1, iter: 2600, curr loss: 1.3848704099655151, avg loss: 1.3862974292039871\n",
      "trial: 1, iter: 2800, curr loss: 1.3859764337539673, avg loss: 1.3863432842493058\n",
      "trial: 1, iter: 3000, curr loss: 1.3866835832595825, avg loss: 1.3863792634010315\n",
      "trial: 1, iter: 3200, curr loss: 1.3860194683074951, avg loss: 1.3863082867860794\n",
      "trial: 1, iter: 3400, curr loss: 1.3864578008651733, avg loss: 1.3863010746240616\n",
      "trial: 1, iter: 3600, curr loss: 1.385858416557312, avg loss: 1.3863002526760102\n",
      "trial: 1, iter: 3800, curr loss: 1.386041283607483, avg loss: 1.3863160610198975\n",
      "trial: 1, iter: 4000, curr loss: 1.3867785930633545, avg loss: 1.3863014191389085\n",
      "trial: 1, iter: 4200, curr loss: 1.38614022731781, avg loss: 1.3862905818223954\n",
      "trial: 1, iter: 4400, curr loss: 1.3864048719406128, avg loss: 1.3862906056642532\n",
      "trial: 1, iter: 4600, curr loss: 1.3863600492477417, avg loss: 1.3863139432668685\n",
      "trial: 1, iter: 4800, curr loss: 1.3860430717468262, avg loss: 1.386339294910431\n",
      "trial: 1, iter: 5000, curr loss: 1.3862107992172241, avg loss: 1.3863317209482193\n",
      "trial: 1, iter: 5200, curr loss: 1.3860424757003784, avg loss: 1.3863200598955154\n",
      "trial: 1, iter: 5400, curr loss: 1.3874701261520386, avg loss: 1.3862861013412475\n",
      "trial: 1, iter: 5600, curr loss: 1.386178731918335, avg loss: 1.3863235872983932\n",
      "trial: 1, iter: 5800, curr loss: 1.3865292072296143, avg loss: 1.386288228034973\n",
      "trial: 1, iter: 6000, curr loss: 1.3865448236465454, avg loss: 1.386333360671997\n",
      "trial: 1, iter: 6200, curr loss: 1.385964274406433, avg loss: 1.3863189774751663\n",
      "trial: 1, ldr: 0.00040832586819306016\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3884012699127197, avg loss: 1.3871247345209121\n",
      "trial: 2, iter: 400, curr loss: 1.3852548599243164, avg loss: 1.3865894162654877\n",
      "trial: 2, iter: 600, curr loss: 1.3862404823303223, avg loss: 1.386535232067108\n",
      "trial: 2, iter: 800, curr loss: 1.3871811628341675, avg loss: 1.386399204134941\n",
      "trial: 2, iter: 1000, curr loss: 1.3856221437454224, avg loss: 1.3864887100458145\n",
      "trial: 2, iter: 1200, curr loss: 1.3850913047790527, avg loss: 1.3864497327804566\n",
      "trial: 2, iter: 1400, curr loss: 1.3870962858200073, avg loss: 1.3864368569850922\n",
      "trial: 2, iter: 1600, curr loss: 1.3872956037521362, avg loss: 1.3864010238647462\n",
      "trial: 2, iter: 1800, curr loss: 1.3847280740737915, avg loss: 1.386355943083763\n",
      "trial: 2, iter: 2000, curr loss: 1.3854796886444092, avg loss: 1.386402086019516\n",
      "trial: 2, iter: 2200, curr loss: 1.3855596780776978, avg loss: 1.3863390707969665\n",
      "trial: 2, iter: 2400, curr loss: 1.3862649202346802, avg loss: 1.3864253973960876\n",
      "trial: 2, iter: 2600, curr loss: 1.3872181177139282, avg loss: 1.3863432449102402\n",
      "trial: 2, iter: 2800, curr loss: 1.3857276439666748, avg loss: 1.386457393169403\n",
      "trial: 2, iter: 3000, curr loss: 1.387123703956604, avg loss: 1.3864433324337007\n",
      "trial: 2, iter: 3200, curr loss: 1.3868424892425537, avg loss: 1.3863423866033555\n",
      "trial: 2, iter: 3400, curr loss: 1.3864659070968628, avg loss: 1.386355242729187\n",
      "trial: 2, iter: 3600, curr loss: 1.3862444162368774, avg loss: 1.3863079768419266\n",
      "trial: 2, iter: 3800, curr loss: 1.3862570524215698, avg loss: 1.3863231998682022\n",
      "trial: 2, iter: 4000, curr loss: 1.3865388631820679, avg loss: 1.3863658899068831\n",
      "trial: 2, iter: 4200, curr loss: 1.385703682899475, avg loss: 1.3863185834884644\n",
      "trial: 2, iter: 4400, curr loss: 1.3862351179122925, avg loss: 1.386346293091774\n",
      "trial: 2, iter: 4600, curr loss: 1.3868366479873657, avg loss: 1.3863280588388442\n",
      "trial: 2, iter: 4800, curr loss: 1.3868383169174194, avg loss: 1.386304280757904\n",
      "trial: 2, iter: 5000, curr loss: 1.3860185146331787, avg loss: 1.3863520920276642\n",
      "trial: 2, iter: 5200, curr loss: 1.3862524032592773, avg loss: 1.3863399988412857\n",
      "trial: 2, iter: 5400, curr loss: 1.3866978883743286, avg loss: 1.386318690776825\n",
      "trial: 2, iter: 5600, curr loss: 1.3862563371658325, avg loss: 1.386326100230217\n",
      "trial: 2, iter: 5800, curr loss: 1.3863005638122559, avg loss: 1.3862864792346954\n",
      "trial: 2, iter: 6000, curr loss: 1.386861801147461, avg loss: 1.3863123971223832\n",
      "trial: 2, iter: 6200, curr loss: 1.3863420486450195, avg loss: 1.3863354641199113\n",
      "trial: 2, ldr: 0.004460756201297045\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3870738744735718, avg loss: 1.3870873111486435\n",
      "trial: 3, iter: 400, curr loss: 1.385877013206482, avg loss: 1.3865583640336991\n",
      "trial: 3, iter: 600, curr loss: 1.3859055042266846, avg loss: 1.3865464359521866\n",
      "trial: 3, iter: 800, curr loss: 1.3861063718795776, avg loss: 1.3864479845762252\n",
      "trial: 3, iter: 1000, curr loss: 1.3874670267105103, avg loss: 1.3863896864652634\n",
      "trial: 3, iter: 1200, curr loss: 1.3879348039627075, avg loss: 1.3865140748023987\n",
      "trial: 3, iter: 1400, curr loss: 1.3862553834915161, avg loss: 1.3865626549720764\n",
      "trial: 3, iter: 1600, curr loss: 1.385101318359375, avg loss: 1.3863661164045333\n",
      "trial: 3, iter: 1800, curr loss: 1.3866103887557983, avg loss: 1.3863402426242828\n",
      "trial: 3, iter: 2000, curr loss: 1.3863821029663086, avg loss: 1.3863914173841476\n",
      "trial: 3, iter: 2200, curr loss: 1.3862942457199097, avg loss: 1.3863318049907685\n",
      "trial: 3, iter: 2400, curr loss: 1.3865230083465576, avg loss: 1.3863430148363114\n",
      "trial: 3, iter: 2600, curr loss: 1.3872219324111938, avg loss: 1.3863788312673568\n",
      "trial: 3, iter: 2800, curr loss: 1.3868545293807983, avg loss: 1.386282702088356\n",
      "trial: 3, iter: 3000, curr loss: 1.3868716955184937, avg loss: 1.3863830763101577\n",
      "trial: 3, iter: 3200, curr loss: 1.387464165687561, avg loss: 1.3863712012767793\n",
      "trial: 3, iter: 3400, curr loss: 1.3856444358825684, avg loss: 1.3863752549886703\n",
      "trial: 3, iter: 3600, curr loss: 1.3858439922332764, avg loss: 1.386319287419319\n",
      "trial: 3, iter: 3800, curr loss: 1.3877513408660889, avg loss: 1.386277803182602\n",
      "trial: 3, iter: 4000, curr loss: 1.3868687152862549, avg loss: 1.386372864842415\n",
      "trial: 3, iter: 4200, curr loss: 1.3858474493026733, avg loss: 1.386317062973976\n",
      "trial: 3, iter: 4400, curr loss: 1.3862212896347046, avg loss: 1.3863018441200257\n",
      "trial: 3, iter: 4600, curr loss: 1.3866134881973267, avg loss: 1.3863680815696717\n",
      "trial: 3, iter: 4800, curr loss: 1.386918306350708, avg loss: 1.3863402354717254\n",
      "trial: 3, iter: 5000, curr loss: 1.3863682746887207, avg loss: 1.3863153797388077\n",
      "trial: 3, iter: 5200, curr loss: 1.3867878913879395, avg loss: 1.3863130301237105\n",
      "trial: 3, iter: 5400, curr loss: 1.3870562314987183, avg loss: 1.3863198399543761\n",
      "trial: 3, iter: 5600, curr loss: 1.3866493701934814, avg loss: 1.3863899201154708\n",
      "trial: 3, iter: 5800, curr loss: 1.3866164684295654, avg loss: 1.3863893151283264\n",
      "trial: 3, iter: 6000, curr loss: 1.3862000703811646, avg loss: 1.3863806062936783\n",
      "trial: 3, iter: 6200, curr loss: 1.3867359161376953, avg loss: 1.3863407212495804\n",
      "trial: 3, ldr: -0.006198799703270197\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3876100778579712, avg loss: 1.387185446023941\n",
      "trial: 4, iter: 400, curr loss: 1.386896014213562, avg loss: 1.3864558571577072\n",
      "trial: 4, iter: 600, curr loss: 1.3838375806808472, avg loss: 1.38658755838871\n",
      "trial: 4, iter: 800, curr loss: 1.3858897686004639, avg loss: 1.3865901923179627\n",
      "trial: 4, iter: 1000, curr loss: 1.386725902557373, avg loss: 1.3864125090837478\n",
      "trial: 4, iter: 1200, curr loss: 1.3873980045318604, avg loss: 1.386441262960434\n",
      "trial: 4, iter: 1400, curr loss: 1.3857479095458984, avg loss: 1.38636146068573\n",
      "trial: 4, iter: 1600, curr loss: 1.3873071670532227, avg loss: 1.3863739585876464\n",
      "trial: 4, iter: 1800, curr loss: 1.3862762451171875, avg loss: 1.3863743788003922\n",
      "trial: 4, iter: 2000, curr loss: 1.3868393898010254, avg loss: 1.3863193362951278\n",
      "trial: 4, iter: 2200, curr loss: 1.385836124420166, avg loss: 1.386378607749939\n",
      "trial: 4, iter: 2400, curr loss: 1.3863153457641602, avg loss: 1.3863299542665481\n",
      "trial: 4, iter: 2600, curr loss: 1.3865350484848022, avg loss: 1.3863256299495696\n",
      "trial: 4, iter: 2800, curr loss: 1.386152744293213, avg loss: 1.3863297390937805\n",
      "trial: 4, iter: 3000, curr loss: 1.386633038520813, avg loss: 1.386332275867462\n",
      "trial: 4, iter: 3200, curr loss: 1.387332558631897, avg loss: 1.3863711601495743\n",
      "trial: 4, iter: 3400, curr loss: 1.3866010904312134, avg loss: 1.3863595509529114\n",
      "trial: 4, iter: 3600, curr loss: 1.3865035772323608, avg loss: 1.3862788373231887\n",
      "trial: 4, iter: 3800, curr loss: 1.3883637189865112, avg loss: 1.3862830543518065\n",
      "trial: 4, iter: 4000, curr loss: 1.385642409324646, avg loss: 1.3863549548387528\n",
      "trial: 4, iter: 4200, curr loss: 1.3861677646636963, avg loss: 1.3863461065292357\n",
      "trial: 4, iter: 4400, curr loss: 1.3868262767791748, avg loss: 1.386337730884552\n",
      "trial: 4, iter: 4600, curr loss: 1.3859705924987793, avg loss: 1.386299946308136\n",
      "trial: 4, iter: 4800, curr loss: 1.386699914932251, avg loss: 1.3862848198413849\n",
      "trial: 4, iter: 5000, curr loss: 1.3864649534225464, avg loss: 1.3863376313447953\n",
      "trial: 4, iter: 5200, curr loss: 1.386292815208435, avg loss: 1.3863241362571717\n",
      "trial: 4, iter: 5400, curr loss: 1.3861278295516968, avg loss: 1.3862889075279237\n",
      "trial: 4, iter: 5600, curr loss: 1.386519432067871, avg loss: 1.386325080394745\n",
      "trial: 4, iter: 5800, curr loss: 1.38655686378479, avg loss: 1.3862948036193847\n",
      "trial: 4, iter: 6000, curr loss: 1.3860445022583008, avg loss: 1.3863004672527313\n",
      "trial: 4, iter: 6200, curr loss: 1.3862563371658325, avg loss: 1.3863016593456268\n",
      "trial: 4, ldr: -0.0026521964464336634\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3844796419143677, avg loss: 1.3872842693328857\n",
      "trial: 5, iter: 400, curr loss: 1.3865541219711304, avg loss: 1.386648917198181\n",
      "trial: 5, iter: 600, curr loss: 1.3863348960876465, avg loss: 1.3865275138616562\n",
      "trial: 5, iter: 800, curr loss: 1.3863770961761475, avg loss: 1.386440258026123\n",
      "trial: 5, iter: 1000, curr loss: 1.3859894275665283, avg loss: 1.3864043599367142\n",
      "trial: 5, iter: 1200, curr loss: 1.3855558633804321, avg loss: 1.3863882553577422\n",
      "trial: 5, iter: 1400, curr loss: 1.385515570640564, avg loss: 1.3863732200860976\n",
      "trial: 5, iter: 1600, curr loss: 1.3863354921340942, avg loss: 1.3863599038124084\n",
      "trial: 5, iter: 1800, curr loss: 1.3851468563079834, avg loss: 1.3863979929685593\n",
      "trial: 5, iter: 2000, curr loss: 1.3850629329681396, avg loss: 1.3864473313093186\n",
      "trial: 5, iter: 2200, curr loss: 1.3864314556121826, avg loss: 1.3863914871215821\n",
      "trial: 5, iter: 2400, curr loss: 1.3860520124435425, avg loss: 1.386415091753006\n",
      "trial: 5, iter: 2600, curr loss: 1.3870810270309448, avg loss: 1.3863409960269928\n",
      "trial: 5, iter: 2800, curr loss: 1.386059045791626, avg loss: 1.3863572925329208\n",
      "trial: 5, iter: 3000, curr loss: 1.386226773262024, avg loss: 1.3863315743207931\n",
      "trial: 5, iter: 3200, curr loss: 1.386634111404419, avg loss: 1.3863228714466096\n",
      "trial: 5, iter: 3400, curr loss: 1.3879308700561523, avg loss: 1.386345921754837\n",
      "trial: 5, iter: 3600, curr loss: 1.3863587379455566, avg loss: 1.3863519936800004\n",
      "trial: 5, iter: 3800, curr loss: 1.3871614933013916, avg loss: 1.3862859827280045\n",
      "trial: 5, iter: 4000, curr loss: 1.3873931169509888, avg loss: 1.3862903863191605\n",
      "trial: 5, iter: 4200, curr loss: 1.3858174085617065, avg loss: 1.3864012068510057\n",
      "trial: 5, iter: 4400, curr loss: 1.3851772546768188, avg loss: 1.3862750041484833\n",
      "trial: 5, iter: 4600, curr loss: 1.385432481765747, avg loss: 1.386332106590271\n",
      "trial: 5, iter: 4800, curr loss: 1.3854787349700928, avg loss: 1.3863702642917632\n",
      "trial: 5, iter: 5000, curr loss: 1.385858416557312, avg loss: 1.3863260531425476\n",
      "trial: 5, iter: 5200, curr loss: 1.385959267616272, avg loss: 1.386369684934616\n",
      "trial: 5, iter: 5400, curr loss: 1.3865505456924438, avg loss: 1.3863837456703185\n",
      "trial: 5, iter: 5600, curr loss: 1.38668954372406, avg loss: 1.386343156695366\n",
      "trial: 5, iter: 5800, curr loss: 1.3869627714157104, avg loss: 1.3863178825378417\n",
      "trial: 5, iter: 6000, curr loss: 1.3856441974639893, avg loss: 1.3863644713163377\n",
      "trial: 5, iter: 6200, curr loss: 1.3860923051834106, avg loss: 1.3863856101036072\n",
      "trial: 5, ldr: 0.00047939151409082115\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0007005045132245869\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3897253274917603, avg loss: 1.3878518164157867\n",
      "trial: 1, iter: 400, curr loss: 1.3862037658691406, avg loss: 1.3869087016582489\n",
      "trial: 1, iter: 600, curr loss: 1.3861724138259888, avg loss: 1.3866360068321228\n",
      "trial: 1, iter: 800, curr loss: 1.3876826763153076, avg loss: 1.386510841846466\n",
      "trial: 1, iter: 1000, curr loss: 1.387115240097046, avg loss: 1.3864988946914674\n",
      "trial: 1, iter: 1200, curr loss: 1.3867466449737549, avg loss: 1.3864784067869187\n",
      "trial: 1, iter: 1400, curr loss: 1.3871428966522217, avg loss: 1.3864526402950288\n",
      "trial: 1, iter: 1600, curr loss: 1.3851361274719238, avg loss: 1.386335352063179\n",
      "trial: 1, iter: 1800, curr loss: 1.387891173362732, avg loss: 1.3865137827396392\n",
      "trial: 1, iter: 2000, curr loss: 1.385825276374817, avg loss: 1.386473660469055\n",
      "trial: 1, iter: 2200, curr loss: 1.3872648477554321, avg loss: 1.3863857889175415\n",
      "trial: 1, iter: 2400, curr loss: 1.387570858001709, avg loss: 1.3863158410787582\n",
      "trial: 1, iter: 2600, curr loss: 1.3856390714645386, avg loss: 1.386373752951622\n",
      "trial: 1, iter: 2800, curr loss: 1.3867740631103516, avg loss: 1.3863787442445754\n",
      "trial: 1, iter: 3000, curr loss: 1.385918378829956, avg loss: 1.3863991022109985\n",
      "trial: 1, iter: 3200, curr loss: 1.386343240737915, avg loss: 1.3863647019863128\n",
      "trial: 1, iter: 3400, curr loss: 1.385892391204834, avg loss: 1.386391328573227\n",
      "trial: 1, iter: 3600, curr loss: 1.3862545490264893, avg loss: 1.3863828545808792\n",
      "trial: 1, iter: 3800, curr loss: 1.3864855766296387, avg loss: 1.386345843076706\n",
      "trial: 1, iter: 4000, curr loss: 1.3855462074279785, avg loss: 1.3863636845350265\n",
      "trial: 1, iter: 4200, curr loss: 1.3847161531448364, avg loss: 1.3863034218549728\n",
      "trial: 1, iter: 4400, curr loss: 1.3860859870910645, avg loss: 1.3863384735584259\n",
      "trial: 1, iter: 4600, curr loss: 1.386137843132019, avg loss: 1.386393390893936\n",
      "trial: 1, iter: 4800, curr loss: 1.387554407119751, avg loss: 1.3863155442476272\n",
      "trial: 1, iter: 5000, curr loss: 1.3864374160766602, avg loss: 1.3863393121957779\n",
      "trial: 1, iter: 5200, curr loss: 1.3857386112213135, avg loss: 1.3862926054000855\n",
      "trial: 1, iter: 5400, curr loss: 1.3860770463943481, avg loss: 1.3863512122631072\n",
      "trial: 1, iter: 5600, curr loss: 1.3852732181549072, avg loss: 1.3863363456726074\n",
      "trial: 1, iter: 5800, curr loss: 1.3855582475662231, avg loss: 1.386302587389946\n",
      "trial: 1, iter: 6000, curr loss: 1.3854234218597412, avg loss: 1.386349670290947\n",
      "trial: 1, iter: 6200, curr loss: 1.3852304220199585, avg loss: 1.3863345527648925\n",
      "trial: 1, ldr: -0.00039378649671562016\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3868919610977173, avg loss: 1.387348664999008\n",
      "trial: 2, iter: 400, curr loss: 1.3874176740646362, avg loss: 1.386702160835266\n",
      "trial: 2, iter: 600, curr loss: 1.3858592510223389, avg loss: 1.3866162955760957\n",
      "trial: 2, iter: 800, curr loss: 1.3862801790237427, avg loss: 1.386530032157898\n",
      "trial: 2, iter: 1000, curr loss: 1.3873817920684814, avg loss: 1.3865018564462661\n",
      "trial: 2, iter: 1200, curr loss: 1.3863714933395386, avg loss: 1.3864384865760804\n",
      "trial: 2, iter: 1400, curr loss: 1.3867402076721191, avg loss: 1.3864548295736312\n",
      "trial: 2, iter: 1600, curr loss: 1.3851653337478638, avg loss: 1.3863717818260193\n",
      "trial: 2, iter: 1800, curr loss: 1.3869832754135132, avg loss: 1.3864180964231492\n",
      "trial: 2, iter: 2000, curr loss: 1.3857909440994263, avg loss: 1.3864003264904021\n",
      "trial: 2, iter: 2200, curr loss: 1.3856557607650757, avg loss: 1.3863540023565293\n",
      "trial: 2, iter: 2400, curr loss: 1.3852390050888062, avg loss: 1.3863453418016434\n",
      "trial: 2, iter: 2600, curr loss: 1.3870813846588135, avg loss: 1.3863912230730058\n",
      "trial: 2, iter: 2800, curr loss: 1.386059284210205, avg loss: 1.3862972199916839\n",
      "trial: 2, iter: 3000, curr loss: 1.3871417045593262, avg loss: 1.3862988704442978\n",
      "trial: 2, iter: 3200, curr loss: 1.3867123126983643, avg loss: 1.3864305484294892\n",
      "trial: 2, iter: 3400, curr loss: 1.3863269090652466, avg loss: 1.3864377343654632\n",
      "trial: 2, iter: 3600, curr loss: 1.3877151012420654, avg loss: 1.3864022034406662\n",
      "trial: 2, iter: 3800, curr loss: 1.3867323398590088, avg loss: 1.386350132226944\n",
      "trial: 2, iter: 4000, curr loss: 1.3873295783996582, avg loss: 1.3863284200429917\n",
      "trial: 2, iter: 4200, curr loss: 1.3864434957504272, avg loss: 1.3863721203804016\n",
      "trial: 2, iter: 4400, curr loss: 1.386135458946228, avg loss: 1.386342785358429\n",
      "trial: 2, iter: 4600, curr loss: 1.3862087726593018, avg loss: 1.3863125097751618\n",
      "trial: 2, iter: 4800, curr loss: 1.3860050439834595, avg loss: 1.3862799924612046\n",
      "trial: 2, iter: 5000, curr loss: 1.3857030868530273, avg loss: 1.3863076591491699\n",
      "trial: 2, iter: 5200, curr loss: 1.3860596418380737, avg loss: 1.386333217024803\n",
      "trial: 2, iter: 5400, curr loss: 1.3858954906463623, avg loss: 1.3863227224349977\n",
      "trial: 2, iter: 5600, curr loss: 1.3866910934448242, avg loss: 1.3862951773405074\n",
      "trial: 2, iter: 5800, curr loss: 1.3861874341964722, avg loss: 1.386329528093338\n",
      "trial: 2, iter: 6000, curr loss: 1.3865240812301636, avg loss: 1.386295765042305\n",
      "trial: 2, iter: 6200, curr loss: 1.3863942623138428, avg loss: 1.3863079023361207\n",
      "trial: 2, ldr: -0.004740182310342789\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3849313259124756, avg loss: 1.3872463709115983\n",
      "trial: 3, iter: 400, curr loss: 1.385841965675354, avg loss: 1.3867908543348313\n",
      "trial: 3, iter: 600, curr loss: 1.3873378038406372, avg loss: 1.3865530008077622\n",
      "trial: 3, iter: 800, curr loss: 1.387639045715332, avg loss: 1.3864474606513977\n",
      "trial: 3, iter: 1000, curr loss: 1.3856866359710693, avg loss: 1.386482267975807\n",
      "trial: 3, iter: 1200, curr loss: 1.3872138261795044, avg loss: 1.3864462554454804\n",
      "trial: 3, iter: 1400, curr loss: 1.38629949092865, avg loss: 1.3863572120666503\n",
      "trial: 3, iter: 1600, curr loss: 1.3853487968444824, avg loss: 1.3862986797094345\n",
      "trial: 3, iter: 1800, curr loss: 1.3861619234085083, avg loss: 1.3864351469278335\n",
      "trial: 3, iter: 2000, curr loss: 1.3862251043319702, avg loss: 1.3863697934150696\n",
      "trial: 3, iter: 2200, curr loss: 1.3852598667144775, avg loss: 1.3863952112197877\n",
      "trial: 3, iter: 2400, curr loss: 1.3861092329025269, avg loss: 1.3863185459375382\n",
      "trial: 3, iter: 2600, curr loss: 1.3868303298950195, avg loss: 1.3863959568738937\n",
      "trial: 3, iter: 2800, curr loss: 1.3860279321670532, avg loss: 1.3863473266363144\n",
      "trial: 3, iter: 3000, curr loss: 1.3859641551971436, avg loss: 1.38636472761631\n",
      "trial: 3, iter: 3200, curr loss: 1.3862191438674927, avg loss: 1.386361523270607\n",
      "trial: 3, iter: 3400, curr loss: 1.3859596252441406, avg loss: 1.3863438898324967\n",
      "trial: 3, iter: 3600, curr loss: 1.3863348960876465, avg loss: 1.386354571580887\n",
      "trial: 3, iter: 3800, curr loss: 1.3875250816345215, avg loss: 1.38635768532753\n",
      "trial: 3, iter: 4000, curr loss: 1.386786937713623, avg loss: 1.3863336712121963\n",
      "trial: 3, iter: 4200, curr loss: 1.3859286308288574, avg loss: 1.386320276260376\n",
      "trial: 3, iter: 4400, curr loss: 1.38558030128479, avg loss: 1.386331483721733\n",
      "trial: 3, iter: 4600, curr loss: 1.3864305019378662, avg loss: 1.3863314527273178\n",
      "trial: 3, iter: 4800, curr loss: 1.3862738609313965, avg loss: 1.3863329529762267\n",
      "trial: 3, iter: 5000, curr loss: 1.3860336542129517, avg loss: 1.3862944489717484\n",
      "trial: 3, iter: 5200, curr loss: 1.3865476846694946, avg loss: 1.3863453412055968\n",
      "trial: 3, iter: 5400, curr loss: 1.3862837553024292, avg loss: 1.3863255292177201\n",
      "trial: 3, iter: 5600, curr loss: 1.3870279788970947, avg loss: 1.3863253206014634\n",
      "trial: 3, iter: 5800, curr loss: 1.3864834308624268, avg loss: 1.3863264232873918\n",
      "trial: 3, iter: 6000, curr loss: 1.3863328695297241, avg loss: 1.3863013368844985\n",
      "trial: 3, iter: 6200, curr loss: 1.3864036798477173, avg loss: 1.3863034600019455\n",
      "trial: 3, ldr: -0.008463743142783642\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3878082036972046, avg loss: 1.387428766489029\n",
      "trial: 4, iter: 400, curr loss: 1.3845113515853882, avg loss: 1.3867738550901414\n",
      "trial: 4, iter: 600, curr loss: 1.3872002363204956, avg loss: 1.3867214393615723\n",
      "trial: 4, iter: 800, curr loss: 1.3871040344238281, avg loss: 1.3864931488037109\n",
      "trial: 4, iter: 1000, curr loss: 1.3874181509017944, avg loss: 1.3864985829591752\n",
      "trial: 4, iter: 1200, curr loss: 1.3869311809539795, avg loss: 1.38644500374794\n",
      "trial: 4, iter: 1400, curr loss: 1.3843152523040771, avg loss: 1.3863301223516464\n",
      "trial: 4, iter: 1600, curr loss: 1.3870176076889038, avg loss: 1.386430316567421\n",
      "trial: 4, iter: 1800, curr loss: 1.3861745595932007, avg loss: 1.3864656227827072\n",
      "trial: 4, iter: 2000, curr loss: 1.3866170644760132, avg loss: 1.386360164284706\n",
      "trial: 4, iter: 2200, curr loss: 1.3876631259918213, avg loss: 1.386403470635414\n",
      "trial: 4, iter: 2400, curr loss: 1.386090636253357, avg loss: 1.3863272881507873\n",
      "trial: 4, iter: 2600, curr loss: 1.3857219219207764, avg loss: 1.3863954043388367\n",
      "trial: 4, iter: 2800, curr loss: 1.3854882717132568, avg loss: 1.3863211578130723\n",
      "trial: 4, iter: 3000, curr loss: 1.388116717338562, avg loss: 1.3863442128896712\n",
      "trial: 4, iter: 3200, curr loss: 1.3862887620925903, avg loss: 1.3863335382938384\n",
      "trial: 4, iter: 3400, curr loss: 1.3861156702041626, avg loss: 1.3863145434856414\n",
      "trial: 4, iter: 3600, curr loss: 1.386186957359314, avg loss: 1.3863296461105348\n",
      "trial: 4, iter: 3800, curr loss: 1.386671543121338, avg loss: 1.3863049888610839\n",
      "trial: 4, iter: 4000, curr loss: 1.385075569152832, avg loss: 1.3862669628858566\n",
      "trial: 4, iter: 4200, curr loss: 1.3867288827896118, avg loss: 1.386382806301117\n",
      "trial: 4, iter: 4400, curr loss: 1.3862394094467163, avg loss: 1.3863569205999375\n",
      "trial: 4, iter: 4600, curr loss: 1.3857884407043457, avg loss: 1.3863322919607162\n",
      "trial: 4, iter: 4800, curr loss: 1.3860716819763184, avg loss: 1.386388196349144\n",
      "trial: 4, iter: 5000, curr loss: 1.3868266344070435, avg loss: 1.386253662109375\n",
      "trial: 4, iter: 5200, curr loss: 1.3866887092590332, avg loss: 1.3863904941082001\n",
      "trial: 4, iter: 5400, curr loss: 1.3857823610305786, avg loss: 1.3863290929794312\n",
      "trial: 4, iter: 5600, curr loss: 1.386290192604065, avg loss: 1.3862968468666077\n",
      "trial: 4, iter: 5800, curr loss: 1.3861989974975586, avg loss: 1.3863270980119706\n",
      "trial: 4, iter: 6000, curr loss: 1.385604739189148, avg loss: 1.3862934517860412\n",
      "trial: 4, iter: 6200, curr loss: 1.3858349323272705, avg loss: 1.3863712221384048\n",
      "trial: 4, ldr: -0.006438421551138163\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3867043256759644, avg loss: 1.3873735231161117\n",
      "trial: 5, iter: 400, curr loss: 1.387702226638794, avg loss: 1.3867580622434617\n",
      "trial: 5, iter: 600, curr loss: 1.3857792615890503, avg loss: 1.3866145890951156\n",
      "trial: 5, iter: 800, curr loss: 1.3869380950927734, avg loss: 1.3865270805358887\n",
      "trial: 5, iter: 1000, curr loss: 1.3865379095077515, avg loss: 1.3864762860536575\n",
      "trial: 5, iter: 1200, curr loss: 1.3862022161483765, avg loss: 1.386340278983116\n",
      "trial: 5, iter: 1400, curr loss: 1.3880445957183838, avg loss: 1.3865192657709122\n",
      "trial: 5, iter: 1600, curr loss: 1.386489748954773, avg loss: 1.3864978283643723\n",
      "trial: 5, iter: 1800, curr loss: 1.386286735534668, avg loss: 1.3864087444543838\n",
      "trial: 5, iter: 2000, curr loss: 1.38788640499115, avg loss: 1.386411709189415\n",
      "trial: 5, iter: 2200, curr loss: 1.3863584995269775, avg loss: 1.3863851308822632\n",
      "trial: 5, iter: 2400, curr loss: 1.386995553970337, avg loss: 1.3863808745145798\n",
      "trial: 5, iter: 2600, curr loss: 1.3864915370941162, avg loss: 1.3863982784748077\n",
      "trial: 5, iter: 2800, curr loss: 1.3856908082962036, avg loss: 1.3863702708482741\n",
      "trial: 5, iter: 3000, curr loss: 1.3872917890548706, avg loss: 1.3863258439302444\n",
      "trial: 5, iter: 3200, curr loss: 1.387146234512329, avg loss: 1.3863713747262956\n",
      "trial: 5, iter: 3400, curr loss: 1.3863717317581177, avg loss: 1.3863799434900284\n",
      "trial: 5, iter: 3600, curr loss: 1.3870755434036255, avg loss: 1.3863103610277177\n",
      "trial: 5, iter: 3800, curr loss: 1.3868248462677002, avg loss: 1.3863668900728225\n",
      "trial: 5, iter: 4000, curr loss: 1.3864598274230957, avg loss: 1.3863689929246903\n",
      "trial: 5, iter: 4200, curr loss: 1.3863067626953125, avg loss: 1.386325558423996\n",
      "trial: 5, iter: 4400, curr loss: 1.3856518268585205, avg loss: 1.3863184607028962\n",
      "trial: 5, iter: 4600, curr loss: 1.3859909772872925, avg loss: 1.386370912194252\n",
      "trial: 5, iter: 4800, curr loss: 1.3869572877883911, avg loss: 1.3863374209403991\n",
      "trial: 5, iter: 5000, curr loss: 1.3865715265274048, avg loss: 1.386290967464447\n",
      "trial: 5, iter: 5200, curr loss: 1.3863420486450195, avg loss: 1.386367678642273\n",
      "trial: 5, iter: 5400, curr loss: 1.3867324590682983, avg loss: 1.3862989258766174\n",
      "trial: 5, iter: 5600, curr loss: 1.3865219354629517, avg loss: 1.3863052982091904\n",
      "trial: 5, iter: 5800, curr loss: 1.3857264518737793, avg loss: 1.3863231760263444\n",
      "trial: 5, iter: 6000, curr loss: 1.3861315250396729, avg loss: 1.386350345015526\n",
      "trial: 5, iter: 6200, curr loss: 1.38664972782135, avg loss: 1.3862981748580934\n",
      "trial: 5, ldr: 0.006381324026733637\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0027309618948493154\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3838982582092285, avg loss: 1.3874718254804612\n",
      "trial: 1, iter: 400, curr loss: 1.3849326372146606, avg loss: 1.3868476378917693\n",
      "trial: 1, iter: 600, curr loss: 1.3868578672409058, avg loss: 1.3866031670570373\n",
      "trial: 1, iter: 800, curr loss: 1.3868837356567383, avg loss: 1.3864813017845155\n",
      "trial: 1, iter: 1000, curr loss: 1.3868753910064697, avg loss: 1.3863858789205552\n",
      "trial: 1, iter: 1200, curr loss: 1.385366678237915, avg loss: 1.386328975558281\n",
      "trial: 1, iter: 1400, curr loss: 1.3858948945999146, avg loss: 1.3863541281223297\n",
      "trial: 1, iter: 1600, curr loss: 1.386549472808838, avg loss: 1.3864697468280793\n",
      "trial: 1, iter: 1800, curr loss: 1.385959267616272, avg loss: 1.3864338928461075\n",
      "trial: 1, iter: 2000, curr loss: 1.3863627910614014, avg loss: 1.3863466054201126\n",
      "trial: 1, iter: 2200, curr loss: 1.3861314058303833, avg loss: 1.386325848698616\n",
      "trial: 1, iter: 2400, curr loss: 1.3862223625183105, avg loss: 1.386361938714981\n",
      "trial: 1, iter: 2600, curr loss: 1.3863791227340698, avg loss: 1.386335711479187\n",
      "trial: 1, iter: 2800, curr loss: 1.3864917755126953, avg loss: 1.386301361322403\n",
      "trial: 1, iter: 3000, curr loss: 1.38621187210083, avg loss: 1.3863547360897064\n",
      "trial: 1, iter: 3200, curr loss: 1.3862073421478271, avg loss: 1.3863511860370636\n",
      "trial: 1, iter: 3400, curr loss: 1.386339545249939, avg loss: 1.3863223373889924\n",
      "trial: 1, iter: 3600, curr loss: 1.3859243392944336, avg loss: 1.3862899106740951\n",
      "trial: 1, iter: 3800, curr loss: 1.3868829011917114, avg loss: 1.3863102608919144\n",
      "trial: 1, iter: 4000, curr loss: 1.3867906332015991, avg loss: 1.3863417941331864\n",
      "trial: 1, iter: 4200, curr loss: 1.3864827156066895, avg loss: 1.3863253700733185\n",
      "trial: 1, iter: 4400, curr loss: 1.386467695236206, avg loss: 1.3863193422555924\n",
      "trial: 1, iter: 4600, curr loss: 1.3866033554077148, avg loss: 1.3862841421365737\n",
      "trial: 1, iter: 4800, curr loss: 1.3866000175476074, avg loss: 1.3863580518960952\n",
      "trial: 1, iter: 5000, curr loss: 1.3866267204284668, avg loss: 1.3863530391454697\n",
      "trial: 1, iter: 5200, curr loss: 1.3865013122558594, avg loss: 1.386337350010872\n",
      "trial: 1, iter: 5400, curr loss: 1.38645601272583, avg loss: 1.3863007247447967\n",
      "trial: 1, iter: 5600, curr loss: 1.386035442352295, avg loss: 1.3863190323114396\n",
      "trial: 1, iter: 5800, curr loss: 1.3864656686782837, avg loss: 1.386317139863968\n",
      "trial: 1, iter: 6000, curr loss: 1.3852887153625488, avg loss: 1.3862878650426864\n",
      "trial: 1, iter: 6200, curr loss: 1.386330008506775, avg loss: 1.3863139307498933\n",
      "trial: 1, ldr: -0.0006403952138498425\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3885353803634644, avg loss: 1.38731958091259\n",
      "trial: 2, iter: 400, curr loss: 1.38400399684906, avg loss: 1.3867235910892486\n",
      "trial: 2, iter: 600, curr loss: 1.3869726657867432, avg loss: 1.3867029190063476\n",
      "trial: 2, iter: 800, curr loss: 1.3866158723831177, avg loss: 1.386534921526909\n",
      "trial: 2, iter: 1000, curr loss: 1.386844515800476, avg loss: 1.386437861919403\n",
      "trial: 2, iter: 1200, curr loss: 1.3860598802566528, avg loss: 1.3864605849981309\n",
      "trial: 2, iter: 1400, curr loss: 1.3879817724227905, avg loss: 1.3862933605909347\n",
      "trial: 2, iter: 1600, curr loss: 1.3872781991958618, avg loss: 1.3864341986179352\n",
      "trial: 2, iter: 1800, curr loss: 1.3854080438613892, avg loss: 1.3863538777828217\n",
      "trial: 2, iter: 2000, curr loss: 1.3862700462341309, avg loss: 1.3864460253715516\n",
      "trial: 2, iter: 2200, curr loss: 1.3850173950195312, avg loss: 1.3863277691602707\n",
      "trial: 2, iter: 2400, curr loss: 1.386844277381897, avg loss: 1.3864404785633087\n",
      "trial: 2, iter: 2600, curr loss: 1.3870201110839844, avg loss: 1.3864346289634704\n",
      "trial: 2, iter: 2800, curr loss: 1.3861958980560303, avg loss: 1.3864519840478897\n",
      "trial: 2, iter: 3000, curr loss: 1.386555552482605, avg loss: 1.3862592661380768\n",
      "trial: 2, iter: 3200, curr loss: 1.3860857486724854, avg loss: 1.3863548201322555\n",
      "trial: 2, iter: 3400, curr loss: 1.3876484632492065, avg loss: 1.3862965196371078\n",
      "trial: 2, iter: 3600, curr loss: 1.3874965906143188, avg loss: 1.386297782063484\n",
      "trial: 2, iter: 3800, curr loss: 1.3850868940353394, avg loss: 1.3863846671581268\n",
      "trial: 2, iter: 4000, curr loss: 1.3861165046691895, avg loss: 1.3863380259275437\n",
      "trial: 2, iter: 4200, curr loss: 1.3863086700439453, avg loss: 1.3863694030046463\n",
      "trial: 2, iter: 4400, curr loss: 1.3867944478988647, avg loss: 1.3863622212409974\n",
      "trial: 2, iter: 4600, curr loss: 1.3857982158660889, avg loss: 1.3863332384824754\n",
      "trial: 2, iter: 4800, curr loss: 1.386223554611206, avg loss: 1.3863533014059066\n",
      "trial: 2, iter: 5000, curr loss: 1.3864028453826904, avg loss: 1.3863038265705108\n",
      "trial: 2, iter: 5200, curr loss: 1.3855597972869873, avg loss: 1.386375008225441\n",
      "trial: 2, iter: 5400, curr loss: 1.3860807418823242, avg loss: 1.3863746964931487\n",
      "trial: 2, iter: 5600, curr loss: 1.3865547180175781, avg loss: 1.3863570737838744\n",
      "trial: 2, iter: 5800, curr loss: 1.386610984802246, avg loss: 1.386349641084671\n",
      "trial: 2, iter: 6000, curr loss: 1.3854385614395142, avg loss: 1.3863814520835875\n",
      "trial: 2, iter: 6200, curr loss: 1.386183738708496, avg loss: 1.3863863319158554\n",
      "trial: 2, ldr: -0.008430770598351955\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3870465755462646, avg loss: 1.3874254322052002\n",
      "trial: 3, iter: 400, curr loss: 1.3858928680419922, avg loss: 1.3865519046783448\n",
      "trial: 3, iter: 600, curr loss: 1.3859336376190186, avg loss: 1.3865709763765335\n",
      "trial: 3, iter: 800, curr loss: 1.3862416744232178, avg loss: 1.3866715782880783\n",
      "trial: 3, iter: 1000, curr loss: 1.3865987062454224, avg loss: 1.3864725780487062\n",
      "trial: 3, iter: 1200, curr loss: 1.3870353698730469, avg loss: 1.38642482817173\n",
      "trial: 3, iter: 1400, curr loss: 1.3868809938430786, avg loss: 1.3864088159799577\n",
      "trial: 3, iter: 1600, curr loss: 1.3875888586044312, avg loss: 1.3864586544036865\n",
      "trial: 3, iter: 1800, curr loss: 1.3874754905700684, avg loss: 1.3865046721696854\n",
      "trial: 3, iter: 2000, curr loss: 1.3867765665054321, avg loss: 1.386364756822586\n",
      "trial: 3, iter: 2200, curr loss: 1.3866877555847168, avg loss: 1.386375796198845\n",
      "trial: 3, iter: 2400, curr loss: 1.3858470916748047, avg loss: 1.3863312023878098\n",
      "trial: 3, iter: 2600, curr loss: 1.3862594366073608, avg loss: 1.3863188010454177\n",
      "trial: 3, iter: 2800, curr loss: 1.387176752090454, avg loss: 1.3864087057113648\n",
      "trial: 3, iter: 3000, curr loss: 1.386120080947876, avg loss: 1.3863881701231002\n",
      "trial: 3, iter: 3200, curr loss: 1.3859411478042603, avg loss: 1.3863236767053604\n",
      "trial: 3, iter: 3400, curr loss: 1.3863838911056519, avg loss: 1.386344120502472\n",
      "trial: 3, iter: 3600, curr loss: 1.3860172033309937, avg loss: 1.3862901604175568\n",
      "trial: 3, iter: 3800, curr loss: 1.386875867843628, avg loss: 1.3863249498605728\n",
      "trial: 3, iter: 4000, curr loss: 1.386441946029663, avg loss: 1.3863367086648941\n",
      "trial: 3, iter: 4200, curr loss: 1.3868887424468994, avg loss: 1.3862891221046447\n",
      "trial: 3, iter: 4400, curr loss: 1.3862587213516235, avg loss: 1.3863454425334931\n",
      "trial: 3, iter: 4600, curr loss: 1.3861647844314575, avg loss: 1.386307308077812\n",
      "trial: 3, iter: 4800, curr loss: 1.385735034942627, avg loss: 1.386309996843338\n",
      "trial: 3, iter: 5000, curr loss: 1.3868944644927979, avg loss: 1.3863856768608094\n",
      "trial: 3, iter: 5200, curr loss: 1.385433554649353, avg loss: 1.3863914543390274\n",
      "trial: 3, iter: 5400, curr loss: 1.3859204053878784, avg loss: 1.3863736033439635\n",
      "trial: 3, iter: 5600, curr loss: 1.3863537311553955, avg loss: 1.3863504010438918\n",
      "trial: 3, iter: 5800, curr loss: 1.3865437507629395, avg loss: 1.3863216310739517\n",
      "trial: 3, iter: 6000, curr loss: 1.3864883184432983, avg loss: 1.3863466358184815\n",
      "trial: 3, iter: 6200, curr loss: 1.3868483304977417, avg loss: 1.3863072115182877\n",
      "trial: 3, ldr: 0.007914839312434196\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3847922086715698, avg loss: 1.3871887493133546\n",
      "trial: 4, iter: 400, curr loss: 1.3870717287063599, avg loss: 1.386937335729599\n",
      "trial: 4, iter: 600, curr loss: 1.3863974809646606, avg loss: 1.386629496216774\n",
      "trial: 4, iter: 800, curr loss: 1.3850921392440796, avg loss: 1.3863291335105896\n",
      "trial: 4, iter: 1000, curr loss: 1.3859238624572754, avg loss: 1.3865581011772157\n",
      "trial: 4, iter: 1200, curr loss: 1.386315941810608, avg loss: 1.3864736557006836\n",
      "trial: 4, iter: 1400, curr loss: 1.3859665393829346, avg loss: 1.3863761281967164\n",
      "trial: 4, iter: 1600, curr loss: 1.3877215385437012, avg loss: 1.3864047348499298\n",
      "trial: 4, iter: 1800, curr loss: 1.386824607849121, avg loss: 1.3864172685146332\n",
      "trial: 4, iter: 2000, curr loss: 1.3863037824630737, avg loss: 1.3863562375307084\n",
      "trial: 4, iter: 2200, curr loss: 1.3864105939865112, avg loss: 1.386356903910637\n",
      "trial: 4, iter: 2400, curr loss: 1.3859261274337769, avg loss: 1.386358392238617\n",
      "trial: 4, iter: 2600, curr loss: 1.385976791381836, avg loss: 1.3863667130470276\n",
      "trial: 4, iter: 2800, curr loss: 1.3832943439483643, avg loss: 1.3863390010595322\n",
      "trial: 4, iter: 3000, curr loss: 1.3865163326263428, avg loss: 1.386428831219673\n",
      "trial: 4, iter: 3200, curr loss: 1.385851502418518, avg loss: 1.3863820397853852\n",
      "trial: 4, iter: 3400, curr loss: 1.3859190940856934, avg loss: 1.3863627779483796\n",
      "trial: 4, iter: 3600, curr loss: 1.3862416744232178, avg loss: 1.386391317844391\n",
      "trial: 4, iter: 3800, curr loss: 1.3863229751586914, avg loss: 1.386328992843628\n",
      "trial: 4, iter: 4000, curr loss: 1.3868327140808105, avg loss: 1.3863450521230698\n",
      "trial: 4, iter: 4200, curr loss: 1.3859641551971436, avg loss: 1.3863554018735886\n",
      "trial: 4, iter: 4400, curr loss: 1.3867895603179932, avg loss: 1.3864084798097611\n",
      "trial: 4, iter: 4600, curr loss: 1.3859472274780273, avg loss: 1.3864251977205277\n",
      "trial: 4, iter: 4800, curr loss: 1.386348843574524, avg loss: 1.3863494569063186\n",
      "trial: 4, iter: 5000, curr loss: 1.3863588571548462, avg loss: 1.386267848610878\n",
      "trial: 4, iter: 5200, curr loss: 1.3861548900604248, avg loss: 1.386349345445633\n",
      "trial: 4, iter: 5400, curr loss: 1.386582374572754, avg loss: 1.386330342888832\n",
      "trial: 4, iter: 5600, curr loss: 1.3860211372375488, avg loss: 1.3863318663835527\n",
      "trial: 4, iter: 5800, curr loss: 1.3859461545944214, avg loss: 1.3863357144594193\n",
      "trial: 4, iter: 6000, curr loss: 1.3866337537765503, avg loss: 1.3863377523422242\n",
      "trial: 4, iter: 6200, curr loss: 1.3869104385375977, avg loss: 1.3862997299432755\n",
      "trial: 4, ldr: -0.0023513317573815584\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3895362615585327, avg loss: 1.387250267267227\n",
      "trial: 5, iter: 400, curr loss: 1.3860210180282593, avg loss: 1.3866138631105422\n",
      "trial: 5, iter: 600, curr loss: 1.3872151374816895, avg loss: 1.3865328407287598\n",
      "trial: 5, iter: 800, curr loss: 1.3858580589294434, avg loss: 1.3865118622779846\n",
      "trial: 5, iter: 1000, curr loss: 1.3863691091537476, avg loss: 1.3865084749460221\n",
      "trial: 5, iter: 1200, curr loss: 1.3867806196212769, avg loss: 1.38644182741642\n",
      "trial: 5, iter: 1400, curr loss: 1.3850617408752441, avg loss: 1.3863745433092118\n",
      "trial: 5, iter: 1600, curr loss: 1.3873449563980103, avg loss: 1.3864065861701966\n",
      "trial: 5, iter: 1800, curr loss: 1.3864617347717285, avg loss: 1.3863573318719864\n",
      "trial: 5, iter: 2000, curr loss: 1.3860902786254883, avg loss: 1.3863646948337556\n",
      "trial: 5, iter: 2200, curr loss: 1.3858661651611328, avg loss: 1.3863085913658142\n",
      "trial: 5, iter: 2400, curr loss: 1.3857018947601318, avg loss: 1.3863937449455261\n",
      "trial: 5, iter: 2600, curr loss: 1.3867132663726807, avg loss: 1.386344277858734\n",
      "trial: 5, iter: 2800, curr loss: 1.3849365711212158, avg loss: 1.3863007378578187\n",
      "trial: 5, iter: 3000, curr loss: 1.3865113258361816, avg loss: 1.3863661533594132\n",
      "trial: 5, iter: 3200, curr loss: 1.387203574180603, avg loss: 1.3863668370246887\n",
      "trial: 5, iter: 3400, curr loss: 1.3861660957336426, avg loss: 1.3863437169790267\n",
      "trial: 5, iter: 3600, curr loss: 1.3857982158660889, avg loss: 1.3863442689180374\n",
      "trial: 5, iter: 3800, curr loss: 1.3861497640609741, avg loss: 1.386341366171837\n",
      "trial: 5, iter: 4000, curr loss: 1.386691927909851, avg loss: 1.3863336670398712\n",
      "trial: 5, iter: 4200, curr loss: 1.3860684633255005, avg loss: 1.3863230121135712\n",
      "trial: 5, iter: 4400, curr loss: 1.386395812034607, avg loss: 1.3863245683908463\n",
      "trial: 5, iter: 4600, curr loss: 1.386309027671814, avg loss: 1.3863159710168838\n",
      "trial: 5, iter: 4800, curr loss: 1.3858177661895752, avg loss: 1.38631136238575\n",
      "trial: 5, iter: 5000, curr loss: 1.3864717483520508, avg loss: 1.3862820035219192\n",
      "trial: 5, iter: 5200, curr loss: 1.3868961334228516, avg loss: 1.3863538509607316\n",
      "trial: 5, iter: 5400, curr loss: 1.3862112760543823, avg loss: 1.386310374736786\n",
      "trial: 5, iter: 5600, curr loss: 1.3861957788467407, avg loss: 1.3863013553619385\n",
      "trial: 5, iter: 5800, curr loss: 1.3864079713821411, avg loss: 1.3863122832775117\n",
      "trial: 5, iter: 6000, curr loss: 1.386240839958191, avg loss: 1.3863506615161896\n",
      "trial: 5, iter: 6200, curr loss: 1.3862049579620361, avg loss: 1.3863321447372436\n",
      "trial: 5, ldr: 0.0003850552311632782\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0006245206051971764\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3895732164382935, avg loss: 1.3874137371778488\n",
      "trial: 1, iter: 400, curr loss: 1.386116862297058, avg loss: 1.386461035013199\n",
      "trial: 1, iter: 600, curr loss: 1.387686848640442, avg loss: 1.3865615022182465\n",
      "trial: 1, iter: 800, curr loss: 1.385416030883789, avg loss: 1.386447438597679\n",
      "trial: 1, iter: 1000, curr loss: 1.3865818977355957, avg loss: 1.3864213192462922\n",
      "trial: 1, iter: 1200, curr loss: 1.3841943740844727, avg loss: 1.3865007650852204\n",
      "trial: 1, iter: 1400, curr loss: 1.3880863189697266, avg loss: 1.3864236557483673\n",
      "trial: 1, iter: 1600, curr loss: 1.3864389657974243, avg loss: 1.3864592057466507\n",
      "trial: 1, iter: 1800, curr loss: 1.3872286081314087, avg loss: 1.386370552778244\n",
      "trial: 1, iter: 2000, curr loss: 1.3860043287277222, avg loss: 1.3865486389398576\n",
      "trial: 1, iter: 2200, curr loss: 1.3856112957000732, avg loss: 1.3864846193790437\n",
      "trial: 1, iter: 2400, curr loss: 1.3871290683746338, avg loss: 1.3864276814460754\n",
      "trial: 1, iter: 2600, curr loss: 1.3859580755233765, avg loss: 1.3864189505577087\n",
      "trial: 1, iter: 2800, curr loss: 1.3865139484405518, avg loss: 1.386420887708664\n",
      "trial: 1, iter: 3000, curr loss: 1.38695228099823, avg loss: 1.3863160473108291\n",
      "trial: 1, iter: 3200, curr loss: 1.386535882949829, avg loss: 1.3863834148645402\n",
      "trial: 1, iter: 3400, curr loss: 1.3866174221038818, avg loss: 1.3863109183311462\n",
      "trial: 1, iter: 3600, curr loss: 1.3874989748001099, avg loss: 1.3864567238092422\n",
      "trial: 1, iter: 3800, curr loss: 1.386343002319336, avg loss: 1.386372971534729\n",
      "trial: 1, iter: 4000, curr loss: 1.3863651752471924, avg loss: 1.3863483184576035\n",
      "trial: 1, iter: 4200, curr loss: 1.3859500885009766, avg loss: 1.3863009124994279\n",
      "trial: 1, iter: 4400, curr loss: 1.3860185146331787, avg loss: 1.3863131648302078\n",
      "trial: 1, iter: 4600, curr loss: 1.3864597082138062, avg loss: 1.386322768330574\n",
      "trial: 1, iter: 4800, curr loss: 1.3858169317245483, avg loss: 1.386316606402397\n",
      "trial: 1, iter: 5000, curr loss: 1.38643479347229, avg loss: 1.3863298189640045\n",
      "trial: 1, iter: 5200, curr loss: 1.3862271308898926, avg loss: 1.3863176393508911\n",
      "trial: 1, iter: 5400, curr loss: 1.3858221769332886, avg loss: 1.3862893038988113\n",
      "trial: 1, iter: 5600, curr loss: 1.3858373165130615, avg loss: 1.386368595957756\n",
      "trial: 1, iter: 5800, curr loss: 1.3865793943405151, avg loss: 1.386370844244957\n",
      "trial: 1, iter: 6000, curr loss: 1.3865935802459717, avg loss: 1.3863187557458878\n",
      "trial: 1, iter: 6200, curr loss: 1.3861675262451172, avg loss: 1.3863068103790284\n",
      "trial: 1, ldr: 0.0022942782379686832\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875792026519775, avg loss: 1.3875600564479829\n",
      "trial: 2, iter: 400, curr loss: 1.3825180530548096, avg loss: 1.3867038828134537\n",
      "trial: 2, iter: 600, curr loss: 1.3859038352966309, avg loss: 1.3868542563915254\n",
      "trial: 2, iter: 800, curr loss: 1.3862059116363525, avg loss: 1.3866018152236939\n",
      "trial: 2, iter: 1000, curr loss: 1.388742208480835, avg loss: 1.386357742547989\n",
      "trial: 2, iter: 1200, curr loss: 1.3894035816192627, avg loss: 1.3864820158481599\n",
      "trial: 2, iter: 1400, curr loss: 1.3855373859405518, avg loss: 1.3865022403001785\n",
      "trial: 2, iter: 1600, curr loss: 1.3865643739700317, avg loss: 1.3864697188138961\n",
      "trial: 2, iter: 1800, curr loss: 1.387237548828125, avg loss: 1.3864390963315965\n",
      "trial: 2, iter: 2000, curr loss: 1.3868563175201416, avg loss: 1.386328517794609\n",
      "trial: 2, iter: 2200, curr loss: 1.3854647874832153, avg loss: 1.3862252056598663\n",
      "trial: 2, iter: 2400, curr loss: 1.3863890171051025, avg loss: 1.3863525259494782\n",
      "trial: 2, iter: 2600, curr loss: 1.3854565620422363, avg loss: 1.386431604027748\n",
      "trial: 2, iter: 2800, curr loss: 1.3860673904418945, avg loss: 1.3864054661989211\n",
      "trial: 2, iter: 3000, curr loss: 1.3874050378799438, avg loss: 1.386391014456749\n",
      "trial: 2, iter: 3200, curr loss: 1.3867661952972412, avg loss: 1.3863801509141922\n",
      "trial: 2, iter: 3400, curr loss: 1.3866719007492065, avg loss: 1.386335751414299\n",
      "trial: 2, iter: 3600, curr loss: 1.3863145112991333, avg loss: 1.3863389587402344\n",
      "trial: 2, iter: 3800, curr loss: 1.3868029117584229, avg loss: 1.386320264339447\n",
      "trial: 2, iter: 4000, curr loss: 1.386062502861023, avg loss: 1.3863254803419114\n",
      "trial: 2, iter: 4200, curr loss: 1.3867632150650024, avg loss: 1.3863124984502793\n",
      "trial: 2, iter: 4400, curr loss: 1.3861539363861084, avg loss: 1.386303706765175\n",
      "trial: 2, iter: 4600, curr loss: 1.3864480257034302, avg loss: 1.3863510495424272\n",
      "trial: 2, iter: 4800, curr loss: 1.3844623565673828, avg loss: 1.3863400119543074\n",
      "trial: 2, iter: 5000, curr loss: 1.386546015739441, avg loss: 1.3863982862234117\n",
      "trial: 2, iter: 5200, curr loss: 1.3860729932785034, avg loss: 1.3863743966817856\n",
      "trial: 2, iter: 5400, curr loss: 1.3869918584823608, avg loss: 1.3863929671049118\n",
      "trial: 2, iter: 5600, curr loss: 1.3860663175582886, avg loss: 1.3863288831710816\n",
      "trial: 2, iter: 5800, curr loss: 1.3865890502929688, avg loss: 1.3863814079761505\n",
      "trial: 2, iter: 6000, curr loss: 1.3860528469085693, avg loss: 1.386310293674469\n",
      "trial: 2, iter: 6200, curr loss: 1.385617971420288, avg loss: 1.3863188683986665\n",
      "trial: 2, ldr: 0.0032696372363716364\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3882451057434082, avg loss: 1.3870845144987107\n",
      "trial: 3, iter: 400, curr loss: 1.3854209184646606, avg loss: 1.3865912836790084\n",
      "trial: 3, iter: 600, curr loss: 1.3851803541183472, avg loss: 1.3866006767749786\n",
      "trial: 3, iter: 800, curr loss: 1.3863555192947388, avg loss: 1.3863835072517394\n",
      "trial: 3, iter: 1000, curr loss: 1.3869928121566772, avg loss: 1.386409676671028\n",
      "trial: 3, iter: 1200, curr loss: 1.3868818283081055, avg loss: 1.3863307094573976\n",
      "trial: 3, iter: 1400, curr loss: 1.385870099067688, avg loss: 1.3863870406150818\n",
      "trial: 3, iter: 1600, curr loss: 1.3849958181381226, avg loss: 1.386486261487007\n",
      "trial: 3, iter: 1800, curr loss: 1.3878945112228394, avg loss: 1.386466502547264\n",
      "trial: 3, iter: 2000, curr loss: 1.3845481872558594, avg loss: 1.3863581663370133\n",
      "trial: 3, iter: 2200, curr loss: 1.386481761932373, avg loss: 1.386503341794014\n",
      "trial: 3, iter: 2400, curr loss: 1.3865574598312378, avg loss: 1.3864213407039643\n",
      "trial: 3, iter: 2600, curr loss: 1.3852977752685547, avg loss: 1.386294836997986\n",
      "trial: 3, iter: 2800, curr loss: 1.386744737625122, avg loss: 1.386340451836586\n",
      "trial: 3, iter: 3000, curr loss: 1.3867216110229492, avg loss: 1.3863259422779084\n",
      "trial: 3, iter: 3200, curr loss: 1.3859747648239136, avg loss: 1.3863576024770736\n",
      "trial: 3, iter: 3400, curr loss: 1.3867242336273193, avg loss: 1.3863353538513183\n",
      "trial: 3, iter: 3600, curr loss: 1.3865067958831787, avg loss: 1.3863302224874496\n",
      "trial: 3, iter: 3800, curr loss: 1.386138916015625, avg loss: 1.3862930262088775\n",
      "trial: 3, iter: 4000, curr loss: 1.384637713432312, avg loss: 1.3863052582740785\n",
      "trial: 3, iter: 4200, curr loss: 1.3868671655654907, avg loss: 1.3863763386011123\n",
      "trial: 3, iter: 4400, curr loss: 1.385959506034851, avg loss: 1.3863671958446502\n",
      "trial: 3, iter: 4600, curr loss: 1.3861585855484009, avg loss: 1.3863346058130264\n",
      "trial: 3, iter: 4800, curr loss: 1.3860368728637695, avg loss: 1.3863134109973907\n",
      "trial: 3, iter: 5000, curr loss: 1.3864513635635376, avg loss: 1.3863243126869202\n",
      "trial: 3, iter: 5200, curr loss: 1.3862000703811646, avg loss: 1.3863256764411926\n",
      "trial: 3, iter: 5400, curr loss: 1.386289358139038, avg loss: 1.3863197946548462\n",
      "trial: 3, iter: 5600, curr loss: 1.3861072063446045, avg loss: 1.3862777900695802\n",
      "trial: 3, iter: 5800, curr loss: 1.3883665800094604, avg loss: 1.386260023713112\n",
      "trial: 3, iter: 6000, curr loss: 1.3867332935333252, avg loss: 1.386333359479904\n",
      "trial: 3, iter: 6200, curr loss: 1.3865982294082642, avg loss: 1.386308119893074\n",
      "trial: 3, ldr: -0.001917854300700128\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3878240585327148, avg loss: 1.3875333315134049\n",
      "trial: 4, iter: 400, curr loss: 1.389269471168518, avg loss: 1.3866601705551147\n",
      "trial: 4, iter: 600, curr loss: 1.387218713760376, avg loss: 1.386488173007965\n",
      "trial: 4, iter: 800, curr loss: 1.3882478475570679, avg loss: 1.3865290874242782\n",
      "trial: 4, iter: 1000, curr loss: 1.3858777284622192, avg loss: 1.3865126341581344\n",
      "trial: 4, iter: 1200, curr loss: 1.3864662647247314, avg loss: 1.3864249032735825\n",
      "trial: 4, iter: 1400, curr loss: 1.3849947452545166, avg loss: 1.3864698219299316\n",
      "trial: 4, iter: 1600, curr loss: 1.3863216638565063, avg loss: 1.386420760154724\n",
      "trial: 4, iter: 1800, curr loss: 1.3859895467758179, avg loss: 1.3863624960184098\n",
      "trial: 4, iter: 2000, curr loss: 1.386418342590332, avg loss: 1.3864180648326874\n",
      "trial: 4, iter: 2200, curr loss: 1.3860986232757568, avg loss: 1.386397870182991\n",
      "trial: 4, iter: 2400, curr loss: 1.3855520486831665, avg loss: 1.3863158816099166\n",
      "trial: 4, iter: 2600, curr loss: 1.3866817951202393, avg loss: 1.3863429993391037\n",
      "trial: 4, iter: 2800, curr loss: 1.3870939016342163, avg loss: 1.386381464600563\n",
      "trial: 4, iter: 3000, curr loss: 1.3866456747055054, avg loss: 1.3864230412244796\n",
      "trial: 4, iter: 3200, curr loss: 1.385836124420166, avg loss: 1.3863394337892532\n",
      "trial: 4, iter: 3400, curr loss: 1.3856279850006104, avg loss: 1.3863132655620576\n",
      "trial: 4, iter: 3600, curr loss: 1.386063575744629, avg loss: 1.386380700469017\n",
      "trial: 4, iter: 3800, curr loss: 1.3855857849121094, avg loss: 1.3862892335653305\n",
      "trial: 4, iter: 4000, curr loss: 1.386610507965088, avg loss: 1.386329223513603\n",
      "trial: 4, iter: 4200, curr loss: 1.385491967201233, avg loss: 1.386381782889366\n",
      "trial: 4, iter: 4400, curr loss: 1.3861809968948364, avg loss: 1.3863491982221603\n",
      "trial: 4, iter: 4600, curr loss: 1.3859459161758423, avg loss: 1.386314151287079\n",
      "trial: 4, iter: 4800, curr loss: 1.3873646259307861, avg loss: 1.3863072556257248\n",
      "trial: 4, iter: 5000, curr loss: 1.3861597776412964, avg loss: 1.3863683480024338\n",
      "trial: 4, iter: 5200, curr loss: 1.3853495121002197, avg loss: 1.3863199877738952\n",
      "trial: 4, iter: 5400, curr loss: 1.3860809803009033, avg loss: 1.3863940060138702\n",
      "trial: 4, iter: 5600, curr loss: 1.3870127201080322, avg loss: 1.3863274073600769\n",
      "trial: 4, iter: 5800, curr loss: 1.3860859870910645, avg loss: 1.3863328063488007\n",
      "trial: 4, iter: 6000, curr loss: 1.3861714601516724, avg loss: 1.3863420617580413\n",
      "trial: 4, iter: 6200, curr loss: 1.3862451314926147, avg loss: 1.3863085401058197\n",
      "trial: 4, ldr: -0.0031158176716417074\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3862192630767822, avg loss: 1.3873246484994888\n",
      "trial: 5, iter: 400, curr loss: 1.388427495956421, avg loss: 1.3866891938447952\n",
      "trial: 5, iter: 600, curr loss: 1.385704517364502, avg loss: 1.38660205245018\n",
      "trial: 5, iter: 800, curr loss: 1.3872590065002441, avg loss: 1.3865325099229813\n",
      "trial: 5, iter: 1000, curr loss: 1.38692307472229, avg loss: 1.3865066963434218\n",
      "trial: 5, iter: 1200, curr loss: 1.3882015943527222, avg loss: 1.3864137560129166\n",
      "trial: 5, iter: 1400, curr loss: 1.3854529857635498, avg loss: 1.3863499999046325\n",
      "trial: 5, iter: 1600, curr loss: 1.3860746622085571, avg loss: 1.3864343130588532\n",
      "trial: 5, iter: 1800, curr loss: 1.3854798078536987, avg loss: 1.3863773214817048\n",
      "trial: 5, iter: 2000, curr loss: 1.3870240449905396, avg loss: 1.386370343565941\n",
      "trial: 5, iter: 2200, curr loss: 1.3862022161483765, avg loss: 1.3863798236846925\n",
      "trial: 5, iter: 2400, curr loss: 1.3862985372543335, avg loss: 1.3863668131828308\n",
      "trial: 5, iter: 2600, curr loss: 1.3856935501098633, avg loss: 1.3863445830345154\n",
      "trial: 5, iter: 2800, curr loss: 1.3856710195541382, avg loss: 1.3863405698537827\n",
      "trial: 5, iter: 3000, curr loss: 1.3860586881637573, avg loss: 1.386322442293167\n",
      "trial: 5, iter: 3200, curr loss: 1.3867219686508179, avg loss: 1.3863433253765107\n",
      "trial: 5, iter: 3400, curr loss: 1.3856958150863647, avg loss: 1.3862993329763413\n",
      "trial: 5, iter: 3600, curr loss: 1.386700987815857, avg loss: 1.3864347153902055\n",
      "trial: 5, iter: 3800, curr loss: 1.388086199760437, avg loss: 1.3862350368499756\n",
      "trial: 5, iter: 4000, curr loss: 1.3864598274230957, avg loss: 1.3864461654424667\n",
      "trial: 5, iter: 4200, curr loss: 1.3860400915145874, avg loss: 1.3863959950208664\n",
      "trial: 5, iter: 4400, curr loss: 1.3867261409759521, avg loss: 1.3863499653339386\n",
      "trial: 5, iter: 4600, curr loss: 1.386970043182373, avg loss: 1.3862826240062713\n",
      "trial: 5, iter: 4800, curr loss: 1.386294960975647, avg loss: 1.3863466084003448\n",
      "trial: 5, iter: 5000, curr loss: 1.3861225843429565, avg loss: 1.3863401919603349\n",
      "trial: 5, iter: 5200, curr loss: 1.3858312368392944, avg loss: 1.3863067525625228\n",
      "trial: 5, iter: 5400, curr loss: 1.3886253833770752, avg loss: 1.3863456761837005\n",
      "trial: 5, iter: 5600, curr loss: 1.3864613771438599, avg loss: 1.3864079678058625\n",
      "trial: 5, iter: 5800, curr loss: 1.385690689086914, avg loss: 1.3864149898290634\n",
      "trial: 5, iter: 6000, curr loss: 1.386744737625122, avg loss: 1.3863236618041992\n",
      "trial: 5, iter: 6200, curr loss: 1.3862134218215942, avg loss: 1.386313025355339\n",
      "trial: 5, ldr: -0.012077156454324722\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0023093825904652475\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3874938488006592, avg loss: 1.3874800634384155\n",
      "trial: 1, iter: 400, curr loss: 1.389386534690857, avg loss: 1.3865345013141632\n",
      "trial: 1, iter: 600, curr loss: 1.3861384391784668, avg loss: 1.3866439473628998\n",
      "trial: 1, iter: 800, curr loss: 1.3856390714645386, avg loss: 1.3863657730817796\n",
      "trial: 1, iter: 1000, curr loss: 1.384953260421753, avg loss: 1.3864428889751435\n",
      "trial: 1, iter: 1200, curr loss: 1.3862155675888062, avg loss: 1.3863266152143479\n",
      "trial: 1, iter: 1400, curr loss: 1.3866688013076782, avg loss: 1.3864581030607224\n",
      "trial: 1, iter: 1600, curr loss: 1.3877501487731934, avg loss: 1.3863674426078796\n",
      "trial: 1, iter: 1800, curr loss: 1.385556697845459, avg loss: 1.3862277430295944\n",
      "trial: 1, iter: 2000, curr loss: 1.3844685554504395, avg loss: 1.386536346077919\n",
      "trial: 1, iter: 2200, curr loss: 1.3868393898010254, avg loss: 1.3863998705148697\n",
      "trial: 1, iter: 2400, curr loss: 1.3862509727478027, avg loss: 1.3863622325658798\n",
      "trial: 1, iter: 2600, curr loss: 1.3858063220977783, avg loss: 1.3863949573040009\n",
      "trial: 1, iter: 2800, curr loss: 1.3865001201629639, avg loss: 1.3863425648212433\n",
      "trial: 1, iter: 3000, curr loss: 1.3859609365463257, avg loss: 1.3863597863912582\n",
      "trial: 1, iter: 3200, curr loss: 1.3865370750427246, avg loss: 1.3863871395587921\n",
      "trial: 1, iter: 3400, curr loss: 1.3863396644592285, avg loss: 1.3862960231304169\n",
      "trial: 1, iter: 3600, curr loss: 1.3865453004837036, avg loss: 1.3863487869501114\n",
      "trial: 1, iter: 3800, curr loss: 1.3873566389083862, avg loss: 1.3863015043735505\n",
      "trial: 1, iter: 4000, curr loss: 1.3859999179840088, avg loss: 1.3863090145587922\n",
      "trial: 1, iter: 4200, curr loss: 1.3860758543014526, avg loss: 1.3863265120983124\n",
      "trial: 1, iter: 4400, curr loss: 1.3859643936157227, avg loss: 1.3863117271661758\n",
      "trial: 1, iter: 4600, curr loss: 1.3862193822860718, avg loss: 1.3862877631187438\n",
      "trial: 1, iter: 4800, curr loss: 1.3864860534667969, avg loss: 1.3863072556257248\n",
      "trial: 1, iter: 5000, curr loss: 1.3866209983825684, avg loss: 1.3863737320899963\n",
      "trial: 1, iter: 5200, curr loss: 1.3853474855422974, avg loss: 1.386309221982956\n",
      "trial: 1, iter: 5400, curr loss: 1.3855526447296143, avg loss: 1.386303922533989\n",
      "trial: 1, iter: 5600, curr loss: 1.3860054016113281, avg loss: 1.3863380551338196\n",
      "trial: 1, iter: 5800, curr loss: 1.3865679502487183, avg loss: 1.3863509327173233\n",
      "trial: 1, iter: 6000, curr loss: 1.3866381645202637, avg loss: 1.3863230627775192\n",
      "trial: 1, iter: 6200, curr loss: 1.3857858180999756, avg loss: 1.3863334959745408\n",
      "trial: 1, ldr: 0.009681041352450848\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866046667099, avg loss: 1.3874973636865615\n",
      "trial: 2, iter: 400, curr loss: 1.387952446937561, avg loss: 1.3868082296848296\n",
      "trial: 2, iter: 600, curr loss: 1.3849931955337524, avg loss: 1.3867070257663727\n",
      "trial: 2, iter: 800, curr loss: 1.3863716125488281, avg loss: 1.386698847413063\n",
      "trial: 2, iter: 1000, curr loss: 1.3871145248413086, avg loss: 1.3865013080835342\n",
      "trial: 2, iter: 1200, curr loss: 1.3863528966903687, avg loss: 1.3865155577659607\n",
      "trial: 2, iter: 1400, curr loss: 1.3872495889663696, avg loss: 1.38635849237442\n",
      "trial: 2, iter: 1600, curr loss: 1.385707974433899, avg loss: 1.3864600795507431\n",
      "trial: 2, iter: 1800, curr loss: 1.3862576484680176, avg loss: 1.3864137083292007\n",
      "trial: 2, iter: 2000, curr loss: 1.3860071897506714, avg loss: 1.386383803486824\n",
      "trial: 2, iter: 2200, curr loss: 1.3868342638015747, avg loss: 1.3864091926813125\n",
      "trial: 2, iter: 2400, curr loss: 1.3864954710006714, avg loss: 1.3864107465744018\n",
      "trial: 2, iter: 2600, curr loss: 1.386382818222046, avg loss: 1.3864214384555817\n",
      "trial: 2, iter: 2800, curr loss: 1.3866299390792847, avg loss: 1.3863448053598404\n",
      "trial: 2, iter: 3000, curr loss: 1.3872452974319458, avg loss: 1.386357477903366\n",
      "trial: 2, iter: 3200, curr loss: 1.3860137462615967, avg loss: 1.3863974159955978\n",
      "trial: 2, iter: 3400, curr loss: 1.386347770690918, avg loss: 1.3863332927227021\n",
      "trial: 2, iter: 3600, curr loss: 1.386795997619629, avg loss: 1.3863442409038544\n",
      "trial: 2, iter: 3800, curr loss: 1.3881433010101318, avg loss: 1.3863581311702728\n",
      "trial: 2, iter: 4000, curr loss: 1.3871973752975464, avg loss: 1.3863289749622345\n",
      "trial: 2, iter: 4200, curr loss: 1.3858734369277954, avg loss: 1.386377763748169\n",
      "trial: 2, iter: 4400, curr loss: 1.3864519596099854, avg loss: 1.3863162416219712\n",
      "trial: 2, iter: 4600, curr loss: 1.3866130113601685, avg loss: 1.3864503347873687\n",
      "trial: 2, iter: 4800, curr loss: 1.3854756355285645, avg loss: 1.3863180363178254\n",
      "trial: 2, iter: 5000, curr loss: 1.3859769105911255, avg loss: 1.3863403195142745\n",
      "trial: 2, iter: 5200, curr loss: 1.386167287826538, avg loss: 1.3863341736793517\n",
      "trial: 2, iter: 5400, curr loss: 1.3850924968719482, avg loss: 1.386354393362999\n",
      "trial: 2, iter: 5600, curr loss: 1.38611900806427, avg loss: 1.3864916849136353\n",
      "trial: 2, iter: 5800, curr loss: 1.3872239589691162, avg loss: 1.3863602471351624\n",
      "trial: 2, iter: 6000, curr loss: 1.3860752582550049, avg loss: 1.3863353276252746\n",
      "trial: 2, iter: 6200, curr loss: 1.3866832256317139, avg loss: 1.3863357782363892\n",
      "trial: 2, ldr: 0.008812562562525272\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3851908445358276, avg loss: 1.3870699441432952\n",
      "trial: 3, iter: 400, curr loss: 1.3849828243255615, avg loss: 1.38678551197052\n",
      "trial: 3, iter: 600, curr loss: 1.3853384256362915, avg loss: 1.3864446705579758\n",
      "trial: 3, iter: 800, curr loss: 1.3852596282958984, avg loss: 1.386543598175049\n",
      "trial: 3, iter: 1000, curr loss: 1.3849903345108032, avg loss: 1.3864939922094346\n",
      "trial: 3, iter: 1200, curr loss: 1.3859353065490723, avg loss: 1.3863655936717987\n",
      "trial: 3, iter: 1400, curr loss: 1.3857216835021973, avg loss: 1.3863933491706848\n",
      "trial: 3, iter: 1600, curr loss: 1.3863383531570435, avg loss: 1.386707209944725\n",
      "trial: 3, iter: 1800, curr loss: 1.3868014812469482, avg loss: 1.3864152008295059\n",
      "trial: 3, iter: 2000, curr loss: 1.3857765197753906, avg loss: 1.386352396607399\n",
      "trial: 3, iter: 2200, curr loss: 1.387924075126648, avg loss: 1.3863546717166901\n",
      "trial: 3, iter: 2400, curr loss: 1.3863821029663086, avg loss: 1.3863905620574952\n",
      "trial: 3, iter: 2600, curr loss: 1.3861976861953735, avg loss: 1.3863437169790267\n",
      "trial: 3, iter: 2800, curr loss: 1.3868428468704224, avg loss: 1.3863103425502776\n",
      "trial: 3, iter: 3000, curr loss: 1.3864545822143555, avg loss: 1.3863387876749038\n",
      "trial: 3, iter: 3200, curr loss: 1.3857043981552124, avg loss: 1.386300613284111\n",
      "trial: 3, iter: 3400, curr loss: 1.386475920677185, avg loss: 1.38638349711895\n",
      "trial: 3, iter: 3600, curr loss: 1.386441946029663, avg loss: 1.386349766254425\n",
      "trial: 3, iter: 3800, curr loss: 1.3860830068588257, avg loss: 1.3863455319404603\n",
      "trial: 3, iter: 4000, curr loss: 1.3859400749206543, avg loss: 1.3863411980867386\n",
      "trial: 3, iter: 4200, curr loss: 1.3864318132400513, avg loss: 1.3863179683685303\n",
      "trial: 3, iter: 4400, curr loss: 1.386393666267395, avg loss: 1.3863492488861084\n",
      "trial: 3, iter: 4600, curr loss: 1.3861812353134155, avg loss: 1.3863902646303177\n",
      "trial: 3, iter: 4800, curr loss: 1.3850133419036865, avg loss: 1.3862911242246627\n",
      "trial: 3, iter: 5000, curr loss: 1.387302041053772, avg loss: 1.386354529261589\n",
      "trial: 3, iter: 5200, curr loss: 1.3864647150039673, avg loss: 1.3864129889011383\n",
      "trial: 3, iter: 5400, curr loss: 1.3858230113983154, avg loss: 1.3862952780723572\n",
      "trial: 3, iter: 5600, curr loss: 1.3861886262893677, avg loss: 1.386339285969734\n",
      "trial: 3, iter: 5800, curr loss: 1.3860931396484375, avg loss: 1.3863038671016694\n",
      "trial: 3, iter: 6000, curr loss: 1.38638436794281, avg loss: 1.3863897305727004\n",
      "trial: 3, iter: 6200, curr loss: 1.3865259885787964, avg loss: 1.386350108385086\n",
      "trial: 3, ldr: -0.0036849137395620346\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838977813720703, avg loss: 1.387200161218643\n",
      "trial: 4, iter: 400, curr loss: 1.3869364261627197, avg loss: 1.3868230080604553\n",
      "trial: 4, iter: 600, curr loss: 1.3855831623077393, avg loss: 1.3866060709953307\n",
      "trial: 4, iter: 800, curr loss: 1.3851585388183594, avg loss: 1.3865597337484359\n",
      "trial: 4, iter: 1000, curr loss: 1.3869502544403076, avg loss: 1.3865178126096724\n",
      "trial: 4, iter: 1200, curr loss: 1.385885238647461, avg loss: 1.3864196026325226\n",
      "trial: 4, iter: 1400, curr loss: 1.3874149322509766, avg loss: 1.38642143368721\n",
      "trial: 4, iter: 1600, curr loss: 1.3855698108673096, avg loss: 1.3864281004667283\n",
      "trial: 4, iter: 1800, curr loss: 1.3866119384765625, avg loss: 1.3864183610677718\n",
      "trial: 4, iter: 2000, curr loss: 1.3852468729019165, avg loss: 1.3863974767923355\n",
      "trial: 4, iter: 2200, curr loss: 1.3864543437957764, avg loss: 1.3863991528749466\n",
      "trial: 4, iter: 2400, curr loss: 1.385907530784607, avg loss: 1.386338824033737\n",
      "trial: 4, iter: 2600, curr loss: 1.3868812322616577, avg loss: 1.3863804650306701\n",
      "trial: 4, iter: 2800, curr loss: 1.3859204053878784, avg loss: 1.3863143861293792\n",
      "trial: 4, iter: 3000, curr loss: 1.3864752054214478, avg loss: 1.3863978350162507\n",
      "trial: 4, iter: 3200, curr loss: 1.3860429525375366, avg loss: 1.386325844526291\n",
      "trial: 4, iter: 3400, curr loss: 1.3868199586868286, avg loss: 1.386325604915619\n",
      "trial: 4, iter: 3600, curr loss: 1.3879621028900146, avg loss: 1.3863026666641236\n",
      "trial: 4, iter: 3800, curr loss: 1.3863921165466309, avg loss: 1.3863352590799332\n",
      "trial: 4, iter: 4000, curr loss: 1.3861026763916016, avg loss: 1.3863716799020767\n",
      "trial: 4, iter: 4200, curr loss: 1.3867309093475342, avg loss: 1.386321138739586\n",
      "trial: 4, iter: 4400, curr loss: 1.386549711227417, avg loss: 1.386309296488762\n",
      "trial: 4, iter: 4600, curr loss: 1.3866302967071533, avg loss: 1.3863430446386338\n",
      "trial: 4, iter: 4800, curr loss: 1.3866658210754395, avg loss: 1.3863312923908233\n",
      "trial: 4, iter: 5000, curr loss: 1.385453224182129, avg loss: 1.3863208454847336\n",
      "trial: 4, iter: 5200, curr loss: 1.3867586851119995, avg loss: 1.3863564103841781\n",
      "trial: 4, iter: 5400, curr loss: 1.3863120079040527, avg loss: 1.386340919137001\n",
      "trial: 4, iter: 5600, curr loss: 1.3866326808929443, avg loss: 1.386313424706459\n",
      "trial: 4, iter: 5800, curr loss: 1.3862954378128052, avg loss: 1.3863138645887374\n",
      "trial: 4, iter: 6000, curr loss: 1.3862484693527222, avg loss: 1.3862755870819092\n",
      "trial: 4, iter: 6200, curr loss: 1.3859115839004517, avg loss: 1.3863128328323364\n",
      "trial: 4, ldr: -0.004417994525283575\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3869813680648804, avg loss: 1.3874227279424667\n",
      "trial: 5, iter: 400, curr loss: 1.3885447978973389, avg loss: 1.3865769571065902\n",
      "trial: 5, iter: 600, curr loss: 1.3828749656677246, avg loss: 1.3866762465238571\n",
      "trial: 5, iter: 800, curr loss: 1.3881198167800903, avg loss: 1.3864344567060471\n",
      "trial: 5, iter: 1000, curr loss: 1.3858612775802612, avg loss: 1.3862822598218918\n",
      "trial: 5, iter: 1200, curr loss: 1.38567316532135, avg loss: 1.3863839143514634\n",
      "trial: 5, iter: 1400, curr loss: 1.386523723602295, avg loss: 1.3863337910175324\n",
      "trial: 5, iter: 1600, curr loss: 1.3863482475280762, avg loss: 1.3864642441272736\n",
      "trial: 5, iter: 1800, curr loss: 1.3861507177352905, avg loss: 1.3864044058322906\n",
      "trial: 5, iter: 2000, curr loss: 1.386539101600647, avg loss: 1.386369281411171\n",
      "trial: 5, iter: 2200, curr loss: 1.386167287826538, avg loss: 1.386400328874588\n",
      "trial: 5, iter: 2400, curr loss: 1.3861685991287231, avg loss: 1.3863454151153565\n",
      "trial: 5, iter: 2600, curr loss: 1.3863502740859985, avg loss: 1.3863323146104813\n",
      "trial: 5, iter: 2800, curr loss: 1.3865331411361694, avg loss: 1.3863259363174438\n",
      "trial: 5, iter: 3000, curr loss: 1.3856955766677856, avg loss: 1.3863252103328705\n",
      "trial: 5, iter: 3200, curr loss: 1.3861618041992188, avg loss: 1.3863888615369797\n",
      "trial: 5, iter: 3400, curr loss: 1.3866711854934692, avg loss: 1.3863589322566987\n",
      "trial: 5, iter: 3600, curr loss: 1.3865972757339478, avg loss: 1.3863478326797485\n",
      "trial: 5, iter: 3800, curr loss: 1.3864995241165161, avg loss: 1.3863675689697266\n",
      "trial: 5, iter: 4000, curr loss: 1.3862162828445435, avg loss: 1.386362727880478\n",
      "trial: 5, iter: 4200, curr loss: 1.3866217136383057, avg loss: 1.386335916519165\n",
      "trial: 5, iter: 4400, curr loss: 1.3856576681137085, avg loss: 1.38629858314991\n",
      "trial: 5, iter: 4600, curr loss: 1.385087251663208, avg loss: 1.38631303191185\n",
      "trial: 5, iter: 4800, curr loss: 1.3862472772598267, avg loss: 1.3863736015558243\n",
      "trial: 5, iter: 5000, curr loss: 1.386273741722107, avg loss: 1.3863268584012984\n",
      "trial: 5, iter: 5200, curr loss: 1.386209487915039, avg loss: 1.3863152545690536\n",
      "trial: 5, iter: 5400, curr loss: 1.3866316080093384, avg loss: 1.3863328403234483\n",
      "trial: 5, iter: 5600, curr loss: 1.3863917589187622, avg loss: 1.3863294994831086\n",
      "trial: 5, iter: 5800, curr loss: 1.386476755142212, avg loss: 1.386343258023262\n",
      "trial: 5, iter: 6000, curr loss: 1.386256456375122, avg loss: 1.3863357704877854\n",
      "trial: 5, iter: 6200, curr loss: 1.386344313621521, avg loss: 1.3863106673955918\n",
      "trial: 5, ldr: -0.0022179107181727886\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0016345569863915443\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3910691738128662, avg loss: 1.3875363790988922\n",
      "trial: 1, iter: 400, curr loss: 1.3867348432540894, avg loss: 1.3866851782798768\n",
      "trial: 1, iter: 600, curr loss: 1.3873262405395508, avg loss: 1.3865188175439835\n",
      "trial: 1, iter: 800, curr loss: 1.3886356353759766, avg loss: 1.3865226632356644\n",
      "trial: 1, iter: 1000, curr loss: 1.3854583501815796, avg loss: 1.3865373480319976\n",
      "trial: 1, iter: 1200, curr loss: 1.3863166570663452, avg loss: 1.3863001227378846\n",
      "trial: 1, iter: 1400, curr loss: 1.3874249458312988, avg loss: 1.3864872533082961\n",
      "trial: 1, iter: 1600, curr loss: 1.3875036239624023, avg loss: 1.3864173591136932\n",
      "trial: 1, iter: 1800, curr loss: 1.3861981630325317, avg loss: 1.3863744401931763\n",
      "trial: 1, iter: 2000, curr loss: 1.3862946033477783, avg loss: 1.3863770580291748\n",
      "trial: 1, iter: 2200, curr loss: 1.3859848976135254, avg loss: 1.386359425187111\n",
      "trial: 1, iter: 2400, curr loss: 1.3857697248458862, avg loss: 1.3864003121852875\n",
      "trial: 1, iter: 2600, curr loss: 1.385151982307434, avg loss: 1.3863273882865905\n",
      "trial: 1, iter: 2800, curr loss: 1.3864401578903198, avg loss: 1.3863476425409318\n",
      "trial: 1, iter: 3000, curr loss: 1.3856549263000488, avg loss: 1.3863544005155564\n",
      "trial: 1, iter: 3200, curr loss: 1.3859952688217163, avg loss: 1.3863852536678314\n",
      "trial: 1, iter: 3400, curr loss: 1.3865331411361694, avg loss: 1.3863679230213166\n",
      "trial: 1, iter: 3600, curr loss: 1.3865931034088135, avg loss: 1.38635326564312\n",
      "trial: 1, iter: 3800, curr loss: 1.3861618041992188, avg loss: 1.38632273375988\n",
      "trial: 1, iter: 4000, curr loss: 1.3869833946228027, avg loss: 1.386311776638031\n",
      "trial: 1, iter: 4200, curr loss: 1.3863075971603394, avg loss: 1.386340430378914\n",
      "trial: 1, iter: 4400, curr loss: 1.38851797580719, avg loss: 1.3863532608747482\n",
      "trial: 1, iter: 4600, curr loss: 1.3867828845977783, avg loss: 1.3863906264305115\n",
      "trial: 1, iter: 4800, curr loss: 1.385783314704895, avg loss: 1.3863120889663696\n",
      "trial: 1, iter: 5000, curr loss: 1.386040210723877, avg loss: 1.386310180425644\n",
      "trial: 1, iter: 5200, curr loss: 1.386903166770935, avg loss: 1.3863467860221863\n",
      "trial: 1, iter: 5400, curr loss: 1.3859691619873047, avg loss: 1.3863311052322387\n",
      "trial: 1, iter: 5600, curr loss: 1.3859738111495972, avg loss: 1.3863393151760102\n",
      "trial: 1, iter: 5800, curr loss: 1.3861899375915527, avg loss: 1.3862843549251556\n",
      "trial: 1, iter: 6000, curr loss: 1.3875958919525146, avg loss: 1.38631656229496\n",
      "trial: 1, iter: 6200, curr loss: 1.3871519565582275, avg loss: 1.3863484239578248\n",
      "trial: 1, ldr: -0.020696081221103668\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3877999782562256, avg loss: 1.3872533655166626\n",
      "trial: 2, iter: 400, curr loss: 1.387791395187378, avg loss: 1.3866020107269288\n",
      "trial: 2, iter: 600, curr loss: 1.3867591619491577, avg loss: 1.386787474155426\n",
      "trial: 2, iter: 800, curr loss: 1.3851529359817505, avg loss: 1.3866487121582032\n",
      "trial: 2, iter: 1000, curr loss: 1.3877202272415161, avg loss: 1.3865019077062606\n",
      "trial: 2, iter: 1200, curr loss: 1.386437177658081, avg loss: 1.3864956283569336\n",
      "trial: 2, iter: 1400, curr loss: 1.3852059841156006, avg loss: 1.3863585716485978\n",
      "trial: 2, iter: 1600, curr loss: 1.3870563507080078, avg loss: 1.3864190977811814\n",
      "trial: 2, iter: 1800, curr loss: 1.3867758512496948, avg loss: 1.3863947159051895\n",
      "trial: 2, iter: 2000, curr loss: 1.3870811462402344, avg loss: 1.3864857828617096\n",
      "trial: 2, iter: 2200, curr loss: 1.385184407234192, avg loss: 1.3863226473331451\n",
      "trial: 2, iter: 2400, curr loss: 1.3873716592788696, avg loss: 1.3864311897754669\n",
      "trial: 2, iter: 2600, curr loss: 1.3861078023910522, avg loss: 1.3864107930660248\n",
      "trial: 2, iter: 2800, curr loss: 1.386987566947937, avg loss: 1.386402084827423\n",
      "trial: 2, iter: 3000, curr loss: 1.387283205986023, avg loss: 1.386352730989456\n",
      "trial: 2, iter: 3200, curr loss: 1.387161374092102, avg loss: 1.3864028304815292\n",
      "trial: 2, iter: 3400, curr loss: 1.3870893716812134, avg loss: 1.3863473641872406\n",
      "trial: 2, iter: 3600, curr loss: 1.3862042427062988, avg loss: 1.3863393610715866\n",
      "trial: 2, iter: 3800, curr loss: 1.3866842985153198, avg loss: 1.3863148993253709\n",
      "trial: 2, iter: 4000, curr loss: 1.3864431381225586, avg loss: 1.386299034357071\n",
      "trial: 2, iter: 4200, curr loss: 1.3864086866378784, avg loss: 1.3863536179065705\n",
      "trial: 2, iter: 4400, curr loss: 1.3866355419158936, avg loss: 1.3863161140680313\n",
      "trial: 2, iter: 4600, curr loss: 1.387034296989441, avg loss: 1.3863072192668915\n",
      "trial: 2, iter: 4800, curr loss: 1.3873107433319092, avg loss: 1.3863562619686127\n",
      "trial: 2, iter: 5000, curr loss: 1.386317491531372, avg loss: 1.3863390040397645\n",
      "trial: 2, iter: 5200, curr loss: 1.3864264488220215, avg loss: 1.3863718408346175\n",
      "trial: 2, iter: 5400, curr loss: 1.3866642713546753, avg loss: 1.3863093876838684\n",
      "trial: 2, iter: 5600, curr loss: 1.3861403465270996, avg loss: 1.3862729716300963\n",
      "trial: 2, iter: 5800, curr loss: 1.3863976001739502, avg loss: 1.3863512229919435\n",
      "trial: 2, iter: 6000, curr loss: 1.386339783668518, avg loss: 1.3863307380676269\n",
      "trial: 2, iter: 6200, curr loss: 1.3861730098724365, avg loss: 1.3863180321455002\n",
      "trial: 2, ldr: 0.001498577301390469\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3870333433151245, avg loss: 1.3873507577180861\n",
      "trial: 3, iter: 400, curr loss: 1.384626030921936, avg loss: 1.3867578077316285\n",
      "trial: 3, iter: 600, curr loss: 1.3856608867645264, avg loss: 1.3866013610363006\n",
      "trial: 3, iter: 800, curr loss: 1.387355923652649, avg loss: 1.3863922828435897\n",
      "trial: 3, iter: 1000, curr loss: 1.3856749534606934, avg loss: 1.3864255410432815\n",
      "trial: 3, iter: 1200, curr loss: 1.3852412700653076, avg loss: 1.3865043008327484\n",
      "trial: 3, iter: 1400, curr loss: 1.386866569519043, avg loss: 1.3863544976711273\n",
      "trial: 3, iter: 1600, curr loss: 1.386527180671692, avg loss: 1.3864359170198441\n",
      "trial: 3, iter: 1800, curr loss: 1.3878365755081177, avg loss: 1.3863630068302155\n",
      "trial: 3, iter: 2000, curr loss: 1.38595712184906, avg loss: 1.3863436383008958\n",
      "trial: 3, iter: 2200, curr loss: 1.3862320184707642, avg loss: 1.3863717687129975\n",
      "trial: 3, iter: 2400, curr loss: 1.3854687213897705, avg loss: 1.386346874833107\n",
      "trial: 3, iter: 2600, curr loss: 1.385805606842041, avg loss: 1.3863817816972732\n",
      "trial: 3, iter: 2800, curr loss: 1.3851420879364014, avg loss: 1.3863227820396424\n",
      "trial: 3, iter: 3000, curr loss: 1.385398268699646, avg loss: 1.386408795118332\n",
      "trial: 3, iter: 3200, curr loss: 1.3852474689483643, avg loss: 1.386332524418831\n",
      "trial: 3, iter: 3400, curr loss: 1.3866440057754517, avg loss: 1.3863308417797089\n",
      "trial: 3, iter: 3600, curr loss: 1.3859634399414062, avg loss: 1.3863928627967834\n",
      "trial: 3, iter: 3800, curr loss: 1.386340618133545, avg loss: 1.386352195739746\n",
      "trial: 3, iter: 4000, curr loss: 1.3867366313934326, avg loss: 1.3863300466537476\n",
      "trial: 3, iter: 4200, curr loss: 1.3862195014953613, avg loss: 1.3863503330945968\n",
      "trial: 3, iter: 4400, curr loss: 1.3864078521728516, avg loss: 1.3863319647312164\n",
      "trial: 3, iter: 4600, curr loss: 1.3864796161651611, avg loss: 1.3862954181432725\n",
      "trial: 3, iter: 4800, curr loss: 1.3864428997039795, avg loss: 1.3863334572315216\n",
      "trial: 3, iter: 5000, curr loss: 1.3869184255599976, avg loss: 1.3863501095771789\n",
      "trial: 3, iter: 5200, curr loss: 1.3864655494689941, avg loss: 1.3862751495838166\n",
      "trial: 3, iter: 5400, curr loss: 1.385956883430481, avg loss: 1.386377790570259\n",
      "trial: 3, iter: 5600, curr loss: 1.3864935636520386, avg loss: 1.386343340277672\n",
      "trial: 3, iter: 5800, curr loss: 1.3865199089050293, avg loss: 1.3863250601291657\n",
      "trial: 3, iter: 6000, curr loss: 1.3864175081253052, avg loss: 1.3862952196598053\n",
      "trial: 3, iter: 6200, curr loss: 1.3863111734390259, avg loss: 1.3863384270668029\n",
      "trial: 3, ldr: 0.0005213472177274525\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388463020324707, avg loss: 1.387434788942337\n",
      "trial: 4, iter: 400, curr loss: 1.3869147300720215, avg loss: 1.3866867524385453\n",
      "trial: 4, iter: 600, curr loss: 1.3863918781280518, avg loss: 1.386630557179451\n",
      "trial: 4, iter: 800, curr loss: 1.3860541582107544, avg loss: 1.386511554121971\n",
      "trial: 4, iter: 1000, curr loss: 1.3863855600357056, avg loss: 1.3863947409391404\n",
      "trial: 4, iter: 1200, curr loss: 1.3870344161987305, avg loss: 1.3863407051563263\n",
      "trial: 4, iter: 1400, curr loss: 1.3861010074615479, avg loss: 1.3863412702083588\n",
      "trial: 4, iter: 1600, curr loss: 1.3871033191680908, avg loss: 1.3863274693489074\n",
      "trial: 4, iter: 1800, curr loss: 1.3870794773101807, avg loss: 1.386236634850502\n",
      "trial: 4, iter: 2000, curr loss: 1.386074185371399, avg loss: 1.3863662898540496\n",
      "trial: 4, iter: 2200, curr loss: 1.3860124349594116, avg loss: 1.3864975470304488\n",
      "trial: 4, iter: 2400, curr loss: 1.3857392072677612, avg loss: 1.3863255339860916\n",
      "trial: 4, iter: 2600, curr loss: 1.387289047241211, avg loss: 1.386429557800293\n",
      "trial: 4, iter: 2800, curr loss: 1.3872430324554443, avg loss: 1.3864126241207122\n",
      "trial: 4, iter: 3000, curr loss: 1.3865787982940674, avg loss: 1.3863426500558853\n",
      "trial: 4, iter: 3200, curr loss: 1.3860626220703125, avg loss: 1.3863081568479538\n",
      "trial: 4, iter: 3400, curr loss: 1.3872259855270386, avg loss: 1.3863581162691117\n",
      "trial: 4, iter: 3600, curr loss: 1.386605978012085, avg loss: 1.3863934069871902\n",
      "trial: 4, iter: 3800, curr loss: 1.3860664367675781, avg loss: 1.3863434600830078\n",
      "trial: 4, iter: 4000, curr loss: 1.3858906030654907, avg loss: 1.3863594555854797\n",
      "trial: 4, iter: 4200, curr loss: 1.3860840797424316, avg loss: 1.3862963062524796\n",
      "trial: 4, iter: 4400, curr loss: 1.386541485786438, avg loss: 1.3863166552782058\n",
      "trial: 4, iter: 4600, curr loss: 1.3863563537597656, avg loss: 1.386340325474739\n",
      "trial: 4, iter: 4800, curr loss: 1.3865240812301636, avg loss: 1.3863253903388977\n",
      "trial: 4, iter: 5000, curr loss: 1.386365294456482, avg loss: 1.3862966918945312\n",
      "trial: 4, iter: 5200, curr loss: 1.3860911130905151, avg loss: 1.3863146686553955\n",
      "trial: 4, iter: 5400, curr loss: 1.3863261938095093, avg loss: 1.386315832734108\n",
      "trial: 4, iter: 5600, curr loss: 1.3864150047302246, avg loss: 1.3863111919164657\n",
      "trial: 4, iter: 5800, curr loss: 1.3862324953079224, avg loss: 1.386303830742836\n",
      "trial: 4, iter: 6000, curr loss: 1.3865197896957397, avg loss: 1.3862920528650284\n",
      "trial: 4, iter: 6200, curr loss: 1.3866289854049683, avg loss: 1.3863403958082199\n",
      "trial: 4, ldr: -0.005529680754989386\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385864019393921, avg loss: 1.3871420454978942\n",
      "trial: 5, iter: 400, curr loss: 1.387439489364624, avg loss: 1.3867775702476501\n",
      "trial: 5, iter: 600, curr loss: 1.3847873210906982, avg loss: 1.3867189908027648\n",
      "trial: 5, iter: 800, curr loss: 1.386931300163269, avg loss: 1.3866012579202651\n",
      "trial: 5, iter: 1000, curr loss: 1.387478232383728, avg loss: 1.3864641332626342\n",
      "trial: 5, iter: 1200, curr loss: 1.388159155845642, avg loss: 1.3863625872135161\n",
      "trial: 5, iter: 1400, curr loss: 1.3851042985916138, avg loss: 1.3864266151189804\n",
      "trial: 5, iter: 1600, curr loss: 1.3871514797210693, avg loss: 1.3865563672780992\n",
      "trial: 5, iter: 1800, curr loss: 1.38772451877594, avg loss: 1.3864138525724412\n",
      "trial: 5, iter: 2000, curr loss: 1.3856606483459473, avg loss: 1.386339191198349\n",
      "trial: 5, iter: 2200, curr loss: 1.385042667388916, avg loss: 1.3864188498258592\n",
      "trial: 5, iter: 2400, curr loss: 1.3860176801681519, avg loss: 1.3864219284057617\n",
      "trial: 5, iter: 2600, curr loss: 1.385972261428833, avg loss: 1.3864125591516494\n",
      "trial: 5, iter: 2800, curr loss: 1.3855233192443848, avg loss: 1.3863240653276443\n",
      "trial: 5, iter: 3000, curr loss: 1.3871862888336182, avg loss: 1.3864015305042268\n",
      "trial: 5, iter: 3200, curr loss: 1.3861886262893677, avg loss: 1.3863997983932494\n",
      "trial: 5, iter: 3400, curr loss: 1.3868485689163208, avg loss: 1.3863468998670578\n",
      "trial: 5, iter: 3600, curr loss: 1.386110544204712, avg loss: 1.386296702027321\n",
      "trial: 5, iter: 3800, curr loss: 1.3862128257751465, avg loss: 1.3863573223352432\n",
      "trial: 5, iter: 4000, curr loss: 1.3862906694412231, avg loss: 1.3863403582572937\n",
      "trial: 5, iter: 4200, curr loss: 1.3861254453659058, avg loss: 1.3864027911424637\n",
      "trial: 5, iter: 4400, curr loss: 1.3859899044036865, avg loss: 1.3863249999284744\n",
      "trial: 5, iter: 4600, curr loss: 1.386354923248291, avg loss: 1.3863957118988037\n",
      "trial: 5, iter: 4800, curr loss: 1.3860913515090942, avg loss: 1.3863466668128968\n",
      "trial: 5, iter: 5000, curr loss: 1.3855011463165283, avg loss: 1.386289176940918\n",
      "trial: 5, iter: 5200, curr loss: 1.385812759399414, avg loss: 1.3863672029972076\n",
      "trial: 5, iter: 5400, curr loss: 1.38624107837677, avg loss: 1.3862828463315964\n",
      "trial: 5, iter: 5600, curr loss: 1.3859446048736572, avg loss: 1.3863415706157685\n",
      "trial: 5, iter: 5800, curr loss: 1.3857792615890503, avg loss: 1.3862949633598327\n",
      "trial: 5, iter: 6000, curr loss: 1.387290358543396, avg loss: 1.386341506242752\n",
      "trial: 5, iter: 6200, curr loss: 1.386721134185791, avg loss: 1.38634308218956\n",
      "trial: 5, ldr: 0.0018081901362165809\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0044795294641517104\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3836958408355713, avg loss: 1.3874426662921906\n",
      "trial: 1, iter: 400, curr loss: 1.387362003326416, avg loss: 1.3868755632638932\n",
      "trial: 1, iter: 600, curr loss: 1.384168267250061, avg loss: 1.386652346253395\n",
      "trial: 1, iter: 800, curr loss: 1.3851853609085083, avg loss: 1.3865439075231552\n",
      "trial: 1, iter: 1000, curr loss: 1.386723279953003, avg loss: 1.3865146833658217\n",
      "trial: 1, iter: 1200, curr loss: 1.387416124343872, avg loss: 1.3864810967445373\n",
      "trial: 1, iter: 1400, curr loss: 1.3852161169052124, avg loss: 1.3865101903676986\n",
      "trial: 1, iter: 1600, curr loss: 1.3873345851898193, avg loss: 1.3864251065254212\n",
      "trial: 1, iter: 1800, curr loss: 1.3866851329803467, avg loss: 1.3864206326007844\n",
      "trial: 1, iter: 2000, curr loss: 1.3870917558670044, avg loss: 1.3863728255033494\n",
      "trial: 1, iter: 2200, curr loss: 1.3853307962417603, avg loss: 1.3863472098112106\n",
      "trial: 1, iter: 2400, curr loss: 1.386478304862976, avg loss: 1.3863316249847413\n",
      "trial: 1, iter: 2600, curr loss: 1.3860468864440918, avg loss: 1.3863773810863496\n",
      "trial: 1, iter: 2800, curr loss: 1.3856059312820435, avg loss: 1.3863438832759858\n",
      "trial: 1, iter: 3000, curr loss: 1.387890100479126, avg loss: 1.3864150410890579\n",
      "trial: 1, iter: 3200, curr loss: 1.3872133493423462, avg loss: 1.3863883137702941\n",
      "trial: 1, iter: 3400, curr loss: 1.3864624500274658, avg loss: 1.3863487148284912\n",
      "trial: 1, iter: 3600, curr loss: 1.385871171951294, avg loss: 1.3863274484872818\n",
      "trial: 1, iter: 3800, curr loss: 1.3857139348983765, avg loss: 1.3863201129436493\n",
      "trial: 1, iter: 4000, curr loss: 1.3860975503921509, avg loss: 1.3863346499204636\n",
      "trial: 1, iter: 4200, curr loss: 1.3856970071792603, avg loss: 1.386314145922661\n",
      "trial: 1, iter: 4400, curr loss: 1.385876178741455, avg loss: 1.3863116973638534\n",
      "trial: 1, iter: 4600, curr loss: 1.3847469091415405, avg loss: 1.3863275170326232\n",
      "trial: 1, iter: 4800, curr loss: 1.3866944313049316, avg loss: 1.3864739346504211\n",
      "trial: 1, iter: 5000, curr loss: 1.3857735395431519, avg loss: 1.3863706755638123\n",
      "trial: 1, iter: 5200, curr loss: 1.3861865997314453, avg loss: 1.386387510895729\n",
      "trial: 1, iter: 5400, curr loss: 1.385460615158081, avg loss: 1.386386821269989\n",
      "trial: 1, iter: 5600, curr loss: 1.3867442607879639, avg loss: 1.3863507306575775\n",
      "trial: 1, iter: 5800, curr loss: 1.386177897453308, avg loss: 1.3863416171073915\n",
      "trial: 1, iter: 6000, curr loss: 1.386422038078308, avg loss: 1.386352903842926\n",
      "trial: 1, iter: 6200, curr loss: 1.3860507011413574, avg loss: 1.3863676029443741\n",
      "trial: 1, ldr: -0.006799402646720409\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3884966373443604, avg loss: 1.3873021322488786\n",
      "trial: 2, iter: 400, curr loss: 1.3876423835754395, avg loss: 1.3867870724201203\n",
      "trial: 2, iter: 600, curr loss: 1.3874496221542358, avg loss: 1.3866764104366303\n",
      "trial: 2, iter: 800, curr loss: 1.3871238231658936, avg loss: 1.3865266579389572\n",
      "trial: 2, iter: 1000, curr loss: 1.3858767747879028, avg loss: 1.3864247798919678\n",
      "trial: 2, iter: 1200, curr loss: 1.3864096403121948, avg loss: 1.386476023197174\n",
      "trial: 2, iter: 1400, curr loss: 1.3869845867156982, avg loss: 1.386468831896782\n",
      "trial: 2, iter: 1600, curr loss: 1.38679838180542, avg loss: 1.3865030133724212\n",
      "trial: 2, iter: 1800, curr loss: 1.3863497972488403, avg loss: 1.3863617533445358\n",
      "trial: 2, iter: 2000, curr loss: 1.3865289688110352, avg loss: 1.3863612538576127\n",
      "trial: 2, iter: 2200, curr loss: 1.385716199874878, avg loss: 1.3863845020532608\n",
      "trial: 2, iter: 2400, curr loss: 1.3866562843322754, avg loss: 1.3863344478607178\n",
      "trial: 2, iter: 2600, curr loss: 1.3855838775634766, avg loss: 1.3862977194786072\n",
      "trial: 2, iter: 2800, curr loss: 1.3864772319793701, avg loss: 1.3864023220539092\n",
      "trial: 2, iter: 3000, curr loss: 1.3869519233703613, avg loss: 1.3863988357782364\n",
      "trial: 2, iter: 3200, curr loss: 1.3861488103866577, avg loss: 1.3863741946220398\n",
      "trial: 2, iter: 3400, curr loss: 1.3865498304367065, avg loss: 1.3862973940372467\n",
      "trial: 2, iter: 3600, curr loss: 1.3863980770111084, avg loss: 1.3863024824857713\n",
      "trial: 2, iter: 3800, curr loss: 1.3864425420761108, avg loss: 1.386388111114502\n",
      "trial: 2, iter: 4000, curr loss: 1.3857256174087524, avg loss: 1.3863238883018494\n",
      "trial: 2, iter: 4200, curr loss: 1.386367678642273, avg loss: 1.3863280314207076\n",
      "trial: 2, iter: 4400, curr loss: 1.3859959840774536, avg loss: 1.3862355422973633\n",
      "trial: 2, iter: 4600, curr loss: 1.386612892150879, avg loss: 1.3863563853502274\n",
      "trial: 2, iter: 4800, curr loss: 1.3867279291152954, avg loss: 1.3863147491216659\n",
      "trial: 2, iter: 5000, curr loss: 1.386176586151123, avg loss: 1.3863250654935837\n",
      "trial: 2, iter: 5200, curr loss: 1.3865432739257812, avg loss: 1.3863445317745209\n",
      "trial: 2, iter: 5400, curr loss: 1.3852890729904175, avg loss: 1.3862876147031784\n",
      "trial: 2, iter: 5600, curr loss: 1.385787010192871, avg loss: 1.3863631570339203\n",
      "trial: 2, iter: 5800, curr loss: 1.3869601488113403, avg loss: 1.3863382184505462\n",
      "trial: 2, iter: 6000, curr loss: 1.3863664865493774, avg loss: 1.3863620162010193\n",
      "trial: 2, iter: 6200, curr loss: 1.385979175567627, avg loss: 1.3862921684980392\n",
      "trial: 2, ldr: -0.001637740875594318\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3876256942749023, avg loss: 1.3873966389894485\n",
      "trial: 3, iter: 400, curr loss: 1.3861030340194702, avg loss: 1.3868024617433548\n",
      "trial: 3, iter: 600, curr loss: 1.3875625133514404, avg loss: 1.3865918546915055\n",
      "trial: 3, iter: 800, curr loss: 1.3858989477157593, avg loss: 1.386597727537155\n",
      "trial: 3, iter: 1000, curr loss: 1.3839659690856934, avg loss: 1.386391058564186\n",
      "trial: 3, iter: 1200, curr loss: 1.3861963748931885, avg loss: 1.3865052092075347\n",
      "trial: 3, iter: 1400, curr loss: 1.386878252029419, avg loss: 1.3863924270868302\n",
      "trial: 3, iter: 1600, curr loss: 1.385535717010498, avg loss: 1.386442130804062\n",
      "trial: 3, iter: 1800, curr loss: 1.3856055736541748, avg loss: 1.3864519095420837\n",
      "trial: 3, iter: 2000, curr loss: 1.3859161138534546, avg loss: 1.3864108246564866\n",
      "trial: 3, iter: 2200, curr loss: 1.3885303735733032, avg loss: 1.3863253206014634\n",
      "trial: 3, iter: 2400, curr loss: 1.386282205581665, avg loss: 1.386418246626854\n",
      "trial: 3, iter: 2600, curr loss: 1.3862240314483643, avg loss: 1.3863840568065644\n",
      "trial: 3, iter: 2800, curr loss: 1.3856359720230103, avg loss: 1.3864334088563919\n",
      "trial: 3, iter: 3000, curr loss: 1.385927677154541, avg loss: 1.386361539363861\n",
      "trial: 3, iter: 3200, curr loss: 1.3853890895843506, avg loss: 1.3864337360858918\n",
      "trial: 3, iter: 3400, curr loss: 1.3852035999298096, avg loss: 1.3863076496124267\n",
      "trial: 3, iter: 3600, curr loss: 1.3862029314041138, avg loss: 1.3864249849319459\n",
      "trial: 3, iter: 3800, curr loss: 1.3859061002731323, avg loss: 1.3863024306297302\n",
      "trial: 3, iter: 4000, curr loss: 1.387305736541748, avg loss: 1.3863742399215697\n",
      "trial: 3, iter: 4200, curr loss: 1.3861387968063354, avg loss: 1.3863289707899094\n",
      "trial: 3, iter: 4400, curr loss: 1.3863515853881836, avg loss: 1.3864094942808152\n",
      "trial: 3, iter: 4600, curr loss: 1.3862663507461548, avg loss: 1.3863136565685272\n",
      "trial: 3, iter: 4800, curr loss: 1.3855456113815308, avg loss: 1.3863090938329696\n",
      "trial: 3, iter: 5000, curr loss: 1.3854438066482544, avg loss: 1.3862943464517594\n",
      "trial: 3, iter: 5200, curr loss: 1.3860375881195068, avg loss: 1.386337958574295\n",
      "trial: 3, iter: 5400, curr loss: 1.3858356475830078, avg loss: 1.3862977939844132\n",
      "trial: 3, iter: 5600, curr loss: 1.3865076303482056, avg loss: 1.3863341563940048\n",
      "trial: 3, iter: 5800, curr loss: 1.3862662315368652, avg loss: 1.3862986660003662\n",
      "trial: 3, iter: 6000, curr loss: 1.3868799209594727, avg loss: 1.3862926423549653\n",
      "trial: 3, iter: 6200, curr loss: 1.386279582977295, avg loss: 1.3863242679834367\n",
      "trial: 3, ldr: 0.003242514794692397\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3850027322769165, avg loss: 1.3870795148611068\n",
      "trial: 4, iter: 400, curr loss: 1.3853306770324707, avg loss: 1.3867483842372894\n",
      "trial: 4, iter: 600, curr loss: 1.3874062299728394, avg loss: 1.3864667719602586\n",
      "trial: 4, iter: 800, curr loss: 1.3869881629943848, avg loss: 1.386567554473877\n",
      "trial: 4, iter: 1000, curr loss: 1.3864437341690063, avg loss: 1.3864525538682937\n",
      "trial: 4, iter: 1200, curr loss: 1.3867478370666504, avg loss: 1.3863778907060622\n",
      "trial: 4, iter: 1400, curr loss: 1.387071967124939, avg loss: 1.38637211561203\n",
      "trial: 4, iter: 1600, curr loss: 1.3863004446029663, avg loss: 1.3863943707942963\n",
      "trial: 4, iter: 1800, curr loss: 1.3851836919784546, avg loss: 1.3862954658269881\n",
      "trial: 4, iter: 2000, curr loss: 1.3868916034698486, avg loss: 1.3863760858774186\n",
      "trial: 4, iter: 2200, curr loss: 1.3850711584091187, avg loss: 1.3863634270429612\n",
      "trial: 4, iter: 2400, curr loss: 1.3860780000686646, avg loss: 1.3863909476995468\n",
      "trial: 4, iter: 2600, curr loss: 1.385445237159729, avg loss: 1.3863583624362945\n",
      "trial: 4, iter: 2800, curr loss: 1.3863826990127563, avg loss: 1.3864411491155624\n",
      "trial: 4, iter: 3000, curr loss: 1.3863338232040405, avg loss: 1.3864228773117064\n",
      "trial: 4, iter: 3200, curr loss: 1.3868228197097778, avg loss: 1.3864868360757827\n",
      "trial: 4, iter: 3400, curr loss: 1.386500597000122, avg loss: 1.3863323038816453\n",
      "trial: 4, iter: 3600, curr loss: 1.3863734006881714, avg loss: 1.3863540476560592\n",
      "trial: 4, iter: 3800, curr loss: 1.386737585067749, avg loss: 1.3863819122314454\n",
      "trial: 4, iter: 4000, curr loss: 1.3852609395980835, avg loss: 1.3862895542383193\n",
      "trial: 4, iter: 4200, curr loss: 1.3866076469421387, avg loss: 1.3863733464479446\n",
      "trial: 4, iter: 4400, curr loss: 1.3864245414733887, avg loss: 1.3863447552919388\n",
      "trial: 4, iter: 4600, curr loss: 1.386088252067566, avg loss: 1.3863551431894303\n",
      "trial: 4, iter: 4800, curr loss: 1.3866958618164062, avg loss: 1.3863293272256851\n",
      "trial: 4, iter: 5000, curr loss: 1.3861792087554932, avg loss: 1.3863501662015916\n",
      "trial: 4, iter: 5200, curr loss: 1.3863481283187866, avg loss: 1.386308829188347\n",
      "trial: 4, iter: 5400, curr loss: 1.3859846591949463, avg loss: 1.38632207095623\n",
      "trial: 4, iter: 5600, curr loss: 1.3862404823303223, avg loss: 1.386309963464737\n",
      "trial: 4, iter: 5800, curr loss: 1.386611819267273, avg loss: 1.3862598842382432\n",
      "trial: 4, iter: 6000, curr loss: 1.3857191801071167, avg loss: 1.386277293562889\n",
      "trial: 4, iter: 6200, curr loss: 1.3861240148544312, avg loss: 1.3863500714302064\n",
      "trial: 4, ldr: 0.005676416680216789\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3834617137908936, avg loss: 1.3872944605350495\n",
      "trial: 5, iter: 400, curr loss: 1.3858586549758911, avg loss: 1.38665691614151\n",
      "trial: 5, iter: 600, curr loss: 1.3882439136505127, avg loss: 1.3867146682739258\n",
      "trial: 5, iter: 800, curr loss: 1.384843111038208, avg loss: 1.3866507446765899\n",
      "trial: 5, iter: 1000, curr loss: 1.3856195211410522, avg loss: 1.386421599984169\n",
      "trial: 5, iter: 1200, curr loss: 1.388670802116394, avg loss: 1.3865388929843903\n",
      "trial: 5, iter: 1400, curr loss: 1.3855475187301636, avg loss: 1.386391590833664\n",
      "trial: 5, iter: 1600, curr loss: 1.3874591588974, avg loss: 1.3863574981689453\n",
      "trial: 5, iter: 1800, curr loss: 1.3860145807266235, avg loss: 1.3864911389350891\n",
      "trial: 5, iter: 2000, curr loss: 1.3862577676773071, avg loss: 1.3864216190576553\n",
      "trial: 5, iter: 2200, curr loss: 1.386130928993225, avg loss: 1.3863144797086715\n",
      "trial: 5, iter: 2400, curr loss: 1.385824203491211, avg loss: 1.3863147437572478\n",
      "trial: 5, iter: 2600, curr loss: 1.3869497776031494, avg loss: 1.3862906789779663\n",
      "trial: 5, iter: 2800, curr loss: 1.3862251043319702, avg loss: 1.386395201086998\n",
      "trial: 5, iter: 3000, curr loss: 1.3852014541625977, avg loss: 1.3863339066505431\n",
      "trial: 5, iter: 3200, curr loss: 1.3863803148269653, avg loss: 1.386390963792801\n",
      "trial: 5, iter: 3400, curr loss: 1.386736512184143, avg loss: 1.3862932235002519\n",
      "trial: 5, iter: 3600, curr loss: 1.3861593008041382, avg loss: 1.386343052983284\n",
      "trial: 5, iter: 3800, curr loss: 1.3866636753082275, avg loss: 1.3863466131687163\n",
      "trial: 5, iter: 4000, curr loss: 1.3862581253051758, avg loss: 1.3863145869970321\n",
      "trial: 5, iter: 4200, curr loss: 1.3853205442428589, avg loss: 1.3863077509403228\n",
      "trial: 5, iter: 4400, curr loss: 1.386521577835083, avg loss: 1.3863263785839082\n",
      "trial: 5, iter: 4600, curr loss: 1.385868787765503, avg loss: 1.3863220971822738\n",
      "trial: 5, iter: 4800, curr loss: 1.3866820335388184, avg loss: 1.386266513466835\n",
      "trial: 5, iter: 5000, curr loss: 1.3857123851776123, avg loss: 1.3863472360372544\n",
      "trial: 5, iter: 5200, curr loss: 1.3859732151031494, avg loss: 1.3863357150554656\n",
      "trial: 5, iter: 5400, curr loss: 1.3867454528808594, avg loss: 1.3862895900011063\n",
      "trial: 5, iter: 5600, curr loss: 1.386429786682129, avg loss: 1.386344684958458\n",
      "trial: 5, iter: 5800, curr loss: 1.3865959644317627, avg loss: 1.3862820810079575\n",
      "trial: 5, iter: 6000, curr loss: 1.386368751525879, avg loss: 1.3863147574663162\n",
      "trial: 5, iter: 6200, curr loss: 1.3857696056365967, avg loss: 1.3862557989358901\n",
      "trial: 5, ldr: 0.00030931379296816885\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00015822034911252558\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3893457651138306, avg loss: 1.3872602713108062\n",
      "trial: 1, iter: 400, curr loss: 1.3864918947219849, avg loss: 1.386651983857155\n",
      "trial: 1, iter: 600, curr loss: 1.3865714073181152, avg loss: 1.3866215640306472\n",
      "trial: 1, iter: 800, curr loss: 1.3879669904708862, avg loss: 1.386545278429985\n",
      "trial: 1, iter: 1000, curr loss: 1.387656807899475, avg loss: 1.386447172164917\n",
      "trial: 1, iter: 1200, curr loss: 1.3869051933288574, avg loss: 1.3864599496126175\n",
      "trial: 1, iter: 1400, curr loss: 1.3866256475448608, avg loss: 1.3864231926202775\n",
      "trial: 1, iter: 1600, curr loss: 1.3875828981399536, avg loss: 1.3863953697681426\n",
      "trial: 1, iter: 1800, curr loss: 1.3868954181671143, avg loss: 1.3864229834079742\n",
      "trial: 1, iter: 2000, curr loss: 1.3844294548034668, avg loss: 1.3863351714611054\n",
      "trial: 1, iter: 2200, curr loss: 1.385806679725647, avg loss: 1.3863704591989516\n",
      "trial: 1, iter: 2400, curr loss: 1.3855990171432495, avg loss: 1.3863592112064362\n",
      "trial: 1, iter: 2600, curr loss: 1.3861708641052246, avg loss: 1.3863935244083405\n",
      "trial: 1, iter: 2800, curr loss: 1.3864573240280151, avg loss: 1.386303488612175\n",
      "trial: 1, iter: 3000, curr loss: 1.38603675365448, avg loss: 1.3863775515556336\n",
      "trial: 1, iter: 3200, curr loss: 1.3861258029937744, avg loss: 1.386334140896797\n",
      "trial: 1, iter: 3400, curr loss: 1.3866876363754272, avg loss: 1.3863548254966735\n",
      "trial: 1, iter: 3600, curr loss: 1.387533187866211, avg loss: 1.3863854753971099\n",
      "trial: 1, iter: 3800, curr loss: 1.3853943347930908, avg loss: 1.3863617122173308\n",
      "trial: 1, iter: 4000, curr loss: 1.3861733675003052, avg loss: 1.3863101583719253\n",
      "trial: 1, iter: 4200, curr loss: 1.3858225345611572, avg loss: 1.3863067263364792\n",
      "trial: 1, iter: 4400, curr loss: 1.3868632316589355, avg loss: 1.3863115572929383\n",
      "trial: 1, iter: 4600, curr loss: 1.3867303133010864, avg loss: 1.3863288098573685\n",
      "trial: 1, iter: 4800, curr loss: 1.3861314058303833, avg loss: 1.3863519406318665\n",
      "trial: 1, iter: 5000, curr loss: 1.3863036632537842, avg loss: 1.3863273280858994\n",
      "trial: 1, iter: 5200, curr loss: 1.3863328695297241, avg loss: 1.386313608288765\n",
      "trial: 1, iter: 5400, curr loss: 1.3865256309509277, avg loss: 1.3863159549236297\n",
      "trial: 1, iter: 5600, curr loss: 1.3869874477386475, avg loss: 1.3863827979564667\n",
      "trial: 1, iter: 5800, curr loss: 1.385725975036621, avg loss: 1.3862985223531723\n",
      "trial: 1, iter: 6000, curr loss: 1.3866004943847656, avg loss: 1.3863110595941543\n",
      "trial: 1, iter: 6200, curr loss: 1.3864609003067017, avg loss: 1.3863507670164108\n",
      "trial: 1, ldr: -0.004248379729688168\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3888144493103027, avg loss: 1.3874578809738158\n",
      "trial: 2, iter: 400, curr loss: 1.3866653442382812, avg loss: 1.3864805579185486\n",
      "trial: 2, iter: 600, curr loss: 1.3853250741958618, avg loss: 1.3865188694000243\n",
      "trial: 2, iter: 800, curr loss: 1.385465145111084, avg loss: 1.3865189284086228\n",
      "trial: 2, iter: 1000, curr loss: 1.387318730354309, avg loss: 1.3863415414094924\n",
      "trial: 2, iter: 1200, curr loss: 1.385647177696228, avg loss: 1.3864206367731093\n",
      "trial: 2, iter: 1400, curr loss: 1.386980652809143, avg loss: 1.3863999193906784\n",
      "trial: 2, iter: 1600, curr loss: 1.3864333629608154, avg loss: 1.3863588410615921\n",
      "trial: 2, iter: 1800, curr loss: 1.3855565786361694, avg loss: 1.3864018833637237\n",
      "trial: 2, iter: 2000, curr loss: 1.3874577283859253, avg loss: 1.3864282011985778\n",
      "trial: 2, iter: 2200, curr loss: 1.3851661682128906, avg loss: 1.3863754534721375\n",
      "trial: 2, iter: 2400, curr loss: 1.3882423639297485, avg loss: 1.3863614183664321\n",
      "trial: 2, iter: 2600, curr loss: 1.3861162662506104, avg loss: 1.3863692450523377\n",
      "trial: 2, iter: 2800, curr loss: 1.3858075141906738, avg loss: 1.3862808334827423\n",
      "trial: 2, iter: 3000, curr loss: 1.3865234851837158, avg loss: 1.3863428163528442\n",
      "trial: 2, iter: 3200, curr loss: 1.386887550354004, avg loss: 1.38635655939579\n",
      "trial: 2, iter: 3400, curr loss: 1.3865113258361816, avg loss: 1.3863384008407593\n",
      "trial: 2, iter: 3600, curr loss: 1.3865474462509155, avg loss: 1.3863264107704163\n",
      "trial: 2, iter: 3800, curr loss: 1.3863749504089355, avg loss: 1.386339772939682\n",
      "trial: 2, iter: 4000, curr loss: 1.3866939544677734, avg loss: 1.3863101971149445\n",
      "trial: 2, iter: 4200, curr loss: 1.3859410285949707, avg loss: 1.3863095402717591\n",
      "trial: 2, iter: 4400, curr loss: 1.3861639499664307, avg loss: 1.386321730017662\n",
      "trial: 2, iter: 4600, curr loss: 1.386846661567688, avg loss: 1.3863244038820266\n",
      "trial: 2, iter: 4800, curr loss: 1.3866291046142578, avg loss: 1.3863165503740311\n",
      "trial: 2, iter: 5000, curr loss: 1.3854173421859741, avg loss: 1.386277032494545\n",
      "trial: 2, iter: 5200, curr loss: 1.3867132663726807, avg loss: 1.386349429488182\n",
      "trial: 2, iter: 5400, curr loss: 1.3865786790847778, avg loss: 1.386303922533989\n",
      "trial: 2, iter: 5600, curr loss: 1.3860470056533813, avg loss: 1.3863093543052674\n",
      "trial: 2, iter: 5800, curr loss: 1.3863667249679565, avg loss: 1.3863221269845962\n",
      "trial: 2, iter: 6000, curr loss: 1.3864119052886963, avg loss: 1.3862885272502898\n",
      "trial: 2, iter: 6200, curr loss: 1.38609778881073, avg loss: 1.3863600677251815\n",
      "trial: 2, ldr: 0.025892674922943115\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3889896869659424, avg loss: 1.3874632477760316\n",
      "trial: 3, iter: 400, curr loss: 1.3831737041473389, avg loss: 1.3866521620750427\n",
      "trial: 3, iter: 600, curr loss: 1.384623408317566, avg loss: 1.3865194916725159\n",
      "trial: 3, iter: 800, curr loss: 1.3873183727264404, avg loss: 1.3864535248279573\n",
      "trial: 3, iter: 1000, curr loss: 1.3870422840118408, avg loss: 1.3863777911663056\n",
      "trial: 3, iter: 1200, curr loss: 1.3857393264770508, avg loss: 1.3864365607500075\n",
      "trial: 3, iter: 1400, curr loss: 1.386746883392334, avg loss: 1.386417226791382\n",
      "trial: 3, iter: 1600, curr loss: 1.3870471715927124, avg loss: 1.3864376294612883\n",
      "trial: 3, iter: 1800, curr loss: 1.386535406112671, avg loss: 1.3864742439985276\n",
      "trial: 3, iter: 2000, curr loss: 1.3854411840438843, avg loss: 1.3862597274780273\n",
      "trial: 3, iter: 2200, curr loss: 1.3863879442214966, avg loss: 1.3863453722000123\n",
      "trial: 3, iter: 2400, curr loss: 1.3863574266433716, avg loss: 1.3862790441513062\n",
      "trial: 3, iter: 2600, curr loss: 1.3854020833969116, avg loss: 1.3863479566574097\n",
      "trial: 3, iter: 2800, curr loss: 1.3868411779403687, avg loss: 1.3863282698392867\n",
      "trial: 3, iter: 3000, curr loss: 1.386533260345459, avg loss: 1.3863301485776902\n",
      "trial: 3, iter: 3200, curr loss: 1.386864185333252, avg loss: 1.3863477200269698\n",
      "trial: 3, iter: 3400, curr loss: 1.3861396312713623, avg loss: 1.386339662671089\n",
      "trial: 3, iter: 3600, curr loss: 1.3852254152297974, avg loss: 1.3862713879346849\n",
      "trial: 3, iter: 3800, curr loss: 1.3867238759994507, avg loss: 1.3863685292005539\n",
      "trial: 3, iter: 4000, curr loss: 1.3866997957229614, avg loss: 1.3863709521293641\n",
      "trial: 3, iter: 4200, curr loss: 1.3865289688110352, avg loss: 1.3863271933794021\n",
      "trial: 3, iter: 4400, curr loss: 1.3869951963424683, avg loss: 1.3863189554214477\n",
      "trial: 3, iter: 4600, curr loss: 1.385533094406128, avg loss: 1.3863357824087144\n",
      "trial: 3, iter: 4800, curr loss: 1.386448860168457, avg loss: 1.3863572680950165\n",
      "trial: 3, iter: 5000, curr loss: 1.3856936693191528, avg loss: 1.3863287019729613\n",
      "trial: 3, iter: 5200, curr loss: 1.3859031200408936, avg loss: 1.3863308602571487\n",
      "trial: 3, iter: 5400, curr loss: 1.3865324258804321, avg loss: 1.386337275505066\n",
      "trial: 3, iter: 5600, curr loss: 1.3857430219650269, avg loss: 1.3863397043943406\n",
      "trial: 3, iter: 5800, curr loss: 1.386125922203064, avg loss: 1.3863270473480225\n",
      "trial: 3, iter: 6000, curr loss: 1.3869673013687134, avg loss: 1.3863542848825454\n",
      "trial: 3, iter: 6200, curr loss: 1.3863252401351929, avg loss: 1.3863248044252396\n",
      "trial: 3, ldr: -0.0028344569727778435\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3878133296966553, avg loss: 1.3872788256406785\n",
      "trial: 4, iter: 400, curr loss: 1.3853535652160645, avg loss: 1.3865554523468018\n",
      "trial: 4, iter: 600, curr loss: 1.3864833116531372, avg loss: 1.3865005952119827\n",
      "trial: 4, iter: 800, curr loss: 1.3869973421096802, avg loss: 1.3865217083692551\n",
      "trial: 4, iter: 1000, curr loss: 1.386426329612732, avg loss: 1.3864277201890944\n",
      "trial: 4, iter: 1200, curr loss: 1.386378288269043, avg loss: 1.3864766830205917\n",
      "trial: 4, iter: 1400, curr loss: 1.3848894834518433, avg loss: 1.3865049213171006\n",
      "trial: 4, iter: 1600, curr loss: 1.3884390592575073, avg loss: 1.3864064061641692\n",
      "trial: 4, iter: 1800, curr loss: 1.385604739189148, avg loss: 1.386398605108261\n",
      "trial: 4, iter: 2000, curr loss: 1.3862426280975342, avg loss: 1.3864037555456161\n",
      "trial: 4, iter: 2200, curr loss: 1.3864575624465942, avg loss: 1.3863651633262635\n",
      "trial: 4, iter: 2400, curr loss: 1.3862918615341187, avg loss: 1.3863517868518829\n",
      "trial: 4, iter: 2600, curr loss: 1.3871625661849976, avg loss: 1.3863512980937958\n",
      "trial: 4, iter: 2800, curr loss: 1.3852953910827637, avg loss: 1.3863300985097886\n",
      "trial: 4, iter: 3000, curr loss: 1.3864095211029053, avg loss: 1.3863893002271652\n",
      "trial: 4, iter: 3200, curr loss: 1.3865854740142822, avg loss: 1.386311953663826\n",
      "trial: 4, iter: 3400, curr loss: 1.386023759841919, avg loss: 1.3863200837373733\n",
      "trial: 4, iter: 3600, curr loss: 1.3868204355239868, avg loss: 1.386289314031601\n",
      "trial: 4, iter: 3800, curr loss: 1.3867582082748413, avg loss: 1.3863937681913376\n",
      "trial: 4, iter: 4000, curr loss: 1.386655330657959, avg loss: 1.3863541102409362\n",
      "trial: 4, iter: 4200, curr loss: 1.3859919309616089, avg loss: 1.3862901389598847\n",
      "trial: 4, iter: 4400, curr loss: 1.3858393430709839, avg loss: 1.386332870721817\n",
      "trial: 4, iter: 4600, curr loss: 1.3865208625793457, avg loss: 1.3862881457805634\n",
      "trial: 4, iter: 4800, curr loss: 1.3864692449569702, avg loss: 1.3863269382715224\n",
      "trial: 4, iter: 5000, curr loss: 1.3875272274017334, avg loss: 1.3863297653198243\n",
      "trial: 4, iter: 5200, curr loss: 1.3868402242660522, avg loss: 1.3863049745559692\n",
      "trial: 4, iter: 5400, curr loss: 1.385295033454895, avg loss: 1.3862641972303391\n",
      "trial: 4, iter: 5600, curr loss: 1.38588285446167, avg loss: 1.3863512510061264\n",
      "trial: 4, iter: 5800, curr loss: 1.3866651058197021, avg loss: 1.3863259607553482\n",
      "trial: 4, iter: 6000, curr loss: 1.3862911462783813, avg loss: 1.3863152170181274\n",
      "trial: 4, iter: 6200, curr loss: 1.3855570554733276, avg loss: 1.3862990128993988\n",
      "trial: 4, ldr: -3.2316966098733246e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3878248929977417, avg loss: 1.3870026272535325\n",
      "trial: 5, iter: 400, curr loss: 1.3878169059753418, avg loss: 1.3869498401880265\n",
      "trial: 5, iter: 600, curr loss: 1.3871511220932007, avg loss: 1.3865212857723237\n",
      "trial: 5, iter: 800, curr loss: 1.3860589265823364, avg loss: 1.3863439166545868\n",
      "trial: 5, iter: 1000, curr loss: 1.3869751691818237, avg loss: 1.3864271646738053\n",
      "trial: 5, iter: 1200, curr loss: 1.3858619928359985, avg loss: 1.3864482235908508\n",
      "trial: 5, iter: 1400, curr loss: 1.3870779275894165, avg loss: 1.3864316618442536\n",
      "trial: 5, iter: 1600, curr loss: 1.38607919216156, avg loss: 1.3863211697340012\n",
      "trial: 5, iter: 1800, curr loss: 1.386308193206787, avg loss: 1.3864070242643356\n",
      "trial: 5, iter: 2000, curr loss: 1.3866944313049316, avg loss: 1.3863802808523178\n",
      "trial: 5, iter: 2200, curr loss: 1.3861223459243774, avg loss: 1.3863406842947006\n",
      "trial: 5, iter: 2400, curr loss: 1.386687994003296, avg loss: 1.3863638746738434\n",
      "trial: 5, iter: 2600, curr loss: 1.387235164642334, avg loss: 1.3863821369409561\n",
      "trial: 5, iter: 2800, curr loss: 1.3866651058197021, avg loss: 1.3863729441165924\n",
      "trial: 5, iter: 3000, curr loss: 1.386464238166809, avg loss: 1.386378823518753\n",
      "trial: 5, iter: 3200, curr loss: 1.3856346607208252, avg loss: 1.3863045167922974\n",
      "trial: 5, iter: 3400, curr loss: 1.3863097429275513, avg loss: 1.386381150484085\n",
      "trial: 5, iter: 3600, curr loss: 1.3865278959274292, avg loss: 1.386427060365677\n",
      "trial: 5, iter: 3800, curr loss: 1.3860347270965576, avg loss: 1.386325855255127\n",
      "trial: 5, iter: 4000, curr loss: 1.3859944343566895, avg loss: 1.386316083073616\n",
      "trial: 5, iter: 4200, curr loss: 1.3863286972045898, avg loss: 1.3863422000408172\n",
      "trial: 5, iter: 4400, curr loss: 1.3862180709838867, avg loss: 1.386336528658867\n",
      "trial: 5, iter: 4600, curr loss: 1.387181282043457, avg loss: 1.3863666540384292\n",
      "trial: 5, iter: 4800, curr loss: 1.3865365982055664, avg loss: 1.386341535449028\n",
      "trial: 5, iter: 5000, curr loss: 1.3865911960601807, avg loss: 1.3863422518968582\n",
      "trial: 5, iter: 5200, curr loss: 1.386057734489441, avg loss: 1.3863531732559204\n",
      "trial: 5, iter: 5400, curr loss: 1.3862144947052002, avg loss: 1.3862805610895157\n",
      "trial: 5, iter: 5600, curr loss: 1.386454701423645, avg loss: 1.386318999528885\n",
      "trial: 5, iter: 5800, curr loss: 1.3858778476715088, avg loss: 1.3863429433107377\n",
      "trial: 5, iter: 6000, curr loss: 1.3878899812698364, avg loss: 1.3861808258295059\n",
      "trial: 5, iter: 6200, curr loss: 1.3863327503204346, avg loss: 1.3864079052209854\n",
      "trial: 5, ldr: 0.0029731702525168657\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0043501383013790475\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3901426792144775, avg loss: 1.387227057814598\n",
      "trial: 1, iter: 400, curr loss: 1.3867756128311157, avg loss: 1.3867754280567168\n",
      "trial: 1, iter: 600, curr loss: 1.3869655132293701, avg loss: 1.3866637015342713\n",
      "trial: 1, iter: 800, curr loss: 1.3862074613571167, avg loss: 1.3866000324487686\n",
      "trial: 1, iter: 1000, curr loss: 1.385921597480774, avg loss: 1.3863879352808\n",
      "trial: 1, iter: 1200, curr loss: 1.3886770009994507, avg loss: 1.3864278334379196\n",
      "trial: 1, iter: 1400, curr loss: 1.385482907295227, avg loss: 1.3863394528627395\n",
      "trial: 1, iter: 1600, curr loss: 1.387318730354309, avg loss: 1.3864036756753921\n",
      "trial: 1, iter: 1800, curr loss: 1.3855507373809814, avg loss: 1.3863764762878419\n",
      "trial: 1, iter: 2000, curr loss: 1.3873556852340698, avg loss: 1.3864309656620026\n",
      "trial: 1, iter: 2200, curr loss: 1.386684775352478, avg loss: 1.38630337536335\n",
      "trial: 1, iter: 2400, curr loss: 1.385677456855774, avg loss: 1.386321702003479\n",
      "trial: 1, iter: 2600, curr loss: 1.3865711688995361, avg loss: 1.3864161175489427\n",
      "trial: 1, iter: 2800, curr loss: 1.3868941068649292, avg loss: 1.3863399946689605\n",
      "trial: 1, iter: 3000, curr loss: 1.3860191106796265, avg loss: 1.3864089220762252\n",
      "trial: 1, iter: 3200, curr loss: 1.3868211507797241, avg loss: 1.3863369935750962\n",
      "trial: 1, iter: 3400, curr loss: 1.3883861303329468, avg loss: 1.3863922226428986\n",
      "trial: 1, iter: 3600, curr loss: 1.3861678838729858, avg loss: 1.3864366614818573\n",
      "trial: 1, iter: 3800, curr loss: 1.3863316774368286, avg loss: 1.3863927656412125\n",
      "trial: 1, iter: 4000, curr loss: 1.3870928287506104, avg loss: 1.3863614135980606\n",
      "trial: 1, iter: 4200, curr loss: 1.386391520500183, avg loss: 1.3863614225387573\n",
      "trial: 1, iter: 4400, curr loss: 1.3873481750488281, avg loss: 1.3863458055257798\n",
      "trial: 1, iter: 4600, curr loss: 1.385859489440918, avg loss: 1.386311161518097\n",
      "trial: 1, iter: 4800, curr loss: 1.3863872289657593, avg loss: 1.3864172929525376\n",
      "trial: 1, iter: 5000, curr loss: 1.386428952217102, avg loss: 1.3863693064451217\n",
      "trial: 1, iter: 5200, curr loss: 1.3858985900878906, avg loss: 1.3863044452667237\n",
      "trial: 1, iter: 5400, curr loss: 1.3859522342681885, avg loss: 1.3863161569833755\n",
      "trial: 1, iter: 5600, curr loss: 1.3861292600631714, avg loss: 1.3863030064105988\n",
      "trial: 1, iter: 5800, curr loss: 1.3863909244537354, avg loss: 1.3863141357898712\n",
      "trial: 1, iter: 6000, curr loss: 1.386306643486023, avg loss: 1.3863225895166398\n",
      "trial: 1, iter: 6200, curr loss: 1.3864014148712158, avg loss: 1.3862999600172043\n",
      "trial: 1, ldr: 8.869107841746882e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3872864246368408, avg loss: 1.3873794376850128\n",
      "trial: 2, iter: 400, curr loss: 1.3853182792663574, avg loss: 1.3865656262636186\n",
      "trial: 2, iter: 600, curr loss: 1.3867833614349365, avg loss: 1.3865102523565291\n",
      "trial: 2, iter: 800, curr loss: 1.386910319328308, avg loss: 1.386463042497635\n",
      "trial: 2, iter: 1000, curr loss: 1.3855016231536865, avg loss: 1.3864352768659591\n",
      "trial: 2, iter: 1200, curr loss: 1.386565923690796, avg loss: 1.3864037877321242\n",
      "trial: 2, iter: 1400, curr loss: 1.387394666671753, avg loss: 1.386475996375084\n",
      "trial: 2, iter: 1600, curr loss: 1.3870302438735962, avg loss: 1.3863964849710464\n",
      "trial: 2, iter: 1800, curr loss: 1.3870081901550293, avg loss: 1.386353276371956\n",
      "trial: 2, iter: 2000, curr loss: 1.3868762254714966, avg loss: 1.3863882911205292\n",
      "trial: 2, iter: 2200, curr loss: 1.3873833417892456, avg loss: 1.3863378751277924\n",
      "trial: 2, iter: 2400, curr loss: 1.386443018913269, avg loss: 1.386359497308731\n",
      "trial: 2, iter: 2600, curr loss: 1.385663628578186, avg loss: 1.3863208270072938\n",
      "trial: 2, iter: 2800, curr loss: 1.3858184814453125, avg loss: 1.386358123421669\n",
      "trial: 2, iter: 3000, curr loss: 1.3862489461898804, avg loss: 1.3863084828853607\n",
      "trial: 2, iter: 3200, curr loss: 1.386549472808838, avg loss: 1.3863498550653457\n",
      "trial: 2, iter: 3400, curr loss: 1.3882765769958496, avg loss: 1.3863599228858947\n",
      "trial: 2, iter: 3600, curr loss: 1.3865822553634644, avg loss: 1.3864068204164506\n",
      "trial: 2, iter: 3800, curr loss: 1.3873709440231323, avg loss: 1.3864036309719086\n",
      "trial: 2, iter: 4000, curr loss: 1.3861125707626343, avg loss: 1.3864198970794677\n",
      "trial: 2, iter: 4200, curr loss: 1.3867849111557007, avg loss: 1.3863321006298066\n",
      "trial: 2, iter: 4400, curr loss: 1.3859535455703735, avg loss: 1.386318908929825\n",
      "trial: 2, iter: 4600, curr loss: 1.3855786323547363, avg loss: 1.3863025385141372\n",
      "trial: 2, iter: 4800, curr loss: 1.386296272277832, avg loss: 1.3862927550077437\n",
      "trial: 2, iter: 5000, curr loss: 1.387012004852295, avg loss: 1.3863767379522323\n",
      "trial: 2, iter: 5200, curr loss: 1.3865835666656494, avg loss: 1.3863298797607422\n",
      "trial: 2, iter: 5400, curr loss: 1.3867855072021484, avg loss: 1.386302383542061\n",
      "trial: 2, iter: 5600, curr loss: 1.3860243558883667, avg loss: 1.3863183826208114\n",
      "trial: 2, iter: 5800, curr loss: 1.3865255117416382, avg loss: 1.3864203894138336\n",
      "trial: 2, iter: 6000, curr loss: 1.3858500719070435, avg loss: 1.3863547664880753\n",
      "trial: 2, iter: 6200, curr loss: 1.3860292434692383, avg loss: 1.3863372910022735\n",
      "trial: 2, ldr: -0.01019561942666769\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3859493732452393, avg loss: 1.3874650472402572\n",
      "trial: 3, iter: 400, curr loss: 1.385331630706787, avg loss: 1.3866114711761475\n",
      "trial: 3, iter: 600, curr loss: 1.3845628499984741, avg loss: 1.3864741331338883\n",
      "trial: 3, iter: 800, curr loss: 1.3868814706802368, avg loss: 1.3865034204721451\n",
      "trial: 3, iter: 1000, curr loss: 1.3856528997421265, avg loss: 1.3864869230985641\n",
      "trial: 3, iter: 1200, curr loss: 1.3877626657485962, avg loss: 1.3863879603147506\n",
      "trial: 3, iter: 1400, curr loss: 1.3866043090820312, avg loss: 1.3864814764261246\n",
      "trial: 3, iter: 1600, curr loss: 1.3863615989685059, avg loss: 1.3863912850618363\n",
      "trial: 3, iter: 1800, curr loss: 1.385275959968567, avg loss: 1.386318914294243\n",
      "trial: 3, iter: 2000, curr loss: 1.386811375617981, avg loss: 1.3863939708471298\n",
      "trial: 3, iter: 2200, curr loss: 1.3863873481750488, avg loss: 1.386379954814911\n",
      "trial: 3, iter: 2400, curr loss: 1.3872584104537964, avg loss: 1.3863684475421905\n",
      "trial: 3, iter: 2600, curr loss: 1.3865553140640259, avg loss: 1.3863726568222046\n",
      "trial: 3, iter: 2800, curr loss: 1.3867075443267822, avg loss: 1.3863583797216414\n",
      "trial: 3, iter: 3000, curr loss: 1.3855329751968384, avg loss: 1.3863244515657425\n",
      "trial: 3, iter: 3200, curr loss: 1.3868917226791382, avg loss: 1.386342435479164\n",
      "trial: 3, iter: 3400, curr loss: 1.3841650485992432, avg loss: 1.386242807507515\n",
      "trial: 3, iter: 3600, curr loss: 1.3853015899658203, avg loss: 1.3863902854919434\n",
      "trial: 3, iter: 3800, curr loss: 1.386133074760437, avg loss: 1.3863594079017638\n",
      "trial: 3, iter: 4000, curr loss: 1.38606858253479, avg loss: 1.3863489365577697\n",
      "trial: 3, iter: 4200, curr loss: 1.3870857954025269, avg loss: 1.3863345664739608\n",
      "trial: 3, iter: 4400, curr loss: 1.3860188722610474, avg loss: 1.386308667063713\n",
      "trial: 3, iter: 4600, curr loss: 1.386094570159912, avg loss: 1.3863460022211074\n",
      "trial: 3, iter: 4800, curr loss: 1.3859241008758545, avg loss: 1.3863145607709884\n",
      "trial: 3, iter: 5000, curr loss: 1.3858343362808228, avg loss: 1.386368979215622\n",
      "trial: 3, iter: 5200, curr loss: 1.3858346939086914, avg loss: 1.3863254648447036\n",
      "trial: 3, iter: 5400, curr loss: 1.386209487915039, avg loss: 1.3863155072927476\n",
      "trial: 3, iter: 5600, curr loss: 1.386669635772705, avg loss: 1.386330612897873\n",
      "trial: 3, iter: 5800, curr loss: 1.3868273496627808, avg loss: 1.386314915418625\n",
      "trial: 3, iter: 6000, curr loss: 1.3864014148712158, avg loss: 1.3863112998008729\n",
      "trial: 3, iter: 6200, curr loss: 1.3863499164581299, avg loss: 1.386306186914444\n",
      "trial: 3, ldr: 0.0002847845898941159\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3876619338989258, avg loss: 1.3871505743265151\n",
      "trial: 4, iter: 400, curr loss: 1.3854814767837524, avg loss: 1.3864677119255067\n",
      "trial: 4, iter: 600, curr loss: 1.385481357574463, avg loss: 1.386571354866028\n",
      "trial: 4, iter: 800, curr loss: 1.3848702907562256, avg loss: 1.3864739447832108\n",
      "trial: 4, iter: 1000, curr loss: 1.3863153457641602, avg loss: 1.3864461767673493\n",
      "trial: 4, iter: 1200, curr loss: 1.3860684633255005, avg loss: 1.3863924592733383\n",
      "trial: 4, iter: 1400, curr loss: 1.3859905004501343, avg loss: 1.3863927483558656\n",
      "trial: 4, iter: 1600, curr loss: 1.3859021663665771, avg loss: 1.3863520979881288\n",
      "trial: 4, iter: 1800, curr loss: 1.385183572769165, avg loss: 1.3863385593891144\n",
      "trial: 4, iter: 2000, curr loss: 1.3863816261291504, avg loss: 1.3863210946321487\n",
      "trial: 4, iter: 2200, curr loss: 1.3857734203338623, avg loss: 1.3863670057058335\n",
      "trial: 4, iter: 2400, curr loss: 1.3856836557388306, avg loss: 1.3863020086288451\n",
      "trial: 4, iter: 2600, curr loss: 1.385461688041687, avg loss: 1.3862396615743637\n",
      "trial: 4, iter: 2800, curr loss: 1.385062336921692, avg loss: 1.3863999980688095\n",
      "trial: 4, iter: 3000, curr loss: 1.3879798650741577, avg loss: 1.3864791589975356\n",
      "trial: 4, iter: 3200, curr loss: 1.3861749172210693, avg loss: 1.3864649337530137\n",
      "trial: 4, iter: 3400, curr loss: 1.386488676071167, avg loss: 1.3864105784893035\n",
      "trial: 4, iter: 3600, curr loss: 1.3850733041763306, avg loss: 1.3863057965040206\n",
      "trial: 4, iter: 3800, curr loss: 1.386318564414978, avg loss: 1.3864035123586655\n",
      "trial: 4, iter: 4000, curr loss: 1.3863389492034912, avg loss: 1.3862997806072235\n",
      "trial: 4, iter: 4200, curr loss: 1.3863945007324219, avg loss: 1.3863177371025086\n",
      "trial: 4, iter: 4400, curr loss: 1.3866002559661865, avg loss: 1.386303214430809\n",
      "trial: 4, iter: 4600, curr loss: 1.387227177619934, avg loss: 1.3862473273277283\n",
      "trial: 4, iter: 4800, curr loss: 1.3864494562149048, avg loss: 1.38638123691082\n",
      "trial: 4, iter: 5000, curr loss: 1.3861950635910034, avg loss: 1.3863738876581193\n",
      "trial: 4, iter: 5200, curr loss: 1.3864825963974, avg loss: 1.386321680545807\n",
      "trial: 4, iter: 5400, curr loss: 1.386260747909546, avg loss: 1.3863148087263106\n",
      "trial: 4, iter: 5600, curr loss: 1.3864163160324097, avg loss: 1.386324171423912\n",
      "trial: 4, iter: 5800, curr loss: 1.386149287223816, avg loss: 1.3863576304912568\n",
      "trial: 4, iter: 6000, curr loss: 1.3868683576583862, avg loss: 1.3862883692979813\n",
      "trial: 4, iter: 6200, curr loss: 1.3862143754959106, avg loss: 1.3862508422136306\n",
      "trial: 4, ldr: -0.002473401604220271\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882060050964355, avg loss: 1.3871202677488328\n",
      "trial: 5, iter: 400, curr loss: 1.384477138519287, avg loss: 1.386832419037819\n",
      "trial: 5, iter: 600, curr loss: 1.3843504190444946, avg loss: 1.386660896539688\n",
      "trial: 5, iter: 800, curr loss: 1.3875237703323364, avg loss: 1.38654123544693\n",
      "trial: 5, iter: 1000, curr loss: 1.3856226205825806, avg loss: 1.386537321805954\n",
      "trial: 5, iter: 1200, curr loss: 1.3854548931121826, avg loss: 1.3864282578229905\n",
      "trial: 5, iter: 1400, curr loss: 1.3839274644851685, avg loss: 1.3863655078411101\n",
      "trial: 5, iter: 1600, curr loss: 1.3868523836135864, avg loss: 1.386520711183548\n",
      "trial: 5, iter: 1800, curr loss: 1.3871294260025024, avg loss: 1.3863201373815537\n",
      "trial: 5, iter: 2000, curr loss: 1.3874558210372925, avg loss: 1.3864104020595551\n",
      "trial: 5, iter: 2200, curr loss: 1.3866046667099, avg loss: 1.3863488918542861\n",
      "trial: 5, iter: 2400, curr loss: 1.3853073120117188, avg loss: 1.3862932848930358\n",
      "trial: 5, iter: 2600, curr loss: 1.3869104385375977, avg loss: 1.3863756251335144\n",
      "trial: 5, iter: 2800, curr loss: 1.3857834339141846, avg loss: 1.3863413989543916\n",
      "trial: 5, iter: 3000, curr loss: 1.3861476182937622, avg loss: 1.3863505661487578\n",
      "trial: 5, iter: 3200, curr loss: 1.3864057064056396, avg loss: 1.3863350033760071\n",
      "trial: 5, iter: 3400, curr loss: 1.3858838081359863, avg loss: 1.3863313621282578\n",
      "trial: 5, iter: 3600, curr loss: 1.386149525642395, avg loss: 1.3863106685876847\n",
      "trial: 5, iter: 3800, curr loss: 1.3877373933792114, avg loss: 1.3863333123922348\n",
      "trial: 5, iter: 4000, curr loss: 1.3865588903427124, avg loss: 1.3863684660196305\n",
      "trial: 5, iter: 4200, curr loss: 1.3864752054214478, avg loss: 1.3863200700283052\n",
      "trial: 5, iter: 4400, curr loss: 1.3859375715255737, avg loss: 1.3863311398029328\n",
      "trial: 5, iter: 4600, curr loss: 1.386539340019226, avg loss: 1.3864088881015777\n",
      "trial: 5, iter: 4800, curr loss: 1.3864452838897705, avg loss: 1.3864115566015243\n",
      "trial: 5, iter: 5000, curr loss: 1.3863731622695923, avg loss: 1.3863992351293564\n",
      "trial: 5, iter: 5200, curr loss: 1.3857053518295288, avg loss: 1.3864303529262543\n",
      "trial: 5, iter: 5400, curr loss: 1.386481761932373, avg loss: 1.3863932806253434\n",
      "trial: 5, iter: 5600, curr loss: 1.3860944509506226, avg loss: 1.386331358551979\n",
      "trial: 5, iter: 5800, curr loss: 1.38675856590271, avg loss: 1.386262510418892\n",
      "trial: 5, iter: 6000, curr loss: 1.386715054512024, avg loss: 1.386348277926445\n",
      "trial: 5, iter: 6200, curr loss: 1.3863544464111328, avg loss: 1.3862940627336502\n",
      "trial: 5, ldr: -0.0004652063362300396\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0025521503397612833\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3895500898361206, avg loss: 1.3872736424207688\n",
      "trial: 1, iter: 400, curr loss: 1.3881919384002686, avg loss: 1.3866125625371932\n",
      "trial: 1, iter: 600, curr loss: 1.3858587741851807, avg loss: 1.3865485298633575\n",
      "trial: 1, iter: 800, curr loss: 1.388730764389038, avg loss: 1.386468801498413\n",
      "trial: 1, iter: 1000, curr loss: 1.3867337703704834, avg loss: 1.3864870017766953\n",
      "trial: 1, iter: 1200, curr loss: 1.385850429534912, avg loss: 1.3864004880189895\n",
      "trial: 1, iter: 1400, curr loss: 1.3867754936218262, avg loss: 1.3864076697826386\n",
      "trial: 1, iter: 1600, curr loss: 1.385370135307312, avg loss: 1.386432508826256\n",
      "trial: 1, iter: 1800, curr loss: 1.3866850137710571, avg loss: 1.3863567924499511\n",
      "trial: 1, iter: 2000, curr loss: 1.386918306350708, avg loss: 1.3863948625326157\n",
      "trial: 1, iter: 2200, curr loss: 1.3858082294464111, avg loss: 1.3862977689504623\n",
      "trial: 1, iter: 2400, curr loss: 1.3862133026123047, avg loss: 1.386380227804184\n",
      "trial: 1, iter: 2600, curr loss: 1.3875584602355957, avg loss: 1.3863538539409637\n",
      "trial: 1, iter: 2800, curr loss: 1.3860971927642822, avg loss: 1.3863824856281282\n",
      "trial: 1, iter: 3000, curr loss: 1.3859927654266357, avg loss: 1.3863206791877747\n",
      "trial: 1, iter: 3200, curr loss: 1.386096715927124, avg loss: 1.3863776183128358\n",
      "trial: 1, iter: 3400, curr loss: 1.3864325284957886, avg loss: 1.3863448566198349\n",
      "trial: 1, iter: 3600, curr loss: 1.3864330053329468, avg loss: 1.3863645869493484\n",
      "trial: 1, iter: 3800, curr loss: 1.3862249851226807, avg loss: 1.3863397914171218\n",
      "trial: 1, iter: 4000, curr loss: 1.3863292932510376, avg loss: 1.3863440757989884\n",
      "trial: 1, iter: 4200, curr loss: 1.3861480951309204, avg loss: 1.386310967206955\n",
      "trial: 1, iter: 4400, curr loss: 1.3860878944396973, avg loss: 1.3863192850351334\n",
      "trial: 1, iter: 4600, curr loss: 1.3862385749816895, avg loss: 1.3863133710622788\n",
      "trial: 1, iter: 4800, curr loss: 1.3859977722167969, avg loss: 1.3863119369745254\n",
      "trial: 1, iter: 5000, curr loss: 1.3862807750701904, avg loss: 1.3863101881742477\n",
      "trial: 1, iter: 5200, curr loss: 1.3859565258026123, avg loss: 1.3863116306066514\n",
      "trial: 1, iter: 5400, curr loss: 1.3860180377960205, avg loss: 1.3863059031963347\n",
      "trial: 1, iter: 5600, curr loss: 1.3861446380615234, avg loss: 1.3862992572784423\n",
      "trial: 1, iter: 5800, curr loss: 1.3864686489105225, avg loss: 1.386349275112152\n",
      "trial: 1, iter: 6000, curr loss: 1.3865528106689453, avg loss: 1.386320412158966\n",
      "trial: 1, iter: 6200, curr loss: 1.3869085311889648, avg loss: 1.3863381165266038\n",
      "trial: 1, ldr: -0.0034544304944574833\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3848127126693726, avg loss: 1.3871711313724517\n",
      "trial: 2, iter: 400, curr loss: 1.3858774900436401, avg loss: 1.3864793479442596\n",
      "trial: 2, iter: 600, curr loss: 1.3861541748046875, avg loss: 1.3865978527069092\n",
      "trial: 2, iter: 800, curr loss: 1.386559009552002, avg loss: 1.3864570915699006\n",
      "trial: 2, iter: 1000, curr loss: 1.387480616569519, avg loss: 1.3864245861768723\n",
      "trial: 2, iter: 1200, curr loss: 1.3858927488327026, avg loss: 1.3863753575086593\n",
      "trial: 2, iter: 1400, curr loss: 1.3855513334274292, avg loss: 1.3863328450918198\n",
      "trial: 2, iter: 1600, curr loss: 1.3855682611465454, avg loss: 1.3863773030042648\n",
      "trial: 2, iter: 1800, curr loss: 1.3850634098052979, avg loss: 1.386324793100357\n",
      "trial: 2, iter: 2000, curr loss: 1.385614037513733, avg loss: 1.3863789039850234\n",
      "trial: 2, iter: 2200, curr loss: 1.387216329574585, avg loss: 1.3863714957237243\n",
      "trial: 2, iter: 2400, curr loss: 1.3876956701278687, avg loss: 1.386369116306305\n",
      "trial: 2, iter: 2600, curr loss: 1.3850452899932861, avg loss: 1.386359348297119\n",
      "trial: 2, iter: 2800, curr loss: 1.3873382806777954, avg loss: 1.3863525897264481\n",
      "trial: 2, iter: 3000, curr loss: 1.3854234218597412, avg loss: 1.3864282304048539\n",
      "trial: 2, iter: 3200, curr loss: 1.3858623504638672, avg loss: 1.3863521587848664\n",
      "trial: 2, iter: 3400, curr loss: 1.3860927820205688, avg loss: 1.3863162004947662\n",
      "trial: 2, iter: 3600, curr loss: 1.3857635259628296, avg loss: 1.3863673466444015\n",
      "trial: 2, iter: 3800, curr loss: 1.3858283758163452, avg loss: 1.3863420498371124\n",
      "trial: 2, iter: 4000, curr loss: 1.387138843536377, avg loss: 1.3863622051477433\n",
      "trial: 2, iter: 4200, curr loss: 1.3866875171661377, avg loss: 1.3863596743345261\n",
      "trial: 2, iter: 4400, curr loss: 1.3864139318466187, avg loss: 1.3863184553384782\n",
      "trial: 2, iter: 4600, curr loss: 1.386515736579895, avg loss: 1.3862934243679046\n",
      "trial: 2, iter: 4800, curr loss: 1.3868895769119263, avg loss: 1.3863530296087265\n",
      "trial: 2, iter: 5000, curr loss: 1.3862284421920776, avg loss: 1.3863394194841385\n",
      "trial: 2, iter: 5200, curr loss: 1.386495590209961, avg loss: 1.386321712732315\n",
      "trial: 2, iter: 5400, curr loss: 1.386549711227417, avg loss: 1.3862995433807372\n",
      "trial: 2, iter: 5600, curr loss: 1.3858301639556885, avg loss: 1.3863428616523743\n",
      "trial: 2, iter: 5800, curr loss: 1.38664972782135, avg loss: 1.3863172882795334\n",
      "trial: 2, iter: 6000, curr loss: 1.386899709701538, avg loss: 1.3863355296850204\n",
      "trial: 2, iter: 6200, curr loss: 1.3864842653274536, avg loss: 1.3863043373823165\n",
      "trial: 2, ldr: -0.00186336156912148\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3875972032546997, avg loss: 1.3870085847377778\n",
      "trial: 3, iter: 400, curr loss: 1.3842114210128784, avg loss: 1.3866283923387528\n",
      "trial: 3, iter: 600, curr loss: 1.3881558179855347, avg loss: 1.3866168075799943\n",
      "trial: 3, iter: 800, curr loss: 1.3870805501937866, avg loss: 1.386511073112488\n",
      "trial: 3, iter: 1000, curr loss: 1.3853322267532349, avg loss: 1.3863624423742293\n",
      "trial: 3, iter: 1200, curr loss: 1.3865386247634888, avg loss: 1.3863896435499192\n",
      "trial: 3, iter: 1400, curr loss: 1.387899398803711, avg loss: 1.3863944619894029\n",
      "trial: 3, iter: 1600, curr loss: 1.386248230934143, avg loss: 1.3864143896102905\n",
      "trial: 3, iter: 1800, curr loss: 1.3871740102767944, avg loss: 1.3863482177257538\n",
      "trial: 3, iter: 2000, curr loss: 1.3862805366516113, avg loss: 1.3863254392147064\n",
      "trial: 3, iter: 2200, curr loss: 1.388068437576294, avg loss: 1.38628793656826\n",
      "trial: 3, iter: 2400, curr loss: 1.3857765197753906, avg loss: 1.3863959699869155\n",
      "trial: 3, iter: 2600, curr loss: 1.385716438293457, avg loss: 1.3863766533136368\n",
      "trial: 3, iter: 2800, curr loss: 1.386317253112793, avg loss: 1.3863166058063507\n",
      "trial: 3, iter: 3000, curr loss: 1.387244701385498, avg loss: 1.3863331133127212\n",
      "trial: 3, iter: 3200, curr loss: 1.386644721031189, avg loss: 1.3863112235069275\n",
      "trial: 3, iter: 3400, curr loss: 1.3852832317352295, avg loss: 1.3863195097446441\n",
      "trial: 3, iter: 3600, curr loss: 1.3858176469802856, avg loss: 1.3864062064886093\n",
      "trial: 3, iter: 3800, curr loss: 1.3860929012298584, avg loss: 1.3863225305080413\n",
      "trial: 3, iter: 4000, curr loss: 1.3864723443984985, avg loss: 1.3863162422180175\n",
      "trial: 3, iter: 4200, curr loss: 1.3866798877716064, avg loss: 1.3863320207595826\n",
      "trial: 3, iter: 4400, curr loss: 1.386189579963684, avg loss: 1.3863042384386062\n",
      "trial: 3, iter: 4600, curr loss: 1.3863554000854492, avg loss: 1.3863211739063264\n",
      "trial: 3, iter: 4800, curr loss: 1.3867384195327759, avg loss: 1.3862912273406982\n",
      "trial: 3, iter: 5000, curr loss: 1.3864408731460571, avg loss: 1.3863309371471404\n",
      "trial: 3, iter: 5200, curr loss: 1.3866618871688843, avg loss: 1.386321598291397\n",
      "trial: 3, iter: 5400, curr loss: 1.3860127925872803, avg loss: 1.3863709712028502\n",
      "trial: 3, iter: 5600, curr loss: 1.3862433433532715, avg loss: 1.386354026198387\n",
      "trial: 3, iter: 5800, curr loss: 1.3863084316253662, avg loss: 1.386316744685173\n",
      "trial: 3, iter: 6000, curr loss: 1.3862254619598389, avg loss: 1.3862833327054978\n",
      "trial: 3, iter: 6200, curr loss: 1.3862223625183105, avg loss: 1.3863259989023209\n",
      "trial: 3, ldr: 0.00022419031301978976\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3853442668914795, avg loss: 1.3877331399917603\n",
      "trial: 4, iter: 400, curr loss: 1.386285662651062, avg loss: 1.3867550295591355\n",
      "trial: 4, iter: 600, curr loss: 1.387844443321228, avg loss: 1.3866796386241913\n",
      "trial: 4, iter: 800, curr loss: 1.3885352611541748, avg loss: 1.386638070344925\n",
      "trial: 4, iter: 1000, curr loss: 1.386181116104126, avg loss: 1.3865548515319823\n",
      "trial: 4, iter: 1200, curr loss: 1.3870153427124023, avg loss: 1.3864287954568864\n",
      "trial: 4, iter: 1400, curr loss: 1.3865885734558105, avg loss: 1.3863580107688904\n",
      "trial: 4, iter: 1600, curr loss: 1.3880950212478638, avg loss: 1.3864102005958556\n",
      "trial: 4, iter: 1800, curr loss: 1.3843574523925781, avg loss: 1.3863586729764938\n",
      "trial: 4, iter: 2000, curr loss: 1.3881425857543945, avg loss: 1.3864168512821198\n",
      "trial: 4, iter: 2200, curr loss: 1.3876160383224487, avg loss: 1.3864086347818374\n",
      "trial: 4, iter: 2400, curr loss: 1.386391043663025, avg loss: 1.3864186722040177\n",
      "trial: 4, iter: 2600, curr loss: 1.3855630159378052, avg loss: 1.3863438493013382\n",
      "trial: 4, iter: 2800, curr loss: 1.3866195678710938, avg loss: 1.3864287918806075\n",
      "trial: 4, iter: 3000, curr loss: 1.3867628574371338, avg loss: 1.3863718336820603\n",
      "trial: 4, iter: 3200, curr loss: 1.3865954875946045, avg loss: 1.3863391375541687\n",
      "trial: 4, iter: 3400, curr loss: 1.3863646984100342, avg loss: 1.3863710957765578\n",
      "trial: 4, iter: 3600, curr loss: 1.3859879970550537, avg loss: 1.3863251686096192\n",
      "trial: 4, iter: 3800, curr loss: 1.3872864246368408, avg loss: 1.3863134747743606\n",
      "trial: 4, iter: 4000, curr loss: 1.3857595920562744, avg loss: 1.3863680160045624\n",
      "trial: 4, iter: 4200, curr loss: 1.3862249851226807, avg loss: 1.3863479602336883\n",
      "trial: 4, iter: 4400, curr loss: 1.3867954015731812, avg loss: 1.3863267916440964\n",
      "trial: 4, iter: 4600, curr loss: 1.3864027261734009, avg loss: 1.3863091534376144\n",
      "trial: 4, iter: 4800, curr loss: 1.3862019777297974, avg loss: 1.3863213270902635\n",
      "trial: 4, iter: 5000, curr loss: 1.3851711750030518, avg loss: 1.3863279634714127\n",
      "trial: 4, iter: 5200, curr loss: 1.3861085176467896, avg loss: 1.3864555835723877\n",
      "trial: 4, iter: 5400, curr loss: 1.386246681213379, avg loss: 1.3863569229841233\n",
      "trial: 4, iter: 5600, curr loss: 1.3870038986206055, avg loss: 1.3863254415988921\n",
      "trial: 4, iter: 5800, curr loss: 1.386155605316162, avg loss: 1.3863126468658447\n",
      "trial: 4, iter: 6000, curr loss: 1.3861910104751587, avg loss: 1.386324889063835\n",
      "trial: 4, iter: 6200, curr loss: 1.3863186836242676, avg loss: 1.3863202649354935\n",
      "trial: 4, ldr: 0.0024453368969261646\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3863831758499146, avg loss: 1.387209303379059\n",
      "trial: 5, iter: 400, curr loss: 1.3847829103469849, avg loss: 1.3866603165864944\n",
      "trial: 5, iter: 600, curr loss: 1.3867583274841309, avg loss: 1.3865919536352158\n",
      "trial: 5, iter: 800, curr loss: 1.3843920230865479, avg loss: 1.3865834766626357\n",
      "trial: 5, iter: 1000, curr loss: 1.3869152069091797, avg loss: 1.3866051840782165\n",
      "trial: 5, iter: 1200, curr loss: 1.3870372772216797, avg loss: 1.3864623963832856\n",
      "trial: 5, iter: 1400, curr loss: 1.3869658708572388, avg loss: 1.3864899384975433\n",
      "trial: 5, iter: 1600, curr loss: 1.3863716125488281, avg loss: 1.3864817959070206\n",
      "trial: 5, iter: 1800, curr loss: 1.3860201835632324, avg loss: 1.386596782207489\n",
      "trial: 5, iter: 2000, curr loss: 1.3863099813461304, avg loss: 1.3864769160747528\n",
      "trial: 5, iter: 2200, curr loss: 1.386333703994751, avg loss: 1.3864081144332885\n",
      "trial: 5, iter: 2400, curr loss: 1.386357307434082, avg loss: 1.3863716959953307\n",
      "trial: 5, iter: 2600, curr loss: 1.385985255241394, avg loss: 1.3864035266637802\n",
      "trial: 5, iter: 2800, curr loss: 1.3875588178634644, avg loss: 1.3863609725236892\n",
      "trial: 5, iter: 3000, curr loss: 1.386727213859558, avg loss: 1.3863719534873962\n",
      "trial: 5, iter: 3200, curr loss: 1.385879635810852, avg loss: 1.386325085759163\n",
      "trial: 5, iter: 3400, curr loss: 1.383328914642334, avg loss: 1.3863855493068695\n",
      "trial: 5, iter: 3600, curr loss: 1.3869420289993286, avg loss: 1.3864019918441772\n",
      "trial: 5, iter: 3800, curr loss: 1.3853679895401, avg loss: 1.3862699222564698\n",
      "trial: 5, iter: 4000, curr loss: 1.3865684270858765, avg loss: 1.3863531339168549\n",
      "trial: 5, iter: 4200, curr loss: 1.3869646787643433, avg loss: 1.386353429555893\n",
      "trial: 5, iter: 4400, curr loss: 1.3862744569778442, avg loss: 1.386342740058899\n",
      "trial: 5, iter: 4600, curr loss: 1.386698603630066, avg loss: 1.386334771513939\n",
      "trial: 5, iter: 4800, curr loss: 1.386988878250122, avg loss: 1.386337194442749\n",
      "trial: 5, iter: 5000, curr loss: 1.3859238624572754, avg loss: 1.3863384062051773\n",
      "trial: 5, iter: 5200, curr loss: 1.3857835531234741, avg loss: 1.3863094490766525\n",
      "trial: 5, iter: 5400, curr loss: 1.3864473104476929, avg loss: 1.3863042253255844\n",
      "trial: 5, iter: 5600, curr loss: 1.3860830068588257, avg loss: 1.386318680047989\n",
      "trial: 5, iter: 5800, curr loss: 1.3863043785095215, avg loss: 1.3863296729326249\n",
      "trial: 5, iter: 6000, curr loss: 1.3864549398422241, avg loss: 1.3863071048259734\n",
      "trial: 5, iter: 6200, curr loss: 1.3864291906356812, avg loss: 1.3863453871011735\n",
      "trial: 5, ldr: 0.001293866545893252\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0002708796615479514\n",
      "Experiment done with data path: ./data/catNon-lin-NI_15/data.20k.dz100.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_8/data.50k.dz20.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.390894889831543, avg loss: 1.3874221712350845\n",
      "trial: 1, iter: 400, curr loss: 1.3869746923446655, avg loss: 1.3867903232574463\n",
      "trial: 1, iter: 600, curr loss: 1.3882611989974976, avg loss: 1.386545860171318\n",
      "trial: 1, iter: 800, curr loss: 1.386724591255188, avg loss: 1.3865645998716354\n",
      "trial: 1, iter: 1000, curr loss: 1.3871821165084839, avg loss: 1.3864745801687242\n",
      "trial: 1, iter: 1200, curr loss: 1.386361837387085, avg loss: 1.3864126473665237\n",
      "trial: 1, iter: 1400, curr loss: 1.3849753141403198, avg loss: 1.3863580495119094\n",
      "trial: 1, iter: 1600, curr loss: 1.385590672492981, avg loss: 1.3864613163471222\n",
      "trial: 1, iter: 1800, curr loss: 1.385998010635376, avg loss: 1.3863795453310013\n",
      "trial: 1, iter: 2000, curr loss: 1.3858423233032227, avg loss: 1.386347344517708\n",
      "trial: 1, iter: 2200, curr loss: 1.3871945142745972, avg loss: 1.3863813805580139\n",
      "trial: 1, iter: 2400, curr loss: 1.3864758014678955, avg loss: 1.3863580948114396\n",
      "trial: 1, iter: 2600, curr loss: 1.38662850856781, avg loss: 1.38641233086586\n",
      "trial: 1, iter: 2800, curr loss: 1.3871499300003052, avg loss: 1.3863455939292908\n",
      "trial: 1, iter: 3000, curr loss: 1.3872634172439575, avg loss: 1.386361363530159\n",
      "trial: 1, iter: 3200, curr loss: 1.3862775564193726, avg loss: 1.3863295197486878\n",
      "trial: 1, iter: 3400, curr loss: 1.3875621557235718, avg loss: 1.3862861454486848\n",
      "trial: 1, iter: 3600, curr loss: 1.3868354558944702, avg loss: 1.3863402342796325\n",
      "trial: 1, iter: 3800, curr loss: 1.3857492208480835, avg loss: 1.3862866121530533\n",
      "trial: 1, iter: 4000, curr loss: 1.385111927986145, avg loss: 1.386320591568947\n",
      "trial: 1, iter: 4200, curr loss: 1.3857866525650024, avg loss: 1.3863852739334106\n",
      "trial: 1, iter: 4400, curr loss: 1.3865060806274414, avg loss: 1.3863681024312973\n",
      "trial: 1, iter: 4600, curr loss: 1.3866546154022217, avg loss: 1.386304104924202\n",
      "trial: 1, iter: 4800, curr loss: 1.386757731437683, avg loss: 1.3863748842477799\n",
      "trial: 1, iter: 5000, curr loss: 1.386782169342041, avg loss: 1.386264482140541\n",
      "trial: 1, iter: 5200, curr loss: 1.3868639469146729, avg loss: 1.38636572599411\n",
      "trial: 1, iter: 5400, curr loss: 1.3863470554351807, avg loss: 1.3863160920143127\n",
      "trial: 1, iter: 5600, curr loss: 1.3866157531738281, avg loss: 1.3863787591457366\n",
      "trial: 1, iter: 5800, curr loss: 1.3875962495803833, avg loss: 1.3862642806768417\n",
      "trial: 1, iter: 6000, curr loss: 1.3855369091033936, avg loss: 1.3863250571489334\n",
      "trial: 1, iter: 6200, curr loss: 1.3858546018600464, avg loss: 1.3862770414352417\n",
      "trial: 1, iter: 6400, curr loss: 1.3858636617660522, avg loss: 1.3863010275363923\n",
      "trial: 1, iter: 6600, curr loss: 1.3860390186309814, avg loss: 1.3863318264484406\n",
      "trial: 1, iter: 6800, curr loss: 1.3859885931015015, avg loss: 1.3863491213321686\n",
      "trial: 1, iter: 7000, curr loss: 1.3863279819488525, avg loss: 1.3863622051477433\n",
      "trial: 1, iter: 7200, curr loss: 1.3862401247024536, avg loss: 1.3863439512252809\n",
      "trial: 1, iter: 7400, curr loss: 1.3862069845199585, avg loss: 1.386358522772789\n",
      "trial: 1, iter: 7600, curr loss: 1.3862429857254028, avg loss: 1.3863069754838944\n",
      "trial: 1, iter: 7800, curr loss: 1.387190580368042, avg loss: 1.386344731450081\n",
      "trial: 1, iter: 8000, curr loss: 1.3862521648406982, avg loss: 1.3863474267721176\n",
      "trial: 1, iter: 8200, curr loss: 1.3862316608428955, avg loss: 1.3863408273458482\n",
      "trial: 1, iter: 8400, curr loss: 1.3861498832702637, avg loss: 1.3863192880153656\n",
      "trial: 1, iter: 8600, curr loss: 1.3865468502044678, avg loss: 1.3863203644752502\n",
      "trial: 1, iter: 8800, curr loss: 1.3860621452331543, avg loss: 1.3863281625509263\n",
      "trial: 1, iter: 9000, curr loss: 1.3861730098724365, avg loss: 1.386361352801323\n",
      "trial: 1, iter: 9200, curr loss: 1.3858498334884644, avg loss: 1.3863419950008393\n",
      "trial: 1, iter: 9400, curr loss: 1.3859455585479736, avg loss: 1.3863133603334428\n",
      "trial: 1, iter: 9600, curr loss: 1.3859989643096924, avg loss: 1.3863259166479112\n",
      "trial: 1, iter: 9800, curr loss: 1.3861289024353027, avg loss: 1.3863006538152696\n",
      "trial: 1, iter: 10000, curr loss: 1.386285662651062, avg loss: 1.3862975591421127\n",
      "trial: 1, iter: 10200, curr loss: 1.3865890502929688, avg loss: 1.386301354765892\n",
      "trial: 1, iter: 10400, curr loss: 1.3864548206329346, avg loss: 1.3862953960895539\n",
      "trial: 1, iter: 10600, curr loss: 1.3854929208755493, avg loss: 1.3862963789701461\n",
      "trial: 1, iter: 10800, curr loss: 1.386243224143982, avg loss: 1.386315153837204\n",
      "trial: 1, iter: 11000, curr loss: 1.3863462209701538, avg loss: 1.386269934773445\n",
      "trial: 1, iter: 11200, curr loss: 1.3860409259796143, avg loss: 1.3863130527734757\n",
      "trial: 1, iter: 11400, curr loss: 1.3863074779510498, avg loss: 1.386290807723999\n",
      "trial: 1, iter: 11600, curr loss: 1.3862082958221436, avg loss: 1.3863073629140854\n",
      "trial: 1, iter: 11800, curr loss: 1.3863950967788696, avg loss: 1.3862718486785888\n",
      "trial: 1, iter: 12000, curr loss: 1.3873777389526367, avg loss: 1.3861717885732652\n",
      "trial: 1, iter: 12200, curr loss: 1.3881745338439941, avg loss: 1.3863435423374175\n",
      "trial: 1, iter: 12400, curr loss: 1.3857526779174805, avg loss: 1.3849046689271927\n",
      "trial: 1, iter: 12600, curr loss: 1.3667654991149902, avg loss: 1.3804446876049041\n",
      "trial: 1, iter: 12800, curr loss: 1.3733720779418945, avg loss: 1.3764229530096055\n",
      "trial: 1, iter: 13000, curr loss: 1.3626099824905396, avg loss: 1.3688248574733735\n",
      "trial: 1, iter: 13200, curr loss: 1.3511650562286377, avg loss: 1.3639145982265473\n",
      "trial: 1, iter: 13400, curr loss: 1.3721835613250732, avg loss: 1.3601105201244355\n",
      "trial: 1, iter: 13600, curr loss: 1.347286581993103, avg loss: 1.3586568856239318\n",
      "trial: 1, iter: 13800, curr loss: 1.3358798027038574, avg loss: 1.3567320454120635\n",
      "trial: 1, iter: 14000, curr loss: 1.3683016300201416, avg loss: 1.354515233039856\n",
      "trial: 1, iter: 14200, curr loss: 1.3466922044754028, avg loss: 1.3573518961668014\n",
      "trial: 1, iter: 14400, curr loss: 1.3395285606384277, avg loss: 1.3534241706132888\n",
      "trial: 1, iter: 14600, curr loss: 1.3327102661132812, avg loss: 1.3480479085445405\n",
      "trial: 1, iter: 14800, curr loss: 1.3273426294326782, avg loss: 1.3473559784889222\n",
      "trial: 1, iter: 15000, curr loss: 1.330016016960144, avg loss: 1.3430420035123825\n",
      "trial: 1, iter: 15200, curr loss: 1.354475975036621, avg loss: 1.3398067981004715\n",
      "trial: 1, iter: 15400, curr loss: 1.331809163093567, avg loss: 1.3367219454050063\n",
      "trial: 1, iter: 15600, curr loss: 1.3249640464782715, avg loss: 1.3335271722078323\n",
      "trial: 1, ldr: 0.3322688341140747\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849784135818481, avg loss: 1.387397322654724\n",
      "trial: 2, iter: 400, curr loss: 1.387639045715332, avg loss: 1.387026576399803\n",
      "trial: 2, iter: 600, curr loss: 1.388877034187317, avg loss: 1.3865413999557494\n",
      "trial: 2, iter: 800, curr loss: 1.384879469871521, avg loss: 1.3865834933519363\n",
      "trial: 2, iter: 1000, curr loss: 1.3874306678771973, avg loss: 1.3865367245674134\n",
      "trial: 2, iter: 1200, curr loss: 1.3869740962982178, avg loss: 1.3864612299203873\n",
      "trial: 2, iter: 1400, curr loss: 1.3868132829666138, avg loss: 1.38638218998909\n",
      "trial: 2, iter: 1600, curr loss: 1.3867968320846558, avg loss: 1.3863449162244796\n",
      "trial: 2, iter: 1800, curr loss: 1.386378526687622, avg loss: 1.3863790678977965\n",
      "trial: 2, iter: 2000, curr loss: 1.3866057395935059, avg loss: 1.3862945795059205\n",
      "trial: 2, iter: 2200, curr loss: 1.3859471082687378, avg loss: 1.386327857375145\n",
      "trial: 2, iter: 2400, curr loss: 1.385748028755188, avg loss: 1.3863798505067826\n",
      "trial: 2, iter: 2600, curr loss: 1.386150598526001, avg loss: 1.3863357788324355\n",
      "trial: 2, iter: 2800, curr loss: 1.3866171836853027, avg loss: 1.386336596608162\n",
      "trial: 2, iter: 3000, curr loss: 1.3857364654541016, avg loss: 1.3862773776054382\n",
      "trial: 2, iter: 3200, curr loss: 1.3866190910339355, avg loss: 1.3863483887910844\n",
      "trial: 2, iter: 3400, curr loss: 1.3847564458847046, avg loss: 1.386266313791275\n",
      "trial: 2, iter: 3600, curr loss: 1.3867496252059937, avg loss: 1.3863559973239898\n",
      "trial: 2, iter: 3800, curr loss: 1.3862112760543823, avg loss: 1.3862792664766312\n",
      "trial: 2, iter: 4000, curr loss: 1.3869153261184692, avg loss: 1.3863638955354691\n",
      "trial: 2, iter: 4200, curr loss: 1.3861122131347656, avg loss: 1.386389491558075\n",
      "trial: 2, iter: 4400, curr loss: 1.3868464231491089, avg loss: 1.3863552188873292\n",
      "trial: 2, iter: 4600, curr loss: 1.386359453201294, avg loss: 1.3864035046100616\n",
      "trial: 2, iter: 4800, curr loss: 1.3865952491760254, avg loss: 1.3862885957956315\n",
      "trial: 2, iter: 5000, curr loss: 1.3863496780395508, avg loss: 1.3863433599472046\n",
      "trial: 2, iter: 5200, curr loss: 1.385843276977539, avg loss: 1.3862673062086106\n",
      "trial: 2, iter: 5400, curr loss: 1.3866169452667236, avg loss: 1.3863059651851655\n",
      "trial: 2, iter: 5600, curr loss: 1.3864476680755615, avg loss: 1.3863726019859315\n",
      "trial: 2, iter: 5800, curr loss: 1.3863205909729004, avg loss: 1.3863185316324234\n",
      "trial: 2, iter: 6000, curr loss: 1.3862003087997437, avg loss: 1.3862679487466811\n",
      "trial: 2, iter: 6200, curr loss: 1.3862286806106567, avg loss: 1.3863417100906372\n",
      "trial: 2, iter: 6400, curr loss: 1.3869590759277344, avg loss: 1.386266570687294\n",
      "trial: 2, iter: 6600, curr loss: 1.3856744766235352, avg loss: 1.3863374012708665\n",
      "trial: 2, iter: 6800, curr loss: 1.3862687349319458, avg loss: 1.3863245898485184\n",
      "trial: 2, iter: 7000, curr loss: 1.3864061832427979, avg loss: 1.386354477405548\n",
      "trial: 2, iter: 7200, curr loss: 1.386229157447815, avg loss: 1.3863401842117309\n",
      "trial: 2, iter: 7400, curr loss: 1.3866502046585083, avg loss: 1.3862739193439484\n",
      "trial: 2, iter: 7600, curr loss: 1.3859176635742188, avg loss: 1.3863376688957214\n",
      "trial: 2, iter: 7800, curr loss: 1.3866944313049316, avg loss: 1.3863023275136948\n",
      "trial: 2, iter: 8000, curr loss: 1.3868569135665894, avg loss: 1.386330788731575\n",
      "trial: 2, iter: 8200, curr loss: 1.3863581418991089, avg loss: 1.3863145416975022\n",
      "trial: 2, iter: 8400, curr loss: 1.3865262269973755, avg loss: 1.3863542532920838\n",
      "trial: 2, iter: 8600, curr loss: 1.3863343000411987, avg loss: 1.386331176161766\n",
      "trial: 2, iter: 8800, curr loss: 1.386449933052063, avg loss: 1.3863039374351502\n",
      "trial: 2, iter: 9000, curr loss: 1.3861172199249268, avg loss: 1.386300801038742\n",
      "trial: 2, iter: 9200, curr loss: 1.3867647647857666, avg loss: 1.3862976866960526\n",
      "trial: 2, iter: 9400, curr loss: 1.3857954740524292, avg loss: 1.3863189697265625\n",
      "trial: 2, iter: 9600, curr loss: 1.3862426280975342, avg loss: 1.386310783624649\n",
      "trial: 2, iter: 9800, curr loss: 1.3862369060516357, avg loss: 1.386300922036171\n",
      "trial: 2, iter: 10000, curr loss: 1.3866920471191406, avg loss: 1.3862769460678102\n",
      "trial: 2, iter: 10200, curr loss: 1.3865894079208374, avg loss: 1.386299923658371\n",
      "trial: 2, iter: 10400, curr loss: 1.3865768909454346, avg loss: 1.3863682228326797\n",
      "trial: 2, iter: 10600, curr loss: 1.386083960533142, avg loss: 1.386272487640381\n",
      "trial: 2, iter: 10800, curr loss: 1.3871955871582031, avg loss: 1.3862069088220597\n",
      "trial: 2, iter: 11000, curr loss: 1.382568597793579, avg loss: 1.3861071968078613\n",
      "trial: 2, iter: 11200, curr loss: 1.3850449323654175, avg loss: 1.3839973515272141\n",
      "trial: 2, iter: 11400, curr loss: 1.3758184909820557, avg loss: 1.3803803473711014\n",
      "trial: 2, iter: 11600, curr loss: 1.3778412342071533, avg loss: 1.3770270675420762\n",
      "trial: 2, iter: 11800, curr loss: 1.3702149391174316, avg loss: 1.3765665578842163\n",
      "trial: 2, iter: 12000, curr loss: 1.374467134475708, avg loss: 1.3747790426015853\n",
      "trial: 2, iter: 12200, curr loss: 1.3640122413635254, avg loss: 1.373865578174591\n",
      "trial: 2, iter: 12400, curr loss: 1.3755970001220703, avg loss: 1.3728038710355759\n",
      "trial: 2, iter: 12600, curr loss: 1.3612512350082397, avg loss: 1.3674369782209397\n",
      "trial: 2, iter: 12800, curr loss: 1.3627246618270874, avg loss: 1.3614666110277176\n",
      "trial: 2, iter: 13000, curr loss: 1.3408366441726685, avg loss: 1.3529936569929122\n",
      "trial: 2, iter: 13200, curr loss: 1.3459815979003906, avg loss: 1.3491417998075486\n",
      "trial: 2, iter: 13400, curr loss: 1.3324247598648071, avg loss: 1.3439869999885559\n",
      "trial: 2, iter: 13600, curr loss: 1.3557837009429932, avg loss: 1.341554153561592\n",
      "trial: 2, iter: 13800, curr loss: 1.362919807434082, avg loss: 1.3391295230388642\n",
      "trial: 2, iter: 14000, curr loss: 1.3247076272964478, avg loss: 1.3390519541502\n",
      "trial: 2, iter: 14200, curr loss: 1.3214824199676514, avg loss: 1.3344955444335938\n",
      "trial: 2, iter: 14400, curr loss: 1.3289321660995483, avg loss: 1.3322912681102752\n",
      "trial: 2, iter: 14600, curr loss: 1.3041859865188599, avg loss: 1.3307154470682143\n",
      "trial: 2, iter: 14800, curr loss: 1.3235942125320435, avg loss: 1.3339078825712205\n",
      "trial: 2, iter: 15000, curr loss: 1.341919183731079, avg loss: 1.329964264035225\n",
      "trial: 2, iter: 15200, curr loss: 1.3377971649169922, avg loss: 1.327885204553604\n",
      "trial: 2, iter: 15400, curr loss: 1.3032211065292358, avg loss: 1.327653732895851\n",
      "trial: 2, iter: 15600, curr loss: 1.3324075937271118, avg loss: 1.3262574690580369\n",
      "trial: 2, ldr: 0.35674235224723816\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3857166767120361, avg loss: 1.387278637290001\n",
      "trial: 3, iter: 400, curr loss: 1.3816343545913696, avg loss: 1.3868469840288162\n",
      "trial: 3, iter: 600, curr loss: 1.3850022554397583, avg loss: 1.3869090479612352\n",
      "trial: 3, iter: 800, curr loss: 1.386884093284607, avg loss: 1.386595566868782\n",
      "trial: 3, iter: 1000, curr loss: 1.3858212232589722, avg loss: 1.386451998949051\n",
      "trial: 3, iter: 1200, curr loss: 1.388055682182312, avg loss: 1.3864621543884277\n",
      "trial: 3, iter: 1400, curr loss: 1.3872135877609253, avg loss: 1.3863259094953537\n",
      "trial: 3, iter: 1600, curr loss: 1.387786626815796, avg loss: 1.3863879883289336\n",
      "trial: 3, iter: 1800, curr loss: 1.387831211090088, avg loss: 1.3864076656103135\n",
      "trial: 3, iter: 2000, curr loss: 1.3862508535385132, avg loss: 1.3864451545476912\n",
      "trial: 3, iter: 2200, curr loss: 1.3851591348648071, avg loss: 1.3863653659820556\n",
      "trial: 3, iter: 2400, curr loss: 1.3865116834640503, avg loss: 1.386306169629097\n",
      "trial: 3, iter: 2600, curr loss: 1.3865187168121338, avg loss: 1.3862210297584534\n",
      "trial: 3, iter: 2800, curr loss: 1.385532259941101, avg loss: 1.3864683532714843\n",
      "trial: 3, iter: 3000, curr loss: 1.3865431547164917, avg loss: 1.3862924021482468\n",
      "trial: 3, iter: 3200, curr loss: 1.3868988752365112, avg loss: 1.3863958233594895\n",
      "trial: 3, iter: 3400, curr loss: 1.386500358581543, avg loss: 1.3863563132286072\n",
      "trial: 3, iter: 3600, curr loss: 1.3863481283187866, avg loss: 1.3863120985031128\n",
      "trial: 3, iter: 3800, curr loss: 1.3861351013183594, avg loss: 1.3863754242658615\n",
      "trial: 3, iter: 4000, curr loss: 1.3862518072128296, avg loss: 1.3863599878549575\n",
      "trial: 3, iter: 4200, curr loss: 1.386227011680603, avg loss: 1.3863571459054946\n",
      "trial: 3, iter: 4400, curr loss: 1.3864879608154297, avg loss: 1.3862855207920075\n",
      "trial: 3, iter: 4600, curr loss: 1.3861281871795654, avg loss: 1.3863030588626861\n",
      "trial: 3, iter: 4800, curr loss: 1.3862687349319458, avg loss: 1.3863341826200486\n",
      "trial: 3, iter: 5000, curr loss: 1.3863121271133423, avg loss: 1.3863870161771774\n",
      "trial: 3, iter: 5200, curr loss: 1.3860877752304077, avg loss: 1.38632129073143\n",
      "trial: 3, iter: 5400, curr loss: 1.3869794607162476, avg loss: 1.3863171368837357\n",
      "trial: 3, iter: 5600, curr loss: 1.385623574256897, avg loss: 1.3863993513584136\n",
      "trial: 3, iter: 5800, curr loss: 1.386248230934143, avg loss: 1.3863125216960908\n",
      "trial: 3, iter: 6000, curr loss: 1.3865149021148682, avg loss: 1.3863318735361099\n",
      "trial: 3, iter: 6200, curr loss: 1.3876597881317139, avg loss: 1.386283985376358\n",
      "trial: 3, iter: 6400, curr loss: 1.3855665922164917, avg loss: 1.3863484728336335\n",
      "trial: 3, iter: 6600, curr loss: 1.3871848583221436, avg loss: 1.386300221681595\n",
      "trial: 3, iter: 6800, curr loss: 1.3860124349594116, avg loss: 1.3862951892614364\n",
      "trial: 3, iter: 7000, curr loss: 1.3857370615005493, avg loss: 1.3862993955612182\n",
      "trial: 3, iter: 7200, curr loss: 1.3860961198806763, avg loss: 1.3863289958238603\n",
      "trial: 3, iter: 7400, curr loss: 1.3862974643707275, avg loss: 1.386300265789032\n",
      "trial: 3, iter: 7600, curr loss: 1.3858275413513184, avg loss: 1.3862995690107345\n",
      "trial: 3, iter: 7800, curr loss: 1.3865535259246826, avg loss: 1.3863680863380432\n",
      "trial: 3, iter: 8000, curr loss: 1.386735439300537, avg loss: 1.3863045352697372\n",
      "trial: 3, iter: 8200, curr loss: 1.3852715492248535, avg loss: 1.3862786144018173\n",
      "trial: 3, iter: 8400, curr loss: 1.3862122297286987, avg loss: 1.3862738382816315\n",
      "trial: 3, iter: 8600, curr loss: 1.3858191967010498, avg loss: 1.3863019049167633\n",
      "trial: 3, iter: 8800, curr loss: 1.3861913681030273, avg loss: 1.386320253610611\n",
      "trial: 3, iter: 9000, curr loss: 1.386720895767212, avg loss: 1.386198210120201\n",
      "trial: 3, iter: 9200, curr loss: 1.387453556060791, avg loss: 1.385765089392662\n",
      "trial: 3, iter: 9400, curr loss: 1.375278353691101, avg loss: 1.3834968465566635\n",
      "trial: 3, iter: 9600, curr loss: 1.3721814155578613, avg loss: 1.3794527637958527\n",
      "trial: 3, iter: 9800, curr loss: 1.3686110973358154, avg loss: 1.376588494181633\n",
      "trial: 3, iter: 10000, curr loss: 1.3915544748306274, avg loss: 1.3699165999889373\n",
      "trial: 3, iter: 10200, curr loss: 1.364128828048706, avg loss: 1.3639698344469071\n",
      "trial: 3, iter: 10400, curr loss: 1.364984393119812, avg loss: 1.361375777721405\n",
      "trial: 3, iter: 10600, curr loss: 1.362187385559082, avg loss: 1.3583953553438186\n",
      "trial: 3, iter: 10800, curr loss: 1.3728210926055908, avg loss: 1.3559467500448228\n",
      "trial: 3, iter: 11000, curr loss: 1.3619097471237183, avg loss: 1.3565686094760894\n",
      "trial: 3, iter: 11200, curr loss: 1.3636728525161743, avg loss: 1.352347195148468\n",
      "trial: 3, iter: 11400, curr loss: 1.3620364665985107, avg loss: 1.3519532233476639\n",
      "trial: 3, iter: 11600, curr loss: 1.3718005418777466, avg loss: 1.3466225367784501\n",
      "trial: 3, iter: 11800, curr loss: 1.3165476322174072, avg loss: 1.34099977850914\n",
      "trial: 3, iter: 12000, curr loss: 1.3286062479019165, avg loss: 1.3365333569049835\n",
      "trial: 3, iter: 12200, curr loss: 1.3148088455200195, avg loss: 1.3307728165388106\n",
      "trial: 3, iter: 12400, curr loss: 1.30995512008667, avg loss: 1.3302509659528732\n",
      "trial: 3, iter: 12600, curr loss: 1.3393489122390747, avg loss: 1.3272955125570298\n",
      "trial: 3, iter: 12800, curr loss: 1.3470538854599, avg loss: 1.3247194349765778\n",
      "trial: 3, iter: 13000, curr loss: 1.3330820798873901, avg loss: 1.3232880675792693\n",
      "trial: 3, iter: 13200, curr loss: 1.3252633810043335, avg loss: 1.3234130018949508\n",
      "trial: 3, iter: 13400, curr loss: 1.33641517162323, avg loss: 1.3229355859756469\n",
      "trial: 3, iter: 13600, curr loss: 1.3069992065429688, avg loss: 1.3222141408920287\n",
      "trial: 3, iter: 13800, curr loss: 1.3047946691513062, avg loss: 1.3195330393314362\n",
      "trial: 3, iter: 14000, curr loss: 1.3196704387664795, avg loss: 1.3192631071805954\n",
      "trial: 3, iter: 14200, curr loss: 1.3250129222869873, avg loss: 1.320372434258461\n",
      "trial: 3, iter: 14400, curr loss: 1.3042323589324951, avg loss: 1.3205857020616532\n",
      "trial: 3, iter: 14600, curr loss: 1.3339415788650513, avg loss: 1.320571004152298\n",
      "trial: 3, iter: 14800, curr loss: 1.3271485567092896, avg loss: 1.3175881159305574\n",
      "trial: 3, iter: 15000, curr loss: 1.3347352743148804, avg loss: 1.3182284837961198\n",
      "trial: 3, iter: 15200, curr loss: 1.3238974809646606, avg loss: 1.3169260048866271\n",
      "trial: 3, iter: 15400, curr loss: 1.3341237306594849, avg loss: 1.3189312690496444\n",
      "trial: 3, iter: 15600, curr loss: 1.3127981424331665, avg loss: 1.3184199011325837\n",
      "trial: 3, ldr: 0.42577797174453735\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3855640888214111, avg loss: 1.386994137763977\n",
      "trial: 4, iter: 400, curr loss: 1.3878872394561768, avg loss: 1.387063997387886\n",
      "trial: 4, iter: 600, curr loss: 1.3876333236694336, avg loss: 1.3867317402362824\n",
      "trial: 4, iter: 800, curr loss: 1.3860033750534058, avg loss: 1.3864608955383302\n",
      "trial: 4, iter: 1000, curr loss: 1.3865792751312256, avg loss: 1.3865513306856156\n",
      "trial: 4, iter: 1200, curr loss: 1.3862428665161133, avg loss: 1.386489701271057\n",
      "trial: 4, iter: 1400, curr loss: 1.3872146606445312, avg loss: 1.386394219994545\n",
      "trial: 4, iter: 1600, curr loss: 1.3877151012420654, avg loss: 1.3863509047031402\n",
      "trial: 4, iter: 1800, curr loss: 1.3871248960494995, avg loss: 1.3863959854841232\n",
      "trial: 4, iter: 2000, curr loss: 1.3860585689544678, avg loss: 1.3863792538642883\n",
      "trial: 4, iter: 2200, curr loss: 1.3869624137878418, avg loss: 1.3863968992233275\n",
      "trial: 4, iter: 2400, curr loss: 1.3855388164520264, avg loss: 1.3862880319356918\n",
      "trial: 4, iter: 2600, curr loss: 1.3867554664611816, avg loss: 1.3863597416877746\n",
      "trial: 4, iter: 2800, curr loss: 1.3874022960662842, avg loss: 1.3862930065393448\n",
      "trial: 4, iter: 3000, curr loss: 1.3874555826187134, avg loss: 1.386274031996727\n",
      "trial: 4, iter: 3200, curr loss: 1.3856149911880493, avg loss: 1.3863619256019593\n",
      "trial: 4, iter: 3400, curr loss: 1.386122465133667, avg loss: 1.3863297379016877\n",
      "trial: 4, iter: 3600, curr loss: 1.3854827880859375, avg loss: 1.3863537895679474\n",
      "trial: 4, iter: 3800, curr loss: 1.3869152069091797, avg loss: 1.3863971918821334\n",
      "trial: 4, iter: 4000, curr loss: 1.3852232694625854, avg loss: 1.3862957906723024\n",
      "trial: 4, iter: 4200, curr loss: 1.385451316833496, avg loss: 1.3862976461648941\n",
      "trial: 4, iter: 4400, curr loss: 1.3865528106689453, avg loss: 1.3863753873109816\n",
      "trial: 4, iter: 4600, curr loss: 1.3844115734100342, avg loss: 1.3863269537687302\n",
      "trial: 4, iter: 4800, curr loss: 1.3859083652496338, avg loss: 1.3863649773597717\n",
      "trial: 4, iter: 5000, curr loss: 1.3861017227172852, avg loss: 1.3862755686044692\n",
      "trial: 4, iter: 5200, curr loss: 1.386032223701477, avg loss: 1.3863125652074815\n",
      "trial: 4, iter: 5400, curr loss: 1.3871768712997437, avg loss: 1.3863618135452271\n",
      "trial: 4, iter: 5600, curr loss: 1.38602614402771, avg loss: 1.3863623774051665\n",
      "trial: 4, iter: 5800, curr loss: 1.38619863986969, avg loss: 1.3863537108898163\n",
      "trial: 4, iter: 6000, curr loss: 1.3865141868591309, avg loss: 1.3862926542758942\n",
      "trial: 4, iter: 6200, curr loss: 1.3866325616836548, avg loss: 1.3863336610794068\n",
      "trial: 4, iter: 6400, curr loss: 1.3864028453826904, avg loss: 1.386364027261734\n",
      "trial: 4, iter: 6600, curr loss: 1.3856045007705688, avg loss: 1.386272800564766\n",
      "trial: 4, iter: 6800, curr loss: 1.3858888149261475, avg loss: 1.3862785190343856\n",
      "trial: 4, iter: 7000, curr loss: 1.3868050575256348, avg loss: 1.3862795174121856\n",
      "trial: 4, iter: 7200, curr loss: 1.3850857019424438, avg loss: 1.3861605286598206\n",
      "trial: 4, iter: 7400, curr loss: 1.3831331729888916, avg loss: 1.3849208813905716\n",
      "trial: 4, iter: 7600, curr loss: 1.3703653812408447, avg loss: 1.379556543827057\n",
      "trial: 4, iter: 7800, curr loss: 1.356207013130188, avg loss: 1.3681408500671386\n",
      "trial: 4, iter: 8000, curr loss: 1.3623855113983154, avg loss: 1.3598453557491303\n",
      "trial: 4, iter: 8200, curr loss: 1.3544385433197021, avg loss: 1.358332757949829\n",
      "trial: 4, iter: 8400, curr loss: 1.3327945470809937, avg loss: 1.3555239152908325\n",
      "trial: 4, iter: 8600, curr loss: 1.3510419130325317, avg loss: 1.3551591980457305\n",
      "trial: 4, iter: 8800, curr loss: 1.335153579711914, avg loss: 1.3530212700366975\n",
      "trial: 4, iter: 9000, curr loss: 1.3361060619354248, avg loss: 1.3495451927185058\n",
      "trial: 4, iter: 9200, curr loss: 1.3434960842132568, avg loss: 1.3435006421804427\n",
      "trial: 4, iter: 9400, curr loss: 1.3553671836853027, avg loss: 1.340477077960968\n",
      "trial: 4, iter: 9600, curr loss: 1.3559519052505493, avg loss: 1.3348517578840255\n",
      "trial: 4, iter: 9800, curr loss: 1.3205313682556152, avg loss: 1.3324851709604264\n",
      "trial: 4, iter: 10000, curr loss: 1.3336570262908936, avg loss: 1.3306243526935577\n",
      "trial: 4, iter: 10200, curr loss: 1.3380560874938965, avg loss: 1.328058272600174\n",
      "trial: 4, iter: 10400, curr loss: 1.3331944942474365, avg loss: 1.3262755662202834\n",
      "trial: 4, iter: 10600, curr loss: 1.319139003753662, avg loss: 1.32809353351593\n",
      "trial: 4, iter: 10800, curr loss: 1.3172264099121094, avg loss: 1.3237547796964646\n",
      "trial: 4, iter: 11000, curr loss: 1.329243779182434, avg loss: 1.3221238213777542\n",
      "trial: 4, iter: 11200, curr loss: 1.3120660781860352, avg loss: 1.3235314226150512\n",
      "trial: 4, iter: 11400, curr loss: 1.3158918619155884, avg loss: 1.319981138110161\n",
      "trial: 4, iter: 11600, curr loss: 1.3280797004699707, avg loss: 1.3215763515233994\n",
      "trial: 4, iter: 11800, curr loss: 1.3366458415985107, avg loss: 1.3191637754440309\n",
      "trial: 4, iter: 12000, curr loss: 1.343002200126648, avg loss: 1.3202870464324952\n",
      "trial: 4, iter: 12200, curr loss: 1.306148648262024, avg loss: 1.3216970676183701\n",
      "trial: 4, iter: 12400, curr loss: 1.3138614892959595, avg loss: 1.3188609236478805\n",
      "trial: 4, iter: 12600, curr loss: 1.3178553581237793, avg loss: 1.3178528320789338\n",
      "trial: 4, iter: 12800, curr loss: 1.3337293863296509, avg loss: 1.3199278217554093\n",
      "trial: 4, iter: 13000, curr loss: 1.3199644088745117, avg loss: 1.3149331986904145\n",
      "trial: 4, iter: 13200, curr loss: 1.3217819929122925, avg loss: 1.317649861574173\n",
      "trial: 4, iter: 13400, curr loss: 1.2937241792678833, avg loss: 1.317149547934532\n",
      "trial: 4, iter: 13600, curr loss: 1.2901510000228882, avg loss: 1.317551019191742\n",
      "trial: 4, iter: 13800, curr loss: 1.3412270545959473, avg loss: 1.3162726455926894\n",
      "trial: 4, iter: 14000, curr loss: 1.3368494510650635, avg loss: 1.3149800455570222\n",
      "trial: 4, iter: 14200, curr loss: 1.3343682289123535, avg loss: 1.3183188706636428\n",
      "trial: 4, iter: 14400, curr loss: 1.2966549396514893, avg loss: 1.3179675948619842\n",
      "trial: 4, iter: 14600, curr loss: 1.3007659912109375, avg loss: 1.31807690680027\n",
      "trial: 4, iter: 14800, curr loss: 1.2714645862579346, avg loss: 1.317605185508728\n",
      "trial: 4, iter: 15000, curr loss: 1.3177788257598877, avg loss: 1.3169031661748887\n",
      "trial: 4, iter: 15200, curr loss: 1.2865792512893677, avg loss: 1.3151697593927383\n",
      "trial: 4, iter: 15400, curr loss: 1.3073786497116089, avg loss: 1.3152809178829192\n",
      "trial: 4, iter: 15600, curr loss: 1.3139399290084839, avg loss: 1.314980536699295\n",
      "trial: 4, ldr: 0.3836885690689087\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882472515106201, avg loss: 1.3873835176229476\n",
      "trial: 5, iter: 400, curr loss: 1.3870402574539185, avg loss: 1.3869005131721497\n",
      "trial: 5, iter: 600, curr loss: 1.3858312368392944, avg loss: 1.386623781323433\n",
      "trial: 5, iter: 800, curr loss: 1.3869565725326538, avg loss: 1.3865085983276366\n",
      "trial: 5, iter: 1000, curr loss: 1.3869068622589111, avg loss: 1.3864200085401535\n",
      "trial: 5, iter: 1200, curr loss: 1.3868958950042725, avg loss: 1.3863518446683885\n",
      "trial: 5, iter: 1400, curr loss: 1.386544942855835, avg loss: 1.3863674783706665\n",
      "trial: 5, iter: 1600, curr loss: 1.3859734535217285, avg loss: 1.3863755774497986\n",
      "trial: 5, iter: 1800, curr loss: 1.3869026899337769, avg loss: 1.3863067018985749\n",
      "trial: 5, iter: 2000, curr loss: 1.386669635772705, avg loss: 1.3864016032218933\n",
      "trial: 5, iter: 2200, curr loss: 1.3871550559997559, avg loss: 1.3863601505756378\n",
      "trial: 5, iter: 2400, curr loss: 1.3852416276931763, avg loss: 1.3863516116142274\n",
      "trial: 5, iter: 2600, curr loss: 1.3862780332565308, avg loss: 1.3862962478399277\n",
      "trial: 5, iter: 2800, curr loss: 1.3872442245483398, avg loss: 1.3863525891304016\n",
      "trial: 5, iter: 3000, curr loss: 1.3862086534500122, avg loss: 1.386289787888527\n",
      "trial: 5, iter: 3200, curr loss: 1.3862065076828003, avg loss: 1.386371790766716\n",
      "trial: 5, iter: 3400, curr loss: 1.3871729373931885, avg loss: 1.3864106118679047\n",
      "trial: 5, iter: 3600, curr loss: 1.386519193649292, avg loss: 1.386334663629532\n",
      "trial: 5, iter: 3800, curr loss: 1.3857885599136353, avg loss: 1.3863672083616256\n",
      "trial: 5, iter: 4000, curr loss: 1.3864434957504272, avg loss: 1.3863144475221634\n",
      "trial: 5, iter: 4200, curr loss: 1.3862862586975098, avg loss: 1.386371511220932\n",
      "trial: 5, iter: 4400, curr loss: 1.386271357536316, avg loss: 1.386331815123558\n",
      "trial: 5, iter: 4600, curr loss: 1.387025237083435, avg loss: 1.386297317147255\n",
      "trial: 5, iter: 4800, curr loss: 1.386154294013977, avg loss: 1.3862908011674882\n",
      "trial: 5, iter: 5000, curr loss: 1.3855299949645996, avg loss: 1.3862140852212905\n",
      "trial: 5, iter: 5200, curr loss: 1.3876034021377563, avg loss: 1.3849026983976365\n",
      "trial: 5, iter: 5400, curr loss: 1.3774081468582153, avg loss: 1.3798138886690139\n",
      "trial: 5, iter: 5600, curr loss: 1.3788366317749023, avg loss: 1.374028690457344\n",
      "trial: 5, iter: 5800, curr loss: 1.3616772890090942, avg loss: 1.3677568912506104\n",
      "trial: 5, iter: 6000, curr loss: 1.3370553255081177, avg loss: 1.3620850157737732\n",
      "trial: 5, iter: 6200, curr loss: 1.341759443283081, avg loss: 1.3553022438287734\n",
      "trial: 5, iter: 6400, curr loss: 1.355379581451416, avg loss: 1.3500023877620697\n",
      "trial: 5, iter: 6600, curr loss: 1.338757872581482, avg loss: 1.3430656296014787\n",
      "trial: 5, iter: 6800, curr loss: 1.3492828607559204, avg loss: 1.3381578642129899\n",
      "trial: 5, iter: 7000, curr loss: 1.3298810720443726, avg loss: 1.337551127076149\n",
      "trial: 5, iter: 7200, curr loss: 1.3046718835830688, avg loss: 1.3319422793388367\n",
      "trial: 5, iter: 7400, curr loss: 1.3534789085388184, avg loss: 1.330100781917572\n",
      "trial: 5, iter: 7600, curr loss: 1.3120887279510498, avg loss: 1.3285504269599915\n",
      "trial: 5, iter: 7800, curr loss: 1.3117635250091553, avg loss: 1.326904401779175\n",
      "trial: 5, iter: 8000, curr loss: 1.3152650594711304, avg loss: 1.327377232313156\n",
      "trial: 5, iter: 8200, curr loss: 1.3057018518447876, avg loss: 1.324285438656807\n",
      "trial: 5, iter: 8400, curr loss: 1.3197174072265625, avg loss: 1.3243371611833572\n",
      "trial: 5, iter: 8600, curr loss: 1.2929874658584595, avg loss: 1.3232912641763688\n",
      "trial: 5, iter: 8800, curr loss: 1.358871579170227, avg loss: 1.3229673743247985\n",
      "trial: 5, iter: 9000, curr loss: 1.3231226205825806, avg loss: 1.3225058174133302\n",
      "trial: 5, iter: 9200, curr loss: 1.3565268516540527, avg loss: 1.3204155611991881\n",
      "trial: 5, iter: 9400, curr loss: 1.3021327257156372, avg loss: 1.3201602572202682\n",
      "trial: 5, iter: 9600, curr loss: 1.3313344717025757, avg loss: 1.3180615264177322\n",
      "trial: 5, iter: 9800, curr loss: 1.2969048023223877, avg loss: 1.318766012787819\n",
      "trial: 5, iter: 10000, curr loss: 1.311373233795166, avg loss: 1.3213393843173982\n",
      "trial: 5, iter: 10200, curr loss: 1.314863681793213, avg loss: 1.3192398309707642\n",
      "trial: 5, iter: 10400, curr loss: 1.2898937463760376, avg loss: 1.319876925945282\n",
      "trial: 5, iter: 10600, curr loss: 1.3103519678115845, avg loss: 1.316490289568901\n",
      "trial: 5, iter: 10800, curr loss: 1.3296843767166138, avg loss: 1.318045735359192\n",
      "trial: 5, iter: 11000, curr loss: 1.3208266496658325, avg loss: 1.3156273972988128\n",
      "trial: 5, iter: 11200, curr loss: 1.352786660194397, avg loss: 1.31721488237381\n",
      "trial: 5, iter: 11400, curr loss: 1.2888538837432861, avg loss: 1.317318565249443\n",
      "trial: 5, iter: 11600, curr loss: 1.2828871011734009, avg loss: 1.3152586102485657\n",
      "trial: 5, iter: 11800, curr loss: 1.3389705419540405, avg loss: 1.3164306110143662\n",
      "trial: 5, iter: 12000, curr loss: 1.2999165058135986, avg loss: 1.3160983407497406\n",
      "trial: 5, iter: 12200, curr loss: 1.309288740158081, avg loss: 1.3155595129728317\n",
      "trial: 5, iter: 12400, curr loss: 1.3021172285079956, avg loss: 1.3173550629615784\n",
      "trial: 5, iter: 12600, curr loss: 1.2823303937911987, avg loss: 1.3194514530897141\n",
      "trial: 5, iter: 12800, curr loss: 1.3410652875900269, avg loss: 1.316669737100601\n",
      "trial: 5, iter: 13000, curr loss: 1.2810722589492798, avg loss: 1.3153001219034195\n",
      "trial: 5, iter: 13200, curr loss: 1.3078532218933105, avg loss: 1.313901121020317\n",
      "trial: 5, iter: 13400, curr loss: 1.3108978271484375, avg loss: 1.3173729062080384\n",
      "trial: 5, iter: 13600, curr loss: 1.2906023263931274, avg loss: 1.3163946837186813\n",
      "trial: 5, iter: 13800, curr loss: 1.3101707696914673, avg loss: 1.3182711225748063\n",
      "trial: 5, iter: 14000, curr loss: 1.312749981880188, avg loss: 1.3166975396871567\n",
      "trial: 5, iter: 14200, curr loss: 1.3168631792068481, avg loss: 1.3170410388708114\n",
      "trial: 5, iter: 14400, curr loss: 1.3498543500900269, avg loss: 1.3146499192714691\n",
      "trial: 5, iter: 14600, curr loss: 1.307112455368042, avg loss: 1.3157287734746932\n",
      "trial: 5, iter: 14800, curr loss: 1.3039093017578125, avg loss: 1.3149918353557586\n",
      "trial: 5, iter: 15000, curr loss: 1.3535972833633423, avg loss: 1.3160058742761611\n",
      "trial: 5, iter: 15200, curr loss: 1.3003795146942139, avg loss: 1.3161480283737184\n",
      "trial: 5, iter: 15400, curr loss: 1.3355185985565186, avg loss: 1.3133856219053268\n",
      "trial: 5, iter: 15600, curr loss: 1.318746566772461, avg loss: 1.3130314183235168\n",
      "trial: 5, ldr: 0.36079898476600647\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.3718553423881531\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.384596347808838, avg loss: 1.3873876267671585\n",
      "trial: 1, iter: 400, curr loss: 1.3885759115219116, avg loss: 1.3867575126886367\n",
      "trial: 1, iter: 600, curr loss: 1.387507438659668, avg loss: 1.3865835177898407\n",
      "trial: 1, iter: 800, curr loss: 1.386613130569458, avg loss: 1.3865126210451126\n",
      "trial: 1, iter: 1000, curr loss: 1.3849362134933472, avg loss: 1.3865406852960587\n",
      "trial: 1, iter: 1200, curr loss: 1.3851512670516968, avg loss: 1.3864832478761673\n",
      "trial: 1, iter: 1400, curr loss: 1.385293960571289, avg loss: 1.3864273089170456\n",
      "trial: 1, iter: 1600, curr loss: 1.387742519378662, avg loss: 1.3864232420921325\n",
      "trial: 1, iter: 1800, curr loss: 1.3870784044265747, avg loss: 1.3863856709003448\n",
      "trial: 1, iter: 2000, curr loss: 1.3865547180175781, avg loss: 1.3863101834058762\n",
      "trial: 1, iter: 2200, curr loss: 1.386826515197754, avg loss: 1.3863646668195724\n",
      "trial: 1, iter: 2400, curr loss: 1.3866448402404785, avg loss: 1.3863449227809905\n",
      "trial: 1, iter: 2600, curr loss: 1.3867583274841309, avg loss: 1.3862905406951904\n",
      "trial: 1, iter: 2800, curr loss: 1.3861761093139648, avg loss: 1.3864063400030135\n",
      "trial: 1, iter: 3000, curr loss: 1.3865437507629395, avg loss: 1.3863244807720185\n",
      "trial: 1, iter: 3200, curr loss: 1.385962963104248, avg loss: 1.386327053308487\n",
      "trial: 1, iter: 3400, curr loss: 1.3860987424850464, avg loss: 1.3863018161058427\n",
      "trial: 1, iter: 3600, curr loss: 1.3866240978240967, avg loss: 1.3862978219985962\n",
      "trial: 1, iter: 3800, curr loss: 1.3856085538864136, avg loss: 1.3863210874795913\n",
      "trial: 1, iter: 4000, curr loss: 1.3867907524108887, avg loss: 1.386305991411209\n",
      "trial: 1, iter: 4200, curr loss: 1.3878352642059326, avg loss: 1.3863562899827957\n",
      "trial: 1, iter: 4400, curr loss: 1.385512351989746, avg loss: 1.3863574010133743\n",
      "trial: 1, iter: 4600, curr loss: 1.3859916925430298, avg loss: 1.386345916390419\n",
      "trial: 1, iter: 4800, curr loss: 1.3871036767959595, avg loss: 1.3862288695573808\n",
      "trial: 1, iter: 5000, curr loss: 1.3856825828552246, avg loss: 1.3863535362482071\n",
      "trial: 1, iter: 5200, curr loss: 1.3864563703536987, avg loss: 1.3863224321603775\n",
      "trial: 1, iter: 5400, curr loss: 1.3867192268371582, avg loss: 1.386371025443077\n",
      "trial: 1, iter: 5600, curr loss: 1.386394739151001, avg loss: 1.3864058196544646\n",
      "trial: 1, iter: 5800, curr loss: 1.38662588596344, avg loss: 1.3863190054893493\n",
      "trial: 1, iter: 6000, curr loss: 1.3861830234527588, avg loss: 1.3862816554307937\n",
      "trial: 1, iter: 6200, curr loss: 1.3862091302871704, avg loss: 1.3863357251882553\n",
      "trial: 1, iter: 6400, curr loss: 1.3861992359161377, avg loss: 1.3863528019189835\n",
      "trial: 1, iter: 6600, curr loss: 1.3856561183929443, avg loss: 1.3863117647171022\n",
      "trial: 1, iter: 6800, curr loss: 1.3862437009811401, avg loss: 1.3863283997774125\n",
      "trial: 1, iter: 7000, curr loss: 1.3861439228057861, avg loss: 1.386304268836975\n",
      "trial: 1, iter: 7200, curr loss: 1.3868619203567505, avg loss: 1.386321374773979\n",
      "trial: 1, iter: 7400, curr loss: 1.3858513832092285, avg loss: 1.386284504532814\n",
      "trial: 1, iter: 7600, curr loss: 1.3861534595489502, avg loss: 1.38629277408123\n",
      "trial: 1, iter: 7800, curr loss: 1.386056661605835, avg loss: 1.3863386237621307\n",
      "trial: 1, iter: 8000, curr loss: 1.385916829109192, avg loss: 1.3863075876235962\n",
      "trial: 1, iter: 8200, curr loss: 1.3862675428390503, avg loss: 1.3863489043712616\n",
      "trial: 1, iter: 8400, curr loss: 1.3863378763198853, avg loss: 1.3863194394111633\n",
      "trial: 1, iter: 8600, curr loss: 1.3851372003555298, avg loss: 1.3862620854377747\n",
      "trial: 1, iter: 8800, curr loss: 1.3863929510116577, avg loss: 1.3863283562660218\n",
      "trial: 1, iter: 9000, curr loss: 1.3865011930465698, avg loss: 1.3863036692142487\n",
      "trial: 1, iter: 9200, curr loss: 1.3865084648132324, avg loss: 1.3862955409288407\n",
      "trial: 1, iter: 9400, curr loss: 1.3868261575698853, avg loss: 1.3863606894016265\n",
      "trial: 1, iter: 9600, curr loss: 1.3880093097686768, avg loss: 1.3863715088367463\n",
      "trial: 1, iter: 9800, curr loss: 1.3851372003555298, avg loss: 1.3862984889745713\n",
      "trial: 1, iter: 10000, curr loss: 1.3866068124771118, avg loss: 1.386347416639328\n",
      "trial: 1, iter: 10200, curr loss: 1.385934829711914, avg loss: 1.3862851947546004\n",
      "trial: 1, iter: 10400, curr loss: 1.3863606452941895, avg loss: 1.3864241844415666\n",
      "trial: 1, iter: 10600, curr loss: 1.3866702318191528, avg loss: 1.386366764307022\n",
      "trial: 1, iter: 10800, curr loss: 1.3866794109344482, avg loss: 1.3862882322072982\n",
      "trial: 1, iter: 11000, curr loss: 1.385990023612976, avg loss: 1.386345738172531\n",
      "trial: 1, iter: 11200, curr loss: 1.3861185312271118, avg loss: 1.3863006716966628\n",
      "trial: 1, iter: 11400, curr loss: 1.386284589767456, avg loss: 1.3862437462806703\n",
      "trial: 1, iter: 11600, curr loss: 1.3866422176361084, avg loss: 1.3861808508634568\n",
      "trial: 1, iter: 11800, curr loss: 1.3849875926971436, avg loss: 1.386181696653366\n",
      "trial: 1, iter: 12000, curr loss: 1.386956810951233, avg loss: 1.3862578344345093\n",
      "trial: 1, iter: 12200, curr loss: 1.3858391046524048, avg loss: 1.3861405342817306\n",
      "trial: 1, iter: 12400, curr loss: 1.3851441144943237, avg loss: 1.3860508030653\n",
      "trial: 1, iter: 12600, curr loss: 1.3850884437561035, avg loss: 1.3859979647397995\n",
      "trial: 1, iter: 12800, curr loss: 1.383915662765503, avg loss: 1.3853018349409103\n",
      "trial: 1, iter: 13000, curr loss: 1.3803457021713257, avg loss: 1.3820166629552841\n",
      "trial: 1, iter: 13200, curr loss: 1.3633816242218018, avg loss: 1.3748000574111938\n",
      "trial: 1, iter: 13400, curr loss: 1.378692388534546, avg loss: 1.3684155064821244\n",
      "trial: 1, iter: 13600, curr loss: 1.347428798675537, avg loss: 1.3604368108510971\n",
      "trial: 1, iter: 13800, curr loss: 1.3255966901779175, avg loss: 1.3517438930273056\n",
      "trial: 1, iter: 14000, curr loss: 1.3917790651321411, avg loss: 1.3474448746442795\n",
      "trial: 1, iter: 14200, curr loss: 1.3481842279434204, avg loss: 1.3424176996946335\n",
      "trial: 1, iter: 14400, curr loss: 1.3141465187072754, avg loss: 1.3366112262010574\n",
      "trial: 1, iter: 14600, curr loss: 1.3095128536224365, avg loss: 1.3343215996026994\n",
      "trial: 1, iter: 14800, curr loss: 1.3719756603240967, avg loss: 1.3307077395915985\n",
      "trial: 1, iter: 15000, curr loss: 1.2897529602050781, avg loss: 1.3270193034410476\n",
      "trial: 1, iter: 15200, curr loss: 1.3603646755218506, avg loss: 1.3261906123161316\n",
      "trial: 1, iter: 15400, curr loss: 1.3275482654571533, avg loss: 1.3239744430780411\n",
      "trial: 1, iter: 15600, curr loss: 1.3450627326965332, avg loss: 1.3246734482049942\n",
      "trial: 1, ldr: 0.2481750249862671\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3878118991851807, avg loss: 1.387436293363571\n",
      "trial: 2, iter: 400, curr loss: 1.386938452720642, avg loss: 1.386820848584175\n",
      "trial: 2, iter: 600, curr loss: 1.3869733810424805, avg loss: 1.386670109629631\n",
      "trial: 2, iter: 800, curr loss: 1.3873339891433716, avg loss: 1.3866596364974975\n",
      "trial: 2, iter: 1000, curr loss: 1.3869332075119019, avg loss: 1.3864800000190736\n",
      "trial: 2, iter: 1200, curr loss: 1.3856804370880127, avg loss: 1.386409314274788\n",
      "trial: 2, iter: 1400, curr loss: 1.3858736753463745, avg loss: 1.386353727579117\n",
      "trial: 2, iter: 1600, curr loss: 1.3878353834152222, avg loss: 1.3864627408981323\n",
      "trial: 2, iter: 1800, curr loss: 1.3863799571990967, avg loss: 1.386402417421341\n",
      "trial: 2, iter: 2000, curr loss: 1.386159062385559, avg loss: 1.3863004279136657\n",
      "trial: 2, iter: 2200, curr loss: 1.3867244720458984, avg loss: 1.3863540464639663\n",
      "trial: 2, iter: 2400, curr loss: 1.385594367980957, avg loss: 1.386376730799675\n",
      "trial: 2, iter: 2600, curr loss: 1.384661078453064, avg loss: 1.3862533050775527\n",
      "trial: 2, iter: 2800, curr loss: 1.3854918479919434, avg loss: 1.386345193386078\n",
      "trial: 2, iter: 3000, curr loss: 1.3859196901321411, avg loss: 1.3863092094659806\n",
      "trial: 2, iter: 3200, curr loss: 1.3863788843154907, avg loss: 1.3863141924142837\n",
      "trial: 2, iter: 3400, curr loss: 1.3877787590026855, avg loss: 1.3863714289665223\n",
      "trial: 2, iter: 3600, curr loss: 1.3851532936096191, avg loss: 1.386325285434723\n",
      "trial: 2, iter: 3800, curr loss: 1.3854116201400757, avg loss: 1.38637288749218\n",
      "trial: 2, iter: 4000, curr loss: 1.3863390684127808, avg loss: 1.3863427704572677\n",
      "trial: 2, iter: 4200, curr loss: 1.3864399194717407, avg loss: 1.386344269514084\n",
      "trial: 2, iter: 4400, curr loss: 1.3864930868148804, avg loss: 1.386308753490448\n",
      "trial: 2, iter: 4600, curr loss: 1.3859301805496216, avg loss: 1.3863234674930573\n",
      "trial: 2, iter: 4800, curr loss: 1.3860630989074707, avg loss: 1.386308628320694\n",
      "trial: 2, iter: 5000, curr loss: 1.3860387802124023, avg loss: 1.3862525945901871\n",
      "trial: 2, iter: 5200, curr loss: 1.3853554725646973, avg loss: 1.3863160914182664\n",
      "trial: 2, iter: 5400, curr loss: 1.386562705039978, avg loss: 1.386429967880249\n",
      "trial: 2, iter: 5600, curr loss: 1.3862181901931763, avg loss: 1.3863316106796264\n",
      "trial: 2, iter: 5800, curr loss: 1.386138916015625, avg loss: 1.3862918043136596\n",
      "trial: 2, iter: 6000, curr loss: 1.3859684467315674, avg loss: 1.3862881720066071\n",
      "trial: 2, iter: 6200, curr loss: 1.38503897190094, avg loss: 1.386291619539261\n",
      "trial: 2, iter: 6400, curr loss: 1.3862202167510986, avg loss: 1.3861011809110642\n",
      "trial: 2, iter: 6600, curr loss: 1.3836042881011963, avg loss: 1.3854800492525101\n",
      "trial: 2, iter: 6800, curr loss: 1.379929542541504, avg loss: 1.3825739008188247\n",
      "trial: 2, iter: 7000, curr loss: 1.3530042171478271, avg loss: 1.374754050374031\n",
      "trial: 2, iter: 7200, curr loss: 1.3644206523895264, avg loss: 1.3661567181348802\n",
      "trial: 2, iter: 7400, curr loss: 1.3622649908065796, avg loss: 1.3625357562303544\n",
      "trial: 2, iter: 7600, curr loss: 1.3607884645462036, avg loss: 1.3603288614749909\n",
      "trial: 2, iter: 7800, curr loss: 1.343359112739563, avg loss: 1.3557622778415679\n",
      "trial: 2, iter: 8000, curr loss: 1.3653079271316528, avg loss: 1.3572112649679184\n",
      "trial: 2, iter: 8200, curr loss: 1.3652199506759644, avg loss: 1.355882784128189\n",
      "trial: 2, iter: 8400, curr loss: 1.3533320426940918, avg loss: 1.3559783971309662\n",
      "trial: 2, iter: 8600, curr loss: 1.3660155534744263, avg loss: 1.3563964384794236\n",
      "trial: 2, iter: 8800, curr loss: 1.346717119216919, avg loss: 1.3550932288169861\n",
      "trial: 2, iter: 9000, curr loss: 1.3369024991989136, avg loss: 1.3523180055618287\n",
      "trial: 2, iter: 9200, curr loss: 1.360459804534912, avg loss: 1.351795865893364\n",
      "trial: 2, iter: 9400, curr loss: 1.3500473499298096, avg loss: 1.3498931407928467\n",
      "trial: 2, iter: 9600, curr loss: 1.3685377836227417, avg loss: 1.3482217025756835\n",
      "trial: 2, iter: 9800, curr loss: 1.3419221639633179, avg loss: 1.3440627187490464\n",
      "trial: 2, iter: 10000, curr loss: 1.3359277248382568, avg loss: 1.337928746342659\n",
      "trial: 2, iter: 10200, curr loss: 1.3488513231277466, avg loss: 1.3322807216644288\n",
      "trial: 2, iter: 10400, curr loss: 1.3218671083450317, avg loss: 1.3308070713281632\n",
      "trial: 2, iter: 10600, curr loss: 1.3298897743225098, avg loss: 1.3291310381889343\n",
      "trial: 2, iter: 10800, curr loss: 1.3261806964874268, avg loss: 1.3254478871822357\n",
      "trial: 2, iter: 11000, curr loss: 1.3520220518112183, avg loss: 1.3245366019010545\n",
      "trial: 2, iter: 11200, curr loss: 1.2955703735351562, avg loss: 1.323220707178116\n",
      "trial: 2, iter: 11400, curr loss: 1.309727668762207, avg loss: 1.3219988387823105\n",
      "trial: 2, iter: 11600, curr loss: 1.3151216506958008, avg loss: 1.321327223777771\n",
      "trial: 2, iter: 11800, curr loss: 1.335851788520813, avg loss: 1.3209736096858977\n",
      "trial: 2, iter: 12000, curr loss: 1.3813670873641968, avg loss: 1.3230604672431945\n",
      "trial: 2, iter: 12200, curr loss: 1.2929998636245728, avg loss: 1.320275673866272\n",
      "trial: 2, iter: 12400, curr loss: 1.3159877061843872, avg loss: 1.3207244044542312\n",
      "trial: 2, iter: 12600, curr loss: 1.3057541847229004, avg loss: 1.3181702345609665\n",
      "trial: 2, iter: 12800, curr loss: 1.2919620275497437, avg loss: 1.318978726863861\n",
      "trial: 2, iter: 13000, curr loss: 1.3080708980560303, avg loss: 1.3200416952371596\n",
      "trial: 2, iter: 13200, curr loss: 1.3388044834136963, avg loss: 1.3180487006902695\n",
      "trial: 2, iter: 13400, curr loss: 1.3261407613754272, avg loss: 1.3192771208286285\n",
      "trial: 2, iter: 13600, curr loss: 1.291325569152832, avg loss: 1.3188239777088164\n",
      "trial: 2, iter: 13800, curr loss: 1.3504958152770996, avg loss: 1.319168337583542\n",
      "trial: 2, iter: 14000, curr loss: 1.3045949935913086, avg loss: 1.3145015853643418\n",
      "trial: 2, iter: 14200, curr loss: 1.325435757637024, avg loss: 1.3187712079286575\n",
      "trial: 2, iter: 14400, curr loss: 1.306923747062683, avg loss: 1.3154620957374572\n",
      "trial: 2, iter: 14600, curr loss: 1.320115327835083, avg loss: 1.3169826889038085\n",
      "trial: 2, iter: 14800, curr loss: 1.3196297883987427, avg loss: 1.3176508748531341\n",
      "trial: 2, iter: 15000, curr loss: 1.3117015361785889, avg loss: 1.3158328992128372\n",
      "trial: 2, iter: 15200, curr loss: 1.294633388519287, avg loss: 1.3183040297031403\n",
      "trial: 2, iter: 15400, curr loss: 1.3186109066009521, avg loss: 1.3185321766138076\n",
      "trial: 2, iter: 15600, curr loss: 1.3118537664413452, avg loss: 1.3168133050203323\n",
      "trial: 2, ldr: 0.388614684343338\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3911809921264648, avg loss: 1.3873260557651519\n",
      "trial: 3, iter: 400, curr loss: 1.3834065198898315, avg loss: 1.386817890405655\n",
      "trial: 3, iter: 600, curr loss: 1.3865379095077515, avg loss: 1.3865496730804443\n",
      "trial: 3, iter: 800, curr loss: 1.3861632347106934, avg loss: 1.3866120821237564\n",
      "trial: 3, iter: 1000, curr loss: 1.3855311870574951, avg loss: 1.3864412862062454\n",
      "trial: 3, iter: 1200, curr loss: 1.3836853504180908, avg loss: 1.3864202481508254\n",
      "trial: 3, iter: 1400, curr loss: 1.3870850801467896, avg loss: 1.386388829946518\n",
      "trial: 3, iter: 1600, curr loss: 1.3875360488891602, avg loss: 1.386413105726242\n",
      "trial: 3, iter: 1800, curr loss: 1.3861958980560303, avg loss: 1.3863881796598434\n",
      "trial: 3, iter: 2000, curr loss: 1.385972023010254, avg loss: 1.3863247168064117\n",
      "trial: 3, iter: 2200, curr loss: 1.386139154434204, avg loss: 1.3864008045196534\n",
      "trial: 3, iter: 2400, curr loss: 1.3864487409591675, avg loss: 1.3863014364242554\n",
      "trial: 3, iter: 2600, curr loss: 1.3869044780731201, avg loss: 1.3864084404706956\n",
      "trial: 3, iter: 2800, curr loss: 1.3863331079483032, avg loss: 1.3864175009727477\n",
      "trial: 3, iter: 3000, curr loss: 1.3866099119186401, avg loss: 1.3863037514686585\n",
      "trial: 3, iter: 3200, curr loss: 1.386927843093872, avg loss: 1.386373091340065\n",
      "trial: 3, iter: 3400, curr loss: 1.385410189628601, avg loss: 1.386236754655838\n",
      "trial: 3, iter: 3600, curr loss: 1.3890897035598755, avg loss: 1.3863321375846862\n",
      "trial: 3, iter: 3800, curr loss: 1.3871650695800781, avg loss: 1.3864932960271836\n",
      "trial: 3, iter: 4000, curr loss: 1.3857892751693726, avg loss: 1.3862736600637435\n",
      "trial: 3, iter: 4200, curr loss: 1.3859961032867432, avg loss: 1.3863307815790176\n",
      "trial: 3, iter: 4400, curr loss: 1.3858922719955444, avg loss: 1.3863390094041825\n",
      "trial: 3, iter: 4600, curr loss: 1.3854817152023315, avg loss: 1.3863180005550384\n",
      "trial: 3, iter: 4800, curr loss: 1.3845970630645752, avg loss: 1.386310111284256\n",
      "trial: 3, iter: 5000, curr loss: 1.3868489265441895, avg loss: 1.3863234102725983\n",
      "trial: 3, iter: 5200, curr loss: 1.386720895767212, avg loss: 1.3863561403751374\n",
      "trial: 3, iter: 5400, curr loss: 1.3867120742797852, avg loss: 1.3863757318258285\n",
      "trial: 3, iter: 5600, curr loss: 1.3860857486724854, avg loss: 1.3862534272670746\n",
      "trial: 3, iter: 5800, curr loss: 1.3855926990509033, avg loss: 1.3862881672382354\n",
      "trial: 3, iter: 6000, curr loss: 1.3870604038238525, avg loss: 1.386360576748848\n",
      "trial: 3, iter: 6200, curr loss: 1.3859466314315796, avg loss: 1.386310019493103\n",
      "trial: 3, iter: 6400, curr loss: 1.38603675365448, avg loss: 1.3863164860010146\n",
      "trial: 3, iter: 6600, curr loss: 1.3862777948379517, avg loss: 1.38628046810627\n",
      "trial: 3, iter: 6800, curr loss: 1.386054277420044, avg loss: 1.3863075822591782\n",
      "trial: 3, iter: 7000, curr loss: 1.3872528076171875, avg loss: 1.3863186842203141\n",
      "trial: 3, iter: 7200, curr loss: 1.3855640888214111, avg loss: 1.3861721044778823\n",
      "trial: 3, iter: 7400, curr loss: 1.3848265409469604, avg loss: 1.3856993520259857\n",
      "trial: 3, iter: 7600, curr loss: 1.371908187866211, avg loss: 1.3835459911823274\n",
      "trial: 3, iter: 7800, curr loss: 1.3756494522094727, avg loss: 1.380383769273758\n",
      "trial: 3, iter: 8000, curr loss: 1.378239393234253, avg loss: 1.3774879628419876\n",
      "trial: 3, iter: 8200, curr loss: 1.4001041650772095, avg loss: 1.3759347569942475\n",
      "trial: 3, iter: 8400, curr loss: 1.3523458242416382, avg loss: 1.3714662355184555\n",
      "trial: 3, iter: 8600, curr loss: 1.3544878959655762, avg loss: 1.3634695249795914\n",
      "trial: 3, iter: 8800, curr loss: 1.333801031112671, avg loss: 1.3555697846412658\n",
      "trial: 3, iter: 9000, curr loss: 1.3488742113113403, avg loss: 1.3498118615150452\n",
      "trial: 3, iter: 9200, curr loss: 1.3345528841018677, avg loss: 1.3436123210191726\n",
      "trial: 3, iter: 9400, curr loss: 1.3382837772369385, avg loss: 1.3397218990325928\n",
      "trial: 3, iter: 9600, curr loss: 1.3687506914138794, avg loss: 1.3353646010160447\n",
      "trial: 3, iter: 9800, curr loss: 1.3143963813781738, avg loss: 1.3314863604307174\n",
      "trial: 3, iter: 10000, curr loss: 1.2906922101974487, avg loss: 1.329832312464714\n",
      "trial: 3, iter: 10200, curr loss: 1.325444221496582, avg loss: 1.3312984293699264\n",
      "trial: 3, iter: 10400, curr loss: 1.310953974723816, avg loss: 1.3276634013652802\n",
      "trial: 3, iter: 10600, curr loss: 1.333998441696167, avg loss: 1.3265148836374283\n",
      "trial: 3, iter: 10800, curr loss: 1.3174335956573486, avg loss: 1.3270509928464889\n",
      "trial: 3, iter: 11000, curr loss: 1.2813398838043213, avg loss: 1.3257851910591125\n",
      "trial: 3, iter: 11200, curr loss: 1.3037875890731812, avg loss: 1.3210023486614226\n",
      "trial: 3, iter: 11400, curr loss: 1.352160096168518, avg loss: 1.3232426047325134\n",
      "trial: 3, iter: 11600, curr loss: 1.328750491142273, avg loss: 1.3230100929737092\n",
      "trial: 3, iter: 11800, curr loss: 1.331093192100525, avg loss: 1.3231853955984116\n",
      "trial: 3, iter: 12000, curr loss: 1.3152246475219727, avg loss: 1.3212372243404389\n",
      "trial: 3, iter: 12200, curr loss: 1.3474560976028442, avg loss: 1.3210982328653336\n",
      "trial: 3, iter: 12400, curr loss: 1.3233731985092163, avg loss: 1.3202947515249253\n",
      "trial: 3, iter: 12600, curr loss: 1.3367531299591064, avg loss: 1.322314122915268\n",
      "trial: 3, iter: 12800, curr loss: 1.3468643426895142, avg loss: 1.3197524958848954\n",
      "trial: 3, iter: 13000, curr loss: 1.3093103170394897, avg loss: 1.3192368191480637\n",
      "trial: 3, iter: 13200, curr loss: 1.2863377332687378, avg loss: 1.3197094506025315\n",
      "trial: 3, iter: 13400, curr loss: 1.3174728155136108, avg loss: 1.3195917809009552\n",
      "trial: 3, iter: 13600, curr loss: 1.317728877067566, avg loss: 1.3173986977338792\n",
      "trial: 3, iter: 13800, curr loss: 1.3480336666107178, avg loss: 1.318234698176384\n",
      "trial: 3, iter: 14000, curr loss: 1.307644248008728, avg loss: 1.3181213867664336\n",
      "trial: 3, iter: 14200, curr loss: 1.2850507497787476, avg loss: 1.3176527273654939\n",
      "trial: 3, iter: 14400, curr loss: 1.3026716709136963, avg loss: 1.3182199054956436\n",
      "trial: 3, iter: 14600, curr loss: 1.3344262838363647, avg loss: 1.3171254909038543\n",
      "trial: 3, iter: 14800, curr loss: 1.3080685138702393, avg loss: 1.3168698894977569\n",
      "trial: 3, iter: 15000, curr loss: 1.322788119316101, avg loss: 1.317105159163475\n",
      "trial: 3, iter: 15200, curr loss: 1.3161962032318115, avg loss: 1.3161254423856734\n",
      "trial: 3, iter: 15400, curr loss: 1.30300772190094, avg loss: 1.316982015967369\n",
      "trial: 3, iter: 15600, curr loss: 1.2984265089035034, avg loss: 1.3183666574954986\n",
      "trial: 3, ldr: 0.3575747609138489\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3867676258087158, avg loss: 1.3870259422063826\n",
      "trial: 4, iter: 400, curr loss: 1.3855509757995605, avg loss: 1.3866925555467606\n",
      "trial: 4, iter: 600, curr loss: 1.3872153759002686, avg loss: 1.3867947244644165\n",
      "trial: 4, iter: 800, curr loss: 1.386729121208191, avg loss: 1.3865618067979812\n",
      "trial: 4, iter: 1000, curr loss: 1.386479139328003, avg loss: 1.386371311545372\n",
      "trial: 4, iter: 1200, curr loss: 1.3872299194335938, avg loss: 1.3864102870225907\n",
      "trial: 4, iter: 1400, curr loss: 1.388093113899231, avg loss: 1.3863844692707061\n",
      "trial: 4, iter: 1600, curr loss: 1.3867697715759277, avg loss: 1.3863412100076675\n",
      "trial: 4, iter: 1800, curr loss: 1.3862988948822021, avg loss: 1.386345820426941\n",
      "trial: 4, iter: 2000, curr loss: 1.3861178159713745, avg loss: 1.386402859687805\n",
      "trial: 4, iter: 2200, curr loss: 1.3861494064331055, avg loss: 1.386370639204979\n",
      "trial: 4, iter: 2400, curr loss: 1.3856643438339233, avg loss: 1.3862903255224228\n",
      "trial: 4, iter: 2600, curr loss: 1.386210322380066, avg loss: 1.3863483375310899\n",
      "trial: 4, iter: 2800, curr loss: 1.3870911598205566, avg loss: 1.386305075287819\n",
      "trial: 4, iter: 3000, curr loss: 1.386492371559143, avg loss: 1.3863464874029159\n",
      "trial: 4, iter: 3200, curr loss: 1.3857780694961548, avg loss: 1.3863319039344788\n",
      "trial: 4, iter: 3400, curr loss: 1.3860896825790405, avg loss: 1.3863413202762604\n",
      "trial: 4, iter: 3600, curr loss: 1.3861815929412842, avg loss: 1.3863685375452042\n",
      "trial: 4, iter: 3800, curr loss: 1.3859474658966064, avg loss: 1.386341131925583\n",
      "trial: 4, iter: 4000, curr loss: 1.3859786987304688, avg loss: 1.3862907028198241\n",
      "trial: 4, iter: 4200, curr loss: 1.3865633010864258, avg loss: 1.3863003951311113\n",
      "trial: 4, iter: 4400, curr loss: 1.3867095708847046, avg loss: 1.3863694453239441\n",
      "trial: 4, iter: 4600, curr loss: 1.386436104774475, avg loss: 1.3862942558526994\n",
      "trial: 4, iter: 4800, curr loss: 1.3863084316253662, avg loss: 1.3863508683443069\n",
      "trial: 4, iter: 5000, curr loss: 1.3863444328308105, avg loss: 1.3863126128911971\n",
      "trial: 4, iter: 5200, curr loss: 1.386502981185913, avg loss: 1.3862952864170075\n",
      "trial: 4, iter: 5400, curr loss: 1.3855931758880615, avg loss: 1.386315060853958\n",
      "trial: 4, iter: 5600, curr loss: 1.3864556550979614, avg loss: 1.38635017991066\n",
      "trial: 4, iter: 5800, curr loss: 1.3862884044647217, avg loss: 1.3863804817199707\n",
      "trial: 4, iter: 6000, curr loss: 1.3863991498947144, avg loss: 1.3863048338890076\n",
      "trial: 4, iter: 6200, curr loss: 1.3857256174087524, avg loss: 1.38626862347126\n",
      "trial: 4, iter: 6400, curr loss: 1.3859957456588745, avg loss: 1.3863495862483979\n",
      "trial: 4, iter: 6600, curr loss: 1.386358380317688, avg loss: 1.3863947868347168\n",
      "trial: 4, iter: 6800, curr loss: 1.3865315914154053, avg loss: 1.3862988936901093\n",
      "trial: 4, iter: 7000, curr loss: 1.3862388134002686, avg loss: 1.3863175731897355\n",
      "trial: 4, iter: 7200, curr loss: 1.3863085508346558, avg loss: 1.3863237339258194\n",
      "trial: 4, iter: 7400, curr loss: 1.3869578838348389, avg loss: 1.3862688487768173\n",
      "trial: 4, iter: 7600, curr loss: 1.3862224817276, avg loss: 1.3862383776903153\n",
      "trial: 4, iter: 7800, curr loss: 1.3868722915649414, avg loss: 1.3862578868865967\n",
      "trial: 4, iter: 8000, curr loss: 1.3859835863113403, avg loss: 1.3862954097986222\n",
      "trial: 4, iter: 8200, curr loss: 1.3868513107299805, avg loss: 1.3862838119268417\n",
      "trial: 4, iter: 8400, curr loss: 1.3855140209197998, avg loss: 1.3862146317958832\n",
      "trial: 4, iter: 8600, curr loss: 1.3852922916412354, avg loss: 1.3856622862815857\n",
      "trial: 4, iter: 8800, curr loss: 1.3819530010223389, avg loss: 1.3839698684215547\n",
      "trial: 4, iter: 9000, curr loss: 1.3743834495544434, avg loss: 1.3819466406106948\n",
      "trial: 4, iter: 9200, curr loss: 1.397186040878296, avg loss: 1.373559164404869\n",
      "trial: 4, iter: 9400, curr loss: 1.3597421646118164, avg loss: 1.3654530215263367\n",
      "trial: 4, iter: 9600, curr loss: 1.3660526275634766, avg loss: 1.362209638953209\n",
      "trial: 4, iter: 9800, curr loss: 1.3711458444595337, avg loss: 1.3585916829109193\n",
      "trial: 4, iter: 10000, curr loss: 1.3396008014678955, avg loss: 1.3565465134382249\n",
      "trial: 4, iter: 10200, curr loss: 1.3552396297454834, avg loss: 1.354465709924698\n",
      "trial: 4, iter: 10400, curr loss: 1.350103735923767, avg loss: 1.3537345671653747\n",
      "trial: 4, iter: 10600, curr loss: 1.3473145961761475, avg loss: 1.3478927576541901\n",
      "trial: 4, iter: 10800, curr loss: 1.3418147563934326, avg loss: 1.342521606683731\n",
      "trial: 4, iter: 11000, curr loss: 1.3284350633621216, avg loss: 1.338666771054268\n",
      "trial: 4, iter: 11200, curr loss: 1.3321467638015747, avg loss: 1.3336411613225936\n",
      "trial: 4, iter: 11400, curr loss: 1.3264250755310059, avg loss: 1.3318241077661515\n",
      "trial: 4, iter: 11600, curr loss: 1.3535993099212646, avg loss: 1.3310471159219741\n",
      "trial: 4, iter: 11800, curr loss: 1.3222360610961914, avg loss: 1.328983952999115\n",
      "trial: 4, iter: 12000, curr loss: 1.3220055103302002, avg loss: 1.326218731403351\n",
      "trial: 4, iter: 12200, curr loss: 1.3556355237960815, avg loss: 1.3261012947559356\n",
      "trial: 4, iter: 12400, curr loss: 1.3030864000320435, avg loss: 1.3255715954303742\n",
      "trial: 4, iter: 12600, curr loss: 1.3318347930908203, avg loss: 1.323087112903595\n",
      "trial: 4, iter: 12800, curr loss: 1.3068420886993408, avg loss: 1.3240376555919646\n",
      "trial: 4, iter: 13000, curr loss: 1.2925268411636353, avg loss: 1.3185379630327225\n",
      "trial: 4, iter: 13200, curr loss: 1.330055832862854, avg loss: 1.322166023850441\n",
      "trial: 4, iter: 13400, curr loss: 1.315053939819336, avg loss: 1.3226923668384551\n",
      "trial: 4, iter: 13600, curr loss: 1.3355871438980103, avg loss: 1.3215276259183883\n",
      "trial: 4, iter: 13800, curr loss: 1.329569935798645, avg loss: 1.3210830038785935\n",
      "trial: 4, iter: 14000, curr loss: 1.3064122200012207, avg loss: 1.3204260700941086\n",
      "trial: 4, iter: 14200, curr loss: 1.320695400238037, avg loss: 1.3218779385089874\n",
      "trial: 4, iter: 14400, curr loss: 1.2751282453536987, avg loss: 1.3196843707561492\n",
      "trial: 4, iter: 14600, curr loss: 1.3276101350784302, avg loss: 1.3189203482866287\n",
      "trial: 4, iter: 14800, curr loss: 1.3083360195159912, avg loss: 1.318475079536438\n",
      "trial: 4, iter: 15000, curr loss: 1.3020514249801636, avg loss: 1.3180738323926926\n",
      "trial: 4, iter: 15200, curr loss: 1.302804708480835, avg loss: 1.3195957523584365\n",
      "trial: 4, iter: 15400, curr loss: 1.3216552734375, avg loss: 1.3180565267801285\n",
      "trial: 4, iter: 15600, curr loss: 1.321945071220398, avg loss: 1.3171637827157974\n",
      "trial: 4, ldr: 0.4048910140991211\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.389959692955017, avg loss: 1.387067273259163\n",
      "trial: 5, iter: 400, curr loss: 1.3864151239395142, avg loss: 1.387042043209076\n",
      "trial: 5, iter: 600, curr loss: 1.3883589506149292, avg loss: 1.3865422159433365\n",
      "trial: 5, iter: 800, curr loss: 1.3880528211593628, avg loss: 1.386685752272606\n",
      "trial: 5, iter: 1000, curr loss: 1.3853734731674194, avg loss: 1.3865483683347701\n",
      "trial: 5, iter: 1200, curr loss: 1.3859634399414062, avg loss: 1.3865341264009476\n",
      "trial: 5, iter: 1400, curr loss: 1.388615369796753, avg loss: 1.3863548463582993\n",
      "trial: 5, iter: 1600, curr loss: 1.3875020742416382, avg loss: 1.3863386708498\n",
      "trial: 5, iter: 1800, curr loss: 1.3872228860855103, avg loss: 1.3863713198900223\n",
      "trial: 5, iter: 2000, curr loss: 1.3858834505081177, avg loss: 1.3863835227489472\n",
      "trial: 5, iter: 2200, curr loss: 1.3853862285614014, avg loss: 1.3863873505592346\n",
      "trial: 5, iter: 2400, curr loss: 1.3861867189407349, avg loss: 1.386339390873909\n",
      "trial: 5, iter: 2600, curr loss: 1.385138750076294, avg loss: 1.3863403099775313\n",
      "trial: 5, iter: 2800, curr loss: 1.3863025903701782, avg loss: 1.3863737154006959\n",
      "trial: 5, iter: 3000, curr loss: 1.3853451013565063, avg loss: 1.3863279527425767\n",
      "trial: 5, iter: 3200, curr loss: 1.3873014450073242, avg loss: 1.3863030391931535\n",
      "trial: 5, iter: 3400, curr loss: 1.386588454246521, avg loss: 1.386347740292549\n",
      "trial: 5, iter: 3600, curr loss: 1.3861072063446045, avg loss: 1.3863547152280808\n",
      "trial: 5, iter: 3800, curr loss: 1.3848196268081665, avg loss: 1.3862570083141328\n",
      "trial: 5, iter: 4000, curr loss: 1.386152982711792, avg loss: 1.386380700469017\n",
      "trial: 5, iter: 4200, curr loss: 1.3891242742538452, avg loss: 1.3862325030565261\n",
      "trial: 5, iter: 4400, curr loss: 1.385630488395691, avg loss: 1.386402046084404\n",
      "trial: 5, iter: 4600, curr loss: 1.3860950469970703, avg loss: 1.386292233467102\n",
      "trial: 5, iter: 4800, curr loss: 1.3860400915145874, avg loss: 1.3863850402832032\n",
      "trial: 5, iter: 5000, curr loss: 1.386199951171875, avg loss: 1.386380227804184\n",
      "trial: 5, iter: 5200, curr loss: 1.3866243362426758, avg loss: 1.3862744563817977\n",
      "trial: 5, iter: 5400, curr loss: 1.3868962526321411, avg loss: 1.3862884080410003\n",
      "trial: 5, iter: 5600, curr loss: 1.385657787322998, avg loss: 1.3862928092479705\n",
      "trial: 5, iter: 5800, curr loss: 1.3869706392288208, avg loss: 1.3863948291540147\n",
      "trial: 5, iter: 6000, curr loss: 1.386278748512268, avg loss: 1.3862836956977844\n",
      "trial: 5, iter: 6200, curr loss: 1.3861804008483887, avg loss: 1.386331787109375\n",
      "trial: 5, iter: 6400, curr loss: 1.3857296705245972, avg loss: 1.3863155609369278\n",
      "trial: 5, iter: 6600, curr loss: 1.3863729238510132, avg loss: 1.3862689185142516\n",
      "trial: 5, iter: 6800, curr loss: 1.3866541385650635, avg loss: 1.3862844467163087\n",
      "trial: 5, iter: 7000, curr loss: 1.385589838027954, avg loss: 1.3863087493181228\n",
      "trial: 5, iter: 7200, curr loss: 1.3841791152954102, avg loss: 1.3861390966176987\n",
      "trial: 5, iter: 7400, curr loss: 1.3858590126037598, avg loss: 1.3862499868869782\n",
      "trial: 5, iter: 7600, curr loss: 1.3869212865829468, avg loss: 1.3860941368341446\n",
      "trial: 5, iter: 7800, curr loss: 1.3881584405899048, avg loss: 1.385426459312439\n",
      "trial: 5, iter: 8000, curr loss: 1.3709759712219238, avg loss: 1.3807173621654512\n",
      "trial: 5, iter: 8200, curr loss: 1.3684425354003906, avg loss: 1.3703725719451905\n",
      "trial: 5, iter: 8400, curr loss: 1.3505768775939941, avg loss: 1.3565572839975357\n",
      "trial: 5, iter: 8600, curr loss: 1.3482024669647217, avg loss: 1.3462905204296112\n",
      "trial: 5, iter: 8800, curr loss: 1.3313188552856445, avg loss: 1.3412783247232438\n",
      "trial: 5, iter: 9000, curr loss: 1.3376861810684204, avg loss: 1.3382102102041245\n",
      "trial: 5, iter: 9200, curr loss: 1.3383395671844482, avg loss: 1.3311607813835145\n",
      "trial: 5, iter: 9400, curr loss: 1.3366453647613525, avg loss: 1.3309454894065857\n",
      "trial: 5, iter: 9600, curr loss: 1.3315925598144531, avg loss: 1.3289312714338302\n",
      "trial: 5, iter: 9800, curr loss: 1.3520361185073853, avg loss: 1.3273962116241456\n",
      "trial: 5, iter: 10000, curr loss: 1.3151854276657104, avg loss: 1.3266556644439698\n",
      "trial: 5, iter: 10200, curr loss: 1.3147660493850708, avg loss: 1.3252023893594742\n",
      "trial: 5, iter: 10400, curr loss: 1.3378496170043945, avg loss: 1.322542610168457\n",
      "trial: 5, iter: 10600, curr loss: 1.3312344551086426, avg loss: 1.3223717713356018\n",
      "trial: 5, iter: 10800, curr loss: 1.3144712448120117, avg loss: 1.323586990237236\n",
      "trial: 5, iter: 11000, curr loss: 1.3181349039077759, avg loss: 1.3207831758260726\n",
      "trial: 5, iter: 11200, curr loss: 1.3312065601348877, avg loss: 1.3211824256181717\n",
      "trial: 5, iter: 11400, curr loss: 1.336949348449707, avg loss: 1.3188743728399277\n",
      "trial: 5, iter: 11600, curr loss: 1.3170465230941772, avg loss: 1.3177980011701584\n",
      "trial: 5, iter: 11800, curr loss: 1.2918059825897217, avg loss: 1.3183937287330627\n",
      "trial: 5, iter: 12000, curr loss: 1.3040062189102173, avg loss: 1.3168837237358093\n",
      "trial: 5, iter: 12200, curr loss: 1.3174047470092773, avg loss: 1.3192963272333145\n",
      "trial: 5, iter: 12400, curr loss: 1.333695888519287, avg loss: 1.3165813583135604\n",
      "trial: 5, iter: 12600, curr loss: 1.333244800567627, avg loss: 1.3177206242084503\n",
      "trial: 5, iter: 12800, curr loss: 1.3471195697784424, avg loss: 1.3181572985649108\n",
      "trial: 5, iter: 13000, curr loss: 1.336759328842163, avg loss: 1.315333554148674\n",
      "trial: 5, iter: 13200, curr loss: 1.2919522523880005, avg loss: 1.3203729903697967\n",
      "trial: 5, iter: 13400, curr loss: 1.3312249183654785, avg loss: 1.3182992959022521\n",
      "trial: 5, iter: 13600, curr loss: 1.3067370653152466, avg loss: 1.3195527875423432\n",
      "trial: 5, iter: 13800, curr loss: 1.325142502784729, avg loss: 1.3209109884500503\n",
      "trial: 5, iter: 14000, curr loss: 1.3059462308883667, avg loss: 1.318384026288986\n",
      "trial: 5, iter: 14200, curr loss: 1.339463472366333, avg loss: 1.318403989672661\n",
      "trial: 5, iter: 14400, curr loss: 1.3063076734542847, avg loss: 1.315829325914383\n",
      "trial: 5, iter: 14600, curr loss: 1.319270133972168, avg loss: 1.316734281182289\n",
      "trial: 5, iter: 14800, curr loss: 1.336176872253418, avg loss: 1.3168775099515915\n",
      "trial: 5, iter: 15000, curr loss: 1.3202866315841675, avg loss: 1.3180171489715575\n",
      "trial: 5, iter: 15200, curr loss: 1.3259433507919312, avg loss: 1.315618988275528\n",
      "trial: 5, iter: 15400, curr loss: 1.3042570352554321, avg loss: 1.3146257048845291\n",
      "trial: 5, iter: 15600, curr loss: 1.3096669912338257, avg loss: 1.317322052717209\n",
      "trial: 5, ldr: 0.3338012099266052\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.34661133885383605\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3872203826904297, avg loss: 1.3874539011716842\n",
      "trial: 1, iter: 400, curr loss: 1.3868417739868164, avg loss: 1.3868829381465912\n",
      "trial: 1, iter: 600, curr loss: 1.3871352672576904, avg loss: 1.3868434095382691\n",
      "trial: 1, iter: 800, curr loss: 1.3886998891830444, avg loss: 1.3865875452756882\n",
      "trial: 1, iter: 1000, curr loss: 1.384909749031067, avg loss: 1.38652603328228\n",
      "trial: 1, iter: 1200, curr loss: 1.387160301208496, avg loss: 1.3865502965450287\n",
      "trial: 1, iter: 1400, curr loss: 1.386742353439331, avg loss: 1.386450515985489\n",
      "trial: 1, iter: 1600, curr loss: 1.3860602378845215, avg loss: 1.3864399933815001\n",
      "trial: 1, iter: 1800, curr loss: 1.3867214918136597, avg loss: 1.3864758723974229\n",
      "trial: 1, iter: 2000, curr loss: 1.3860607147216797, avg loss: 1.3864435988664627\n",
      "trial: 1, iter: 2200, curr loss: 1.3870961666107178, avg loss: 1.3863123720884323\n",
      "trial: 1, iter: 2400, curr loss: 1.3867278099060059, avg loss: 1.3863545399904251\n",
      "trial: 1, iter: 2600, curr loss: 1.385091781616211, avg loss: 1.386391887664795\n",
      "trial: 1, iter: 2800, curr loss: 1.3867005109786987, avg loss: 1.386393569111824\n",
      "trial: 1, iter: 3000, curr loss: 1.3872030973434448, avg loss: 1.3863344663381576\n",
      "trial: 1, iter: 3200, curr loss: 1.3861926794052124, avg loss: 1.3863127768039702\n",
      "trial: 1, iter: 3400, curr loss: 1.387102723121643, avg loss: 1.3862903916835785\n",
      "trial: 1, iter: 3600, curr loss: 1.3880099058151245, avg loss: 1.386311907172203\n",
      "trial: 1, iter: 3800, curr loss: 1.3856738805770874, avg loss: 1.3863347578048706\n",
      "trial: 1, iter: 4000, curr loss: 1.3871195316314697, avg loss: 1.3863237076997756\n",
      "trial: 1, iter: 4200, curr loss: 1.386540174484253, avg loss: 1.3863289338350295\n",
      "trial: 1, iter: 4400, curr loss: 1.385680079460144, avg loss: 1.386314283013344\n",
      "trial: 1, iter: 4600, curr loss: 1.3868829011917114, avg loss: 1.3862886130809784\n",
      "trial: 1, iter: 4800, curr loss: 1.3860174417495728, avg loss: 1.3862916934490204\n",
      "trial: 1, iter: 5000, curr loss: 1.3820253610610962, avg loss: 1.3861271208524704\n",
      "trial: 1, iter: 5200, curr loss: 1.3861860036849976, avg loss: 1.3854356157779693\n",
      "trial: 1, iter: 5400, curr loss: 1.3814479112625122, avg loss: 1.3830909317731857\n",
      "trial: 1, iter: 5600, curr loss: 1.3824992179870605, avg loss: 1.378595615029335\n",
      "trial: 1, iter: 5800, curr loss: 1.369483470916748, avg loss: 1.376619229912758\n",
      "trial: 1, iter: 6000, curr loss: 1.3854552507400513, avg loss: 1.3756229799985886\n",
      "trial: 1, iter: 6200, curr loss: 1.3677548170089722, avg loss: 1.3729272788763047\n",
      "trial: 1, iter: 6400, curr loss: 1.3509656190872192, avg loss: 1.3690389961004257\n",
      "trial: 1, iter: 6600, curr loss: 1.36626398563385, avg loss: 1.3668841195106507\n",
      "trial: 1, iter: 6800, curr loss: 1.361598014831543, avg loss: 1.3660217958688736\n",
      "trial: 1, iter: 7000, curr loss: 1.367061972618103, avg loss: 1.3625601488351822\n",
      "trial: 1, iter: 7200, curr loss: 1.367688536643982, avg loss: 1.3605344951152802\n",
      "trial: 1, iter: 7400, curr loss: 1.3358298540115356, avg loss: 1.3556020915508271\n",
      "trial: 1, iter: 7600, curr loss: 1.330361008644104, avg loss: 1.3477641242742537\n",
      "trial: 1, iter: 7800, curr loss: 1.3398175239562988, avg loss: 1.34076946914196\n",
      "trial: 1, iter: 8000, curr loss: 1.3124306201934814, avg loss: 1.333417295217514\n",
      "trial: 1, iter: 8200, curr loss: 1.3145325183868408, avg loss: 1.3301390367746353\n",
      "trial: 1, iter: 8400, curr loss: 1.2953510284423828, avg loss: 1.328431220650673\n",
      "trial: 1, iter: 8600, curr loss: 1.341418743133545, avg loss: 1.3268879389762878\n",
      "trial: 1, iter: 8800, curr loss: 1.3462189435958862, avg loss: 1.3239389526844025\n",
      "trial: 1, iter: 9000, curr loss: 1.3250410556793213, avg loss: 1.3239238518476486\n",
      "trial: 1, iter: 9200, curr loss: 1.3195981979370117, avg loss: 1.3239554327726364\n",
      "trial: 1, iter: 9400, curr loss: 1.342254638671875, avg loss: 1.3218924820423126\n",
      "trial: 1, iter: 9600, curr loss: 1.3203493356704712, avg loss: 1.3211637938022613\n",
      "trial: 1, iter: 9800, curr loss: 1.3179614543914795, avg loss: 1.3206968539953232\n",
      "trial: 1, iter: 10000, curr loss: 1.3318923711776733, avg loss: 1.3187469881772995\n",
      "trial: 1, iter: 10200, curr loss: 1.2869952917099, avg loss: 1.3215724343061448\n",
      "trial: 1, iter: 10400, curr loss: 1.2950774431228638, avg loss: 1.3195082449913025\n",
      "trial: 1, iter: 10600, curr loss: 1.3226869106292725, avg loss: 1.3187857788801194\n",
      "trial: 1, iter: 10800, curr loss: 1.3268550634384155, avg loss: 1.3186329305171967\n",
      "trial: 1, iter: 11000, curr loss: 1.3418536186218262, avg loss: 1.3175863552093505\n",
      "trial: 1, iter: 11200, curr loss: 1.3630452156066895, avg loss: 1.3197572720050812\n",
      "trial: 1, iter: 11400, curr loss: 1.3259676694869995, avg loss: 1.3165989816188812\n",
      "trial: 1, iter: 11600, curr loss: 1.286925196647644, avg loss: 1.3196107637882233\n",
      "trial: 1, iter: 11800, curr loss: 1.3181025981903076, avg loss: 1.3166691821813583\n",
      "trial: 1, iter: 12000, curr loss: 1.3368178606033325, avg loss: 1.3180870682001113\n",
      "trial: 1, iter: 12200, curr loss: 1.3253477811813354, avg loss: 1.3181249439716338\n",
      "trial: 1, iter: 12400, curr loss: 1.2967605590820312, avg loss: 1.3158228784799575\n",
      "trial: 1, iter: 12600, curr loss: 1.328756332397461, avg loss: 1.3203668475151062\n",
      "trial: 1, iter: 12800, curr loss: 1.3196848630905151, avg loss: 1.3165994411706925\n",
      "trial: 1, iter: 13000, curr loss: 1.3208115100860596, avg loss: 1.3166321921348572\n",
      "trial: 1, iter: 13200, curr loss: 1.3014944791793823, avg loss: 1.3161239612102509\n",
      "trial: 1, iter: 13400, curr loss: 1.288477897644043, avg loss: 1.3171218979358672\n",
      "trial: 1, iter: 13600, curr loss: 1.3039844036102295, avg loss: 1.3164468705654144\n",
      "trial: 1, iter: 13800, curr loss: 1.3020765781402588, avg loss: 1.316616672873497\n",
      "trial: 1, iter: 14000, curr loss: 1.303558111190796, avg loss: 1.3156554651260377\n",
      "trial: 1, iter: 14200, curr loss: 1.294730544090271, avg loss: 1.3165949416160583\n",
      "trial: 1, iter: 14400, curr loss: 1.328932762145996, avg loss: 1.3175388211011887\n",
      "trial: 1, iter: 14600, curr loss: 1.3032711744308472, avg loss: 1.3170822608470916\n",
      "trial: 1, iter: 14800, curr loss: 1.312832236289978, avg loss: 1.3157182228565216\n",
      "trial: 1, iter: 15000, curr loss: 1.3383889198303223, avg loss: 1.3180535072088242\n",
      "trial: 1, iter: 15200, curr loss: 1.3117296695709229, avg loss: 1.3135845518112184\n",
      "trial: 1, iter: 15400, curr loss: 1.324697732925415, avg loss: 1.3138466745615005\n",
      "trial: 1, iter: 15600, curr loss: 1.3156800270080566, avg loss: 1.3151330429315566\n",
      "trial: 1, ldr: 0.3249772787094116\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386528491973877, avg loss: 1.387359492778778\n",
      "trial: 2, iter: 400, curr loss: 1.3893067836761475, avg loss: 1.386951076388359\n",
      "trial: 2, iter: 600, curr loss: 1.3897886276245117, avg loss: 1.3865291696786881\n",
      "trial: 2, iter: 800, curr loss: 1.3843941688537598, avg loss: 1.3865175181627274\n",
      "trial: 2, iter: 1000, curr loss: 1.3871371746063232, avg loss: 1.3865052843093872\n",
      "trial: 2, iter: 1200, curr loss: 1.3851189613342285, avg loss: 1.3864734441041946\n",
      "trial: 2, iter: 1400, curr loss: 1.3872963190078735, avg loss: 1.386424350142479\n",
      "trial: 2, iter: 1600, curr loss: 1.3870962858200073, avg loss: 1.3864123111963271\n",
      "trial: 2, iter: 1800, curr loss: 1.3862316608428955, avg loss: 1.3863794374465943\n",
      "trial: 2, iter: 2000, curr loss: 1.3860015869140625, avg loss: 1.3863108414411545\n",
      "trial: 2, iter: 2200, curr loss: 1.3852897882461548, avg loss: 1.3863463753461838\n",
      "trial: 2, iter: 2400, curr loss: 1.3853520154953003, avg loss: 1.386286625266075\n",
      "trial: 2, iter: 2600, curr loss: 1.3861274719238281, avg loss: 1.3863392668962478\n",
      "trial: 2, iter: 2800, curr loss: 1.3863136768341064, avg loss: 1.3863332790136338\n",
      "trial: 2, iter: 3000, curr loss: 1.3858941793441772, avg loss: 1.3862900042533874\n",
      "trial: 2, iter: 3200, curr loss: 1.3873240947723389, avg loss: 1.3864344400167465\n",
      "trial: 2, iter: 3400, curr loss: 1.3861348628997803, avg loss: 1.3863153898715972\n",
      "trial: 2, iter: 3600, curr loss: 1.38582444190979, avg loss: 1.386302118897438\n",
      "trial: 2, iter: 3800, curr loss: 1.3858686685562134, avg loss: 1.386352469921112\n",
      "trial: 2, iter: 4000, curr loss: 1.3865951299667358, avg loss: 1.3863409388065338\n",
      "trial: 2, iter: 4200, curr loss: 1.3858561515808105, avg loss: 1.3863085252046585\n",
      "trial: 2, iter: 4400, curr loss: 1.386759877204895, avg loss: 1.3862795346975327\n",
      "trial: 2, iter: 4600, curr loss: 1.3863296508789062, avg loss: 1.3863064068555833\n",
      "trial: 2, iter: 4800, curr loss: 1.3867647647857666, avg loss: 1.3863261938095093\n",
      "trial: 2, iter: 5000, curr loss: 1.3862334489822388, avg loss: 1.3863333702087401\n",
      "trial: 2, iter: 5200, curr loss: 1.3864285945892334, avg loss: 1.3863546192646026\n",
      "trial: 2, iter: 5400, curr loss: 1.3862521648406982, avg loss: 1.3862978357076645\n",
      "trial: 2, iter: 5600, curr loss: 1.3853956460952759, avg loss: 1.386336354613304\n",
      "trial: 2, iter: 5800, curr loss: 1.3858991861343384, avg loss: 1.386309266090393\n",
      "trial: 2, iter: 6000, curr loss: 1.3864208459854126, avg loss: 1.386362566947937\n",
      "trial: 2, iter: 6200, curr loss: 1.3857065439224243, avg loss: 1.3863196754455567\n",
      "trial: 2, iter: 6400, curr loss: 1.3857625722885132, avg loss: 1.3862905400991439\n",
      "trial: 2, iter: 6600, curr loss: 1.3857959508895874, avg loss: 1.3863083124160767\n",
      "trial: 2, iter: 6800, curr loss: 1.3859976530075073, avg loss: 1.3863129860162735\n",
      "trial: 2, iter: 7000, curr loss: 1.3869465589523315, avg loss: 1.386353605389595\n",
      "trial: 2, iter: 7200, curr loss: 1.3867003917694092, avg loss: 1.3863625228404999\n",
      "trial: 2, iter: 7400, curr loss: 1.3853567838668823, avg loss: 1.3862362617254258\n",
      "trial: 2, iter: 7600, curr loss: 1.3857412338256836, avg loss: 1.3863434565067292\n",
      "trial: 2, iter: 7800, curr loss: 1.3859007358551025, avg loss: 1.3863081020116805\n",
      "trial: 2, iter: 8000, curr loss: 1.3858031034469604, avg loss: 1.3863316190242767\n",
      "trial: 2, iter: 8200, curr loss: 1.386367917060852, avg loss: 1.3863269531726836\n",
      "trial: 2, iter: 8400, curr loss: 1.3869719505310059, avg loss: 1.3862801152467727\n",
      "trial: 2, iter: 8600, curr loss: 1.3863095045089722, avg loss: 1.3863157218694686\n",
      "trial: 2, iter: 8800, curr loss: 1.3866413831710815, avg loss: 1.3862943929433822\n",
      "trial: 2, iter: 9000, curr loss: 1.3867319822311401, avg loss: 1.386301708817482\n",
      "trial: 2, iter: 9200, curr loss: 1.3872023820877075, avg loss: 1.3862877196073533\n",
      "trial: 2, iter: 9400, curr loss: 1.3866260051727295, avg loss: 1.3863672804832459\n",
      "trial: 2, iter: 9600, curr loss: 1.3869354724884033, avg loss: 1.3863357377052308\n",
      "trial: 2, iter: 9800, curr loss: 1.3860204219818115, avg loss: 1.3862916672229766\n",
      "trial: 2, iter: 10000, curr loss: 1.386346459388733, avg loss: 1.3863368022441864\n",
      "trial: 2, iter: 10200, curr loss: 1.3863022327423096, avg loss: 1.3863313865661622\n",
      "trial: 2, iter: 10400, curr loss: 1.3862407207489014, avg loss: 1.3863046753406525\n",
      "trial: 2, iter: 10600, curr loss: 1.386584997177124, avg loss: 1.3862426680326463\n",
      "trial: 2, iter: 10800, curr loss: 1.3868412971496582, avg loss: 1.3863405358791352\n",
      "trial: 2, iter: 11000, curr loss: 1.3867470026016235, avg loss: 1.386318524479866\n",
      "trial: 2, iter: 11200, curr loss: 1.3864442110061646, avg loss: 1.3862983244657516\n",
      "trial: 2, iter: 11400, curr loss: 1.3862018585205078, avg loss: 1.3862524819374085\n",
      "trial: 2, iter: 11600, curr loss: 1.384705662727356, avg loss: 1.3861445105075836\n",
      "trial: 2, iter: 11800, curr loss: 1.3793256282806396, avg loss: 1.3853072983026504\n",
      "trial: 2, iter: 12000, curr loss: 1.3914377689361572, avg loss: 1.382684513926506\n",
      "trial: 2, iter: 12200, curr loss: 1.359960675239563, avg loss: 1.3743410795927047\n",
      "trial: 2, iter: 12400, curr loss: 1.3792164325714111, avg loss: 1.3672336781024932\n",
      "trial: 2, iter: 12600, curr loss: 1.3697506189346313, avg loss: 1.3619011324644088\n",
      "trial: 2, iter: 12800, curr loss: 1.3668854236602783, avg loss: 1.3586337125301362\n",
      "trial: 2, iter: 13000, curr loss: 1.3616019487380981, avg loss: 1.3561074364185333\n",
      "trial: 2, iter: 13200, curr loss: 1.3773869276046753, avg loss: 1.3531249624490738\n",
      "trial: 2, iter: 13400, curr loss: 1.3458688259124756, avg loss: 1.3461470985412598\n",
      "trial: 2, iter: 13600, curr loss: 1.3639682531356812, avg loss: 1.3426726770401\n",
      "trial: 2, iter: 13800, curr loss: 1.3098132610321045, avg loss: 1.3365149736404418\n",
      "trial: 2, iter: 14000, curr loss: 1.3320436477661133, avg loss: 1.333275362253189\n",
      "trial: 2, iter: 14200, curr loss: 1.3150147199630737, avg loss: 1.328586959838867\n",
      "trial: 2, iter: 14400, curr loss: 1.3059563636779785, avg loss: 1.3268362230062485\n",
      "trial: 2, iter: 14600, curr loss: 1.3000727891921997, avg loss: 1.3226333314180374\n",
      "trial: 2, iter: 14800, curr loss: 1.3164408206939697, avg loss: 1.3232854813337327\n",
      "trial: 2, iter: 15000, curr loss: 1.3313195705413818, avg loss: 1.3249541771411897\n",
      "trial: 2, iter: 15200, curr loss: 1.3039730787277222, avg loss: 1.3245728999376296\n",
      "trial: 2, iter: 15400, curr loss: 1.330033779144287, avg loss: 1.3195153319835662\n",
      "trial: 2, iter: 15600, curr loss: 1.313227653503418, avg loss: 1.3228086072206497\n",
      "trial: 2, ldr: 0.3310357332229614\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3835340738296509, avg loss: 1.387226955294609\n",
      "trial: 3, iter: 400, curr loss: 1.386522650718689, avg loss: 1.3869011104106903\n",
      "trial: 3, iter: 600, curr loss: 1.3876972198486328, avg loss: 1.3866090565919875\n",
      "trial: 3, iter: 800, curr loss: 1.390296220779419, avg loss: 1.3865823900699616\n",
      "trial: 3, iter: 1000, curr loss: 1.3854060173034668, avg loss: 1.3865138322114945\n",
      "trial: 3, iter: 1200, curr loss: 1.3859424591064453, avg loss: 1.3865048056840896\n",
      "trial: 3, iter: 1400, curr loss: 1.387313723564148, avg loss: 1.3863873612880706\n",
      "trial: 3, iter: 1600, curr loss: 1.3858182430267334, avg loss: 1.3863899993896485\n",
      "trial: 3, iter: 1800, curr loss: 1.3866430521011353, avg loss: 1.3863506990671157\n",
      "trial: 3, iter: 2000, curr loss: 1.3860936164855957, avg loss: 1.3864060562849045\n",
      "trial: 3, iter: 2200, curr loss: 1.3866952657699585, avg loss: 1.3863508301973342\n",
      "trial: 3, iter: 2400, curr loss: 1.3862346410751343, avg loss: 1.3863145858049393\n",
      "trial: 3, iter: 2600, curr loss: 1.3861162662506104, avg loss: 1.3864014959335327\n",
      "trial: 3, iter: 2800, curr loss: 1.386338472366333, avg loss: 1.386332138776779\n",
      "trial: 3, iter: 3000, curr loss: 1.3860629796981812, avg loss: 1.3862885999679566\n",
      "trial: 3, iter: 3200, curr loss: 1.385160207748413, avg loss: 1.386300996541977\n",
      "trial: 3, iter: 3400, curr loss: 1.385723352432251, avg loss: 1.3863206386566163\n",
      "trial: 3, iter: 3600, curr loss: 1.385880947113037, avg loss: 1.3862730503082275\n",
      "trial: 3, iter: 3800, curr loss: 1.3863239288330078, avg loss: 1.3863563895225526\n",
      "trial: 3, iter: 4000, curr loss: 1.3859719038009644, avg loss: 1.386280705332756\n",
      "trial: 3, iter: 4200, curr loss: 1.3844585418701172, avg loss: 1.3863153392076493\n",
      "trial: 3, iter: 4400, curr loss: 1.3871678113937378, avg loss: 1.3864349591732026\n",
      "trial: 3, iter: 4600, curr loss: 1.3865963220596313, avg loss: 1.3864022690057753\n",
      "trial: 3, iter: 4800, curr loss: 1.3870795965194702, avg loss: 1.3863123351335525\n",
      "trial: 3, iter: 5000, curr loss: 1.3871169090270996, avg loss: 1.386342357993126\n",
      "trial: 3, iter: 5200, curr loss: 1.3863310813903809, avg loss: 1.3863137274980546\n",
      "trial: 3, iter: 5400, curr loss: 1.3864047527313232, avg loss: 1.3863379240036011\n",
      "trial: 3, iter: 5600, curr loss: 1.3862340450286865, avg loss: 1.3863358098268508\n",
      "trial: 3, iter: 5800, curr loss: 1.3861440420150757, avg loss: 1.386309877038002\n",
      "trial: 3, iter: 6000, curr loss: 1.3851863145828247, avg loss: 1.38626701772213\n",
      "trial: 3, iter: 6200, curr loss: 1.3870642185211182, avg loss: 1.3863252782821656\n",
      "trial: 3, iter: 6400, curr loss: 1.3862265348434448, avg loss: 1.3863426208496095\n",
      "trial: 3, iter: 6600, curr loss: 1.3864154815673828, avg loss: 1.3863217425346375\n",
      "trial: 3, iter: 6800, curr loss: 1.3857698440551758, avg loss: 1.386312239766121\n",
      "trial: 3, iter: 7000, curr loss: 1.3871017694473267, avg loss: 1.386310059428215\n",
      "trial: 3, iter: 7200, curr loss: 1.385713815689087, avg loss: 1.3862932723760606\n",
      "trial: 3, iter: 7400, curr loss: 1.3860023021697998, avg loss: 1.3863997900485991\n",
      "trial: 3, iter: 7600, curr loss: 1.38619065284729, avg loss: 1.3863052833080292\n",
      "trial: 3, iter: 7800, curr loss: 1.3863654136657715, avg loss: 1.3863141870498656\n",
      "trial: 3, iter: 8000, curr loss: 1.3864375352859497, avg loss: 1.3863151198625565\n",
      "trial: 3, iter: 8200, curr loss: 1.3862255811691284, avg loss: 1.3862894725799562\n",
      "trial: 3, iter: 8400, curr loss: 1.3863738775253296, avg loss: 1.3863130861520767\n",
      "trial: 3, iter: 8600, curr loss: 1.3862181901931763, avg loss: 1.3863061648607253\n",
      "trial: 3, iter: 8800, curr loss: 1.386176586151123, avg loss: 1.3862804663181305\n",
      "trial: 3, iter: 9000, curr loss: 1.3863662481307983, avg loss: 1.3862901604175568\n",
      "trial: 3, iter: 9200, curr loss: 1.3865177631378174, avg loss: 1.386253659725189\n",
      "trial: 3, iter: 9400, curr loss: 1.3854591846466064, avg loss: 1.3863200181722641\n",
      "trial: 3, iter: 9600, curr loss: 1.385560154914856, avg loss: 1.386303994655609\n",
      "trial: 3, iter: 9800, curr loss: 1.3873753547668457, avg loss: 1.3863200485706328\n",
      "trial: 3, iter: 10000, curr loss: 1.3865947723388672, avg loss: 1.3862925028800965\n",
      "trial: 3, iter: 10200, curr loss: 1.386027455329895, avg loss: 1.3862749809026718\n",
      "trial: 3, iter: 10400, curr loss: 1.3851581811904907, avg loss: 1.3862629055976867\n",
      "trial: 3, iter: 10600, curr loss: 1.3864127397537231, avg loss: 1.386287460923195\n",
      "trial: 3, iter: 10800, curr loss: 1.3867428302764893, avg loss: 1.3862338221073152\n",
      "trial: 3, iter: 11000, curr loss: 1.3875541687011719, avg loss: 1.3861580097675323\n",
      "trial: 3, iter: 11200, curr loss: 1.3848628997802734, avg loss: 1.3861622750759124\n",
      "trial: 3, iter: 11400, curr loss: 1.386817455291748, avg loss: 1.3860616743564607\n",
      "trial: 3, iter: 11600, curr loss: 1.387142300605774, avg loss: 1.3859973651170732\n",
      "trial: 3, iter: 11800, curr loss: 1.3866264820098877, avg loss: 1.3858318883180618\n",
      "trial: 3, iter: 12000, curr loss: 1.3838196992874146, avg loss: 1.3849111646413803\n",
      "trial: 3, iter: 12200, curr loss: 1.381427526473999, avg loss: 1.3824984246492387\n",
      "trial: 3, iter: 12400, curr loss: 1.374800205230713, avg loss: 1.3788825243711471\n",
      "trial: 3, iter: 12600, curr loss: 1.3589584827423096, avg loss: 1.3714178538322448\n",
      "trial: 3, iter: 12800, curr loss: 1.3519816398620605, avg loss: 1.3639369302988051\n",
      "trial: 3, iter: 13000, curr loss: 1.3389941453933716, avg loss: 1.3502198088169097\n",
      "trial: 3, iter: 13200, curr loss: 1.3236019611358643, avg loss: 1.3432746261358262\n",
      "trial: 3, iter: 13400, curr loss: 1.3507235050201416, avg loss: 1.3389781272411347\n",
      "trial: 3, iter: 13600, curr loss: 1.329613208770752, avg loss: 1.3358459240198135\n",
      "trial: 3, iter: 13800, curr loss: 1.3313193321228027, avg loss: 1.3297522032260896\n",
      "trial: 3, iter: 14000, curr loss: 1.3155567646026611, avg loss: 1.3294788074493409\n",
      "trial: 3, iter: 14200, curr loss: 1.305855393409729, avg loss: 1.3278971803188324\n",
      "trial: 3, iter: 14400, curr loss: 1.3369708061218262, avg loss: 1.3254805767536164\n",
      "trial: 3, iter: 14600, curr loss: 1.3148126602172852, avg loss: 1.3260179018974305\n",
      "trial: 3, iter: 14800, curr loss: 1.3342446088790894, avg loss: 1.324736230969429\n",
      "trial: 3, iter: 15000, curr loss: 1.3174717426300049, avg loss: 1.3232156819105148\n",
      "trial: 3, iter: 15200, curr loss: 1.3102524280548096, avg loss: 1.322467805147171\n",
      "trial: 3, iter: 15400, curr loss: 1.3109880685806274, avg loss: 1.3232523387670516\n",
      "trial: 3, iter: 15600, curr loss: 1.3022270202636719, avg loss: 1.3209766364097595\n",
      "trial: 3, ldr: 0.39613693952560425\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3869847059249878, avg loss: 1.3872412127256393\n",
      "trial: 4, iter: 400, curr loss: 1.387981653213501, avg loss: 1.3867741614580154\n",
      "trial: 4, iter: 600, curr loss: 1.3857067823410034, avg loss: 1.3867366290092469\n",
      "trial: 4, iter: 800, curr loss: 1.3847324848175049, avg loss: 1.3865008437633515\n",
      "trial: 4, iter: 1000, curr loss: 1.388613224029541, avg loss: 1.386415899991989\n",
      "trial: 4, iter: 1200, curr loss: 1.3857645988464355, avg loss: 1.3865302562713624\n",
      "trial: 4, iter: 1400, curr loss: 1.3865008354187012, avg loss: 1.3863600420951843\n",
      "trial: 4, iter: 1600, curr loss: 1.386208176612854, avg loss: 1.3865093785524367\n",
      "trial: 4, iter: 1800, curr loss: 1.3869919776916504, avg loss: 1.3863752728700638\n",
      "trial: 4, iter: 2000, curr loss: 1.3866726160049438, avg loss: 1.386433036327362\n",
      "trial: 4, iter: 2200, curr loss: 1.386423945426941, avg loss: 1.3863256788253784\n",
      "trial: 4, iter: 2400, curr loss: 1.3851590156555176, avg loss: 1.386384937763214\n",
      "trial: 4, iter: 2600, curr loss: 1.3859857320785522, avg loss: 1.3862703847885132\n",
      "trial: 4, iter: 2800, curr loss: 1.386474370956421, avg loss: 1.3863849836587905\n",
      "trial: 4, iter: 3000, curr loss: 1.386149287223816, avg loss: 1.3863416349887847\n",
      "trial: 4, iter: 3200, curr loss: 1.3860613107681274, avg loss: 1.3863785684108734\n",
      "trial: 4, iter: 3400, curr loss: 1.3864601850509644, avg loss: 1.3862681823968888\n",
      "trial: 4, iter: 3600, curr loss: 1.386405110359192, avg loss: 1.3863555723428727\n",
      "trial: 4, iter: 3800, curr loss: 1.3859517574310303, avg loss: 1.3863287955522536\n",
      "trial: 4, iter: 4000, curr loss: 1.3857179880142212, avg loss: 1.3863302129507065\n",
      "trial: 4, iter: 4200, curr loss: 1.3862987756729126, avg loss: 1.3863281029462815\n",
      "trial: 4, iter: 4400, curr loss: 1.3860584497451782, avg loss: 1.3863507896661758\n",
      "trial: 4, iter: 4600, curr loss: 1.3871568441390991, avg loss: 1.3863579457998276\n",
      "trial: 4, iter: 4800, curr loss: 1.386036992073059, avg loss: 1.3863396006822586\n",
      "trial: 4, iter: 5000, curr loss: 1.3862875699996948, avg loss: 1.3863566845655442\n",
      "trial: 4, iter: 5200, curr loss: 1.3856669664382935, avg loss: 1.3862929266691209\n",
      "trial: 4, iter: 5400, curr loss: 1.386826992034912, avg loss: 1.3863507062196732\n",
      "trial: 4, iter: 5600, curr loss: 1.3861522674560547, avg loss: 1.3863235318660736\n",
      "trial: 4, iter: 5800, curr loss: 1.3868542909622192, avg loss: 1.386325919032097\n",
      "trial: 4, iter: 6000, curr loss: 1.385999083518982, avg loss: 1.3863683927059174\n",
      "trial: 4, iter: 6200, curr loss: 1.3857697248458862, avg loss: 1.3863362658023834\n",
      "trial: 4, iter: 6400, curr loss: 1.386048674583435, avg loss: 1.3863108497858048\n",
      "trial: 4, iter: 6600, curr loss: 1.3871393203735352, avg loss: 1.3863169276714324\n",
      "trial: 4, iter: 6800, curr loss: 1.3872736692428589, avg loss: 1.386294429898262\n",
      "trial: 4, iter: 7000, curr loss: 1.3852932453155518, avg loss: 1.3860276389122008\n",
      "trial: 4, iter: 7200, curr loss: 1.3850139379501343, avg loss: 1.3860270673036574\n",
      "trial: 4, iter: 7400, curr loss: 1.381639003753662, avg loss: 1.38480038523674\n",
      "trial: 4, iter: 7600, curr loss: 1.3845158815383911, avg loss: 1.3819490730762483\n",
      "trial: 4, iter: 7800, curr loss: 1.3715730905532837, avg loss: 1.3728844022750855\n",
      "trial: 4, iter: 8000, curr loss: 1.3877642154693604, avg loss: 1.3657115477323531\n",
      "trial: 4, iter: 8200, curr loss: 1.3669469356536865, avg loss: 1.3628211003541946\n",
      "trial: 4, iter: 8400, curr loss: 1.3434303998947144, avg loss: 1.359779760837555\n",
      "trial: 4, iter: 8600, curr loss: 1.3467097282409668, avg loss: 1.3567040073871612\n",
      "trial: 4, iter: 8800, curr loss: 1.344334363937378, avg loss: 1.35671506524086\n",
      "trial: 4, iter: 9000, curr loss: 1.3610033988952637, avg loss: 1.3555141061544418\n",
      "trial: 4, iter: 9200, curr loss: 1.3519998788833618, avg loss: 1.3526630526781083\n",
      "trial: 4, iter: 9400, curr loss: 1.335547685623169, avg loss: 1.349227835536003\n",
      "trial: 4, iter: 9600, curr loss: 1.3680734634399414, avg loss: 1.3462706696987152\n",
      "trial: 4, iter: 9800, curr loss: 1.3393248319625854, avg loss: 1.343931463956833\n",
      "trial: 4, iter: 10000, curr loss: 1.3473737239837646, avg loss: 1.339266876578331\n",
      "trial: 4, iter: 10200, curr loss: 1.3117237091064453, avg loss: 1.3350256884098053\n",
      "trial: 4, iter: 10400, curr loss: 1.3239930868148804, avg loss: 1.333575623035431\n",
      "trial: 4, iter: 10600, curr loss: 1.3284471035003662, avg loss: 1.329990211725235\n",
      "trial: 4, iter: 10800, curr loss: 1.3164042234420776, avg loss: 1.3297838687896728\n",
      "trial: 4, iter: 11000, curr loss: 1.324968934059143, avg loss: 1.3276321190595626\n",
      "trial: 4, iter: 11200, curr loss: 1.3111953735351562, avg loss: 1.3276234805583953\n",
      "trial: 4, iter: 11400, curr loss: 1.30925452709198, avg loss: 1.325275092124939\n",
      "trial: 4, iter: 11600, curr loss: 1.331233263015747, avg loss: 1.3236039364337921\n",
      "trial: 4, iter: 11800, curr loss: 1.3182177543640137, avg loss: 1.3216326659917832\n",
      "trial: 4, iter: 12000, curr loss: 1.3232460021972656, avg loss: 1.3236897867918014\n",
      "trial: 4, iter: 12200, curr loss: 1.3030831813812256, avg loss: 1.3226123428344727\n",
      "trial: 4, iter: 12400, curr loss: 1.3196252584457397, avg loss: 1.3219394528865813\n",
      "trial: 4, iter: 12600, curr loss: 1.3143044710159302, avg loss: 1.3200527346134185\n",
      "trial: 4, iter: 12800, curr loss: 1.3051189184188843, avg loss: 1.3200761061906814\n",
      "trial: 4, iter: 13000, curr loss: 1.2757960557937622, avg loss: 1.3171142065525054\n",
      "trial: 4, iter: 13200, curr loss: 1.3106931447982788, avg loss: 1.318015392422676\n",
      "trial: 4, iter: 13400, curr loss: 1.3255658149719238, avg loss: 1.3197113811969756\n",
      "trial: 4, iter: 13600, curr loss: 1.3053247928619385, avg loss: 1.3203789299726487\n",
      "trial: 4, iter: 13800, curr loss: 1.3164136409759521, avg loss: 1.317040930390358\n",
      "trial: 4, iter: 14000, curr loss: 1.3227757215499878, avg loss: 1.3168070459365844\n",
      "trial: 4, iter: 14200, curr loss: 1.3377964496612549, avg loss: 1.3190661585330963\n",
      "trial: 4, iter: 14400, curr loss: 1.3404284715652466, avg loss: 1.3195335751771926\n",
      "trial: 4, iter: 14600, curr loss: 1.350100040435791, avg loss: 1.3196342068910598\n",
      "trial: 4, iter: 14800, curr loss: 1.3412425518035889, avg loss: 1.32124307513237\n",
      "trial: 4, iter: 15000, curr loss: 1.3080350160598755, avg loss: 1.3175168484449387\n",
      "trial: 4, iter: 15200, curr loss: 1.3213400840759277, avg loss: 1.3192730218172073\n",
      "trial: 4, iter: 15400, curr loss: 1.310193419456482, avg loss: 1.3177897012233735\n",
      "trial: 4, iter: 15600, curr loss: 1.3029022216796875, avg loss: 1.3176412427425384\n",
      "trial: 4, ldr: 0.32062438130378723\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.38661789894104, avg loss: 1.3872977459430695\n",
      "trial: 5, iter: 400, curr loss: 1.3918688297271729, avg loss: 1.386633775830269\n",
      "trial: 5, iter: 600, curr loss: 1.3879847526550293, avg loss: 1.3866362071037293\n",
      "trial: 5, iter: 800, curr loss: 1.3863598108291626, avg loss: 1.386565945148468\n",
      "trial: 5, iter: 1000, curr loss: 1.3853578567504883, avg loss: 1.3864081966876984\n",
      "trial: 5, iter: 1200, curr loss: 1.3876186609268188, avg loss: 1.386459767818451\n",
      "trial: 5, iter: 1400, curr loss: 1.3857011795043945, avg loss: 1.386365415453911\n",
      "trial: 5, iter: 1600, curr loss: 1.385790467262268, avg loss: 1.3864406603574753\n",
      "trial: 5, iter: 1800, curr loss: 1.3858177661895752, avg loss: 1.386391168832779\n",
      "trial: 5, iter: 2000, curr loss: 1.38706374168396, avg loss: 1.3863369739055633\n",
      "trial: 5, iter: 2200, curr loss: 1.385847806930542, avg loss: 1.3863787418603897\n",
      "trial: 5, iter: 2400, curr loss: 1.3874999284744263, avg loss: 1.3863485598564147\n",
      "trial: 5, iter: 2600, curr loss: 1.3864765167236328, avg loss: 1.3863440030813217\n",
      "trial: 5, iter: 2800, curr loss: 1.3859968185424805, avg loss: 1.386365584731102\n",
      "trial: 5, iter: 3000, curr loss: 1.3874328136444092, avg loss: 1.386297914981842\n",
      "trial: 5, iter: 3200, curr loss: 1.386273741722107, avg loss: 1.3863329261541366\n",
      "trial: 5, iter: 3400, curr loss: 1.3868334293365479, avg loss: 1.38634685754776\n",
      "trial: 5, iter: 3600, curr loss: 1.386491298675537, avg loss: 1.3863682752847672\n",
      "trial: 5, iter: 3800, curr loss: 1.3868428468704224, avg loss: 1.386339110136032\n",
      "trial: 5, iter: 4000, curr loss: 1.386300802230835, avg loss: 1.3863593411445618\n",
      "trial: 5, iter: 4200, curr loss: 1.3865468502044678, avg loss: 1.3863224917650223\n",
      "trial: 5, iter: 4400, curr loss: 1.3863542079925537, avg loss: 1.386337588429451\n",
      "trial: 5, iter: 4600, curr loss: 1.3871053457260132, avg loss: 1.3862490391731261\n",
      "trial: 5, iter: 4800, curr loss: 1.3866456747055054, avg loss: 1.386360728740692\n",
      "trial: 5, iter: 5000, curr loss: 1.386246681213379, avg loss: 1.386314372420311\n",
      "trial: 5, iter: 5200, curr loss: 1.386122703552246, avg loss: 1.386317665576935\n",
      "trial: 5, iter: 5400, curr loss: 1.3864095211029053, avg loss: 1.386301937699318\n",
      "trial: 5, iter: 5600, curr loss: 1.3859670162200928, avg loss: 1.3863389575481415\n",
      "trial: 5, iter: 5800, curr loss: 1.3864339590072632, avg loss: 1.3863119721412658\n",
      "trial: 5, iter: 6000, curr loss: 1.3866991996765137, avg loss: 1.386311565041542\n",
      "trial: 5, iter: 6200, curr loss: 1.3862535953521729, avg loss: 1.3863015758991242\n",
      "trial: 5, iter: 6400, curr loss: 1.3860716819763184, avg loss: 1.386331369280815\n",
      "trial: 5, iter: 6600, curr loss: 1.3859108686447144, avg loss: 1.3863213884830474\n",
      "trial: 5, iter: 6800, curr loss: 1.386742353439331, avg loss: 1.3863066583871841\n",
      "trial: 5, iter: 7000, curr loss: 1.3862937688827515, avg loss: 1.386317995786667\n",
      "trial: 5, iter: 7200, curr loss: 1.3856414556503296, avg loss: 1.3862752878665925\n",
      "trial: 5, iter: 7400, curr loss: 1.3864434957504272, avg loss: 1.3863359469175338\n",
      "trial: 5, iter: 7600, curr loss: 1.385378360748291, avg loss: 1.3862845551967622\n",
      "trial: 5, iter: 7800, curr loss: 1.3865721225738525, avg loss: 1.386362702846527\n",
      "trial: 5, iter: 8000, curr loss: 1.386294960975647, avg loss: 1.3863293188810348\n",
      "trial: 5, iter: 8200, curr loss: 1.3865714073181152, avg loss: 1.3862728434801102\n",
      "trial: 5, iter: 8400, curr loss: 1.3869441747665405, avg loss: 1.3863453274965287\n",
      "trial: 5, iter: 8600, curr loss: 1.3861125707626343, avg loss: 1.38632184445858\n",
      "trial: 5, iter: 8800, curr loss: 1.3863375186920166, avg loss: 1.3862884312868118\n",
      "trial: 5, iter: 9000, curr loss: 1.3863983154296875, avg loss: 1.38632588326931\n",
      "trial: 5, iter: 9200, curr loss: 1.3868738412857056, avg loss: 1.3862762922048568\n",
      "trial: 5, iter: 9400, curr loss: 1.385833978652954, avg loss: 1.386304412484169\n",
      "trial: 5, iter: 9600, curr loss: 1.3860787153244019, avg loss: 1.3862851464748382\n",
      "trial: 5, iter: 9800, curr loss: 1.3856797218322754, avg loss: 1.386342894434929\n",
      "trial: 5, iter: 10000, curr loss: 1.3871629238128662, avg loss: 1.3862828975915908\n",
      "trial: 5, iter: 10200, curr loss: 1.385672926902771, avg loss: 1.3863024759292601\n",
      "trial: 5, iter: 10400, curr loss: 1.387848138809204, avg loss: 1.3863228917121888\n",
      "trial: 5, iter: 10600, curr loss: 1.3868132829666138, avg loss: 1.3863322657346726\n",
      "trial: 5, iter: 10800, curr loss: 1.385660171508789, avg loss: 1.3862256759405136\n",
      "trial: 5, iter: 11000, curr loss: 1.3861876726150513, avg loss: 1.3862918031215667\n",
      "trial: 5, iter: 11200, curr loss: 1.386709451675415, avg loss: 1.3862821263074876\n",
      "trial: 5, iter: 11400, curr loss: 1.3861029148101807, avg loss: 1.3862308794260025\n",
      "trial: 5, iter: 11600, curr loss: 1.3864755630493164, avg loss: 1.386279854774475\n",
      "trial: 5, iter: 11800, curr loss: 1.3853014707565308, avg loss: 1.3862994861602784\n",
      "trial: 5, iter: 12000, curr loss: 1.3865599632263184, avg loss: 1.3862271589040756\n",
      "trial: 5, iter: 12200, curr loss: 1.3862125873565674, avg loss: 1.3862662851810454\n",
      "trial: 5, iter: 12400, curr loss: 1.3862324953079224, avg loss: 1.3862769246101379\n",
      "trial: 5, iter: 12600, curr loss: 1.3857940435409546, avg loss: 1.3862332850694656\n",
      "trial: 5, iter: 12800, curr loss: 1.3864530324935913, avg loss: 1.3862730610370635\n",
      "trial: 5, iter: 13000, curr loss: 1.3862162828445435, avg loss: 1.386181696653366\n",
      "trial: 5, iter: 13200, curr loss: 1.386351227760315, avg loss: 1.386223514676094\n",
      "trial: 5, iter: 13400, curr loss: 1.3864305019378662, avg loss: 1.386136229634285\n",
      "trial: 5, iter: 13600, curr loss: 1.3864620923995972, avg loss: 1.386047478914261\n",
      "trial: 5, iter: 13800, curr loss: 1.3862384557724, avg loss: 1.3861698299646377\n",
      "trial: 5, iter: 14000, curr loss: 1.387673020362854, avg loss: 1.3860331332683564\n",
      "trial: 5, iter: 14200, curr loss: 1.387052059173584, avg loss: 1.3859768575429916\n",
      "trial: 5, iter: 14400, curr loss: 1.3852920532226562, avg loss: 1.3861868089437486\n",
      "trial: 5, iter: 14600, curr loss: 1.383055329322815, avg loss: 1.386005895137787\n",
      "trial: 5, iter: 14800, curr loss: 1.386372447013855, avg loss: 1.3859499239921569\n",
      "trial: 5, iter: 15000, curr loss: 1.3882057666778564, avg loss: 1.3858768916130066\n",
      "trial: 5, iter: 15200, curr loss: 1.383764386177063, avg loss: 1.3859980922937394\n",
      "trial: 5, iter: 15400, curr loss: 1.3837878704071045, avg loss: 1.3858398938179015\n",
      "trial: 5, iter: 15600, curr loss: 1.385833740234375, avg loss: 1.3857672333717346\n",
      "trial: 5, ldr: 0.0013632774353027344\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.27482752203941346\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3917449712753296, avg loss: 1.3875052446126939\n",
      "trial: 1, iter: 400, curr loss: 1.386906385421753, avg loss: 1.3869172257184983\n",
      "trial: 1, iter: 600, curr loss: 1.3864134550094604, avg loss: 1.3867957413196563\n",
      "trial: 1, iter: 800, curr loss: 1.3863469362258911, avg loss: 1.386557799577713\n",
      "trial: 1, iter: 1000, curr loss: 1.3880349397659302, avg loss: 1.3864144164323806\n",
      "trial: 1, iter: 1200, curr loss: 1.3863813877105713, avg loss: 1.3865050095319749\n",
      "trial: 1, iter: 1400, curr loss: 1.386240005493164, avg loss: 1.3864767807722091\n",
      "trial: 1, iter: 1600, curr loss: 1.3854899406433105, avg loss: 1.386258346438408\n",
      "trial: 1, iter: 1800, curr loss: 1.3848758935928345, avg loss: 1.3864736688137054\n",
      "trial: 1, iter: 2000, curr loss: 1.385310173034668, avg loss: 1.3864124703407288\n",
      "trial: 1, iter: 2200, curr loss: 1.3859949111938477, avg loss: 1.3864873731136322\n",
      "trial: 1, iter: 2400, curr loss: 1.386778712272644, avg loss: 1.3863814479112626\n",
      "trial: 1, iter: 2600, curr loss: 1.3869905471801758, avg loss: 1.3863350039720534\n",
      "trial: 1, iter: 2800, curr loss: 1.3857344388961792, avg loss: 1.3863781702518463\n",
      "trial: 1, iter: 3000, curr loss: 1.38608980178833, avg loss: 1.3863840806484222\n",
      "trial: 1, iter: 3200, curr loss: 1.3857892751693726, avg loss: 1.3863017743825912\n",
      "trial: 1, iter: 3400, curr loss: 1.386368751525879, avg loss: 1.3863309836387634\n",
      "trial: 1, iter: 3600, curr loss: 1.3867496252059937, avg loss: 1.3862953966856002\n",
      "trial: 1, iter: 3800, curr loss: 1.3859663009643555, avg loss: 1.3863686621189117\n",
      "trial: 1, iter: 4000, curr loss: 1.3867300748825073, avg loss: 1.3863351440429688\n",
      "trial: 1, iter: 4200, curr loss: 1.386292815208435, avg loss: 1.386335397362709\n",
      "trial: 1, iter: 4400, curr loss: 1.3860416412353516, avg loss: 1.3863200891017913\n",
      "trial: 1, iter: 4600, curr loss: 1.3864405155181885, avg loss: 1.3863471800088882\n",
      "trial: 1, iter: 4800, curr loss: 1.3864645957946777, avg loss: 1.3863214725255966\n",
      "trial: 1, iter: 5000, curr loss: 1.3859983682632446, avg loss: 1.3862946432828904\n",
      "trial: 1, iter: 5200, curr loss: 1.3856879472732544, avg loss: 1.3863199877738952\n",
      "trial: 1, iter: 5400, curr loss: 1.3862016201019287, avg loss: 1.3863197654485702\n",
      "trial: 1, iter: 5600, curr loss: 1.3868216276168823, avg loss: 1.3863219487667084\n",
      "trial: 1, iter: 5800, curr loss: 1.386562466621399, avg loss: 1.3863150173425673\n",
      "trial: 1, iter: 6000, curr loss: 1.3866448402404785, avg loss: 1.3863201159238816\n",
      "trial: 1, iter: 6200, curr loss: 1.3859984874725342, avg loss: 1.3863433849811555\n",
      "trial: 1, iter: 6400, curr loss: 1.3856700658798218, avg loss: 1.3863647341728211\n",
      "trial: 1, iter: 6600, curr loss: 1.387060523033142, avg loss: 1.3863471919298171\n",
      "trial: 1, iter: 6800, curr loss: 1.3866066932678223, avg loss: 1.386361793279648\n",
      "trial: 1, iter: 7000, curr loss: 1.3862460851669312, avg loss: 1.3863490688800812\n",
      "trial: 1, iter: 7200, curr loss: 1.3872222900390625, avg loss: 1.386320242881775\n",
      "trial: 1, iter: 7400, curr loss: 1.386466383934021, avg loss: 1.3863485395908355\n",
      "trial: 1, iter: 7600, curr loss: 1.3859968185424805, avg loss: 1.3863004916906356\n",
      "trial: 1, iter: 7800, curr loss: 1.3864980936050415, avg loss: 1.386428223848343\n",
      "trial: 1, iter: 8000, curr loss: 1.3865196704864502, avg loss: 1.3863150781393052\n",
      "trial: 1, iter: 8200, curr loss: 1.3862886428833008, avg loss: 1.3862828600406647\n",
      "trial: 1, iter: 8400, curr loss: 1.386316180229187, avg loss: 1.3863206911087036\n",
      "trial: 1, iter: 8600, curr loss: 1.3864970207214355, avg loss: 1.3863176822662353\n",
      "trial: 1, iter: 8800, curr loss: 1.3861507177352905, avg loss: 1.3863094997406007\n",
      "trial: 1, iter: 9000, curr loss: 1.3865127563476562, avg loss: 1.3863180416822434\n",
      "trial: 1, iter: 9200, curr loss: 1.3866913318634033, avg loss: 1.3862960571050644\n",
      "trial: 1, iter: 9400, curr loss: 1.386387825012207, avg loss: 1.3863286089897155\n",
      "trial: 1, iter: 9600, curr loss: 1.3855249881744385, avg loss: 1.3863167357444763\n",
      "trial: 1, iter: 9800, curr loss: 1.3864225149154663, avg loss: 1.386310328245163\n",
      "trial: 1, iter: 10000, curr loss: 1.3868147134780884, avg loss: 1.3863353860378265\n",
      "trial: 1, iter: 10200, curr loss: 1.385819435119629, avg loss: 1.3863182425498963\n",
      "trial: 1, iter: 10400, curr loss: 1.385941743850708, avg loss: 1.3862584221363068\n",
      "trial: 1, iter: 10600, curr loss: 1.386627197265625, avg loss: 1.3863580363988877\n",
      "trial: 1, iter: 10800, curr loss: 1.386575698852539, avg loss: 1.3863149172067641\n",
      "trial: 1, iter: 11000, curr loss: 1.3861981630325317, avg loss: 1.3862971949577332\n",
      "trial: 1, iter: 11200, curr loss: 1.387453317642212, avg loss: 1.3862653678655625\n",
      "trial: 1, iter: 11400, curr loss: 1.3868727684020996, avg loss: 1.3862791150808333\n",
      "trial: 1, iter: 11600, curr loss: 1.386099100112915, avg loss: 1.3862873721122742\n",
      "trial: 1, iter: 11800, curr loss: 1.3865911960601807, avg loss: 1.3862707287073135\n",
      "trial: 1, iter: 12000, curr loss: 1.3846627473831177, avg loss: 1.3861991614103317\n",
      "trial: 1, iter: 12200, curr loss: 1.384988784790039, avg loss: 1.3859265583753586\n",
      "trial: 1, iter: 12400, curr loss: 1.3859299421310425, avg loss: 1.3849262237548827\n",
      "trial: 1, iter: 12600, curr loss: 1.372053623199463, avg loss: 1.3817147833108903\n",
      "trial: 1, iter: 12800, curr loss: 1.3744349479675293, avg loss: 1.3781734883785248\n",
      "trial: 1, iter: 13000, curr loss: 1.3801846504211426, avg loss: 1.3745475423336029\n",
      "trial: 1, iter: 13200, curr loss: 1.364396572113037, avg loss: 1.3661011785268784\n",
      "trial: 1, iter: 13400, curr loss: 1.3861794471740723, avg loss: 1.3620499569177626\n",
      "trial: 1, iter: 13600, curr loss: 1.3601958751678467, avg loss: 1.3577727431058884\n",
      "trial: 1, iter: 13800, curr loss: 1.3487316370010376, avg loss: 1.3535339063405991\n",
      "trial: 1, iter: 14000, curr loss: 1.3587403297424316, avg loss: 1.3477314412593842\n",
      "trial: 1, iter: 14200, curr loss: 1.344550609588623, avg loss: 1.3404862070083619\n",
      "trial: 1, iter: 14400, curr loss: 1.3286311626434326, avg loss: 1.3367755228281022\n",
      "trial: 1, iter: 14600, curr loss: 1.35573410987854, avg loss: 1.3371192997694015\n",
      "trial: 1, iter: 14800, curr loss: 1.3849595785140991, avg loss: 1.3345147168636322\n",
      "trial: 1, iter: 15000, curr loss: 1.3321020603179932, avg loss: 1.3329477232694626\n",
      "trial: 1, iter: 15200, curr loss: 1.3243770599365234, avg loss: 1.3331049126386643\n",
      "trial: 1, iter: 15400, curr loss: 1.345255970954895, avg loss: 1.3297053802013397\n",
      "trial: 1, iter: 15600, curr loss: 1.3313541412353516, avg loss: 1.3270577162504196\n",
      "trial: 1, ldr: 0.3154229521751404\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3888081312179565, avg loss: 1.3875167852640151\n",
      "trial: 2, iter: 400, curr loss: 1.3906141519546509, avg loss: 1.386687000989914\n",
      "trial: 2, iter: 600, curr loss: 1.3849631547927856, avg loss: 1.3865776348114014\n",
      "trial: 2, iter: 800, curr loss: 1.3886538743972778, avg loss: 1.3865129107236862\n",
      "trial: 2, iter: 1000, curr loss: 1.386301040649414, avg loss: 1.3864664489030838\n",
      "trial: 2, iter: 1200, curr loss: 1.3851736783981323, avg loss: 1.386570644378662\n",
      "trial: 2, iter: 1400, curr loss: 1.3859076499938965, avg loss: 1.3864216309785844\n",
      "trial: 2, iter: 1600, curr loss: 1.386271595954895, avg loss: 1.386391166448593\n",
      "trial: 2, iter: 1800, curr loss: 1.3868954181671143, avg loss: 1.3863523763418197\n",
      "trial: 2, iter: 2000, curr loss: 1.384916067123413, avg loss: 1.3863926094770431\n",
      "trial: 2, iter: 2200, curr loss: 1.3878997564315796, avg loss: 1.3864063376188278\n",
      "trial: 2, iter: 2400, curr loss: 1.3866652250289917, avg loss: 1.3863510745763779\n",
      "trial: 2, iter: 2600, curr loss: 1.3866384029388428, avg loss: 1.386310322880745\n",
      "trial: 2, iter: 2800, curr loss: 1.3846334218978882, avg loss: 1.386321160197258\n",
      "trial: 2, iter: 3000, curr loss: 1.3861366510391235, avg loss: 1.386412220597267\n",
      "trial: 2, iter: 3200, curr loss: 1.3865582942962646, avg loss: 1.3863269484043121\n",
      "trial: 2, iter: 3400, curr loss: 1.3855267763137817, avg loss: 1.3862739425897599\n",
      "trial: 2, iter: 3600, curr loss: 1.3863402605056763, avg loss: 1.3863640356063842\n",
      "trial: 2, iter: 3800, curr loss: 1.3857661485671997, avg loss: 1.3863387775421143\n",
      "trial: 2, iter: 4000, curr loss: 1.3866584300994873, avg loss: 1.3862906897068024\n",
      "trial: 2, iter: 4200, curr loss: 1.3841359615325928, avg loss: 1.3862453174591065\n",
      "trial: 2, iter: 4400, curr loss: 1.3827894926071167, avg loss: 1.3853175443410874\n",
      "trial: 2, iter: 4600, curr loss: 1.3758951425552368, avg loss: 1.38158840239048\n",
      "trial: 2, iter: 4800, curr loss: 1.3642892837524414, avg loss: 1.3747073954343796\n",
      "trial: 2, iter: 5000, curr loss: 1.3568580150604248, avg loss: 1.365342561006546\n",
      "trial: 2, iter: 5200, curr loss: 1.372161626815796, avg loss: 1.3624459129571915\n",
      "trial: 2, iter: 5400, curr loss: 1.3710613250732422, avg loss: 1.3590321451425553\n",
      "trial: 2, iter: 5600, curr loss: 1.3515348434448242, avg loss: 1.357085456252098\n",
      "trial: 2, iter: 5800, curr loss: 1.3811179399490356, avg loss: 1.3556773722171784\n",
      "trial: 2, iter: 6000, curr loss: 1.3554390668869019, avg loss: 1.3553680688142777\n",
      "trial: 2, iter: 6200, curr loss: 1.3695878982543945, avg loss: 1.353856845498085\n",
      "trial: 2, iter: 6400, curr loss: 1.3517554998397827, avg loss: 1.3506171905994415\n",
      "trial: 2, iter: 6600, curr loss: 1.357287883758545, avg loss: 1.344066025018692\n",
      "trial: 2, iter: 6800, curr loss: 1.3470441102981567, avg loss: 1.3416256326436997\n",
      "trial: 2, iter: 7000, curr loss: 1.3327085971832275, avg loss: 1.341351170539856\n",
      "trial: 2, iter: 7200, curr loss: 1.3125439882278442, avg loss: 1.3368818652629852\n",
      "trial: 2, iter: 7400, curr loss: 1.3430122137069702, avg loss: 1.3353452324867248\n",
      "trial: 2, iter: 7600, curr loss: 1.3352203369140625, avg loss: 1.3312730765342713\n",
      "trial: 2, iter: 7800, curr loss: 1.3290562629699707, avg loss: 1.3313195949792862\n",
      "trial: 2, iter: 8000, curr loss: 1.3199633359909058, avg loss: 1.3282064521312713\n",
      "trial: 2, iter: 8200, curr loss: 1.3533011674880981, avg loss: 1.329169393181801\n",
      "trial: 2, iter: 8400, curr loss: 1.3253917694091797, avg loss: 1.3269841122627257\n",
      "trial: 2, iter: 8600, curr loss: 1.3323910236358643, avg loss: 1.3254524046182632\n",
      "trial: 2, iter: 8800, curr loss: 1.3182165622711182, avg loss: 1.3260537767410279\n",
      "trial: 2, iter: 9000, curr loss: 1.2975894212722778, avg loss: 1.3241426241397858\n",
      "trial: 2, iter: 9200, curr loss: 1.3078721761703491, avg loss: 1.3232516092061997\n",
      "trial: 2, iter: 9400, curr loss: 1.3188830614089966, avg loss: 1.322210522890091\n",
      "trial: 2, iter: 9600, curr loss: 1.3012396097183228, avg loss: 1.3213752061128616\n",
      "trial: 2, iter: 9800, curr loss: 1.2947076559066772, avg loss: 1.3222472804784775\n",
      "trial: 2, iter: 10000, curr loss: 1.3467828035354614, avg loss: 1.3239763236045838\n",
      "trial: 2, iter: 10200, curr loss: 1.3414418697357178, avg loss: 1.3199713802337647\n",
      "trial: 2, iter: 10400, curr loss: 1.3165892362594604, avg loss: 1.3206095153093338\n",
      "trial: 2, iter: 10600, curr loss: 1.3144378662109375, avg loss: 1.3196246099472047\n",
      "trial: 2, iter: 10800, curr loss: 1.3051338195800781, avg loss: 1.3186329221725464\n",
      "trial: 2, iter: 11000, curr loss: 1.3378392457962036, avg loss: 1.3194892144203185\n",
      "trial: 2, iter: 11200, curr loss: 1.3314881324768066, avg loss: 1.3176442450284958\n",
      "trial: 2, iter: 11400, curr loss: 1.2968510389328003, avg loss: 1.3193157547712326\n",
      "trial: 2, iter: 11600, curr loss: 1.3336845636367798, avg loss: 1.3183156108856202\n",
      "trial: 2, iter: 11800, curr loss: 1.3184092044830322, avg loss: 1.3172482174634934\n",
      "trial: 2, iter: 12000, curr loss: 1.3053280115127563, avg loss: 1.3171200031042098\n",
      "trial: 2, iter: 12200, curr loss: 1.3293287754058838, avg loss: 1.3156762874126435\n",
      "trial: 2, iter: 12400, curr loss: 1.3136814832687378, avg loss: 1.3186638575792313\n",
      "trial: 2, iter: 12600, curr loss: 1.3309261798858643, avg loss: 1.3207713544368744\n",
      "trial: 2, iter: 12800, curr loss: 1.3329702615737915, avg loss: 1.3180495208501817\n",
      "trial: 2, iter: 13000, curr loss: 1.31236732006073, avg loss: 1.315130997300148\n",
      "trial: 2, iter: 13200, curr loss: 1.3453460931777954, avg loss: 1.3168378448486329\n",
      "trial: 2, iter: 13400, curr loss: 1.3367494344711304, avg loss: 1.3167324048280715\n",
      "trial: 2, iter: 13600, curr loss: 1.323991298675537, avg loss: 1.3151893192529678\n",
      "trial: 2, iter: 13800, curr loss: 1.3140826225280762, avg loss: 1.3172117424011232\n",
      "trial: 2, iter: 14000, curr loss: 1.3205024003982544, avg loss: 1.3157769352197648\n",
      "trial: 2, iter: 14200, curr loss: 1.317492127418518, avg loss: 1.3153747999668122\n",
      "trial: 2, iter: 14400, curr loss: 1.2968921661376953, avg loss: 1.3150321972370147\n",
      "trial: 2, iter: 14600, curr loss: 1.315064549446106, avg loss: 1.3156070458889007\n",
      "trial: 2, iter: 14800, curr loss: 1.3226722478866577, avg loss: 1.3137124848365784\n",
      "trial: 2, iter: 15000, curr loss: 1.2956207990646362, avg loss: 1.3154689967632294\n",
      "trial: 2, iter: 15200, curr loss: 1.3283954858779907, avg loss: 1.3141610252857208\n",
      "trial: 2, iter: 15400, curr loss: 1.3580615520477295, avg loss: 1.3153735733032226\n",
      "trial: 2, iter: 15600, curr loss: 1.3189599514007568, avg loss: 1.311137860417366\n",
      "trial: 2, ldr: 0.3981570303440094\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3863788843154907, avg loss: 1.3874165713787079\n",
      "trial: 3, iter: 400, curr loss: 1.3856463432312012, avg loss: 1.3867296612262725\n",
      "trial: 3, iter: 600, curr loss: 1.3853480815887451, avg loss: 1.386585328578949\n",
      "trial: 3, iter: 800, curr loss: 1.3872894048690796, avg loss: 1.3864892303943634\n",
      "trial: 3, iter: 1000, curr loss: 1.387099266052246, avg loss: 1.3865564078092576\n",
      "trial: 3, iter: 1200, curr loss: 1.3869178295135498, avg loss: 1.3862349605560302\n",
      "trial: 3, iter: 1400, curr loss: 1.3870264291763306, avg loss: 1.386548558473587\n",
      "trial: 3, iter: 1600, curr loss: 1.3873249292373657, avg loss: 1.3864014589786529\n",
      "trial: 3, iter: 1800, curr loss: 1.3867493867874146, avg loss: 1.386388773918152\n",
      "trial: 3, iter: 2000, curr loss: 1.3866804838180542, avg loss: 1.3863074159622193\n",
      "trial: 3, iter: 2200, curr loss: 1.3863332271575928, avg loss: 1.3862853199243546\n",
      "trial: 3, iter: 2400, curr loss: 1.3865363597869873, avg loss: 1.3863889855146407\n",
      "trial: 3, iter: 2600, curr loss: 1.386303424835205, avg loss: 1.3863761216402053\n",
      "trial: 3, iter: 2800, curr loss: 1.3858067989349365, avg loss: 1.3863237780332565\n",
      "trial: 3, iter: 3000, curr loss: 1.3851866722106934, avg loss: 1.3863196903467179\n",
      "trial: 3, iter: 3200, curr loss: 1.3864829540252686, avg loss: 1.386345831155777\n",
      "trial: 3, iter: 3400, curr loss: 1.38607656955719, avg loss: 1.386318547129631\n",
      "trial: 3, iter: 3600, curr loss: 1.3861362934112549, avg loss: 1.3863218998908997\n",
      "trial: 3, iter: 3800, curr loss: 1.3865141868591309, avg loss: 1.386275866627693\n",
      "trial: 3, iter: 4000, curr loss: 1.3856847286224365, avg loss: 1.3864151138067244\n",
      "trial: 3, iter: 4200, curr loss: 1.386755108833313, avg loss: 1.3863063657283783\n",
      "trial: 3, iter: 4400, curr loss: 1.386684536933899, avg loss: 1.386313115954399\n",
      "trial: 3, iter: 4600, curr loss: 1.3863433599472046, avg loss: 1.3863219767808914\n",
      "trial: 3, iter: 4800, curr loss: 1.3862698078155518, avg loss: 1.3863018494844437\n",
      "trial: 3, iter: 5000, curr loss: 1.3847302198410034, avg loss: 1.386270071864128\n",
      "trial: 3, iter: 5200, curr loss: 1.3863717317581177, avg loss: 1.3863334321975709\n",
      "trial: 3, iter: 5400, curr loss: 1.3861820697784424, avg loss: 1.3863481152057648\n",
      "trial: 3, iter: 5600, curr loss: 1.3871484994888306, avg loss: 1.38630928337574\n",
      "trial: 3, iter: 5800, curr loss: 1.3862067461013794, avg loss: 1.3863072377443313\n",
      "trial: 3, iter: 6000, curr loss: 1.385993242263794, avg loss: 1.3863028824329375\n",
      "trial: 3, iter: 6200, curr loss: 1.3864909410476685, avg loss: 1.3863335806131363\n",
      "trial: 3, iter: 6400, curr loss: 1.3847945928573608, avg loss: 1.386312021613121\n",
      "trial: 3, iter: 6600, curr loss: 1.3863599300384521, avg loss: 1.3863620537519454\n",
      "trial: 3, iter: 6800, curr loss: 1.3864269256591797, avg loss: 1.3863525635004044\n",
      "trial: 3, iter: 7000, curr loss: 1.385341763496399, avg loss: 1.3862886065244675\n",
      "trial: 3, iter: 7200, curr loss: 1.3873639106750488, avg loss: 1.3862701547145844\n",
      "trial: 3, iter: 7400, curr loss: 1.3856391906738281, avg loss: 1.3862564277648926\n",
      "trial: 3, iter: 7600, curr loss: 1.3862662315368652, avg loss: 1.3860132277011872\n",
      "trial: 3, iter: 7800, curr loss: 1.38106107711792, avg loss: 1.3846746224164963\n",
      "trial: 3, iter: 8000, curr loss: 1.3883986473083496, avg loss: 1.3822142970561981\n",
      "trial: 3, iter: 8200, curr loss: 1.3799147605895996, avg loss: 1.3790502321720124\n",
      "trial: 3, iter: 8400, curr loss: 1.3674864768981934, avg loss: 1.3737986695766449\n",
      "trial: 3, iter: 8600, curr loss: 1.401648998260498, avg loss: 1.3630837976932526\n",
      "trial: 3, iter: 8800, curr loss: 1.350402593612671, avg loss: 1.3574097812175752\n",
      "trial: 3, iter: 9000, curr loss: 1.3388060331344604, avg loss: 1.3531474763154983\n",
      "trial: 3, iter: 9200, curr loss: 1.336897611618042, avg loss: 1.3494893789291382\n",
      "trial: 3, iter: 9400, curr loss: 1.3366364240646362, avg loss: 1.3461956781148912\n",
      "trial: 3, iter: 9600, curr loss: 1.3460842370986938, avg loss: 1.3412021368741989\n",
      "trial: 3, iter: 9800, curr loss: 1.3375437259674072, avg loss: 1.33506136238575\n",
      "trial: 3, iter: 10000, curr loss: 1.3222522735595703, avg loss: 1.334101905822754\n",
      "trial: 3, iter: 10200, curr loss: 1.3086745738983154, avg loss: 1.3291782677173614\n",
      "trial: 3, iter: 10400, curr loss: 1.322151780128479, avg loss: 1.3274895942211151\n",
      "trial: 3, iter: 10600, curr loss: 1.3299810886383057, avg loss: 1.323808850646019\n",
      "trial: 3, iter: 10800, curr loss: 1.3320413827896118, avg loss: 1.3237366110086441\n",
      "trial: 3, iter: 11000, curr loss: 1.3089185953140259, avg loss: 1.3244076067209243\n",
      "trial: 3, iter: 11200, curr loss: 1.3090155124664307, avg loss: 1.3215696287155152\n",
      "trial: 3, iter: 11400, curr loss: 1.312960147857666, avg loss: 1.3210836726427078\n",
      "trial: 3, iter: 11600, curr loss: 1.3267157077789307, avg loss: 1.3192521011829377\n",
      "trial: 3, iter: 11800, curr loss: 1.3477718830108643, avg loss: 1.3206403350830078\n",
      "trial: 3, iter: 12000, curr loss: 1.3375507593154907, avg loss: 1.3186440187692643\n",
      "trial: 3, iter: 12200, curr loss: 1.3277984857559204, avg loss: 1.319790216088295\n",
      "trial: 3, iter: 12400, curr loss: 1.3131533861160278, avg loss: 1.31860600233078\n",
      "trial: 3, iter: 12600, curr loss: 1.3429851531982422, avg loss: 1.3181234562397004\n",
      "trial: 3, iter: 12800, curr loss: 1.3299967050552368, avg loss: 1.3186867088079453\n",
      "trial: 3, iter: 13000, curr loss: 1.3589749336242676, avg loss: 1.3179672414064407\n",
      "trial: 3, iter: 13200, curr loss: 1.3258247375488281, avg loss: 1.3175959938764572\n",
      "trial: 3, iter: 13400, curr loss: 1.3119235038757324, avg loss: 1.3158878648281098\n",
      "trial: 3, iter: 13600, curr loss: 1.3079636096954346, avg loss: 1.315696688890457\n",
      "trial: 3, iter: 13800, curr loss: 1.322818398475647, avg loss: 1.3181819009780884\n",
      "trial: 3, iter: 14000, curr loss: 1.3279532194137573, avg loss: 1.3161732792854308\n",
      "trial: 3, iter: 14200, curr loss: 1.3107224702835083, avg loss: 1.3182709008455276\n",
      "trial: 3, iter: 14400, curr loss: 1.3019155263900757, avg loss: 1.3157851207256317\n",
      "trial: 3, iter: 14600, curr loss: 1.374349594116211, avg loss: 1.3156243973970414\n",
      "trial: 3, iter: 14800, curr loss: 1.3287739753723145, avg loss: 1.3188682043552398\n",
      "trial: 3, iter: 15000, curr loss: 1.3042317628860474, avg loss: 1.314252399802208\n",
      "trial: 3, iter: 15200, curr loss: 1.3134279251098633, avg loss: 1.3173917984962464\n",
      "trial: 3, iter: 15400, curr loss: 1.3124029636383057, avg loss: 1.3177176350355149\n",
      "trial: 3, iter: 15600, curr loss: 1.3100377321243286, avg loss: 1.3161770379543305\n",
      "trial: 3, ldr: 0.21422667801380157\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3855950832366943, avg loss: 1.3872973638772965\n",
      "trial: 4, iter: 400, curr loss: 1.3878782987594604, avg loss: 1.3866906398534775\n",
      "trial: 4, iter: 600, curr loss: 1.3857712745666504, avg loss: 1.3864369010925293\n",
      "trial: 4, iter: 800, curr loss: 1.3858232498168945, avg loss: 1.386534783244133\n",
      "trial: 4, iter: 1000, curr loss: 1.3855361938476562, avg loss: 1.38638802587986\n",
      "trial: 4, iter: 1200, curr loss: 1.3877350091934204, avg loss: 1.3863841480016708\n",
      "trial: 4, iter: 1400, curr loss: 1.385743260383606, avg loss: 1.3864317387342453\n",
      "trial: 4, iter: 1600, curr loss: 1.3873318433761597, avg loss: 1.3865358477830887\n",
      "trial: 4, iter: 1800, curr loss: 1.3854385614395142, avg loss: 1.3862034338712692\n",
      "trial: 4, iter: 2000, curr loss: 1.3862751722335815, avg loss: 1.386396576166153\n",
      "trial: 4, iter: 2200, curr loss: 1.3869802951812744, avg loss: 1.3863827002048492\n",
      "trial: 4, iter: 2400, curr loss: 1.3866108655929565, avg loss: 1.3863124895095824\n",
      "trial: 4, iter: 2600, curr loss: 1.3856663703918457, avg loss: 1.3863079518079757\n",
      "trial: 4, iter: 2800, curr loss: 1.3873647451400757, avg loss: 1.386386334300041\n",
      "trial: 4, iter: 3000, curr loss: 1.3867405652999878, avg loss: 1.3863270837068558\n",
      "trial: 4, iter: 3200, curr loss: 1.3857026100158691, avg loss: 1.3863091510534287\n",
      "trial: 4, iter: 3400, curr loss: 1.3860554695129395, avg loss: 1.3863739830255508\n",
      "trial: 4, iter: 3600, curr loss: 1.3859403133392334, avg loss: 1.3862939023971557\n",
      "trial: 4, iter: 3800, curr loss: 1.3864835500717163, avg loss: 1.386298684477806\n",
      "trial: 4, iter: 4000, curr loss: 1.386664628982544, avg loss: 1.3862266308069229\n",
      "trial: 4, iter: 4200, curr loss: 1.38668954372406, avg loss: 1.3863275301456452\n",
      "trial: 4, iter: 4400, curr loss: 1.3852503299713135, avg loss: 1.386322648525238\n",
      "trial: 4, iter: 4600, curr loss: 1.3869256973266602, avg loss: 1.3863848745822906\n",
      "trial: 4, iter: 4800, curr loss: 1.3867161273956299, avg loss: 1.3863441997766495\n",
      "trial: 4, iter: 5000, curr loss: 1.3866136074066162, avg loss: 1.3863180381059648\n",
      "trial: 4, iter: 5200, curr loss: 1.386460542678833, avg loss: 1.3863018661737443\n",
      "trial: 4, iter: 5400, curr loss: 1.3861467838287354, avg loss: 1.3862252640724182\n",
      "trial: 4, iter: 5600, curr loss: 1.3897197246551514, avg loss: 1.385153506398201\n",
      "trial: 4, iter: 5800, curr loss: 1.381042718887329, avg loss: 1.383329095840454\n",
      "trial: 4, iter: 6000, curr loss: 1.3791513442993164, avg loss: 1.3803336066007614\n",
      "trial: 4, iter: 6200, curr loss: 1.396012544631958, avg loss: 1.3784071719646454\n",
      "trial: 4, iter: 6400, curr loss: 1.3892208337783813, avg loss: 1.3757741749286652\n",
      "trial: 4, iter: 6600, curr loss: 1.3633029460906982, avg loss: 1.3705908650159835\n",
      "trial: 4, iter: 6800, curr loss: 1.326081395149231, avg loss: 1.360399803519249\n",
      "trial: 4, iter: 7000, curr loss: 1.3566052913665771, avg loss: 1.3540378934144974\n",
      "trial: 4, iter: 7200, curr loss: 1.3428033590316772, avg loss: 1.3482505309581756\n",
      "trial: 4, iter: 7400, curr loss: 1.3637199401855469, avg loss: 1.3444456052780152\n",
      "trial: 4, iter: 7600, curr loss: 1.333609938621521, avg loss: 1.338967097401619\n",
      "trial: 4, iter: 7800, curr loss: 1.3463568687438965, avg loss: 1.3359488636255263\n",
      "trial: 4, iter: 8000, curr loss: 1.3055683374404907, avg loss: 1.3335124909877778\n",
      "trial: 4, iter: 8200, curr loss: 1.3009368181228638, avg loss: 1.3306828820705414\n",
      "trial: 4, iter: 8400, curr loss: 1.3306370973587036, avg loss: 1.32989561855793\n",
      "trial: 4, iter: 8600, curr loss: 1.3137060403823853, avg loss: 1.3270629596710206\n",
      "trial: 4, iter: 8800, curr loss: 1.3469266891479492, avg loss: 1.3243905836343766\n",
      "trial: 4, iter: 9000, curr loss: 1.3071829080581665, avg loss: 1.324160203933716\n",
      "trial: 4, iter: 9200, curr loss: 1.3301970958709717, avg loss: 1.3246545261144638\n",
      "trial: 4, iter: 9400, curr loss: 1.3419616222381592, avg loss: 1.3242887783050536\n",
      "trial: 4, iter: 9600, curr loss: 1.3129889965057373, avg loss: 1.3214092081785203\n",
      "trial: 4, iter: 9800, curr loss: 1.3380671739578247, avg loss: 1.3199933141469955\n",
      "trial: 4, iter: 10000, curr loss: 1.3135651350021362, avg loss: 1.3217903238534927\n",
      "trial: 4, iter: 10200, curr loss: 1.3134182691574097, avg loss: 1.3206002032756805\n",
      "trial: 4, iter: 10400, curr loss: 1.3259668350219727, avg loss: 1.3224998193979263\n",
      "trial: 4, iter: 10600, curr loss: 1.2934645414352417, avg loss: 1.319915286898613\n",
      "trial: 4, iter: 10800, curr loss: 1.3394999504089355, avg loss: 1.3191139316558838\n",
      "trial: 4, iter: 11000, curr loss: 1.3563101291656494, avg loss: 1.3203228878974915\n",
      "trial: 4, iter: 11200, curr loss: 1.3460968732833862, avg loss: 1.320502246618271\n",
      "trial: 4, iter: 11400, curr loss: 1.2890268564224243, avg loss: 1.3179372411966324\n",
      "trial: 4, iter: 11600, curr loss: 1.355096697807312, avg loss: 1.3172574937343597\n",
      "trial: 4, iter: 11800, curr loss: 1.322092890739441, avg loss: 1.3169533056020737\n",
      "trial: 4, iter: 12000, curr loss: 1.3321177959442139, avg loss: 1.3174637895822525\n",
      "trial: 4, iter: 12200, curr loss: 1.3388725519180298, avg loss: 1.3168899887800216\n",
      "trial: 4, iter: 12400, curr loss: 1.3249932527542114, avg loss: 1.3192437535524368\n",
      "trial: 4, iter: 12600, curr loss: 1.3468736410140991, avg loss: 1.3188484001159668\n",
      "trial: 4, iter: 12800, curr loss: 1.326711893081665, avg loss: 1.3182291448116303\n",
      "trial: 4, iter: 13000, curr loss: 1.334594964981079, avg loss: 1.31743792116642\n",
      "trial: 4, iter: 13200, curr loss: 1.3356627225875854, avg loss: 1.317061585187912\n",
      "trial: 4, iter: 13400, curr loss: 1.341056227684021, avg loss: 1.3162104511260986\n",
      "trial: 4, iter: 13600, curr loss: 1.3644051551818848, avg loss: 1.316388264298439\n",
      "trial: 4, iter: 13800, curr loss: 1.3106609582901, avg loss: 1.3162188726663588\n",
      "trial: 4, iter: 14000, curr loss: 1.3215336799621582, avg loss: 1.317640970349312\n",
      "trial: 4, iter: 14200, curr loss: 1.3188782930374146, avg loss: 1.3158651274442672\n",
      "trial: 4, iter: 14400, curr loss: 1.288140892982483, avg loss: 1.3178128558397293\n",
      "trial: 4, iter: 14600, curr loss: 1.3284586668014526, avg loss: 1.3161966007947923\n",
      "trial: 4, iter: 14800, curr loss: 1.3094732761383057, avg loss: 1.316194640994072\n",
      "trial: 4, iter: 15000, curr loss: 1.2983918190002441, avg loss: 1.3163809782266618\n",
      "trial: 4, iter: 15200, curr loss: 1.38560950756073, avg loss: 1.315524867773056\n",
      "trial: 4, iter: 15400, curr loss: 1.3051881790161133, avg loss: 1.3173212778568268\n",
      "trial: 4, iter: 15600, curr loss: 1.3207213878631592, avg loss: 1.315205785036087\n",
      "trial: 4, ldr: 0.33457645773887634\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387973427772522, avg loss: 1.3876805925369262\n",
      "trial: 5, iter: 400, curr loss: 1.3854997158050537, avg loss: 1.3869114696979523\n",
      "trial: 5, iter: 600, curr loss: 1.3877644538879395, avg loss: 1.386656284928322\n",
      "trial: 5, iter: 800, curr loss: 1.385309100151062, avg loss: 1.3865808534622193\n",
      "trial: 5, iter: 1000, curr loss: 1.3858262300491333, avg loss: 1.3865285575389863\n",
      "trial: 5, iter: 1200, curr loss: 1.3858368396759033, avg loss: 1.386455460190773\n",
      "trial: 5, iter: 1400, curr loss: 1.388148546218872, avg loss: 1.386464585661888\n",
      "trial: 5, iter: 1600, curr loss: 1.385717749595642, avg loss: 1.3864195317029953\n",
      "trial: 5, iter: 1800, curr loss: 1.3873913288116455, avg loss: 1.386360587477684\n",
      "trial: 5, iter: 2000, curr loss: 1.3865026235580444, avg loss: 1.3865042197704316\n",
      "trial: 5, iter: 2200, curr loss: 1.3874071836471558, avg loss: 1.3864385819435119\n",
      "trial: 5, iter: 2400, curr loss: 1.384904146194458, avg loss: 1.3862516957521438\n",
      "trial: 5, iter: 2600, curr loss: 1.3886443376541138, avg loss: 1.3863623440265656\n",
      "trial: 5, iter: 2800, curr loss: 1.3862138986587524, avg loss: 1.3863919103145599\n",
      "trial: 5, iter: 3000, curr loss: 1.387186884880066, avg loss: 1.3864076989889145\n",
      "trial: 5, iter: 3200, curr loss: 1.3855310678482056, avg loss: 1.3862931168079375\n",
      "trial: 5, iter: 3400, curr loss: 1.3866032361984253, avg loss: 1.3862824243307115\n",
      "trial: 5, iter: 3600, curr loss: 1.3864514827728271, avg loss: 1.3863922542333602\n",
      "trial: 5, iter: 3800, curr loss: 1.3864874839782715, avg loss: 1.3862604147195816\n",
      "trial: 5, iter: 4000, curr loss: 1.3860268592834473, avg loss: 1.3862489455938338\n",
      "trial: 5, iter: 4200, curr loss: 1.3860400915145874, avg loss: 1.3859275567531586\n",
      "trial: 5, iter: 4400, curr loss: 1.3814274072647095, avg loss: 1.384532198905945\n",
      "trial: 5, iter: 4600, curr loss: 1.3762538433074951, avg loss: 1.3825201952457429\n",
      "trial: 5, iter: 4800, curr loss: 1.3767848014831543, avg loss: 1.3781292408704757\n",
      "trial: 5, iter: 5000, curr loss: 1.3726582527160645, avg loss: 1.3725304543972014\n",
      "trial: 5, iter: 5200, curr loss: 1.3812675476074219, avg loss: 1.3658727473020553\n",
      "trial: 5, iter: 5400, curr loss: 1.3712865114212036, avg loss: 1.3626483631134034\n",
      "trial: 5, iter: 5600, curr loss: 1.3638627529144287, avg loss: 1.3592167538404465\n",
      "trial: 5, iter: 5800, curr loss: 1.358667016029358, avg loss: 1.3573213458061217\n",
      "trial: 5, iter: 6000, curr loss: 1.357785940170288, avg loss: 1.356281095147133\n",
      "trial: 5, iter: 6200, curr loss: 1.350507140159607, avg loss: 1.3546540278196335\n",
      "trial: 5, iter: 6400, curr loss: 1.3609589338302612, avg loss: 1.351563052535057\n",
      "trial: 5, iter: 6600, curr loss: 1.368466854095459, avg loss: 1.3490720677375794\n",
      "trial: 5, iter: 6800, curr loss: 1.3390307426452637, avg loss: 1.3446990692615508\n",
      "trial: 5, iter: 7000, curr loss: 1.3740471601486206, avg loss: 1.340621383190155\n",
      "trial: 5, iter: 7200, curr loss: 1.3278923034667969, avg loss: 1.3385786414146423\n",
      "trial: 5, iter: 7400, curr loss: 1.32829749584198, avg loss: 1.3342794233560562\n",
      "trial: 5, iter: 7600, curr loss: 1.3431057929992676, avg loss: 1.334269552230835\n",
      "trial: 5, iter: 7800, curr loss: 1.3213930130004883, avg loss: 1.331985200047493\n",
      "trial: 5, iter: 8000, curr loss: 1.3068801164627075, avg loss: 1.3296862626075745\n",
      "trial: 5, iter: 8200, curr loss: 1.36232328414917, avg loss: 1.3287077236175537\n",
      "trial: 5, iter: 8400, curr loss: 1.3434441089630127, avg loss: 1.3246681541204453\n",
      "trial: 5, iter: 8600, curr loss: 1.3108338117599487, avg loss: 1.3277846866846084\n",
      "trial: 5, iter: 8800, curr loss: 1.3465968370437622, avg loss: 1.3248894214630127\n",
      "trial: 5, iter: 9000, curr loss: 1.2940131425857544, avg loss: 1.3263699263334274\n",
      "trial: 5, iter: 9200, curr loss: 1.308462142944336, avg loss: 1.323641636967659\n",
      "trial: 5, iter: 9400, curr loss: 1.3391205072402954, avg loss: 1.3241951543092727\n",
      "trial: 5, iter: 9600, curr loss: 1.3176536560058594, avg loss: 1.3245346474647521\n",
      "trial: 5, iter: 9800, curr loss: 1.3192602396011353, avg loss: 1.3243148988485336\n",
      "trial: 5, iter: 10000, curr loss: 1.3108911514282227, avg loss: 1.3221580922603606\n",
      "trial: 5, iter: 10200, curr loss: 1.3039106130599976, avg loss: 1.3201722979545594\n",
      "trial: 5, iter: 10400, curr loss: 1.29755437374115, avg loss: 1.321162914633751\n",
      "trial: 5, iter: 10600, curr loss: 1.3160927295684814, avg loss: 1.3193619751930237\n",
      "trial: 5, iter: 10800, curr loss: 1.3278437852859497, avg loss: 1.322440494298935\n",
      "trial: 5, iter: 11000, curr loss: 1.3154420852661133, avg loss: 1.3185793948173523\n",
      "trial: 5, iter: 11200, curr loss: 1.3060966730117798, avg loss: 1.3211267578601837\n",
      "trial: 5, iter: 11400, curr loss: 1.3043609857559204, avg loss: 1.3198190504312515\n",
      "trial: 5, iter: 11600, curr loss: 1.2899680137634277, avg loss: 1.316565279364586\n",
      "trial: 5, iter: 11800, curr loss: 1.3013849258422852, avg loss: 1.3195557653903962\n",
      "trial: 5, iter: 12000, curr loss: 1.303196907043457, avg loss: 1.3177904510498046\n",
      "trial: 5, iter: 12200, curr loss: 1.3027763366699219, avg loss: 1.3191088420152663\n",
      "trial: 5, iter: 12400, curr loss: 1.3010952472686768, avg loss: 1.3158552986383438\n",
      "trial: 5, iter: 12600, curr loss: 1.3023592233657837, avg loss: 1.3178870177268982\n",
      "trial: 5, iter: 12800, curr loss: 1.303177833557129, avg loss: 1.3165638309717178\n",
      "trial: 5, iter: 13000, curr loss: 1.3451111316680908, avg loss: 1.316828691959381\n",
      "trial: 5, iter: 13200, curr loss: 1.2971030473709106, avg loss: 1.3166059815883637\n",
      "trial: 5, iter: 13400, curr loss: 1.324985146522522, avg loss: 1.3163335865736008\n",
      "trial: 5, iter: 13600, curr loss: 1.2950153350830078, avg loss: 1.315655226111412\n",
      "trial: 5, iter: 13800, curr loss: 1.3202744722366333, avg loss: 1.315277127623558\n",
      "trial: 5, iter: 14000, curr loss: 1.3267638683319092, avg loss: 1.316276234984398\n",
      "trial: 5, iter: 14200, curr loss: 1.2796077728271484, avg loss: 1.3149776315689088\n",
      "trial: 5, iter: 14400, curr loss: 1.3112984895706177, avg loss: 1.313159886598587\n",
      "trial: 5, iter: 14600, curr loss: 1.312070369720459, avg loss: 1.3149556744098663\n",
      "trial: 5, iter: 14800, curr loss: 1.3065435886383057, avg loss: 1.3159759116172791\n",
      "trial: 5, iter: 15000, curr loss: 1.3266323804855347, avg loss: 1.3161932319402694\n",
      "trial: 5, iter: 15200, curr loss: 1.3347253799438477, avg loss: 1.3159058582782746\n",
      "trial: 5, iter: 15400, curr loss: 1.3004405498504639, avg loss: 1.3115047895908356\n",
      "trial: 5, iter: 15600, curr loss: 1.3309780359268188, avg loss: 1.314066060781479\n",
      "trial: 5, ldr: 0.32025012373924255\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.31652664840221406\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3891589641571045, avg loss: 1.3871516913175583\n",
      "trial: 1, iter: 400, curr loss: 1.3866991996765137, avg loss: 1.3867871230840683\n",
      "trial: 1, iter: 600, curr loss: 1.3839313983917236, avg loss: 1.3865047085285187\n",
      "trial: 1, iter: 800, curr loss: 1.3862359523773193, avg loss: 1.3865257996320723\n",
      "trial: 1, iter: 1000, curr loss: 1.3861576318740845, avg loss: 1.3864295542240144\n",
      "trial: 1, iter: 1200, curr loss: 1.38789701461792, avg loss: 1.3864015752077103\n",
      "trial: 1, iter: 1400, curr loss: 1.3857803344726562, avg loss: 1.3864865338802337\n",
      "trial: 1, iter: 1600, curr loss: 1.386290192604065, avg loss: 1.386460068821907\n",
      "trial: 1, iter: 1800, curr loss: 1.3870584964752197, avg loss: 1.3863778907060622\n",
      "trial: 1, iter: 2000, curr loss: 1.3855105638504028, avg loss: 1.3863439810276033\n",
      "trial: 1, iter: 2200, curr loss: 1.386871337890625, avg loss: 1.3863702040910721\n",
      "trial: 1, iter: 2400, curr loss: 1.3871006965637207, avg loss: 1.386386991739273\n",
      "trial: 1, iter: 2600, curr loss: 1.3863996267318726, avg loss: 1.3863103485107422\n",
      "trial: 1, iter: 2800, curr loss: 1.385365605354309, avg loss: 1.386355989575386\n",
      "trial: 1, iter: 3000, curr loss: 1.38624906539917, avg loss: 1.3862908428907394\n",
      "trial: 1, iter: 3200, curr loss: 1.386677861213684, avg loss: 1.38635009765625\n",
      "trial: 1, iter: 3400, curr loss: 1.3865251541137695, avg loss: 1.3863541907072068\n",
      "trial: 1, iter: 3600, curr loss: 1.3871060609817505, avg loss: 1.3862703132629395\n",
      "trial: 1, iter: 3800, curr loss: 1.3863732814788818, avg loss: 1.3863453036546707\n",
      "trial: 1, iter: 4000, curr loss: 1.3857030868530273, avg loss: 1.386340131163597\n",
      "trial: 1, iter: 4200, curr loss: 1.3868273496627808, avg loss: 1.3863637572526932\n",
      "trial: 1, iter: 4400, curr loss: 1.386035680770874, avg loss: 1.386324295401573\n",
      "trial: 1, iter: 4600, curr loss: 1.3866748809814453, avg loss: 1.3862762886285782\n",
      "trial: 1, iter: 4800, curr loss: 1.3882590532302856, avg loss: 1.3862913423776626\n",
      "trial: 1, iter: 5000, curr loss: 1.3853423595428467, avg loss: 1.3863283336162566\n",
      "trial: 1, iter: 5200, curr loss: 1.386992335319519, avg loss: 1.386316584944725\n",
      "trial: 1, iter: 5400, curr loss: 1.385209560394287, avg loss: 1.3861281275749207\n",
      "trial: 1, iter: 5600, curr loss: 1.3823312520980835, avg loss: 1.3849772334098815\n",
      "trial: 1, iter: 5800, curr loss: 1.3742316961288452, avg loss: 1.37944315969944\n",
      "trial: 1, iter: 6000, curr loss: 1.3806605339050293, avg loss: 1.3678340941667557\n",
      "trial: 1, iter: 6200, curr loss: 1.3461337089538574, avg loss: 1.3625482362508774\n",
      "trial: 1, iter: 6400, curr loss: 1.3601664304733276, avg loss: 1.3597860765457153\n",
      "trial: 1, iter: 6600, curr loss: 1.3652361631393433, avg loss: 1.3573921036720276\n",
      "trial: 1, iter: 6800, curr loss: 1.3627712726593018, avg loss: 1.3558555960655212\n",
      "trial: 1, iter: 7000, curr loss: 1.362478256225586, avg loss: 1.3546034157276154\n",
      "trial: 1, iter: 7200, curr loss: 1.353575348854065, avg loss: 1.3551053762435914\n",
      "trial: 1, iter: 7400, curr loss: 1.3589540719985962, avg loss: 1.3540372455120087\n",
      "trial: 1, iter: 7600, curr loss: 1.3673039674758911, avg loss: 1.3501377975940705\n",
      "trial: 1, iter: 7800, curr loss: 1.3189284801483154, avg loss: 1.346137901544571\n",
      "trial: 1, iter: 8000, curr loss: 1.320875644683838, avg loss: 1.3388883858919143\n",
      "trial: 1, iter: 8200, curr loss: 1.3077439069747925, avg loss: 1.3370104479789733\n",
      "trial: 1, iter: 8400, curr loss: 1.334113597869873, avg loss: 1.3341491669416428\n",
      "trial: 1, iter: 8600, curr loss: 1.3546940088272095, avg loss: 1.3334342485666275\n",
      "trial: 1, iter: 8800, curr loss: 1.2907370328903198, avg loss: 1.3281447303295135\n",
      "trial: 1, iter: 9000, curr loss: 1.304970145225525, avg loss: 1.328312925696373\n",
      "trial: 1, iter: 9200, curr loss: 1.3285565376281738, avg loss: 1.3269839107990264\n",
      "trial: 1, iter: 9400, curr loss: 1.3218834400177002, avg loss: 1.323943098783493\n",
      "trial: 1, iter: 9600, curr loss: 1.3234308958053589, avg loss: 1.3251441353559494\n",
      "trial: 1, iter: 9800, curr loss: 1.2999203205108643, avg loss: 1.321145167350769\n",
      "trial: 1, iter: 10000, curr loss: 1.335795521736145, avg loss: 1.3204147136211395\n",
      "trial: 1, iter: 10200, curr loss: 1.334662675857544, avg loss: 1.3219518637657166\n",
      "trial: 1, iter: 10400, curr loss: 1.3300418853759766, avg loss: 1.3223427200317384\n",
      "trial: 1, iter: 10600, curr loss: 1.3306134939193726, avg loss: 1.3212320876121522\n",
      "trial: 1, iter: 10800, curr loss: 1.3129963874816895, avg loss: 1.3210461789369583\n",
      "trial: 1, iter: 11000, curr loss: 1.3189170360565186, avg loss: 1.3232369112968445\n",
      "trial: 1, iter: 11200, curr loss: 1.3156999349594116, avg loss: 1.319007424712181\n",
      "trial: 1, iter: 11400, curr loss: 1.3115752935409546, avg loss: 1.3202215665578843\n",
      "trial: 1, iter: 11600, curr loss: 1.3462103605270386, avg loss: 1.3196618121862411\n",
      "trial: 1, iter: 11800, curr loss: 1.305343508720398, avg loss: 1.3194137799739838\n",
      "trial: 1, iter: 12000, curr loss: 1.286668300628662, avg loss: 1.3145320683717727\n",
      "trial: 1, iter: 12200, curr loss: 1.3480085134506226, avg loss: 1.318948096036911\n",
      "trial: 1, iter: 12400, curr loss: 1.3035324811935425, avg loss: 1.3201152247190475\n",
      "trial: 1, iter: 12600, curr loss: 1.286739468574524, avg loss: 1.3206980657577514\n",
      "trial: 1, iter: 12800, curr loss: 1.3188685178756714, avg loss: 1.3173424047231674\n",
      "trial: 1, iter: 13000, curr loss: 1.3236011266708374, avg loss: 1.3214431017637254\n",
      "trial: 1, iter: 13200, curr loss: 1.3358501195907593, avg loss: 1.3170484799146651\n",
      "trial: 1, iter: 13400, curr loss: 1.3226083517074585, avg loss: 1.3208182013034822\n",
      "trial: 1, iter: 13600, curr loss: 1.3057993650436401, avg loss: 1.3167871516942977\n",
      "trial: 1, iter: 13800, curr loss: 1.3411494493484497, avg loss: 1.3166561621427535\n",
      "trial: 1, iter: 14000, curr loss: 1.3027701377868652, avg loss: 1.314993264079094\n",
      "trial: 1, iter: 14200, curr loss: 1.3076850175857544, avg loss: 1.3151925748586655\n",
      "trial: 1, iter: 14400, curr loss: 1.2921841144561768, avg loss: 1.3176430886983872\n",
      "trial: 1, iter: 14600, curr loss: 1.2917356491088867, avg loss: 1.3168487799167634\n",
      "trial: 1, iter: 14800, curr loss: 1.342719554901123, avg loss: 1.3189790952205658\n",
      "trial: 1, iter: 15000, curr loss: 1.3380547761917114, avg loss: 1.3183555668592453\n",
      "trial: 1, iter: 15200, curr loss: 1.3297514915466309, avg loss: 1.3186496430635453\n",
      "trial: 1, iter: 15400, curr loss: 1.3108102083206177, avg loss: 1.3127996444702148\n",
      "trial: 1, iter: 15600, curr loss: 1.3177456855773926, avg loss: 1.3181093072891235\n",
      "trial: 1, ldr: 0.31321394443511963\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863075971603394, avg loss: 1.3871880340576173\n",
      "trial: 2, iter: 400, curr loss: 1.3873653411865234, avg loss: 1.3867230004072189\n",
      "trial: 2, iter: 600, curr loss: 1.3833266496658325, avg loss: 1.3868049472570418\n",
      "trial: 2, iter: 800, curr loss: 1.3846620321273804, avg loss: 1.3867807239294052\n",
      "trial: 2, iter: 1000, curr loss: 1.386734127998352, avg loss: 1.3863524937629699\n",
      "trial: 2, iter: 1200, curr loss: 1.387014389038086, avg loss: 1.3865483844280242\n",
      "trial: 2, iter: 1400, curr loss: 1.3854169845581055, avg loss: 1.3863475501537323\n",
      "trial: 2, iter: 1600, curr loss: 1.3882027864456177, avg loss: 1.3865359610319137\n",
      "trial: 2, iter: 1800, curr loss: 1.3865087032318115, avg loss: 1.3863032722473145\n",
      "trial: 2, iter: 2000, curr loss: 1.3863492012023926, avg loss: 1.3864157259464265\n",
      "trial: 2, iter: 2200, curr loss: 1.3863651752471924, avg loss: 1.3863548785448074\n",
      "trial: 2, iter: 2400, curr loss: 1.3876277208328247, avg loss: 1.3863567835092545\n",
      "trial: 2, iter: 2600, curr loss: 1.3875200748443604, avg loss: 1.3862706065177917\n",
      "trial: 2, iter: 2800, curr loss: 1.3846715688705444, avg loss: 1.3864096462726594\n",
      "trial: 2, iter: 3000, curr loss: 1.3870182037353516, avg loss: 1.3863113528490068\n",
      "trial: 2, iter: 3200, curr loss: 1.3870513439178467, avg loss: 1.3863544738292695\n",
      "trial: 2, iter: 3400, curr loss: 1.3865242004394531, avg loss: 1.3863806432485581\n",
      "trial: 2, iter: 3600, curr loss: 1.38624107837677, avg loss: 1.3863086354732514\n",
      "trial: 2, iter: 3800, curr loss: 1.3858319520950317, avg loss: 1.386383296251297\n",
      "trial: 2, iter: 4000, curr loss: 1.3857465982437134, avg loss: 1.3863119548559188\n",
      "trial: 2, iter: 4200, curr loss: 1.386126160621643, avg loss: 1.3863318657875061\n",
      "trial: 2, iter: 4400, curr loss: 1.386763572692871, avg loss: 1.386353490948677\n",
      "trial: 2, iter: 4600, curr loss: 1.3866651058197021, avg loss: 1.3862678384780884\n",
      "trial: 2, iter: 4800, curr loss: 1.3863035440444946, avg loss: 1.3863473707437515\n",
      "trial: 2, iter: 5000, curr loss: 1.3866969347000122, avg loss: 1.3862852382659911\n",
      "trial: 2, iter: 5200, curr loss: 1.3866149187088013, avg loss: 1.3863102132081986\n",
      "trial: 2, iter: 5400, curr loss: 1.3865121603012085, avg loss: 1.3862838351726532\n",
      "trial: 2, iter: 5600, curr loss: 1.3862903118133545, avg loss: 1.3863437223434447\n",
      "trial: 2, iter: 5800, curr loss: 1.3856734037399292, avg loss: 1.3862990373373032\n",
      "trial: 2, iter: 6000, curr loss: 1.3856838941574097, avg loss: 1.3863228476047516\n",
      "trial: 2, iter: 6200, curr loss: 1.3860303163528442, avg loss: 1.3863175594806671\n",
      "trial: 2, iter: 6400, curr loss: 1.386608600616455, avg loss: 1.386299175620079\n",
      "trial: 2, iter: 6600, curr loss: 1.3865243196487427, avg loss: 1.3862997549772262\n",
      "trial: 2, iter: 6800, curr loss: 1.387576937675476, avg loss: 1.386282986998558\n",
      "trial: 2, iter: 7000, curr loss: 1.3865898847579956, avg loss: 1.3863966220617294\n",
      "trial: 2, iter: 7200, curr loss: 1.38626229763031, avg loss: 1.3863192677497864\n",
      "trial: 2, iter: 7400, curr loss: 1.3869165182113647, avg loss: 1.3863155740499495\n",
      "trial: 2, iter: 7600, curr loss: 1.386727213859558, avg loss: 1.38631068110466\n",
      "trial: 2, iter: 7800, curr loss: 1.3863838911056519, avg loss: 1.3863135063648224\n",
      "trial: 2, iter: 8000, curr loss: 1.3865433931350708, avg loss: 1.3862796223163605\n",
      "trial: 2, iter: 8200, curr loss: 1.386653184890747, avg loss: 1.3862822723388672\n",
      "trial: 2, iter: 8400, curr loss: 1.3840818405151367, avg loss: 1.3858331036567688\n",
      "trial: 2, iter: 8600, curr loss: 1.3843079805374146, avg loss: 1.384104279279709\n",
      "trial: 2, iter: 8800, curr loss: 1.3632264137268066, avg loss: 1.378148854970932\n",
      "trial: 2, iter: 9000, curr loss: 1.37730872631073, avg loss: 1.368949516415596\n",
      "trial: 2, iter: 9200, curr loss: 1.373928189277649, avg loss: 1.361789628267288\n",
      "trial: 2, iter: 9400, curr loss: 1.3618690967559814, avg loss: 1.3594757276773453\n",
      "trial: 2, iter: 9600, curr loss: 1.3539912700653076, avg loss: 1.3562789571285248\n",
      "trial: 2, iter: 9800, curr loss: 1.3406155109405518, avg loss: 1.356002346277237\n",
      "trial: 2, iter: 10000, curr loss: 1.3601102828979492, avg loss: 1.3556207638978959\n",
      "trial: 2, iter: 10200, curr loss: 1.3415223360061646, avg loss: 1.354545858502388\n",
      "trial: 2, iter: 10400, curr loss: 1.3476214408874512, avg loss: 1.349539937376976\n",
      "trial: 2, iter: 10600, curr loss: 1.3537944555282593, avg loss: 1.3474800074100495\n",
      "trial: 2, iter: 10800, curr loss: 1.3590365648269653, avg loss: 1.342579100728035\n",
      "trial: 2, iter: 11000, curr loss: 1.3300654888153076, avg loss: 1.338085960149765\n",
      "trial: 2, iter: 11200, curr loss: 1.3336900472640991, avg loss: 1.3335279256105423\n",
      "trial: 2, iter: 11400, curr loss: 1.3428189754486084, avg loss: 1.327504676580429\n",
      "trial: 2, iter: 11600, curr loss: 1.3371309041976929, avg loss: 1.3264733213186264\n",
      "trial: 2, iter: 11800, curr loss: 1.29523503780365, avg loss: 1.3255055087804795\n",
      "trial: 2, iter: 12000, curr loss: 1.3072079420089722, avg loss: 1.3243326342105866\n",
      "trial: 2, iter: 12200, curr loss: 1.3346720933914185, avg loss: 1.325219642519951\n",
      "trial: 2, iter: 12400, curr loss: 1.32830810546875, avg loss: 1.3221051388978957\n",
      "trial: 2, iter: 12600, curr loss: 1.319162368774414, avg loss: 1.3217463755607606\n",
      "trial: 2, iter: 12800, curr loss: 1.3090988397598267, avg loss: 1.320351985692978\n",
      "trial: 2, iter: 13000, curr loss: 1.3195289373397827, avg loss: 1.3218907558917998\n",
      "trial: 2, iter: 13200, curr loss: 1.3006242513656616, avg loss: 1.318680140376091\n",
      "trial: 2, iter: 13400, curr loss: 1.3436269760131836, avg loss: 1.3210316270589828\n",
      "trial: 2, iter: 13600, curr loss: 1.319538950920105, avg loss: 1.3212530320882798\n",
      "trial: 2, iter: 13800, curr loss: 1.3337866067886353, avg loss: 1.3212806171178817\n",
      "trial: 2, iter: 14000, curr loss: 1.3228693008422852, avg loss: 1.3198822647333146\n",
      "trial: 2, iter: 14200, curr loss: 1.3521955013275146, avg loss: 1.3200903987884522\n",
      "trial: 2, iter: 14400, curr loss: 1.371725082397461, avg loss: 1.320233127474785\n",
      "trial: 2, iter: 14600, curr loss: 1.317366600036621, avg loss: 1.3196828204393387\n",
      "trial: 2, iter: 14800, curr loss: 1.336766242980957, avg loss: 1.314798914194107\n",
      "trial: 2, iter: 15000, curr loss: 1.3338799476623535, avg loss: 1.318327470421791\n",
      "trial: 2, iter: 15200, curr loss: 1.3114171028137207, avg loss: 1.316557558774948\n",
      "trial: 2, iter: 15400, curr loss: 1.3566477298736572, avg loss: 1.3162458509206771\n",
      "trial: 2, iter: 15600, curr loss: 1.3486659526824951, avg loss: 1.3180414992570877\n",
      "trial: 2, ldr: 0.3233838379383087\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3839643001556396, avg loss: 1.387482172846794\n",
      "trial: 3, iter: 400, curr loss: 1.3841341733932495, avg loss: 1.3870598310232163\n",
      "trial: 3, iter: 600, curr loss: 1.3878827095031738, avg loss: 1.3865557354688645\n",
      "trial: 3, iter: 800, curr loss: 1.3874822854995728, avg loss: 1.3865428054332734\n",
      "trial: 3, iter: 1000, curr loss: 1.3878631591796875, avg loss: 1.3865612763166428\n",
      "trial: 3, iter: 1200, curr loss: 1.3846992254257202, avg loss: 1.3864420890808105\n",
      "trial: 3, iter: 1400, curr loss: 1.3868581056594849, avg loss: 1.386402449607849\n",
      "trial: 3, iter: 1600, curr loss: 1.385900616645813, avg loss: 1.3863488042354584\n",
      "trial: 3, iter: 1800, curr loss: 1.3867183923721313, avg loss: 1.3863296860456467\n",
      "trial: 3, iter: 2000, curr loss: 1.3865865468978882, avg loss: 1.3863501292467117\n",
      "trial: 3, iter: 2200, curr loss: 1.3859944343566895, avg loss: 1.3863472634553908\n",
      "trial: 3, iter: 2400, curr loss: 1.3874915838241577, avg loss: 1.386324290037155\n",
      "trial: 3, iter: 2600, curr loss: 1.3862717151641846, avg loss: 1.3863347393274308\n",
      "trial: 3, iter: 2800, curr loss: 1.3846120834350586, avg loss: 1.3863171488046646\n",
      "trial: 3, iter: 3000, curr loss: 1.3854095935821533, avg loss: 1.3863478589057923\n",
      "trial: 3, iter: 3200, curr loss: 1.3859927654266357, avg loss: 1.3863452368974685\n",
      "trial: 3, iter: 3400, curr loss: 1.3863840103149414, avg loss: 1.3863205575942994\n",
      "trial: 3, iter: 3600, curr loss: 1.3866063356399536, avg loss: 1.3863159042596818\n",
      "trial: 3, iter: 3800, curr loss: 1.3849208354949951, avg loss: 1.386254807114601\n",
      "trial: 3, iter: 4000, curr loss: 1.3864736557006836, avg loss: 1.3863522452116013\n",
      "trial: 3, iter: 4200, curr loss: 1.3858619928359985, avg loss: 1.3862645244598388\n",
      "trial: 3, iter: 4400, curr loss: 1.3866997957229614, avg loss: 1.3863341635465622\n",
      "trial: 3, iter: 4600, curr loss: 1.386552333831787, avg loss: 1.386303340792656\n",
      "trial: 3, iter: 4800, curr loss: 1.386265516281128, avg loss: 1.3863569355010987\n",
      "trial: 3, iter: 5000, curr loss: 1.3858842849731445, avg loss: 1.3863306337594985\n",
      "trial: 3, iter: 5200, curr loss: 1.3861451148986816, avg loss: 1.3863170975446701\n",
      "trial: 3, iter: 5400, curr loss: 1.3862950801849365, avg loss: 1.386319870352745\n",
      "trial: 3, iter: 5600, curr loss: 1.3863413333892822, avg loss: 1.386292023062706\n",
      "trial: 3, iter: 5800, curr loss: 1.386292815208435, avg loss: 1.3863002735376357\n",
      "trial: 3, iter: 6000, curr loss: 1.386371374130249, avg loss: 1.3862607711553574\n",
      "trial: 3, iter: 6200, curr loss: 1.386050820350647, avg loss: 1.3863488936424255\n",
      "trial: 3, iter: 6400, curr loss: 1.385117530822754, avg loss: 1.3863012760877609\n",
      "trial: 3, iter: 6600, curr loss: 1.386066198348999, avg loss: 1.3863991671800613\n",
      "trial: 3, iter: 6800, curr loss: 1.3859000205993652, avg loss: 1.3863156950473785\n",
      "trial: 3, iter: 7000, curr loss: 1.3864175081253052, avg loss: 1.3862384229898452\n",
      "trial: 3, iter: 7200, curr loss: 1.3843625783920288, avg loss: 1.3858416187763214\n",
      "trial: 3, iter: 7400, curr loss: 1.3806394338607788, avg loss: 1.3837664353847503\n",
      "trial: 3, iter: 7600, curr loss: 1.3702850341796875, avg loss: 1.3785092449188232\n",
      "trial: 3, iter: 7800, curr loss: 1.366744875907898, avg loss: 1.3699486750364303\n",
      "trial: 3, iter: 8000, curr loss: 1.3633813858032227, avg loss: 1.363383292555809\n",
      "trial: 3, iter: 8200, curr loss: 1.3573050498962402, avg loss: 1.3613095921278\n",
      "trial: 3, iter: 8400, curr loss: 1.3671796321868896, avg loss: 1.3576874560117722\n",
      "trial: 3, iter: 8600, curr loss: 1.3613786697387695, avg loss: 1.358508340716362\n",
      "trial: 3, iter: 8800, curr loss: 1.355143666267395, avg loss: 1.3584879058599473\n",
      "trial: 3, iter: 9000, curr loss: 1.3833565711975098, avg loss: 1.3574825727939606\n",
      "trial: 3, iter: 9200, curr loss: 1.3520796298980713, avg loss: 1.354532891511917\n",
      "trial: 3, iter: 9400, curr loss: 1.3442611694335938, avg loss: 1.3557710754871368\n",
      "trial: 3, iter: 9600, curr loss: 1.3436672687530518, avg loss: 1.354230786561966\n",
      "trial: 3, iter: 9800, curr loss: 1.344460368156433, avg loss: 1.3526551324129104\n",
      "trial: 3, iter: 10000, curr loss: 1.3529249429702759, avg loss: 1.3540944308042526\n",
      "trial: 3, iter: 10200, curr loss: 1.3423608541488647, avg loss: 1.3506428611278534\n",
      "trial: 3, iter: 10400, curr loss: 1.3419426679611206, avg loss: 1.3482505583763122\n",
      "trial: 3, iter: 10600, curr loss: 1.3569940328598022, avg loss: 1.34664827644825\n",
      "trial: 3, iter: 10800, curr loss: 1.369536280632019, avg loss: 1.3426925510168075\n",
      "trial: 3, iter: 11000, curr loss: 1.3214194774627686, avg loss: 1.3392964720726013\n",
      "trial: 3, iter: 11200, curr loss: 1.3556556701660156, avg loss: 1.3388883066177368\n",
      "trial: 3, iter: 11400, curr loss: 1.350815773010254, avg loss: 1.33505676984787\n",
      "trial: 3, iter: 11600, curr loss: 1.3411049842834473, avg loss: 1.3321596997976304\n",
      "trial: 3, iter: 11800, curr loss: 1.3387395143508911, avg loss: 1.3280728006362914\n",
      "trial: 3, iter: 12000, curr loss: 1.3314480781555176, avg loss: 1.3251219034194945\n",
      "trial: 3, iter: 12200, curr loss: 1.3141071796417236, avg loss: 1.3275500935316087\n",
      "trial: 3, iter: 12400, curr loss: 1.3557918071746826, avg loss: 1.3256398087739945\n",
      "trial: 3, iter: 12600, curr loss: 1.3275516033172607, avg loss: 1.3227615934610366\n",
      "trial: 3, iter: 12800, curr loss: 1.2991975545883179, avg loss: 1.322907709479332\n",
      "trial: 3, iter: 13000, curr loss: 1.350400686264038, avg loss: 1.3212937599420547\n",
      "trial: 3, iter: 13200, curr loss: 1.305077314376831, avg loss: 1.322623878121376\n",
      "trial: 3, iter: 13400, curr loss: 1.3353962898254395, avg loss: 1.3197761178016663\n",
      "trial: 3, iter: 13600, curr loss: 1.2888011932373047, avg loss: 1.32111197412014\n",
      "trial: 3, iter: 13800, curr loss: 1.3484195470809937, avg loss: 1.3210347771644593\n",
      "trial: 3, iter: 14000, curr loss: 1.3081787824630737, avg loss: 1.3211580193042756\n",
      "trial: 3, iter: 14200, curr loss: 1.3356927633285522, avg loss: 1.3187377560138702\n",
      "trial: 3, iter: 14400, curr loss: 1.3076726198196411, avg loss: 1.3184883373975753\n",
      "trial: 3, iter: 14600, curr loss: 1.3158472776412964, avg loss: 1.3172926414012909\n",
      "trial: 3, iter: 14800, curr loss: 1.3374072313308716, avg loss: 1.3175355058908462\n",
      "trial: 3, iter: 15000, curr loss: 1.3079352378845215, avg loss: 1.3202611213922502\n",
      "trial: 3, iter: 15200, curr loss: 1.3110437393188477, avg loss: 1.319008863568306\n",
      "trial: 3, iter: 15400, curr loss: 1.3164504766464233, avg loss: 1.3170477843284607\n",
      "trial: 3, iter: 15600, curr loss: 1.3394383192062378, avg loss: 1.3169501304626465\n",
      "trial: 3, ldr: 0.3358016312122345\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3872445821762085, avg loss: 1.38743783056736\n",
      "trial: 4, iter: 400, curr loss: 1.3878898620605469, avg loss: 1.3867751216888429\n",
      "trial: 4, iter: 600, curr loss: 1.3857955932617188, avg loss: 1.3866138315200807\n",
      "trial: 4, iter: 800, curr loss: 1.38564133644104, avg loss: 1.3865094095468522\n",
      "trial: 4, iter: 1000, curr loss: 1.3863255977630615, avg loss: 1.3864590340852738\n",
      "trial: 4, iter: 1200, curr loss: 1.3867498636245728, avg loss: 1.3864198368787766\n",
      "trial: 4, iter: 1400, curr loss: 1.3879966735839844, avg loss: 1.3864407843351365\n",
      "trial: 4, iter: 1600, curr loss: 1.3864874839782715, avg loss: 1.386435137987137\n",
      "trial: 4, iter: 1800, curr loss: 1.3855633735656738, avg loss: 1.386335043311119\n",
      "trial: 4, iter: 2000, curr loss: 1.3857029676437378, avg loss: 1.3863037312030793\n",
      "trial: 4, iter: 2200, curr loss: 1.3865368366241455, avg loss: 1.3864161598682403\n",
      "trial: 4, iter: 2400, curr loss: 1.3878484964370728, avg loss: 1.3862942916154861\n",
      "trial: 4, iter: 2600, curr loss: 1.3876534700393677, avg loss: 1.3863362616300583\n",
      "trial: 4, iter: 2800, curr loss: 1.3859034776687622, avg loss: 1.3863736361265182\n",
      "trial: 4, iter: 3000, curr loss: 1.3866448402404785, avg loss: 1.3863143396377564\n",
      "trial: 4, iter: 3200, curr loss: 1.3870424032211304, avg loss: 1.3863306534290314\n",
      "trial: 4, iter: 3400, curr loss: 1.3862541913986206, avg loss: 1.3863038182258607\n",
      "trial: 4, iter: 3600, curr loss: 1.3863224983215332, avg loss: 1.3863049787282944\n",
      "trial: 4, iter: 3800, curr loss: 1.3864701986312866, avg loss: 1.3863010591268539\n",
      "trial: 4, iter: 4000, curr loss: 1.3865433931350708, avg loss: 1.3863659143447875\n",
      "trial: 4, iter: 4200, curr loss: 1.3872089385986328, avg loss: 1.3863588905334472\n",
      "trial: 4, iter: 4400, curr loss: 1.3865326642990112, avg loss: 1.3864008343219758\n",
      "trial: 4, iter: 4600, curr loss: 1.3865373134613037, avg loss: 1.3863290649652482\n",
      "trial: 4, iter: 4800, curr loss: 1.3862062692642212, avg loss: 1.3863169157505035\n",
      "trial: 4, iter: 5000, curr loss: 1.385806679725647, avg loss: 1.3863219821453094\n",
      "trial: 4, iter: 5200, curr loss: 1.3864002227783203, avg loss: 1.3863746112585067\n",
      "trial: 4, iter: 5400, curr loss: 1.386267066001892, avg loss: 1.386348767876625\n",
      "trial: 4, iter: 5600, curr loss: 1.3860844373703003, avg loss: 1.3863046497106553\n",
      "trial: 4, iter: 5800, curr loss: 1.3867546319961548, avg loss: 1.386335704922676\n",
      "trial: 4, iter: 6000, curr loss: 1.386479377746582, avg loss: 1.3863267624378204\n",
      "trial: 4, iter: 6200, curr loss: 1.3857897520065308, avg loss: 1.3863158684968948\n",
      "trial: 4, iter: 6400, curr loss: 1.3862990140914917, avg loss: 1.3863533288240433\n",
      "trial: 4, iter: 6600, curr loss: 1.386138677597046, avg loss: 1.3863333588838578\n",
      "trial: 4, iter: 6800, curr loss: 1.3864538669586182, avg loss: 1.3863067454099656\n",
      "trial: 4, iter: 7000, curr loss: 1.3862667083740234, avg loss: 1.3863119328022002\n",
      "trial: 4, iter: 7200, curr loss: 1.3860517740249634, avg loss: 1.3862827432155609\n",
      "trial: 4, iter: 7400, curr loss: 1.3865556716918945, avg loss: 1.3862796902656556\n",
      "trial: 4, iter: 7600, curr loss: 1.3862667083740234, avg loss: 1.3862821996212005\n",
      "trial: 4, iter: 7800, curr loss: 1.386188268661499, avg loss: 1.3863543683290482\n",
      "trial: 4, iter: 8000, curr loss: 1.3861452341079712, avg loss: 1.3862861746549606\n",
      "trial: 4, iter: 8200, curr loss: 1.3866398334503174, avg loss: 1.3862720346450805\n",
      "trial: 4, iter: 8400, curr loss: 1.38651704788208, avg loss: 1.3863243782520294\n",
      "trial: 4, iter: 8600, curr loss: 1.3864483833312988, avg loss: 1.3861815232038497\n",
      "trial: 4, iter: 8800, curr loss: 1.3858824968338013, avg loss: 1.3854556339979172\n",
      "trial: 4, iter: 9000, curr loss: 1.3744747638702393, avg loss: 1.382831757068634\n",
      "trial: 4, iter: 9200, curr loss: 1.3583186864852905, avg loss: 1.3762236988544465\n",
      "trial: 4, iter: 9400, curr loss: 1.3801242113113403, avg loss: 1.3682351207733154\n",
      "trial: 4, iter: 9600, curr loss: 1.3441534042358398, avg loss: 1.3651362085342407\n",
      "trial: 4, iter: 9800, curr loss: 1.3591150045394897, avg loss: 1.361899612545967\n",
      "trial: 4, iter: 10000, curr loss: 1.3445994853973389, avg loss: 1.3597343945503235\n",
      "trial: 4, iter: 10200, curr loss: 1.3753410577774048, avg loss: 1.3574653738737106\n",
      "trial: 4, iter: 10400, curr loss: 1.3717437982559204, avg loss: 1.358105411529541\n",
      "trial: 4, iter: 10600, curr loss: 1.3895844221115112, avg loss: 1.3544665390253068\n",
      "trial: 4, iter: 10800, curr loss: 1.342292308807373, avg loss: 1.356532679796219\n",
      "trial: 4, iter: 11000, curr loss: 1.3423019647598267, avg loss: 1.3523312729597092\n",
      "trial: 4, iter: 11200, curr loss: 1.3277101516723633, avg loss: 1.3510895103216172\n",
      "trial: 4, iter: 11400, curr loss: 1.3587334156036377, avg loss: 1.3470818316936493\n",
      "trial: 4, iter: 11600, curr loss: 1.3456040620803833, avg loss: 1.3455681991577149\n",
      "trial: 4, iter: 11800, curr loss: 1.354224443435669, avg loss: 1.3400377804040908\n",
      "trial: 4, iter: 12000, curr loss: 1.3801922798156738, avg loss: 1.335808823108673\n",
      "trial: 4, iter: 12200, curr loss: 1.3448914289474487, avg loss: 1.332451080083847\n",
      "trial: 4, iter: 12400, curr loss: 1.3566633462905884, avg loss: 1.330041537284851\n",
      "trial: 4, iter: 12600, curr loss: 1.316718339920044, avg loss: 1.3254472881555557\n",
      "trial: 4, iter: 12800, curr loss: 1.3087290525436401, avg loss: 1.324506738781929\n",
      "trial: 4, iter: 13000, curr loss: 1.3091477155685425, avg loss: 1.3253743237257003\n",
      "trial: 4, iter: 13200, curr loss: 1.3296869993209839, avg loss: 1.323738067150116\n",
      "trial: 4, iter: 13400, curr loss: 1.2999534606933594, avg loss: 1.3248218232393265\n",
      "trial: 4, iter: 13600, curr loss: 1.3459718227386475, avg loss: 1.324195203781128\n",
      "trial: 4, iter: 13800, curr loss: 1.329572319984436, avg loss: 1.3208778697252272\n",
      "trial: 4, iter: 14000, curr loss: 1.299230933189392, avg loss: 1.3195219379663468\n",
      "trial: 4, iter: 14200, curr loss: 1.3237212896347046, avg loss: 1.3197595673799514\n",
      "trial: 4, iter: 14400, curr loss: 1.321420669555664, avg loss: 1.320316369533539\n",
      "trial: 4, iter: 14600, curr loss: 1.3040927648544312, avg loss: 1.3214006012678146\n",
      "trial: 4, iter: 14800, curr loss: 1.2983757257461548, avg loss: 1.3167636728286742\n",
      "trial: 4, iter: 15000, curr loss: 1.315995216369629, avg loss: 1.3178306102752686\n",
      "trial: 4, iter: 15200, curr loss: 1.3232896327972412, avg loss: 1.319974857568741\n",
      "trial: 4, iter: 15400, curr loss: 1.3013945817947388, avg loss: 1.3179082506895066\n",
      "trial: 4, iter: 15600, curr loss: 1.3328983783721924, avg loss: 1.3192280399799348\n",
      "trial: 4, ldr: 0.42158710956573486\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3902528285980225, avg loss: 1.3873472166061402\n",
      "trial: 5, iter: 400, curr loss: 1.3878365755081177, avg loss: 1.386705166697502\n",
      "trial: 5, iter: 600, curr loss: 1.386486291885376, avg loss: 1.3865419620275496\n",
      "trial: 5, iter: 800, curr loss: 1.384197473526001, avg loss: 1.3864690005779265\n",
      "trial: 5, iter: 1000, curr loss: 1.3848146200180054, avg loss: 1.3864967226982117\n",
      "trial: 5, iter: 1200, curr loss: 1.3853564262390137, avg loss: 1.3864935791492463\n",
      "trial: 5, iter: 1400, curr loss: 1.3868229389190674, avg loss: 1.3864956992864608\n",
      "trial: 5, iter: 1600, curr loss: 1.3863650560379028, avg loss: 1.3863431203365326\n",
      "trial: 5, iter: 1800, curr loss: 1.3868557214736938, avg loss: 1.3863891017436982\n",
      "trial: 5, iter: 2000, curr loss: 1.3856929540634155, avg loss: 1.3863806587457657\n",
      "trial: 5, iter: 2200, curr loss: 1.386063814163208, avg loss: 1.386314216852188\n",
      "trial: 5, iter: 2400, curr loss: 1.3864929676055908, avg loss: 1.3863900887966156\n",
      "trial: 5, iter: 2600, curr loss: 1.3869222402572632, avg loss: 1.3864192599058152\n",
      "trial: 5, iter: 2800, curr loss: 1.3861783742904663, avg loss: 1.3862944185733794\n",
      "trial: 5, iter: 3000, curr loss: 1.3868451118469238, avg loss: 1.3863345557451248\n",
      "trial: 5, iter: 3200, curr loss: 1.3864977359771729, avg loss: 1.3863072001934051\n",
      "trial: 5, iter: 3400, curr loss: 1.38670015335083, avg loss: 1.3862905871868134\n",
      "trial: 5, iter: 3600, curr loss: 1.3863177299499512, avg loss: 1.3862001192569733\n",
      "trial: 5, iter: 3800, curr loss: 1.3869727849960327, avg loss: 1.3863492274284364\n",
      "trial: 5, iter: 4000, curr loss: 1.3858832120895386, avg loss: 1.3862845587730408\n",
      "trial: 5, iter: 4200, curr loss: 1.3864238262176514, avg loss: 1.386220752596855\n",
      "trial: 5, iter: 4400, curr loss: 1.384975552558899, avg loss: 1.3860560768842698\n",
      "trial: 5, iter: 4600, curr loss: 1.3898546695709229, avg loss: 1.3846982711553573\n",
      "trial: 5, iter: 4800, curr loss: 1.3837571144104004, avg loss: 1.3802931076288223\n",
      "trial: 5, iter: 5000, curr loss: 1.3641618490219116, avg loss: 1.3774681621789933\n",
      "trial: 5, iter: 5200, curr loss: 1.3597619533538818, avg loss: 1.3727413868904115\n",
      "trial: 5, iter: 5400, curr loss: 1.3653252124786377, avg loss: 1.3664441937208176\n",
      "trial: 5, iter: 5600, curr loss: 1.3683562278747559, avg loss: 1.363928736448288\n",
      "trial: 5, iter: 5800, curr loss: 1.365092158317566, avg loss: 1.3608613401651382\n",
      "trial: 5, iter: 6000, curr loss: 1.3464308977127075, avg loss: 1.3590872120857238\n",
      "trial: 5, iter: 6200, curr loss: 1.3663785457611084, avg loss: 1.357064061164856\n",
      "trial: 5, iter: 6400, curr loss: 1.3548192977905273, avg loss: 1.3555867767333984\n",
      "trial: 5, iter: 6600, curr loss: 1.3755966424942017, avg loss: 1.3554255318641664\n",
      "trial: 5, iter: 6800, curr loss: 1.3583558797836304, avg loss: 1.3532357460260391\n",
      "trial: 5, iter: 7000, curr loss: 1.3342467546463013, avg loss: 1.3537355118989944\n",
      "trial: 5, iter: 7200, curr loss: 1.348702311515808, avg loss: 1.3495037406682968\n",
      "trial: 5, iter: 7400, curr loss: 1.3324366807937622, avg loss: 1.348739785552025\n",
      "trial: 5, iter: 7600, curr loss: 1.3164583444595337, avg loss: 1.3431579715013504\n",
      "trial: 5, iter: 7800, curr loss: 1.349618911743164, avg loss: 1.342766716480255\n",
      "trial: 5, iter: 8000, curr loss: 1.327817440032959, avg loss: 1.339439787864685\n",
      "trial: 5, iter: 8200, curr loss: 1.3193613290786743, avg loss: 1.3364786773920059\n",
      "trial: 5, iter: 8400, curr loss: 1.3442738056182861, avg loss: 1.3338793659210204\n",
      "trial: 5, iter: 8600, curr loss: 1.3144906759262085, avg loss: 1.3321446281671525\n",
      "trial: 5, iter: 8800, curr loss: 1.3179831504821777, avg loss: 1.3314514076709747\n",
      "trial: 5, iter: 9000, curr loss: 1.3335201740264893, avg loss: 1.3322033435106277\n",
      "trial: 5, iter: 9200, curr loss: 1.3137545585632324, avg loss: 1.3284683334827423\n",
      "trial: 5, iter: 9400, curr loss: 1.3264386653900146, avg loss: 1.328606642484665\n",
      "trial: 5, iter: 9600, curr loss: 1.355884313583374, avg loss: 1.3234929424524307\n",
      "trial: 5, iter: 9800, curr loss: 1.335459589958191, avg loss: 1.326780155301094\n",
      "trial: 5, iter: 10000, curr loss: 1.336955189704895, avg loss: 1.3248299884796142\n",
      "trial: 5, iter: 10200, curr loss: 1.311131238937378, avg loss: 1.3229738569259644\n",
      "trial: 5, iter: 10400, curr loss: 1.295348048210144, avg loss: 1.321993904709816\n",
      "trial: 5, iter: 10600, curr loss: 1.2926219701766968, avg loss: 1.3225231873989105\n",
      "trial: 5, iter: 10800, curr loss: 1.342441201210022, avg loss: 1.3214046990871429\n",
      "trial: 5, iter: 11000, curr loss: 1.336289644241333, avg loss: 1.3232625156641007\n",
      "trial: 5, iter: 11200, curr loss: 1.319646954536438, avg loss: 1.3190241140127181\n",
      "trial: 5, iter: 11400, curr loss: 1.3265435695648193, avg loss: 1.320347819328308\n",
      "trial: 5, iter: 11600, curr loss: 1.3361386060714722, avg loss: 1.318507331609726\n",
      "trial: 5, iter: 11800, curr loss: 1.3249644041061401, avg loss: 1.3225156217813492\n",
      "trial: 5, iter: 12000, curr loss: 1.3572174310684204, avg loss: 1.320175684094429\n",
      "trial: 5, iter: 12200, curr loss: 1.3313874006271362, avg loss: 1.3213084429502486\n",
      "trial: 5, iter: 12400, curr loss: 1.3171191215515137, avg loss: 1.3210151529312133\n",
      "trial: 5, iter: 12600, curr loss: 1.3076984882354736, avg loss: 1.3195277190208434\n",
      "trial: 5, iter: 12800, curr loss: 1.338148593902588, avg loss: 1.3202138769626617\n",
      "trial: 5, iter: 13000, curr loss: 1.2786340713500977, avg loss: 1.3198912006616592\n",
      "trial: 5, iter: 13200, curr loss: 1.3622134923934937, avg loss: 1.3208554530143737\n",
      "trial: 5, iter: 13400, curr loss: 1.3042728900909424, avg loss: 1.3197423976659775\n",
      "trial: 5, iter: 13600, curr loss: 1.3259451389312744, avg loss: 1.3158804786205291\n",
      "trial: 5, iter: 13800, curr loss: 1.3440215587615967, avg loss: 1.3163026559352875\n",
      "trial: 5, iter: 14000, curr loss: 1.3210166692733765, avg loss: 1.31692909181118\n",
      "trial: 5, iter: 14200, curr loss: 1.324902892112732, avg loss: 1.3159083050489426\n",
      "trial: 5, iter: 14400, curr loss: 1.3107596635818481, avg loss: 1.318389009833336\n",
      "trial: 5, iter: 14600, curr loss: 1.3128095865249634, avg loss: 1.3181495016813278\n",
      "trial: 5, iter: 14800, curr loss: 1.2922987937927246, avg loss: 1.319235953092575\n",
      "trial: 5, iter: 15000, curr loss: 1.3150355815887451, avg loss: 1.317817406654358\n",
      "trial: 5, iter: 15200, curr loss: 1.3423552513122559, avg loss: 1.316160745024681\n",
      "trial: 5, iter: 15400, curr loss: 1.3075376749038696, avg loss: 1.3164316576719284\n",
      "trial: 5, iter: 15600, curr loss: 1.32276451587677, avg loss: 1.317665410041809\n",
      "trial: 5, ldr: 0.40964826941490173\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.36072695851325987\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.385512113571167, avg loss: 1.3870376873016357\n",
      "trial: 1, iter: 400, curr loss: 1.3912632465362549, avg loss: 1.387094597220421\n",
      "trial: 1, iter: 600, curr loss: 1.3849773406982422, avg loss: 1.386573080420494\n",
      "trial: 1, iter: 800, curr loss: 1.3871945142745972, avg loss: 1.3864270538091659\n",
      "trial: 1, iter: 1000, curr loss: 1.3869078159332275, avg loss: 1.3865494269132614\n",
      "trial: 1, iter: 1200, curr loss: 1.3846203088760376, avg loss: 1.3864044284820556\n",
      "trial: 1, iter: 1400, curr loss: 1.3877371549606323, avg loss: 1.3863644075393677\n",
      "trial: 1, iter: 1600, curr loss: 1.3862906694412231, avg loss: 1.3863049566745758\n",
      "trial: 1, iter: 1800, curr loss: 1.3865350484848022, avg loss: 1.386463502049446\n",
      "trial: 1, iter: 2000, curr loss: 1.3835155963897705, avg loss: 1.3862878841161728\n",
      "trial: 1, iter: 2200, curr loss: 1.3861935138702393, avg loss: 1.3864384800195695\n",
      "trial: 1, iter: 2400, curr loss: 1.3859601020812988, avg loss: 1.3863605463504791\n",
      "trial: 1, iter: 2600, curr loss: 1.3872981071472168, avg loss: 1.3862434738874436\n",
      "trial: 1, iter: 2800, curr loss: 1.3866132497787476, avg loss: 1.3863887548446656\n",
      "trial: 1, iter: 3000, curr loss: 1.3866945505142212, avg loss: 1.3863892072439195\n",
      "trial: 1, iter: 3200, curr loss: 1.383876085281372, avg loss: 1.3863419842720033\n",
      "trial: 1, iter: 3400, curr loss: 1.3864840269088745, avg loss: 1.3863368815183639\n",
      "trial: 1, iter: 3600, curr loss: 1.386412501335144, avg loss: 1.3863412714004517\n",
      "trial: 1, iter: 3800, curr loss: 1.3841075897216797, avg loss: 1.386238334774971\n",
      "trial: 1, iter: 4000, curr loss: 1.3861583471298218, avg loss: 1.3862509977817536\n",
      "trial: 1, iter: 4200, curr loss: 1.3849517107009888, avg loss: 1.3856974303722382\n",
      "trial: 1, iter: 4400, curr loss: 1.377228856086731, avg loss: 1.3816410881280898\n",
      "trial: 1, iter: 4600, curr loss: 1.3628383874893188, avg loss: 1.3735554713010787\n",
      "trial: 1, iter: 4800, curr loss: 1.3649014234542847, avg loss: 1.3684680354595185\n",
      "trial: 1, iter: 5000, curr loss: 1.3605103492736816, avg loss: 1.3626171219348908\n",
      "trial: 1, iter: 5200, curr loss: 1.3577861785888672, avg loss: 1.3592062044143676\n",
      "trial: 1, iter: 5400, curr loss: 1.3444700241088867, avg loss: 1.3589029848575591\n",
      "trial: 1, iter: 5600, curr loss: 1.3525155782699585, avg loss: 1.3548071300983429\n",
      "trial: 1, iter: 5800, curr loss: 1.3590198755264282, avg loss: 1.3548737049102784\n",
      "trial: 1, iter: 6000, curr loss: 1.3451330661773682, avg loss: 1.3514130342006683\n",
      "trial: 1, iter: 6200, curr loss: 1.3348522186279297, avg loss: 1.348405504822731\n",
      "trial: 1, iter: 6400, curr loss: 1.309905767440796, avg loss: 1.3445844966173173\n",
      "trial: 1, iter: 6600, curr loss: 1.3243746757507324, avg loss: 1.3402187323570252\n",
      "trial: 1, iter: 6800, curr loss: 1.3452317714691162, avg loss: 1.3347485840320588\n",
      "trial: 1, iter: 7000, curr loss: 1.3111108541488647, avg loss: 1.3307982391119004\n",
      "trial: 1, iter: 7200, curr loss: 1.2886966466903687, avg loss: 1.3274191761016845\n",
      "trial: 1, iter: 7400, curr loss: 1.3098934888839722, avg loss: 1.324023505449295\n",
      "trial: 1, iter: 7600, curr loss: 1.3417083024978638, avg loss: 1.3231409358978272\n",
      "trial: 1, iter: 7800, curr loss: 1.3037866353988647, avg loss: 1.3214542365074158\n",
      "trial: 1, iter: 8000, curr loss: 1.3207322359085083, avg loss: 1.319716486930847\n",
      "trial: 1, iter: 8200, curr loss: 1.3054324388504028, avg loss: 1.3222188478708268\n",
      "trial: 1, iter: 8400, curr loss: 1.3217943906784058, avg loss: 1.3193120157718659\n",
      "trial: 1, iter: 8600, curr loss: 1.2889676094055176, avg loss: 1.319781613945961\n",
      "trial: 1, iter: 8800, curr loss: 1.2854465246200562, avg loss: 1.3200042605400086\n",
      "trial: 1, iter: 9000, curr loss: 1.3599741458892822, avg loss: 1.317933269739151\n",
      "trial: 1, iter: 9200, curr loss: 1.316449522972107, avg loss: 1.3171195036172867\n",
      "trial: 1, iter: 9400, curr loss: 1.2845611572265625, avg loss: 1.3171848064661027\n",
      "trial: 1, iter: 9600, curr loss: 1.3579862117767334, avg loss: 1.3182721734046936\n",
      "trial: 1, iter: 9800, curr loss: 1.3339169025421143, avg loss: 1.315722330212593\n",
      "trial: 1, iter: 10000, curr loss: 1.3519318103790283, avg loss: 1.3137091374397278\n",
      "trial: 1, iter: 10200, curr loss: 1.3585264682769775, avg loss: 1.3161422634124755\n",
      "trial: 1, iter: 10400, curr loss: 1.2945319414138794, avg loss: 1.3174711018800735\n",
      "trial: 1, iter: 10600, curr loss: 1.296054482460022, avg loss: 1.3171953928470612\n",
      "trial: 1, iter: 10800, curr loss: 1.3127917051315308, avg loss: 1.3170801872014999\n",
      "trial: 1, iter: 11000, curr loss: 1.3026268482208252, avg loss: 1.3145030927658081\n",
      "trial: 1, iter: 11200, curr loss: 1.3068654537200928, avg loss: 1.3156825816631317\n",
      "trial: 1, iter: 11400, curr loss: 1.3211294412612915, avg loss: 1.3134935522079467\n",
      "trial: 1, iter: 11600, curr loss: 1.3896746635437012, avg loss: 1.3138101494312286\n",
      "trial: 1, iter: 11800, curr loss: 1.3487077951431274, avg loss: 1.3153651916980744\n",
      "trial: 1, iter: 12000, curr loss: 1.3230199813842773, avg loss: 1.3157786428928375\n",
      "trial: 1, iter: 12200, curr loss: 1.3110072612762451, avg loss: 1.3144477558135987\n",
      "trial: 1, iter: 12400, curr loss: 1.3019604682922363, avg loss: 1.3155391865968704\n",
      "trial: 1, iter: 12600, curr loss: 1.3248993158340454, avg loss: 1.3136459124088287\n",
      "trial: 1, iter: 12800, curr loss: 1.3223261833190918, avg loss: 1.3155846691131592\n",
      "trial: 1, iter: 13000, curr loss: 1.3413258790969849, avg loss: 1.3127782481908798\n",
      "trial: 1, iter: 13200, curr loss: 1.3050487041473389, avg loss: 1.3150321656465531\n",
      "trial: 1, iter: 13400, curr loss: 1.3217326402664185, avg loss: 1.3141643995046615\n",
      "trial: 1, iter: 13600, curr loss: 1.3395825624465942, avg loss: 1.3166297996044158\n",
      "trial: 1, iter: 13800, curr loss: 1.3035786151885986, avg loss: 1.312928956747055\n",
      "trial: 1, iter: 14000, curr loss: 1.341802954673767, avg loss: 1.3118339920043944\n",
      "trial: 1, iter: 14200, curr loss: 1.309336543083191, avg loss: 1.314294967651367\n",
      "trial: 1, iter: 14400, curr loss: 1.3172701597213745, avg loss: 1.3129398506879806\n",
      "trial: 1, iter: 14600, curr loss: 1.3141227960586548, avg loss: 1.3148935371637345\n",
      "trial: 1, iter: 14800, curr loss: 1.3193795680999756, avg loss: 1.3137412303686142\n",
      "trial: 1, iter: 15000, curr loss: 1.3200072050094604, avg loss: 1.313141096830368\n",
      "trial: 1, iter: 15200, curr loss: 1.3090418577194214, avg loss: 1.3144301635026931\n",
      "trial: 1, iter: 15400, curr loss: 1.3282960653305054, avg loss: 1.3122694706916809\n",
      "trial: 1, iter: 15600, curr loss: 1.343332052230835, avg loss: 1.3124809885025024\n",
      "trial: 1, ldr: 0.3148941397666931\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866621255874634, avg loss: 1.3874108564853669\n",
      "trial: 2, iter: 400, curr loss: 1.3824656009674072, avg loss: 1.3868157327175141\n",
      "trial: 2, iter: 600, curr loss: 1.3845142126083374, avg loss: 1.3866476094722748\n",
      "trial: 2, iter: 800, curr loss: 1.3900030851364136, avg loss: 1.3864647895097733\n",
      "trial: 2, iter: 1000, curr loss: 1.3866052627563477, avg loss: 1.386583479642868\n",
      "trial: 2, iter: 1200, curr loss: 1.384533405303955, avg loss: 1.3864564508199693\n",
      "trial: 2, iter: 1400, curr loss: 1.3845676183700562, avg loss: 1.3863988649845123\n",
      "trial: 2, iter: 1600, curr loss: 1.3853302001953125, avg loss: 1.3864605045318603\n",
      "trial: 2, iter: 1800, curr loss: 1.3894264698028564, avg loss: 1.386355094909668\n",
      "trial: 2, iter: 2000, curr loss: 1.386594295501709, avg loss: 1.3863810360431672\n",
      "trial: 2, iter: 2200, curr loss: 1.3855992555618286, avg loss: 1.386450166106224\n",
      "trial: 2, iter: 2400, curr loss: 1.3868279457092285, avg loss: 1.386380250453949\n",
      "trial: 2, iter: 2600, curr loss: 1.3854440450668335, avg loss: 1.3863276135921478\n",
      "trial: 2, iter: 2800, curr loss: 1.386662244796753, avg loss: 1.3863511884212494\n",
      "trial: 2, iter: 3000, curr loss: 1.3857673406600952, avg loss: 1.386344040632248\n",
      "trial: 2, iter: 3200, curr loss: 1.3863555192947388, avg loss: 1.386253137588501\n",
      "trial: 2, iter: 3400, curr loss: 1.3860281705856323, avg loss: 1.3863333946466445\n",
      "trial: 2, iter: 3600, curr loss: 1.38627028465271, avg loss: 1.386295458674431\n",
      "trial: 2, iter: 3800, curr loss: 1.3867980241775513, avg loss: 1.386301257610321\n",
      "trial: 2, iter: 4000, curr loss: 1.3871535062789917, avg loss: 1.3863560837507247\n",
      "trial: 2, iter: 4200, curr loss: 1.3866991996765137, avg loss: 1.3863342690467835\n",
      "trial: 2, iter: 4400, curr loss: 1.3859877586364746, avg loss: 1.3863322085142136\n",
      "trial: 2, iter: 4600, curr loss: 1.386694312095642, avg loss: 1.386268430352211\n",
      "trial: 2, iter: 4800, curr loss: 1.386103868484497, avg loss: 1.3863177758455276\n",
      "trial: 2, iter: 5000, curr loss: 1.3860716819763184, avg loss: 1.3862245535850526\n",
      "trial: 2, iter: 5200, curr loss: 1.3849138021469116, avg loss: 1.386038715839386\n",
      "trial: 2, iter: 5400, curr loss: 1.381629467010498, avg loss: 1.3852180111408234\n",
      "trial: 2, iter: 5600, curr loss: 1.3762390613555908, avg loss: 1.3826219630241394\n",
      "trial: 2, iter: 5800, curr loss: 1.3508268594741821, avg loss: 1.3766008150577544\n",
      "trial: 2, iter: 6000, curr loss: 1.383350133895874, avg loss: 1.3678593534231185\n",
      "trial: 2, iter: 6200, curr loss: 1.3436483144760132, avg loss: 1.3621554154157638\n",
      "trial: 2, iter: 6400, curr loss: 1.367556095123291, avg loss: 1.3586899793148042\n",
      "trial: 2, iter: 6600, curr loss: 1.3676108121871948, avg loss: 1.3597237557172774\n",
      "trial: 2, iter: 6800, curr loss: 1.3471109867095947, avg loss: 1.356593455672264\n",
      "trial: 2, iter: 7000, curr loss: 1.3574771881103516, avg loss: 1.3539350110292434\n",
      "trial: 2, iter: 7200, curr loss: 1.3360024690628052, avg loss: 1.3541464173793794\n",
      "trial: 2, iter: 7400, curr loss: 1.3361021280288696, avg loss: 1.3501665955781936\n",
      "trial: 2, iter: 7600, curr loss: 1.3363642692565918, avg loss: 1.3475774711370467\n",
      "trial: 2, iter: 7800, curr loss: 1.3367009162902832, avg loss: 1.3436465644836426\n",
      "trial: 2, iter: 8000, curr loss: 1.3199119567871094, avg loss: 1.3421403849124909\n",
      "trial: 2, iter: 8200, curr loss: 1.3413957357406616, avg loss: 1.338136755824089\n",
      "trial: 2, iter: 8400, curr loss: 1.3456388711929321, avg loss: 1.3351669573783875\n",
      "trial: 2, iter: 8600, curr loss: 1.3168909549713135, avg loss: 1.3332689726352691\n",
      "trial: 2, iter: 8800, curr loss: 1.3403254747390747, avg loss: 1.3319425439834596\n",
      "trial: 2, iter: 9000, curr loss: 1.3324869871139526, avg loss: 1.3312113112211228\n",
      "trial: 2, iter: 9200, curr loss: 1.3427157402038574, avg loss: 1.3296341848373414\n",
      "trial: 2, iter: 9400, curr loss: 1.317849040031433, avg loss: 1.3279378551244736\n",
      "trial: 2, iter: 9600, curr loss: 1.2817994356155396, avg loss: 1.3251161527633668\n",
      "trial: 2, iter: 9800, curr loss: 1.3050363063812256, avg loss: 1.3240093326568603\n",
      "trial: 2, iter: 10000, curr loss: 1.3035625219345093, avg loss: 1.3230961167812347\n",
      "trial: 2, iter: 10200, curr loss: 1.3324311971664429, avg loss: 1.3223618102073669\n",
      "trial: 2, iter: 10400, curr loss: 1.3140192031860352, avg loss: 1.3218737018108369\n",
      "trial: 2, iter: 10600, curr loss: 1.3444734811782837, avg loss: 1.3214985758066178\n",
      "trial: 2, iter: 10800, curr loss: 1.3134527206420898, avg loss: 1.3197586351633073\n",
      "trial: 2, iter: 11000, curr loss: 1.3428020477294922, avg loss: 1.3189413332939148\n",
      "trial: 2, iter: 11200, curr loss: 1.325842022895813, avg loss: 1.320122309923172\n",
      "trial: 2, iter: 11400, curr loss: 1.3259291648864746, avg loss: 1.319517040848732\n",
      "trial: 2, iter: 11600, curr loss: 1.3276677131652832, avg loss: 1.3183398830890656\n",
      "trial: 2, iter: 11800, curr loss: 1.3178209066390991, avg loss: 1.3197180259227752\n",
      "trial: 2, iter: 12000, curr loss: 1.3361234664916992, avg loss: 1.317313751578331\n",
      "trial: 2, iter: 12200, curr loss: 1.2988625764846802, avg loss: 1.3182626956701278\n",
      "trial: 2, iter: 12400, curr loss: 1.3123209476470947, avg loss: 1.317812219262123\n",
      "trial: 2, iter: 12600, curr loss: 1.313460350036621, avg loss: 1.3212475442886353\n",
      "trial: 2, iter: 12800, curr loss: 1.338783621788025, avg loss: 1.3155015671253205\n",
      "trial: 2, iter: 13000, curr loss: 1.2976794242858887, avg loss: 1.3160517978668214\n",
      "trial: 2, iter: 13200, curr loss: 1.3001471757888794, avg loss: 1.3174738919734954\n",
      "trial: 2, iter: 13400, curr loss: 1.3136069774627686, avg loss: 1.31673235476017\n",
      "trial: 2, iter: 13600, curr loss: 1.3253998756408691, avg loss: 1.3181127178668977\n",
      "trial: 2, iter: 13800, curr loss: 1.3065963983535767, avg loss: 1.3164111763238906\n",
      "trial: 2, iter: 14000, curr loss: 1.336572289466858, avg loss: 1.316460401415825\n",
      "trial: 2, iter: 14200, curr loss: 1.2951570749282837, avg loss: 1.3198044884204865\n",
      "trial: 2, iter: 14400, curr loss: 1.3098552227020264, avg loss: 1.3172479420900345\n",
      "trial: 2, iter: 14600, curr loss: 1.3174822330474854, avg loss: 1.3138194960355758\n",
      "trial: 2, iter: 14800, curr loss: 1.33793044090271, avg loss: 1.3173836719989778\n",
      "trial: 2, iter: 15000, curr loss: 1.3138744831085205, avg loss: 1.3169424843788147\n",
      "trial: 2, iter: 15200, curr loss: 1.3452162742614746, avg loss: 1.3127814722061157\n",
      "trial: 2, iter: 15400, curr loss: 1.309872031211853, avg loss: 1.3163517212867737\n",
      "trial: 2, iter: 15600, curr loss: 1.354109764099121, avg loss: 1.3154818361997604\n",
      "trial: 2, ldr: 0.4104814827442169\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3881021738052368, avg loss: 1.3875743013620376\n",
      "trial: 3, iter: 400, curr loss: 1.3857357501983643, avg loss: 1.386955788731575\n",
      "trial: 3, iter: 600, curr loss: 1.3870664834976196, avg loss: 1.3867019575834274\n",
      "trial: 3, iter: 800, curr loss: 1.3864450454711914, avg loss: 1.3866610360145568\n",
      "trial: 3, iter: 1000, curr loss: 1.385324239730835, avg loss: 1.3864710962772369\n",
      "trial: 3, iter: 1200, curr loss: 1.3853195905685425, avg loss: 1.3865492749214172\n",
      "trial: 3, iter: 1400, curr loss: 1.386592149734497, avg loss: 1.3865561681985854\n",
      "trial: 3, iter: 1600, curr loss: 1.3853243589401245, avg loss: 1.3863691753149032\n",
      "trial: 3, iter: 1800, curr loss: 1.385520339012146, avg loss: 1.3863382369279862\n",
      "trial: 3, iter: 2000, curr loss: 1.3870666027069092, avg loss: 1.3863670122623444\n",
      "trial: 3, iter: 2200, curr loss: 1.3861088752746582, avg loss: 1.3863938039541244\n",
      "trial: 3, iter: 2400, curr loss: 1.385724425315857, avg loss: 1.3863839930295945\n",
      "trial: 3, iter: 2600, curr loss: 1.3861398696899414, avg loss: 1.386355156302452\n",
      "trial: 3, iter: 2800, curr loss: 1.3868112564086914, avg loss: 1.386377259492874\n",
      "trial: 3, iter: 3000, curr loss: 1.3875161409378052, avg loss: 1.3863462495803833\n",
      "trial: 3, iter: 3200, curr loss: 1.3858885765075684, avg loss: 1.386317617893219\n",
      "trial: 3, iter: 3400, curr loss: 1.3864943981170654, avg loss: 1.386308771967888\n",
      "trial: 3, iter: 3600, curr loss: 1.3861162662506104, avg loss: 1.3863754469156264\n",
      "trial: 3, iter: 3800, curr loss: 1.3861773014068604, avg loss: 1.3863204783201217\n",
      "trial: 3, iter: 4000, curr loss: 1.3849842548370361, avg loss: 1.3862773883342743\n",
      "trial: 3, iter: 4200, curr loss: 1.3860350847244263, avg loss: 1.3863312715291978\n",
      "trial: 3, iter: 4400, curr loss: 1.3859118223190308, avg loss: 1.386322764158249\n",
      "trial: 3, iter: 4600, curr loss: 1.386662483215332, avg loss: 1.386366556286812\n",
      "trial: 3, iter: 4800, curr loss: 1.386385440826416, avg loss: 1.3863027268648147\n",
      "trial: 3, iter: 5000, curr loss: 1.384648323059082, avg loss: 1.3862842231988908\n",
      "trial: 3, iter: 5200, curr loss: 1.385344386100769, avg loss: 1.3862957864999772\n",
      "trial: 3, iter: 5400, curr loss: 1.3868639469146729, avg loss: 1.3863292157649993\n",
      "trial: 3, iter: 5600, curr loss: 1.3855156898498535, avg loss: 1.3863016885519028\n",
      "trial: 3, iter: 5800, curr loss: 1.3856271505355835, avg loss: 1.3862897920608521\n",
      "trial: 3, iter: 6000, curr loss: 1.3862557411193848, avg loss: 1.3863389354944229\n",
      "trial: 3, iter: 6200, curr loss: 1.3856977224349976, avg loss: 1.386346937417984\n",
      "trial: 3, iter: 6400, curr loss: 1.387069582939148, avg loss: 1.3862744140625\n",
      "trial: 3, iter: 6600, curr loss: 1.386284351348877, avg loss: 1.3863376849889755\n",
      "trial: 3, iter: 6800, curr loss: 1.38608980178833, avg loss: 1.3863265597820282\n",
      "trial: 3, iter: 7000, curr loss: 1.386549949645996, avg loss: 1.3862283998727798\n",
      "trial: 3, iter: 7200, curr loss: 1.3857500553131104, avg loss: 1.386072502732277\n",
      "trial: 3, iter: 7400, curr loss: 1.389326572418213, avg loss: 1.3852475678920746\n",
      "trial: 3, iter: 7600, curr loss: 1.3765220642089844, avg loss: 1.3826509302854537\n",
      "trial: 3, iter: 7800, curr loss: 1.3892061710357666, avg loss: 1.3767980182170867\n",
      "trial: 3, iter: 8000, curr loss: 1.3582050800323486, avg loss: 1.3666905224323274\n",
      "trial: 3, iter: 8200, curr loss: 1.3445076942443848, avg loss: 1.3633325958251954\n",
      "trial: 3, iter: 8400, curr loss: 1.3544501066207886, avg loss: 1.3616650623083115\n",
      "trial: 3, iter: 8600, curr loss: 1.3428336381912231, avg loss: 1.3577909415960312\n",
      "trial: 3, iter: 8800, curr loss: 1.3522896766662598, avg loss: 1.3574670153856276\n",
      "trial: 3, iter: 9000, curr loss: 1.3326752185821533, avg loss: 1.355951231122017\n",
      "trial: 3, iter: 9200, curr loss: 1.341112494468689, avg loss: 1.3510787504911423\n",
      "trial: 3, iter: 9400, curr loss: 1.3504490852355957, avg loss: 1.346319095492363\n",
      "trial: 3, iter: 9600, curr loss: 1.3240007162094116, avg loss: 1.3390142607688904\n",
      "trial: 3, iter: 9800, curr loss: 1.364003300666809, avg loss: 1.3318960523605348\n",
      "trial: 3, iter: 10000, curr loss: 1.336127519607544, avg loss: 1.3287935942411422\n",
      "trial: 3, iter: 10200, curr loss: 1.3062540292739868, avg loss: 1.3257763981819153\n",
      "trial: 3, iter: 10400, curr loss: 1.3248118162155151, avg loss: 1.325049723982811\n",
      "trial: 3, iter: 10600, curr loss: 1.3238394260406494, avg loss: 1.3238249081373215\n",
      "trial: 3, iter: 10800, curr loss: 1.3188942670822144, avg loss: 1.3208283179998397\n",
      "trial: 3, iter: 11000, curr loss: 1.3317278623580933, avg loss: 1.3218113547563553\n",
      "trial: 3, iter: 11200, curr loss: 1.3292875289916992, avg loss: 1.32171657204628\n",
      "trial: 3, iter: 11400, curr loss: 1.3194602727890015, avg loss: 1.32052450299263\n",
      "trial: 3, iter: 11600, curr loss: 1.3405128717422485, avg loss: 1.3192102527618408\n",
      "trial: 3, iter: 11800, curr loss: 1.3202550411224365, avg loss: 1.3202513080835343\n",
      "trial: 3, iter: 12000, curr loss: 1.3090287446975708, avg loss: 1.3171183449029922\n",
      "trial: 3, iter: 12200, curr loss: 1.3144218921661377, avg loss: 1.3209534728527068\n",
      "trial: 3, iter: 12400, curr loss: 1.3343952894210815, avg loss: 1.317808111310005\n",
      "trial: 3, iter: 12600, curr loss: 1.2774231433868408, avg loss: 1.3162291640043258\n",
      "trial: 3, iter: 12800, curr loss: 1.3072327375411987, avg loss: 1.3163108187913894\n",
      "trial: 3, iter: 13000, curr loss: 1.3121143579483032, avg loss: 1.316272875070572\n",
      "trial: 3, iter: 13200, curr loss: 1.3175009489059448, avg loss: 1.3156107920408249\n",
      "trial: 3, iter: 13400, curr loss: 1.3305797576904297, avg loss: 1.3187023353576661\n",
      "trial: 3, iter: 13600, curr loss: 1.3415063619613647, avg loss: 1.3145215916633606\n",
      "trial: 3, iter: 13800, curr loss: 1.2903660535812378, avg loss: 1.3140762382745743\n",
      "trial: 3, iter: 14000, curr loss: 1.3125247955322266, avg loss: 1.3159577059745788\n",
      "trial: 3, iter: 14200, curr loss: 1.2971184253692627, avg loss: 1.31548714697361\n",
      "trial: 3, iter: 14400, curr loss: 1.3052254915237427, avg loss: 1.3148330879211425\n",
      "trial: 3, iter: 14600, curr loss: 1.3290973901748657, avg loss: 1.3163161861896515\n",
      "trial: 3, iter: 14800, curr loss: 1.3688699007034302, avg loss: 1.3186309790611268\n",
      "trial: 3, iter: 15000, curr loss: 1.316156029701233, avg loss: 1.314877358675003\n",
      "trial: 3, iter: 15200, curr loss: 1.305334210395813, avg loss: 1.3153297078609467\n",
      "trial: 3, iter: 15400, curr loss: 1.296020746231079, avg loss: 1.315602703690529\n",
      "trial: 3, iter: 15600, curr loss: 1.3203297853469849, avg loss: 1.3131611776351928\n",
      "trial: 3, ldr: 0.37381139397621155\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3833420276641846, avg loss: 1.3870903474092484\n",
      "trial: 4, iter: 400, curr loss: 1.3865915536880493, avg loss: 1.3866293269395829\n",
      "trial: 4, iter: 600, curr loss: 1.388396143913269, avg loss: 1.3865175008773805\n",
      "trial: 4, iter: 800, curr loss: 1.386704921722412, avg loss: 1.3864102882146836\n",
      "trial: 4, iter: 1000, curr loss: 1.3870841264724731, avg loss: 1.3864602184295653\n",
      "trial: 4, iter: 1200, curr loss: 1.3865556716918945, avg loss: 1.3862774682044983\n",
      "trial: 4, iter: 1400, curr loss: 1.3871266841888428, avg loss: 1.3864396435022355\n",
      "trial: 4, iter: 1600, curr loss: 1.388134241104126, avg loss: 1.38633409678936\n",
      "trial: 4, iter: 1800, curr loss: 1.386562705039978, avg loss: 1.3864009809494018\n",
      "trial: 4, iter: 2000, curr loss: 1.3871504068374634, avg loss: 1.3863214486837387\n",
      "trial: 4, iter: 2200, curr loss: 1.3868763446807861, avg loss: 1.3863962423801421\n",
      "trial: 4, iter: 2400, curr loss: 1.3861666917800903, avg loss: 1.3863353908061982\n",
      "trial: 4, iter: 2600, curr loss: 1.3866478204727173, avg loss: 1.3863156121969222\n",
      "trial: 4, iter: 2800, curr loss: 1.3867003917694092, avg loss: 1.3863920325040817\n",
      "trial: 4, iter: 3000, curr loss: 1.3883196115493774, avg loss: 1.3862872463464737\n",
      "trial: 4, iter: 3200, curr loss: 1.3864436149597168, avg loss: 1.3863516795635222\n",
      "trial: 4, iter: 3400, curr loss: 1.3869439363479614, avg loss: 1.3863389217853546\n",
      "trial: 4, iter: 3600, curr loss: 1.3864909410476685, avg loss: 1.3863460224866868\n",
      "trial: 4, iter: 3800, curr loss: 1.3860232830047607, avg loss: 1.3862662386894227\n",
      "trial: 4, iter: 4000, curr loss: 1.3853999376296997, avg loss: 1.3863126921653748\n",
      "trial: 4, iter: 4200, curr loss: 1.3868427276611328, avg loss: 1.3863223695755005\n",
      "trial: 4, iter: 4400, curr loss: 1.3862717151641846, avg loss: 1.3863529026508332\n",
      "trial: 4, iter: 4600, curr loss: 1.3868083953857422, avg loss: 1.3862969923019408\n",
      "trial: 4, iter: 4800, curr loss: 1.386139154434204, avg loss: 1.3863286167383193\n",
      "trial: 4, iter: 5000, curr loss: 1.3882523775100708, avg loss: 1.3863007825613023\n",
      "trial: 4, iter: 5200, curr loss: 1.3866021633148193, avg loss: 1.38636696100235\n",
      "trial: 4, iter: 5400, curr loss: 1.385208010673523, avg loss: 1.3863486814498902\n",
      "trial: 4, iter: 5600, curr loss: 1.386566162109375, avg loss: 1.3863940387964249\n",
      "trial: 4, iter: 5800, curr loss: 1.3861744403839111, avg loss: 1.3862974226474762\n",
      "trial: 4, iter: 6000, curr loss: 1.386413812637329, avg loss: 1.3863290852308274\n",
      "trial: 4, iter: 6200, curr loss: 1.3861784934997559, avg loss: 1.386320983171463\n",
      "trial: 4, iter: 6400, curr loss: 1.3870398998260498, avg loss: 1.3863201004266739\n",
      "trial: 4, iter: 6600, curr loss: 1.3864386081695557, avg loss: 1.3863161891698836\n",
      "trial: 4, iter: 6800, curr loss: 1.3857090473175049, avg loss: 1.3863219326734544\n",
      "trial: 4, iter: 7000, curr loss: 1.3857461214065552, avg loss: 1.3863438403606414\n",
      "trial: 4, iter: 7200, curr loss: 1.3858189582824707, avg loss: 1.3863043260574341\n",
      "trial: 4, iter: 7400, curr loss: 1.3869569301605225, avg loss: 1.3862953990697862\n",
      "trial: 4, iter: 7600, curr loss: 1.3876063823699951, avg loss: 1.3863653916120529\n",
      "trial: 4, iter: 7800, curr loss: 1.3858789205551147, avg loss: 1.3863862252235413\n",
      "trial: 4, iter: 8000, curr loss: 1.386611819267273, avg loss: 1.3863357895612716\n",
      "trial: 4, iter: 8200, curr loss: 1.386335849761963, avg loss: 1.3862543499469757\n",
      "trial: 4, iter: 8400, curr loss: 1.389449954032898, avg loss: 1.3860157519578933\n",
      "trial: 4, iter: 8600, curr loss: 1.3816192150115967, avg loss: 1.3852125370502473\n",
      "trial: 4, iter: 8800, curr loss: 1.384803295135498, avg loss: 1.3832115143537522\n",
      "trial: 4, iter: 9000, curr loss: 1.3763858079910278, avg loss: 1.3805674016475677\n",
      "trial: 4, iter: 9200, curr loss: 1.3649959564208984, avg loss: 1.3776454085111618\n",
      "trial: 4, iter: 9400, curr loss: 1.3740731477737427, avg loss: 1.3742723435163497\n",
      "trial: 4, iter: 9600, curr loss: 1.386210322380066, avg loss: 1.3682843834161758\n",
      "trial: 4, iter: 9800, curr loss: 1.3657326698303223, avg loss: 1.359025177359581\n",
      "trial: 4, iter: 10000, curr loss: 1.3605517148971558, avg loss: 1.357445685863495\n",
      "trial: 4, iter: 10200, curr loss: 1.3363901376724243, avg loss: 1.3517403399944306\n",
      "trial: 4, iter: 10400, curr loss: 1.3777172565460205, avg loss: 1.3477660977840424\n",
      "trial: 4, iter: 10600, curr loss: 1.3559131622314453, avg loss: 1.3444517332315444\n",
      "trial: 4, iter: 10800, curr loss: 1.3208105564117432, avg loss: 1.3416965889930725\n",
      "trial: 4, iter: 11000, curr loss: 1.326019287109375, avg loss: 1.3404059475660324\n",
      "trial: 4, iter: 11200, curr loss: 1.3602235317230225, avg loss: 1.3392977738380432\n",
      "trial: 4, iter: 11400, curr loss: 1.3491666316986084, avg loss: 1.340090674161911\n",
      "trial: 4, iter: 11600, curr loss: 1.319440484046936, avg loss: 1.3384362548589706\n",
      "trial: 4, iter: 11800, curr loss: 1.3443500995635986, avg loss: 1.335509307384491\n",
      "trial: 4, iter: 12000, curr loss: 1.3464760780334473, avg loss: 1.3340807718038559\n",
      "trial: 4, iter: 12200, curr loss: 1.3258486986160278, avg loss: 1.3301850581169128\n",
      "trial: 4, iter: 12400, curr loss: 1.3224905729293823, avg loss: 1.330752294063568\n",
      "trial: 4, iter: 12600, curr loss: 1.3222205638885498, avg loss: 1.3276551669836045\n",
      "trial: 4, iter: 12800, curr loss: 1.3321994543075562, avg loss: 1.3264653152227401\n",
      "trial: 4, iter: 13000, curr loss: 1.3298234939575195, avg loss: 1.3255983835458756\n",
      "trial: 4, iter: 13200, curr loss: 1.3431166410446167, avg loss: 1.326405114531517\n",
      "trial: 4, iter: 13400, curr loss: 1.3305842876434326, avg loss: 1.3227963972091674\n",
      "trial: 4, iter: 13600, curr loss: 1.3500266075134277, avg loss: 1.3240419006347657\n",
      "trial: 4, iter: 13800, curr loss: 1.3581039905548096, avg loss: 1.3245656633377074\n",
      "trial: 4, iter: 14000, curr loss: 1.2895376682281494, avg loss: 1.3209379756450652\n",
      "trial: 4, iter: 14200, curr loss: 1.3100831508636475, avg loss: 1.3211824989318848\n",
      "trial: 4, iter: 14400, curr loss: 1.3318450450897217, avg loss: 1.321039144396782\n",
      "trial: 4, iter: 14600, curr loss: 1.3369370698928833, avg loss: 1.3206873029470443\n",
      "trial: 4, iter: 14800, curr loss: 1.3207725286483765, avg loss: 1.3194079685211182\n",
      "trial: 4, iter: 15000, curr loss: 1.3397302627563477, avg loss: 1.3188374561071396\n",
      "trial: 4, iter: 15200, curr loss: 1.3340295553207397, avg loss: 1.320734341740608\n",
      "trial: 4, iter: 15400, curr loss: 1.3073378801345825, avg loss: 1.3197792875766754\n",
      "trial: 4, iter: 15600, curr loss: 1.3257509469985962, avg loss: 1.3188335907459259\n",
      "trial: 4, ldr: 0.29766368865966797\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3868951797485352, avg loss: 1.3873817497491836\n",
      "trial: 5, iter: 400, curr loss: 1.3876782655715942, avg loss: 1.3868391054868698\n",
      "trial: 5, iter: 600, curr loss: 1.3868026733398438, avg loss: 1.3867495167255401\n",
      "trial: 5, iter: 800, curr loss: 1.388489007949829, avg loss: 1.3866140395402908\n",
      "trial: 5, iter: 1000, curr loss: 1.3860207796096802, avg loss: 1.386577695608139\n",
      "trial: 5, iter: 1200, curr loss: 1.3856971263885498, avg loss: 1.3864761739969254\n",
      "trial: 5, iter: 1400, curr loss: 1.3866455554962158, avg loss: 1.3864404606819152\n",
      "trial: 5, iter: 1600, curr loss: 1.384775996208191, avg loss: 1.3862963753938675\n",
      "trial: 5, iter: 1800, curr loss: 1.3865927457809448, avg loss: 1.386394225358963\n",
      "trial: 5, iter: 2000, curr loss: 1.3876672983169556, avg loss: 1.3863897573947908\n",
      "trial: 5, iter: 2200, curr loss: 1.3852958679199219, avg loss: 1.3863715195655824\n",
      "trial: 5, iter: 2400, curr loss: 1.386400580406189, avg loss: 1.3864030027389527\n",
      "trial: 5, iter: 2600, curr loss: 1.3851327896118164, avg loss: 1.386335454583168\n",
      "trial: 5, iter: 2800, curr loss: 1.38664710521698, avg loss: 1.3864027112722397\n",
      "trial: 5, iter: 3000, curr loss: 1.3870028257369995, avg loss: 1.3863446855545043\n",
      "trial: 5, iter: 3200, curr loss: 1.387126088142395, avg loss: 1.3863128119707107\n",
      "trial: 5, iter: 3400, curr loss: 1.3857866525650024, avg loss: 1.3863182097673417\n",
      "trial: 5, iter: 3600, curr loss: 1.3861476182937622, avg loss: 1.3863097655773162\n",
      "trial: 5, iter: 3800, curr loss: 1.3856050968170166, avg loss: 1.3863589209318161\n",
      "trial: 5, iter: 4000, curr loss: 1.3859153985977173, avg loss: 1.3863367468118668\n",
      "trial: 5, iter: 4200, curr loss: 1.386438012123108, avg loss: 1.3863051784038545\n",
      "trial: 5, iter: 4400, curr loss: 1.3867595195770264, avg loss: 1.3862859296798706\n",
      "trial: 5, iter: 4600, curr loss: 1.3866897821426392, avg loss: 1.3862837445735932\n",
      "trial: 5, iter: 4800, curr loss: 1.3868399858474731, avg loss: 1.3863462096452712\n",
      "trial: 5, iter: 5000, curr loss: 1.3867771625518799, avg loss: 1.386242623925209\n",
      "trial: 5, iter: 5200, curr loss: 1.3857043981552124, avg loss: 1.3862394684553145\n",
      "trial: 5, iter: 5400, curr loss: 1.3831790685653687, avg loss: 1.3853266537189484\n",
      "trial: 5, iter: 5600, curr loss: 1.3750813007354736, avg loss: 1.3816056829690933\n",
      "trial: 5, iter: 5800, curr loss: 1.3672733306884766, avg loss: 1.37525082051754\n",
      "trial: 5, iter: 6000, curr loss: 1.3666361570358276, avg loss: 1.3705759465694427\n",
      "trial: 5, iter: 6200, curr loss: 1.3719120025634766, avg loss: 1.365193503499031\n",
      "trial: 5, iter: 6400, curr loss: 1.3484549522399902, avg loss: 1.36144985973835\n",
      "trial: 5, iter: 6600, curr loss: 1.3377605676651, avg loss: 1.3565113133192062\n",
      "trial: 5, iter: 6800, curr loss: 1.345258355140686, avg loss: 1.3576595157384872\n",
      "trial: 5, iter: 7000, curr loss: 1.3407697677612305, avg loss: 1.355334929227829\n",
      "trial: 5, iter: 7200, curr loss: 1.338271141052246, avg loss: 1.352232169508934\n",
      "trial: 5, iter: 7400, curr loss: 1.3484184741973877, avg loss: 1.3495091277360916\n",
      "trial: 5, iter: 7600, curr loss: 1.3670159578323364, avg loss: 1.3471040707826614\n",
      "trial: 5, iter: 7800, curr loss: 1.3374135494232178, avg loss: 1.3404741603136063\n",
      "trial: 5, iter: 8000, curr loss: 1.3106224536895752, avg loss: 1.3360376292467118\n",
      "trial: 5, iter: 8200, curr loss: 1.3214985132217407, avg loss: 1.3317789548635484\n",
      "trial: 5, iter: 8400, curr loss: 1.3157753944396973, avg loss: 1.3291023272275924\n",
      "trial: 5, iter: 8600, curr loss: 1.3308430910110474, avg loss: 1.3265794599056244\n",
      "trial: 5, iter: 8800, curr loss: 1.3449985980987549, avg loss: 1.3252377635240555\n",
      "trial: 5, iter: 9000, curr loss: 1.3130956888198853, avg loss: 1.3243238562345505\n",
      "trial: 5, iter: 9200, curr loss: 1.3462159633636475, avg loss: 1.323685411810875\n",
      "trial: 5, iter: 9400, curr loss: 1.3184725046157837, avg loss: 1.3223222923278808\n",
      "trial: 5, iter: 9600, curr loss: 1.318668246269226, avg loss: 1.3227738976478576\n",
      "trial: 5, iter: 9800, curr loss: 1.3348151445388794, avg loss: 1.3221447032690048\n",
      "trial: 5, iter: 10000, curr loss: 1.3107647895812988, avg loss: 1.3202154958248138\n",
      "trial: 5, iter: 10200, curr loss: 1.3304060697555542, avg loss: 1.32083809196949\n",
      "trial: 5, iter: 10400, curr loss: 1.317037582397461, avg loss: 1.320601863861084\n",
      "trial: 5, iter: 10600, curr loss: 1.326500415802002, avg loss: 1.321617459654808\n",
      "trial: 5, iter: 10800, curr loss: 1.320543646812439, avg loss: 1.318189593553543\n",
      "trial: 5, iter: 11000, curr loss: 1.3393869400024414, avg loss: 1.3185628193616867\n",
      "trial: 5, iter: 11200, curr loss: 1.3471074104309082, avg loss: 1.319790123105049\n",
      "trial: 5, iter: 11400, curr loss: 1.3055962324142456, avg loss: 1.3183422034978867\n",
      "trial: 5, iter: 11600, curr loss: 1.3126220703125, avg loss: 1.3169631052017212\n",
      "trial: 5, iter: 11800, curr loss: 1.3437044620513916, avg loss: 1.3203332710266114\n",
      "trial: 5, iter: 12000, curr loss: 1.33297598361969, avg loss: 1.3179573392868043\n",
      "trial: 5, iter: 12200, curr loss: 1.3239288330078125, avg loss: 1.316109654903412\n",
      "trial: 5, iter: 12400, curr loss: 1.3410061597824097, avg loss: 1.319414540529251\n",
      "trial: 5, iter: 12600, curr loss: 1.3244245052337646, avg loss: 1.3164018839597702\n",
      "trial: 5, iter: 12800, curr loss: 1.3090972900390625, avg loss: 1.31895839035511\n",
      "trial: 5, iter: 13000, curr loss: 1.295678734779358, avg loss: 1.316603455543518\n",
      "trial: 5, iter: 13200, curr loss: 1.328019618988037, avg loss: 1.3164325481653214\n",
      "trial: 5, iter: 13400, curr loss: 1.3118765354156494, avg loss: 1.3181290644407273\n",
      "trial: 5, iter: 13600, curr loss: 1.332033634185791, avg loss: 1.3191875994205475\n",
      "trial: 5, iter: 13800, curr loss: 1.275060772895813, avg loss: 1.3158517754077912\n",
      "trial: 5, iter: 14000, curr loss: 1.3340519666671753, avg loss: 1.3165461450815201\n",
      "trial: 5, iter: 14200, curr loss: 1.3371738195419312, avg loss: 1.313717582821846\n",
      "trial: 5, iter: 14400, curr loss: 1.32682204246521, avg loss: 1.3159561276435852\n",
      "trial: 5, iter: 14600, curr loss: 1.3088995218276978, avg loss: 1.3173168724775315\n",
      "trial: 5, iter: 14800, curr loss: 1.3000918626785278, avg loss: 1.3178216391801834\n",
      "trial: 5, iter: 15000, curr loss: 1.3186588287353516, avg loss: 1.3158698165416718\n",
      "trial: 5, iter: 15200, curr loss: 1.311439871788025, avg loss: 1.3159069114923476\n",
      "trial: 5, iter: 15400, curr loss: 1.317793369293213, avg loss: 1.318074839115143\n",
      "trial: 5, iter: 15600, curr loss: 1.3065928220748901, avg loss: 1.315376000404358\n",
      "trial: 5, ldr: 0.346694678068161\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.3487090766429901\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.387912392616272, avg loss: 1.38735434114933\n",
      "trial: 1, iter: 400, curr loss: 1.3882862329483032, avg loss: 1.38674984395504\n",
      "trial: 1, iter: 600, curr loss: 1.386602759361267, avg loss: 1.3864719080924988\n",
      "trial: 1, iter: 800, curr loss: 1.3863110542297363, avg loss: 1.386527680158615\n",
      "trial: 1, iter: 1000, curr loss: 1.3872754573822021, avg loss: 1.3863567519187927\n",
      "trial: 1, iter: 1200, curr loss: 1.387040138244629, avg loss: 1.3864355993270874\n",
      "trial: 1, iter: 1400, curr loss: 1.3866503238677979, avg loss: 1.3864493060112\n",
      "trial: 1, iter: 1600, curr loss: 1.3864250183105469, avg loss: 1.3863620710372926\n",
      "trial: 1, iter: 1800, curr loss: 1.3863542079925537, avg loss: 1.3864237368106842\n",
      "trial: 1, iter: 2000, curr loss: 1.3864580392837524, avg loss: 1.3863856154680252\n",
      "trial: 1, iter: 2200, curr loss: 1.3875203132629395, avg loss: 1.3863201552629472\n",
      "trial: 1, iter: 2400, curr loss: 1.3868488073349, avg loss: 1.3864311641454696\n",
      "trial: 1, iter: 2600, curr loss: 1.385741114616394, avg loss: 1.3863475024700165\n",
      "trial: 1, iter: 2800, curr loss: 1.3861876726150513, avg loss: 1.386336635351181\n",
      "trial: 1, iter: 3000, curr loss: 1.3876469135284424, avg loss: 1.3863427746295929\n",
      "trial: 1, iter: 3200, curr loss: 1.3857734203338623, avg loss: 1.3863344997167588\n",
      "trial: 1, iter: 3400, curr loss: 1.3860164880752563, avg loss: 1.3863544619083406\n",
      "trial: 1, iter: 3600, curr loss: 1.3863857984542847, avg loss: 1.3863162523508072\n",
      "trial: 1, iter: 3800, curr loss: 1.3857579231262207, avg loss: 1.3862923312187194\n",
      "trial: 1, iter: 4000, curr loss: 1.3863469362258911, avg loss: 1.386354929804802\n",
      "trial: 1, iter: 4200, curr loss: 1.3862361907958984, avg loss: 1.3863528829813003\n",
      "trial: 1, iter: 4400, curr loss: 1.3864610195159912, avg loss: 1.386323053240776\n",
      "trial: 1, iter: 4600, curr loss: 1.386063814163208, avg loss: 1.3863096392154695\n",
      "trial: 1, iter: 4800, curr loss: 1.386438250541687, avg loss: 1.3863033604621888\n",
      "trial: 1, iter: 5000, curr loss: 1.3865429162979126, avg loss: 1.3863155633211135\n",
      "trial: 1, iter: 5200, curr loss: 1.3864697217941284, avg loss: 1.386302129626274\n",
      "trial: 1, iter: 5400, curr loss: 1.3869190216064453, avg loss: 1.3862995499372481\n",
      "trial: 1, iter: 5600, curr loss: 1.385881781578064, avg loss: 1.386283559203148\n",
      "trial: 1, iter: 5800, curr loss: 1.3864023685455322, avg loss: 1.386255581974983\n",
      "trial: 1, iter: 6000, curr loss: 1.3865087032318115, avg loss: 1.3863272148370742\n",
      "trial: 1, iter: 6200, curr loss: 1.3857959508895874, avg loss: 1.3863277906179428\n",
      "trial: 1, iter: 6400, curr loss: 1.3861457109451294, avg loss: 1.3863122928142548\n",
      "trial: 1, iter: 6600, curr loss: 1.3858602046966553, avg loss: 1.3863230472803116\n",
      "trial: 1, iter: 6800, curr loss: 1.3861935138702393, avg loss: 1.3863036620616913\n",
      "trial: 1, iter: 7000, curr loss: 1.3863760232925415, avg loss: 1.3863191664218903\n",
      "trial: 1, iter: 7200, curr loss: 1.3868006467819214, avg loss: 1.3862939226627349\n",
      "trial: 1, iter: 7400, curr loss: 1.3863649368286133, avg loss: 1.3862841176986693\n",
      "trial: 1, iter: 7600, curr loss: 1.3868401050567627, avg loss: 1.386285154223442\n",
      "trial: 1, iter: 7800, curr loss: 1.3860284090042114, avg loss: 1.3863574051856995\n",
      "trial: 1, iter: 8000, curr loss: 1.3861582279205322, avg loss: 1.3863147151470185\n",
      "trial: 1, iter: 8200, curr loss: 1.3862541913986206, avg loss: 1.3863238900899888\n",
      "trial: 1, iter: 8400, curr loss: 1.3862462043762207, avg loss: 1.3863292092084885\n",
      "trial: 1, iter: 8600, curr loss: 1.3855448961257935, avg loss: 1.386364859342575\n",
      "trial: 1, iter: 8800, curr loss: 1.385813593864441, avg loss: 1.3863560777902604\n",
      "trial: 1, iter: 9000, curr loss: 1.3861358165740967, avg loss: 1.3863399028778076\n",
      "trial: 1, iter: 9200, curr loss: 1.3855119943618774, avg loss: 1.3863242983818054\n",
      "trial: 1, iter: 9400, curr loss: 1.387066125869751, avg loss: 1.3864181226491927\n",
      "trial: 1, iter: 9600, curr loss: 1.3855527639389038, avg loss: 1.3863238501548767\n",
      "trial: 1, iter: 9800, curr loss: 1.3862520456314087, avg loss: 1.3863366454839707\n",
      "trial: 1, iter: 10000, curr loss: 1.3860646486282349, avg loss: 1.3863111007213593\n",
      "trial: 1, iter: 10200, curr loss: 1.3869298696517944, avg loss: 1.386341705918312\n",
      "trial: 1, iter: 10400, curr loss: 1.3863792419433594, avg loss: 1.3863293945789337\n",
      "trial: 1, iter: 10600, curr loss: 1.3860141038894653, avg loss: 1.386293005347252\n",
      "trial: 1, iter: 10800, curr loss: 1.3865416049957275, avg loss: 1.3863373237848282\n",
      "trial: 1, iter: 11000, curr loss: 1.3865183591842651, avg loss: 1.386327290534973\n",
      "trial: 1, iter: 11200, curr loss: 1.3863005638122559, avg loss: 1.3863275736570357\n",
      "trial: 1, iter: 11400, curr loss: 1.3864070177078247, avg loss: 1.3862632393836976\n",
      "trial: 1, iter: 11600, curr loss: 1.3865453004837036, avg loss: 1.3863041758537293\n",
      "trial: 1, iter: 11800, curr loss: 1.3866193294525146, avg loss: 1.3863391089439392\n",
      "trial: 1, iter: 12000, curr loss: 1.3863348960876465, avg loss: 1.3862984764575959\n",
      "trial: 1, iter: 12200, curr loss: 1.3862121105194092, avg loss: 1.38627648293972\n",
      "trial: 1, iter: 12400, curr loss: 1.3862618207931519, avg loss: 1.3863126826286316\n",
      "trial: 1, iter: 12600, curr loss: 1.386258840560913, avg loss: 1.3863192653656007\n",
      "trial: 1, iter: 12800, curr loss: 1.3862926959991455, avg loss: 1.386298041343689\n",
      "trial: 1, iter: 13000, curr loss: 1.3864792585372925, avg loss: 1.3862452220916748\n",
      "trial: 1, iter: 13200, curr loss: 1.387258768081665, avg loss: 1.3863250106573104\n",
      "trial: 1, iter: 13400, curr loss: 1.3857406377792358, avg loss: 1.3862709134817124\n",
      "trial: 1, iter: 13600, curr loss: 1.3866021633148193, avg loss: 1.3862972617149354\n",
      "trial: 1, iter: 13800, curr loss: 1.3863904476165771, avg loss: 1.3862775576114654\n",
      "trial: 1, iter: 14000, curr loss: 1.386020302772522, avg loss: 1.3863175827264786\n",
      "trial: 1, iter: 14200, curr loss: 1.3853263854980469, avg loss: 1.3862833350896835\n",
      "trial: 1, iter: 14400, curr loss: 1.3861429691314697, avg loss: 1.3862978893518447\n",
      "trial: 1, iter: 14600, curr loss: 1.3858016729354858, avg loss: 1.386284466981888\n",
      "trial: 1, iter: 14800, curr loss: 1.3866071701049805, avg loss: 1.3863550674915315\n",
      "trial: 1, iter: 15000, curr loss: 1.3869441747665405, avg loss: 1.3862596553564073\n",
      "trial: 1, iter: 15200, curr loss: 1.3860909938812256, avg loss: 1.3863517987728118\n",
      "trial: 1, iter: 15400, curr loss: 1.3861639499664307, avg loss: 1.3862729525566102\n",
      "trial: 1, iter: 15600, curr loss: 1.3861111402511597, avg loss: 1.38630169570446\n",
      "trial: 1, ldr: 0.0007897376781329513\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3836458921432495, avg loss: 1.3874458211660385\n",
      "trial: 2, iter: 400, curr loss: 1.3873028755187988, avg loss: 1.3865545850992202\n",
      "trial: 2, iter: 600, curr loss: 1.386004090309143, avg loss: 1.3866742610931397\n",
      "trial: 2, iter: 800, curr loss: 1.3876073360443115, avg loss: 1.3864606910943984\n",
      "trial: 2, iter: 1000, curr loss: 1.3865817785263062, avg loss: 1.3864597022533416\n",
      "trial: 2, iter: 1200, curr loss: 1.384385585784912, avg loss: 1.3863925594091415\n",
      "trial: 2, iter: 1400, curr loss: 1.3864893913269043, avg loss: 1.3863442629575728\n",
      "trial: 2, iter: 1600, curr loss: 1.3863047361373901, avg loss: 1.3862569111585616\n",
      "trial: 2, iter: 1800, curr loss: 1.3872919082641602, avg loss: 1.3863684302568435\n",
      "trial: 2, iter: 2000, curr loss: 1.3873239755630493, avg loss: 1.3863148510456085\n",
      "trial: 2, iter: 2200, curr loss: 1.3865582942962646, avg loss: 1.3863388031721116\n",
      "trial: 2, iter: 2400, curr loss: 1.3858238458633423, avg loss: 1.3863345605134965\n",
      "trial: 2, iter: 2600, curr loss: 1.3871759176254272, avg loss: 1.3863416403532027\n",
      "trial: 2, iter: 2800, curr loss: 1.3870798349380493, avg loss: 1.3863204729557037\n",
      "trial: 2, iter: 3000, curr loss: 1.3869744539260864, avg loss: 1.3863561868667602\n",
      "trial: 2, iter: 3200, curr loss: 1.3864301443099976, avg loss: 1.3863568818569183\n",
      "trial: 2, iter: 3400, curr loss: 1.3858088254928589, avg loss: 1.3862984693050384\n",
      "trial: 2, iter: 3600, curr loss: 1.386294960975647, avg loss: 1.386304184794426\n",
      "trial: 2, iter: 3800, curr loss: 1.3862382173538208, avg loss: 1.386294577717781\n",
      "trial: 2, iter: 4000, curr loss: 1.3864822387695312, avg loss: 1.3863122832775117\n",
      "trial: 2, iter: 4200, curr loss: 1.3861219882965088, avg loss: 1.386305304169655\n",
      "trial: 2, iter: 4400, curr loss: 1.3868004083633423, avg loss: 1.3863754272460938\n",
      "trial: 2, iter: 4600, curr loss: 1.3864684104919434, avg loss: 1.3863421845436097\n",
      "trial: 2, iter: 4800, curr loss: 1.3864647150039673, avg loss: 1.3863464349508285\n",
      "trial: 2, iter: 5000, curr loss: 1.3863919973373413, avg loss: 1.386339790225029\n",
      "trial: 2, iter: 5200, curr loss: 1.3862950801849365, avg loss: 1.3862823665142059\n",
      "trial: 2, iter: 5400, curr loss: 1.3863333463668823, avg loss: 1.386356424689293\n",
      "trial: 2, iter: 5600, curr loss: 1.386305570602417, avg loss: 1.3862901443243028\n",
      "trial: 2, iter: 5800, curr loss: 1.3865246772766113, avg loss: 1.3863100093603133\n",
      "trial: 2, iter: 6000, curr loss: 1.3860089778900146, avg loss: 1.3862981867790223\n",
      "trial: 2, iter: 6200, curr loss: 1.3862411975860596, avg loss: 1.3863080167770385\n",
      "trial: 2, iter: 6400, curr loss: 1.386254906654358, avg loss: 1.386301918029785\n",
      "trial: 2, iter: 6600, curr loss: 1.3865644931793213, avg loss: 1.3863117092847823\n",
      "trial: 2, iter: 6800, curr loss: 1.3862971067428589, avg loss: 1.3863173776865005\n",
      "trial: 2, iter: 7000, curr loss: 1.3865896463394165, avg loss: 1.3863321030139923\n",
      "trial: 2, iter: 7200, curr loss: 1.3863520622253418, avg loss: 1.3863253843784333\n",
      "trial: 2, iter: 7400, curr loss: 1.3863164186477661, avg loss: 1.386312627196312\n",
      "trial: 2, iter: 7600, curr loss: 1.3862371444702148, avg loss: 1.3863008600473403\n",
      "trial: 2, iter: 7800, curr loss: 1.3865184783935547, avg loss: 1.386303591132164\n",
      "trial: 2, iter: 8000, curr loss: 1.3867251873016357, avg loss: 1.3863077253103255\n",
      "trial: 2, iter: 8200, curr loss: 1.3870567083358765, avg loss: 1.3863266980648041\n",
      "trial: 2, iter: 8400, curr loss: 1.3862251043319702, avg loss: 1.3863441908359528\n",
      "trial: 2, iter: 8600, curr loss: 1.3866366147994995, avg loss: 1.3862828367948532\n",
      "trial: 2, iter: 8800, curr loss: 1.3866089582443237, avg loss: 1.3863192808628082\n",
      "trial: 2, iter: 9000, curr loss: 1.3868260383605957, avg loss: 1.3862994521856309\n",
      "trial: 2, iter: 9200, curr loss: 1.3874682188034058, avg loss: 1.3863046580553056\n",
      "trial: 2, iter: 9400, curr loss: 1.386629581451416, avg loss: 1.3862390202283859\n",
      "trial: 2, iter: 9600, curr loss: 1.3833366632461548, avg loss: 1.3851845806837082\n",
      "trial: 2, iter: 9800, curr loss: 1.3801770210266113, avg loss: 1.3829850721359254\n",
      "trial: 2, iter: 10000, curr loss: 1.3529295921325684, avg loss: 1.373073542714119\n",
      "trial: 2, iter: 10200, curr loss: 1.3360008001327515, avg loss: 1.3655619484186172\n",
      "trial: 2, iter: 10400, curr loss: 1.356437087059021, avg loss: 1.36162937104702\n",
      "trial: 2, iter: 10600, curr loss: 1.3511381149291992, avg loss: 1.3602968227863312\n",
      "trial: 2, iter: 10800, curr loss: 1.383628010749817, avg loss: 1.3588918852806091\n",
      "trial: 2, iter: 11000, curr loss: 1.3469034433364868, avg loss: 1.3558231085538863\n",
      "trial: 2, iter: 11200, curr loss: 1.3343708515167236, avg loss: 1.354559005498886\n",
      "trial: 2, iter: 11400, curr loss: 1.3453426361083984, avg loss: 1.3511747908592224\n",
      "trial: 2, iter: 11600, curr loss: 1.372144103050232, avg loss: 1.3473511016368866\n",
      "trial: 2, iter: 11800, curr loss: 1.3549665212631226, avg loss: 1.3409722316265107\n",
      "trial: 2, iter: 12000, curr loss: 1.325624704360962, avg loss: 1.338581628203392\n",
      "trial: 2, iter: 12200, curr loss: 1.326953649520874, avg loss: 1.3356834161281586\n",
      "trial: 2, iter: 12400, curr loss: 1.2958828210830688, avg loss: 1.3304227793216705\n",
      "trial: 2, iter: 12600, curr loss: 1.3322480916976929, avg loss: 1.3322906267642975\n",
      "trial: 2, iter: 12800, curr loss: 1.3753412961959839, avg loss: 1.3284686440229416\n",
      "trial: 2, iter: 13000, curr loss: 1.3274832963943481, avg loss: 1.3255084896087646\n",
      "trial: 2, iter: 13200, curr loss: 1.3373709917068481, avg loss: 1.3264988434314728\n",
      "trial: 2, iter: 13400, curr loss: 1.3427871465682983, avg loss: 1.3256371277570724\n",
      "trial: 2, iter: 13600, curr loss: 1.3086687326431274, avg loss: 1.325596448779106\n",
      "trial: 2, iter: 13800, curr loss: 1.311737298965454, avg loss: 1.3236479771137237\n",
      "trial: 2, iter: 14000, curr loss: 1.315368890762329, avg loss: 1.3243726843595505\n",
      "trial: 2, iter: 14200, curr loss: 1.3058955669403076, avg loss: 1.3244137632846833\n",
      "trial: 2, iter: 14400, curr loss: 1.3181554079055786, avg loss: 1.321116423010826\n",
      "trial: 2, iter: 14600, curr loss: 1.3167545795440674, avg loss: 1.3198770368099213\n",
      "trial: 2, iter: 14800, curr loss: 1.3102807998657227, avg loss: 1.3197257590293885\n",
      "trial: 2, iter: 15000, curr loss: 1.277609944343567, avg loss: 1.3193249928951263\n",
      "trial: 2, iter: 15200, curr loss: 1.3155704736709595, avg loss: 1.3235210013389587\n",
      "trial: 2, iter: 15400, curr loss: 1.3060956001281738, avg loss: 1.3182673287391662\n",
      "trial: 2, iter: 15600, curr loss: 1.303983449935913, avg loss: 1.3210283309221267\n",
      "trial: 2, ldr: 0.3101857304573059\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389091968536377, avg loss: 1.3873121756315232\n",
      "trial: 3, iter: 400, curr loss: 1.3875443935394287, avg loss: 1.386541958451271\n",
      "trial: 3, iter: 600, curr loss: 1.385626196861267, avg loss: 1.386745018362999\n",
      "trial: 3, iter: 800, curr loss: 1.3851929903030396, avg loss: 1.3865961807966232\n",
      "trial: 3, iter: 1000, curr loss: 1.3863580226898193, avg loss: 1.3864979022741317\n",
      "trial: 3, iter: 1200, curr loss: 1.3847357034683228, avg loss: 1.3864700877666474\n",
      "trial: 3, iter: 1400, curr loss: 1.38663649559021, avg loss: 1.3863707947731019\n",
      "trial: 3, iter: 1600, curr loss: 1.386704921722412, avg loss: 1.386378012895584\n",
      "trial: 3, iter: 1800, curr loss: 1.3856295347213745, avg loss: 1.386355354785919\n",
      "trial: 3, iter: 2000, curr loss: 1.3864904642105103, avg loss: 1.3863348776102067\n",
      "trial: 3, iter: 2200, curr loss: 1.3871392011642456, avg loss: 1.3863827288150787\n",
      "trial: 3, iter: 2400, curr loss: 1.3852778673171997, avg loss: 1.386378092765808\n",
      "trial: 3, iter: 2600, curr loss: 1.385589361190796, avg loss: 1.3863291466236114\n",
      "trial: 3, iter: 2800, curr loss: 1.3858563899993896, avg loss: 1.386353770494461\n",
      "trial: 3, iter: 3000, curr loss: 1.3870140314102173, avg loss: 1.3863559383153916\n",
      "trial: 3, iter: 3200, curr loss: 1.386259913444519, avg loss: 1.3863317596912383\n",
      "trial: 3, iter: 3400, curr loss: 1.3858580589294434, avg loss: 1.3863443410396576\n",
      "trial: 3, iter: 3600, curr loss: 1.3865886926651, avg loss: 1.3863896292448044\n",
      "trial: 3, iter: 3800, curr loss: 1.3870573043823242, avg loss: 1.3863607746362687\n",
      "trial: 3, iter: 4000, curr loss: 1.386326789855957, avg loss: 1.3863065350055694\n",
      "trial: 3, iter: 4200, curr loss: 1.3860951662063599, avg loss: 1.3862997859716415\n",
      "trial: 3, iter: 4400, curr loss: 1.3860681056976318, avg loss: 1.3862726342678071\n",
      "trial: 3, iter: 4600, curr loss: 1.3861150741577148, avg loss: 1.386337235569954\n",
      "trial: 3, iter: 4800, curr loss: 1.3866543769836426, avg loss: 1.386304098367691\n",
      "trial: 3, iter: 5000, curr loss: 1.3865209817886353, avg loss: 1.3864099401235581\n",
      "trial: 3, iter: 5200, curr loss: 1.3863788843154907, avg loss: 1.386343364715576\n",
      "trial: 3, iter: 5400, curr loss: 1.3851702213287354, avg loss: 1.3862644165754319\n",
      "trial: 3, iter: 5600, curr loss: 1.386446475982666, avg loss: 1.3863307237625122\n",
      "trial: 3, iter: 5800, curr loss: 1.386515498161316, avg loss: 1.3863112074136734\n",
      "trial: 3, iter: 6000, curr loss: 1.3859190940856934, avg loss: 1.386277631521225\n",
      "trial: 3, iter: 6200, curr loss: 1.386020302772522, avg loss: 1.3863041561841964\n",
      "trial: 3, iter: 6400, curr loss: 1.3853625059127808, avg loss: 1.3863131272792817\n",
      "trial: 3, iter: 6600, curr loss: 1.3871203660964966, avg loss: 1.3864035576581955\n",
      "trial: 3, iter: 6800, curr loss: 1.3884121179580688, avg loss: 1.3862796443700791\n",
      "trial: 3, iter: 7000, curr loss: 1.3850809335708618, avg loss: 1.3863032364845276\n",
      "trial: 3, iter: 7200, curr loss: 1.3873839378356934, avg loss: 1.3863712126016616\n",
      "trial: 3, iter: 7400, curr loss: 1.3867148160934448, avg loss: 1.3863062179088592\n",
      "trial: 3, iter: 7600, curr loss: 1.3875166177749634, avg loss: 1.3862655436992646\n",
      "trial: 3, iter: 7800, curr loss: 1.3860194683074951, avg loss: 1.3863625532388688\n",
      "trial: 3, iter: 8000, curr loss: 1.3870266675949097, avg loss: 1.3862772911787034\n",
      "trial: 3, iter: 8200, curr loss: 1.3864322900772095, avg loss: 1.386288531422615\n",
      "trial: 3, iter: 8400, curr loss: 1.3854440450668335, avg loss: 1.386238831281662\n",
      "trial: 3, iter: 8600, curr loss: 1.386902093887329, avg loss: 1.3862059020996094\n",
      "trial: 3, iter: 8800, curr loss: 1.3880077600479126, avg loss: 1.386195214986801\n",
      "trial: 3, iter: 9000, curr loss: 1.3844558000564575, avg loss: 1.3857168006896972\n",
      "trial: 3, iter: 9200, curr loss: 1.3764804601669312, avg loss: 1.383579916357994\n",
      "trial: 3, iter: 9400, curr loss: 1.3849250078201294, avg loss: 1.3786396992206573\n",
      "trial: 3, iter: 9600, curr loss: 1.363783836364746, avg loss: 1.3768623632192611\n",
      "trial: 3, iter: 9800, curr loss: 1.3719956874847412, avg loss: 1.3747834247350692\n",
      "trial: 3, iter: 10000, curr loss: 1.3713066577911377, avg loss: 1.3718457788228988\n",
      "trial: 3, iter: 10200, curr loss: 1.378793716430664, avg loss: 1.366802099943161\n",
      "trial: 3, iter: 10400, curr loss: 1.3646992444992065, avg loss: 1.3610196119546891\n",
      "trial: 3, iter: 10600, curr loss: 1.338738203048706, avg loss: 1.3535001218318938\n",
      "trial: 3, iter: 10800, curr loss: 1.324401617050171, avg loss: 1.346857444047928\n",
      "trial: 3, iter: 11000, curr loss: 1.3283450603485107, avg loss: 1.342347429394722\n",
      "trial: 3, iter: 11200, curr loss: 1.309493899345398, avg loss: 1.3372111594676972\n",
      "trial: 3, iter: 11400, curr loss: 1.3337551355361938, avg loss: 1.3351916992664337\n",
      "trial: 3, iter: 11600, curr loss: 1.3402187824249268, avg loss: 1.332377474308014\n",
      "trial: 3, iter: 11800, curr loss: 1.3536442518234253, avg loss: 1.3288238227367402\n",
      "trial: 3, iter: 12000, curr loss: 1.302927851676941, avg loss: 1.3300113320350646\n",
      "trial: 3, iter: 12200, curr loss: 1.3219289779663086, avg loss: 1.324434522986412\n",
      "trial: 3, iter: 12400, curr loss: 1.3098418712615967, avg loss: 1.3237908327579497\n",
      "trial: 3, iter: 12600, curr loss: 1.3328880071640015, avg loss: 1.323314682841301\n",
      "trial: 3, iter: 12800, curr loss: 1.3006651401519775, avg loss: 1.3232496267557143\n",
      "trial: 3, iter: 13000, curr loss: 1.3149281740188599, avg loss: 1.3231129407882691\n",
      "trial: 3, iter: 13200, curr loss: 1.3093925714492798, avg loss: 1.32130977332592\n",
      "trial: 3, iter: 13400, curr loss: 1.3186761140823364, avg loss: 1.3195280987024307\n",
      "trial: 3, iter: 13600, curr loss: 1.3232753276824951, avg loss: 1.3197847771644593\n",
      "trial: 3, iter: 13800, curr loss: 1.3179517984390259, avg loss: 1.3196219438314438\n",
      "trial: 3, iter: 14000, curr loss: 1.329257845878601, avg loss: 1.3175658375024795\n",
      "trial: 3, iter: 14200, curr loss: 1.3346970081329346, avg loss: 1.3184934467077256\n",
      "trial: 3, iter: 14400, curr loss: 1.3035879135131836, avg loss: 1.3182111996412278\n",
      "trial: 3, iter: 14600, curr loss: 1.3004531860351562, avg loss: 1.3166004008054732\n",
      "trial: 3, iter: 14800, curr loss: 1.3402186632156372, avg loss: 1.3182887065410613\n",
      "trial: 3, iter: 15000, curr loss: 1.3446458578109741, avg loss: 1.3185914969444275\n",
      "trial: 3, iter: 15200, curr loss: 1.2987366914749146, avg loss: 1.3174757307767868\n",
      "trial: 3, iter: 15400, curr loss: 1.326655626296997, avg loss: 1.3150254893302917\n",
      "trial: 3, iter: 15600, curr loss: 1.2775506973266602, avg loss: 1.3181397676467896\n",
      "trial: 3, ldr: 0.27197614312171936\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388427495956421, avg loss: 1.3871014440059661\n",
      "trial: 4, iter: 400, curr loss: 1.387947916984558, avg loss: 1.3868952244520187\n",
      "trial: 4, iter: 600, curr loss: 1.3853720426559448, avg loss: 1.3866945314407348\n",
      "trial: 4, iter: 800, curr loss: 1.3878908157348633, avg loss: 1.386594336628914\n",
      "trial: 4, iter: 1000, curr loss: 1.384541630744934, avg loss: 1.3864469802379609\n",
      "trial: 4, iter: 1200, curr loss: 1.3863270282745361, avg loss: 1.3865715289115905\n",
      "trial: 4, iter: 1400, curr loss: 1.388075828552246, avg loss: 1.3863795655965805\n",
      "trial: 4, iter: 1600, curr loss: 1.3857243061065674, avg loss: 1.3863517451286316\n",
      "trial: 4, iter: 1800, curr loss: 1.3855992555618286, avg loss: 1.3863508093357086\n",
      "trial: 4, iter: 2000, curr loss: 1.3863897323608398, avg loss: 1.3864057713747024\n",
      "trial: 4, iter: 2200, curr loss: 1.386074185371399, avg loss: 1.3864117872714996\n",
      "trial: 4, iter: 2400, curr loss: 1.3872277736663818, avg loss: 1.3863544076681138\n",
      "trial: 4, iter: 2600, curr loss: 1.3845747709274292, avg loss: 1.3863449102640153\n",
      "trial: 4, iter: 2800, curr loss: 1.386340618133545, avg loss: 1.3863961565494538\n",
      "trial: 4, iter: 3000, curr loss: 1.3868728876113892, avg loss: 1.3863227951526642\n",
      "trial: 4, iter: 3200, curr loss: 1.3863824605941772, avg loss: 1.3863466382026672\n",
      "trial: 4, iter: 3400, curr loss: 1.385362148284912, avg loss: 1.3863786667585374\n",
      "trial: 4, iter: 3600, curr loss: 1.3854962587356567, avg loss: 1.38641128718853\n",
      "trial: 4, iter: 3800, curr loss: 1.3863115310668945, avg loss: 1.3863330417871476\n",
      "trial: 4, iter: 4000, curr loss: 1.3869094848632812, avg loss: 1.3863008642196655\n",
      "trial: 4, iter: 4200, curr loss: 1.386029601097107, avg loss: 1.386337424516678\n",
      "trial: 4, iter: 4400, curr loss: 1.3859940767288208, avg loss: 1.3863121557235718\n",
      "trial: 4, iter: 4600, curr loss: 1.3866803646087646, avg loss: 1.3863426971435546\n",
      "trial: 4, iter: 4800, curr loss: 1.3864408731460571, avg loss: 1.3863594913482666\n",
      "trial: 4, iter: 5000, curr loss: 1.3858669996261597, avg loss: 1.3862971657514571\n",
      "trial: 4, iter: 5200, curr loss: 1.386420726776123, avg loss: 1.386309553384781\n",
      "trial: 4, iter: 5400, curr loss: 1.3862831592559814, avg loss: 1.3863254016637803\n",
      "trial: 4, iter: 5600, curr loss: 1.3852777481079102, avg loss: 1.3862774735689163\n",
      "trial: 4, iter: 5800, curr loss: 1.38534677028656, avg loss: 1.3863040310144426\n",
      "trial: 4, iter: 6000, curr loss: 1.3861597776412964, avg loss: 1.3863019812107087\n",
      "trial: 4, iter: 6200, curr loss: 1.3866333961486816, avg loss: 1.3863032764196397\n",
      "trial: 4, iter: 6400, curr loss: 1.3878984451293945, avg loss: 1.3862612503767013\n",
      "trial: 4, iter: 6600, curr loss: 1.3872913122177124, avg loss: 1.3863401252031327\n",
      "trial: 4, iter: 6800, curr loss: 1.3862634897232056, avg loss: 1.386328472495079\n",
      "trial: 4, iter: 7000, curr loss: 1.3859831094741821, avg loss: 1.386259080171585\n",
      "trial: 4, iter: 7200, curr loss: 1.3864136934280396, avg loss: 1.3861832231283189\n",
      "trial: 4, iter: 7400, curr loss: 1.387263536453247, avg loss: 1.3855759394168854\n",
      "trial: 4, iter: 7600, curr loss: 1.3818426132202148, avg loss: 1.383823704123497\n",
      "trial: 4, iter: 7800, curr loss: 1.3839484453201294, avg loss: 1.3792073273658751\n",
      "trial: 4, iter: 8000, curr loss: 1.3695333003997803, avg loss: 1.375544701218605\n",
      "trial: 4, iter: 8200, curr loss: 1.3489807844161987, avg loss: 1.3699760222434998\n",
      "trial: 4, iter: 8400, curr loss: 1.3775510787963867, avg loss: 1.3661692535877228\n",
      "trial: 4, iter: 8600, curr loss: 1.3670761585235596, avg loss: 1.3629039365053177\n",
      "trial: 4, iter: 8800, curr loss: 1.3761039972305298, avg loss: 1.3592224413156508\n",
      "trial: 4, iter: 9000, curr loss: 1.3699238300323486, avg loss: 1.3582712668180466\n",
      "trial: 4, iter: 9200, curr loss: 1.374670386314392, avg loss: 1.3559125691652298\n",
      "trial: 4, iter: 9400, curr loss: 1.3460237979888916, avg loss: 1.3521924912929535\n",
      "trial: 4, iter: 9600, curr loss: 1.3308051824569702, avg loss: 1.3496949833631515\n",
      "trial: 4, iter: 9800, curr loss: 1.3379265069961548, avg loss: 1.3450640779733658\n",
      "trial: 4, iter: 10000, curr loss: 1.3309543132781982, avg loss: 1.3395931828022003\n",
      "trial: 4, iter: 10200, curr loss: 1.362147331237793, avg loss: 1.3377854043245316\n",
      "trial: 4, iter: 10400, curr loss: 1.3280385732650757, avg loss: 1.3349863582849502\n",
      "trial: 4, iter: 10600, curr loss: 1.3260126113891602, avg loss: 1.3334764218330384\n",
      "trial: 4, iter: 10800, curr loss: 1.3204772472381592, avg loss: 1.3316350662708283\n",
      "trial: 4, iter: 11000, curr loss: 1.3255590200424194, avg loss: 1.3286198145151138\n",
      "trial: 4, iter: 11200, curr loss: 1.330315113067627, avg loss: 1.3291222208738327\n",
      "trial: 4, iter: 11400, curr loss: 1.3069980144500732, avg loss: 1.3276680743694305\n",
      "trial: 4, iter: 11600, curr loss: 1.2981278896331787, avg loss: 1.325215595960617\n",
      "trial: 4, iter: 11800, curr loss: 1.3264168500900269, avg loss: 1.3246086078882218\n",
      "trial: 4, iter: 12000, curr loss: 1.3278435468673706, avg loss: 1.324401112794876\n",
      "trial: 4, iter: 12200, curr loss: 1.322296380996704, avg loss: 1.3274046021699906\n",
      "trial: 4, iter: 12400, curr loss: 1.312213659286499, avg loss: 1.3225916743278503\n",
      "trial: 4, iter: 12600, curr loss: 1.3196837902069092, avg loss: 1.3241762018203735\n",
      "trial: 4, iter: 12800, curr loss: 1.336039423942566, avg loss: 1.3224306225776672\n",
      "trial: 4, iter: 13000, curr loss: 1.30971360206604, avg loss: 1.3206435191631316\n",
      "trial: 4, iter: 13200, curr loss: 1.3147711753845215, avg loss: 1.3212141901254655\n",
      "trial: 4, iter: 13400, curr loss: 1.3265830278396606, avg loss: 1.3247819632291793\n",
      "trial: 4, iter: 13600, curr loss: 1.282831072807312, avg loss: 1.3214022791385651\n",
      "trial: 4, iter: 13800, curr loss: 1.316049575805664, avg loss: 1.3208606797456741\n",
      "trial: 4, iter: 14000, curr loss: 1.3484039306640625, avg loss: 1.3202728366851806\n",
      "trial: 4, iter: 14200, curr loss: 1.3226251602172852, avg loss: 1.320791695713997\n",
      "trial: 4, iter: 14400, curr loss: 1.3253364562988281, avg loss: 1.3212690138816834\n",
      "trial: 4, iter: 14600, curr loss: 1.3132920265197754, avg loss: 1.3186180329322814\n",
      "trial: 4, iter: 14800, curr loss: 1.3002814054489136, avg loss: 1.3215114611387253\n",
      "trial: 4, iter: 15000, curr loss: 1.2986894845962524, avg loss: 1.3218736636638642\n",
      "trial: 4, iter: 15200, curr loss: 1.3157157897949219, avg loss: 1.3190459942817687\n",
      "trial: 4, iter: 15400, curr loss: 1.3494237661361694, avg loss: 1.3181596934795379\n",
      "trial: 4, iter: 15600, curr loss: 1.3008723258972168, avg loss: 1.3202526956796645\n",
      "trial: 4, ldr: 0.2226858139038086\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3864439725875854, avg loss: 1.388657084107399\n",
      "trial: 5, iter: 400, curr loss: 1.3851395845413208, avg loss: 1.3868480408191681\n",
      "trial: 5, iter: 600, curr loss: 1.3869367837905884, avg loss: 1.386631234884262\n",
      "trial: 5, iter: 800, curr loss: 1.388047456741333, avg loss: 1.3866456258296966\n",
      "trial: 5, iter: 1000, curr loss: 1.3886137008666992, avg loss: 1.3865152806043626\n",
      "trial: 5, iter: 1200, curr loss: 1.386656403541565, avg loss: 1.386402273774147\n",
      "trial: 5, iter: 1400, curr loss: 1.3863087892532349, avg loss: 1.3864375203847885\n",
      "trial: 5, iter: 1600, curr loss: 1.386283278465271, avg loss: 1.3864130544662476\n",
      "trial: 5, iter: 1800, curr loss: 1.3857051134109497, avg loss: 1.3863951325416566\n",
      "trial: 5, iter: 2000, curr loss: 1.3861032724380493, avg loss: 1.3863398337364197\n",
      "trial: 5, iter: 2200, curr loss: 1.3867156505584717, avg loss: 1.3863742923736573\n",
      "trial: 5, iter: 2400, curr loss: 1.3866897821426392, avg loss: 1.386357616186142\n",
      "trial: 5, iter: 2600, curr loss: 1.3864662647247314, avg loss: 1.3863183718919754\n",
      "trial: 5, iter: 2800, curr loss: 1.3862519264221191, avg loss: 1.3863221889734267\n",
      "trial: 5, iter: 3000, curr loss: 1.3861497640609741, avg loss: 1.3863246607780457\n",
      "trial: 5, iter: 3200, curr loss: 1.3869874477386475, avg loss: 1.3863447427749633\n",
      "trial: 5, iter: 3400, curr loss: 1.3866424560546875, avg loss: 1.3862852972745896\n",
      "trial: 5, iter: 3600, curr loss: 1.3862507343292236, avg loss: 1.3863646233081817\n",
      "trial: 5, iter: 3800, curr loss: 1.3861888647079468, avg loss: 1.3863544017076492\n",
      "trial: 5, iter: 4000, curr loss: 1.3859405517578125, avg loss: 1.3863595521450043\n",
      "trial: 5, iter: 4200, curr loss: 1.3860894441604614, avg loss: 1.386317713856697\n",
      "trial: 5, iter: 4400, curr loss: 1.3871750831604004, avg loss: 1.3863822078704835\n",
      "trial: 5, iter: 4600, curr loss: 1.3860238790512085, avg loss: 1.386327029466629\n",
      "trial: 5, iter: 4800, curr loss: 1.3861294984817505, avg loss: 1.3863466107845306\n",
      "trial: 5, iter: 5000, curr loss: 1.386060357093811, avg loss: 1.3863144665956497\n",
      "trial: 5, iter: 5200, curr loss: 1.3867517709732056, avg loss: 1.3863000130653382\n",
      "trial: 5, iter: 5400, curr loss: 1.3865704536437988, avg loss: 1.3862821000814438\n",
      "trial: 5, iter: 5600, curr loss: 1.386406660079956, avg loss: 1.386373722553253\n",
      "trial: 5, iter: 5800, curr loss: 1.3870580196380615, avg loss: 1.3863891822099685\n",
      "trial: 5, iter: 6000, curr loss: 1.3861534595489502, avg loss: 1.386348340511322\n",
      "trial: 5, iter: 6200, curr loss: 1.3866888284683228, avg loss: 1.3863220942020416\n",
      "trial: 5, iter: 6400, curr loss: 1.3864907026290894, avg loss: 1.3863164705038071\n",
      "trial: 5, iter: 6600, curr loss: 1.3864405155181885, avg loss: 1.3863706147670747\n",
      "trial: 5, iter: 6800, curr loss: 1.3864778280258179, avg loss: 1.3863020074367522\n",
      "trial: 5, iter: 7000, curr loss: 1.3857861757278442, avg loss: 1.3862788683176042\n",
      "trial: 5, iter: 7200, curr loss: 1.3862941265106201, avg loss: 1.3863457804918289\n",
      "trial: 5, iter: 7400, curr loss: 1.3864147663116455, avg loss: 1.386336944103241\n",
      "trial: 5, iter: 7600, curr loss: 1.387121319770813, avg loss: 1.3862590008974076\n",
      "trial: 5, iter: 7800, curr loss: 1.386315941810608, avg loss: 1.3862976491451264\n",
      "trial: 5, iter: 8000, curr loss: 1.3866207599639893, avg loss: 1.3863531917333602\n",
      "trial: 5, iter: 8200, curr loss: 1.38713800907135, avg loss: 1.3863140726089478\n",
      "trial: 5, iter: 8400, curr loss: 1.3864468336105347, avg loss: 1.3863169193267821\n",
      "trial: 5, iter: 8600, curr loss: 1.3861241340637207, avg loss: 1.386325404047966\n",
      "trial: 5, iter: 8800, curr loss: 1.3864977359771729, avg loss: 1.3863042819499969\n",
      "trial: 5, iter: 9000, curr loss: 1.3872932195663452, avg loss: 1.386238329410553\n",
      "trial: 5, iter: 9200, curr loss: 1.3861198425292969, avg loss: 1.3863597851991654\n",
      "trial: 5, iter: 9400, curr loss: 1.386100172996521, avg loss: 1.3863226193189622\n",
      "trial: 5, iter: 9600, curr loss: 1.386364459991455, avg loss: 1.3863146209716797\n",
      "trial: 5, iter: 9800, curr loss: 1.3859889507293701, avg loss: 1.3862919855117797\n",
      "trial: 5, iter: 10000, curr loss: 1.3865143060684204, avg loss: 1.3862965375185012\n",
      "trial: 5, iter: 10200, curr loss: 1.3866088390350342, avg loss: 1.3863254493474961\n",
      "trial: 5, iter: 10400, curr loss: 1.3858273029327393, avg loss: 1.3863381415605545\n",
      "trial: 5, iter: 10600, curr loss: 1.3861018419265747, avg loss: 1.3863046085834503\n",
      "trial: 5, iter: 10800, curr loss: 1.386446237564087, avg loss: 1.3863232290744782\n",
      "trial: 5, iter: 11000, curr loss: 1.3862820863723755, avg loss: 1.3862974447011949\n",
      "trial: 5, iter: 11200, curr loss: 1.3862558603286743, avg loss: 1.386304561495781\n",
      "trial: 5, iter: 11400, curr loss: 1.3863394260406494, avg loss: 1.3862883394956589\n",
      "trial: 5, iter: 11600, curr loss: 1.386245608329773, avg loss: 1.3862918090820313\n",
      "trial: 5, iter: 11800, curr loss: 1.3858091831207275, avg loss: 1.3862841254472733\n",
      "trial: 5, iter: 12000, curr loss: 1.3863089084625244, avg loss: 1.3862977522611617\n",
      "trial: 5, iter: 12200, curr loss: 1.3862186670303345, avg loss: 1.3862855237722398\n",
      "trial: 5, iter: 12400, curr loss: 1.3862673044204712, avg loss: 1.3862499976158142\n",
      "trial: 5, iter: 12600, curr loss: 1.386252760887146, avg loss: 1.3863516110181808\n",
      "trial: 5, iter: 12800, curr loss: 1.3863674402236938, avg loss: 1.3862950098514557\n",
      "trial: 5, iter: 13000, curr loss: 1.3862539529800415, avg loss: 1.3862730836868287\n",
      "trial: 5, iter: 13200, curr loss: 1.3864750862121582, avg loss: 1.3862845700979234\n",
      "trial: 5, iter: 13400, curr loss: 1.3862731456756592, avg loss: 1.3863272136449813\n",
      "trial: 5, iter: 13600, curr loss: 1.3863067626953125, avg loss: 1.386296448111534\n",
      "trial: 5, iter: 13800, curr loss: 1.3866727352142334, avg loss: 1.3862789219617844\n",
      "trial: 5, iter: 14000, curr loss: 1.3865580558776855, avg loss: 1.386232566833496\n",
      "trial: 5, iter: 14200, curr loss: 1.3855464458465576, avg loss: 1.3863298499584198\n",
      "trial: 5, iter: 14400, curr loss: 1.3862706422805786, avg loss: 1.386288183927536\n",
      "trial: 5, iter: 14600, curr loss: 1.385855793952942, avg loss: 1.3862639367580414\n",
      "trial: 5, iter: 14800, curr loss: 1.3863917589187622, avg loss: 1.3863029634952546\n",
      "trial: 5, iter: 15000, curr loss: 1.3862959146499634, avg loss: 1.3862084180116654\n",
      "trial: 5, iter: 15200, curr loss: 1.3847543001174927, avg loss: 1.386268898844719\n",
      "trial: 5, iter: 15400, curr loss: 1.385969638824463, avg loss: 1.3862211656570436\n",
      "trial: 5, iter: 15600, curr loss: 1.3851479291915894, avg loss: 1.3862272483110427\n",
      "trial: 5, ldr: -0.0019033208955079317\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.16074682085309178\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3872421979904175, avg loss: 1.387546517252922\n",
      "trial: 1, iter: 400, curr loss: 1.3891797065734863, avg loss: 1.3866062402725219\n",
      "trial: 1, iter: 600, curr loss: 1.3879224061965942, avg loss: 1.3867418628931045\n",
      "trial: 1, iter: 800, curr loss: 1.3865214586257935, avg loss: 1.3866020739078522\n",
      "trial: 1, iter: 1000, curr loss: 1.3868036270141602, avg loss: 1.386513825058937\n",
      "trial: 1, iter: 1200, curr loss: 1.384981632232666, avg loss: 1.3863435178995132\n",
      "trial: 1, iter: 1400, curr loss: 1.3862788677215576, avg loss: 1.3863676524162292\n",
      "trial: 1, iter: 1600, curr loss: 1.3863974809646606, avg loss: 1.3864663922786713\n",
      "trial: 1, iter: 1800, curr loss: 1.386265754699707, avg loss: 1.3863686501979828\n",
      "trial: 1, iter: 2000, curr loss: 1.3849384784698486, avg loss: 1.3863232791423798\n",
      "trial: 1, iter: 2200, curr loss: 1.3863338232040405, avg loss: 1.3864532810449601\n",
      "trial: 1, iter: 2400, curr loss: 1.3862907886505127, avg loss: 1.3862958502769471\n",
      "trial: 1, iter: 2600, curr loss: 1.3862123489379883, avg loss: 1.3863836109638215\n",
      "trial: 1, iter: 2800, curr loss: 1.3865572214126587, avg loss: 1.3863468664884566\n",
      "trial: 1, iter: 3000, curr loss: 1.3870025873184204, avg loss: 1.3863407969474792\n",
      "trial: 1, iter: 3200, curr loss: 1.385601282119751, avg loss: 1.3863538193702698\n",
      "trial: 1, iter: 3400, curr loss: 1.3861359357833862, avg loss: 1.386357536315918\n",
      "trial: 1, iter: 3600, curr loss: 1.3862091302871704, avg loss: 1.3863566088676453\n",
      "trial: 1, iter: 3800, curr loss: 1.385977029800415, avg loss: 1.386356098651886\n",
      "trial: 1, iter: 4000, curr loss: 1.3859552145004272, avg loss: 1.3863828080892562\n",
      "trial: 1, iter: 4200, curr loss: 1.3864761590957642, avg loss: 1.3863525414466857\n",
      "trial: 1, iter: 4400, curr loss: 1.386352777481079, avg loss: 1.3863306415081025\n",
      "trial: 1, iter: 4600, curr loss: 1.3867781162261963, avg loss: 1.3863550066947936\n",
      "trial: 1, iter: 4800, curr loss: 1.3861932754516602, avg loss: 1.386353512406349\n",
      "trial: 1, iter: 5000, curr loss: 1.3868119716644287, avg loss: 1.3863214474916459\n",
      "trial: 1, iter: 5200, curr loss: 1.3857375383377075, avg loss: 1.3862865376472473\n",
      "trial: 1, iter: 5400, curr loss: 1.3862104415893555, avg loss: 1.386364415884018\n",
      "trial: 1, iter: 5600, curr loss: 1.3858799934387207, avg loss: 1.3863215458393097\n",
      "trial: 1, iter: 5800, curr loss: 1.3865091800689697, avg loss: 1.3863608342409135\n",
      "trial: 1, iter: 6000, curr loss: 1.3875095844268799, avg loss: 1.3863202333450317\n",
      "trial: 1, iter: 6200, curr loss: 1.3868725299835205, avg loss: 1.3863695228099824\n",
      "trial: 1, iter: 6400, curr loss: 1.386829137802124, avg loss: 1.3863128423690796\n",
      "trial: 1, iter: 6600, curr loss: 1.3874542713165283, avg loss: 1.3863631343841554\n",
      "trial: 1, iter: 6800, curr loss: 1.3851253986358643, avg loss: 1.3863129180669784\n",
      "trial: 1, iter: 7000, curr loss: 1.387155294418335, avg loss: 1.38630601644516\n",
      "trial: 1, iter: 7200, curr loss: 1.3852488994598389, avg loss: 1.3863975489139557\n",
      "trial: 1, iter: 7400, curr loss: 1.386510968208313, avg loss: 1.3863764888048171\n",
      "trial: 1, iter: 7600, curr loss: 1.3859621286392212, avg loss: 1.3863204073905946\n",
      "trial: 1, iter: 7800, curr loss: 1.3864316940307617, avg loss: 1.3862735223770142\n",
      "trial: 1, iter: 8000, curr loss: 1.3864691257476807, avg loss: 1.3863160067796707\n",
      "trial: 1, iter: 8200, curr loss: 1.3866887092590332, avg loss: 1.3864113426208495\n",
      "trial: 1, iter: 8400, curr loss: 1.3866209983825684, avg loss: 1.386289001107216\n",
      "trial: 1, iter: 8600, curr loss: 1.3857731819152832, avg loss: 1.3863146072626114\n",
      "trial: 1, iter: 8800, curr loss: 1.3866554498672485, avg loss: 1.3862233263254167\n",
      "trial: 1, iter: 9000, curr loss: 1.386203646659851, avg loss: 1.3862949192523957\n",
      "trial: 1, iter: 9200, curr loss: 1.3857362270355225, avg loss: 1.386238837838173\n",
      "trial: 1, iter: 9400, curr loss: 1.3848764896392822, avg loss: 1.3861538910865783\n",
      "trial: 1, iter: 9600, curr loss: 1.3832674026489258, avg loss: 1.3855305290222169\n",
      "trial: 1, iter: 9800, curr loss: 1.3796192407608032, avg loss: 1.3800655174255372\n",
      "trial: 1, iter: 10000, curr loss: 1.3283785581588745, avg loss: 1.3606565237045287\n",
      "trial: 1, iter: 10200, curr loss: 1.3436685800552368, avg loss: 1.3417313635349273\n",
      "trial: 1, iter: 10400, curr loss: 1.3155473470687866, avg loss: 1.332025642991066\n",
      "trial: 1, iter: 10600, curr loss: 1.328554391860962, avg loss: 1.327572506070137\n",
      "trial: 1, iter: 10800, curr loss: 1.324060082435608, avg loss: 1.3246439230442046\n",
      "trial: 1, iter: 11000, curr loss: 1.3614976406097412, avg loss: 1.3227717983722687\n",
      "trial: 1, iter: 11200, curr loss: 1.3060626983642578, avg loss: 1.3217978620529174\n",
      "trial: 1, iter: 11400, curr loss: 1.322259545326233, avg loss: 1.3207087045907975\n",
      "trial: 1, iter: 11600, curr loss: 1.322852373123169, avg loss: 1.320193641781807\n",
      "trial: 1, iter: 11800, curr loss: 1.3092467784881592, avg loss: 1.3204527932405472\n",
      "trial: 1, iter: 12000, curr loss: 1.3470187187194824, avg loss: 1.3181549537181854\n",
      "trial: 1, iter: 12200, curr loss: 1.3453257083892822, avg loss: 1.3171070617437364\n",
      "trial: 1, iter: 12400, curr loss: 1.2753334045410156, avg loss: 1.3175056427717209\n",
      "trial: 1, iter: 12600, curr loss: 1.30996572971344, avg loss: 1.31672436773777\n",
      "trial: 1, iter: 12800, curr loss: 1.3218575716018677, avg loss: 1.3197298628091811\n",
      "trial: 1, iter: 13000, curr loss: 1.3435221910476685, avg loss: 1.317914245724678\n",
      "trial: 1, iter: 13200, curr loss: 1.3120074272155762, avg loss: 1.3168313574790955\n",
      "trial: 1, iter: 13400, curr loss: 1.2940765619277954, avg loss: 1.3171092945337295\n",
      "trial: 1, iter: 13600, curr loss: 1.3648877143859863, avg loss: 1.3148613828420639\n",
      "trial: 1, iter: 13800, curr loss: 1.2975493669509888, avg loss: 1.3170254808664321\n",
      "trial: 1, iter: 14000, curr loss: 1.3276307582855225, avg loss: 1.3187202626466752\n",
      "trial: 1, iter: 14200, curr loss: 1.2968584299087524, avg loss: 1.3163104635477065\n",
      "trial: 1, iter: 14400, curr loss: 1.3044370412826538, avg loss: 1.318870374560356\n",
      "trial: 1, iter: 14600, curr loss: 1.323055624961853, avg loss: 1.31790491938591\n",
      "trial: 1, iter: 14800, curr loss: 1.3320934772491455, avg loss: 1.3155946838855743\n",
      "trial: 1, iter: 15000, curr loss: 1.3143885135650635, avg loss: 1.31692699611187\n",
      "trial: 1, iter: 15200, curr loss: 1.2981690168380737, avg loss: 1.3156208628416062\n",
      "trial: 1, iter: 15400, curr loss: 1.3224802017211914, avg loss: 1.3168148028850555\n",
      "trial: 1, iter: 15600, curr loss: 1.3107621669769287, avg loss: 1.3157489335536956\n",
      "trial: 1, ldr: 0.3748786747455597\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3847829103469849, avg loss: 1.387524923682213\n",
      "trial: 2, iter: 400, curr loss: 1.3851503133773804, avg loss: 1.3867534738779068\n",
      "trial: 2, iter: 600, curr loss: 1.3833918571472168, avg loss: 1.3866754424571992\n",
      "trial: 2, iter: 800, curr loss: 1.3865621089935303, avg loss: 1.3865856194496156\n",
      "trial: 2, iter: 1000, curr loss: 1.388574481010437, avg loss: 1.3865654563903809\n",
      "trial: 2, iter: 1200, curr loss: 1.3863824605941772, avg loss: 1.3864608365297317\n",
      "trial: 2, iter: 1400, curr loss: 1.3857982158660889, avg loss: 1.3864216738939286\n",
      "trial: 2, iter: 1600, curr loss: 1.3871657848358154, avg loss: 1.386457422375679\n",
      "trial: 2, iter: 1800, curr loss: 1.385080337524414, avg loss: 1.386354827284813\n",
      "trial: 2, iter: 2000, curr loss: 1.3851696252822876, avg loss: 1.3864037984609603\n",
      "trial: 2, iter: 2200, curr loss: 1.3863774538040161, avg loss: 1.386410796046257\n",
      "trial: 2, iter: 2400, curr loss: 1.3864772319793701, avg loss: 1.3863886308670044\n",
      "trial: 2, iter: 2600, curr loss: 1.386283040046692, avg loss: 1.386308268904686\n",
      "trial: 2, iter: 2800, curr loss: 1.3865727186203003, avg loss: 1.3863539481163025\n",
      "trial: 2, iter: 3000, curr loss: 1.3857855796813965, avg loss: 1.3863633525371553\n",
      "trial: 2, iter: 3200, curr loss: 1.3864305019378662, avg loss: 1.3862983268499374\n",
      "trial: 2, iter: 3400, curr loss: 1.3856438398361206, avg loss: 1.3863398653268815\n",
      "trial: 2, iter: 3600, curr loss: 1.3869704008102417, avg loss: 1.3863196104764939\n",
      "trial: 2, iter: 3800, curr loss: 1.3856065273284912, avg loss: 1.386370098590851\n",
      "trial: 2, iter: 4000, curr loss: 1.3860819339752197, avg loss: 1.38633267223835\n",
      "trial: 2, iter: 4200, curr loss: 1.3865153789520264, avg loss: 1.386427486538887\n",
      "trial: 2, iter: 4400, curr loss: 1.386199712753296, avg loss: 1.3863261395692825\n",
      "trial: 2, iter: 4600, curr loss: 1.3864103555679321, avg loss: 1.3863216423988343\n",
      "trial: 2, iter: 4800, curr loss: 1.3868943452835083, avg loss: 1.3863225126266479\n",
      "trial: 2, iter: 5000, curr loss: 1.3858903646469116, avg loss: 1.3863069927692413\n",
      "trial: 2, iter: 5200, curr loss: 1.3865501880645752, avg loss: 1.3863279044628143\n",
      "trial: 2, iter: 5400, curr loss: 1.3867028951644897, avg loss: 1.3863788503408432\n",
      "trial: 2, iter: 5600, curr loss: 1.3866761922836304, avg loss: 1.3863160765171052\n",
      "trial: 2, iter: 5800, curr loss: 1.3867182731628418, avg loss: 1.3863302034139633\n",
      "trial: 2, iter: 6000, curr loss: 1.385827660560608, avg loss: 1.3863432222604752\n",
      "trial: 2, iter: 6200, curr loss: 1.3854341506958008, avg loss: 1.3863022476434708\n",
      "trial: 2, iter: 6400, curr loss: 1.3861101865768433, avg loss: 1.3863831984996795\n",
      "trial: 2, iter: 6600, curr loss: 1.3859578371047974, avg loss: 1.3863465052843094\n",
      "trial: 2, iter: 6800, curr loss: 1.3854897022247314, avg loss: 1.3862540674209596\n",
      "trial: 2, iter: 7000, curr loss: 1.3862429857254028, avg loss: 1.3862752568721772\n",
      "trial: 2, iter: 7200, curr loss: 1.3858484029769897, avg loss: 1.3863459646701812\n",
      "trial: 2, iter: 7400, curr loss: 1.3887931108474731, avg loss: 1.3857987797260285\n",
      "trial: 2, iter: 7600, curr loss: 1.3898160457611084, avg loss: 1.382503120303154\n",
      "trial: 2, iter: 7800, curr loss: 1.3666454553604126, avg loss: 1.375094910264015\n",
      "trial: 2, iter: 8000, curr loss: 1.3661717176437378, avg loss: 1.3700252372026442\n",
      "trial: 2, iter: 8200, curr loss: 1.362436294555664, avg loss: 1.365171684026718\n",
      "trial: 2, iter: 8400, curr loss: 1.3585338592529297, avg loss: 1.3620612317323684\n",
      "trial: 2, iter: 8600, curr loss: 1.3752326965332031, avg loss: 1.3605739432573318\n",
      "trial: 2, iter: 8800, curr loss: 1.3447693586349487, avg loss: 1.3598037719726563\n",
      "trial: 2, iter: 9000, curr loss: 1.3446487188339233, avg loss: 1.358803848028183\n",
      "trial: 2, iter: 9200, curr loss: 1.3476849794387817, avg loss: 1.3562130671739578\n",
      "trial: 2, iter: 9400, curr loss: 1.3621670007705688, avg loss: 1.3543780010938644\n",
      "trial: 2, iter: 9600, curr loss: 1.3688474893569946, avg loss: 1.3523101913928985\n",
      "trial: 2, iter: 9800, curr loss: 1.3363752365112305, avg loss: 1.3481194245815278\n",
      "trial: 2, iter: 10000, curr loss: 1.3341331481933594, avg loss: 1.3437298035621643\n",
      "trial: 2, iter: 10200, curr loss: 1.3335204124450684, avg loss: 1.3364652574062348\n",
      "trial: 2, iter: 10400, curr loss: 1.3312751054763794, avg loss: 1.3323857432603836\n",
      "trial: 2, iter: 10600, curr loss: 1.3321443796157837, avg loss: 1.3297470211982727\n",
      "trial: 2, iter: 10800, curr loss: 1.3337669372558594, avg loss: 1.3311134260892867\n",
      "trial: 2, iter: 11000, curr loss: 1.3415461778640747, avg loss: 1.327238844037056\n",
      "trial: 2, iter: 11200, curr loss: 1.2824574708938599, avg loss: 1.3261513721942901\n",
      "trial: 2, iter: 11400, curr loss: 1.3241249322891235, avg loss: 1.3257193678617478\n",
      "trial: 2, iter: 11600, curr loss: 1.343597650527954, avg loss: 1.3239919978380204\n",
      "trial: 2, iter: 11800, curr loss: 1.3597322702407837, avg loss: 1.3216991740465165\n",
      "trial: 2, iter: 12000, curr loss: 1.3369144201278687, avg loss: 1.3223077917099\n",
      "trial: 2, iter: 12200, curr loss: 1.3140389919281006, avg loss: 1.3233200025558471\n",
      "trial: 2, iter: 12400, curr loss: 1.3193005323410034, avg loss: 1.3244226419925689\n",
      "trial: 2, iter: 12600, curr loss: 1.30436372756958, avg loss: 1.321709804534912\n",
      "trial: 2, iter: 12800, curr loss: 1.3152729272842407, avg loss: 1.3232771861553192\n",
      "trial: 2, iter: 13000, curr loss: 1.3132655620574951, avg loss: 1.3218871396780014\n",
      "trial: 2, iter: 13200, curr loss: 1.323203682899475, avg loss: 1.3207821947336198\n",
      "trial: 2, iter: 13400, curr loss: 1.3466360569000244, avg loss: 1.3207979518175126\n",
      "trial: 2, iter: 13600, curr loss: 1.3354334831237793, avg loss: 1.323028372526169\n",
      "trial: 2, iter: 13800, curr loss: 1.304982304573059, avg loss: 1.3177892470359802\n",
      "trial: 2, iter: 14000, curr loss: 1.3347605466842651, avg loss: 1.3186435008049011\n",
      "trial: 2, iter: 14200, curr loss: 1.3156578540802002, avg loss: 1.3208853566646577\n",
      "trial: 2, iter: 14400, curr loss: 1.309151291847229, avg loss: 1.3187315434217453\n",
      "trial: 2, iter: 14600, curr loss: 1.2998075485229492, avg loss: 1.3180664145946503\n",
      "trial: 2, iter: 14800, curr loss: 1.3654717206954956, avg loss: 1.3189665484428406\n",
      "trial: 2, iter: 15000, curr loss: 1.3213709592819214, avg loss: 1.3175094544887542\n",
      "trial: 2, iter: 15200, curr loss: 1.3431730270385742, avg loss: 1.3193520832061767\n",
      "trial: 2, iter: 15400, curr loss: 1.2894554138183594, avg loss: 1.31832261800766\n",
      "trial: 2, iter: 15600, curr loss: 1.3075922727584839, avg loss: 1.3195050573348999\n",
      "trial: 2, ldr: 0.39238619804382324\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387333631515503, avg loss: 1.3871626722812653\n",
      "trial: 3, iter: 400, curr loss: 1.3847525119781494, avg loss: 1.3868288016319275\n",
      "trial: 3, iter: 600, curr loss: 1.3873921632766724, avg loss: 1.3867052274942397\n",
      "trial: 3, iter: 800, curr loss: 1.3856712579727173, avg loss: 1.3865972721576691\n",
      "trial: 3, iter: 1000, curr loss: 1.3864680528640747, avg loss: 1.386493558883667\n",
      "trial: 3, iter: 1200, curr loss: 1.387111783027649, avg loss: 1.3865166693925857\n",
      "trial: 3, iter: 1400, curr loss: 1.3889104127883911, avg loss: 1.38634681224823\n",
      "trial: 3, iter: 1600, curr loss: 1.3872827291488647, avg loss: 1.386444930434227\n",
      "trial: 3, iter: 1800, curr loss: 1.3864312171936035, avg loss: 1.3862946778535843\n",
      "trial: 3, iter: 2000, curr loss: 1.3869564533233643, avg loss: 1.3864532256126403\n",
      "trial: 3, iter: 2200, curr loss: 1.3865506649017334, avg loss: 1.3863453483581543\n",
      "trial: 3, iter: 2400, curr loss: 1.3868550062179565, avg loss: 1.3862659233808516\n",
      "trial: 3, iter: 2600, curr loss: 1.3861658573150635, avg loss: 1.3863732981681824\n",
      "trial: 3, iter: 2800, curr loss: 1.387030839920044, avg loss: 1.3863207960128785\n",
      "trial: 3, iter: 3000, curr loss: 1.3869576454162598, avg loss: 1.386324518918991\n",
      "trial: 3, iter: 3200, curr loss: 1.3864647150039673, avg loss: 1.3863328969478608\n",
      "trial: 3, iter: 3400, curr loss: 1.386487603187561, avg loss: 1.3863500607013703\n",
      "trial: 3, iter: 3600, curr loss: 1.3847376108169556, avg loss: 1.3862824076414109\n",
      "trial: 3, iter: 3800, curr loss: 1.3885328769683838, avg loss: 1.386335780620575\n",
      "trial: 3, iter: 4000, curr loss: 1.385169506072998, avg loss: 1.3862167096138\n",
      "trial: 3, iter: 4200, curr loss: 1.386511206626892, avg loss: 1.3863993710279465\n",
      "trial: 3, iter: 4400, curr loss: 1.3871827125549316, avg loss: 1.386310539841652\n",
      "trial: 3, iter: 4600, curr loss: 1.386522889137268, avg loss: 1.3863222873210908\n",
      "trial: 3, iter: 4800, curr loss: 1.3861942291259766, avg loss: 1.3863395100831986\n",
      "trial: 3, iter: 5000, curr loss: 1.386529564857483, avg loss: 1.386302295923233\n",
      "trial: 3, iter: 5200, curr loss: 1.3864179849624634, avg loss: 1.386318616271019\n",
      "trial: 3, iter: 5400, curr loss: 1.386713981628418, avg loss: 1.3863649702072143\n",
      "trial: 3, iter: 5600, curr loss: 1.3852415084838867, avg loss: 1.3862290585041046\n",
      "trial: 3, iter: 5800, curr loss: 1.385898470878601, avg loss: 1.3863131481409072\n",
      "trial: 3, iter: 6000, curr loss: 1.385911464691162, avg loss: 1.3862678110599518\n",
      "trial: 3, iter: 6200, curr loss: 1.3860697746276855, avg loss: 1.3863235783576966\n",
      "trial: 3, iter: 6400, curr loss: 1.3860143423080444, avg loss: 1.386283466219902\n",
      "trial: 3, iter: 6600, curr loss: 1.3860560655593872, avg loss: 1.386329212784767\n",
      "trial: 3, iter: 6800, curr loss: 1.3857964277267456, avg loss: 1.386299329996109\n",
      "trial: 3, iter: 7000, curr loss: 1.3858866691589355, avg loss: 1.3863599973917007\n",
      "trial: 3, iter: 7200, curr loss: 1.3851215839385986, avg loss: 1.3862926703691483\n",
      "trial: 3, iter: 7400, curr loss: 1.386984944343567, avg loss: 1.3863300079107284\n",
      "trial: 3, iter: 7600, curr loss: 1.386722207069397, avg loss: 1.3863512551784516\n",
      "trial: 3, iter: 7800, curr loss: 1.3857513666152954, avg loss: 1.3862809199094772\n",
      "trial: 3, iter: 8000, curr loss: 1.386123538017273, avg loss: 1.3863540399074554\n",
      "trial: 3, iter: 8200, curr loss: 1.3868052959442139, avg loss: 1.386239219903946\n",
      "trial: 3, iter: 8400, curr loss: 1.385196566581726, avg loss: 1.3860695153474807\n",
      "trial: 3, iter: 8600, curr loss: 1.380723237991333, avg loss: 1.385284349322319\n",
      "trial: 3, iter: 8800, curr loss: 1.3731436729431152, avg loss: 1.3832659471035003\n",
      "trial: 3, iter: 9000, curr loss: 1.363845944404602, avg loss: 1.3763659071922303\n",
      "trial: 3, iter: 9200, curr loss: 1.376907229423523, avg loss: 1.367701827287674\n",
      "trial: 3, iter: 9400, curr loss: 1.3828933238983154, avg loss: 1.3625927674770355\n",
      "trial: 3, iter: 9600, curr loss: 1.3682081699371338, avg loss: 1.361906880736351\n",
      "trial: 3, iter: 9800, curr loss: 1.3519011735916138, avg loss: 1.359055179953575\n",
      "trial: 3, iter: 10000, curr loss: 1.3454952239990234, avg loss: 1.3558101028203964\n",
      "trial: 3, iter: 10200, curr loss: 1.3197014331817627, avg loss: 1.3499690371751785\n",
      "trial: 3, iter: 10400, curr loss: 1.3429983854293823, avg loss: 1.3480752730369567\n",
      "trial: 3, iter: 10600, curr loss: 1.337668776512146, avg loss: 1.341080859899521\n",
      "trial: 3, iter: 10800, curr loss: 1.3462927341461182, avg loss: 1.3390519106388092\n",
      "trial: 3, iter: 11000, curr loss: 1.327012538909912, avg loss: 1.3358097714185715\n",
      "trial: 3, iter: 11200, curr loss: 1.35374116897583, avg loss: 1.3349740612506866\n",
      "trial: 3, iter: 11400, curr loss: 1.3545918464660645, avg loss: 1.3307945787906648\n",
      "trial: 3, iter: 11600, curr loss: 1.325764536857605, avg loss: 1.3295971208810806\n",
      "trial: 3, iter: 11800, curr loss: 1.3320187330245972, avg loss: 1.3306694519519806\n",
      "trial: 3, iter: 12000, curr loss: 1.3241935968399048, avg loss: 1.3294802099466323\n",
      "trial: 3, iter: 12200, curr loss: 1.3103089332580566, avg loss: 1.3255773520469665\n",
      "trial: 3, iter: 12400, curr loss: 1.3377693891525269, avg loss: 1.3271327924728393\n",
      "trial: 3, iter: 12600, curr loss: 1.3286653757095337, avg loss: 1.3282308560609817\n",
      "trial: 3, iter: 12800, curr loss: 1.3157042264938354, avg loss: 1.3245915085077287\n",
      "trial: 3, iter: 13000, curr loss: 1.3309249877929688, avg loss: 1.323941787481308\n",
      "trial: 3, iter: 13200, curr loss: 1.351189136505127, avg loss: 1.3242811834812165\n",
      "trial: 3, iter: 13400, curr loss: 1.3386069536209106, avg loss: 1.3206751245260238\n",
      "trial: 3, iter: 13600, curr loss: 1.3189351558685303, avg loss: 1.3212261199951172\n",
      "trial: 3, iter: 13800, curr loss: 1.3252394199371338, avg loss: 1.3207080173492431\n",
      "trial: 3, iter: 14000, curr loss: 1.3213118314743042, avg loss: 1.3222909808158874\n",
      "trial: 3, iter: 14200, curr loss: 1.3071352243423462, avg loss: 1.3212900066375732\n",
      "trial: 3, iter: 14400, curr loss: 1.3219348192214966, avg loss: 1.320313395857811\n",
      "trial: 3, iter: 14600, curr loss: 1.3198966979980469, avg loss: 1.322971863746643\n",
      "trial: 3, iter: 14800, curr loss: 1.340807557106018, avg loss: 1.3203571861982346\n",
      "trial: 3, iter: 15000, curr loss: 1.3266373872756958, avg loss: 1.3200904655456542\n",
      "trial: 3, iter: 15200, curr loss: 1.317202091217041, avg loss: 1.3219143283367156\n",
      "trial: 3, iter: 15400, curr loss: 1.3063105344772339, avg loss: 1.319720947742462\n",
      "trial: 3, iter: 15600, curr loss: 1.3506760597229004, avg loss: 1.3203640431165695\n",
      "trial: 3, ldr: 0.29903343319892883\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3900244235992432, avg loss: 1.3876970511674882\n",
      "trial: 4, iter: 400, curr loss: 1.386317253112793, avg loss: 1.3867048627138139\n",
      "trial: 4, iter: 600, curr loss: 1.3877195119857788, avg loss: 1.386789991259575\n",
      "trial: 4, iter: 800, curr loss: 1.3859471082687378, avg loss: 1.3864180058240891\n",
      "trial: 4, iter: 1000, curr loss: 1.3852680921554565, avg loss: 1.3864890664815903\n",
      "trial: 4, iter: 1200, curr loss: 1.3855681419372559, avg loss: 1.3864209884405136\n",
      "trial: 4, iter: 1400, curr loss: 1.3861480951309204, avg loss: 1.3864334172010422\n",
      "trial: 4, iter: 1600, curr loss: 1.3865035772323608, avg loss: 1.3864718449115754\n",
      "trial: 4, iter: 1800, curr loss: 1.386762261390686, avg loss: 1.3864113253355026\n",
      "trial: 4, iter: 2000, curr loss: 1.3871818780899048, avg loss: 1.3864026921987533\n",
      "trial: 4, iter: 2200, curr loss: 1.387064814567566, avg loss: 1.3864084273576736\n",
      "trial: 4, iter: 2400, curr loss: 1.385636806488037, avg loss: 1.3863707494735718\n",
      "trial: 4, iter: 2600, curr loss: 1.3867336511611938, avg loss: 1.3863772422075271\n",
      "trial: 4, iter: 2800, curr loss: 1.3867710828781128, avg loss: 1.3863664448261261\n",
      "trial: 4, iter: 3000, curr loss: 1.3863420486450195, avg loss: 1.3863097196817398\n",
      "trial: 4, iter: 3200, curr loss: 1.38736093044281, avg loss: 1.3862836706638335\n",
      "trial: 4, iter: 3400, curr loss: 1.386386752128601, avg loss: 1.3864319390058517\n",
      "trial: 4, iter: 3600, curr loss: 1.386754035949707, avg loss: 1.3863503795862198\n",
      "trial: 4, iter: 3800, curr loss: 1.3855235576629639, avg loss: 1.3863158589601516\n",
      "trial: 4, iter: 4000, curr loss: 1.3858495950698853, avg loss: 1.3863910245895386\n",
      "trial: 4, iter: 4200, curr loss: 1.3865751028060913, avg loss: 1.3862646543979644\n",
      "trial: 4, iter: 4400, curr loss: 1.3860875368118286, avg loss: 1.3863578838109971\n",
      "trial: 4, iter: 4600, curr loss: 1.3864469528198242, avg loss: 1.3863005298376083\n",
      "trial: 4, iter: 4800, curr loss: 1.386242151260376, avg loss: 1.3862983453273774\n",
      "trial: 4, iter: 5000, curr loss: 1.3852816820144653, avg loss: 1.386142361164093\n",
      "trial: 4, iter: 5200, curr loss: 1.3819448947906494, avg loss: 1.385214256644249\n",
      "trial: 4, iter: 5400, curr loss: 1.3736648559570312, avg loss: 1.3814802199602128\n",
      "trial: 4, iter: 5600, curr loss: 1.3737884759902954, avg loss: 1.377530699968338\n",
      "trial: 4, iter: 5800, curr loss: 1.3785545825958252, avg loss: 1.3739280998706818\n",
      "trial: 4, iter: 6000, curr loss: 1.3714501857757568, avg loss: 1.3695696038007736\n",
      "trial: 4, iter: 6200, curr loss: 1.3729077577590942, avg loss: 1.3638027185201644\n",
      "trial: 4, iter: 6400, curr loss: 1.3542178869247437, avg loss: 1.3617832189798356\n",
      "trial: 4, iter: 6600, curr loss: 1.3609405755996704, avg loss: 1.3583698982000352\n",
      "trial: 4, iter: 6800, curr loss: 1.3656392097473145, avg loss: 1.358123310804367\n",
      "trial: 4, iter: 7000, curr loss: 1.3375707864761353, avg loss: 1.3544275957345961\n",
      "trial: 4, iter: 7200, curr loss: 1.3758116960525513, avg loss: 1.351752414703369\n",
      "trial: 4, iter: 7400, curr loss: 1.342754602432251, avg loss: 1.3476003420352936\n",
      "trial: 4, iter: 7600, curr loss: 1.3571982383728027, avg loss: 1.3460472947359086\n",
      "trial: 4, iter: 7800, curr loss: 1.3129465579986572, avg loss: 1.3403561639785766\n",
      "trial: 4, iter: 8000, curr loss: 1.3322638273239136, avg loss: 1.3358319669961929\n",
      "trial: 4, iter: 8200, curr loss: 1.305151343345642, avg loss: 1.333018985390663\n",
      "trial: 4, iter: 8400, curr loss: 1.3324264287948608, avg loss: 1.3311802494525908\n",
      "trial: 4, iter: 8600, curr loss: 1.3133550882339478, avg loss: 1.3272157460451126\n",
      "trial: 4, iter: 8800, curr loss: 1.3141754865646362, avg loss: 1.325115804672241\n",
      "trial: 4, iter: 9000, curr loss: 1.3301284313201904, avg loss: 1.324217328429222\n",
      "trial: 4, iter: 9200, curr loss: 1.3190971612930298, avg loss: 1.3205155318975448\n",
      "trial: 4, iter: 9400, curr loss: 1.3036305904388428, avg loss: 1.3211178803443908\n",
      "trial: 4, iter: 9600, curr loss: 1.3249372243881226, avg loss: 1.3200689792633056\n",
      "trial: 4, iter: 9800, curr loss: 1.34441339969635, avg loss: 1.3220335197448732\n",
      "trial: 4, iter: 10000, curr loss: 1.288668155670166, avg loss: 1.3180424690246582\n",
      "trial: 4, iter: 10200, curr loss: 1.292578101158142, avg loss: 1.3167637199163438\n",
      "trial: 4, iter: 10400, curr loss: 1.2987037897109985, avg loss: 1.3186837446689605\n",
      "trial: 4, iter: 10600, curr loss: 1.3177615404129028, avg loss: 1.3174911522865296\n",
      "trial: 4, iter: 10800, curr loss: 1.3222169876098633, avg loss: 1.3164711952209474\n",
      "trial: 4, iter: 11000, curr loss: 1.3427919149398804, avg loss: 1.3166589826345443\n",
      "trial: 4, iter: 11200, curr loss: 1.3602893352508545, avg loss: 1.3194433748722076\n",
      "trial: 4, iter: 11400, curr loss: 1.2941980361938477, avg loss: 1.3159663379192352\n",
      "trial: 4, iter: 11600, curr loss: 1.3357818126678467, avg loss: 1.3164784622192383\n",
      "trial: 4, iter: 11800, curr loss: 1.3254128694534302, avg loss: 1.314314455986023\n",
      "trial: 4, iter: 12000, curr loss: 1.3258843421936035, avg loss: 1.3162636905908585\n",
      "trial: 4, iter: 12200, curr loss: 1.3431397676467896, avg loss: 1.3179584383964538\n",
      "trial: 4, iter: 12400, curr loss: 1.2804961204528809, avg loss: 1.3166440397500991\n",
      "trial: 4, iter: 12600, curr loss: 1.337938666343689, avg loss: 1.316713397502899\n",
      "trial: 4, iter: 12800, curr loss: 1.2920106649398804, avg loss: 1.3144614613056183\n",
      "trial: 4, iter: 13000, curr loss: 1.3082029819488525, avg loss: 1.3161233627796174\n",
      "trial: 4, iter: 13200, curr loss: 1.2932950258255005, avg loss: 1.3155952078104018\n",
      "trial: 4, iter: 13400, curr loss: 1.276639699935913, avg loss: 1.3141167002916336\n",
      "trial: 4, iter: 13600, curr loss: 1.2759268283843994, avg loss: 1.3169176322221756\n",
      "trial: 4, iter: 13800, curr loss: 1.314691424369812, avg loss: 1.3170003139972686\n",
      "trial: 4, iter: 14000, curr loss: 1.3215997219085693, avg loss: 1.3148388195037841\n",
      "trial: 4, iter: 14200, curr loss: 1.3148994445800781, avg loss: 1.314998750090599\n",
      "trial: 4, iter: 14400, curr loss: 1.3196810483932495, avg loss: 1.3149575608968735\n",
      "trial: 4, iter: 14600, curr loss: 1.3165756464004517, avg loss: 1.3132609629631042\n",
      "trial: 4, iter: 14800, curr loss: 1.2984944581985474, avg loss: 1.3160910093784333\n",
      "trial: 4, iter: 15000, curr loss: 1.2956113815307617, avg loss: 1.315940181016922\n",
      "trial: 4, iter: 15200, curr loss: 1.3194085359573364, avg loss: 1.3143160659074784\n",
      "trial: 4, iter: 15400, curr loss: 1.3354947566986084, avg loss: 1.3144399797916413\n",
      "trial: 4, iter: 15600, curr loss: 1.3037374019622803, avg loss: 1.3154581427574157\n",
      "trial: 4, ldr: 0.3344358503818512\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3897699117660522, avg loss: 1.387332373857498\n",
      "trial: 5, iter: 400, curr loss: 1.3899399042129517, avg loss: 1.3867945331335068\n",
      "trial: 5, iter: 600, curr loss: 1.3852049112319946, avg loss: 1.386675768494606\n",
      "trial: 5, iter: 800, curr loss: 1.3869644403457642, avg loss: 1.3865855556726456\n",
      "trial: 5, iter: 1000, curr loss: 1.3860268592834473, avg loss: 1.3864208525419235\n",
      "trial: 5, iter: 1200, curr loss: 1.3856743574142456, avg loss: 1.3863184344768524\n",
      "trial: 5, iter: 1400, curr loss: 1.3841596841812134, avg loss: 1.3864774864912033\n",
      "trial: 5, iter: 1600, curr loss: 1.386168122291565, avg loss: 1.386452283859253\n",
      "trial: 5, iter: 1800, curr loss: 1.3859003782272339, avg loss: 1.3863639271259307\n",
      "trial: 5, iter: 2000, curr loss: 1.3868588209152222, avg loss: 1.3864276540279388\n",
      "trial: 5, iter: 2200, curr loss: 1.3864173889160156, avg loss: 1.3863580584526063\n",
      "trial: 5, iter: 2400, curr loss: 1.3878943920135498, avg loss: 1.3863579833507538\n",
      "trial: 5, iter: 2600, curr loss: 1.3853881359100342, avg loss: 1.3863233458995818\n",
      "trial: 5, iter: 2800, curr loss: 1.3866854906082153, avg loss: 1.3863676458597183\n",
      "trial: 5, iter: 3000, curr loss: 1.3859788179397583, avg loss: 1.3863009470701217\n",
      "trial: 5, iter: 3200, curr loss: 1.3866034746170044, avg loss: 1.3863412815332412\n",
      "trial: 5, iter: 3400, curr loss: 1.386884331703186, avg loss: 1.3864209282398223\n",
      "trial: 5, iter: 3600, curr loss: 1.3859138488769531, avg loss: 1.3863387495279311\n",
      "trial: 5, iter: 3800, curr loss: 1.3856749534606934, avg loss: 1.3863402968645095\n",
      "trial: 5, iter: 4000, curr loss: 1.3859755992889404, avg loss: 1.386316270828247\n",
      "trial: 5, iter: 4200, curr loss: 1.3862886428833008, avg loss: 1.3863131219148637\n",
      "trial: 5, iter: 4400, curr loss: 1.3865094184875488, avg loss: 1.3862588065862655\n",
      "trial: 5, iter: 4600, curr loss: 1.3862427473068237, avg loss: 1.3859363424777984\n",
      "trial: 5, iter: 4800, curr loss: 1.3841475248336792, avg loss: 1.3843451583385467\n",
      "trial: 5, iter: 5000, curr loss: 1.3833576440811157, avg loss: 1.381770254969597\n",
      "trial: 5, iter: 5200, curr loss: 1.36566162109375, avg loss: 1.3780552518367768\n",
      "trial: 5, iter: 5400, curr loss: 1.3612028360366821, avg loss: 1.372206333875656\n",
      "trial: 5, iter: 5600, curr loss: 1.3546632528305054, avg loss: 1.3633189463615418\n",
      "trial: 5, iter: 5800, curr loss: 1.3429336547851562, avg loss: 1.3584858840703964\n",
      "trial: 5, iter: 6000, curr loss: 1.3451076745986938, avg loss: 1.3565376979112624\n",
      "trial: 5, iter: 6200, curr loss: 1.3527065515518188, avg loss: 1.3561507201194762\n",
      "trial: 5, iter: 6400, curr loss: 1.3528809547424316, avg loss: 1.3557505470514297\n",
      "trial: 5, iter: 6600, curr loss: 1.3543825149536133, avg loss: 1.3535695225000381\n",
      "trial: 5, iter: 6800, curr loss: 1.334672212600708, avg loss: 1.3537563854455947\n",
      "trial: 5, iter: 7000, curr loss: 1.3705469369888306, avg loss: 1.3520613998174666\n",
      "trial: 5, iter: 7200, curr loss: 1.3448994159698486, avg loss: 1.3482501500844954\n",
      "trial: 5, iter: 7400, curr loss: 1.3349556922912598, avg loss: 1.3409775865077973\n",
      "trial: 5, iter: 7600, curr loss: 1.3402048349380493, avg loss: 1.3361994820833205\n",
      "trial: 5, iter: 7800, curr loss: 1.3123931884765625, avg loss: 1.3312316036224365\n",
      "trial: 5, iter: 8000, curr loss: 1.3265321254730225, avg loss: 1.3273193740844726\n",
      "trial: 5, iter: 8200, curr loss: 1.3022409677505493, avg loss: 1.325399351119995\n",
      "trial: 5, iter: 8400, curr loss: 1.2988896369934082, avg loss: 1.3238093554973602\n",
      "trial: 5, iter: 8600, curr loss: 1.3400943279266357, avg loss: 1.320998649597168\n",
      "trial: 5, iter: 8800, curr loss: 1.3423625230789185, avg loss: 1.321118271946907\n",
      "trial: 5, iter: 9000, curr loss: 1.303084373474121, avg loss: 1.3191730183362962\n",
      "trial: 5, iter: 9200, curr loss: 1.3513481616973877, avg loss: 1.3210732650756836\n",
      "trial: 5, iter: 9400, curr loss: 1.3253772258758545, avg loss: 1.3184593731164933\n",
      "trial: 5, iter: 9600, curr loss: 1.3201779127120972, avg loss: 1.3185660707950593\n",
      "trial: 5, iter: 9800, curr loss: 1.2647600173950195, avg loss: 1.3190973544120788\n",
      "trial: 5, iter: 10000, curr loss: 1.3052490949630737, avg loss: 1.3178355932235717\n",
      "trial: 5, iter: 10200, curr loss: 1.3018100261688232, avg loss: 1.3190063810348511\n",
      "trial: 5, iter: 10400, curr loss: 1.2930339574813843, avg loss: 1.319025440812111\n",
      "trial: 5, iter: 10600, curr loss: 1.3229343891143799, avg loss: 1.318189987540245\n",
      "trial: 5, iter: 10800, curr loss: 1.3454396724700928, avg loss: 1.3160415136814116\n",
      "trial: 5, iter: 11000, curr loss: 1.3000843524932861, avg loss: 1.316153358221054\n",
      "trial: 5, iter: 11200, curr loss: 1.3043773174285889, avg loss: 1.3184973722696305\n",
      "trial: 5, iter: 11400, curr loss: 1.324605107307434, avg loss: 1.3168892216682435\n",
      "trial: 5, iter: 11600, curr loss: 1.3230319023132324, avg loss: 1.3156317567825317\n",
      "trial: 5, iter: 11800, curr loss: 1.3364733457565308, avg loss: 1.317437345981598\n",
      "trial: 5, iter: 12000, curr loss: 1.3078618049621582, avg loss: 1.3169866716861724\n",
      "trial: 5, iter: 12200, curr loss: 1.328584909439087, avg loss: 1.319032525420189\n",
      "trial: 5, iter: 12400, curr loss: 1.3256832361221313, avg loss: 1.3156335216760635\n",
      "trial: 5, iter: 12600, curr loss: 1.3147977590560913, avg loss: 1.316315807700157\n",
      "trial: 5, iter: 12800, curr loss: 1.2834830284118652, avg loss: 1.3175592279434205\n",
      "trial: 5, iter: 13000, curr loss: 1.3138796091079712, avg loss: 1.3157501351833343\n",
      "trial: 5, iter: 13200, curr loss: 1.345533013343811, avg loss: 1.3151567125320434\n",
      "trial: 5, iter: 13400, curr loss: 1.309540867805481, avg loss: 1.3143808084726334\n",
      "trial: 5, iter: 13600, curr loss: 1.303301215171814, avg loss: 1.3163714301586151\n",
      "trial: 5, iter: 13800, curr loss: 1.3476959466934204, avg loss: 1.3147700744867326\n",
      "trial: 5, iter: 14000, curr loss: 1.3119196891784668, avg loss: 1.3137590163946151\n",
      "trial: 5, iter: 14200, curr loss: 1.2952591180801392, avg loss: 1.3163907051086425\n",
      "trial: 5, iter: 14400, curr loss: 1.315346121788025, avg loss: 1.3158507347106934\n",
      "trial: 5, iter: 14600, curr loss: 1.29775869846344, avg loss: 1.316442185640335\n",
      "trial: 5, iter: 14800, curr loss: 1.3152059316635132, avg loss: 1.3153321075439453\n",
      "trial: 5, iter: 15000, curr loss: 1.3483370542526245, avg loss: 1.3173513424396515\n",
      "trial: 5, iter: 15200, curr loss: 1.308666467666626, avg loss: 1.313747119307518\n",
      "trial: 5, iter: 15400, curr loss: 1.344207525253296, avg loss: 1.3155086755752563\n",
      "trial: 5, iter: 15600, curr loss: 1.337852954864502, avg loss: 1.317234291434288\n",
      "trial: 5, ldr: 0.35442501306533813\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.35103183388710024\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3848049640655518, avg loss: 1.3875498282909393\n",
      "trial: 1, iter: 400, curr loss: 1.3893787860870361, avg loss: 1.3866945594549178\n",
      "trial: 1, iter: 600, curr loss: 1.3852264881134033, avg loss: 1.3864382648468017\n",
      "trial: 1, iter: 800, curr loss: 1.3845680952072144, avg loss: 1.3866626912355422\n",
      "trial: 1, iter: 1000, curr loss: 1.3862035274505615, avg loss: 1.3864364808797836\n",
      "trial: 1, iter: 1200, curr loss: 1.3858129978179932, avg loss: 1.386573023200035\n",
      "trial: 1, iter: 1400, curr loss: 1.3862440586090088, avg loss: 1.3864621287584304\n",
      "trial: 1, iter: 1600, curr loss: 1.3837099075317383, avg loss: 1.3862513071298599\n",
      "trial: 1, iter: 1800, curr loss: 1.38627290725708, avg loss: 1.3862868523597718\n",
      "trial: 1, iter: 2000, curr loss: 1.3860604763031006, avg loss: 1.3864166587591171\n",
      "trial: 1, iter: 2200, curr loss: 1.3873581886291504, avg loss: 1.3864102679491044\n",
      "trial: 1, iter: 2400, curr loss: 1.3850444555282593, avg loss: 1.3862985062599182\n",
      "trial: 1, iter: 2600, curr loss: 1.3861676454544067, avg loss: 1.3864030438661574\n",
      "trial: 1, iter: 2800, curr loss: 1.3865975141525269, avg loss: 1.3862939476966858\n",
      "trial: 1, iter: 3000, curr loss: 1.386693000793457, avg loss: 1.3863768839836121\n",
      "trial: 1, iter: 3200, curr loss: 1.3872804641723633, avg loss: 1.386289947628975\n",
      "trial: 1, iter: 3400, curr loss: 1.3861722946166992, avg loss: 1.3863526195287705\n",
      "trial: 1, iter: 3600, curr loss: 1.386627435684204, avg loss: 1.386286044716835\n",
      "trial: 1, iter: 3800, curr loss: 1.385643720626831, avg loss: 1.3863340550661087\n",
      "trial: 1, iter: 4000, curr loss: 1.3860676288604736, avg loss: 1.3863295388221741\n",
      "trial: 1, iter: 4200, curr loss: 1.3865982294082642, avg loss: 1.386300472021103\n",
      "trial: 1, iter: 4400, curr loss: 1.3852894306182861, avg loss: 1.3863714283704758\n",
      "trial: 1, iter: 4600, curr loss: 1.3864784240722656, avg loss: 1.3863510954380036\n",
      "trial: 1, iter: 4800, curr loss: 1.3860912322998047, avg loss: 1.3863355869054794\n",
      "trial: 1, iter: 5000, curr loss: 1.3862559795379639, avg loss: 1.3863622266054154\n",
      "trial: 1, iter: 5200, curr loss: 1.3868519067764282, avg loss: 1.3863142675161362\n",
      "trial: 1, iter: 5400, curr loss: 1.3865824937820435, avg loss: 1.386276872754097\n",
      "trial: 1, iter: 5600, curr loss: 1.3867661952972412, avg loss: 1.3862659901380538\n",
      "trial: 1, iter: 5800, curr loss: 1.3864892721176147, avg loss: 1.3862791734933853\n",
      "trial: 1, iter: 6000, curr loss: 1.386216402053833, avg loss: 1.3862350606918334\n",
      "trial: 1, iter: 6200, curr loss: 1.3869824409484863, avg loss: 1.38637246966362\n",
      "trial: 1, iter: 6400, curr loss: 1.3863754272460938, avg loss: 1.386335604786873\n",
      "trial: 1, iter: 6600, curr loss: 1.38591730594635, avg loss: 1.3860786765813828\n",
      "trial: 1, iter: 6800, curr loss: 1.3848549127578735, avg loss: 1.3847161632776261\n",
      "trial: 1, iter: 7000, curr loss: 1.3680851459503174, avg loss: 1.380624452829361\n",
      "trial: 1, iter: 7200, curr loss: 1.3701400756835938, avg loss: 1.3730167120695114\n",
      "trial: 1, iter: 7400, curr loss: 1.354736566543579, avg loss: 1.3645343512296677\n",
      "trial: 1, iter: 7600, curr loss: 1.3620777130126953, avg loss: 1.3601476019620895\n",
      "trial: 1, iter: 7800, curr loss: 1.3376597166061401, avg loss: 1.3567936778068543\n",
      "trial: 1, iter: 8000, curr loss: 1.3540571928024292, avg loss: 1.353660649061203\n",
      "trial: 1, iter: 8200, curr loss: 1.3445549011230469, avg loss: 1.3521454399824142\n",
      "trial: 1, iter: 8400, curr loss: 1.344162940979004, avg loss: 1.3455577474832534\n",
      "trial: 1, iter: 8600, curr loss: 1.3262993097305298, avg loss: 1.3367748111486435\n",
      "trial: 1, iter: 8800, curr loss: 1.3155215978622437, avg loss: 1.3332100814580918\n",
      "trial: 1, iter: 9000, curr loss: 1.338810682296753, avg loss: 1.3295524728298187\n",
      "trial: 1, iter: 9200, curr loss: 1.3227876424789429, avg loss: 1.326919023990631\n",
      "trial: 1, iter: 9400, curr loss: 1.3286118507385254, avg loss: 1.3227432733774185\n",
      "trial: 1, iter: 9600, curr loss: 1.311684489250183, avg loss: 1.3219420826435089\n",
      "trial: 1, iter: 9800, curr loss: 1.3149513006210327, avg loss: 1.3182952135801316\n",
      "trial: 1, iter: 10000, curr loss: 1.3130069971084595, avg loss: 1.3208822637796402\n",
      "trial: 1, iter: 10200, curr loss: 1.343422532081604, avg loss: 1.3218016886711121\n",
      "trial: 1, iter: 10400, curr loss: 1.303895115852356, avg loss: 1.3204358232021332\n",
      "trial: 1, iter: 10600, curr loss: 1.3433717489242554, avg loss: 1.3192536860704422\n",
      "trial: 1, iter: 10800, curr loss: 1.2601035833358765, avg loss: 1.3183347588777543\n",
      "trial: 1, iter: 11000, curr loss: 1.3160910606384277, avg loss: 1.3177559667825698\n",
      "trial: 1, iter: 11200, curr loss: 1.3378194570541382, avg loss: 1.3166316962242126\n",
      "trial: 1, iter: 11400, curr loss: 1.315779447555542, avg loss: 1.3177503764629364\n",
      "trial: 1, iter: 11600, curr loss: 1.304914951324463, avg loss: 1.319036501646042\n",
      "trial: 1, iter: 11800, curr loss: 1.3369004726409912, avg loss: 1.3175098049640654\n",
      "trial: 1, iter: 12000, curr loss: 1.330869197845459, avg loss: 1.315020399093628\n",
      "trial: 1, iter: 12200, curr loss: 1.3497357368469238, avg loss: 1.3165386998653412\n",
      "trial: 1, iter: 12400, curr loss: 1.3213344812393188, avg loss: 1.314791065454483\n",
      "trial: 1, iter: 12600, curr loss: 1.2669886350631714, avg loss: 1.315033861398697\n",
      "trial: 1, iter: 12800, curr loss: 1.3124791383743286, avg loss: 1.3152386665344238\n",
      "trial: 1, iter: 13000, curr loss: 1.3501324653625488, avg loss: 1.3127332097291946\n",
      "trial: 1, iter: 13200, curr loss: 1.334633231163025, avg loss: 1.3165757590532303\n",
      "trial: 1, iter: 13400, curr loss: 1.3554555177688599, avg loss: 1.3148541182279587\n",
      "trial: 1, iter: 13600, curr loss: 1.324720025062561, avg loss: 1.3151827335357666\n",
      "trial: 1, iter: 13800, curr loss: 1.3110464811325073, avg loss: 1.3152496635913848\n",
      "trial: 1, iter: 14000, curr loss: 1.3531556129455566, avg loss: 1.3153129351139068\n",
      "trial: 1, iter: 14200, curr loss: 1.3185657262802124, avg loss: 1.3141501134634017\n",
      "trial: 1, iter: 14400, curr loss: 1.3240760564804077, avg loss: 1.3149696296453477\n",
      "trial: 1, iter: 14600, curr loss: 1.3375494480133057, avg loss: 1.314428106546402\n",
      "trial: 1, iter: 14800, curr loss: 1.3168847560882568, avg loss: 1.3127086555957794\n",
      "trial: 1, iter: 15000, curr loss: 1.3112455606460571, avg loss: 1.3143754839897155\n",
      "trial: 1, iter: 15200, curr loss: 1.3119145631790161, avg loss: 1.313792694211006\n",
      "trial: 1, iter: 15400, curr loss: 1.3013861179351807, avg loss: 1.3136052638292313\n",
      "trial: 1, iter: 15600, curr loss: 1.2781877517700195, avg loss: 1.3140161979198455\n",
      "trial: 1, ldr: 0.32945963740348816\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3861887454986572, avg loss: 1.3872078889608384\n",
      "trial: 2, iter: 400, curr loss: 1.3858035802841187, avg loss: 1.386668382883072\n",
      "trial: 2, iter: 600, curr loss: 1.385833978652954, avg loss: 1.386544054746628\n",
      "trial: 2, iter: 800, curr loss: 1.3841960430145264, avg loss: 1.3866095900535584\n",
      "trial: 2, iter: 1000, curr loss: 1.3859573602676392, avg loss: 1.3863907879590989\n",
      "trial: 2, iter: 1200, curr loss: 1.3856921195983887, avg loss: 1.3864226889610292\n",
      "trial: 2, iter: 1400, curr loss: 1.3872932195663452, avg loss: 1.3864031851291656\n",
      "trial: 2, iter: 1600, curr loss: 1.3861641883850098, avg loss: 1.3863768464326858\n",
      "trial: 2, iter: 1800, curr loss: 1.3878192901611328, avg loss: 1.3864250880479814\n",
      "trial: 2, iter: 2000, curr loss: 1.3852416276931763, avg loss: 1.3863185447454454\n",
      "trial: 2, iter: 2200, curr loss: 1.3863153457641602, avg loss: 1.3863215559720994\n",
      "trial: 2, iter: 2400, curr loss: 1.3874467611312866, avg loss: 1.3863072574138642\n",
      "trial: 2, iter: 2600, curr loss: 1.3857173919677734, avg loss: 1.386284058690071\n",
      "trial: 2, iter: 2800, curr loss: 1.3855094909667969, avg loss: 1.3862994176149368\n",
      "trial: 2, iter: 3000, curr loss: 1.3859901428222656, avg loss: 1.3863527649641036\n",
      "trial: 2, iter: 3200, curr loss: 1.3857686519622803, avg loss: 1.3863028573989868\n",
      "trial: 2, iter: 3400, curr loss: 1.3867402076721191, avg loss: 1.386372155547142\n",
      "trial: 2, iter: 3600, curr loss: 1.38663911819458, avg loss: 1.3863322615623475\n",
      "trial: 2, iter: 3800, curr loss: 1.3858840465545654, avg loss: 1.3863457077741623\n",
      "trial: 2, iter: 4000, curr loss: 1.386652946472168, avg loss: 1.3864090609550477\n",
      "trial: 2, iter: 4200, curr loss: 1.386681318283081, avg loss: 1.3863368105888367\n",
      "trial: 2, iter: 4400, curr loss: 1.387410283088684, avg loss: 1.38638340651989\n",
      "trial: 2, iter: 4600, curr loss: 1.3864820003509521, avg loss: 1.386329738497734\n",
      "trial: 2, iter: 4800, curr loss: 1.3863409757614136, avg loss: 1.3863641768693924\n",
      "trial: 2, iter: 5000, curr loss: 1.386318325996399, avg loss: 1.3863360011577606\n",
      "trial: 2, iter: 5200, curr loss: 1.3852685689926147, avg loss: 1.3863190752267838\n",
      "trial: 2, iter: 5400, curr loss: 1.3854994773864746, avg loss: 1.386326121687889\n",
      "trial: 2, iter: 5600, curr loss: 1.3863061666488647, avg loss: 1.3863038623332977\n",
      "trial: 2, iter: 5800, curr loss: 1.3861258029937744, avg loss: 1.3862523317337037\n",
      "trial: 2, iter: 6000, curr loss: 1.3861351013183594, avg loss: 1.386290983557701\n",
      "trial: 2, iter: 6200, curr loss: 1.384590983390808, avg loss: 1.3859585309028626\n",
      "trial: 2, iter: 6400, curr loss: 1.3818987607955933, avg loss: 1.3842281937599181\n",
      "trial: 2, iter: 6600, curr loss: 1.3827006816864014, avg loss: 1.3816015613079071\n",
      "trial: 2, iter: 6800, curr loss: 1.3742464780807495, avg loss: 1.3713875913619995\n",
      "trial: 2, iter: 7000, curr loss: 1.3518959283828735, avg loss: 1.3643731260299683\n",
      "trial: 2, iter: 7200, curr loss: 1.3687340021133423, avg loss: 1.3600202643871306\n",
      "trial: 2, iter: 7400, curr loss: 1.3475266695022583, avg loss: 1.3550657057762145\n",
      "trial: 2, iter: 7600, curr loss: 1.347212553024292, avg loss: 1.351086049079895\n",
      "trial: 2, iter: 7800, curr loss: 1.3416476249694824, avg loss: 1.344521186351776\n",
      "trial: 2, iter: 8000, curr loss: 1.3124887943267822, avg loss: 1.3400577998161316\n",
      "trial: 2, iter: 8200, curr loss: 1.3266843557357788, avg loss: 1.3320449936389922\n",
      "trial: 2, iter: 8400, curr loss: 1.3376002311706543, avg loss: 1.3310057520866394\n",
      "trial: 2, iter: 8600, curr loss: 1.3435207605361938, avg loss: 1.326539732813835\n",
      "trial: 2, iter: 8800, curr loss: 1.3256977796554565, avg loss: 1.3246422612667084\n",
      "trial: 2, iter: 9000, curr loss: 1.3276005983352661, avg loss: 1.3242411285638809\n",
      "trial: 2, iter: 9200, curr loss: 1.2764326333999634, avg loss: 1.3213983047008515\n",
      "trial: 2, iter: 9400, curr loss: 1.3041249513626099, avg loss: 1.3229130381345748\n",
      "trial: 2, iter: 9600, curr loss: 1.3091676235198975, avg loss: 1.3209814518690108\n",
      "trial: 2, iter: 9800, curr loss: 1.3244478702545166, avg loss: 1.3192078655958175\n",
      "trial: 2, iter: 10000, curr loss: 1.335866093635559, avg loss: 1.3208138018846511\n",
      "trial: 2, iter: 10200, curr loss: 1.3311806917190552, avg loss: 1.319589136838913\n",
      "trial: 2, iter: 10400, curr loss: 1.349151849746704, avg loss: 1.3177279472351073\n",
      "trial: 2, iter: 10600, curr loss: 1.3229166269302368, avg loss: 1.3183908808231353\n",
      "trial: 2, iter: 10800, curr loss: 1.3383294343948364, avg loss: 1.3172303408384323\n",
      "trial: 2, iter: 11000, curr loss: 1.3236114978790283, avg loss: 1.3181998854875565\n",
      "trial: 2, iter: 11200, curr loss: 1.317277193069458, avg loss: 1.3199710136651992\n",
      "trial: 2, iter: 11400, curr loss: 1.3034331798553467, avg loss: 1.3200462597608567\n",
      "trial: 2, iter: 11600, curr loss: 1.3038386106491089, avg loss: 1.3173951727151871\n",
      "trial: 2, iter: 11800, curr loss: 1.3332258462905884, avg loss: 1.3180081254243852\n",
      "trial: 2, iter: 12000, curr loss: 1.3074020147323608, avg loss: 1.31736942589283\n",
      "trial: 2, iter: 12200, curr loss: 1.3147547245025635, avg loss: 1.3162347054481507\n",
      "trial: 2, iter: 12400, curr loss: 1.3058724403381348, avg loss: 1.319002902507782\n",
      "trial: 2, iter: 12600, curr loss: 1.310990810394287, avg loss: 1.3160131734609604\n",
      "trial: 2, iter: 12800, curr loss: 1.3286426067352295, avg loss: 1.3175376129150391\n",
      "trial: 2, iter: 13000, curr loss: 1.3299570083618164, avg loss: 1.3178897720575333\n",
      "trial: 2, iter: 13200, curr loss: 1.3166111707687378, avg loss: 1.3171294808387757\n",
      "trial: 2, iter: 13400, curr loss: 1.2994948625564575, avg loss: 1.3153732949495316\n",
      "trial: 2, iter: 13600, curr loss: 1.3421391248703003, avg loss: 1.3193880021572113\n",
      "trial: 2, iter: 13800, curr loss: 1.296081304550171, avg loss: 1.316949406862259\n",
      "trial: 2, iter: 14000, curr loss: 1.3345626592636108, avg loss: 1.3172282820940018\n",
      "trial: 2, iter: 14200, curr loss: 1.3260817527770996, avg loss: 1.3166785556077958\n",
      "trial: 2, iter: 14400, curr loss: 1.3132234811782837, avg loss: 1.3170122480392457\n",
      "trial: 2, iter: 14600, curr loss: 1.3053269386291504, avg loss: 1.3166963040828705\n",
      "trial: 2, iter: 14800, curr loss: 1.2900848388671875, avg loss: 1.3130306112766266\n",
      "trial: 2, iter: 15000, curr loss: 1.3139545917510986, avg loss: 1.3153931766748428\n",
      "trial: 2, iter: 15200, curr loss: 1.3198987245559692, avg loss: 1.3171533554792405\n",
      "trial: 2, iter: 15400, curr loss: 1.331710696220398, avg loss: 1.3166426593065261\n",
      "trial: 2, iter: 15600, curr loss: 1.3416916131973267, avg loss: 1.3158003741502762\n",
      "trial: 2, ldr: 0.29532501101493835\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3870255947113037, avg loss: 1.3874398350715638\n",
      "trial: 3, iter: 400, curr loss: 1.3845329284667969, avg loss: 1.3867812222242355\n",
      "trial: 3, iter: 600, curr loss: 1.3866769075393677, avg loss: 1.3866058391332627\n",
      "trial: 3, iter: 800, curr loss: 1.387734055519104, avg loss: 1.386733250617981\n",
      "trial: 3, iter: 1000, curr loss: 1.3881818056106567, avg loss: 1.3864659970998765\n",
      "trial: 3, iter: 1200, curr loss: 1.388197898864746, avg loss: 1.3865822476148606\n",
      "trial: 3, iter: 1400, curr loss: 1.387488603591919, avg loss: 1.3864189386367798\n",
      "trial: 3, iter: 1600, curr loss: 1.3861192464828491, avg loss: 1.3864622724056244\n",
      "trial: 3, iter: 1800, curr loss: 1.3864350318908691, avg loss: 1.3864446896314622\n",
      "trial: 3, iter: 2000, curr loss: 1.3867703676223755, avg loss: 1.3863941609859467\n",
      "trial: 3, iter: 2200, curr loss: 1.387687087059021, avg loss: 1.3863012397289276\n",
      "trial: 3, iter: 2400, curr loss: 1.387213110923767, avg loss: 1.3864920544624328\n",
      "trial: 3, iter: 2600, curr loss: 1.3866002559661865, avg loss: 1.386364706158638\n",
      "trial: 3, iter: 2800, curr loss: 1.3869545459747314, avg loss: 1.3862932115793227\n",
      "trial: 3, iter: 3000, curr loss: 1.3859002590179443, avg loss: 1.386367991566658\n",
      "trial: 3, iter: 3200, curr loss: 1.386131763458252, avg loss: 1.3863305366039276\n",
      "trial: 3, iter: 3400, curr loss: 1.3865700960159302, avg loss: 1.3863615590333938\n",
      "trial: 3, iter: 3600, curr loss: 1.3861058950424194, avg loss: 1.3863260608911514\n",
      "trial: 3, iter: 3800, curr loss: 1.3869529962539673, avg loss: 1.3863264918327332\n",
      "trial: 3, iter: 4000, curr loss: 1.3856463432312012, avg loss: 1.386280251145363\n",
      "trial: 3, iter: 4200, curr loss: 1.3867604732513428, avg loss: 1.3863640129566193\n",
      "trial: 3, iter: 4400, curr loss: 1.3865132331848145, avg loss: 1.386307517886162\n",
      "trial: 3, iter: 4600, curr loss: 1.3861171007156372, avg loss: 1.3862826579809189\n",
      "trial: 3, iter: 4800, curr loss: 1.3856639862060547, avg loss: 1.386316864490509\n",
      "trial: 3, iter: 5000, curr loss: 1.3866503238677979, avg loss: 1.3862983119487762\n",
      "trial: 3, iter: 5200, curr loss: 1.3858516216278076, avg loss: 1.3863049429655074\n",
      "trial: 3, iter: 5400, curr loss: 1.385834813117981, avg loss: 1.3862973070144653\n",
      "trial: 3, iter: 5600, curr loss: 1.3857462406158447, avg loss: 1.3863560271263122\n",
      "trial: 3, iter: 5800, curr loss: 1.3864233493804932, avg loss: 1.3863506239652634\n",
      "trial: 3, iter: 6000, curr loss: 1.3866260051727295, avg loss: 1.3863667905330659\n",
      "trial: 3, iter: 6200, curr loss: 1.3865931034088135, avg loss: 1.3863336688280106\n",
      "trial: 3, iter: 6400, curr loss: 1.3865913152694702, avg loss: 1.3863141876459122\n",
      "trial: 3, iter: 6600, curr loss: 1.386451244354248, avg loss: 1.386305638551712\n",
      "trial: 3, iter: 6800, curr loss: 1.3863341808319092, avg loss: 1.3863268953561783\n",
      "trial: 3, iter: 7000, curr loss: 1.3860183954238892, avg loss: 1.3863143914937972\n",
      "trial: 3, iter: 7200, curr loss: 1.3861992359161377, avg loss: 1.3863040763139725\n",
      "trial: 3, iter: 7400, curr loss: 1.3864248991012573, avg loss: 1.3862935876846314\n",
      "trial: 3, iter: 7600, curr loss: 1.385614275932312, avg loss: 1.3862865555286408\n",
      "trial: 3, iter: 7800, curr loss: 1.3862347602844238, avg loss: 1.3862560945749283\n",
      "trial: 3, iter: 8000, curr loss: 1.3863568305969238, avg loss: 1.3863898509740828\n",
      "trial: 3, iter: 8200, curr loss: 1.385819911956787, avg loss: 1.386296575665474\n",
      "trial: 3, iter: 8400, curr loss: 1.3865280151367188, avg loss: 1.386338456273079\n",
      "trial: 3, iter: 8600, curr loss: 1.3863112926483154, avg loss: 1.3862746012210847\n",
      "trial: 3, iter: 8800, curr loss: 1.3873167037963867, avg loss: 1.3863182222843171\n",
      "trial: 3, iter: 9000, curr loss: 1.3875161409378052, avg loss: 1.386297842860222\n",
      "trial: 3, iter: 9200, curr loss: 1.3859671354293823, avg loss: 1.3862888771295547\n",
      "trial: 3, iter: 9400, curr loss: 1.38186776638031, avg loss: 1.385478390455246\n",
      "trial: 3, iter: 9600, curr loss: 1.38626229763031, avg loss: 1.3806390690803527\n",
      "trial: 3, iter: 9800, curr loss: 1.358796238899231, avg loss: 1.3750023311376571\n",
      "trial: 3, iter: 10000, curr loss: 1.3720588684082031, avg loss: 1.368348777294159\n",
      "trial: 3, iter: 10200, curr loss: 1.3477953672409058, avg loss: 1.3636735993623734\n",
      "trial: 3, iter: 10400, curr loss: 1.3613340854644775, avg loss: 1.362022008895874\n",
      "trial: 3, iter: 10600, curr loss: 1.3510029315948486, avg loss: 1.3570091551542283\n",
      "trial: 3, iter: 10800, curr loss: 1.3308770656585693, avg loss: 1.354810712337494\n",
      "trial: 3, iter: 11000, curr loss: 1.3171762228012085, avg loss: 1.3516350799798966\n",
      "trial: 3, iter: 11200, curr loss: 1.339033603668213, avg loss: 1.3457393395900725\n",
      "trial: 3, iter: 11400, curr loss: 1.3688844442367554, avg loss: 1.343406239748001\n",
      "trial: 3, iter: 11600, curr loss: 1.3284140825271606, avg loss: 1.3378978949785232\n",
      "trial: 3, iter: 11800, curr loss: 1.3383899927139282, avg loss: 1.3370551753044129\n",
      "trial: 3, iter: 12000, curr loss: 1.3543204069137573, avg loss: 1.3342195904254914\n",
      "trial: 3, iter: 12200, curr loss: 1.3232215642929077, avg loss: 1.33099338889122\n",
      "trial: 3, iter: 12400, curr loss: 1.3363063335418701, avg loss: 1.3301301962137222\n",
      "trial: 3, iter: 12600, curr loss: 1.3353906869888306, avg loss: 1.329578878879547\n",
      "trial: 3, iter: 12800, curr loss: 1.3427848815917969, avg loss: 1.325215426683426\n",
      "trial: 3, iter: 13000, curr loss: 1.3250247240066528, avg loss: 1.3254674780368805\n",
      "trial: 3, iter: 13200, curr loss: 1.3173086643218994, avg loss: 1.3252722865343094\n",
      "trial: 3, iter: 13400, curr loss: 1.308097004890442, avg loss: 1.3243849772214888\n",
      "trial: 3, iter: 13600, curr loss: 1.3396328687667847, avg loss: 1.3199023389816285\n",
      "trial: 3, iter: 13800, curr loss: 1.3291593790054321, avg loss: 1.3211033976078033\n",
      "trial: 3, iter: 14000, curr loss: 1.3055135011672974, avg loss: 1.321332617998123\n",
      "trial: 3, iter: 14200, curr loss: 1.3260961771011353, avg loss: 1.320752158164978\n",
      "trial: 3, iter: 14400, curr loss: 1.334136724472046, avg loss: 1.32100323677063\n",
      "trial: 3, iter: 14600, curr loss: 1.3544731140136719, avg loss: 1.3207651245594025\n",
      "trial: 3, iter: 14800, curr loss: 1.3028820753097534, avg loss: 1.3190655583143234\n",
      "trial: 3, iter: 15000, curr loss: 1.3141955137252808, avg loss: 1.3195901185274124\n",
      "trial: 3, iter: 15200, curr loss: 1.3254390954971313, avg loss: 1.3166616398096085\n",
      "trial: 3, iter: 15400, curr loss: 1.334917426109314, avg loss: 1.3198030471801758\n",
      "trial: 3, iter: 15600, curr loss: 1.3020814657211304, avg loss: 1.3171250450611114\n",
      "trial: 3, ldr: 0.2945897877216339\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3845012187957764, avg loss: 1.387703664302826\n",
      "trial: 4, iter: 400, curr loss: 1.3870326280593872, avg loss: 1.3867316102981568\n",
      "trial: 4, iter: 600, curr loss: 1.387640357017517, avg loss: 1.3866225951910018\n",
      "trial: 4, iter: 800, curr loss: 1.38705575466156, avg loss: 1.386533762216568\n",
      "trial: 4, iter: 1000, curr loss: 1.3855111598968506, avg loss: 1.386485944390297\n",
      "trial: 4, iter: 1200, curr loss: 1.386839747428894, avg loss: 1.38640199303627\n",
      "trial: 4, iter: 1400, curr loss: 1.3871572017669678, avg loss: 1.3863962370157241\n",
      "trial: 4, iter: 1600, curr loss: 1.3858656883239746, avg loss: 1.3863335704803468\n",
      "trial: 4, iter: 1800, curr loss: 1.385377049446106, avg loss: 1.3864268481731414\n",
      "trial: 4, iter: 2000, curr loss: 1.386108636856079, avg loss: 1.3864991372823716\n",
      "trial: 4, iter: 2200, curr loss: 1.3860931396484375, avg loss: 1.3863587832450868\n",
      "trial: 4, iter: 2400, curr loss: 1.3868837356567383, avg loss: 1.3863786572217942\n",
      "trial: 4, iter: 2600, curr loss: 1.3860878944396973, avg loss: 1.3863389158248902\n",
      "trial: 4, iter: 2800, curr loss: 1.3857439756393433, avg loss: 1.3863233929872514\n",
      "trial: 4, iter: 3000, curr loss: 1.3861992359161377, avg loss: 1.3863512891530991\n",
      "trial: 4, iter: 3200, curr loss: 1.387162685394287, avg loss: 1.3863484382629394\n",
      "trial: 4, iter: 3400, curr loss: 1.3856230974197388, avg loss: 1.3863654404878616\n",
      "trial: 4, iter: 3600, curr loss: 1.3874280452728271, avg loss: 1.386253091096878\n",
      "trial: 4, iter: 3800, curr loss: 1.3875821828842163, avg loss: 1.3864375418424606\n",
      "trial: 4, iter: 4000, curr loss: 1.385371446609497, avg loss: 1.3863264852762223\n",
      "trial: 4, iter: 4200, curr loss: 1.386536955833435, avg loss: 1.3863111752271653\n",
      "trial: 4, iter: 4400, curr loss: 1.3865399360656738, avg loss: 1.3863077092170715\n",
      "trial: 4, iter: 4600, curr loss: 1.3871484994888306, avg loss: 1.3863261419534683\n",
      "trial: 4, iter: 4800, curr loss: 1.3846806287765503, avg loss: 1.3862491691112517\n",
      "trial: 4, iter: 5000, curr loss: 1.387803077697754, avg loss: 1.3864413595199585\n",
      "trial: 4, iter: 5200, curr loss: 1.3864597082138062, avg loss: 1.3863620936870575\n",
      "trial: 4, iter: 5400, curr loss: 1.3861148357391357, avg loss: 1.3863495296239854\n",
      "trial: 4, iter: 5600, curr loss: 1.385585069656372, avg loss: 1.3862844914197923\n",
      "trial: 4, iter: 5800, curr loss: 1.3864240646362305, avg loss: 1.3863180482387543\n",
      "trial: 4, iter: 6000, curr loss: 1.3863469362258911, avg loss: 1.3863186103105545\n",
      "trial: 4, iter: 6200, curr loss: 1.385872721672058, avg loss: 1.3863073343038559\n",
      "trial: 4, iter: 6400, curr loss: 1.3868408203125, avg loss: 1.3862558150291442\n",
      "trial: 4, iter: 6600, curr loss: 1.383384346961975, avg loss: 1.3859659522771834\n",
      "trial: 4, iter: 6800, curr loss: 1.3759446144104004, avg loss: 1.3847052824497224\n",
      "trial: 4, iter: 7000, curr loss: 1.3812534809112549, avg loss: 1.3823764055967331\n",
      "trial: 4, iter: 7200, curr loss: 1.3868516683578491, avg loss: 1.3792223620414734\n",
      "trial: 4, iter: 7400, curr loss: 1.385825514793396, avg loss: 1.3765365725755692\n",
      "trial: 4, iter: 7600, curr loss: 1.3728265762329102, avg loss: 1.373476465344429\n",
      "trial: 4, iter: 7800, curr loss: 1.367232084274292, avg loss: 1.3688020449876785\n",
      "trial: 4, iter: 8000, curr loss: 1.3617478609085083, avg loss: 1.3644874614477158\n",
      "trial: 4, iter: 8200, curr loss: 1.3645936250686646, avg loss: 1.3604119050502776\n",
      "trial: 4, iter: 8400, curr loss: 1.362400770187378, avg loss: 1.3575672644376755\n",
      "trial: 4, iter: 8600, curr loss: 1.3581500053405762, avg loss: 1.3562238669395448\n",
      "trial: 4, iter: 8800, curr loss: 1.3759725093841553, avg loss: 1.3552348697185517\n",
      "trial: 4, iter: 9000, curr loss: 1.3519086837768555, avg loss: 1.3522780913114547\n",
      "trial: 4, iter: 9200, curr loss: 1.3271284103393555, avg loss: 1.348201080560684\n",
      "trial: 4, iter: 9400, curr loss: 1.331835150718689, avg loss: 1.346062540411949\n",
      "trial: 4, iter: 9600, curr loss: 1.344378113746643, avg loss: 1.3407090824842454\n",
      "trial: 4, iter: 9800, curr loss: 1.3339184522628784, avg loss: 1.3339372617006302\n",
      "trial: 4, iter: 10000, curr loss: 1.3095365762710571, avg loss: 1.3323487430810927\n",
      "trial: 4, iter: 10200, curr loss: 1.3126933574676514, avg loss: 1.3335752111673356\n",
      "trial: 4, iter: 10400, curr loss: 1.3417010307312012, avg loss: 1.3295584696531295\n",
      "trial: 4, iter: 10600, curr loss: 1.3209556341171265, avg loss: 1.3271950441598892\n",
      "trial: 4, iter: 10800, curr loss: 1.3451000452041626, avg loss: 1.3272463548183442\n",
      "trial: 4, iter: 11000, curr loss: 1.317124366760254, avg loss: 1.325319246649742\n",
      "trial: 4, iter: 11200, curr loss: 1.3305284976959229, avg loss: 1.3249197322130204\n",
      "trial: 4, iter: 11400, curr loss: 1.3287817239761353, avg loss: 1.323080499768257\n",
      "trial: 4, iter: 11600, curr loss: 1.3285764455795288, avg loss: 1.3227220052480697\n",
      "trial: 4, iter: 11800, curr loss: 1.3234972953796387, avg loss: 1.322617300748825\n",
      "trial: 4, iter: 12000, curr loss: 1.3030493259429932, avg loss: 1.320353388786316\n",
      "trial: 4, iter: 12200, curr loss: 1.319306492805481, avg loss: 1.32199200630188\n",
      "trial: 4, iter: 12400, curr loss: 1.3362957239151, avg loss: 1.3198551243543626\n",
      "trial: 4, iter: 12600, curr loss: 1.3118252754211426, avg loss: 1.3197892874479293\n",
      "trial: 4, iter: 12800, curr loss: 1.2985605001449585, avg loss: 1.318713089823723\n",
      "trial: 4, iter: 13000, curr loss: 1.2934015989303589, avg loss: 1.318233273625374\n",
      "trial: 4, iter: 13200, curr loss: 1.3331326246261597, avg loss: 1.3202342927455901\n",
      "trial: 4, iter: 13400, curr loss: 1.3022375106811523, avg loss: 1.3187225669622422\n",
      "trial: 4, iter: 13600, curr loss: 1.3119124174118042, avg loss: 1.3195157170295715\n",
      "trial: 4, iter: 13800, curr loss: 1.331533432006836, avg loss: 1.3187706261873244\n",
      "trial: 4, iter: 14000, curr loss: 1.3031095266342163, avg loss: 1.3185253727436066\n",
      "trial: 4, iter: 14200, curr loss: 1.2884169816970825, avg loss: 1.3168386620283128\n",
      "trial: 4, iter: 14400, curr loss: 1.3293308019638062, avg loss: 1.317656129002571\n",
      "trial: 4, iter: 14600, curr loss: 1.3099772930145264, avg loss: 1.3148474484682082\n",
      "trial: 4, iter: 14800, curr loss: 1.326770544052124, avg loss: 1.3155159801244736\n",
      "trial: 4, iter: 15000, curr loss: 1.3198063373565674, avg loss: 1.3186380219459535\n",
      "trial: 4, iter: 15200, curr loss: 1.3172227144241333, avg loss: 1.31873619556427\n",
      "trial: 4, iter: 15400, curr loss: 1.3120323419570923, avg loss: 1.3187062042951583\n",
      "trial: 4, iter: 15600, curr loss: 1.3128005266189575, avg loss: 1.3174301391839982\n",
      "trial: 4, ldr: 0.32776761054992676\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3849620819091797, avg loss: 1.3871867084503173\n",
      "trial: 5, iter: 400, curr loss: 1.3851633071899414, avg loss: 1.3867607128620147\n",
      "trial: 5, iter: 600, curr loss: 1.3877503871917725, avg loss: 1.3866873878240584\n",
      "trial: 5, iter: 800, curr loss: 1.3865221738815308, avg loss: 1.3865216642618179\n",
      "trial: 5, iter: 1000, curr loss: 1.3848241567611694, avg loss: 1.386506769657135\n",
      "trial: 5, iter: 1200, curr loss: 1.386043667793274, avg loss: 1.386413081884384\n",
      "trial: 5, iter: 1400, curr loss: 1.3859690427780151, avg loss: 1.3863399565219878\n",
      "trial: 5, iter: 1600, curr loss: 1.3865817785263062, avg loss: 1.38644214451313\n",
      "trial: 5, iter: 1800, curr loss: 1.3867344856262207, avg loss: 1.386419575214386\n",
      "trial: 5, iter: 2000, curr loss: 1.3857553005218506, avg loss: 1.3863422632217408\n",
      "trial: 5, iter: 2200, curr loss: 1.3855865001678467, avg loss: 1.3863041555881501\n",
      "trial: 5, iter: 2400, curr loss: 1.3858352899551392, avg loss: 1.3863501578569413\n",
      "trial: 5, iter: 2600, curr loss: 1.3855767250061035, avg loss: 1.38633249938488\n",
      "trial: 5, iter: 2800, curr loss: 1.386818289756775, avg loss: 1.3863502568006516\n",
      "trial: 5, iter: 3000, curr loss: 1.386146068572998, avg loss: 1.386390398144722\n",
      "trial: 5, iter: 3200, curr loss: 1.3868316411972046, avg loss: 1.3863796281814575\n",
      "trial: 5, iter: 3400, curr loss: 1.387125015258789, avg loss: 1.386321383714676\n",
      "trial: 5, iter: 3600, curr loss: 1.3864753246307373, avg loss: 1.3863190907239913\n",
      "trial: 5, iter: 3800, curr loss: 1.386493444442749, avg loss: 1.3863555872440338\n",
      "trial: 5, iter: 4000, curr loss: 1.387244462966919, avg loss: 1.3863224363327027\n",
      "trial: 5, iter: 4200, curr loss: 1.3856953382492065, avg loss: 1.3863722509145737\n",
      "trial: 5, iter: 4400, curr loss: 1.3868989944458008, avg loss: 1.386333179473877\n",
      "trial: 5, iter: 4600, curr loss: 1.3869411945343018, avg loss: 1.3863111728429793\n",
      "trial: 5, iter: 4800, curr loss: 1.3860749006271362, avg loss: 1.3863208037614823\n",
      "trial: 5, iter: 5000, curr loss: 1.386820673942566, avg loss: 1.3863423925638199\n",
      "trial: 5, iter: 5200, curr loss: 1.3860145807266235, avg loss: 1.3863471341133118\n",
      "trial: 5, iter: 5400, curr loss: 1.38694167137146, avg loss: 1.3863394725322724\n",
      "trial: 5, iter: 5600, curr loss: 1.3856817483901978, avg loss: 1.386386347413063\n",
      "trial: 5, iter: 5800, curr loss: 1.3866543769836426, avg loss: 1.3864113402366638\n",
      "trial: 5, iter: 6000, curr loss: 1.3860174417495728, avg loss: 1.3863358855247498\n",
      "trial: 5, iter: 6200, curr loss: 1.38625967502594, avg loss: 1.3864295369386672\n",
      "trial: 5, iter: 6400, curr loss: 1.3865240812301636, avg loss: 1.3863622593879699\n",
      "trial: 5, iter: 6600, curr loss: 1.3870186805725098, avg loss: 1.386265367269516\n",
      "trial: 5, iter: 6800, curr loss: 1.3853800296783447, avg loss: 1.3864021766185761\n",
      "trial: 5, iter: 7000, curr loss: 1.3854365348815918, avg loss: 1.386331575512886\n",
      "trial: 5, iter: 7200, curr loss: 1.3856858015060425, avg loss: 1.3863237112760545\n",
      "trial: 5, iter: 7400, curr loss: 1.3872824907302856, avg loss: 1.3863919258117676\n",
      "trial: 5, iter: 7600, curr loss: 1.3849773406982422, avg loss: 1.3862793338298798\n",
      "trial: 5, iter: 7800, curr loss: 1.3866559267044067, avg loss: 1.3861680597066879\n",
      "trial: 5, iter: 8000, curr loss: 1.3851261138916016, avg loss: 1.3861172086000442\n",
      "trial: 5, iter: 8200, curr loss: 1.3860156536102295, avg loss: 1.3848286718130112\n",
      "trial: 5, iter: 8400, curr loss: 1.3702040910720825, avg loss: 1.3796897661685943\n",
      "trial: 5, iter: 8600, curr loss: 1.3698079586029053, avg loss: 1.3701836442947388\n",
      "trial: 5, iter: 8800, curr loss: 1.3715448379516602, avg loss: 1.3624556738138198\n",
      "trial: 5, iter: 9000, curr loss: 1.3597019910812378, avg loss: 1.3577849435806275\n",
      "trial: 5, iter: 9200, curr loss: 1.3253440856933594, avg loss: 1.3542516404390335\n",
      "trial: 5, iter: 9400, curr loss: 1.361061453819275, avg loss: 1.351470096707344\n",
      "trial: 5, iter: 9600, curr loss: 1.3430180549621582, avg loss: 1.349064993262291\n",
      "trial: 5, iter: 9800, curr loss: 1.315860390663147, avg loss: 1.3450188392400741\n",
      "trial: 5, iter: 10000, curr loss: 1.3194085359573364, avg loss: 1.3405056935548783\n",
      "trial: 5, iter: 10200, curr loss: 1.3457036018371582, avg loss: 1.3391214323043823\n",
      "trial: 5, iter: 10400, curr loss: 1.3128408193588257, avg loss: 1.3348084527254105\n",
      "trial: 5, iter: 10600, curr loss: 1.3021937608718872, avg loss: 1.33240567445755\n",
      "trial: 5, iter: 10800, curr loss: 1.318984866142273, avg loss: 1.330825846195221\n",
      "trial: 5, iter: 11000, curr loss: 1.336348533630371, avg loss: 1.3309988164901734\n",
      "trial: 5, iter: 11200, curr loss: 1.3143656253814697, avg loss: 1.3264960688352585\n",
      "trial: 5, iter: 11400, curr loss: 1.3075779676437378, avg loss: 1.3277520334720612\n",
      "trial: 5, iter: 11600, curr loss: 1.345857858657837, avg loss: 1.326147984266281\n",
      "trial: 5, iter: 11800, curr loss: 1.3159023523330688, avg loss: 1.3254634243249894\n",
      "trial: 5, iter: 12000, curr loss: 1.3163913488388062, avg loss: 1.3259498286247253\n",
      "trial: 5, iter: 12200, curr loss: 1.3437881469726562, avg loss: 1.3240673977136612\n",
      "trial: 5, iter: 12400, curr loss: 1.3220373392105103, avg loss: 1.3231970262527466\n",
      "trial: 5, iter: 12600, curr loss: 1.3568819761276245, avg loss: 1.3233727580308914\n",
      "trial: 5, iter: 12800, curr loss: 1.3275035619735718, avg loss: 1.3203609293699266\n",
      "trial: 5, iter: 13000, curr loss: 1.316204309463501, avg loss: 1.3217837285995484\n",
      "trial: 5, iter: 13200, curr loss: 1.3314632177352905, avg loss: 1.321977942585945\n",
      "trial: 5, iter: 13400, curr loss: 1.3138363361358643, avg loss: 1.3203908735513687\n",
      "trial: 5, iter: 13600, curr loss: 1.314941167831421, avg loss: 1.3212477105855942\n",
      "trial: 5, iter: 13800, curr loss: 1.2868022918701172, avg loss: 1.319542756676674\n",
      "trial: 5, iter: 14000, curr loss: 1.3239854574203491, avg loss: 1.3185035854578018\n",
      "trial: 5, iter: 14200, curr loss: 1.3027921915054321, avg loss: 1.3194727063179017\n",
      "trial: 5, iter: 14400, curr loss: 1.3107225894927979, avg loss: 1.3166033363342284\n",
      "trial: 5, iter: 14600, curr loss: 1.3337273597717285, avg loss: 1.3179362219572068\n",
      "trial: 5, iter: 14800, curr loss: 1.3088090419769287, avg loss: 1.3177741527557374\n",
      "trial: 5, iter: 15000, curr loss: 1.2873377799987793, avg loss: 1.3199885779619216\n",
      "trial: 5, iter: 15200, curr loss: 1.2879821062088013, avg loss: 1.3225135433673858\n",
      "trial: 5, iter: 15400, curr loss: 1.3029435873031616, avg loss: 1.3176810711622238\n",
      "trial: 5, iter: 15600, curr loss: 1.318673014640808, avg loss: 1.3185567623376846\n",
      "trial: 5, ldr: 0.3649669587612152\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.3224218010902405\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3844045400619507, avg loss: 1.3872309553623199\n",
      "trial: 1, iter: 400, curr loss: 1.3872536420822144, avg loss: 1.3869027292728424\n",
      "trial: 1, iter: 600, curr loss: 1.387485146522522, avg loss: 1.3866009134054185\n",
      "trial: 1, iter: 800, curr loss: 1.3863016366958618, avg loss: 1.386424857378006\n",
      "trial: 1, iter: 1000, curr loss: 1.3869291543960571, avg loss: 1.3864656728506088\n",
      "trial: 1, iter: 1200, curr loss: 1.3873310089111328, avg loss: 1.3864880305528642\n",
      "trial: 1, iter: 1400, curr loss: 1.3868333101272583, avg loss: 1.386317132115364\n",
      "trial: 1, iter: 1600, curr loss: 1.3871208429336548, avg loss: 1.386378108859062\n",
      "trial: 1, iter: 1800, curr loss: 1.3869072198867798, avg loss: 1.3864215224981309\n",
      "trial: 1, iter: 2000, curr loss: 1.3846955299377441, avg loss: 1.3862719660997391\n",
      "trial: 1, iter: 2200, curr loss: 1.3857433795928955, avg loss: 1.3864767915010452\n",
      "trial: 1, iter: 2400, curr loss: 1.386675477027893, avg loss: 1.3863086104393005\n",
      "trial: 1, iter: 2600, curr loss: 1.386296272277832, avg loss: 1.3863185560703277\n",
      "trial: 1, iter: 2800, curr loss: 1.3858627080917358, avg loss: 1.3864148384332657\n",
      "trial: 1, iter: 3000, curr loss: 1.3876835107803345, avg loss: 1.3863602459430695\n",
      "trial: 1, iter: 3200, curr loss: 1.38680100440979, avg loss: 1.386294881105423\n",
      "trial: 1, iter: 3400, curr loss: 1.3853256702423096, avg loss: 1.3862598556280137\n",
      "trial: 1, iter: 3600, curr loss: 1.3862727880477905, avg loss: 1.3862836754322052\n",
      "trial: 1, iter: 3800, curr loss: 1.3866602182388306, avg loss: 1.386357871890068\n",
      "trial: 1, iter: 4000, curr loss: 1.3864355087280273, avg loss: 1.3862804609537125\n",
      "trial: 1, iter: 4200, curr loss: 1.3864907026290894, avg loss: 1.3863771432638168\n",
      "trial: 1, iter: 4400, curr loss: 1.385482907295227, avg loss: 1.3863337153196336\n",
      "trial: 1, iter: 4600, curr loss: 1.3860673904418945, avg loss: 1.386311639547348\n",
      "trial: 1, iter: 4800, curr loss: 1.386006236076355, avg loss: 1.3862571263313292\n",
      "trial: 1, iter: 5000, curr loss: 1.3852535486221313, avg loss: 1.3860654133558272\n",
      "trial: 1, iter: 5200, curr loss: 1.3823784589767456, avg loss: 1.3848728489875795\n",
      "trial: 1, iter: 5400, curr loss: 1.3768515586853027, avg loss: 1.3828382623195647\n",
      "trial: 1, iter: 5600, curr loss: 1.3763682842254639, avg loss: 1.381419233083725\n",
      "trial: 1, iter: 5800, curr loss: 1.3648072481155396, avg loss: 1.3746735382080078\n",
      "trial: 1, iter: 6000, curr loss: 1.3581321239471436, avg loss: 1.3672880405187606\n",
      "trial: 1, iter: 6200, curr loss: 1.3625857830047607, avg loss: 1.3643745458126069\n",
      "trial: 1, iter: 6400, curr loss: 1.3660783767700195, avg loss: 1.3607841157913207\n",
      "trial: 1, iter: 6600, curr loss: 1.3707042932510376, avg loss: 1.3588705658912659\n",
      "trial: 1, iter: 6800, curr loss: 1.342663049697876, avg loss: 1.3575775384902955\n",
      "trial: 1, iter: 7000, curr loss: 1.3746271133422852, avg loss: 1.3567791253328323\n",
      "trial: 1, iter: 7200, curr loss: 1.3500820398330688, avg loss: 1.3575451451539993\n",
      "trial: 1, iter: 7400, curr loss: 1.32197105884552, avg loss: 1.3575256371498108\n",
      "trial: 1, iter: 7600, curr loss: 1.3398048877716064, avg loss: 1.3549456959962844\n",
      "trial: 1, iter: 7800, curr loss: 1.339905023574829, avg loss: 1.3546461933851242\n",
      "trial: 1, iter: 8000, curr loss: 1.3540091514587402, avg loss: 1.352204337120056\n",
      "trial: 1, iter: 8200, curr loss: 1.3411129713058472, avg loss: 1.3489201575517655\n",
      "trial: 1, iter: 8400, curr loss: 1.3408719301223755, avg loss: 1.3455655360221863\n",
      "trial: 1, iter: 8600, curr loss: 1.3299111127853394, avg loss: 1.3404880887269974\n",
      "trial: 1, iter: 8800, curr loss: 1.3224306106567383, avg loss: 1.337771034836769\n",
      "trial: 1, iter: 9000, curr loss: 1.3153833150863647, avg loss: 1.3315256124734878\n",
      "trial: 1, iter: 9200, curr loss: 1.345896601676941, avg loss: 1.3321588319540023\n",
      "trial: 1, iter: 9400, curr loss: 1.3047068119049072, avg loss: 1.3278825712203979\n",
      "trial: 1, iter: 9600, curr loss: 1.3242138624191284, avg loss: 1.325734493136406\n",
      "trial: 1, iter: 9800, curr loss: 1.3506253957748413, avg loss: 1.325986497402191\n",
      "trial: 1, iter: 10000, curr loss: 1.34232759475708, avg loss: 1.3258133155107499\n",
      "trial: 1, iter: 10200, curr loss: 1.332454800605774, avg loss: 1.324047446846962\n",
      "trial: 1, iter: 10400, curr loss: 1.3385446071624756, avg loss: 1.3239762037992477\n",
      "trial: 1, iter: 10600, curr loss: 1.3011680841445923, avg loss: 1.3228298431634904\n",
      "trial: 1, iter: 10800, curr loss: 1.336669683456421, avg loss: 1.3219955837726594\n",
      "trial: 1, iter: 11000, curr loss: 1.2794177532196045, avg loss: 1.323643496632576\n",
      "trial: 1, iter: 11200, curr loss: 1.315647840499878, avg loss: 1.3209476530551911\n",
      "trial: 1, iter: 11400, curr loss: 1.3693668842315674, avg loss: 1.3194540071487426\n",
      "trial: 1, iter: 11600, curr loss: 1.3082947731018066, avg loss: 1.320166426897049\n",
      "trial: 1, iter: 11800, curr loss: 1.3093632459640503, avg loss: 1.3196888464689254\n",
      "trial: 1, iter: 12000, curr loss: 1.2981096506118774, avg loss: 1.3180740338563919\n",
      "trial: 1, iter: 12200, curr loss: 1.3390374183654785, avg loss: 1.3206259727478027\n",
      "trial: 1, iter: 12400, curr loss: 1.312423825263977, avg loss: 1.3181391632556916\n",
      "trial: 1, iter: 12600, curr loss: 1.3011173009872437, avg loss: 1.319539913535118\n",
      "trial: 1, iter: 12800, curr loss: 1.3177704811096191, avg loss: 1.3177295798063278\n",
      "trial: 1, iter: 13000, curr loss: 1.306044578552246, avg loss: 1.318941566348076\n",
      "trial: 1, iter: 13200, curr loss: 1.3381078243255615, avg loss: 1.3179106003046035\n",
      "trial: 1, iter: 13400, curr loss: 1.330856442451477, avg loss: 1.3182099360227584\n",
      "trial: 1, iter: 13600, curr loss: 1.31132173538208, avg loss: 1.3177773588895798\n",
      "trial: 1, iter: 13800, curr loss: 1.3392239809036255, avg loss: 1.3165466570854187\n",
      "trial: 1, iter: 14000, curr loss: 1.3089851140975952, avg loss: 1.3182059383392335\n",
      "trial: 1, iter: 14200, curr loss: 1.307403326034546, avg loss: 1.318635811805725\n",
      "trial: 1, iter: 14400, curr loss: 1.3016626834869385, avg loss: 1.318996424674988\n",
      "trial: 1, iter: 14600, curr loss: 1.292582392692566, avg loss: 1.3214404702186584\n",
      "trial: 1, iter: 14800, curr loss: 1.300220251083374, avg loss: 1.3164175635576247\n",
      "trial: 1, iter: 15000, curr loss: 1.3441437482833862, avg loss: 1.3182091748714446\n",
      "trial: 1, iter: 15200, curr loss: 1.2979165315628052, avg loss: 1.3162609398365022\n",
      "trial: 1, iter: 15400, curr loss: 1.308443307876587, avg loss: 1.3186191719770433\n",
      "trial: 1, iter: 15600, curr loss: 1.3403706550598145, avg loss: 1.3165076631307602\n",
      "trial: 1, ldr: 0.4020417332649231\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3877848386764526, avg loss: 1.3872571498155595\n",
      "trial: 2, iter: 400, curr loss: 1.3847829103469849, avg loss: 1.3868948197364808\n",
      "trial: 2, iter: 600, curr loss: 1.3859498500823975, avg loss: 1.3866674047708512\n",
      "trial: 2, iter: 800, curr loss: 1.3861263990402222, avg loss: 1.3865034627914428\n",
      "trial: 2, iter: 1000, curr loss: 1.385966181755066, avg loss: 1.3864610582590102\n",
      "trial: 2, iter: 1200, curr loss: 1.385690450668335, avg loss: 1.3863674318790435\n",
      "trial: 2, iter: 1400, curr loss: 1.3864060640335083, avg loss: 1.3863338071107865\n",
      "trial: 2, iter: 1600, curr loss: 1.3855048418045044, avg loss: 1.386396192908287\n",
      "trial: 2, iter: 1800, curr loss: 1.384873867034912, avg loss: 1.3863101607561112\n",
      "trial: 2, iter: 2000, curr loss: 1.386433482170105, avg loss: 1.3864477360248566\n",
      "trial: 2, iter: 2200, curr loss: 1.3872933387756348, avg loss: 1.386308672428131\n",
      "trial: 2, iter: 2400, curr loss: 1.3870387077331543, avg loss: 1.3863752949237824\n",
      "trial: 2, iter: 2600, curr loss: 1.3863376379013062, avg loss: 1.3862719130516052\n",
      "trial: 2, iter: 2800, curr loss: 1.3860251903533936, avg loss: 1.3863885408639909\n",
      "trial: 2, iter: 3000, curr loss: 1.3864868879318237, avg loss: 1.3863196510076523\n",
      "trial: 2, iter: 3200, curr loss: 1.3865463733673096, avg loss: 1.3863251292705536\n",
      "trial: 2, iter: 3400, curr loss: 1.3856685161590576, avg loss: 1.3863012719154357\n",
      "trial: 2, iter: 3600, curr loss: 1.3860814571380615, avg loss: 1.38632344186306\n",
      "trial: 2, iter: 3800, curr loss: 1.386155605316162, avg loss: 1.386333368420601\n",
      "trial: 2, iter: 4000, curr loss: 1.3856984376907349, avg loss: 1.3862606739997865\n",
      "trial: 2, iter: 4200, curr loss: 1.3855184316635132, avg loss: 1.3862979263067245\n",
      "trial: 2, iter: 4400, curr loss: 1.3867605924606323, avg loss: 1.3863472086191178\n",
      "trial: 2, iter: 4600, curr loss: 1.386303424835205, avg loss: 1.386344667673111\n",
      "trial: 2, iter: 4800, curr loss: 1.386045217514038, avg loss: 1.3862854218482972\n",
      "trial: 2, iter: 5000, curr loss: 1.3866280317306519, avg loss: 1.3863006931543351\n",
      "trial: 2, iter: 5200, curr loss: 1.384789228439331, avg loss: 1.3862761873006821\n",
      "trial: 2, iter: 5400, curr loss: 1.3870257139205933, avg loss: 1.3863585394620896\n",
      "trial: 2, iter: 5600, curr loss: 1.3859412670135498, avg loss: 1.3863251554965972\n",
      "trial: 2, iter: 5800, curr loss: 1.386293649673462, avg loss: 1.3863207310438157\n",
      "trial: 2, iter: 6000, curr loss: 1.3859843015670776, avg loss: 1.3863264912366866\n",
      "trial: 2, iter: 6200, curr loss: 1.3864495754241943, avg loss: 1.3863032788038254\n",
      "trial: 2, iter: 6400, curr loss: 1.3865487575531006, avg loss: 1.386312234401703\n",
      "trial: 2, iter: 6600, curr loss: 1.38688325881958, avg loss: 1.3862854582071304\n",
      "trial: 2, iter: 6800, curr loss: 1.3860552310943604, avg loss: 1.3863252490758895\n",
      "trial: 2, iter: 7000, curr loss: 1.3864083290100098, avg loss: 1.386304236650467\n",
      "trial: 2, iter: 7200, curr loss: 1.3864225149154663, avg loss: 1.3863019281625748\n",
      "trial: 2, iter: 7400, curr loss: 1.385672926902771, avg loss: 1.386294355392456\n",
      "trial: 2, iter: 7600, curr loss: 1.3862078189849854, avg loss: 1.3863230729103089\n",
      "trial: 2, iter: 7800, curr loss: 1.386220097541809, avg loss: 1.386307371854782\n",
      "trial: 2, iter: 8000, curr loss: 1.3863131999969482, avg loss: 1.3863240456581116\n",
      "trial: 2, iter: 8200, curr loss: 1.3866796493530273, avg loss: 1.3863725519180299\n",
      "trial: 2, iter: 8400, curr loss: 1.38624906539917, avg loss: 1.386318218111992\n",
      "trial: 2, iter: 8600, curr loss: 1.3864928483963013, avg loss: 1.3863015633821487\n",
      "trial: 2, iter: 8800, curr loss: 1.385789394378662, avg loss: 1.3862688946723938\n",
      "trial: 2, iter: 9000, curr loss: 1.3868961334228516, avg loss: 1.3863384890556336\n",
      "trial: 2, iter: 9200, curr loss: 1.3860132694244385, avg loss: 1.3862637424468993\n",
      "trial: 2, iter: 9400, curr loss: 1.3860408067703247, avg loss: 1.3862867087125779\n",
      "trial: 2, iter: 9600, curr loss: 1.3855721950531006, avg loss: 1.3863093012571335\n",
      "trial: 2, iter: 9800, curr loss: 1.386552333831787, avg loss: 1.3862999033927919\n",
      "trial: 2, iter: 10000, curr loss: 1.3866164684295654, avg loss: 1.3863437569141388\n",
      "trial: 2, iter: 10200, curr loss: 1.3860138654708862, avg loss: 1.3863049358129502\n",
      "trial: 2, iter: 10400, curr loss: 1.3865606784820557, avg loss: 1.3862966418266296\n",
      "trial: 2, iter: 10600, curr loss: 1.3864493370056152, avg loss: 1.386308224797249\n",
      "trial: 2, iter: 10800, curr loss: 1.3855782747268677, avg loss: 1.3862800592184066\n",
      "trial: 2, iter: 11000, curr loss: 1.3860342502593994, avg loss: 1.3863092690706253\n",
      "trial: 2, iter: 11200, curr loss: 1.386462688446045, avg loss: 1.3863103169202804\n",
      "trial: 2, iter: 11400, curr loss: 1.3861336708068848, avg loss: 1.3862550586462021\n",
      "trial: 2, iter: 11600, curr loss: 1.38644540309906, avg loss: 1.3862722951173783\n",
      "trial: 2, iter: 11800, curr loss: 1.384838342666626, avg loss: 1.3863416004180908\n",
      "trial: 2, iter: 12000, curr loss: 1.3875398635864258, avg loss: 1.386297470331192\n",
      "trial: 2, iter: 12200, curr loss: 1.386985421180725, avg loss: 1.3862429457902907\n",
      "trial: 2, iter: 12400, curr loss: 1.3859891891479492, avg loss: 1.386266552209854\n",
      "trial: 2, iter: 12600, curr loss: 1.3863630294799805, avg loss: 1.3863534617424011\n",
      "trial: 2, iter: 12800, curr loss: 1.3845134973526, avg loss: 1.3862094461917878\n",
      "trial: 2, iter: 13000, curr loss: 1.386582851409912, avg loss: 1.386212918162346\n",
      "trial: 2, iter: 13200, curr loss: 1.3861863613128662, avg loss: 1.3862112045288086\n",
      "trial: 2, iter: 13400, curr loss: 1.386196494102478, avg loss: 1.3860988581180573\n",
      "trial: 2, iter: 13600, curr loss: 1.386127233505249, avg loss: 1.386209722161293\n",
      "trial: 2, iter: 13800, curr loss: 1.3870564699172974, avg loss: 1.3860805922746657\n",
      "trial: 2, iter: 14000, curr loss: 1.3843902349472046, avg loss: 1.386142105460167\n",
      "trial: 2, iter: 14200, curr loss: 1.3863415718078613, avg loss: 1.3860317093133927\n",
      "trial: 2, iter: 14400, curr loss: 1.3763411045074463, avg loss: 1.3857232058048248\n",
      "trial: 2, iter: 14600, curr loss: 1.3796043395996094, avg loss: 1.3846145313978195\n",
      "trial: 2, iter: 14800, curr loss: 1.3790870904922485, avg loss: 1.380835478901863\n",
      "trial: 2, iter: 15000, curr loss: 1.3796132802963257, avg loss: 1.3785479491949082\n",
      "trial: 2, iter: 15200, curr loss: 1.3652740716934204, avg loss: 1.37503821849823\n",
      "trial: 2, iter: 15400, curr loss: 1.3732138872146606, avg loss: 1.371727545261383\n",
      "trial: 2, iter: 15600, curr loss: 1.352925419807434, avg loss: 1.364406909942627\n",
      "trial: 2, ldr: 0.10208605229854584\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3859769105911255, avg loss: 1.3875356566905976\n",
      "trial: 3, iter: 400, curr loss: 1.3842957019805908, avg loss: 1.386771820783615\n",
      "trial: 3, iter: 600, curr loss: 1.3864725828170776, avg loss: 1.386654755473137\n",
      "trial: 3, iter: 800, curr loss: 1.3868663311004639, avg loss: 1.3867045032978058\n",
      "trial: 3, iter: 1000, curr loss: 1.386112928390503, avg loss: 1.386533843278885\n",
      "trial: 3, iter: 1200, curr loss: 1.3870387077331543, avg loss: 1.3864497369527817\n",
      "trial: 3, iter: 1400, curr loss: 1.3881428241729736, avg loss: 1.3865413522720338\n",
      "trial: 3, iter: 1600, curr loss: 1.3873227834701538, avg loss: 1.3864155501127242\n",
      "trial: 3, iter: 1800, curr loss: 1.386052131652832, avg loss: 1.3863180184364319\n",
      "trial: 3, iter: 2000, curr loss: 1.3870218992233276, avg loss: 1.3863982611894607\n",
      "trial: 3, iter: 2200, curr loss: 1.3869997262954712, avg loss: 1.3864267712831497\n",
      "trial: 3, iter: 2400, curr loss: 1.3853391408920288, avg loss: 1.3863492780923843\n",
      "trial: 3, iter: 2600, curr loss: 1.3863511085510254, avg loss: 1.3862452697753906\n",
      "trial: 3, iter: 2800, curr loss: 1.3878142833709717, avg loss: 1.3864351636171341\n",
      "trial: 3, iter: 3000, curr loss: 1.3864126205444336, avg loss: 1.3863850873708725\n",
      "trial: 3, iter: 3200, curr loss: 1.386938452720642, avg loss: 1.3863489264249802\n",
      "trial: 3, iter: 3400, curr loss: 1.3862061500549316, avg loss: 1.386330692768097\n",
      "trial: 3, iter: 3600, curr loss: 1.3864105939865112, avg loss: 1.386366589665413\n",
      "trial: 3, iter: 3800, curr loss: 1.386679768562317, avg loss: 1.386300465464592\n",
      "trial: 3, iter: 4000, curr loss: 1.3862096071243286, avg loss: 1.3862711745500564\n",
      "trial: 3, iter: 4200, curr loss: 1.385848879814148, avg loss: 1.3863147085905074\n",
      "trial: 3, iter: 4400, curr loss: 1.3879667520523071, avg loss: 1.3863327848911284\n",
      "trial: 3, iter: 4600, curr loss: 1.3855403661727905, avg loss: 1.3863937121629715\n",
      "trial: 3, iter: 4800, curr loss: 1.385561466217041, avg loss: 1.3863530510663986\n",
      "trial: 3, iter: 5000, curr loss: 1.3863904476165771, avg loss: 1.3863663643598556\n",
      "trial: 3, iter: 5200, curr loss: 1.3864009380340576, avg loss: 1.3863196176290513\n",
      "trial: 3, iter: 5400, curr loss: 1.3859177827835083, avg loss: 1.3863145738840104\n",
      "trial: 3, iter: 5600, curr loss: 1.3862025737762451, avg loss: 1.3863133412599564\n",
      "trial: 3, iter: 5800, curr loss: 1.3866816759109497, avg loss: 1.3863056737184525\n",
      "trial: 3, iter: 6000, curr loss: 1.3863201141357422, avg loss: 1.38631327688694\n",
      "trial: 3, iter: 6200, curr loss: 1.3868857622146606, avg loss: 1.3862940114736557\n",
      "trial: 3, iter: 6400, curr loss: 1.3864388465881348, avg loss: 1.3863106924295425\n",
      "trial: 3, iter: 6600, curr loss: 1.3858141899108887, avg loss: 1.3863151472806932\n",
      "trial: 3, iter: 6800, curr loss: 1.3859783411026, avg loss: 1.3863487923145295\n",
      "trial: 3, iter: 7000, curr loss: 1.3874237537384033, avg loss: 1.3863104635477066\n",
      "trial: 3, iter: 7200, curr loss: 1.3844897747039795, avg loss: 1.3863145846128464\n",
      "trial: 3, iter: 7400, curr loss: 1.3860596418380737, avg loss: 1.386418098807335\n",
      "trial: 3, iter: 7600, curr loss: 1.3865225315093994, avg loss: 1.386324449777603\n",
      "trial: 3, iter: 7800, curr loss: 1.3849849700927734, avg loss: 1.3862775892019272\n",
      "trial: 3, iter: 8000, curr loss: 1.3858287334442139, avg loss: 1.3862522453069688\n",
      "trial: 3, iter: 8200, curr loss: 1.3866926431655884, avg loss: 1.3863177919387817\n",
      "trial: 3, iter: 8400, curr loss: 1.386433482170105, avg loss: 1.3861941277980805\n",
      "trial: 3, iter: 8600, curr loss: 1.385970115661621, avg loss: 1.3857895529270172\n",
      "trial: 3, iter: 8800, curr loss: 1.3862063884735107, avg loss: 1.3845852172374726\n",
      "trial: 3, iter: 9000, curr loss: 1.3911066055297852, avg loss: 1.3815941309928894\n",
      "trial: 3, iter: 9200, curr loss: 1.3849525451660156, avg loss: 1.380819612145424\n",
      "trial: 3, iter: 9400, curr loss: 1.3816900253295898, avg loss: 1.3776140183210372\n",
      "trial: 3, iter: 9600, curr loss: 1.3716596364974976, avg loss: 1.3728353494405747\n",
      "trial: 3, iter: 9800, curr loss: 1.3702391386032104, avg loss: 1.366853306889534\n",
      "trial: 3, iter: 10000, curr loss: 1.356496810913086, avg loss: 1.363392355442047\n",
      "trial: 3, iter: 10200, curr loss: 1.3623548746109009, avg loss: 1.3606587260961533\n",
      "trial: 3, iter: 10400, curr loss: 1.3557050228118896, avg loss: 1.3599985468387603\n",
      "trial: 3, iter: 10600, curr loss: 1.3783091306686401, avg loss: 1.3577617555856705\n",
      "trial: 3, iter: 10800, curr loss: 1.3624155521392822, avg loss: 1.354438809156418\n",
      "trial: 3, iter: 11000, curr loss: 1.3554562330245972, avg loss: 1.3533727127313613\n",
      "trial: 3, iter: 11200, curr loss: 1.3457536697387695, avg loss: 1.352085011601448\n",
      "trial: 3, iter: 11400, curr loss: 1.348340630531311, avg loss: 1.3456142956018449\n",
      "trial: 3, iter: 11600, curr loss: 1.3471653461456299, avg loss: 1.3431369656324386\n",
      "trial: 3, iter: 11800, curr loss: 1.3475325107574463, avg loss: 1.341275553703308\n",
      "trial: 3, iter: 12000, curr loss: 1.3230769634246826, avg loss: 1.3398852634429932\n",
      "trial: 3, iter: 12200, curr loss: 1.3213984966278076, avg loss: 1.3350778782367707\n",
      "trial: 3, iter: 12400, curr loss: 1.333319902420044, avg loss: 1.3350916743278503\n",
      "trial: 3, iter: 12600, curr loss: 1.3496631383895874, avg loss: 1.332224497795105\n",
      "trial: 3, iter: 12800, curr loss: 1.3278154134750366, avg loss: 1.3320522546768188\n",
      "trial: 3, iter: 13000, curr loss: 1.3474982976913452, avg loss: 1.3299939090013504\n",
      "trial: 3, iter: 13200, curr loss: 1.3299779891967773, avg loss: 1.3310920071601868\n",
      "trial: 3, iter: 13400, curr loss: 1.3080731630325317, avg loss: 1.3278484946489335\n",
      "trial: 3, iter: 13600, curr loss: 1.340002417564392, avg loss: 1.327000373005867\n",
      "trial: 3, iter: 13800, curr loss: 1.3166916370391846, avg loss: 1.3272558963298797\n",
      "trial: 3, iter: 14000, curr loss: 1.3183809518814087, avg loss: 1.3261628073453904\n",
      "trial: 3, iter: 14200, curr loss: 1.314918875694275, avg loss: 1.3242424350976945\n",
      "trial: 3, iter: 14400, curr loss: 1.325140118598938, avg loss: 1.3243832695484161\n",
      "trial: 3, iter: 14600, curr loss: 1.2907288074493408, avg loss: 1.3244593495130539\n",
      "trial: 3, iter: 14800, curr loss: 1.3125756978988647, avg loss: 1.321814244389534\n",
      "trial: 3, iter: 15000, curr loss: 1.3325815200805664, avg loss: 1.3229340994358063\n",
      "trial: 3, iter: 15200, curr loss: 1.320235252380371, avg loss: 1.3225936716794968\n",
      "trial: 3, iter: 15400, curr loss: 1.3274282217025757, avg loss: 1.3223281627893448\n",
      "trial: 3, iter: 15600, curr loss: 1.3496954441070557, avg loss: 1.3242980217933655\n",
      "trial: 3, ldr: 0.38260167837142944\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860224485397339, avg loss: 1.3872257500886918\n",
      "trial: 4, iter: 400, curr loss: 1.3857038021087646, avg loss: 1.3867343306541442\n",
      "trial: 4, iter: 600, curr loss: 1.386555790901184, avg loss: 1.3865794759988785\n",
      "trial: 4, iter: 800, curr loss: 1.3871031999588013, avg loss: 1.3866307944059373\n",
      "trial: 4, iter: 1000, curr loss: 1.3857327699661255, avg loss: 1.386440665125847\n",
      "trial: 4, iter: 1200, curr loss: 1.3859262466430664, avg loss: 1.386456354856491\n",
      "trial: 4, iter: 1400, curr loss: 1.3861137628555298, avg loss: 1.3864203208684922\n",
      "trial: 4, iter: 1600, curr loss: 1.3875428438186646, avg loss: 1.3864168643951416\n",
      "trial: 4, iter: 1800, curr loss: 1.3867319822311401, avg loss: 1.3863452136516572\n",
      "trial: 4, iter: 2000, curr loss: 1.3852572441101074, avg loss: 1.386476799249649\n",
      "trial: 4, iter: 2200, curr loss: 1.3867459297180176, avg loss: 1.3863308489322663\n",
      "trial: 4, iter: 2400, curr loss: 1.3865320682525635, avg loss: 1.3862532371282577\n",
      "trial: 4, iter: 2600, curr loss: 1.3883049488067627, avg loss: 1.3863531345129012\n",
      "trial: 4, iter: 2800, curr loss: 1.386415719985962, avg loss: 1.386385504603386\n",
      "trial: 4, iter: 3000, curr loss: 1.3865762948989868, avg loss: 1.3863104224205016\n",
      "trial: 4, iter: 3200, curr loss: 1.3854947090148926, avg loss: 1.3863051718473434\n",
      "trial: 4, iter: 3400, curr loss: 1.386565923690796, avg loss: 1.3863393318653108\n",
      "trial: 4, iter: 3600, curr loss: 1.3864492177963257, avg loss: 1.3863388001918793\n",
      "trial: 4, iter: 3800, curr loss: 1.3866206407546997, avg loss: 1.3863895016908645\n",
      "trial: 4, iter: 4000, curr loss: 1.3867037296295166, avg loss: 1.3863125681877135\n",
      "trial: 4, iter: 4200, curr loss: 1.3870075941085815, avg loss: 1.3863756507635117\n",
      "trial: 4, iter: 4400, curr loss: 1.3863192796707153, avg loss: 1.3863507348299027\n",
      "trial: 4, iter: 4600, curr loss: 1.3856745958328247, avg loss: 1.3863326245546341\n",
      "trial: 4, iter: 4800, curr loss: 1.3854583501815796, avg loss: 1.3863141417503357\n",
      "trial: 4, iter: 5000, curr loss: 1.3862966299057007, avg loss: 1.3863429820537567\n",
      "trial: 4, iter: 5200, curr loss: 1.3862801790237427, avg loss: 1.3863407099246978\n",
      "trial: 4, iter: 5400, curr loss: 1.3864996433258057, avg loss: 1.386337809562683\n",
      "trial: 4, iter: 5600, curr loss: 1.3878166675567627, avg loss: 1.3862874114513397\n",
      "trial: 4, iter: 5800, curr loss: 1.3859071731567383, avg loss: 1.3863071644306182\n",
      "trial: 4, iter: 6000, curr loss: 1.3863123655319214, avg loss: 1.3862985235452652\n",
      "trial: 4, iter: 6200, curr loss: 1.3868708610534668, avg loss: 1.3863329643011093\n",
      "trial: 4, iter: 6400, curr loss: 1.386225938796997, avg loss: 1.3863971042633056\n",
      "trial: 4, iter: 6600, curr loss: 1.3891798257827759, avg loss: 1.3862399637699128\n",
      "trial: 4, iter: 6800, curr loss: 1.3865166902542114, avg loss: 1.3863985687494278\n",
      "trial: 4, iter: 7000, curr loss: 1.3861744403839111, avg loss: 1.3862558943033219\n",
      "trial: 4, iter: 7200, curr loss: 1.3844473361968994, avg loss: 1.3860542154312134\n",
      "trial: 4, iter: 7400, curr loss: 1.3816139698028564, avg loss: 1.384325104355812\n",
      "trial: 4, iter: 7600, curr loss: 1.3698644638061523, avg loss: 1.3744421499967574\n",
      "trial: 4, iter: 7800, curr loss: 1.360763430595398, avg loss: 1.3517540818452836\n",
      "trial: 4, iter: 8000, curr loss: 1.3231884241104126, avg loss: 1.3387285494804382\n",
      "trial: 4, iter: 8200, curr loss: 1.3454632759094238, avg loss: 1.329961079955101\n",
      "trial: 4, iter: 8400, curr loss: 1.316103219985962, avg loss: 1.3265816009044646\n",
      "trial: 4, iter: 8600, curr loss: 1.346522331237793, avg loss: 1.3234139144420625\n",
      "trial: 4, iter: 8800, curr loss: 1.3306173086166382, avg loss: 1.3248487693071365\n",
      "trial: 4, iter: 9000, curr loss: 1.316634178161621, avg loss: 1.3217703527212143\n",
      "trial: 4, iter: 9200, curr loss: 1.3249201774597168, avg loss: 1.3223304754495622\n",
      "trial: 4, iter: 9400, curr loss: 1.3160640001296997, avg loss: 1.3185085505247116\n",
      "trial: 4, iter: 9600, curr loss: 1.3286577463150024, avg loss: 1.3209454840421677\n",
      "trial: 4, iter: 9800, curr loss: 1.3276633024215698, avg loss: 1.3202391791343688\n",
      "trial: 4, iter: 10000, curr loss: 1.3422104120254517, avg loss: 1.3197816520929337\n",
      "trial: 4, iter: 10200, curr loss: 1.3512458801269531, avg loss: 1.3176006090641021\n",
      "trial: 4, iter: 10400, curr loss: 1.3070605993270874, avg loss: 1.3174080491065978\n",
      "trial: 4, iter: 10600, curr loss: 1.3290293216705322, avg loss: 1.3178735017776488\n",
      "trial: 4, iter: 10800, curr loss: 1.3017815351486206, avg loss: 1.3178648322820663\n",
      "trial: 4, iter: 11000, curr loss: 1.3368775844573975, avg loss: 1.3152332121133805\n",
      "trial: 4, iter: 11200, curr loss: 1.307904601097107, avg loss: 1.3170462900400162\n",
      "trial: 4, iter: 11400, curr loss: 1.301274299621582, avg loss: 1.3194925689697266\n",
      "trial: 4, iter: 11600, curr loss: 1.289320468902588, avg loss: 1.3173995858430863\n",
      "trial: 4, iter: 11800, curr loss: 1.3370624780654907, avg loss: 1.317199676632881\n",
      "trial: 4, iter: 12000, curr loss: 1.2827999591827393, avg loss: 1.314812377691269\n",
      "trial: 4, iter: 12200, curr loss: 1.3079479932785034, avg loss: 1.317296040058136\n",
      "trial: 4, iter: 12400, curr loss: 1.3232735395431519, avg loss: 1.3171912682056428\n",
      "trial: 4, iter: 12600, curr loss: 1.3348301649093628, avg loss: 1.3150391829013826\n",
      "trial: 4, iter: 12800, curr loss: 1.3425066471099854, avg loss: 1.3164529353380203\n",
      "trial: 4, iter: 13000, curr loss: 1.3158375024795532, avg loss: 1.316077396273613\n",
      "trial: 4, iter: 13200, curr loss: 1.295960783958435, avg loss: 1.3158906334638596\n",
      "trial: 4, iter: 13400, curr loss: 1.310991644859314, avg loss: 1.3153363734483718\n",
      "trial: 4, iter: 13600, curr loss: 1.3138363361358643, avg loss: 1.3142912697792053\n",
      "trial: 4, iter: 13800, curr loss: 1.3087139129638672, avg loss: 1.3137589800357818\n",
      "trial: 4, iter: 14000, curr loss: 1.298683762550354, avg loss: 1.3104466700553894\n",
      "trial: 4, iter: 14200, curr loss: 1.2881723642349243, avg loss: 1.3143749487400056\n",
      "trial: 4, iter: 14400, curr loss: 1.3255127668380737, avg loss: 1.3158390486240388\n",
      "trial: 4, iter: 14600, curr loss: 1.2991126775741577, avg loss: 1.3150774395465852\n",
      "trial: 4, iter: 14800, curr loss: 1.323272943496704, avg loss: 1.3141192680597304\n",
      "trial: 4, iter: 15000, curr loss: 1.2778435945510864, avg loss: 1.3111526954174042\n",
      "trial: 4, iter: 15200, curr loss: 1.3104139566421509, avg loss: 1.3123406660556793\n",
      "trial: 4, iter: 15400, curr loss: 1.2837212085723877, avg loss: 1.3132851523160936\n",
      "trial: 4, iter: 15600, curr loss: 1.2913963794708252, avg loss: 1.3150209498405456\n",
      "trial: 4, ldr: 0.3841562569141388\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3927788734436035, avg loss: 1.3871241313219072\n",
      "trial: 5, iter: 400, curr loss: 1.3859751224517822, avg loss: 1.3868644547462463\n",
      "trial: 5, iter: 600, curr loss: 1.386612892150879, avg loss: 1.3865088903903962\n",
      "trial: 5, iter: 800, curr loss: 1.387804388999939, avg loss: 1.386651675105095\n",
      "trial: 5, iter: 1000, curr loss: 1.3855454921722412, avg loss: 1.3862351423501968\n",
      "trial: 5, iter: 1200, curr loss: 1.3877875804901123, avg loss: 1.3865846645832063\n",
      "trial: 5, iter: 1400, curr loss: 1.386831521987915, avg loss: 1.3864966982603073\n",
      "trial: 5, iter: 1600, curr loss: 1.386289119720459, avg loss: 1.3865411138534547\n",
      "trial: 5, iter: 1800, curr loss: 1.384625792503357, avg loss: 1.3863580799102784\n",
      "trial: 5, iter: 2000, curr loss: 1.3833240270614624, avg loss: 1.3863703685998916\n",
      "trial: 5, iter: 2200, curr loss: 1.3852795362472534, avg loss: 1.3864061629772186\n",
      "trial: 5, iter: 2400, curr loss: 1.386474370956421, avg loss: 1.3863276410102845\n",
      "trial: 5, iter: 2600, curr loss: 1.3868489265441895, avg loss: 1.386298668384552\n",
      "trial: 5, iter: 2800, curr loss: 1.3880454301834106, avg loss: 1.3862631666660308\n",
      "trial: 5, iter: 3000, curr loss: 1.385033369064331, avg loss: 1.3863531798124313\n",
      "trial: 5, iter: 3200, curr loss: 1.3852295875549316, avg loss: 1.3864089024066926\n",
      "trial: 5, iter: 3400, curr loss: 1.3863370418548584, avg loss: 1.3863696736097335\n",
      "trial: 5, iter: 3600, curr loss: 1.387134075164795, avg loss: 1.3863446241617203\n",
      "trial: 5, iter: 3800, curr loss: 1.3869274854660034, avg loss: 1.3863019025325776\n",
      "trial: 5, iter: 4000, curr loss: 1.386580467224121, avg loss: 1.3863333427906037\n",
      "trial: 5, iter: 4200, curr loss: 1.3864108324050903, avg loss: 1.386369880437851\n",
      "trial: 5, iter: 4400, curr loss: 1.3859920501708984, avg loss: 1.386385641694069\n",
      "trial: 5, iter: 4600, curr loss: 1.3861719369888306, avg loss: 1.3863075190782548\n",
      "trial: 5, iter: 4800, curr loss: 1.3865222930908203, avg loss: 1.3863193500041961\n",
      "trial: 5, iter: 5000, curr loss: 1.3856629133224487, avg loss: 1.3863244956731797\n",
      "trial: 5, iter: 5200, curr loss: 1.387595295906067, avg loss: 1.3862910920381546\n",
      "trial: 5, iter: 5400, curr loss: 1.3850957155227661, avg loss: 1.3863103789091111\n",
      "trial: 5, iter: 5600, curr loss: 1.386048436164856, avg loss: 1.3863318318128586\n",
      "trial: 5, iter: 5800, curr loss: 1.3875417709350586, avg loss: 1.3863053458929062\n",
      "trial: 5, iter: 6000, curr loss: 1.3873889446258545, avg loss: 1.3863413083553313\n",
      "trial: 5, iter: 6200, curr loss: 1.386335015296936, avg loss: 1.3863018667697906\n",
      "trial: 5, iter: 6400, curr loss: 1.3864542245864868, avg loss: 1.3863495975732802\n",
      "trial: 5, iter: 6600, curr loss: 1.3862230777740479, avg loss: 1.3862941783666611\n",
      "trial: 5, iter: 6800, curr loss: 1.3858537673950195, avg loss: 1.3863144719600677\n",
      "trial: 5, iter: 7000, curr loss: 1.386149287223816, avg loss: 1.3863415855169297\n",
      "trial: 5, iter: 7200, curr loss: 1.3863588571548462, avg loss: 1.3863409328460694\n",
      "trial: 5, iter: 7400, curr loss: 1.3862836360931396, avg loss: 1.3863445276021957\n",
      "trial: 5, iter: 7600, curr loss: 1.3866206407546997, avg loss: 1.3863139349222182\n",
      "trial: 5, iter: 7800, curr loss: 1.3863661289215088, avg loss: 1.386287938952446\n",
      "trial: 5, iter: 8000, curr loss: 1.3864322900772095, avg loss: 1.3864189910888671\n",
      "trial: 5, iter: 8200, curr loss: 1.386099934577942, avg loss: 1.3863099348545074\n",
      "trial: 5, iter: 8400, curr loss: 1.3857839107513428, avg loss: 1.3863056874275208\n",
      "trial: 5, iter: 8600, curr loss: 1.385892629623413, avg loss: 1.3863328623771667\n",
      "trial: 5, iter: 8800, curr loss: 1.3859995603561401, avg loss: 1.386311395764351\n",
      "trial: 5, iter: 9000, curr loss: 1.386391043663025, avg loss: 1.3862938678264618\n",
      "trial: 5, iter: 9200, curr loss: 1.3865305185317993, avg loss: 1.3862622874975203\n",
      "trial: 5, iter: 9400, curr loss: 1.3870372772216797, avg loss: 1.3863116544485092\n",
      "trial: 5, iter: 9600, curr loss: 1.3859269618988037, avg loss: 1.3863110536336898\n",
      "trial: 5, iter: 9800, curr loss: 1.3880374431610107, avg loss: 1.3862784665822983\n",
      "trial: 5, iter: 10000, curr loss: 1.3863158226013184, avg loss: 1.3863381624221802\n",
      "trial: 5, iter: 10200, curr loss: 1.3861134052276611, avg loss: 1.3862437850236893\n",
      "trial: 5, iter: 10400, curr loss: 1.3860993385314941, avg loss: 1.3863175576925277\n",
      "trial: 5, iter: 10600, curr loss: 1.3862723112106323, avg loss: 1.386239885687828\n",
      "trial: 5, iter: 10800, curr loss: 1.3856329917907715, avg loss: 1.386007318496704\n",
      "trial: 5, iter: 11000, curr loss: 1.3809659481048584, avg loss: 1.3844062608480454\n",
      "trial: 5, iter: 11200, curr loss: 1.378889560699463, avg loss: 1.3804418629407882\n",
      "trial: 5, iter: 11400, curr loss: 1.360028862953186, avg loss: 1.374577472805977\n",
      "trial: 5, iter: 11600, curr loss: 1.3831782341003418, avg loss: 1.3676120406389236\n",
      "trial: 5, iter: 11800, curr loss: 1.3574548959732056, avg loss: 1.3619239699840546\n",
      "trial: 5, iter: 12000, curr loss: 1.3519692420959473, avg loss: 1.3593105792999267\n",
      "trial: 5, iter: 12200, curr loss: 1.361162543296814, avg loss: 1.3582017195224763\n",
      "trial: 5, iter: 12400, curr loss: 1.3497252464294434, avg loss: 1.3551254081726074\n",
      "trial: 5, iter: 12600, curr loss: 1.3574227094650269, avg loss: 1.352900828719139\n",
      "trial: 5, iter: 12800, curr loss: 1.3466235399246216, avg loss: 1.3493307828903198\n",
      "trial: 5, iter: 13000, curr loss: 1.3534106016159058, avg loss: 1.3462846493721008\n",
      "trial: 5, iter: 13200, curr loss: 1.3533915281295776, avg loss: 1.3388881230354308\n",
      "trial: 5, iter: 13400, curr loss: 1.3617697954177856, avg loss: 1.33465172290802\n",
      "trial: 5, iter: 13600, curr loss: 1.314178466796875, avg loss: 1.3295993107557296\n",
      "trial: 5, iter: 13800, curr loss: 1.3405025005340576, avg loss: 1.326757715344429\n",
      "trial: 5, iter: 14000, curr loss: 1.3167052268981934, avg loss: 1.3266113030910491\n",
      "trial: 5, iter: 14200, curr loss: 1.3018252849578857, avg loss: 1.324271080493927\n",
      "trial: 5, iter: 14400, curr loss: 1.3343234062194824, avg loss: 1.325191112756729\n",
      "trial: 5, iter: 14600, curr loss: 1.3176205158233643, avg loss: 1.3250365275144578\n",
      "trial: 5, iter: 14800, curr loss: 1.3098032474517822, avg loss: 1.32323666036129\n",
      "trial: 5, iter: 15000, curr loss: 1.3162715435028076, avg loss: 1.3234590965509414\n",
      "trial: 5, iter: 15200, curr loss: 1.3249239921569824, avg loss: 1.320900731086731\n",
      "trial: 5, iter: 15400, curr loss: 1.3295384645462036, avg loss: 1.320918264389038\n",
      "trial: 5, iter: 15600, curr loss: 1.3285455703735352, avg loss: 1.3202248752117156\n",
      "trial: 5, ldr: 0.38991856575012207\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.33216085731983186\n",
      "Experiment done with data path: ./data/catNon-lin-NI_8/data.50k.dz20.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_20/data.50k.dz200.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3912372589111328, avg loss: 1.3870785999298096\n",
      "trial: 1, iter: 400, curr loss: 1.3880516290664673, avg loss: 1.386538627743721\n",
      "trial: 1, iter: 600, curr loss: 1.384566307067871, avg loss: 1.3867297178506852\n",
      "trial: 1, iter: 800, curr loss: 1.3868192434310913, avg loss: 1.3865602332353593\n",
      "trial: 1, iter: 1000, curr loss: 1.3852314949035645, avg loss: 1.3865268099308015\n",
      "trial: 1, iter: 1200, curr loss: 1.3861719369888306, avg loss: 1.386437861919403\n",
      "trial: 1, iter: 1400, curr loss: 1.3855271339416504, avg loss: 1.38632497549057\n",
      "trial: 1, iter: 1600, curr loss: 1.3866862058639526, avg loss: 1.3864204043149948\n",
      "trial: 1, iter: 1800, curr loss: 1.386102318763733, avg loss: 1.3863320744037628\n",
      "trial: 1, iter: 2000, curr loss: 1.3862391710281372, avg loss: 1.3864540266990661\n",
      "trial: 1, iter: 2200, curr loss: 1.3850489854812622, avg loss: 1.386423413157463\n",
      "trial: 1, iter: 2400, curr loss: 1.3866541385650635, avg loss: 1.386318793296814\n",
      "trial: 1, iter: 2600, curr loss: 1.3858429193496704, avg loss: 1.3863992631435393\n",
      "trial: 1, iter: 2800, curr loss: 1.3867716789245605, avg loss: 1.386394340991974\n",
      "trial: 1, iter: 3000, curr loss: 1.3859782218933105, avg loss: 1.386403750181198\n",
      "trial: 1, iter: 3200, curr loss: 1.3863413333892822, avg loss: 1.3865203702449798\n",
      "trial: 1, iter: 3400, curr loss: 1.3867310285568237, avg loss: 1.3863805854320526\n",
      "trial: 1, iter: 3600, curr loss: 1.3867855072021484, avg loss: 1.38630566239357\n",
      "trial: 1, iter: 3800, curr loss: 1.38784658908844, avg loss: 1.386303090453148\n",
      "trial: 1, iter: 4000, curr loss: 1.3863862752914429, avg loss: 1.386369652748108\n",
      "trial: 1, iter: 4200, curr loss: 1.3876404762268066, avg loss: 1.386280911564827\n",
      "trial: 1, iter: 4400, curr loss: 1.3856004476547241, avg loss: 1.3863613682985305\n",
      "trial: 1, iter: 4600, curr loss: 1.3848767280578613, avg loss: 1.3863833963871002\n",
      "trial: 1, iter: 4800, curr loss: 1.3862274885177612, avg loss: 1.386304452419281\n",
      "trial: 1, iter: 5000, curr loss: 1.385683298110962, avg loss: 1.3862915515899659\n",
      "trial: 1, iter: 5200, curr loss: 1.3858201503753662, avg loss: 1.3863103491067887\n",
      "trial: 1, iter: 5400, curr loss: 1.38620924949646, avg loss: 1.3863060665130615\n",
      "trial: 1, iter: 5600, curr loss: 1.3858553171157837, avg loss: 1.386323212981224\n",
      "trial: 1, iter: 5800, curr loss: 1.3856910467147827, avg loss: 1.386324325799942\n",
      "trial: 1, iter: 6000, curr loss: 1.3860127925872803, avg loss: 1.3863209408521653\n",
      "trial: 1, iter: 6200, curr loss: 1.385555386543274, avg loss: 1.3863886141777038\n",
      "trial: 1, iter: 6400, curr loss: 1.3862316608428955, avg loss: 1.3863194090127946\n",
      "trial: 1, iter: 6600, curr loss: 1.3864644765853882, avg loss: 1.3863511848449708\n",
      "trial: 1, iter: 6800, curr loss: 1.3865286111831665, avg loss: 1.3863141220808028\n",
      "trial: 1, iter: 7000, curr loss: 1.3861744403839111, avg loss: 1.3863163512945176\n",
      "trial: 1, iter: 7200, curr loss: 1.3863482475280762, avg loss: 1.3862924373149872\n",
      "trial: 1, iter: 7400, curr loss: 1.386027455329895, avg loss: 1.386317458152771\n",
      "trial: 1, iter: 7600, curr loss: 1.3861733675003052, avg loss: 1.3862999659776687\n",
      "trial: 1, iter: 7800, curr loss: 1.385940432548523, avg loss: 1.3863349705934525\n",
      "trial: 1, iter: 8000, curr loss: 1.3860960006713867, avg loss: 1.3863140332698822\n",
      "trial: 1, iter: 8200, curr loss: 1.3861992359161377, avg loss: 1.3863061755895614\n",
      "trial: 1, iter: 8400, curr loss: 1.386379599571228, avg loss: 1.3863084268569947\n",
      "trial: 1, iter: 8600, curr loss: 1.3863394260406494, avg loss: 1.3862949013710022\n",
      "trial: 1, iter: 8800, curr loss: 1.3863654136657715, avg loss: 1.3862931483983993\n",
      "trial: 1, iter: 9000, curr loss: 1.3864753246307373, avg loss: 1.3862798285484315\n",
      "trial: 1, iter: 9200, curr loss: 1.386404037475586, avg loss: 1.3863226634263992\n",
      "trial: 1, iter: 9400, curr loss: 1.3863117694854736, avg loss: 1.3863120472431183\n",
      "trial: 1, iter: 9600, curr loss: 1.386254072189331, avg loss: 1.3863068199157715\n",
      "trial: 1, iter: 9800, curr loss: 1.3863662481307983, avg loss: 1.386313195824623\n",
      "trial: 1, iter: 10000, curr loss: 1.3863067626953125, avg loss: 1.3862877047061921\n",
      "trial: 1, iter: 10200, curr loss: 1.3857394456863403, avg loss: 1.3863119065761567\n",
      "trial: 1, iter: 10400, curr loss: 1.386331558227539, avg loss: 1.3863106578588487\n",
      "trial: 1, iter: 10600, curr loss: 1.3862645626068115, avg loss: 1.3862979912757873\n",
      "trial: 1, iter: 10800, curr loss: 1.3863787651062012, avg loss: 1.3862914943695068\n",
      "trial: 1, iter: 11000, curr loss: 1.3861010074615479, avg loss: 1.3862888491153718\n",
      "trial: 1, iter: 11200, curr loss: 1.3862581253051758, avg loss: 1.386362572312355\n",
      "trial: 1, iter: 11400, curr loss: 1.3864521980285645, avg loss: 1.386304228901863\n",
      "trial: 1, iter: 11600, curr loss: 1.3862162828445435, avg loss: 1.386294618844986\n",
      "trial: 1, iter: 11800, curr loss: 1.3862882852554321, avg loss: 1.3862969642877578\n",
      "trial: 1, iter: 12000, curr loss: 1.3862963914871216, avg loss: 1.3862945342063904\n",
      "trial: 1, iter: 12200, curr loss: 1.3862943649291992, avg loss: 1.386294378042221\n",
      "trial: 1, iter: 12400, curr loss: 1.3862946033477783, avg loss: 1.386294778585434\n",
      "trial: 1, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.3862947177886964\n",
      "trial: 1, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.3862946707010269\n",
      "trial: 1, iter: 13000, curr loss: 1.3862946033477783, avg loss: 1.386294737458229\n",
      "trial: 1, iter: 13200, curr loss: 1.3862944841384888, avg loss: 1.3862943893671036\n",
      "trial: 1, iter: 13400, curr loss: 1.3862946033477783, avg loss: 1.3862947088479995\n",
      "trial: 1, iter: 13600, curr loss: 1.3862947225570679, avg loss: 1.3862946349382401\n",
      "trial: 1, iter: 13800, curr loss: 1.3862944841384888, avg loss: 1.3862946105003358\n",
      "trial: 1, iter: 14000, curr loss: 1.3862947225570679, avg loss: 1.3862946873903275\n",
      "trial: 1, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.3862947696447372\n",
      "trial: 1, iter: 14400, curr loss: 1.3862944841384888, avg loss: 1.3862946796417237\n",
      "trial: 1, iter: 14600, curr loss: 1.3862944841384888, avg loss: 1.386294733285904\n",
      "trial: 1, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.3862948656082152\n",
      "trial: 1, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294881105423\n",
      "trial: 1, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.3862948876619339\n",
      "trial: 1, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862948763370513\n",
      "trial: 1, ldr: 4.4853337044514774e-08\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3874573707580566, avg loss: 1.3871930050849914\n",
      "trial: 2, iter: 400, curr loss: 1.3919658660888672, avg loss: 1.3868149942159653\n",
      "trial: 2, iter: 600, curr loss: 1.3882399797439575, avg loss: 1.386759489774704\n",
      "trial: 2, iter: 800, curr loss: 1.3860008716583252, avg loss: 1.3864717131853104\n",
      "trial: 2, iter: 1000, curr loss: 1.3864349126815796, avg loss: 1.3864064937829972\n",
      "trial: 2, iter: 1200, curr loss: 1.382256031036377, avg loss: 1.3864608079195022\n",
      "trial: 2, iter: 1400, curr loss: 1.3846640586853027, avg loss: 1.3865334516763688\n",
      "trial: 2, iter: 1600, curr loss: 1.3872931003570557, avg loss: 1.3864235067367554\n",
      "trial: 2, iter: 1800, curr loss: 1.386733889579773, avg loss: 1.3864581763744355\n",
      "trial: 2, iter: 2000, curr loss: 1.3865015506744385, avg loss: 1.3864472925662994\n",
      "trial: 2, iter: 2200, curr loss: 1.3856587409973145, avg loss: 1.3864357244968415\n",
      "trial: 2, iter: 2400, curr loss: 1.3856643438339233, avg loss: 1.3862582355737687\n",
      "trial: 2, iter: 2600, curr loss: 1.3864068984985352, avg loss: 1.3864585655927657\n",
      "trial: 2, iter: 2800, curr loss: 1.385852575302124, avg loss: 1.3864618849754333\n",
      "trial: 2, iter: 3000, curr loss: 1.3867855072021484, avg loss: 1.3864628607034684\n",
      "trial: 2, iter: 3200, curr loss: 1.386303186416626, avg loss: 1.3864215862751008\n",
      "trial: 2, iter: 3400, curr loss: 1.3862766027450562, avg loss: 1.386447497010231\n",
      "trial: 2, iter: 3600, curr loss: 1.3866124153137207, avg loss: 1.3863964599370957\n",
      "trial: 2, iter: 3800, curr loss: 1.386729121208191, avg loss: 1.38646477997303\n",
      "trial: 2, iter: 4000, curr loss: 1.3863445520401, avg loss: 1.386411131620407\n",
      "trial: 2, iter: 4200, curr loss: 1.3859175443649292, avg loss: 1.3863597279787063\n",
      "trial: 2, iter: 4400, curr loss: 1.3864479064941406, avg loss: 1.3863254982233046\n",
      "trial: 2, iter: 4600, curr loss: 1.3858330249786377, avg loss: 1.3863203555345536\n",
      "trial: 2, iter: 4800, curr loss: 1.3863166570663452, avg loss: 1.386290629506111\n",
      "trial: 2, iter: 5000, curr loss: 1.3854271173477173, avg loss: 1.3863193082809449\n",
      "trial: 2, iter: 5200, curr loss: 1.386500597000122, avg loss: 1.3863230013847352\n",
      "trial: 2, iter: 5400, curr loss: 1.3865525722503662, avg loss: 1.3863219761848449\n",
      "trial: 2, iter: 5600, curr loss: 1.3863450288772583, avg loss: 1.3862703680992126\n",
      "trial: 2, iter: 5800, curr loss: 1.3870704174041748, avg loss: 1.3863392436504365\n",
      "trial: 2, iter: 6000, curr loss: 1.3861358165740967, avg loss: 1.3863554805517198\n",
      "trial: 2, iter: 6200, curr loss: 1.3861589431762695, avg loss: 1.3864139729738236\n",
      "trial: 2, iter: 6400, curr loss: 1.38729727268219, avg loss: 1.3863455581665038\n",
      "trial: 2, iter: 6600, curr loss: 1.3863561153411865, avg loss: 1.3863581728935241\n",
      "trial: 2, iter: 6800, curr loss: 1.3864041566848755, avg loss: 1.3863050508499146\n",
      "trial: 2, iter: 7000, curr loss: 1.3864963054656982, avg loss: 1.3863407981395721\n",
      "trial: 2, iter: 7200, curr loss: 1.3863723278045654, avg loss: 1.3862992912530898\n",
      "trial: 2, iter: 7400, curr loss: 1.3861202001571655, avg loss: 1.3863285088539123\n",
      "trial: 2, iter: 7600, curr loss: 1.3862496614456177, avg loss: 1.386291647553444\n",
      "trial: 2, iter: 7800, curr loss: 1.3860396146774292, avg loss: 1.3863052803277969\n",
      "trial: 2, iter: 8000, curr loss: 1.385810375213623, avg loss: 1.3863359647989273\n",
      "trial: 2, iter: 8200, curr loss: 1.3864963054656982, avg loss: 1.3863064539432526\n",
      "trial: 2, iter: 8400, curr loss: 1.3863329887390137, avg loss: 1.3863377124071121\n",
      "trial: 2, iter: 8600, curr loss: 1.386509895324707, avg loss: 1.3862977641820908\n",
      "trial: 2, iter: 8800, curr loss: 1.386388897895813, avg loss: 1.3862971752882003\n",
      "trial: 2, iter: 9000, curr loss: 1.3862791061401367, avg loss: 1.3862955904006957\n",
      "trial: 2, iter: 9200, curr loss: 1.3863407373428345, avg loss: 1.3863044852018356\n",
      "trial: 2, iter: 9400, curr loss: 1.3863171339035034, avg loss: 1.3862854552268982\n",
      "trial: 2, iter: 9600, curr loss: 1.3858661651611328, avg loss: 1.3863473469018937\n",
      "trial: 2, iter: 9800, curr loss: 1.3862491846084595, avg loss: 1.386318786740303\n",
      "trial: 2, iter: 10000, curr loss: 1.3858530521392822, avg loss: 1.3863615119457244\n",
      "trial: 2, iter: 10200, curr loss: 1.3858674764633179, avg loss: 1.386353224515915\n",
      "trial: 2, iter: 10400, curr loss: 1.3864330053329468, avg loss: 1.3863779819011688\n",
      "trial: 2, iter: 10600, curr loss: 1.3860576152801514, avg loss: 1.3863267993927002\n",
      "trial: 2, iter: 10800, curr loss: 1.387344241142273, avg loss: 1.3863382285833359\n",
      "trial: 2, iter: 11000, curr loss: 1.3868567943572998, avg loss: 1.3863719499111176\n",
      "trial: 2, iter: 11200, curr loss: 1.3861799240112305, avg loss: 1.3863183492422104\n",
      "trial: 2, iter: 11400, curr loss: 1.3860584497451782, avg loss: 1.3863574904203415\n",
      "trial: 2, iter: 11600, curr loss: 1.386270523071289, avg loss: 1.3863114035129547\n",
      "trial: 2, iter: 11800, curr loss: 1.3860925436019897, avg loss: 1.3862972396612168\n",
      "trial: 2, iter: 12000, curr loss: 1.3863059282302856, avg loss: 1.3863138902187346\n",
      "trial: 2, iter: 12200, curr loss: 1.3861546516418457, avg loss: 1.386305114030838\n",
      "trial: 2, iter: 12400, curr loss: 1.3862701654434204, avg loss: 1.3863014245033265\n",
      "trial: 2, iter: 12600, curr loss: 1.386256456375122, avg loss: 1.3863020157814026\n",
      "trial: 2, iter: 12800, curr loss: 1.3863229751586914, avg loss: 1.3862965077161788\n",
      "trial: 2, iter: 13000, curr loss: 1.3863439559936523, avg loss: 1.3862913399934769\n",
      "trial: 2, iter: 13200, curr loss: 1.3865571022033691, avg loss: 1.3862932807207107\n",
      "trial: 2, iter: 13400, curr loss: 1.386217474937439, avg loss: 1.386302834749222\n",
      "trial: 2, iter: 13600, curr loss: 1.3863524198532104, avg loss: 1.386293814778328\n",
      "trial: 2, iter: 13800, curr loss: 1.3861188888549805, avg loss: 1.3862899363040924\n",
      "trial: 2, iter: 14000, curr loss: 1.3867558240890503, avg loss: 1.3863113045692443\n",
      "trial: 2, iter: 14200, curr loss: 1.3864777088165283, avg loss: 1.3862996172904969\n",
      "trial: 2, iter: 14400, curr loss: 1.386415958404541, avg loss: 1.3862796008586884\n",
      "trial: 2, iter: 14600, curr loss: 1.3866636753082275, avg loss: 1.386289405822754\n",
      "trial: 2, iter: 14800, curr loss: 1.386242151260376, avg loss: 1.386309798359871\n",
      "trial: 2, iter: 15000, curr loss: 1.386268973350525, avg loss: 1.3863087755441665\n",
      "trial: 2, iter: 15200, curr loss: 1.3865606784820557, avg loss: 1.3862777346372603\n",
      "trial: 2, iter: 15400, curr loss: 1.3861474990844727, avg loss: 1.38630446434021\n",
      "trial: 2, iter: 15600, curr loss: 1.3862979412078857, avg loss: 1.386305908560753\n",
      "trial: 2, ldr: 0.00036994938272982836\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3866572380065918, avg loss: 1.3873647379875182\n",
      "trial: 3, iter: 400, curr loss: 1.3882938623428345, avg loss: 1.3866163629293442\n",
      "trial: 3, iter: 600, curr loss: 1.3846853971481323, avg loss: 1.3864846694469453\n",
      "trial: 3, iter: 800, curr loss: 1.38645339012146, avg loss: 1.3864487081766128\n",
      "trial: 3, iter: 1000, curr loss: 1.3860573768615723, avg loss: 1.3864511293172836\n",
      "trial: 3, iter: 1200, curr loss: 1.386738657951355, avg loss: 1.3864029800891877\n",
      "trial: 3, iter: 1400, curr loss: 1.386236548423767, avg loss: 1.3864023679494857\n",
      "trial: 3, iter: 1600, curr loss: 1.3861901760101318, avg loss: 1.3863694167137146\n",
      "trial: 3, iter: 1800, curr loss: 1.3862049579620361, avg loss: 1.3864376312494278\n",
      "trial: 3, iter: 2000, curr loss: 1.3864072561264038, avg loss: 1.38635273873806\n",
      "trial: 3, iter: 2200, curr loss: 1.3871638774871826, avg loss: 1.386332904100418\n",
      "trial: 3, iter: 2400, curr loss: 1.3864233493804932, avg loss: 1.386308604478836\n",
      "trial: 3, iter: 2600, curr loss: 1.3863486051559448, avg loss: 1.3863651257753373\n",
      "trial: 3, iter: 2800, curr loss: 1.38594388961792, avg loss: 1.386293643116951\n",
      "trial: 3, iter: 3000, curr loss: 1.386296033859253, avg loss: 1.386346669793129\n",
      "trial: 3, iter: 3200, curr loss: 1.386232614517212, avg loss: 1.3863539272546768\n",
      "trial: 3, iter: 3400, curr loss: 1.3866976499557495, avg loss: 1.3863237446546555\n",
      "trial: 3, iter: 3600, curr loss: 1.3867994546890259, avg loss: 1.386303769350052\n",
      "trial: 3, iter: 3800, curr loss: 1.3862416744232178, avg loss: 1.3863180273771285\n",
      "trial: 3, iter: 4000, curr loss: 1.3873050212860107, avg loss: 1.3863576072454453\n",
      "trial: 3, iter: 4200, curr loss: 1.3865818977355957, avg loss: 1.3865453469753266\n",
      "trial: 3, iter: 4400, curr loss: 1.3858901262283325, avg loss: 1.386341568827629\n",
      "trial: 3, iter: 4600, curr loss: 1.3863434791564941, avg loss: 1.3863334882259368\n",
      "trial: 3, iter: 4800, curr loss: 1.386230230331421, avg loss: 1.386309605240822\n",
      "trial: 3, iter: 5000, curr loss: 1.3861889839172363, avg loss: 1.3863105648756027\n",
      "trial: 3, iter: 5200, curr loss: 1.3863964080810547, avg loss: 1.3863305777311326\n",
      "trial: 3, iter: 5400, curr loss: 1.3864144086837769, avg loss: 1.386315039396286\n",
      "trial: 3, iter: 5600, curr loss: 1.3860540390014648, avg loss: 1.3863101649284362\n",
      "trial: 3, iter: 5800, curr loss: 1.3864295482635498, avg loss: 1.3863076770305633\n",
      "trial: 3, iter: 6000, curr loss: 1.3862789869308472, avg loss: 1.3863142508268356\n",
      "trial: 3, iter: 6200, curr loss: 1.3862788677215576, avg loss: 1.386306294798851\n",
      "trial: 3, iter: 6400, curr loss: 1.3862671852111816, avg loss: 1.3862960028648377\n",
      "trial: 3, iter: 6600, curr loss: 1.3862888813018799, avg loss: 1.386316881775856\n",
      "trial: 3, iter: 6800, curr loss: 1.3862407207489014, avg loss: 1.3863077038526535\n",
      "trial: 3, iter: 7000, curr loss: 1.386422038078308, avg loss: 1.3862959694862367\n",
      "trial: 3, iter: 7200, curr loss: 1.3862991333007812, avg loss: 1.3863062691688537\n",
      "trial: 3, iter: 7400, curr loss: 1.386221170425415, avg loss: 1.3862926614284516\n",
      "trial: 3, iter: 7600, curr loss: 1.3863396644592285, avg loss: 1.3862758564949036\n",
      "trial: 3, iter: 7800, curr loss: 1.3859853744506836, avg loss: 1.3863093155622481\n",
      "trial: 3, iter: 8000, curr loss: 1.3862791061401367, avg loss: 1.386305827498436\n",
      "trial: 3, iter: 8200, curr loss: 1.3868333101272583, avg loss: 1.3863363832235336\n",
      "trial: 3, iter: 8400, curr loss: 1.38657546043396, avg loss: 1.3863178074359894\n",
      "trial: 3, iter: 8600, curr loss: 1.3871427774429321, avg loss: 1.3862683075666427\n",
      "trial: 3, iter: 8800, curr loss: 1.386458158493042, avg loss: 1.386320932507515\n",
      "trial: 3, iter: 9000, curr loss: 1.385739803314209, avg loss: 1.3863906061649323\n",
      "trial: 3, iter: 9200, curr loss: 1.387209415435791, avg loss: 1.3863732486963272\n",
      "trial: 3, iter: 9400, curr loss: 1.3868541717529297, avg loss: 1.386294850707054\n",
      "trial: 3, iter: 9600, curr loss: 1.3863643407821655, avg loss: 1.3863347047567367\n",
      "trial: 3, iter: 9800, curr loss: 1.3863385915756226, avg loss: 1.386360574364662\n",
      "trial: 3, iter: 10000, curr loss: 1.3865047693252563, avg loss: 1.3862945234775543\n",
      "trial: 3, iter: 10200, curr loss: 1.3864952325820923, avg loss: 1.386338266134262\n",
      "trial: 3, iter: 10400, curr loss: 1.3864903450012207, avg loss: 1.3863167721033096\n",
      "trial: 3, iter: 10600, curr loss: 1.386531114578247, avg loss: 1.3863002288341522\n",
      "trial: 3, iter: 10800, curr loss: 1.3864468336105347, avg loss: 1.3863021820783614\n",
      "trial: 3, iter: 11000, curr loss: 1.3861593008041382, avg loss: 1.3863157939910888\n",
      "trial: 3, iter: 11200, curr loss: 1.3859440088272095, avg loss: 1.3862742245197297\n",
      "trial: 3, iter: 11400, curr loss: 1.3865283727645874, avg loss: 1.386302005648613\n",
      "trial: 3, iter: 11600, curr loss: 1.3865034580230713, avg loss: 1.386292216181755\n",
      "trial: 3, iter: 11800, curr loss: 1.3863489627838135, avg loss: 1.3863053315877913\n",
      "trial: 3, iter: 12000, curr loss: 1.3863654136657715, avg loss: 1.3862929368019103\n",
      "trial: 3, iter: 12200, curr loss: 1.3862273693084717, avg loss: 1.386297538280487\n",
      "trial: 3, iter: 12400, curr loss: 1.3862299919128418, avg loss: 1.3862974166870117\n",
      "trial: 3, iter: 12600, curr loss: 1.3859206438064575, avg loss: 1.3862877690792084\n",
      "trial: 3, iter: 12800, curr loss: 1.3866791725158691, avg loss: 1.3862828850746154\n",
      "trial: 3, iter: 13000, curr loss: 1.3861629962921143, avg loss: 1.3863184225559235\n",
      "trial: 3, iter: 13200, curr loss: 1.3866610527038574, avg loss: 1.386299831867218\n",
      "trial: 3, iter: 13400, curr loss: 1.386566162109375, avg loss: 1.3862917226552964\n",
      "trial: 3, iter: 13600, curr loss: 1.3863422870635986, avg loss: 1.3862960225343703\n",
      "trial: 3, iter: 13800, curr loss: 1.3864082098007202, avg loss: 1.3863050931692122\n",
      "trial: 3, iter: 14000, curr loss: 1.3862314224243164, avg loss: 1.3862998062372207\n",
      "trial: 3, iter: 14200, curr loss: 1.3862797021865845, avg loss: 1.3862951737642288\n",
      "trial: 3, iter: 14400, curr loss: 1.3863023519515991, avg loss: 1.3862950551509856\n",
      "trial: 3, iter: 14600, curr loss: 1.386281967163086, avg loss: 1.3862990200519563\n",
      "trial: 3, iter: 14800, curr loss: 1.386237382888794, avg loss: 1.386291853785515\n",
      "trial: 3, iter: 15000, curr loss: 1.3862576484680176, avg loss: 1.3862965351343155\n",
      "trial: 3, iter: 15200, curr loss: 1.3863046169281006, avg loss: 1.3862966728210449\n",
      "trial: 3, iter: 15400, curr loss: 1.3863061666488647, avg loss: 1.386294738650322\n",
      "trial: 3, iter: 15600, curr loss: 1.3862946033477783, avg loss: 1.3862949061393737\n",
      "trial: 3, ldr: -7.111178547347663e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3867970705032349, avg loss: 1.3874806880950927\n",
      "trial: 4, iter: 400, curr loss: 1.385657787322998, avg loss: 1.386832475066185\n",
      "trial: 4, iter: 600, curr loss: 1.3865442276000977, avg loss: 1.3866921520233155\n",
      "trial: 4, iter: 800, curr loss: 1.3841139078140259, avg loss: 1.3865622854232789\n",
      "trial: 4, iter: 1000, curr loss: 1.3851852416992188, avg loss: 1.3865011048316955\n",
      "trial: 4, iter: 1200, curr loss: 1.386149525642395, avg loss: 1.386521109342575\n",
      "trial: 4, iter: 1400, curr loss: 1.38741934299469, avg loss: 1.386456868648529\n",
      "trial: 4, iter: 1600, curr loss: 1.3867000341415405, avg loss: 1.3864989203214646\n",
      "trial: 4, iter: 1800, curr loss: 1.3858695030212402, avg loss: 1.3863401728868485\n",
      "trial: 4, iter: 2000, curr loss: 1.3861536979675293, avg loss: 1.3865042865276336\n",
      "trial: 4, iter: 2200, curr loss: 1.3875750303268433, avg loss: 1.386429026722908\n",
      "trial: 4, iter: 2400, curr loss: 1.3862380981445312, avg loss: 1.3864259815216065\n",
      "trial: 4, iter: 2600, curr loss: 1.3866599798202515, avg loss: 1.3864323818683624\n",
      "trial: 4, iter: 2800, curr loss: 1.3870265483856201, avg loss: 1.3863367593288423\n",
      "trial: 4, iter: 3000, curr loss: 1.3860665559768677, avg loss: 1.3864138960838317\n",
      "trial: 4, iter: 3200, curr loss: 1.3867653608322144, avg loss: 1.3863098829984666\n",
      "trial: 4, iter: 3400, curr loss: 1.386081337928772, avg loss: 1.3863662368059158\n",
      "trial: 4, iter: 3600, curr loss: 1.3864389657974243, avg loss: 1.3863144361972808\n",
      "trial: 4, iter: 3800, curr loss: 1.3862857818603516, avg loss: 1.3863818842172622\n",
      "trial: 4, iter: 4000, curr loss: 1.386130452156067, avg loss: 1.3863723850250245\n",
      "trial: 4, iter: 4200, curr loss: 1.3857320547103882, avg loss: 1.3863227492570878\n",
      "trial: 4, iter: 4400, curr loss: 1.3872545957565308, avg loss: 1.3863391518592834\n",
      "trial: 4, iter: 4600, curr loss: 1.3859997987747192, avg loss: 1.3863292938470841\n",
      "trial: 4, iter: 4800, curr loss: 1.386250615119934, avg loss: 1.3863128209114075\n",
      "trial: 4, iter: 5000, curr loss: 1.3867905139923096, avg loss: 1.386337821483612\n",
      "trial: 4, iter: 5200, curr loss: 1.386488437652588, avg loss: 1.38639117538929\n",
      "trial: 4, iter: 5400, curr loss: 1.3856241703033447, avg loss: 1.3863491427898407\n",
      "trial: 4, iter: 5600, curr loss: 1.3855780363082886, avg loss: 1.3862815409898759\n",
      "trial: 4, iter: 5800, curr loss: 1.386291265487671, avg loss: 1.3863887441158296\n",
      "trial: 4, iter: 6000, curr loss: 1.3862318992614746, avg loss: 1.386325176358223\n",
      "trial: 4, iter: 6200, curr loss: 1.3864941596984863, avg loss: 1.386357817053795\n",
      "trial: 4, iter: 6400, curr loss: 1.3860360383987427, avg loss: 1.3863078904151918\n",
      "trial: 4, iter: 6600, curr loss: 1.3866716623306274, avg loss: 1.386321914792061\n",
      "trial: 4, iter: 6800, curr loss: 1.385972261428833, avg loss: 1.386301960349083\n",
      "trial: 4, iter: 7000, curr loss: 1.386254072189331, avg loss: 1.3863226449489594\n",
      "trial: 4, iter: 7200, curr loss: 1.3862181901931763, avg loss: 1.3863266915082932\n",
      "trial: 4, iter: 7400, curr loss: 1.386161208152771, avg loss: 1.3863124781847\n",
      "trial: 4, iter: 7600, curr loss: 1.3865776062011719, avg loss: 1.386320816874504\n",
      "trial: 4, iter: 7800, curr loss: 1.38529372215271, avg loss: 1.3863428300619125\n",
      "trial: 4, iter: 8000, curr loss: 1.3863974809646606, avg loss: 1.3863517773151397\n",
      "trial: 4, iter: 8200, curr loss: 1.3857256174087524, avg loss: 1.3863224869966506\n",
      "trial: 4, iter: 8400, curr loss: 1.3861868381500244, avg loss: 1.3862955164909363\n",
      "trial: 4, iter: 8600, curr loss: 1.3864799737930298, avg loss: 1.386322209239006\n",
      "trial: 4, iter: 8800, curr loss: 1.3860728740692139, avg loss: 1.3862931871414184\n",
      "trial: 4, iter: 9000, curr loss: 1.3859676122665405, avg loss: 1.386287721991539\n",
      "trial: 4, iter: 9200, curr loss: 1.3862642049789429, avg loss: 1.3863094121217727\n",
      "trial: 4, iter: 9400, curr loss: 1.3863602876663208, avg loss: 1.3863024300336837\n",
      "trial: 4, iter: 9600, curr loss: 1.3863131999969482, avg loss: 1.3863071972131729\n",
      "trial: 4, iter: 9800, curr loss: 1.3863508701324463, avg loss: 1.3862984883785248\n",
      "trial: 4, iter: 10000, curr loss: 1.3862240314483643, avg loss: 1.3862986570596696\n",
      "trial: 4, iter: 10200, curr loss: 1.3863108158111572, avg loss: 1.3862974923849105\n",
      "trial: 4, iter: 10400, curr loss: 1.3863438367843628, avg loss: 1.3862866777181626\n",
      "trial: 4, iter: 10600, curr loss: 1.3862574100494385, avg loss: 1.386287236213684\n",
      "trial: 4, iter: 10800, curr loss: 1.3855804204940796, avg loss: 1.3862731450796126\n",
      "trial: 4, iter: 11000, curr loss: 1.386155128479004, avg loss: 1.386300160884857\n",
      "trial: 4, iter: 11200, curr loss: 1.3859632015228271, avg loss: 1.3862993609905243\n",
      "trial: 4, iter: 11400, curr loss: 1.3863664865493774, avg loss: 1.386315071582794\n",
      "trial: 4, iter: 11600, curr loss: 1.386226773262024, avg loss: 1.3862969750165939\n",
      "trial: 4, iter: 11800, curr loss: 1.38634192943573, avg loss: 1.386295525431633\n",
      "trial: 4, iter: 12000, curr loss: 1.386191725730896, avg loss: 1.3862965232133866\n",
      "trial: 4, iter: 12200, curr loss: 1.3863041400909424, avg loss: 1.386301035284996\n",
      "trial: 4, iter: 12400, curr loss: 1.3863006830215454, avg loss: 1.3862948751449584\n",
      "trial: 4, iter: 12600, curr loss: 1.3862998485565186, avg loss: 1.386295469403267\n",
      "trial: 4, iter: 12800, curr loss: 1.3862946033477783, avg loss: 1.386294550895691\n",
      "trial: 4, iter: 13000, curr loss: 1.3863052129745483, avg loss: 1.3862944155931474\n",
      "trial: 4, iter: 13200, curr loss: 1.3862875699996948, avg loss: 1.3862936663627625\n",
      "trial: 4, iter: 13400, curr loss: 1.3862805366516113, avg loss: 1.386295838356018\n",
      "trial: 4, iter: 13600, curr loss: 1.3863263130187988, avg loss: 1.3862940222024918\n",
      "trial: 4, iter: 13800, curr loss: 1.3863657712936401, avg loss: 1.3862947887182235\n",
      "trial: 4, iter: 14000, curr loss: 1.3862996101379395, avg loss: 1.3863024014234542\n",
      "trial: 4, iter: 14200, curr loss: 1.3863064050674438, avg loss: 1.3862941628694534\n",
      "trial: 4, iter: 14400, curr loss: 1.3863019943237305, avg loss: 1.3862971025705337\n",
      "trial: 4, iter: 14600, curr loss: 1.3863223791122437, avg loss: 1.386292233467102\n",
      "trial: 4, iter: 14800, curr loss: 1.3862888813018799, avg loss: 1.386297082901001\n",
      "trial: 4, iter: 15000, curr loss: 1.3861922025680542, avg loss: 1.386291457414627\n",
      "trial: 4, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386299825310707\n",
      "trial: 4, iter: 15400, curr loss: 1.38630211353302, avg loss: 1.3862952888011932\n",
      "trial: 4, iter: 15600, curr loss: 1.3863037824630737, avg loss: 1.3862956446409225\n",
      "trial: 4, ldr: -5.026059807278216e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3864094018936157, avg loss: 1.387429069876671\n",
      "trial: 5, iter: 400, curr loss: 1.386359691619873, avg loss: 1.3865776497125626\n",
      "trial: 5, iter: 600, curr loss: 1.3852462768554688, avg loss: 1.3865110963582992\n",
      "trial: 5, iter: 800, curr loss: 1.3861340284347534, avg loss: 1.3864908164739609\n",
      "trial: 5, iter: 1000, curr loss: 1.3854148387908936, avg loss: 1.3864896428585052\n",
      "trial: 5, iter: 1200, curr loss: 1.387304663658142, avg loss: 1.3864016675949096\n",
      "trial: 5, iter: 1400, curr loss: 1.386356234550476, avg loss: 1.3865332359075546\n",
      "trial: 5, iter: 1600, curr loss: 1.3858492374420166, avg loss: 1.3864577341079711\n",
      "trial: 5, iter: 1800, curr loss: 1.386183261871338, avg loss: 1.386370347738266\n",
      "trial: 5, iter: 2000, curr loss: 1.3864952325820923, avg loss: 1.3864134895801543\n",
      "trial: 5, iter: 2200, curr loss: 1.386717438697815, avg loss: 1.3863603645563125\n",
      "trial: 5, iter: 2400, curr loss: 1.3858211040496826, avg loss: 1.3863734990358352\n",
      "trial: 5, iter: 2600, curr loss: 1.385475993156433, avg loss: 1.3863076841831208\n",
      "trial: 5, iter: 2800, curr loss: 1.3860714435577393, avg loss: 1.3863541185855865\n",
      "trial: 5, iter: 3000, curr loss: 1.3866815567016602, avg loss: 1.3863412153720855\n",
      "trial: 5, iter: 3200, curr loss: 1.3864635229110718, avg loss: 1.3863251042366027\n",
      "trial: 5, iter: 3400, curr loss: 1.3862059116363525, avg loss: 1.3863829028606416\n",
      "trial: 5, iter: 3600, curr loss: 1.3856672048568726, avg loss: 1.3863079583644866\n",
      "trial: 5, iter: 3800, curr loss: 1.386426568031311, avg loss: 1.3864502227306366\n",
      "trial: 5, iter: 4000, curr loss: 1.3863580226898193, avg loss: 1.3863357120752335\n",
      "trial: 5, iter: 4200, curr loss: 1.3867924213409424, avg loss: 1.3863971161842346\n",
      "trial: 5, iter: 4400, curr loss: 1.3858884572982788, avg loss: 1.3863350290060044\n",
      "trial: 5, iter: 4600, curr loss: 1.386075735092163, avg loss: 1.386374089717865\n",
      "trial: 5, iter: 4800, curr loss: 1.3867441415786743, avg loss: 1.3863413047790527\n",
      "trial: 5, iter: 5000, curr loss: 1.3863646984100342, avg loss: 1.386323218345642\n",
      "trial: 5, iter: 5200, curr loss: 1.3865694999694824, avg loss: 1.3863297063112259\n",
      "trial: 5, iter: 5400, curr loss: 1.3863605260849, avg loss: 1.3863530606031418\n",
      "trial: 5, iter: 5600, curr loss: 1.3866313695907593, avg loss: 1.386330813765526\n",
      "trial: 5, iter: 5800, curr loss: 1.3855738639831543, avg loss: 1.386268355846405\n",
      "trial: 5, iter: 6000, curr loss: 1.3866771459579468, avg loss: 1.386340658068657\n",
      "trial: 5, iter: 6200, curr loss: 1.386303186416626, avg loss: 1.3863258284330369\n",
      "trial: 5, iter: 6400, curr loss: 1.386273980140686, avg loss: 1.3863006192445755\n",
      "trial: 5, iter: 6600, curr loss: 1.3864328861236572, avg loss: 1.3863198775053025\n",
      "trial: 5, iter: 6800, curr loss: 1.386184811592102, avg loss: 1.3863352847099304\n",
      "trial: 5, iter: 7000, curr loss: 1.3858811855316162, avg loss: 1.386286683678627\n",
      "trial: 5, iter: 7200, curr loss: 1.3860191106796265, avg loss: 1.3863233906030654\n",
      "trial: 5, iter: 7400, curr loss: 1.3866114616394043, avg loss: 1.3863223993778229\n",
      "trial: 5, iter: 7600, curr loss: 1.386496901512146, avg loss: 1.3862914216518403\n",
      "trial: 5, iter: 7800, curr loss: 1.3862354755401611, avg loss: 1.3863273775577545\n",
      "trial: 5, iter: 8000, curr loss: 1.3862769603729248, avg loss: 1.3863161051273345\n",
      "trial: 5, iter: 8200, curr loss: 1.3866230249404907, avg loss: 1.3863347214460373\n",
      "trial: 5, iter: 8400, curr loss: 1.3862228393554688, avg loss: 1.3863097751140594\n",
      "trial: 5, iter: 8600, curr loss: 1.3862696886062622, avg loss: 1.386311772465706\n",
      "trial: 5, iter: 8800, curr loss: 1.386161208152771, avg loss: 1.3863043862581252\n",
      "trial: 5, iter: 9000, curr loss: 1.386603593826294, avg loss: 1.3862797230482102\n",
      "trial: 5, iter: 9200, curr loss: 1.3863743543624878, avg loss: 1.3863160675764084\n",
      "trial: 5, iter: 9400, curr loss: 1.385323405265808, avg loss: 1.386335977911949\n",
      "trial: 5, iter: 9600, curr loss: 1.3854858875274658, avg loss: 1.3863019812107087\n",
      "trial: 5, iter: 9800, curr loss: 1.3862969875335693, avg loss: 1.3863417685031891\n",
      "trial: 5, iter: 10000, curr loss: 1.3864898681640625, avg loss: 1.3863001900911331\n",
      "trial: 5, iter: 10200, curr loss: 1.3865879774093628, avg loss: 1.3863030779361725\n",
      "trial: 5, iter: 10400, curr loss: 1.3865983486175537, avg loss: 1.3863181376457214\n",
      "trial: 5, iter: 10600, curr loss: 1.3862460851669312, avg loss: 1.3862889748811722\n",
      "trial: 5, iter: 10800, curr loss: 1.3864527940750122, avg loss: 1.3863160496950149\n",
      "trial: 5, iter: 11000, curr loss: 1.3856232166290283, avg loss: 1.3862929040193557\n",
      "trial: 5, iter: 11200, curr loss: 1.3867133855819702, avg loss: 1.3863206148147582\n",
      "trial: 5, iter: 11400, curr loss: 1.3862794637680054, avg loss: 1.3862880343198776\n",
      "trial: 5, iter: 11600, curr loss: 1.3862409591674805, avg loss: 1.3863255017995835\n",
      "trial: 5, iter: 11800, curr loss: 1.38661789894104, avg loss: 1.386295131444931\n",
      "trial: 5, iter: 12000, curr loss: 1.386243224143982, avg loss: 1.3862982267141342\n",
      "trial: 5, iter: 12200, curr loss: 1.3867075443267822, avg loss: 1.386279764175415\n",
      "trial: 5, iter: 12400, curr loss: 1.3859705924987793, avg loss: 1.3863196074962616\n",
      "trial: 5, iter: 12600, curr loss: 1.3859177827835083, avg loss: 1.386291577219963\n",
      "trial: 5, iter: 12800, curr loss: 1.3858983516693115, avg loss: 1.386313903927803\n",
      "trial: 5, iter: 13000, curr loss: 1.386568307876587, avg loss: 1.3863076972961426\n",
      "trial: 5, iter: 13200, curr loss: 1.3863221406936646, avg loss: 1.386291642189026\n",
      "trial: 5, iter: 13400, curr loss: 1.3862327337265015, avg loss: 1.3862935674190522\n",
      "trial: 5, iter: 13600, curr loss: 1.386292576789856, avg loss: 1.386295010447502\n",
      "trial: 5, iter: 13800, curr loss: 1.3863850831985474, avg loss: 1.3862976002693177\n",
      "trial: 5, iter: 14000, curr loss: 1.386194109916687, avg loss: 1.3862978965044022\n",
      "trial: 5, iter: 14200, curr loss: 1.3866665363311768, avg loss: 1.3862931352853776\n",
      "trial: 5, iter: 14400, curr loss: 1.3862680196762085, avg loss: 1.386309455037117\n",
      "trial: 5, iter: 14600, curr loss: 1.3863145112991333, avg loss: 1.3862986743450165\n",
      "trial: 5, iter: 14800, curr loss: 1.3862379789352417, avg loss: 1.3863046115636826\n",
      "trial: 5, iter: 15000, curr loss: 1.3863223791122437, avg loss: 1.3862980973720551\n",
      "trial: 5, iter: 15200, curr loss: 1.3862570524215698, avg loss: 1.38629924595356\n",
      "trial: 5, iter: 15400, curr loss: 1.386243462562561, avg loss: 1.3862965589761733\n",
      "trial: 5, iter: 15600, curr loss: 1.3861857652664185, avg loss: 1.3862967741489411\n",
      "trial: 5, ldr: -0.00028953698347322643\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 4.617095194703325e-06\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3865633010864258, avg loss: 1.387020623087883\n",
      "trial: 1, iter: 400, curr loss: 1.3862336874008179, avg loss: 1.386650658249855\n",
      "trial: 1, iter: 600, curr loss: 1.3875969648361206, avg loss: 1.3863741099834441\n",
      "trial: 1, iter: 800, curr loss: 1.3856825828552246, avg loss: 1.3864908838272094\n",
      "trial: 1, iter: 1000, curr loss: 1.388013243675232, avg loss: 1.38651780128479\n",
      "trial: 1, iter: 1200, curr loss: 1.3842841386795044, avg loss: 1.386565889120102\n",
      "trial: 1, iter: 1400, curr loss: 1.3869099617004395, avg loss: 1.3864610004425049\n",
      "trial: 1, iter: 1600, curr loss: 1.3872588872909546, avg loss: 1.3864493644237519\n",
      "trial: 1, iter: 1800, curr loss: 1.3855348825454712, avg loss: 1.3864039307832718\n",
      "trial: 1, iter: 2000, curr loss: 1.3875341415405273, avg loss: 1.3863977909088134\n",
      "trial: 1, iter: 2200, curr loss: 1.3877061605453491, avg loss: 1.3863927793502808\n",
      "trial: 1, iter: 2400, curr loss: 1.3867062330245972, avg loss: 1.3863779097795486\n",
      "trial: 1, iter: 2600, curr loss: 1.386656403541565, avg loss: 1.38641284763813\n",
      "trial: 1, iter: 2800, curr loss: 1.3860316276550293, avg loss: 1.3863389658927918\n",
      "trial: 1, iter: 3000, curr loss: 1.3867825269699097, avg loss: 1.3862738037109374\n",
      "trial: 1, iter: 3200, curr loss: 1.3856538534164429, avg loss: 1.3863824075460434\n",
      "trial: 1, iter: 3400, curr loss: 1.3842041492462158, avg loss: 1.3862204569578171\n",
      "trial: 1, iter: 3600, curr loss: 1.3854526281356812, avg loss: 1.3863713037967682\n",
      "trial: 1, iter: 3800, curr loss: 1.3854176998138428, avg loss: 1.3864102923870087\n",
      "trial: 1, iter: 4000, curr loss: 1.386353850364685, avg loss: 1.3863287574052812\n",
      "trial: 1, iter: 4200, curr loss: 1.3863898515701294, avg loss: 1.3863465678691864\n",
      "trial: 1, iter: 4400, curr loss: 1.3864195346832275, avg loss: 1.3863407725095749\n",
      "trial: 1, iter: 4600, curr loss: 1.386673092842102, avg loss: 1.3863318639993667\n",
      "trial: 1, iter: 4800, curr loss: 1.385703444480896, avg loss: 1.3862919521331787\n",
      "trial: 1, iter: 5000, curr loss: 1.3861178159713745, avg loss: 1.3863356417417527\n",
      "trial: 1, iter: 5200, curr loss: 1.386222004890442, avg loss: 1.386376811861992\n",
      "trial: 1, iter: 5400, curr loss: 1.386124849319458, avg loss: 1.386312291622162\n",
      "trial: 1, iter: 5600, curr loss: 1.386788249015808, avg loss: 1.3863096249103546\n",
      "trial: 1, iter: 5800, curr loss: 1.385965347290039, avg loss: 1.3863404983282088\n",
      "trial: 1, iter: 6000, curr loss: 1.3865503072738647, avg loss: 1.386323545575142\n",
      "trial: 1, iter: 6200, curr loss: 1.3864953517913818, avg loss: 1.386329591870308\n",
      "trial: 1, iter: 6400, curr loss: 1.3863656520843506, avg loss: 1.3863137406110764\n",
      "trial: 1, iter: 6600, curr loss: 1.3863381147384644, avg loss: 1.3863183802366257\n",
      "trial: 1, iter: 6800, curr loss: 1.386413812637329, avg loss: 1.3863108456134796\n",
      "trial: 1, iter: 7000, curr loss: 1.386310338973999, avg loss: 1.3862996435165404\n",
      "trial: 1, iter: 7200, curr loss: 1.3863263130187988, avg loss: 1.3863074612617492\n",
      "trial: 1, iter: 7400, curr loss: 1.3856875896453857, avg loss: 1.3863364464044572\n",
      "trial: 1, iter: 7600, curr loss: 1.386157512664795, avg loss: 1.3862983494997025\n",
      "trial: 1, iter: 7800, curr loss: 1.385834813117981, avg loss: 1.3863273864984513\n",
      "trial: 1, iter: 8000, curr loss: 1.3865444660186768, avg loss: 1.3863398653268815\n",
      "trial: 1, iter: 8200, curr loss: 1.3860492706298828, avg loss: 1.3863137501478195\n",
      "trial: 1, iter: 8400, curr loss: 1.386250376701355, avg loss: 1.386285424232483\n",
      "trial: 1, iter: 8600, curr loss: 1.3860670328140259, avg loss: 1.386297037601471\n",
      "trial: 1, iter: 8800, curr loss: 1.3862615823745728, avg loss: 1.3863223439455032\n",
      "trial: 1, iter: 9000, curr loss: 1.3862603902816772, avg loss: 1.3863151121139525\n",
      "trial: 1, iter: 9200, curr loss: 1.387075662612915, avg loss: 1.3862862861156464\n",
      "trial: 1, iter: 9400, curr loss: 1.3862160444259644, avg loss: 1.3863501811027528\n",
      "trial: 1, iter: 9600, curr loss: 1.3859938383102417, avg loss: 1.3862955325841904\n",
      "trial: 1, iter: 9800, curr loss: 1.3859202861785889, avg loss: 1.3863625866174698\n",
      "trial: 1, iter: 10000, curr loss: 1.386364459991455, avg loss: 1.3862921172380447\n",
      "trial: 1, iter: 10200, curr loss: 1.3856531381607056, avg loss: 1.3862925398349761\n",
      "trial: 1, iter: 10400, curr loss: 1.38625168800354, avg loss: 1.3863369977474214\n",
      "trial: 1, iter: 10600, curr loss: 1.3862088918685913, avg loss: 1.3862949711084367\n",
      "trial: 1, iter: 10800, curr loss: 1.3865774869918823, avg loss: 1.386302188038826\n",
      "trial: 1, iter: 11000, curr loss: 1.3867099285125732, avg loss: 1.386283294558525\n",
      "trial: 1, iter: 11200, curr loss: 1.3851041793823242, avg loss: 1.3862516379356384\n",
      "trial: 1, iter: 11400, curr loss: 1.3863815069198608, avg loss: 1.3863078743219375\n",
      "trial: 1, iter: 11600, curr loss: 1.386173129081726, avg loss: 1.3863374263048172\n",
      "trial: 1, iter: 11800, curr loss: 1.3861552476882935, avg loss: 1.3863022768497466\n",
      "trial: 1, iter: 12000, curr loss: 1.386375069618225, avg loss: 1.3863032507896422\n",
      "trial: 1, iter: 12200, curr loss: 1.3860383033752441, avg loss: 1.3862929594516755\n",
      "trial: 1, iter: 12400, curr loss: 1.3863089084625244, avg loss: 1.3863144022226335\n",
      "trial: 1, iter: 12600, curr loss: 1.386263370513916, avg loss: 1.386303499341011\n",
      "trial: 1, iter: 12800, curr loss: 1.3862577676773071, avg loss: 1.3863036549091339\n",
      "trial: 1, iter: 13000, curr loss: 1.3863741159439087, avg loss: 1.3862960773706436\n",
      "trial: 1, iter: 13200, curr loss: 1.38628351688385, avg loss: 1.3862816727161407\n",
      "trial: 1, iter: 13400, curr loss: 1.3864909410476685, avg loss: 1.3863122129440308\n",
      "trial: 1, iter: 13600, curr loss: 1.3863390684127808, avg loss: 1.3862965667247773\n",
      "trial: 1, iter: 13800, curr loss: 1.3864176273345947, avg loss: 1.3863018101453781\n",
      "trial: 1, iter: 14000, curr loss: 1.3864548206329346, avg loss: 1.386294520497322\n",
      "trial: 1, iter: 14200, curr loss: 1.3862265348434448, avg loss: 1.386319392323494\n",
      "trial: 1, iter: 14400, curr loss: 1.3864015340805054, avg loss: 1.3862990587949753\n",
      "trial: 1, iter: 14600, curr loss: 1.3861905336380005, avg loss: 1.3862935250997543\n",
      "trial: 1, iter: 14800, curr loss: 1.3862590789794922, avg loss: 1.3863112944364548\n",
      "trial: 1, iter: 15000, curr loss: 1.3863352537155151, avg loss: 1.3862926602363586\n",
      "trial: 1, iter: 15200, curr loss: 1.3864187002182007, avg loss: 1.3862924313545226\n",
      "trial: 1, iter: 15400, curr loss: 1.386529803276062, avg loss: 1.3863135278224945\n",
      "trial: 1, iter: 15600, curr loss: 1.3862876892089844, avg loss: 1.3862983560562134\n",
      "trial: 1, ldr: 0.0004018941253889352\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3845916986465454, avg loss: 1.3872633051872254\n",
      "trial: 2, iter: 400, curr loss: 1.3853461742401123, avg loss: 1.38665409386158\n",
      "trial: 2, iter: 600, curr loss: 1.384964942932129, avg loss: 1.3865156865119934\n",
      "trial: 2, iter: 800, curr loss: 1.3870949745178223, avg loss: 1.3865298306941987\n",
      "trial: 2, iter: 1000, curr loss: 1.3876843452453613, avg loss: 1.3863612115383148\n",
      "trial: 2, iter: 1200, curr loss: 1.3864402770996094, avg loss: 1.3865291696786881\n",
      "trial: 2, iter: 1400, curr loss: 1.3873002529144287, avg loss: 1.3864641338586807\n",
      "trial: 2, iter: 1600, curr loss: 1.3861501216888428, avg loss: 1.386362019777298\n",
      "trial: 2, iter: 1800, curr loss: 1.3870958089828491, avg loss: 1.386429786682129\n",
      "trial: 2, iter: 2000, curr loss: 1.3858227729797363, avg loss: 1.3864590209722518\n",
      "trial: 2, iter: 2200, curr loss: 1.3865644931793213, avg loss: 1.386411066055298\n",
      "trial: 2, iter: 2400, curr loss: 1.3862433433532715, avg loss: 1.3864352869987489\n",
      "trial: 2, iter: 2600, curr loss: 1.3858994245529175, avg loss: 1.386404173374176\n",
      "trial: 2, iter: 2800, curr loss: 1.387424111366272, avg loss: 1.3864173889160156\n",
      "trial: 2, iter: 3000, curr loss: 1.3868461847305298, avg loss: 1.3863121896982193\n",
      "trial: 2, iter: 3200, curr loss: 1.3859550952911377, avg loss: 1.3863088601827622\n",
      "trial: 2, iter: 3400, curr loss: 1.3873792886734009, avg loss: 1.3864600878953934\n",
      "trial: 2, iter: 3600, curr loss: 1.3862959146499634, avg loss: 1.3863495761156082\n",
      "trial: 2, iter: 3800, curr loss: 1.3857589960098267, avg loss: 1.3863918566703797\n",
      "trial: 2, iter: 4000, curr loss: 1.3867871761322021, avg loss: 1.3863699704408645\n",
      "trial: 2, iter: 4200, curr loss: 1.3870645761489868, avg loss: 1.3863376355171204\n",
      "trial: 2, iter: 4400, curr loss: 1.3879778385162354, avg loss: 1.386377927660942\n",
      "trial: 2, iter: 4600, curr loss: 1.385776162147522, avg loss: 1.3864133715629579\n",
      "trial: 2, iter: 4800, curr loss: 1.386014699935913, avg loss: 1.3863630068302155\n",
      "trial: 2, iter: 5000, curr loss: 1.3870162963867188, avg loss: 1.386325260400772\n",
      "trial: 2, iter: 5200, curr loss: 1.3865940570831299, avg loss: 1.3863772654533386\n",
      "trial: 2, iter: 5400, curr loss: 1.3865140676498413, avg loss: 1.3863503861427307\n",
      "trial: 2, iter: 5600, curr loss: 1.3868204355239868, avg loss: 1.3863170886039733\n",
      "trial: 2, iter: 5800, curr loss: 1.3860976696014404, avg loss: 1.3863288086652756\n",
      "trial: 2, iter: 6000, curr loss: 1.3870220184326172, avg loss: 1.386306213736534\n",
      "trial: 2, iter: 6200, curr loss: 1.3865234851837158, avg loss: 1.3863503575325011\n",
      "trial: 2, iter: 6400, curr loss: 1.3869202136993408, avg loss: 1.386261013150215\n",
      "trial: 2, iter: 6600, curr loss: 1.3859378099441528, avg loss: 1.3863567942380906\n",
      "trial: 2, iter: 6800, curr loss: 1.3864272832870483, avg loss: 1.3862969797849656\n",
      "trial: 2, iter: 7000, curr loss: 1.386220932006836, avg loss: 1.3862918150424957\n",
      "trial: 2, iter: 7200, curr loss: 1.386479377746582, avg loss: 1.386312050819397\n",
      "trial: 2, iter: 7400, curr loss: 1.3862624168395996, avg loss: 1.386308988928795\n",
      "trial: 2, iter: 7600, curr loss: 1.3863131999969482, avg loss: 1.3862946206331253\n",
      "trial: 2, iter: 7800, curr loss: 1.3862814903259277, avg loss: 1.3862972152233124\n",
      "trial: 2, iter: 8000, curr loss: 1.3862922191619873, avg loss: 1.3862975031137466\n",
      "trial: 2, iter: 8200, curr loss: 1.3863261938095093, avg loss: 1.3862974911928176\n",
      "trial: 2, iter: 8400, curr loss: 1.3862992525100708, avg loss: 1.3862945461273193\n",
      "trial: 2, iter: 8600, curr loss: 1.3863043785095215, avg loss: 1.3862957918643952\n",
      "trial: 2, iter: 8800, curr loss: 1.3862943649291992, avg loss: 1.3862938106060028\n",
      "trial: 2, iter: 9000, curr loss: 1.3863788843154907, avg loss: 1.3862928944826125\n",
      "trial: 2, iter: 9200, curr loss: 1.3862855434417725, avg loss: 1.3862964695692062\n",
      "trial: 2, iter: 9400, curr loss: 1.3862941265106201, avg loss: 1.3862949126958848\n",
      "trial: 2, iter: 9600, curr loss: 1.3864920139312744, avg loss: 1.3863688057661057\n",
      "trial: 2, iter: 9800, curr loss: 1.386501669883728, avg loss: 1.3863071870803834\n",
      "trial: 2, iter: 10000, curr loss: 1.3867666721343994, avg loss: 1.3863106578588487\n",
      "trial: 2, iter: 10200, curr loss: 1.386206030845642, avg loss: 1.3862631690502167\n",
      "trial: 2, iter: 10400, curr loss: 1.3863333463668823, avg loss: 1.3863149666786194\n",
      "trial: 2, iter: 10600, curr loss: 1.3862004280090332, avg loss: 1.386298217177391\n",
      "trial: 2, iter: 10800, curr loss: 1.3862196207046509, avg loss: 1.3862985068559646\n",
      "trial: 2, iter: 11000, curr loss: 1.3862996101379395, avg loss: 1.386309022307396\n",
      "trial: 2, iter: 11200, curr loss: 1.386094331741333, avg loss: 1.3862911039590835\n",
      "trial: 2, iter: 11400, curr loss: 1.3863353729248047, avg loss: 1.3863032549619674\n",
      "trial: 2, iter: 11600, curr loss: 1.3862910270690918, avg loss: 1.3862970632314682\n",
      "trial: 2, iter: 11800, curr loss: 1.3862966299057007, avg loss: 1.386296688914299\n",
      "trial: 2, iter: 12000, curr loss: 1.386292576789856, avg loss: 1.3862972509860993\n",
      "trial: 2, iter: 12200, curr loss: 1.3862800598144531, avg loss: 1.3862952506542205\n",
      "trial: 2, iter: 12400, curr loss: 1.3863472938537598, avg loss: 1.3862949001789093\n",
      "trial: 2, iter: 12600, curr loss: 1.3863611221313477, avg loss: 1.3862941122055055\n",
      "trial: 2, iter: 12800, curr loss: 1.3863047361373901, avg loss: 1.3862970572710038\n",
      "trial: 2, iter: 13000, curr loss: 1.3862996101379395, avg loss: 1.386294388771057\n",
      "trial: 2, iter: 13200, curr loss: 1.386268973350525, avg loss: 1.3862940406799316\n",
      "trial: 2, iter: 13400, curr loss: 1.3862587213516235, avg loss: 1.3862935853004457\n",
      "trial: 2, iter: 13600, curr loss: 1.3867086172103882, avg loss: 1.386285110116005\n",
      "trial: 2, iter: 13800, curr loss: 1.3865201473236084, avg loss: 1.3862997174263\n",
      "trial: 2, iter: 14000, curr loss: 1.386326551437378, avg loss: 1.386308650970459\n",
      "trial: 2, iter: 14200, curr loss: 1.386296272277832, avg loss: 1.3863009923696519\n",
      "trial: 2, iter: 14400, curr loss: 1.3862539529800415, avg loss: 1.3862956976890564\n",
      "trial: 2, iter: 14600, curr loss: 1.3862981796264648, avg loss: 1.38629727602005\n",
      "trial: 2, iter: 14800, curr loss: 1.386303424835205, avg loss: 1.3862950229644775\n",
      "trial: 2, iter: 15000, curr loss: 1.386334776878357, avg loss: 1.3862957590818406\n",
      "trial: 2, iter: 15200, curr loss: 1.3863129615783691, avg loss: 1.386298098564148\n",
      "trial: 2, iter: 15400, curr loss: 1.3862767219543457, avg loss: 1.3862958663702012\n",
      "trial: 2, iter: 15600, curr loss: 1.3863283395767212, avg loss: 1.3862953931093216\n",
      "trial: 2, ldr: 0.00010794658737722784\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3867565393447876, avg loss: 1.3873191970586776\n",
      "trial: 3, iter: 400, curr loss: 1.3867466449737549, avg loss: 1.3865632456541062\n",
      "trial: 3, iter: 600, curr loss: 1.3861396312713623, avg loss: 1.3865566802024842\n",
      "trial: 3, iter: 800, curr loss: 1.3887430429458618, avg loss: 1.3865510934591294\n",
      "trial: 3, iter: 1000, curr loss: 1.387562870979309, avg loss: 1.3865809690952302\n",
      "trial: 3, iter: 1200, curr loss: 1.3863248825073242, avg loss: 1.3865090930461883\n",
      "trial: 3, iter: 1400, curr loss: 1.3853200674057007, avg loss: 1.3863337850570678\n",
      "trial: 3, iter: 1600, curr loss: 1.3857815265655518, avg loss: 1.386454622745514\n",
      "trial: 3, iter: 1800, curr loss: 1.386403203010559, avg loss: 1.3865293151140212\n",
      "trial: 3, iter: 2000, curr loss: 1.3867454528808594, avg loss: 1.3864659172296525\n",
      "trial: 3, iter: 2200, curr loss: 1.3864564895629883, avg loss: 1.3863736915588378\n",
      "trial: 3, iter: 2400, curr loss: 1.3862394094467163, avg loss: 1.3863097196817398\n",
      "trial: 3, iter: 2600, curr loss: 1.383880853652954, avg loss: 1.3864436489343643\n",
      "trial: 3, iter: 2800, curr loss: 1.3862708806991577, avg loss: 1.3864158409833909\n",
      "trial: 3, iter: 3000, curr loss: 1.386254906654358, avg loss: 1.3863397014141083\n",
      "trial: 3, iter: 3200, curr loss: 1.387001633644104, avg loss: 1.3864031606912612\n",
      "trial: 3, iter: 3400, curr loss: 1.3866777420043945, avg loss: 1.3863467001914977\n",
      "trial: 3, iter: 3600, curr loss: 1.3870364427566528, avg loss: 1.3863120305538177\n",
      "trial: 3, iter: 3800, curr loss: 1.3862053155899048, avg loss: 1.386334052681923\n",
      "trial: 3, iter: 4000, curr loss: 1.3859100341796875, avg loss: 1.3863435941934585\n",
      "trial: 3, iter: 4200, curr loss: 1.385951280593872, avg loss: 1.3863110905885696\n",
      "trial: 3, iter: 4400, curr loss: 1.3862357139587402, avg loss: 1.3863356226682664\n",
      "trial: 3, iter: 4600, curr loss: 1.3861198425292969, avg loss: 1.3863025993108749\n",
      "trial: 3, iter: 4800, curr loss: 1.3871644735336304, avg loss: 1.386407461166382\n",
      "trial: 3, iter: 5000, curr loss: 1.387033224105835, avg loss: 1.3863647413253783\n",
      "trial: 3, iter: 5200, curr loss: 1.3868346214294434, avg loss: 1.3863960903882981\n",
      "trial: 3, iter: 5400, curr loss: 1.386409878730774, avg loss: 1.3863275045156478\n",
      "trial: 3, iter: 5600, curr loss: 1.3863723278045654, avg loss: 1.3863203018903731\n",
      "trial: 3, iter: 5800, curr loss: 1.386427640914917, avg loss: 1.3863403648138046\n",
      "trial: 3, iter: 6000, curr loss: 1.3863576650619507, avg loss: 1.3863144689798355\n",
      "trial: 3, iter: 6200, curr loss: 1.3861701488494873, avg loss: 1.386312112212181\n",
      "trial: 3, iter: 6400, curr loss: 1.3862378597259521, avg loss: 1.3863115227222442\n",
      "trial: 3, iter: 6600, curr loss: 1.3862658739089966, avg loss: 1.3862975722551345\n",
      "trial: 3, iter: 6800, curr loss: 1.3862357139587402, avg loss: 1.386307224035263\n",
      "trial: 3, iter: 7000, curr loss: 1.3862028121948242, avg loss: 1.3863012385368347\n",
      "trial: 3, iter: 7200, curr loss: 1.3862664699554443, avg loss: 1.3863037532567979\n",
      "trial: 3, iter: 7400, curr loss: 1.386220932006836, avg loss: 1.386295783519745\n",
      "trial: 3, iter: 7600, curr loss: 1.386372685432434, avg loss: 1.386296536922455\n",
      "trial: 3, iter: 7800, curr loss: 1.3863551616668701, avg loss: 1.38629452586174\n",
      "trial: 3, iter: 8000, curr loss: 1.3863309621810913, avg loss: 1.386302146911621\n",
      "trial: 3, iter: 8200, curr loss: 1.3861985206604004, avg loss: 1.386291011571884\n",
      "trial: 3, iter: 8400, curr loss: 1.3863370418548584, avg loss: 1.3862907314300537\n",
      "trial: 3, iter: 8600, curr loss: 1.3860864639282227, avg loss: 1.386277202963829\n",
      "trial: 3, iter: 8800, curr loss: 1.386289358139038, avg loss: 1.3863389724493027\n",
      "trial: 3, iter: 9000, curr loss: 1.3863662481307983, avg loss: 1.3862979125976562\n",
      "trial: 3, iter: 9200, curr loss: 1.386295199394226, avg loss: 1.3863023507595063\n",
      "trial: 3, iter: 9400, curr loss: 1.3863379955291748, avg loss: 1.3862957453727722\n",
      "trial: 3, iter: 9600, curr loss: 1.3853651285171509, avg loss: 1.3863558650016785\n",
      "trial: 3, iter: 9800, curr loss: 1.3861173391342163, avg loss: 1.3863625717163086\n",
      "trial: 3, iter: 10000, curr loss: 1.3865474462509155, avg loss: 1.3863394093513488\n",
      "trial: 3, iter: 10200, curr loss: 1.3861163854599, avg loss: 1.386295685172081\n",
      "trial: 3, iter: 10400, curr loss: 1.3864933252334595, avg loss: 1.3863058984279633\n",
      "trial: 3, iter: 10600, curr loss: 1.3867213726043701, avg loss: 1.3863103115558624\n",
      "trial: 3, iter: 10800, curr loss: 1.3862206935882568, avg loss: 1.386317915916443\n",
      "trial: 3, iter: 11000, curr loss: 1.3862861394882202, avg loss: 1.386322245001793\n",
      "trial: 3, iter: 11200, curr loss: 1.3864768743515015, avg loss: 1.3863024812936784\n",
      "trial: 3, iter: 11400, curr loss: 1.3866448402404785, avg loss: 1.3863069534301757\n",
      "trial: 3, iter: 11600, curr loss: 1.3863879442214966, avg loss: 1.3862997055053712\n",
      "trial: 3, iter: 11800, curr loss: 1.3863601684570312, avg loss: 1.3863243818283082\n",
      "trial: 3, iter: 12000, curr loss: 1.3863801956176758, avg loss: 1.3863262438774109\n",
      "trial: 3, iter: 12200, curr loss: 1.3862485885620117, avg loss: 1.3863082015514374\n",
      "trial: 3, iter: 12400, curr loss: 1.3864883184432983, avg loss: 1.3863057601451874\n",
      "trial: 3, iter: 12600, curr loss: 1.3863085508346558, avg loss: 1.3862946224212647\n",
      "trial: 3, iter: 12800, curr loss: 1.3859472274780273, avg loss: 1.3862713122367858\n",
      "trial: 3, iter: 13000, curr loss: 1.3865975141525269, avg loss: 1.3863178771734237\n",
      "trial: 3, iter: 13200, curr loss: 1.3862707614898682, avg loss: 1.3863045704364776\n",
      "trial: 3, iter: 13400, curr loss: 1.3862560987472534, avg loss: 1.3863025748729705\n",
      "trial: 3, iter: 13600, curr loss: 1.3862112760543823, avg loss: 1.3862977147102356\n",
      "trial: 3, iter: 13800, curr loss: 1.3866636753082275, avg loss: 1.3862781977653504\n",
      "trial: 3, iter: 14000, curr loss: 1.386379361152649, avg loss: 1.3863216024637222\n",
      "trial: 3, iter: 14200, curr loss: 1.386430263519287, avg loss: 1.3862940204143523\n",
      "trial: 3, iter: 14400, curr loss: 1.38631272315979, avg loss: 1.3862973880767822\n",
      "trial: 3, iter: 14600, curr loss: 1.3863533735275269, avg loss: 1.386295480132103\n",
      "trial: 3, iter: 14800, curr loss: 1.3863011598587036, avg loss: 1.3862990951538086\n",
      "trial: 3, iter: 15000, curr loss: 1.3863013982772827, avg loss: 1.3862917989492416\n",
      "trial: 3, iter: 15200, curr loss: 1.3863343000411987, avg loss: 1.3862979608774184\n",
      "trial: 3, iter: 15400, curr loss: 1.3865634202957153, avg loss: 1.386295126080513\n",
      "trial: 3, iter: 15600, curr loss: 1.3862769603729248, avg loss: 1.386296830177307\n",
      "trial: 3, ldr: 0.0011029765009880066\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3883682489395142, avg loss: 1.3871617823839189\n",
      "trial: 4, iter: 400, curr loss: 1.387425184249878, avg loss: 1.3867515987157821\n",
      "trial: 4, iter: 600, curr loss: 1.3882883787155151, avg loss: 1.3866190248727799\n",
      "trial: 4, iter: 800, curr loss: 1.388481616973877, avg loss: 1.3864581042528152\n",
      "trial: 4, iter: 1000, curr loss: 1.3859647512435913, avg loss: 1.3865539258718491\n",
      "trial: 4, iter: 1200, curr loss: 1.385799527168274, avg loss: 1.386596164703369\n",
      "trial: 4, iter: 1400, curr loss: 1.3872268199920654, avg loss: 1.3864220046997071\n",
      "trial: 4, iter: 1600, curr loss: 1.386765480041504, avg loss: 1.386307842731476\n",
      "trial: 4, iter: 1800, curr loss: 1.3865187168121338, avg loss: 1.386402763724327\n",
      "trial: 4, iter: 2000, curr loss: 1.3867515325546265, avg loss: 1.3863673901557922\n",
      "trial: 4, iter: 2200, curr loss: 1.3871601819992065, avg loss: 1.3863510048389436\n",
      "trial: 4, iter: 2400, curr loss: 1.3870652914047241, avg loss: 1.3863126534223555\n",
      "trial: 4, iter: 2600, curr loss: 1.3865094184875488, avg loss: 1.38645036816597\n",
      "trial: 4, iter: 2800, curr loss: 1.385351538658142, avg loss: 1.386310487985611\n",
      "trial: 4, iter: 3000, curr loss: 1.3849693536758423, avg loss: 1.3863912224769592\n",
      "trial: 4, iter: 3200, curr loss: 1.3857611417770386, avg loss: 1.3863557386398315\n",
      "trial: 4, iter: 3400, curr loss: 1.3867307901382446, avg loss: 1.3864316791296005\n",
      "trial: 4, iter: 3600, curr loss: 1.3867932558059692, avg loss: 1.3863580638170243\n",
      "trial: 4, iter: 3800, curr loss: 1.386457920074463, avg loss: 1.3863596731424332\n",
      "trial: 4, iter: 4000, curr loss: 1.3863779306411743, avg loss: 1.386341542005539\n",
      "trial: 4, iter: 4200, curr loss: 1.3853939771652222, avg loss: 1.3862754184007644\n",
      "trial: 4, iter: 4400, curr loss: 1.3870289325714111, avg loss: 1.3863709247112275\n",
      "trial: 4, iter: 4600, curr loss: 1.3871561288833618, avg loss: 1.3863598358631135\n",
      "trial: 4, iter: 4800, curr loss: 1.3864166736602783, avg loss: 1.3863268560171127\n",
      "trial: 4, iter: 5000, curr loss: 1.386419653892517, avg loss: 1.3863513618707657\n",
      "trial: 4, iter: 5200, curr loss: 1.3861839771270752, avg loss: 1.3863281333446502\n",
      "trial: 4, iter: 5400, curr loss: 1.3850326538085938, avg loss: 1.3863338512182235\n",
      "trial: 4, iter: 5600, curr loss: 1.386920690536499, avg loss: 1.3863166165351868\n",
      "trial: 4, iter: 5800, curr loss: 1.386518955230713, avg loss: 1.386328891515732\n",
      "trial: 4, iter: 6000, curr loss: 1.3867170810699463, avg loss: 1.3863294583559036\n",
      "trial: 4, iter: 6200, curr loss: 1.3864623308181763, avg loss: 1.3863509786128998\n",
      "trial: 4, iter: 6400, curr loss: 1.3866922855377197, avg loss: 1.3863219010829926\n",
      "trial: 4, iter: 6600, curr loss: 1.3863776922225952, avg loss: 1.3863282489776612\n",
      "trial: 4, iter: 6800, curr loss: 1.385919213294983, avg loss: 1.3862956935167312\n",
      "trial: 4, iter: 7000, curr loss: 1.3865861892700195, avg loss: 1.3863080638647078\n",
      "trial: 4, iter: 7200, curr loss: 1.3862231969833374, avg loss: 1.3863145571947098\n",
      "trial: 4, iter: 7400, curr loss: 1.3860760927200317, avg loss: 1.3862969923019408\n",
      "trial: 4, iter: 7600, curr loss: 1.3859435319900513, avg loss: 1.386331399679184\n",
      "trial: 4, iter: 7800, curr loss: 1.3859374523162842, avg loss: 1.386316048502922\n",
      "trial: 4, iter: 8000, curr loss: 1.386160969734192, avg loss: 1.3863902294635773\n",
      "trial: 4, iter: 8200, curr loss: 1.386430025100708, avg loss: 1.3863589960336684\n",
      "trial: 4, iter: 8400, curr loss: 1.3860799074172974, avg loss: 1.3863773733377456\n",
      "trial: 4, iter: 8600, curr loss: 1.3866513967514038, avg loss: 1.386334079504013\n",
      "trial: 4, iter: 8800, curr loss: 1.38639235496521, avg loss: 1.3863308238983154\n",
      "trial: 4, iter: 9000, curr loss: 1.3861366510391235, avg loss: 1.3863103222846984\n",
      "trial: 4, iter: 9200, curr loss: 1.3864858150482178, avg loss: 1.3863103044033052\n",
      "trial: 4, iter: 9400, curr loss: 1.3859739303588867, avg loss: 1.3863095372915268\n",
      "trial: 4, iter: 9600, curr loss: 1.3860833644866943, avg loss: 1.3862883728742599\n",
      "trial: 4, iter: 9800, curr loss: 1.3864845037460327, avg loss: 1.3862950366735458\n",
      "trial: 4, iter: 10000, curr loss: 1.386183738708496, avg loss: 1.3863130396604537\n",
      "trial: 4, iter: 10200, curr loss: 1.3859728574752808, avg loss: 1.386305724978447\n",
      "trial: 4, iter: 10400, curr loss: 1.3861169815063477, avg loss: 1.3862971806526183\n",
      "trial: 4, iter: 10600, curr loss: 1.3863027095794678, avg loss: 1.3863191920518876\n",
      "trial: 4, iter: 10800, curr loss: 1.3863095045089722, avg loss: 1.3862946647405625\n",
      "trial: 4, iter: 11000, curr loss: 1.38629949092865, avg loss: 1.386298446059227\n",
      "trial: 4, iter: 11200, curr loss: 1.3863195180892944, avg loss: 1.3863043469190597\n",
      "trial: 4, iter: 11400, curr loss: 1.386308193206787, avg loss: 1.3863019227981568\n",
      "trial: 4, iter: 11600, curr loss: 1.3865535259246826, avg loss: 1.3862908273935317\n",
      "trial: 4, iter: 11800, curr loss: 1.3864505290985107, avg loss: 1.3863241004943847\n",
      "trial: 4, iter: 12000, curr loss: 1.3861966133117676, avg loss: 1.3863131129741668\n",
      "trial: 4, iter: 12200, curr loss: 1.3863316774368286, avg loss: 1.3863101071119308\n",
      "trial: 4, iter: 12400, curr loss: 1.3862149715423584, avg loss: 1.3863004916906356\n",
      "trial: 4, iter: 12600, curr loss: 1.387094259262085, avg loss: 1.3862999814748764\n",
      "trial: 4, iter: 12800, curr loss: 1.3864736557006836, avg loss: 1.3863327687978744\n",
      "trial: 4, iter: 13000, curr loss: 1.3860740661621094, avg loss: 1.3863243663311005\n",
      "trial: 4, iter: 13200, curr loss: 1.38654363155365, avg loss: 1.3863040804862976\n",
      "trial: 4, iter: 13400, curr loss: 1.3865070343017578, avg loss: 1.386284150481224\n",
      "trial: 4, iter: 13600, curr loss: 1.3862868547439575, avg loss: 1.3863075655698776\n",
      "trial: 4, iter: 13800, curr loss: 1.3861123323440552, avg loss: 1.3863235092163086\n",
      "trial: 4, iter: 14000, curr loss: 1.3865177631378174, avg loss: 1.3862975704669953\n",
      "trial: 4, iter: 14200, curr loss: 1.3861873149871826, avg loss: 1.3863085103034973\n",
      "trial: 4, iter: 14400, curr loss: 1.3864330053329468, avg loss: 1.386317105293274\n",
      "trial: 4, iter: 14600, curr loss: 1.386289358139038, avg loss: 1.386304965019226\n",
      "trial: 4, iter: 14800, curr loss: 1.3864177465438843, avg loss: 1.3862960720062256\n",
      "trial: 4, iter: 15000, curr loss: 1.3863095045089722, avg loss: 1.3862979179620742\n",
      "trial: 4, iter: 15200, curr loss: 1.3863099813461304, avg loss: 1.3862956476211548\n",
      "trial: 4, iter: 15400, curr loss: 1.3863122463226318, avg loss: 1.3862959253787994\n",
      "trial: 4, iter: 15600, curr loss: 1.386311411857605, avg loss: 1.386295081973076\n",
      "trial: 4, ldr: 0.0002877453516703099\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3859590291976929, avg loss: 1.3872011852264405\n",
      "trial: 5, iter: 400, curr loss: 1.3874428272247314, avg loss: 1.3866728258132934\n",
      "trial: 5, iter: 600, curr loss: 1.3873839378356934, avg loss: 1.3864485120773316\n",
      "trial: 5, iter: 800, curr loss: 1.385574460029602, avg loss: 1.3865768080949783\n",
      "trial: 5, iter: 1000, curr loss: 1.3883370161056519, avg loss: 1.3864638298749923\n",
      "trial: 5, iter: 1200, curr loss: 1.3865771293640137, avg loss: 1.3863925886154176\n",
      "trial: 5, iter: 1400, curr loss: 1.3866841793060303, avg loss: 1.3863801181316375\n",
      "trial: 5, iter: 1600, curr loss: 1.3879684209823608, avg loss: 1.38639885365963\n",
      "trial: 5, iter: 1800, curr loss: 1.3871867656707764, avg loss: 1.3864364224672316\n",
      "trial: 5, iter: 2000, curr loss: 1.386804461479187, avg loss: 1.3864295679330825\n",
      "trial: 5, iter: 2200, curr loss: 1.386589527130127, avg loss: 1.3864441376924515\n",
      "trial: 5, iter: 2400, curr loss: 1.3871663808822632, avg loss: 1.3863679522275925\n",
      "trial: 5, iter: 2600, curr loss: 1.3865330219268799, avg loss: 1.3863648676872253\n",
      "trial: 5, iter: 2800, curr loss: 1.387138843536377, avg loss: 1.386364837884903\n",
      "trial: 5, iter: 3000, curr loss: 1.3860362768173218, avg loss: 1.3863115125894547\n",
      "trial: 5, iter: 3200, curr loss: 1.3862019777297974, avg loss: 1.3863875502347947\n",
      "trial: 5, iter: 3400, curr loss: 1.3867156505584717, avg loss: 1.3863565689325332\n",
      "trial: 5, iter: 3600, curr loss: 1.3871967792510986, avg loss: 1.386336047053337\n",
      "trial: 5, iter: 3800, curr loss: 1.3869521617889404, avg loss: 1.3863486462831498\n",
      "trial: 5, iter: 4000, curr loss: 1.3872584104537964, avg loss: 1.386268230676651\n",
      "trial: 5, iter: 4200, curr loss: 1.3866651058197021, avg loss: 1.3863777703046798\n",
      "trial: 5, iter: 4400, curr loss: 1.387439250946045, avg loss: 1.3863427090644835\n",
      "trial: 5, iter: 4600, curr loss: 1.3861557245254517, avg loss: 1.3863292509317398\n",
      "trial: 5, iter: 4800, curr loss: 1.3863096237182617, avg loss: 1.3863079887628555\n",
      "trial: 5, iter: 5000, curr loss: 1.3862371444702148, avg loss: 1.3863151443004609\n",
      "trial: 5, iter: 5200, curr loss: 1.3863096237182617, avg loss: 1.3863241666555404\n",
      "trial: 5, iter: 5400, curr loss: 1.3864787817001343, avg loss: 1.3863014274835586\n",
      "trial: 5, iter: 5600, curr loss: 1.3865916728973389, avg loss: 1.3863190340995788\n",
      "trial: 5, iter: 5800, curr loss: 1.3862677812576294, avg loss: 1.3863180696964263\n",
      "trial: 5, iter: 6000, curr loss: 1.3863471746444702, avg loss: 1.386306384205818\n",
      "trial: 5, iter: 6200, curr loss: 1.3862844705581665, avg loss: 1.3863074368238448\n",
      "trial: 5, iter: 6400, curr loss: 1.386304497718811, avg loss: 1.3863056123256683\n",
      "trial: 5, iter: 6600, curr loss: 1.3865562677383423, avg loss: 1.3862984442710877\n",
      "trial: 5, iter: 6800, curr loss: 1.3863638639450073, avg loss: 1.386307128071785\n",
      "trial: 5, iter: 7000, curr loss: 1.3864995241165161, avg loss: 1.3862984371185303\n",
      "trial: 5, iter: 7200, curr loss: 1.3863409757614136, avg loss: 1.3863007140159607\n",
      "trial: 5, iter: 7400, curr loss: 1.3859349489212036, avg loss: 1.3862758696079254\n",
      "trial: 5, iter: 7600, curr loss: 1.3862619400024414, avg loss: 1.386308535337448\n",
      "trial: 5, iter: 7800, curr loss: 1.3862760066986084, avg loss: 1.3862997263669967\n",
      "trial: 5, iter: 8000, curr loss: 1.386350393295288, avg loss: 1.386309403181076\n",
      "trial: 5, iter: 8200, curr loss: 1.3863292932510376, avg loss: 1.3862978857755661\n",
      "trial: 5, iter: 8400, curr loss: 1.3862794637680054, avg loss: 1.3862997817993163\n",
      "trial: 5, iter: 8600, curr loss: 1.386155605316162, avg loss: 1.3863051682710648\n",
      "trial: 5, iter: 8800, curr loss: 1.3863742351531982, avg loss: 1.3863040882349014\n",
      "trial: 5, iter: 9000, curr loss: 1.3863011598587036, avg loss: 1.3863025796413422\n",
      "trial: 5, iter: 9200, curr loss: 1.386349081993103, avg loss: 1.3862946265935898\n",
      "trial: 5, iter: 9400, curr loss: 1.3861896991729736, avg loss: 1.3863025724887847\n",
      "trial: 5, iter: 9600, curr loss: 1.386320948600769, avg loss: 1.3862985914945603\n",
      "trial: 5, iter: 9800, curr loss: 1.3862916231155396, avg loss: 1.3862955969572068\n",
      "trial: 5, iter: 10000, curr loss: 1.3862926959991455, avg loss: 1.3863002210855484\n",
      "trial: 5, iter: 10200, curr loss: 1.386301875114441, avg loss: 1.3862982660531997\n",
      "trial: 5, iter: 10400, curr loss: 1.3863379955291748, avg loss: 1.3862971705198288\n",
      "trial: 5, iter: 10600, curr loss: 1.3863571882247925, avg loss: 1.3862952321767807\n",
      "trial: 5, iter: 10800, curr loss: 1.3862965106964111, avg loss: 1.3862971556186676\n",
      "trial: 5, iter: 11000, curr loss: 1.3862993717193604, avg loss: 1.3862980431318284\n",
      "trial: 5, iter: 11200, curr loss: 1.386287808418274, avg loss: 1.386294773221016\n",
      "trial: 5, iter: 11400, curr loss: 1.3862496614456177, avg loss: 1.3862948459386826\n",
      "trial: 5, iter: 11600, curr loss: 1.3863046169281006, avg loss: 1.3862958627939224\n",
      "trial: 5, iter: 11800, curr loss: 1.3862954378128052, avg loss: 1.3862969923019408\n",
      "trial: 5, iter: 12000, curr loss: 1.38631010055542, avg loss: 1.3862976348400116\n",
      "trial: 5, iter: 12200, curr loss: 1.3862569332122803, avg loss: 1.3862910604476928\n",
      "trial: 5, iter: 12400, curr loss: 1.3862969875335693, avg loss: 1.3863039761781693\n",
      "trial: 5, iter: 12600, curr loss: 1.386264443397522, avg loss: 1.3862970739603042\n",
      "trial: 5, iter: 12800, curr loss: 1.3863515853881836, avg loss: 1.3862942600250243\n",
      "trial: 5, iter: 13000, curr loss: 1.386301875114441, avg loss: 1.386296415925026\n",
      "trial: 5, iter: 13200, curr loss: 1.3862932920455933, avg loss: 1.3862985843420028\n",
      "trial: 5, iter: 13400, curr loss: 1.386299729347229, avg loss: 1.3862948364019394\n",
      "trial: 5, iter: 13600, curr loss: 1.3863128423690796, avg loss: 1.386294111609459\n",
      "trial: 5, iter: 13800, curr loss: 1.386306881904602, avg loss: 1.3862937933206558\n",
      "trial: 5, iter: 14000, curr loss: 1.3861981630325317, avg loss: 1.386313892006874\n",
      "trial: 5, iter: 14200, curr loss: 1.386286735534668, avg loss: 1.3862966203689575\n",
      "trial: 5, iter: 14400, curr loss: 1.3864282369613647, avg loss: 1.3863009136915208\n",
      "trial: 5, iter: 14600, curr loss: 1.3862909078598022, avg loss: 1.386297574043274\n",
      "trial: 5, iter: 14800, curr loss: 1.386298656463623, avg loss: 1.386294577717781\n",
      "trial: 5, iter: 15000, curr loss: 1.3862943649291992, avg loss: 1.3862937426567077\n",
      "trial: 5, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.3862943506240846\n",
      "trial: 5, iter: 15400, curr loss: 1.3862944841384888, avg loss: 1.386294465661049\n",
      "trial: 5, iter: 15600, curr loss: 1.3862943649291992, avg loss: 1.3862944746017456\n",
      "trial: 5, ldr: -5.289018190524075e-06\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0003790547094467911\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3856585025787354, avg loss: 1.387191880941391\n",
      "trial: 1, iter: 400, curr loss: 1.3888968229293823, avg loss: 1.386823843717575\n",
      "trial: 1, iter: 600, curr loss: 1.3884004354476929, avg loss: 1.3865718334913253\n",
      "trial: 1, iter: 800, curr loss: 1.3875303268432617, avg loss: 1.3865465748310088\n",
      "trial: 1, iter: 1000, curr loss: 1.3859498500823975, avg loss: 1.3864395660161972\n",
      "trial: 1, iter: 1200, curr loss: 1.3854817152023315, avg loss: 1.3863864213228225\n",
      "trial: 1, iter: 1400, curr loss: 1.3850549459457397, avg loss: 1.3864084208011627\n",
      "trial: 1, iter: 1600, curr loss: 1.389350175857544, avg loss: 1.3863876855373383\n",
      "trial: 1, iter: 1800, curr loss: 1.384508728981018, avg loss: 1.3864168602228164\n",
      "trial: 1, iter: 2000, curr loss: 1.3873887062072754, avg loss: 1.3864420801401138\n",
      "trial: 1, iter: 2200, curr loss: 1.3865771293640137, avg loss: 1.3864289706945419\n",
      "trial: 1, iter: 2400, curr loss: 1.386492371559143, avg loss: 1.3864280664920807\n",
      "trial: 1, iter: 2600, curr loss: 1.3855928182601929, avg loss: 1.3864751225709915\n",
      "trial: 1, iter: 2800, curr loss: 1.3869705200195312, avg loss: 1.386361495256424\n",
      "trial: 1, iter: 3000, curr loss: 1.3861461877822876, avg loss: 1.3863717412948608\n",
      "trial: 1, iter: 3200, curr loss: 1.3871464729309082, avg loss: 1.386370838880539\n",
      "trial: 1, iter: 3400, curr loss: 1.3857446908950806, avg loss: 1.3863325607776642\n",
      "trial: 1, iter: 3600, curr loss: 1.3880283832550049, avg loss: 1.3864136284589768\n",
      "trial: 1, iter: 3800, curr loss: 1.3862533569335938, avg loss: 1.3863763344287872\n",
      "trial: 1, iter: 4000, curr loss: 1.3862272500991821, avg loss: 1.3863474369049071\n",
      "trial: 1, iter: 4200, curr loss: 1.385520577430725, avg loss: 1.3862805128097535\n",
      "trial: 1, iter: 4400, curr loss: 1.3857454061508179, avg loss: 1.3863012850284577\n",
      "trial: 1, iter: 4600, curr loss: 1.3868211507797241, avg loss: 1.386382658481598\n",
      "trial: 1, iter: 4800, curr loss: 1.3862191438674927, avg loss: 1.3863602662086487\n",
      "trial: 1, iter: 5000, curr loss: 1.3862050771713257, avg loss: 1.3862949985265731\n",
      "trial: 1, iter: 5200, curr loss: 1.3861794471740723, avg loss: 1.386314348578453\n",
      "trial: 1, iter: 5400, curr loss: 1.386448621749878, avg loss: 1.3863155621290206\n",
      "trial: 1, iter: 5600, curr loss: 1.3860889673233032, avg loss: 1.3863222336769103\n",
      "trial: 1, iter: 5800, curr loss: 1.3859496116638184, avg loss: 1.3863229113817215\n",
      "trial: 1, iter: 6000, curr loss: 1.3860993385314941, avg loss: 1.3862944543361664\n",
      "trial: 1, iter: 6200, curr loss: 1.386810302734375, avg loss: 1.3863429427146912\n",
      "trial: 1, iter: 6400, curr loss: 1.38676118850708, avg loss: 1.3862527006864547\n",
      "trial: 1, iter: 6600, curr loss: 1.3852392435073853, avg loss: 1.3862953001260758\n",
      "trial: 1, iter: 6800, curr loss: 1.386551856994629, avg loss: 1.3863362896442413\n",
      "trial: 1, iter: 7000, curr loss: 1.387142539024353, avg loss: 1.3863698422908783\n",
      "trial: 1, iter: 7200, curr loss: 1.3864532709121704, avg loss: 1.3864012318849563\n",
      "trial: 1, iter: 7400, curr loss: 1.3860788345336914, avg loss: 1.3863107603788376\n",
      "trial: 1, iter: 7600, curr loss: 1.386000633239746, avg loss: 1.3863081192970277\n",
      "trial: 1, iter: 7800, curr loss: 1.386751413345337, avg loss: 1.386334182024002\n",
      "trial: 1, iter: 8000, curr loss: 1.3858588933944702, avg loss: 1.3863540607690812\n",
      "trial: 1, iter: 8200, curr loss: 1.386767864227295, avg loss: 1.3863261020183564\n",
      "trial: 1, iter: 8400, curr loss: 1.386386513710022, avg loss: 1.3863218438625335\n",
      "trial: 1, iter: 8600, curr loss: 1.3866528272628784, avg loss: 1.386318135857582\n",
      "trial: 1, iter: 8800, curr loss: 1.386191725730896, avg loss: 1.3863405323028564\n",
      "trial: 1, iter: 9000, curr loss: 1.3862178325653076, avg loss: 1.3863178783655166\n",
      "trial: 1, iter: 9200, curr loss: 1.385980248451233, avg loss: 1.386299843788147\n",
      "trial: 1, iter: 9400, curr loss: 1.3860920667648315, avg loss: 1.386306238770485\n",
      "trial: 1, iter: 9600, curr loss: 1.385804295539856, avg loss: 1.3862965947389603\n",
      "trial: 1, iter: 9800, curr loss: 1.3865199089050293, avg loss: 1.3862968826293944\n",
      "trial: 1, iter: 10000, curr loss: 1.3860663175582886, avg loss: 1.3863142985105514\n",
      "trial: 1, iter: 10200, curr loss: 1.3859930038452148, avg loss: 1.386306803226471\n",
      "trial: 1, iter: 10400, curr loss: 1.386084794998169, avg loss: 1.386297534108162\n",
      "trial: 1, iter: 10600, curr loss: 1.3863741159439087, avg loss: 1.3863026738166808\n",
      "trial: 1, iter: 10800, curr loss: 1.3865166902542114, avg loss: 1.3863072335720061\n",
      "trial: 1, iter: 11000, curr loss: 1.3861827850341797, avg loss: 1.3863122218847275\n",
      "trial: 1, iter: 11200, curr loss: 1.3863277435302734, avg loss: 1.3863029712438584\n",
      "trial: 1, iter: 11400, curr loss: 1.3864624500274658, avg loss: 1.3862960159778595\n",
      "trial: 1, iter: 11600, curr loss: 1.3863270282745361, avg loss: 1.3862960040569305\n",
      "trial: 1, iter: 11800, curr loss: 1.386292815208435, avg loss: 1.38629969060421\n",
      "trial: 1, iter: 12000, curr loss: 1.3863779306411743, avg loss: 1.3863039439916611\n",
      "trial: 1, iter: 12200, curr loss: 1.3863105773925781, avg loss: 1.3862985146045685\n",
      "trial: 1, iter: 12400, curr loss: 1.3862249851226807, avg loss: 1.3862851440906525\n",
      "trial: 1, iter: 12600, curr loss: 1.3863499164581299, avg loss: 1.3862956881523132\n",
      "trial: 1, iter: 12800, curr loss: 1.3862332105636597, avg loss: 1.386299124956131\n",
      "trial: 1, iter: 13000, curr loss: 1.3863084316253662, avg loss: 1.3863014107942582\n",
      "trial: 1, iter: 13200, curr loss: 1.3864145278930664, avg loss: 1.3862931609153748\n",
      "trial: 1, iter: 13400, curr loss: 1.3862920999526978, avg loss: 1.3863085395097732\n",
      "trial: 1, iter: 13600, curr loss: 1.3863117694854736, avg loss: 1.386305496096611\n",
      "trial: 1, iter: 13800, curr loss: 1.3862658739089966, avg loss: 1.3862986862659454\n",
      "trial: 1, iter: 14000, curr loss: 1.3862147331237793, avg loss: 1.3862935709953308\n",
      "trial: 1, iter: 14200, curr loss: 1.386210322380066, avg loss: 1.3862904584407807\n",
      "trial: 1, iter: 14400, curr loss: 1.3861427307128906, avg loss: 1.3863043886423112\n",
      "trial: 1, iter: 14600, curr loss: 1.386277437210083, avg loss: 1.3862991225719452\n",
      "trial: 1, iter: 14800, curr loss: 1.38611900806427, avg loss: 1.386289383172989\n",
      "trial: 1, iter: 15000, curr loss: 1.3860965967178345, avg loss: 1.3863004660606384\n",
      "trial: 1, iter: 15200, curr loss: 1.387542724609375, avg loss: 1.3862856954336167\n",
      "trial: 1, iter: 15400, curr loss: 1.3862000703811646, avg loss: 1.3863075011968613\n",
      "trial: 1, iter: 15600, curr loss: 1.386407732963562, avg loss: 1.3863020426034927\n",
      "trial: 1, ldr: -0.0014364691451191902\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.383100152015686, avg loss: 1.3873018091917038\n",
      "trial: 2, iter: 400, curr loss: 1.3850502967834473, avg loss: 1.386621509194374\n",
      "trial: 2, iter: 600, curr loss: 1.386527180671692, avg loss: 1.3865603917837144\n",
      "trial: 2, iter: 800, curr loss: 1.3873100280761719, avg loss: 1.386514589190483\n",
      "trial: 2, iter: 1000, curr loss: 1.385981559753418, avg loss: 1.3863845700025559\n",
      "trial: 2, iter: 1200, curr loss: 1.3884613513946533, avg loss: 1.3865031486749648\n",
      "trial: 2, iter: 1400, curr loss: 1.3865256309509277, avg loss: 1.3864046323299408\n",
      "trial: 2, iter: 1600, curr loss: 1.3863472938537598, avg loss: 1.3864307928085327\n",
      "trial: 2, iter: 1800, curr loss: 1.3864988088607788, avg loss: 1.3865132075548172\n",
      "trial: 2, iter: 2000, curr loss: 1.3864645957946777, avg loss: 1.3864046460390091\n",
      "trial: 2, iter: 2200, curr loss: 1.3861191272735596, avg loss: 1.3863912528753282\n",
      "trial: 2, iter: 2400, curr loss: 1.3861415386199951, avg loss: 1.3863489210605622\n",
      "trial: 2, iter: 2600, curr loss: 1.386054515838623, avg loss: 1.3864295482635498\n",
      "trial: 2, iter: 2800, curr loss: 1.3859964609146118, avg loss: 1.386276200413704\n",
      "trial: 2, iter: 3000, curr loss: 1.3869634866714478, avg loss: 1.3863240629434586\n",
      "trial: 2, iter: 3200, curr loss: 1.386913537979126, avg loss: 1.3864159363508224\n",
      "trial: 2, iter: 3400, curr loss: 1.386954426765442, avg loss: 1.3863334673643113\n",
      "trial: 2, iter: 3600, curr loss: 1.3866832256317139, avg loss: 1.3863448762893678\n",
      "trial: 2, iter: 3800, curr loss: 1.3856770992279053, avg loss: 1.3863416570425033\n",
      "trial: 2, iter: 4000, curr loss: 1.386293649673462, avg loss: 1.386346675157547\n",
      "trial: 2, iter: 4200, curr loss: 1.3856186866760254, avg loss: 1.3863329476118087\n",
      "trial: 2, iter: 4400, curr loss: 1.3873746395111084, avg loss: 1.3862856018543244\n",
      "trial: 2, iter: 4600, curr loss: 1.3854376077651978, avg loss: 1.386422815322876\n",
      "trial: 2, iter: 4800, curr loss: 1.3857665061950684, avg loss: 1.3863411903381349\n",
      "trial: 2, iter: 5000, curr loss: 1.386576771736145, avg loss: 1.3863101667165756\n",
      "trial: 2, iter: 5200, curr loss: 1.3862600326538086, avg loss: 1.3863205301761627\n",
      "trial: 2, iter: 5400, curr loss: 1.386589527130127, avg loss: 1.3863311004638672\n",
      "trial: 2, iter: 5600, curr loss: 1.3864376544952393, avg loss: 1.3863192009925842\n",
      "trial: 2, iter: 5800, curr loss: 1.3864713907241821, avg loss: 1.3862918025255204\n",
      "trial: 2, iter: 6000, curr loss: 1.3862603902816772, avg loss: 1.3863193970918655\n",
      "trial: 2, iter: 6200, curr loss: 1.3863778114318848, avg loss: 1.3863174909353255\n",
      "trial: 2, iter: 6400, curr loss: 1.3860242366790771, avg loss: 1.386269632577896\n",
      "trial: 2, iter: 6600, curr loss: 1.3862133026123047, avg loss: 1.3862999480962754\n",
      "trial: 2, iter: 6800, curr loss: 1.3865423202514648, avg loss: 1.3863358211517334\n",
      "trial: 2, iter: 7000, curr loss: 1.3860739469528198, avg loss: 1.3862773263454438\n",
      "trial: 2, iter: 7200, curr loss: 1.3862944841384888, avg loss: 1.386315103173256\n",
      "trial: 2, iter: 7400, curr loss: 1.3863310813903809, avg loss: 1.3863016563653945\n",
      "trial: 2, iter: 7600, curr loss: 1.3863240480422974, avg loss: 1.3863342463970185\n",
      "trial: 2, iter: 7800, curr loss: 1.3863332271575928, avg loss: 1.3863074636459352\n",
      "trial: 2, iter: 8000, curr loss: 1.3862751722335815, avg loss: 1.3863006961345672\n",
      "trial: 2, iter: 8200, curr loss: 1.3863372802734375, avg loss: 1.3863080388307571\n",
      "trial: 2, iter: 8400, curr loss: 1.3864974975585938, avg loss: 1.3862968409061431\n",
      "trial: 2, iter: 8600, curr loss: 1.3864309787750244, avg loss: 1.3862964618206024\n",
      "trial: 2, iter: 8800, curr loss: 1.3862624168395996, avg loss: 1.386310201883316\n",
      "trial: 2, iter: 9000, curr loss: 1.3862345218658447, avg loss: 1.38628846347332\n",
      "trial: 2, iter: 9200, curr loss: 1.386255145072937, avg loss: 1.386313493847847\n",
      "trial: 2, iter: 9400, curr loss: 1.386520266532898, avg loss: 1.3862958395481109\n",
      "trial: 2, iter: 9600, curr loss: 1.3864113092422485, avg loss: 1.3863049334287643\n",
      "trial: 2, iter: 9800, curr loss: 1.3861860036849976, avg loss: 1.3862957620620728\n",
      "trial: 2, iter: 10000, curr loss: 1.3864927291870117, avg loss: 1.3863375639915467\n",
      "trial: 2, iter: 10200, curr loss: 1.3863812685012817, avg loss: 1.386318690776825\n",
      "trial: 2, iter: 10400, curr loss: 1.3861031532287598, avg loss: 1.3863156086206436\n",
      "trial: 2, iter: 10600, curr loss: 1.3864006996154785, avg loss: 1.386350849866867\n",
      "trial: 2, iter: 10800, curr loss: 1.3869943618774414, avg loss: 1.3862933450937271\n",
      "trial: 2, iter: 11000, curr loss: 1.386301875114441, avg loss: 1.3863352793455124\n",
      "trial: 2, iter: 11200, curr loss: 1.3859820365905762, avg loss: 1.3862878787517547\n",
      "trial: 2, iter: 11400, curr loss: 1.3864037990570068, avg loss: 1.386321920156479\n",
      "trial: 2, iter: 11600, curr loss: 1.386336088180542, avg loss: 1.3863017666339874\n",
      "trial: 2, iter: 11800, curr loss: 1.3862935304641724, avg loss: 1.3862932592630386\n",
      "trial: 2, iter: 12000, curr loss: 1.3863885402679443, avg loss: 1.3862967550754548\n",
      "trial: 2, iter: 12200, curr loss: 1.3864667415618896, avg loss: 1.3862926745414734\n",
      "trial: 2, iter: 12400, curr loss: 1.3862913846969604, avg loss: 1.3863005781173705\n",
      "trial: 2, iter: 12600, curr loss: 1.3862802982330322, avg loss: 1.3862951791286469\n",
      "trial: 2, iter: 12800, curr loss: 1.3862948417663574, avg loss: 1.386295387148857\n",
      "trial: 2, iter: 13000, curr loss: 1.386294960975647, avg loss: 1.3862949067354202\n",
      "trial: 2, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.3862956351041793\n",
      "trial: 2, iter: 13400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13600, curr loss: 1.3862944841384888, avg loss: 1.3862949723005296\n",
      "trial: 2, iter: 13800, curr loss: 1.3862946033477783, avg loss: 1.3862949454784392\n",
      "trial: 2, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.3862949126958848\n",
      "trial: 2, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, ldr: 1.1920928244535389e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3894248008728027, avg loss: 1.387269241809845\n",
      "trial: 3, iter: 400, curr loss: 1.384096384048462, avg loss: 1.386585830450058\n",
      "trial: 3, iter: 600, curr loss: 1.386063575744629, avg loss: 1.3866109317541122\n",
      "trial: 3, iter: 800, curr loss: 1.3857834339141846, avg loss: 1.3864318615198135\n",
      "trial: 3, iter: 1000, curr loss: 1.3868063688278198, avg loss: 1.3864316147565843\n",
      "trial: 3, iter: 1200, curr loss: 1.3853223323822021, avg loss: 1.3864091229438782\n",
      "trial: 3, iter: 1400, curr loss: 1.3874460458755493, avg loss: 1.3863640171289444\n",
      "trial: 3, iter: 1600, curr loss: 1.3864983320236206, avg loss: 1.386357657313347\n",
      "trial: 3, iter: 1800, curr loss: 1.3862718343734741, avg loss: 1.3863774931430817\n",
      "trial: 3, iter: 2000, curr loss: 1.3863165378570557, avg loss: 1.3864271807670594\n",
      "trial: 3, iter: 2200, curr loss: 1.3861666917800903, avg loss: 1.3863537442684173\n",
      "trial: 3, iter: 2400, curr loss: 1.385804533958435, avg loss: 1.38631886780262\n",
      "trial: 3, iter: 2600, curr loss: 1.3862353563308716, avg loss: 1.3863495147228242\n",
      "trial: 3, iter: 2800, curr loss: 1.3857923746109009, avg loss: 1.3863302648067475\n",
      "trial: 3, iter: 3000, curr loss: 1.386319637298584, avg loss: 1.3863134169578553\n",
      "trial: 3, iter: 3200, curr loss: 1.3864113092422485, avg loss: 1.386320286989212\n",
      "trial: 3, iter: 3400, curr loss: 1.3863743543624878, avg loss: 1.386326442360878\n",
      "trial: 3, iter: 3600, curr loss: 1.3862706422805786, avg loss: 1.3863490438461303\n",
      "trial: 3, iter: 3800, curr loss: 1.386725664138794, avg loss: 1.3864389890432358\n",
      "trial: 3, iter: 4000, curr loss: 1.3863935470581055, avg loss: 1.3863409453630446\n",
      "trial: 3, iter: 4200, curr loss: 1.386197805404663, avg loss: 1.3863225626945495\n",
      "trial: 3, iter: 4400, curr loss: 1.3860509395599365, avg loss: 1.3862985181808472\n",
      "trial: 3, iter: 4600, curr loss: 1.3860890865325928, avg loss: 1.3863504594564438\n",
      "trial: 3, iter: 4800, curr loss: 1.3862115144729614, avg loss: 1.3863180685043335\n",
      "trial: 3, iter: 5000, curr loss: 1.3865972757339478, avg loss: 1.3863024091720582\n",
      "trial: 3, iter: 5200, curr loss: 1.3865439891815186, avg loss: 1.3863357263803482\n",
      "trial: 3, iter: 5400, curr loss: 1.3861578702926636, avg loss: 1.3863011866807937\n",
      "trial: 3, iter: 5600, curr loss: 1.3861504793167114, avg loss: 1.3863237339258194\n",
      "trial: 3, iter: 5800, curr loss: 1.3861587047576904, avg loss: 1.3863152742385865\n",
      "trial: 3, iter: 6000, curr loss: 1.3860927820205688, avg loss: 1.3863234239816666\n",
      "trial: 3, iter: 6200, curr loss: 1.3862501382827759, avg loss: 1.3862989711761475\n",
      "trial: 3, iter: 6400, curr loss: 1.3863686323165894, avg loss: 1.386315159201622\n",
      "trial: 3, iter: 6600, curr loss: 1.3856920003890991, avg loss: 1.3862853783369065\n",
      "trial: 3, iter: 6800, curr loss: 1.3860036134719849, avg loss: 1.386265839934349\n",
      "trial: 3, iter: 7000, curr loss: 1.3866496086120605, avg loss: 1.386331302523613\n",
      "trial: 3, iter: 7200, curr loss: 1.3863472938537598, avg loss: 1.386308720111847\n",
      "trial: 3, iter: 7400, curr loss: 1.386183738708496, avg loss: 1.3863316476345062\n",
      "trial: 3, iter: 7600, curr loss: 1.3864816427230835, avg loss: 1.3863015103340148\n",
      "trial: 3, iter: 7800, curr loss: 1.3864942789077759, avg loss: 1.3863061785697937\n",
      "trial: 3, iter: 8000, curr loss: 1.3862863779067993, avg loss: 1.3863134115934372\n",
      "trial: 3, iter: 8200, curr loss: 1.386338233947754, avg loss: 1.3862925750017165\n",
      "trial: 3, iter: 8400, curr loss: 1.3863444328308105, avg loss: 1.3863044840097427\n",
      "trial: 3, iter: 8600, curr loss: 1.3866024017333984, avg loss: 1.386298667192459\n",
      "trial: 3, iter: 8800, curr loss: 1.386164903640747, avg loss: 1.3862971806526183\n",
      "trial: 3, iter: 9000, curr loss: 1.3867007493972778, avg loss: 1.3862931752204894\n",
      "trial: 3, iter: 9200, curr loss: 1.3864041566848755, avg loss: 1.3863212502002715\n",
      "trial: 3, iter: 9400, curr loss: 1.3862124681472778, avg loss: 1.3863016402721404\n",
      "trial: 3, iter: 9600, curr loss: 1.386662483215332, avg loss: 1.3862769603729248\n",
      "trial: 3, iter: 9800, curr loss: 1.3863815069198608, avg loss: 1.3863024395704269\n",
      "trial: 3, iter: 10000, curr loss: 1.3864468336105347, avg loss: 1.386326169371605\n",
      "trial: 3, iter: 10200, curr loss: 1.3862061500549316, avg loss: 1.3863016432523727\n",
      "trial: 3, iter: 10400, curr loss: 1.386246681213379, avg loss: 1.3863022494316102\n",
      "trial: 3, iter: 10600, curr loss: 1.3860753774642944, avg loss: 1.3862868219614028\n",
      "trial: 3, iter: 10800, curr loss: 1.3862446546554565, avg loss: 1.3863004326820374\n",
      "trial: 3, iter: 11000, curr loss: 1.385921835899353, avg loss: 1.3862858486175538\n",
      "trial: 3, iter: 11200, curr loss: 1.3863286972045898, avg loss: 1.3863116520643235\n",
      "trial: 3, iter: 11400, curr loss: 1.386228322982788, avg loss: 1.3863032484054565\n",
      "trial: 3, iter: 11600, curr loss: 1.3863433599472046, avg loss: 1.3862926423549653\n",
      "trial: 3, iter: 11800, curr loss: 1.386393666267395, avg loss: 1.3863006323575973\n",
      "trial: 3, iter: 12000, curr loss: 1.386298418045044, avg loss: 1.3863003426790237\n",
      "trial: 3, iter: 12200, curr loss: 1.3863004446029663, avg loss: 1.3863075304031371\n",
      "trial: 3, iter: 12400, curr loss: 1.386297583580017, avg loss: 1.3863003659248352\n",
      "trial: 3, iter: 12600, curr loss: 1.385585904121399, avg loss: 1.3862655192613602\n",
      "trial: 3, iter: 12800, curr loss: 1.3862965106964111, avg loss: 1.3863182175159454\n",
      "trial: 3, iter: 13000, curr loss: 1.3862980604171753, avg loss: 1.3862965297698975\n",
      "trial: 3, iter: 13200, curr loss: 1.3862953186035156, avg loss: 1.3862947487831117\n",
      "trial: 3, iter: 13400, curr loss: 1.3862950801849365, avg loss: 1.386294286251068\n",
      "trial: 3, iter: 13600, curr loss: 1.3863012790679932, avg loss: 1.3862945705652236\n",
      "trial: 3, iter: 13800, curr loss: 1.3862943649291992, avg loss: 1.386294794678688\n",
      "trial: 3, iter: 14000, curr loss: 1.386295199394226, avg loss: 1.3862944334745406\n",
      "trial: 3, iter: 14200, curr loss: 1.3862946033477783, avg loss: 1.386294391155243\n",
      "trial: 3, iter: 14400, curr loss: 1.3862946033477783, avg loss: 1.3862944155931474\n",
      "trial: 3, iter: 14600, curr loss: 1.386293888092041, avg loss: 1.386294417977333\n",
      "trial: 3, iter: 14800, curr loss: 1.3862934112548828, avg loss: 1.3862946432828904\n",
      "trial: 3, iter: 15000, curr loss: 1.3862946033477783, avg loss: 1.3862945014238357\n",
      "trial: 3, iter: 15200, curr loss: 1.3862944841384888, avg loss: 1.3862944281101226\n",
      "trial: 3, iter: 15400, curr loss: 1.3862944841384888, avg loss: 1.3862945330142975\n",
      "trial: 3, iter: 15600, curr loss: 1.3862943649291992, avg loss: 1.3862943768501281\n",
      "trial: 3, ldr: -1.3535120160668157e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3842118978500366, avg loss: 1.387474769949913\n",
      "trial: 4, iter: 400, curr loss: 1.3841776847839355, avg loss: 1.3865864503383636\n",
      "trial: 4, iter: 600, curr loss: 1.3865004777908325, avg loss: 1.3866425609588624\n",
      "trial: 4, iter: 800, curr loss: 1.385933756828308, avg loss: 1.3865162295103073\n",
      "trial: 4, iter: 1000, curr loss: 1.3869072198867798, avg loss: 1.386557273864746\n",
      "trial: 4, iter: 1200, curr loss: 1.3851726055145264, avg loss: 1.3864890486001968\n",
      "trial: 4, iter: 1400, curr loss: 1.385876178741455, avg loss: 1.3864709895849228\n",
      "trial: 4, iter: 1600, curr loss: 1.3863000869750977, avg loss: 1.386432586312294\n",
      "trial: 4, iter: 1800, curr loss: 1.3866846561431885, avg loss: 1.3863621491193772\n",
      "trial: 4, iter: 2000, curr loss: 1.386287808418274, avg loss: 1.386479606628418\n",
      "trial: 4, iter: 2200, curr loss: 1.3862406015396118, avg loss: 1.3863563561439514\n",
      "trial: 4, iter: 2400, curr loss: 1.386724829673767, avg loss: 1.3864359575510026\n",
      "trial: 4, iter: 2600, curr loss: 1.3857649564743042, avg loss: 1.386328426003456\n",
      "trial: 4, iter: 2800, curr loss: 1.3851994276046753, avg loss: 1.386369611620903\n",
      "trial: 4, iter: 3000, curr loss: 1.3871530294418335, avg loss: 1.3863535636663438\n",
      "trial: 4, iter: 3200, curr loss: 1.3878724575042725, avg loss: 1.386348301768303\n",
      "trial: 4, iter: 3400, curr loss: 1.385654091835022, avg loss: 1.386355112195015\n",
      "trial: 4, iter: 3600, curr loss: 1.3866829872131348, avg loss: 1.3864027005434036\n",
      "trial: 4, iter: 3800, curr loss: 1.3865383863449097, avg loss: 1.3864352959394455\n",
      "trial: 4, iter: 4000, curr loss: 1.385312795639038, avg loss: 1.386363748908043\n",
      "trial: 4, iter: 4200, curr loss: 1.3866502046585083, avg loss: 1.386342853307724\n",
      "trial: 4, iter: 4400, curr loss: 1.3867850303649902, avg loss: 1.3863285207748413\n",
      "trial: 4, iter: 4600, curr loss: 1.38687002658844, avg loss: 1.3863702130317688\n",
      "trial: 4, iter: 4800, curr loss: 1.3861662149429321, avg loss: 1.386334239244461\n",
      "trial: 4, iter: 5000, curr loss: 1.386541485786438, avg loss: 1.386319290995598\n",
      "trial: 4, iter: 5200, curr loss: 1.3866292238235474, avg loss: 1.3862831538915634\n",
      "trial: 4, iter: 5400, curr loss: 1.3867342472076416, avg loss: 1.3863630318641662\n",
      "trial: 4, iter: 5600, curr loss: 1.3870576620101929, avg loss: 1.386272047162056\n",
      "trial: 4, iter: 5800, curr loss: 1.386511206626892, avg loss: 1.3863352990150453\n",
      "trial: 4, iter: 6000, curr loss: 1.3863505125045776, avg loss: 1.3863276082277298\n",
      "trial: 4, iter: 6200, curr loss: 1.386327862739563, avg loss: 1.386325398683548\n",
      "trial: 4, iter: 6400, curr loss: 1.386504054069519, avg loss: 1.386313556432724\n",
      "trial: 4, iter: 6600, curr loss: 1.3861321210861206, avg loss: 1.3862986040115357\n",
      "trial: 4, iter: 6800, curr loss: 1.386772632598877, avg loss: 1.386313219666481\n",
      "trial: 4, iter: 7000, curr loss: 1.3862383365631104, avg loss: 1.386326904296875\n",
      "trial: 4, iter: 7200, curr loss: 1.385499119758606, avg loss: 1.3863065397739411\n",
      "trial: 4, iter: 7400, curr loss: 1.3865618705749512, avg loss: 1.3863520294427871\n",
      "trial: 4, iter: 7600, curr loss: 1.3861455917358398, avg loss: 1.3863218128681183\n",
      "trial: 4, iter: 7800, curr loss: 1.3863646984100342, avg loss: 1.3863153660297394\n",
      "trial: 4, iter: 8000, curr loss: 1.386420726776123, avg loss: 1.3862963819503784\n",
      "trial: 4, iter: 8200, curr loss: 1.3863482475280762, avg loss: 1.386331845521927\n",
      "trial: 4, iter: 8400, curr loss: 1.3860753774642944, avg loss: 1.3862847423553466\n",
      "trial: 4, iter: 8600, curr loss: 1.3865559101104736, avg loss: 1.386306345462799\n",
      "trial: 4, iter: 8800, curr loss: 1.38605535030365, avg loss: 1.3863071423768998\n",
      "trial: 4, iter: 9000, curr loss: 1.3865747451782227, avg loss: 1.3863384300470352\n",
      "trial: 4, iter: 9200, curr loss: 1.3864402770996094, avg loss: 1.3863007247447967\n",
      "trial: 4, iter: 9400, curr loss: 1.3867552280426025, avg loss: 1.3863113880157472\n",
      "trial: 4, iter: 9600, curr loss: 1.3860445022583008, avg loss: 1.3863043051958084\n",
      "trial: 4, iter: 9800, curr loss: 1.3865957260131836, avg loss: 1.3863007348775864\n",
      "trial: 4, iter: 10000, curr loss: 1.3860344886779785, avg loss: 1.3862928014993667\n",
      "trial: 4, iter: 10200, curr loss: 1.3861515522003174, avg loss: 1.3863073414564133\n",
      "trial: 4, iter: 10400, curr loss: 1.3865420818328857, avg loss: 1.3862863862514496\n",
      "trial: 4, iter: 10600, curr loss: 1.3862520456314087, avg loss: 1.3863113367557525\n",
      "trial: 4, iter: 10800, curr loss: 1.3866658210754395, avg loss: 1.3862952774763107\n",
      "trial: 4, iter: 11000, curr loss: 1.3864463567733765, avg loss: 1.3862998348474502\n",
      "trial: 4, iter: 11200, curr loss: 1.3861887454986572, avg loss: 1.3863006168603897\n",
      "trial: 4, iter: 11400, curr loss: 1.386326551437378, avg loss: 1.3863091254234314\n",
      "trial: 4, iter: 11600, curr loss: 1.3863972425460815, avg loss: 1.3862974113225937\n",
      "trial: 4, iter: 11800, curr loss: 1.3862944841384888, avg loss: 1.3863026481866836\n",
      "trial: 4, iter: 12000, curr loss: 1.3863086700439453, avg loss: 1.3862896418571473\n",
      "trial: 4, iter: 12200, curr loss: 1.3862947225570679, avg loss: 1.3862991386651993\n",
      "trial: 4, iter: 12400, curr loss: 1.3862974643707275, avg loss: 1.3862969261407851\n",
      "trial: 4, iter: 12600, curr loss: 1.3863961696624756, avg loss: 1.3862993484735489\n",
      "trial: 4, iter: 12800, curr loss: 1.3862265348434448, avg loss: 1.386296306848526\n",
      "trial: 4, iter: 13000, curr loss: 1.386406660079956, avg loss: 1.3862985903024674\n",
      "trial: 4, iter: 13200, curr loss: 1.3863435983657837, avg loss: 1.386295774579048\n",
      "trial: 4, iter: 13400, curr loss: 1.386225938796997, avg loss: 1.3862940460443496\n",
      "trial: 4, iter: 13600, curr loss: 1.386500358581543, avg loss: 1.386284180879593\n",
      "trial: 4, iter: 13800, curr loss: 1.3861339092254639, avg loss: 1.3863951450586318\n",
      "trial: 4, iter: 14000, curr loss: 1.386687994003296, avg loss: 1.3863377034664155\n",
      "trial: 4, iter: 14200, curr loss: 1.386562466621399, avg loss: 1.3863359385728835\n",
      "trial: 4, iter: 14400, curr loss: 1.3862403631210327, avg loss: 1.3863437587022782\n",
      "trial: 4, iter: 14600, curr loss: 1.3860044479370117, avg loss: 1.3862687635421753\n",
      "trial: 4, iter: 14800, curr loss: 1.3861714601516724, avg loss: 1.38634810090065\n",
      "trial: 4, iter: 15000, curr loss: 1.3863310813903809, avg loss: 1.38633543074131\n",
      "trial: 4, iter: 15200, curr loss: 1.3863576650619507, avg loss: 1.3863136237859726\n",
      "trial: 4, iter: 15400, curr loss: 1.3861944675445557, avg loss: 1.3863064324855805\n",
      "trial: 4, iter: 15600, curr loss: 1.3865453004837036, avg loss: 1.3863112795352937\n",
      "trial: 4, ldr: 7.292976079043001e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3844245672225952, avg loss: 1.3874375188350678\n",
      "trial: 5, iter: 400, curr loss: 1.3868582248687744, avg loss: 1.3866055130958557\n",
      "trial: 5, iter: 600, curr loss: 1.3871617317199707, avg loss: 1.3866367137432098\n",
      "trial: 5, iter: 800, curr loss: 1.3851567506790161, avg loss: 1.3864809364080428\n",
      "trial: 5, iter: 1000, curr loss: 1.3859857320785522, avg loss: 1.3865183925628661\n",
      "trial: 5, iter: 1200, curr loss: 1.3848704099655151, avg loss: 1.3865826845169067\n",
      "trial: 5, iter: 1400, curr loss: 1.3877029418945312, avg loss: 1.3864200633764268\n",
      "trial: 5, iter: 1600, curr loss: 1.385735273361206, avg loss: 1.3863172656297684\n",
      "trial: 5, iter: 1800, curr loss: 1.3853580951690674, avg loss: 1.3863961321115494\n",
      "trial: 5, iter: 2000, curr loss: 1.3878082036972046, avg loss: 1.3863254070281983\n",
      "trial: 5, iter: 2200, curr loss: 1.3851648569107056, avg loss: 1.3863908731937409\n",
      "trial: 5, iter: 2400, curr loss: 1.3862228393554688, avg loss: 1.386392273902893\n",
      "trial: 5, iter: 2600, curr loss: 1.3861725330352783, avg loss: 1.3864041697978973\n",
      "trial: 5, iter: 2800, curr loss: 1.385930061340332, avg loss: 1.3863469475507737\n",
      "trial: 5, iter: 3000, curr loss: 1.3859398365020752, avg loss: 1.3863674485683442\n",
      "trial: 5, iter: 3200, curr loss: 1.3867591619491577, avg loss: 1.3863793182373048\n",
      "trial: 5, iter: 3400, curr loss: 1.3867390155792236, avg loss: 1.3862979298830032\n",
      "trial: 5, iter: 3600, curr loss: 1.3863283395767212, avg loss: 1.3863659977912903\n",
      "trial: 5, iter: 3800, curr loss: 1.3859286308288574, avg loss: 1.3863385504484176\n",
      "trial: 5, iter: 4000, curr loss: 1.386971354484558, avg loss: 1.3863491547107696\n",
      "trial: 5, iter: 4200, curr loss: 1.3860843181610107, avg loss: 1.3862756139039993\n",
      "trial: 5, iter: 4400, curr loss: 1.3865976333618164, avg loss: 1.3863764274120332\n",
      "trial: 5, iter: 4600, curr loss: 1.3865176439285278, avg loss: 1.3864151519536971\n",
      "trial: 5, iter: 4800, curr loss: 1.3862366676330566, avg loss: 1.3863947719335556\n",
      "trial: 5, iter: 5000, curr loss: 1.386213779449463, avg loss: 1.3863440078496934\n",
      "trial: 5, iter: 5200, curr loss: 1.3866466283798218, avg loss: 1.3863533955812455\n",
      "trial: 5, iter: 5400, curr loss: 1.3861503601074219, avg loss: 1.3863169264793396\n",
      "trial: 5, iter: 5600, curr loss: 1.385404348373413, avg loss: 1.386321957707405\n",
      "trial: 5, iter: 5800, curr loss: 1.386579155921936, avg loss: 1.3863553446531296\n",
      "trial: 5, iter: 6000, curr loss: 1.3863247632980347, avg loss: 1.3862806153297424\n",
      "trial: 5, iter: 6200, curr loss: 1.3865234851837158, avg loss: 1.3863206487894058\n",
      "trial: 5, iter: 6400, curr loss: 1.386262059211731, avg loss: 1.3863480770587921\n",
      "trial: 5, iter: 6600, curr loss: 1.3866539001464844, avg loss: 1.3863160985708236\n",
      "trial: 5, iter: 6800, curr loss: 1.3860944509506226, avg loss: 1.3862922203540802\n",
      "trial: 5, iter: 7000, curr loss: 1.3858617544174194, avg loss: 1.3862732350826263\n",
      "trial: 5, iter: 7200, curr loss: 1.3860970735549927, avg loss: 1.386326352953911\n",
      "trial: 5, iter: 7400, curr loss: 1.3859387636184692, avg loss: 1.386335334777832\n",
      "trial: 5, iter: 7600, curr loss: 1.3864275217056274, avg loss: 1.3863096219301223\n",
      "trial: 5, iter: 7800, curr loss: 1.3858343362808228, avg loss: 1.3862890976667404\n",
      "trial: 5, iter: 8000, curr loss: 1.386195182800293, avg loss: 1.386319106221199\n",
      "trial: 5, iter: 8200, curr loss: 1.3862398862838745, avg loss: 1.3862836915254593\n",
      "trial: 5, iter: 8400, curr loss: 1.3865301609039307, avg loss: 1.3863040333986283\n",
      "trial: 5, iter: 8600, curr loss: 1.386081576347351, avg loss: 1.386293776035309\n",
      "trial: 5, iter: 8800, curr loss: 1.3863708972930908, avg loss: 1.3863416075706483\n",
      "trial: 5, iter: 9000, curr loss: 1.3861268758773804, avg loss: 1.3863726377487182\n",
      "trial: 5, iter: 9200, curr loss: 1.386198878288269, avg loss: 1.3863232612609864\n",
      "trial: 5, iter: 9400, curr loss: 1.386347770690918, avg loss: 1.386311639547348\n",
      "trial: 5, iter: 9600, curr loss: 1.3865278959274292, avg loss: 1.3863727176189422\n",
      "trial: 5, iter: 9800, curr loss: 1.386509895324707, avg loss: 1.386314691901207\n",
      "trial: 5, iter: 10000, curr loss: 1.386576533317566, avg loss: 1.386295450925827\n",
      "trial: 5, iter: 10200, curr loss: 1.3864023685455322, avg loss: 1.3863443356752396\n",
      "trial: 5, iter: 10400, curr loss: 1.3865901231765747, avg loss: 1.386321877837181\n",
      "trial: 5, iter: 10600, curr loss: 1.3862998485565186, avg loss: 1.3862984544038772\n",
      "trial: 5, iter: 10800, curr loss: 1.3863320350646973, avg loss: 1.3863329577445984\n",
      "trial: 5, iter: 11000, curr loss: 1.3865578174591064, avg loss: 1.3863146203756331\n",
      "trial: 5, iter: 11200, curr loss: 1.3862762451171875, avg loss: 1.38631553709507\n",
      "trial: 5, iter: 11400, curr loss: 1.386150598526001, avg loss: 1.3863123643398285\n",
      "trial: 5, iter: 11600, curr loss: 1.3862910270690918, avg loss: 1.3862941390275956\n",
      "trial: 5, iter: 11800, curr loss: 1.3862895965576172, avg loss: 1.386317126750946\n",
      "trial: 5, iter: 12000, curr loss: 1.386604905128479, avg loss: 1.3863463652133943\n",
      "trial: 5, iter: 12200, curr loss: 1.3857241868972778, avg loss: 1.3863276022672653\n",
      "trial: 5, iter: 12400, curr loss: 1.3879342079162598, avg loss: 1.3862760192155839\n",
      "trial: 5, iter: 12600, curr loss: 1.3865916728973389, avg loss: 1.3863627207279205\n",
      "trial: 5, iter: 12800, curr loss: 1.386291742324829, avg loss: 1.3863504147529602\n",
      "trial: 5, iter: 13000, curr loss: 1.3864796161651611, avg loss: 1.3863747382164002\n",
      "trial: 5, iter: 13200, curr loss: 1.3864216804504395, avg loss: 1.3863367056846618\n",
      "trial: 5, iter: 13400, curr loss: 1.3861560821533203, avg loss: 1.3863577526807784\n",
      "trial: 5, iter: 13600, curr loss: 1.3862693309783936, avg loss: 1.3863082891702652\n",
      "trial: 5, iter: 13800, curr loss: 1.386108636856079, avg loss: 1.3863037073612212\n",
      "trial: 5, iter: 14000, curr loss: 1.3864308595657349, avg loss: 1.3863043785095215\n",
      "trial: 5, iter: 14200, curr loss: 1.386307954788208, avg loss: 1.3863024520874023\n",
      "trial: 5, iter: 14400, curr loss: 1.3862553834915161, avg loss: 1.3862977117300033\n",
      "trial: 5, iter: 14600, curr loss: 1.3862842321395874, avg loss: 1.3862872076034547\n",
      "trial: 5, iter: 14800, curr loss: 1.3862979412078857, avg loss: 1.3863075643777847\n",
      "trial: 5, iter: 15000, curr loss: 1.3862519264221191, avg loss: 1.3863033747673035\n",
      "trial: 5, iter: 15200, curr loss: 1.3863376379013062, avg loss: 1.3862973630428315\n",
      "trial: 5, iter: 15400, curr loss: 1.386267066001892, avg loss: 1.3862942677736283\n",
      "trial: 5, iter: 15600, curr loss: 1.3863927125930786, avg loss: 1.3862978613376618\n",
      "trial: 5, ldr: 0.00024720936198718846\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00022594918664395892\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38761568069458, avg loss: 1.3873645269870758\n",
      "trial: 1, iter: 400, curr loss: 1.3866307735443115, avg loss: 1.3868988651037215\n",
      "trial: 1, iter: 600, curr loss: 1.3894100189208984, avg loss: 1.3865031260251999\n",
      "trial: 1, iter: 800, curr loss: 1.3856688737869263, avg loss: 1.3865481382608413\n",
      "trial: 1, iter: 1000, curr loss: 1.387913703918457, avg loss: 1.386404001712799\n",
      "trial: 1, iter: 1200, curr loss: 1.385830283164978, avg loss: 1.3863865232467651\n",
      "trial: 1, iter: 1400, curr loss: 1.3862062692642212, avg loss: 1.3864145255088807\n",
      "trial: 1, iter: 1600, curr loss: 1.3845854997634888, avg loss: 1.386402703523636\n",
      "trial: 1, iter: 1800, curr loss: 1.3857247829437256, avg loss: 1.386545930504799\n",
      "trial: 1, iter: 2000, curr loss: 1.3872387409210205, avg loss: 1.3863993227481841\n",
      "trial: 1, iter: 2200, curr loss: 1.386461853981018, avg loss: 1.3864158910512925\n",
      "trial: 1, iter: 2400, curr loss: 1.385715126991272, avg loss: 1.3863451719284057\n",
      "trial: 1, iter: 2600, curr loss: 1.3854643106460571, avg loss: 1.3864848417043687\n",
      "trial: 1, iter: 2800, curr loss: 1.386984944343567, avg loss: 1.3864114248752595\n",
      "trial: 1, iter: 3000, curr loss: 1.3859736919403076, avg loss: 1.386368172764778\n",
      "trial: 1, iter: 3200, curr loss: 1.3864046335220337, avg loss: 1.3863386124372483\n",
      "trial: 1, iter: 3400, curr loss: 1.3873605728149414, avg loss: 1.3864075195789338\n",
      "trial: 1, iter: 3600, curr loss: 1.3863524198532104, avg loss: 1.3863349026441574\n",
      "trial: 1, iter: 3800, curr loss: 1.3887710571289062, avg loss: 1.3863194978237152\n",
      "trial: 1, iter: 4000, curr loss: 1.3862940073013306, avg loss: 1.3864298838376998\n",
      "trial: 1, iter: 4200, curr loss: 1.3860968351364136, avg loss: 1.3864056086540222\n",
      "trial: 1, iter: 4400, curr loss: 1.3855412006378174, avg loss: 1.3863385319709778\n",
      "trial: 1, iter: 4600, curr loss: 1.3869075775146484, avg loss: 1.3865307343006135\n",
      "trial: 1, iter: 4800, curr loss: 1.3858400583267212, avg loss: 1.3864174121618271\n",
      "trial: 1, iter: 5000, curr loss: 1.3857053518295288, avg loss: 1.3863806319236756\n",
      "trial: 1, iter: 5200, curr loss: 1.386624813079834, avg loss: 1.3864237529039383\n",
      "trial: 1, iter: 5400, curr loss: 1.3865888118743896, avg loss: 1.3863686281442642\n",
      "trial: 1, iter: 5600, curr loss: 1.3855900764465332, avg loss: 1.3863288897275925\n",
      "trial: 1, iter: 5800, curr loss: 1.3864909410476685, avg loss: 1.3863317227363587\n",
      "trial: 1, iter: 6000, curr loss: 1.3861467838287354, avg loss: 1.3863371050357818\n",
      "trial: 1, iter: 6200, curr loss: 1.386022925376892, avg loss: 1.386313817501068\n",
      "trial: 1, iter: 6400, curr loss: 1.386473536491394, avg loss: 1.3863366037607192\n",
      "trial: 1, iter: 6600, curr loss: 1.3856388330459595, avg loss: 1.3863031733036042\n",
      "trial: 1, iter: 6800, curr loss: 1.3861161470413208, avg loss: 1.386326013803482\n",
      "trial: 1, iter: 7000, curr loss: 1.3865214586257935, avg loss: 1.3863430273532868\n",
      "trial: 1, iter: 7200, curr loss: 1.387642502784729, avg loss: 1.3863057094812392\n",
      "trial: 1, iter: 7400, curr loss: 1.3860783576965332, avg loss: 1.3863505655527115\n",
      "trial: 1, iter: 7600, curr loss: 1.3867318630218506, avg loss: 1.386327224969864\n",
      "trial: 1, iter: 7800, curr loss: 1.3859058618545532, avg loss: 1.3863107007741928\n",
      "trial: 1, iter: 8000, curr loss: 1.3862041234970093, avg loss: 1.3863329535722733\n",
      "trial: 1, iter: 8200, curr loss: 1.3866535425186157, avg loss: 1.3862867778539658\n",
      "trial: 1, iter: 8400, curr loss: 1.38618004322052, avg loss: 1.3863386070728303\n",
      "trial: 1, iter: 8600, curr loss: 1.3857252597808838, avg loss: 1.3862974393367766\n",
      "trial: 1, iter: 8800, curr loss: 1.3861814737319946, avg loss: 1.3863609206676484\n",
      "trial: 1, iter: 9000, curr loss: 1.386147141456604, avg loss: 1.3863105970621108\n",
      "trial: 1, iter: 9200, curr loss: 1.3854520320892334, avg loss: 1.3862914425134658\n",
      "trial: 1, iter: 9400, curr loss: 1.3860126733779907, avg loss: 1.386320912837982\n",
      "trial: 1, iter: 9600, curr loss: 1.3862531185150146, avg loss: 1.38630257666111\n",
      "trial: 1, iter: 9800, curr loss: 1.3862888813018799, avg loss: 1.3863133656978608\n",
      "trial: 1, iter: 10000, curr loss: 1.385820984840393, avg loss: 1.3862960278987884\n",
      "trial: 1, iter: 10200, curr loss: 1.3862817287445068, avg loss: 1.3863088804483414\n",
      "trial: 1, iter: 10400, curr loss: 1.386610746383667, avg loss: 1.3862895059585572\n",
      "trial: 1, iter: 10600, curr loss: 1.386532187461853, avg loss: 1.3862991958856583\n",
      "trial: 1, iter: 10800, curr loss: 1.386358618736267, avg loss: 1.3863100570440292\n",
      "trial: 1, iter: 11000, curr loss: 1.3862377405166626, avg loss: 1.3862847995758056\n",
      "trial: 1, iter: 11200, curr loss: 1.386444091796875, avg loss: 1.386303026676178\n",
      "trial: 1, iter: 11400, curr loss: 1.3855719566345215, avg loss: 1.3862823045253754\n",
      "trial: 1, iter: 11600, curr loss: 1.3873589038848877, avg loss: 1.386306832432747\n",
      "trial: 1, iter: 11800, curr loss: 1.3864537477493286, avg loss: 1.3863868075609207\n",
      "trial: 1, iter: 12000, curr loss: 1.3861498832702637, avg loss: 1.386306293606758\n",
      "trial: 1, iter: 12200, curr loss: 1.3860125541687012, avg loss: 1.3863183277845383\n",
      "trial: 1, iter: 12400, curr loss: 1.3863157033920288, avg loss: 1.3863196736574173\n",
      "trial: 1, iter: 12600, curr loss: 1.3863134384155273, avg loss: 1.386286782026291\n",
      "trial: 1, iter: 12800, curr loss: 1.3862054347991943, avg loss: 1.386308056116104\n",
      "trial: 1, iter: 13000, curr loss: 1.3867112398147583, avg loss: 1.3862968295812608\n",
      "trial: 1, iter: 13200, curr loss: 1.3858628273010254, avg loss: 1.3862987321615219\n",
      "trial: 1, iter: 13400, curr loss: 1.3862965106964111, avg loss: 1.386321828365326\n",
      "trial: 1, iter: 13600, curr loss: 1.386360764503479, avg loss: 1.386260502934456\n",
      "trial: 1, iter: 13800, curr loss: 1.3869372606277466, avg loss: 1.3863008368015288\n",
      "trial: 1, iter: 14000, curr loss: 1.3869661092758179, avg loss: 1.3862817621231078\n",
      "trial: 1, iter: 14200, curr loss: 1.3862172365188599, avg loss: 1.38630408346653\n",
      "trial: 1, iter: 14400, curr loss: 1.3859080076217651, avg loss: 1.3863226574659349\n",
      "trial: 1, iter: 14600, curr loss: 1.3864175081253052, avg loss: 1.3863046145439148\n",
      "trial: 1, iter: 14800, curr loss: 1.3863927125930786, avg loss: 1.3863119995594024\n",
      "trial: 1, iter: 15000, curr loss: 1.3864811658859253, avg loss: 1.3863137245178223\n",
      "trial: 1, iter: 15200, curr loss: 1.386491060256958, avg loss: 1.3862890541553496\n",
      "trial: 1, iter: 15400, curr loss: 1.3860609531402588, avg loss: 1.386285387277603\n",
      "trial: 1, iter: 15600, curr loss: 1.3864727020263672, avg loss: 1.3863053768873215\n",
      "trial: 1, ldr: -0.002504169475287199\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386573314666748, avg loss: 1.3870292961597444\n",
      "trial: 2, iter: 400, curr loss: 1.3888306617736816, avg loss: 1.3868563264608382\n",
      "trial: 2, iter: 600, curr loss: 1.3864057064056396, avg loss: 1.3867077440023423\n",
      "trial: 2, iter: 800, curr loss: 1.386462926864624, avg loss: 1.3865208673477172\n",
      "trial: 2, iter: 1000, curr loss: 1.3858414888381958, avg loss: 1.3865173161029816\n",
      "trial: 2, iter: 1200, curr loss: 1.3867963552474976, avg loss: 1.3864331758022308\n",
      "trial: 2, iter: 1400, curr loss: 1.3867688179016113, avg loss: 1.3864241772890091\n",
      "trial: 2, iter: 1600, curr loss: 1.3873569965362549, avg loss: 1.386414434313774\n",
      "trial: 2, iter: 1800, curr loss: 1.38572096824646, avg loss: 1.3864406794309616\n",
      "trial: 2, iter: 2000, curr loss: 1.3865195512771606, avg loss: 1.3863796204328538\n",
      "trial: 2, iter: 2200, curr loss: 1.3856627941131592, avg loss: 1.386388172507286\n",
      "trial: 2, iter: 2400, curr loss: 1.3862920999526978, avg loss: 1.386344472169876\n",
      "trial: 2, iter: 2600, curr loss: 1.3865163326263428, avg loss: 1.3863651156425476\n",
      "trial: 2, iter: 2800, curr loss: 1.3864562511444092, avg loss: 1.3863567876815797\n",
      "trial: 2, iter: 3000, curr loss: 1.3872356414794922, avg loss: 1.3862935602664948\n",
      "trial: 2, iter: 3200, curr loss: 1.3856189250946045, avg loss: 1.3863579630851746\n",
      "trial: 2, iter: 3400, curr loss: 1.3857795000076294, avg loss: 1.3863677752017975\n",
      "trial: 2, iter: 3600, curr loss: 1.3859963417053223, avg loss: 1.3863417792320252\n",
      "trial: 2, iter: 3800, curr loss: 1.3859084844589233, avg loss: 1.3863745892047883\n",
      "trial: 2, iter: 4000, curr loss: 1.386226773262024, avg loss: 1.3863473749160766\n",
      "trial: 2, iter: 4200, curr loss: 1.385940670967102, avg loss: 1.386318256855011\n",
      "trial: 2, iter: 4400, curr loss: 1.3862839937210083, avg loss: 1.3863448029756547\n",
      "trial: 2, iter: 4600, curr loss: 1.3867614269256592, avg loss: 1.3863055223226548\n",
      "trial: 2, iter: 4800, curr loss: 1.3865355253219604, avg loss: 1.3863190865516664\n",
      "trial: 2, iter: 5000, curr loss: 1.3857983350753784, avg loss: 1.3863178068399429\n",
      "trial: 2, iter: 5200, curr loss: 1.3863835334777832, avg loss: 1.3863207024335862\n",
      "trial: 2, iter: 5400, curr loss: 1.3860564231872559, avg loss: 1.3863240998983384\n",
      "trial: 2, iter: 5600, curr loss: 1.3862587213516235, avg loss: 1.386291874051094\n",
      "trial: 2, iter: 5800, curr loss: 1.3860641717910767, avg loss: 1.3863502246141435\n",
      "trial: 2, iter: 6000, curr loss: 1.3862069845199585, avg loss: 1.3863165616989135\n",
      "trial: 2, iter: 6200, curr loss: 1.3864117860794067, avg loss: 1.386311896443367\n",
      "trial: 2, iter: 6400, curr loss: 1.386399507522583, avg loss: 1.3863201439380646\n",
      "trial: 2, iter: 6600, curr loss: 1.3864178657531738, avg loss: 1.3863030362129212\n",
      "trial: 2, iter: 6800, curr loss: 1.3862988948822021, avg loss: 1.3862989842891693\n",
      "trial: 2, iter: 7000, curr loss: 1.3859446048736572, avg loss: 1.38632463991642\n",
      "trial: 2, iter: 7200, curr loss: 1.3862099647521973, avg loss: 1.3862872517108917\n",
      "trial: 2, iter: 7400, curr loss: 1.3862745761871338, avg loss: 1.3863321590423583\n",
      "trial: 2, iter: 7600, curr loss: 1.3862061500549316, avg loss: 1.3862989747524261\n",
      "trial: 2, iter: 7800, curr loss: 1.3862767219543457, avg loss: 1.3863023537397385\n",
      "trial: 2, iter: 8000, curr loss: 1.38627028465271, avg loss: 1.3862983763217926\n",
      "trial: 2, iter: 8200, curr loss: 1.3861110210418701, avg loss: 1.386293860077858\n",
      "trial: 2, iter: 8400, curr loss: 1.3861839771270752, avg loss: 1.3862862336635589\n",
      "trial: 2, iter: 8600, curr loss: 1.3863811492919922, avg loss: 1.3862912023067475\n",
      "trial: 2, iter: 8800, curr loss: 1.3862946033477783, avg loss: 1.3862957066297532\n",
      "trial: 2, iter: 9000, curr loss: 1.3862947225570679, avg loss: 1.3862948191165925\n",
      "trial: 2, iter: 9200, curr loss: 1.386294960975647, avg loss: 1.3862948739528655\n",
      "trial: 2, iter: 9400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 9600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 9800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 10000, curr loss: 1.3862947225570679, avg loss: 1.3862949317693711\n",
      "trial: 2, iter: 10200, curr loss: 1.386294960975647, avg loss: 1.3862949603796004\n",
      "trial: 2, iter: 10400, curr loss: 1.386294960975647, avg loss: 1.386294950246811\n",
      "trial: 2, iter: 10600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 10800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 11000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 11200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 11400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 11600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 11800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 12000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 12200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 12400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, ldr: 0.0\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873653411865234, avg loss: 1.3873552995920182\n",
      "trial: 3, iter: 400, curr loss: 1.38792884349823, avg loss: 1.3866557329893112\n",
      "trial: 3, iter: 600, curr loss: 1.3886164426803589, avg loss: 1.3863289171457291\n",
      "trial: 3, iter: 800, curr loss: 1.387383222579956, avg loss: 1.3865069216489792\n",
      "trial: 3, iter: 1000, curr loss: 1.3862056732177734, avg loss: 1.3865513956546784\n",
      "trial: 3, iter: 1200, curr loss: 1.3867266178131104, avg loss: 1.3863143253326415\n",
      "trial: 3, iter: 1400, curr loss: 1.3859772682189941, avg loss: 1.3864599472284318\n",
      "trial: 3, iter: 1600, curr loss: 1.3872380256652832, avg loss: 1.3863840478658676\n",
      "trial: 3, iter: 1800, curr loss: 1.3868046998977661, avg loss: 1.386359452009201\n",
      "trial: 3, iter: 2000, curr loss: 1.3855748176574707, avg loss: 1.3863265544176102\n",
      "trial: 3, iter: 2200, curr loss: 1.3852732181549072, avg loss: 1.3863947623968125\n",
      "trial: 3, iter: 2400, curr loss: 1.387115716934204, avg loss: 1.3863886326551438\n",
      "trial: 3, iter: 2600, curr loss: 1.3867170810699463, avg loss: 1.386390243768692\n",
      "trial: 3, iter: 2800, curr loss: 1.3864201307296753, avg loss: 1.3863917291164398\n",
      "trial: 3, iter: 3000, curr loss: 1.3853646516799927, avg loss: 1.3863683700561524\n",
      "trial: 3, iter: 3200, curr loss: 1.387166976928711, avg loss: 1.386330218911171\n",
      "trial: 3, iter: 3400, curr loss: 1.3863539695739746, avg loss: 1.3863765376806259\n",
      "trial: 3, iter: 3600, curr loss: 1.3859633207321167, avg loss: 1.3863132244348526\n",
      "trial: 3, iter: 3800, curr loss: 1.3865935802459717, avg loss: 1.3863003385066985\n",
      "trial: 3, iter: 4000, curr loss: 1.3841432332992554, avg loss: 1.386276039481163\n",
      "trial: 3, iter: 4200, curr loss: 1.386081337928772, avg loss: 1.386437731385231\n",
      "trial: 3, iter: 4400, curr loss: 1.3867337703704834, avg loss: 1.3863594394922256\n",
      "trial: 3, iter: 4600, curr loss: 1.3874484300613403, avg loss: 1.3863405400514603\n",
      "trial: 3, iter: 4800, curr loss: 1.3859174251556396, avg loss: 1.3863109171390533\n",
      "trial: 3, iter: 5000, curr loss: 1.386039137840271, avg loss: 1.3863334757089616\n",
      "trial: 3, iter: 5200, curr loss: 1.3864010572433472, avg loss: 1.3863230967521667\n",
      "trial: 3, iter: 5400, curr loss: 1.3861143589019775, avg loss: 1.3863402551412582\n",
      "trial: 3, iter: 5600, curr loss: 1.3857572078704834, avg loss: 1.3863163429498673\n",
      "trial: 3, iter: 5800, curr loss: 1.386300802230835, avg loss: 1.38634645819664\n",
      "trial: 3, iter: 6000, curr loss: 1.3863188028335571, avg loss: 1.3863043630123137\n",
      "trial: 3, iter: 6200, curr loss: 1.386824369430542, avg loss: 1.3863444232940674\n",
      "trial: 3, iter: 6400, curr loss: 1.3863335847854614, avg loss: 1.3863068509101868\n",
      "trial: 3, iter: 6600, curr loss: 1.387474775314331, avg loss: 1.3863222002983093\n",
      "trial: 3, iter: 6800, curr loss: 1.3862576484680176, avg loss: 1.3863793730735778\n",
      "trial: 3, iter: 7000, curr loss: 1.3860163688659668, avg loss: 1.3863372671604157\n",
      "trial: 3, iter: 7200, curr loss: 1.3861844539642334, avg loss: 1.3862930738925934\n",
      "trial: 3, iter: 7400, curr loss: 1.387635588645935, avg loss: 1.3863211554288863\n",
      "trial: 3, iter: 7600, curr loss: 1.3855805397033691, avg loss: 1.3862808483839035\n",
      "trial: 3, iter: 7800, curr loss: 1.3853906393051147, avg loss: 1.3863407474756242\n",
      "trial: 3, iter: 8000, curr loss: 1.3855907917022705, avg loss: 1.3863641518354415\n",
      "trial: 3, iter: 8200, curr loss: 1.3855081796646118, avg loss: 1.3862977361679076\n",
      "trial: 3, iter: 8400, curr loss: 1.386401653289795, avg loss: 1.3862904459238052\n",
      "trial: 3, iter: 8600, curr loss: 1.386958122253418, avg loss: 1.3863265734910966\n",
      "trial: 3, iter: 8800, curr loss: 1.3865458965301514, avg loss: 1.3862905806303025\n",
      "trial: 3, iter: 9000, curr loss: 1.3868244886398315, avg loss: 1.3863120061159133\n",
      "trial: 3, iter: 9200, curr loss: 1.3864833116531372, avg loss: 1.386324954032898\n",
      "trial: 3, iter: 9400, curr loss: 1.3861559629440308, avg loss: 1.3863152354955672\n",
      "trial: 3, iter: 9600, curr loss: 1.386472225189209, avg loss: 1.3863245970010758\n",
      "trial: 3, iter: 9800, curr loss: 1.3863506317138672, avg loss: 1.3862920886278152\n",
      "trial: 3, iter: 10000, curr loss: 1.3863043785095215, avg loss: 1.3863161993026734\n",
      "trial: 3, iter: 10200, curr loss: 1.3863474130630493, avg loss: 1.3862985587120056\n",
      "trial: 3, iter: 10400, curr loss: 1.3861579895019531, avg loss: 1.3863035356998443\n",
      "trial: 3, iter: 10600, curr loss: 1.3862347602844238, avg loss: 1.3863147544860839\n",
      "trial: 3, iter: 10800, curr loss: 1.3857086896896362, avg loss: 1.3863036191463471\n",
      "trial: 3, iter: 11000, curr loss: 1.3861479759216309, avg loss: 1.3863690710067749\n",
      "trial: 3, iter: 11200, curr loss: 1.3867756128311157, avg loss: 1.3864053797721863\n",
      "trial: 3, iter: 11400, curr loss: 1.3862189054489136, avg loss: 1.3863457173109055\n",
      "trial: 3, iter: 11600, curr loss: 1.3861867189407349, avg loss: 1.3863262850046159\n",
      "trial: 3, iter: 11800, curr loss: 1.3849138021469116, avg loss: 1.386311326622963\n",
      "trial: 3, iter: 12000, curr loss: 1.38673734664917, avg loss: 1.3863365429639816\n",
      "trial: 3, iter: 12200, curr loss: 1.3859599828720093, avg loss: 1.3863072299957275\n",
      "trial: 3, iter: 12400, curr loss: 1.3864015340805054, avg loss: 1.3863155573606492\n",
      "trial: 3, iter: 12600, curr loss: 1.3866009712219238, avg loss: 1.386305142045021\n",
      "trial: 3, iter: 12800, curr loss: 1.3858017921447754, avg loss: 1.3863156014680862\n",
      "trial: 3, iter: 13000, curr loss: 1.3861536979675293, avg loss: 1.3862915760278702\n",
      "trial: 3, iter: 13200, curr loss: 1.3862310647964478, avg loss: 1.3863330090045929\n",
      "trial: 3, iter: 13400, curr loss: 1.3862309455871582, avg loss: 1.38631445646286\n",
      "trial: 3, iter: 13600, curr loss: 1.3863067626953125, avg loss: 1.3863002294301987\n",
      "trial: 3, iter: 13800, curr loss: 1.3862603902816772, avg loss: 1.3863031470775604\n",
      "trial: 3, iter: 14000, curr loss: 1.3863378763198853, avg loss: 1.3863029289245605\n",
      "trial: 3, iter: 14200, curr loss: 1.3863495588302612, avg loss: 1.3863079845905304\n",
      "trial: 3, iter: 14400, curr loss: 1.386307954788208, avg loss: 1.3863012778759003\n",
      "trial: 3, iter: 14600, curr loss: 1.3862504959106445, avg loss: 1.386299831867218\n",
      "trial: 3, iter: 14800, curr loss: 1.3862067461013794, avg loss: 1.3862943559885026\n",
      "trial: 3, iter: 15000, curr loss: 1.3864651918411255, avg loss: 1.3863038182258607\n",
      "trial: 3, iter: 15200, curr loss: 1.3868072032928467, avg loss: 1.386326178908348\n",
      "trial: 3, iter: 15400, curr loss: 1.385772705078125, avg loss: 1.3863329821825028\n",
      "trial: 3, iter: 15600, curr loss: 1.3863699436187744, avg loss: 1.3863278341293335\n",
      "trial: 3, ldr: 0.00037790765054523945\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3836514949798584, avg loss: 1.3876075756549835\n",
      "trial: 4, iter: 400, curr loss: 1.386608362197876, avg loss: 1.3868737584352493\n",
      "trial: 4, iter: 600, curr loss: 1.3872230052947998, avg loss: 1.386556375026703\n",
      "trial: 4, iter: 800, curr loss: 1.3852322101593018, avg loss: 1.3866725999116898\n",
      "trial: 4, iter: 1000, curr loss: 1.3841729164123535, avg loss: 1.386500443816185\n",
      "trial: 4, iter: 1200, curr loss: 1.3837859630584717, avg loss: 1.3866154170036316\n",
      "trial: 4, iter: 1400, curr loss: 1.3867727518081665, avg loss: 1.3865473932027816\n",
      "trial: 4, iter: 1600, curr loss: 1.3859155178070068, avg loss: 1.386415284872055\n",
      "trial: 4, iter: 1800, curr loss: 1.3851922750473022, avg loss: 1.3865014922618866\n",
      "trial: 4, iter: 2000, curr loss: 1.386818528175354, avg loss: 1.3864399152994156\n",
      "trial: 4, iter: 2200, curr loss: 1.3859843015670776, avg loss: 1.3864576709270477\n",
      "trial: 4, iter: 2400, curr loss: 1.3866195678710938, avg loss: 1.3864340275526046\n",
      "trial: 4, iter: 2600, curr loss: 1.3854860067367554, avg loss: 1.3863853150606156\n",
      "trial: 4, iter: 2800, curr loss: 1.3867671489715576, avg loss: 1.3864295715093613\n",
      "trial: 4, iter: 3000, curr loss: 1.3868390321731567, avg loss: 1.3863378310203551\n",
      "trial: 4, iter: 3200, curr loss: 1.3851983547210693, avg loss: 1.3864044082164764\n",
      "trial: 4, iter: 3400, curr loss: 1.3875269889831543, avg loss: 1.3864699792861939\n",
      "trial: 4, iter: 3600, curr loss: 1.3861526250839233, avg loss: 1.3863342577219009\n",
      "trial: 4, iter: 3800, curr loss: 1.3851836919784546, avg loss: 1.3863371723890305\n",
      "trial: 4, iter: 4000, curr loss: 1.3857059478759766, avg loss: 1.3863422149419784\n",
      "trial: 4, iter: 4200, curr loss: 1.3860132694244385, avg loss: 1.3863725262880324\n",
      "trial: 4, iter: 4400, curr loss: 1.3868001699447632, avg loss: 1.3863180255889893\n",
      "trial: 4, iter: 4600, curr loss: 1.3857200145721436, avg loss: 1.386301153898239\n",
      "trial: 4, iter: 4800, curr loss: 1.3860321044921875, avg loss: 1.3863393479585648\n",
      "trial: 4, iter: 5000, curr loss: 1.3853808641433716, avg loss: 1.3863524103164673\n",
      "trial: 4, iter: 5200, curr loss: 1.3854081630706787, avg loss: 1.3863275438547134\n",
      "trial: 4, iter: 5400, curr loss: 1.3863753080368042, avg loss: 1.3863892751932143\n",
      "trial: 4, iter: 5600, curr loss: 1.3868224620819092, avg loss: 1.3862838709354401\n",
      "trial: 4, iter: 5800, curr loss: 1.3865693807601929, avg loss: 1.386341381072998\n",
      "trial: 4, iter: 6000, curr loss: 1.3869708776474, avg loss: 1.3862899321317672\n",
      "trial: 4, iter: 6200, curr loss: 1.3859654664993286, avg loss: 1.3863158017396926\n",
      "trial: 4, iter: 6400, curr loss: 1.3864177465438843, avg loss: 1.386357572078705\n",
      "trial: 4, iter: 6600, curr loss: 1.3865535259246826, avg loss: 1.3863204854726792\n",
      "trial: 4, iter: 6800, curr loss: 1.3859444856643677, avg loss: 1.3863137543201447\n",
      "trial: 4, iter: 7000, curr loss: 1.3865538835525513, avg loss: 1.386352443099022\n",
      "trial: 4, iter: 7200, curr loss: 1.386800765991211, avg loss: 1.3864090484380722\n",
      "trial: 4, iter: 7400, curr loss: 1.3861582279205322, avg loss: 1.3863204407691956\n",
      "trial: 4, iter: 7600, curr loss: 1.3861855268478394, avg loss: 1.3863188552856445\n",
      "trial: 4, iter: 7800, curr loss: 1.386542558670044, avg loss: 1.3862963777780533\n",
      "trial: 4, iter: 8000, curr loss: 1.3859316110610962, avg loss: 1.3863179898262024\n",
      "trial: 4, iter: 8200, curr loss: 1.3861799240112305, avg loss: 1.3863140189647674\n",
      "trial: 4, iter: 8400, curr loss: 1.386495590209961, avg loss: 1.3862972885370255\n",
      "trial: 4, iter: 8600, curr loss: 1.3860039710998535, avg loss: 1.3863426554203033\n",
      "trial: 4, iter: 8800, curr loss: 1.3863227367401123, avg loss: 1.3863084363937377\n",
      "trial: 4, iter: 9000, curr loss: 1.3863651752471924, avg loss: 1.3862956178188324\n",
      "trial: 4, iter: 9200, curr loss: 1.386452317237854, avg loss: 1.3863000947237014\n",
      "trial: 4, iter: 9400, curr loss: 1.3861703872680664, avg loss: 1.3863118302822113\n",
      "trial: 4, iter: 9600, curr loss: 1.3865389823913574, avg loss: 1.3863282185792922\n",
      "trial: 4, iter: 9800, curr loss: 1.3860687017440796, avg loss: 1.3862887102365493\n",
      "trial: 4, iter: 10000, curr loss: 1.3861793279647827, avg loss: 1.386276119351387\n",
      "trial: 4, iter: 10200, curr loss: 1.3863279819488525, avg loss: 1.3862532466650008\n",
      "trial: 4, iter: 10400, curr loss: 1.3861390352249146, avg loss: 1.3863387680053711\n",
      "trial: 4, iter: 10600, curr loss: 1.3869538307189941, avg loss: 1.3863306659460068\n",
      "trial: 4, iter: 10800, curr loss: 1.386804461479187, avg loss: 1.3863091325759889\n",
      "trial: 4, iter: 11000, curr loss: 1.3862723112106323, avg loss: 1.3863266974687576\n",
      "trial: 4, iter: 11200, curr loss: 1.3860210180282593, avg loss: 1.3862903374433517\n",
      "trial: 4, iter: 11400, curr loss: 1.3863627910614014, avg loss: 1.386299786567688\n",
      "trial: 4, iter: 11600, curr loss: 1.3862262964248657, avg loss: 1.3863129448890685\n",
      "trial: 4, iter: 11800, curr loss: 1.3861966133117676, avg loss: 1.3862909090518951\n",
      "trial: 4, iter: 12000, curr loss: 1.3863744735717773, avg loss: 1.38629440844059\n",
      "trial: 4, iter: 12200, curr loss: 1.3865724802017212, avg loss: 1.3863507151603698\n",
      "trial: 4, iter: 12400, curr loss: 1.3862431049346924, avg loss: 1.3863199031352997\n",
      "trial: 4, iter: 12600, curr loss: 1.3861643075942993, avg loss: 1.3862942630052566\n",
      "trial: 4, iter: 12800, curr loss: 1.3858704566955566, avg loss: 1.3862938117980956\n",
      "trial: 4, iter: 13000, curr loss: 1.3860490322113037, avg loss: 1.386313042640686\n",
      "trial: 4, iter: 13200, curr loss: 1.3862427473068237, avg loss: 1.386311395764351\n",
      "trial: 4, iter: 13400, curr loss: 1.3861922025680542, avg loss: 1.3863170355558396\n",
      "trial: 4, iter: 13600, curr loss: 1.3862746953964233, avg loss: 1.3863064867258073\n",
      "trial: 4, iter: 13800, curr loss: 1.3863128423690796, avg loss: 1.3862992876768112\n",
      "trial: 4, iter: 14000, curr loss: 1.3862361907958984, avg loss: 1.386298572421074\n",
      "trial: 4, iter: 14200, curr loss: 1.3861879110336304, avg loss: 1.3863024777173996\n",
      "trial: 4, iter: 14400, curr loss: 1.3862648010253906, avg loss: 1.3863036143779754\n",
      "trial: 4, iter: 14600, curr loss: 1.3863199949264526, avg loss: 1.3863007700443268\n",
      "trial: 4, iter: 14800, curr loss: 1.386295199394226, avg loss: 1.3863102579116822\n",
      "trial: 4, iter: 15000, curr loss: 1.3862435817718506, avg loss: 1.386301577091217\n",
      "trial: 4, iter: 15200, curr loss: 1.3863204717636108, avg loss: 1.3863000470399856\n",
      "trial: 4, iter: 15400, curr loss: 1.3862353563308716, avg loss: 1.3862938183546065\n",
      "trial: 4, iter: 15600, curr loss: 1.3862956762313843, avg loss: 1.3862919771671296\n",
      "trial: 4, ldr: 2.0944075004081242e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3883339166641235, avg loss: 1.387256920337677\n",
      "trial: 5, iter: 400, curr loss: 1.3871116638183594, avg loss: 1.3867313641309738\n",
      "trial: 5, iter: 600, curr loss: 1.3883546590805054, avg loss: 1.3865995228290557\n",
      "trial: 5, iter: 800, curr loss: 1.387662410736084, avg loss: 1.3865176045894623\n",
      "trial: 5, iter: 1000, curr loss: 1.3857519626617432, avg loss: 1.3864897364377975\n",
      "trial: 5, iter: 1200, curr loss: 1.3853633403778076, avg loss: 1.386427129507065\n",
      "trial: 5, iter: 1400, curr loss: 1.3878827095031738, avg loss: 1.3864123284816743\n",
      "trial: 5, iter: 1600, curr loss: 1.3883880376815796, avg loss: 1.3864609336853027\n",
      "trial: 5, iter: 1800, curr loss: 1.385633945465088, avg loss: 1.3864515221118927\n",
      "trial: 5, iter: 2000, curr loss: 1.3846244812011719, avg loss: 1.3863449400663377\n",
      "trial: 5, iter: 2200, curr loss: 1.3860846757888794, avg loss: 1.386491024494171\n",
      "trial: 5, iter: 2400, curr loss: 1.386716604232788, avg loss: 1.3862844455242156\n",
      "trial: 5, iter: 2600, curr loss: 1.386611819267273, avg loss: 1.3864090090990067\n",
      "trial: 5, iter: 2800, curr loss: 1.387385606765747, avg loss: 1.3863780921697617\n",
      "trial: 5, iter: 3000, curr loss: 1.385609745979309, avg loss: 1.3863396829366683\n",
      "trial: 5, iter: 3200, curr loss: 1.3852384090423584, avg loss: 1.3863316762447357\n",
      "trial: 5, iter: 3400, curr loss: 1.3866586685180664, avg loss: 1.3863524490594863\n",
      "trial: 5, iter: 3600, curr loss: 1.3852217197418213, avg loss: 1.3862987631559371\n",
      "trial: 5, iter: 3800, curr loss: 1.386641025543213, avg loss: 1.3863648039102554\n",
      "trial: 5, iter: 4000, curr loss: 1.3866912126541138, avg loss: 1.3863887667655945\n",
      "trial: 5, iter: 4200, curr loss: 1.3870220184326172, avg loss: 1.3863570034503936\n",
      "trial: 5, iter: 4400, curr loss: 1.3861650228500366, avg loss: 1.3863463699817657\n",
      "trial: 5, iter: 4600, curr loss: 1.386412501335144, avg loss: 1.3863531535863876\n",
      "trial: 5, iter: 4800, curr loss: 1.3863269090652466, avg loss: 1.386373364329338\n",
      "trial: 5, iter: 5000, curr loss: 1.386175513267517, avg loss: 1.3863929933309556\n",
      "trial: 5, iter: 5200, curr loss: 1.386549711227417, avg loss: 1.3863026309013367\n",
      "trial: 5, iter: 5400, curr loss: 1.3863383531570435, avg loss: 1.38634350001812\n",
      "trial: 5, iter: 5600, curr loss: 1.3867305517196655, avg loss: 1.3863454723358155\n",
      "trial: 5, iter: 5800, curr loss: 1.3862674236297607, avg loss: 1.3863222217559814\n",
      "trial: 5, iter: 6000, curr loss: 1.3860806226730347, avg loss: 1.386300100684166\n",
      "trial: 5, iter: 6200, curr loss: 1.3864389657974243, avg loss: 1.386283564567566\n",
      "trial: 5, iter: 6400, curr loss: 1.3860269784927368, avg loss: 1.3863118696212768\n",
      "trial: 5, iter: 6600, curr loss: 1.386235237121582, avg loss: 1.3863124871253967\n",
      "trial: 5, iter: 6800, curr loss: 1.3852243423461914, avg loss: 1.3862897437810897\n",
      "trial: 5, iter: 7000, curr loss: 1.386599063873291, avg loss: 1.386323903799057\n",
      "trial: 5, iter: 7200, curr loss: 1.3863242864608765, avg loss: 1.3863051074743271\n",
      "trial: 5, iter: 7400, curr loss: 1.3861385583877563, avg loss: 1.3863060557842255\n",
      "trial: 5, iter: 7600, curr loss: 1.3864548206329346, avg loss: 1.386323053240776\n",
      "trial: 5, iter: 7800, curr loss: 1.3863447904586792, avg loss: 1.3863115453720092\n",
      "trial: 5, iter: 8000, curr loss: 1.3864545822143555, avg loss: 1.3863136231899262\n",
      "trial: 5, iter: 8200, curr loss: 1.3862687349319458, avg loss: 1.386308848261833\n",
      "trial: 5, iter: 8400, curr loss: 1.3863424062728882, avg loss: 1.3862992244958878\n",
      "trial: 5, iter: 8600, curr loss: 1.3863694667816162, avg loss: 1.3862999039888382\n",
      "trial: 5, iter: 8800, curr loss: 1.3862707614898682, avg loss: 1.386288478374481\n",
      "trial: 5, iter: 9000, curr loss: 1.386385202407837, avg loss: 1.3863022780418397\n",
      "trial: 5, iter: 9200, curr loss: 1.3863478899002075, avg loss: 1.386290318965912\n",
      "trial: 5, iter: 9400, curr loss: 1.3862156867980957, avg loss: 1.3863014787435533\n",
      "trial: 5, iter: 9600, curr loss: 1.3863006830215454, avg loss: 1.386305463910103\n",
      "trial: 5, iter: 9800, curr loss: 1.3862550258636475, avg loss: 1.3862945407629013\n",
      "trial: 5, iter: 10000, curr loss: 1.3862581253051758, avg loss: 1.386294271349907\n",
      "trial: 5, iter: 10200, curr loss: 1.3862920999526978, avg loss: 1.386297265291214\n",
      "trial: 5, iter: 10400, curr loss: 1.386290431022644, avg loss: 1.3863037306070327\n",
      "trial: 5, iter: 10600, curr loss: 1.3862998485565186, avg loss: 1.3862935453653336\n",
      "trial: 5, iter: 10800, curr loss: 1.3863948583602905, avg loss: 1.3863024592399598\n",
      "trial: 5, iter: 11000, curr loss: 1.3863027095794678, avg loss: 1.3862967401742936\n",
      "trial: 5, iter: 11200, curr loss: 1.3863303661346436, avg loss: 1.3863533824682235\n",
      "trial: 5, iter: 11400, curr loss: 1.3860803842544556, avg loss: 1.386302393078804\n",
      "trial: 5, iter: 11600, curr loss: 1.3869191408157349, avg loss: 1.3863185912370681\n",
      "trial: 5, iter: 11800, curr loss: 1.3866758346557617, avg loss: 1.3862920010089874\n",
      "trial: 5, iter: 12000, curr loss: 1.3859739303588867, avg loss: 1.3863533359766007\n",
      "trial: 5, iter: 12200, curr loss: 1.3860077857971191, avg loss: 1.3863371109962463\n",
      "trial: 5, iter: 12400, curr loss: 1.3861839771270752, avg loss: 1.3862874561548233\n",
      "trial: 5, iter: 12600, curr loss: 1.3864730596542358, avg loss: 1.3863261419534683\n",
      "trial: 5, iter: 12800, curr loss: 1.3865492343902588, avg loss: 1.3863013982772827\n",
      "trial: 5, iter: 13000, curr loss: 1.3864930868148804, avg loss: 1.3863023430109025\n",
      "trial: 5, iter: 13200, curr loss: 1.3859401941299438, avg loss: 1.3862990272045135\n",
      "trial: 5, iter: 13400, curr loss: 1.3862777948379517, avg loss: 1.3863263756036759\n",
      "trial: 5, iter: 13600, curr loss: 1.3863040208816528, avg loss: 1.3863033509254457\n",
      "trial: 5, iter: 13800, curr loss: 1.3861678838729858, avg loss: 1.3863020998239517\n",
      "trial: 5, iter: 14000, curr loss: 1.3868876695632935, avg loss: 1.3862872475385666\n",
      "trial: 5, iter: 14200, curr loss: 1.3862664699554443, avg loss: 1.386296569108963\n",
      "trial: 5, iter: 14400, curr loss: 1.386522650718689, avg loss: 1.3863169640302657\n",
      "trial: 5, iter: 14600, curr loss: 1.3859442472457886, avg loss: 1.386272875070572\n",
      "trial: 5, iter: 14800, curr loss: 1.386549949645996, avg loss: 1.3862749403715133\n",
      "trial: 5, iter: 15000, curr loss: 1.3867082595825195, avg loss: 1.3863167774677276\n",
      "trial: 5, iter: 15200, curr loss: 1.3861411809921265, avg loss: 1.3863024228811265\n",
      "trial: 5, iter: 15400, curr loss: 1.3862905502319336, avg loss: 1.38630768597126\n",
      "trial: 5, iter: 15600, curr loss: 1.3863446712493896, avg loss: 1.386309987306595\n",
      "trial: 5, ldr: 0.00011928104504477233\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0003972073409386212\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3876315355300903, avg loss: 1.3871466982364655\n",
      "trial: 1, iter: 400, curr loss: 1.390407919883728, avg loss: 1.3865375792980195\n",
      "trial: 1, iter: 600, curr loss: 1.385364294052124, avg loss: 1.3865671384334564\n",
      "trial: 1, iter: 800, curr loss: 1.3864367008209229, avg loss: 1.3865052050352096\n",
      "trial: 1, iter: 1000, curr loss: 1.3861569166183472, avg loss: 1.3864430767297744\n",
      "trial: 1, iter: 1200, curr loss: 1.3864809274673462, avg loss: 1.386441052556038\n",
      "trial: 1, iter: 1400, curr loss: 1.385453462600708, avg loss: 1.3865112709999083\n",
      "trial: 1, iter: 1600, curr loss: 1.3862035274505615, avg loss: 1.3864641451835633\n",
      "trial: 1, iter: 1800, curr loss: 1.386324405670166, avg loss: 1.3863374066352845\n",
      "trial: 1, iter: 2000, curr loss: 1.3867244720458984, avg loss: 1.386443126797676\n",
      "trial: 1, iter: 2200, curr loss: 1.386270523071289, avg loss: 1.3863569247722625\n",
      "trial: 1, iter: 2400, curr loss: 1.3864140510559082, avg loss: 1.386384996175766\n",
      "trial: 1, iter: 2600, curr loss: 1.3865182399749756, avg loss: 1.3863503581285477\n",
      "trial: 1, iter: 2800, curr loss: 1.3868917226791382, avg loss: 1.386332122683525\n",
      "trial: 1, iter: 3000, curr loss: 1.3868250846862793, avg loss: 1.3863085317611694\n",
      "trial: 1, iter: 3200, curr loss: 1.38658607006073, avg loss: 1.3863437396287919\n",
      "trial: 1, iter: 3400, curr loss: 1.3865368366241455, avg loss: 1.3863435244560243\n",
      "trial: 1, iter: 3600, curr loss: 1.3860682249069214, avg loss: 1.3863343769311904\n",
      "trial: 1, iter: 3800, curr loss: 1.3863366842269897, avg loss: 1.386357577443123\n",
      "trial: 1, iter: 4000, curr loss: 1.3867002725601196, avg loss: 1.3863113355636596\n",
      "trial: 1, iter: 4200, curr loss: 1.3869179487228394, avg loss: 1.3862415355443956\n",
      "trial: 1, iter: 4400, curr loss: 1.3866130113601685, avg loss: 1.3864034432172776\n",
      "trial: 1, iter: 4600, curr loss: 1.3865660429000854, avg loss: 1.3863196843862533\n",
      "trial: 1, iter: 4800, curr loss: 1.3864994049072266, avg loss: 1.3862989246845245\n",
      "trial: 1, iter: 5000, curr loss: 1.3860183954238892, avg loss: 1.3863416087627412\n",
      "trial: 1, iter: 5200, curr loss: 1.3859446048736572, avg loss: 1.3862952667474746\n",
      "trial: 1, iter: 5400, curr loss: 1.3860142230987549, avg loss: 1.386350121498108\n",
      "trial: 1, iter: 5600, curr loss: 1.386113166809082, avg loss: 1.3863517826795577\n",
      "trial: 1, iter: 5800, curr loss: 1.3883938789367676, avg loss: 1.3864365601539612\n",
      "trial: 1, iter: 6000, curr loss: 1.3875685930252075, avg loss: 1.3864313387870788\n",
      "trial: 1, iter: 6200, curr loss: 1.386064887046814, avg loss: 1.3863867628574371\n",
      "trial: 1, iter: 6400, curr loss: 1.3854156732559204, avg loss: 1.3863511008024216\n",
      "trial: 1, iter: 6600, curr loss: 1.3861061334609985, avg loss: 1.3863028359413148\n",
      "trial: 1, iter: 6800, curr loss: 1.3859118223190308, avg loss: 1.3863255733251572\n",
      "trial: 1, iter: 7000, curr loss: 1.3871111869812012, avg loss: 1.3863712799549104\n",
      "trial: 1, iter: 7200, curr loss: 1.3854265213012695, avg loss: 1.3863375353813172\n",
      "trial: 1, iter: 7400, curr loss: 1.386764407157898, avg loss: 1.3863893657922746\n",
      "trial: 1, iter: 7600, curr loss: 1.3859890699386597, avg loss: 1.3863756358623505\n",
      "trial: 1, iter: 7800, curr loss: 1.3861621618270874, avg loss: 1.3863229995965958\n",
      "trial: 1, iter: 8000, curr loss: 1.3863952159881592, avg loss: 1.3863477039337158\n",
      "trial: 1, iter: 8200, curr loss: 1.386224389076233, avg loss: 1.386305941939354\n",
      "trial: 1, iter: 8400, curr loss: 1.3857808113098145, avg loss: 1.3863116991519928\n",
      "trial: 1, iter: 8600, curr loss: 1.3864543437957764, avg loss: 1.3863076233863831\n",
      "trial: 1, iter: 8800, curr loss: 1.3865208625793457, avg loss: 1.3862930262088775\n",
      "trial: 1, iter: 9000, curr loss: 1.3865035772323608, avg loss: 1.3863242334127426\n",
      "trial: 1, iter: 9200, curr loss: 1.3862144947052002, avg loss: 1.3863195168972016\n",
      "trial: 1, iter: 9400, curr loss: 1.386141300201416, avg loss: 1.3863047873973846\n",
      "trial: 1, iter: 9600, curr loss: 1.3865553140640259, avg loss: 1.386308004260063\n",
      "trial: 1, iter: 9800, curr loss: 1.3868286609649658, avg loss: 1.3862719094753266\n",
      "trial: 1, iter: 10000, curr loss: 1.3862669467926025, avg loss: 1.3863505554199218\n",
      "trial: 1, iter: 10200, curr loss: 1.386298418045044, avg loss: 1.3863079023361207\n",
      "trial: 1, iter: 10400, curr loss: 1.3862576484680176, avg loss: 1.3863091105222702\n",
      "trial: 1, iter: 10600, curr loss: 1.3863182067871094, avg loss: 1.3863033717870712\n",
      "trial: 1, iter: 10800, curr loss: 1.3862497806549072, avg loss: 1.3862909138202668\n",
      "trial: 1, iter: 11000, curr loss: 1.386169195175171, avg loss: 1.38630053460598\n",
      "trial: 1, iter: 11200, curr loss: 1.3863012790679932, avg loss: 1.3862893670797347\n",
      "trial: 1, iter: 11400, curr loss: 1.3865176439285278, avg loss: 1.3862838912010194\n",
      "trial: 1, iter: 11600, curr loss: 1.3859984874725342, avg loss: 1.3863016486167907\n",
      "trial: 1, iter: 11800, curr loss: 1.386353850364685, avg loss: 1.3863188499212264\n",
      "trial: 1, iter: 12000, curr loss: 1.3861907720565796, avg loss: 1.3862893199920654\n",
      "trial: 1, iter: 12200, curr loss: 1.3863195180892944, avg loss: 1.3862959414720535\n",
      "trial: 1, iter: 12400, curr loss: 1.386289119720459, avg loss: 1.3862754929065704\n",
      "trial: 1, iter: 12600, curr loss: 1.3854432106018066, avg loss: 1.386328891515732\n",
      "trial: 1, iter: 12800, curr loss: 1.387081503868103, avg loss: 1.38631498336792\n",
      "trial: 1, iter: 13000, curr loss: 1.3863041400909424, avg loss: 1.3863187527656555\n",
      "trial: 1, iter: 13200, curr loss: 1.3864718675613403, avg loss: 1.3862977015972138\n",
      "trial: 1, iter: 13400, curr loss: 1.3864848613739014, avg loss: 1.386317129135132\n",
      "trial: 1, iter: 13600, curr loss: 1.3862987756729126, avg loss: 1.3863148778676986\n",
      "trial: 1, iter: 13800, curr loss: 1.3865485191345215, avg loss: 1.3863228148221969\n",
      "trial: 1, iter: 14000, curr loss: 1.3862709999084473, avg loss: 1.3862704646587372\n",
      "trial: 1, iter: 14200, curr loss: 1.3864353895187378, avg loss: 1.3863200616836548\n",
      "trial: 1, iter: 14400, curr loss: 1.3862136602401733, avg loss: 1.386284475326538\n",
      "trial: 1, iter: 14600, curr loss: 1.3865617513656616, avg loss: 1.386307258605957\n",
      "trial: 1, iter: 14800, curr loss: 1.386502742767334, avg loss: 1.3862903344631194\n",
      "trial: 1, iter: 15000, curr loss: 1.386334776878357, avg loss: 1.3863253378868103\n",
      "trial: 1, iter: 15200, curr loss: 1.3861545324325562, avg loss: 1.3863006258010864\n",
      "trial: 1, iter: 15400, curr loss: 1.386218547821045, avg loss: 1.386294236779213\n",
      "trial: 1, iter: 15600, curr loss: 1.3863458633422852, avg loss: 1.386296004652977\n",
      "trial: 1, ldr: -0.0005617539281956851\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.388377070426941, avg loss: 1.3873179161548614\n",
      "trial: 2, iter: 400, curr loss: 1.387971043586731, avg loss: 1.3865692520141601\n",
      "trial: 2, iter: 600, curr loss: 1.3869616985321045, avg loss: 1.386635230779648\n",
      "trial: 2, iter: 800, curr loss: 1.3874833583831787, avg loss: 1.3865722978115083\n",
      "trial: 2, iter: 1000, curr loss: 1.3866697549819946, avg loss: 1.3866011720895768\n",
      "trial: 2, iter: 1200, curr loss: 1.385750412940979, avg loss: 1.386423705816269\n",
      "trial: 2, iter: 1400, curr loss: 1.3865113258361816, avg loss: 1.3865633779764175\n",
      "trial: 2, iter: 1600, curr loss: 1.3869789838790894, avg loss: 1.3864102935791016\n",
      "trial: 2, iter: 1800, curr loss: 1.386559009552002, avg loss: 1.3863688051700591\n",
      "trial: 2, iter: 2000, curr loss: 1.3870257139205933, avg loss: 1.3864102816581727\n",
      "trial: 2, iter: 2200, curr loss: 1.3864116668701172, avg loss: 1.3864007115364074\n",
      "trial: 2, iter: 2400, curr loss: 1.3863410949707031, avg loss: 1.3863490772247316\n",
      "trial: 2, iter: 2600, curr loss: 1.3864350318908691, avg loss: 1.386303122639656\n",
      "trial: 2, iter: 2800, curr loss: 1.3865350484848022, avg loss: 1.3863480007648468\n",
      "trial: 2, iter: 3000, curr loss: 1.386257290840149, avg loss: 1.386334366798401\n",
      "trial: 2, iter: 3200, curr loss: 1.386455774307251, avg loss: 1.3863136667013167\n",
      "trial: 2, iter: 3400, curr loss: 1.3861515522003174, avg loss: 1.3863287007808685\n",
      "trial: 2, iter: 3600, curr loss: 1.3861632347106934, avg loss: 1.3863094979524613\n",
      "trial: 2, iter: 3800, curr loss: 1.3861706256866455, avg loss: 1.3863275027275086\n",
      "trial: 2, iter: 4000, curr loss: 1.3861722946166992, avg loss: 1.3863551169633865\n",
      "trial: 2, iter: 4200, curr loss: 1.386267900466919, avg loss: 1.386308845281601\n",
      "trial: 2, iter: 4400, curr loss: 1.3863575458526611, avg loss: 1.3863177335262298\n",
      "trial: 2, iter: 4600, curr loss: 1.3862675428390503, avg loss: 1.3863144797086715\n",
      "trial: 2, iter: 4800, curr loss: 1.3863953351974487, avg loss: 1.3862959641218184\n",
      "trial: 2, iter: 5000, curr loss: 1.386339783668518, avg loss: 1.3863189202547073\n",
      "trial: 2, iter: 5200, curr loss: 1.3861191272735596, avg loss: 1.3862905758619308\n",
      "trial: 2, iter: 5400, curr loss: 1.3863589763641357, avg loss: 1.3863330620527268\n",
      "trial: 2, iter: 5600, curr loss: 1.3864277601242065, avg loss: 1.3863050353527069\n",
      "trial: 2, iter: 5800, curr loss: 1.3858822584152222, avg loss: 1.3862763142585754\n",
      "trial: 2, iter: 6000, curr loss: 1.3864277601242065, avg loss: 1.38631412088871\n",
      "trial: 2, iter: 6200, curr loss: 1.3862309455871582, avg loss: 1.3863132172822952\n",
      "trial: 2, iter: 6400, curr loss: 1.3864378929138184, avg loss: 1.3863018554449082\n",
      "trial: 2, iter: 6600, curr loss: 1.3864473104476929, avg loss: 1.3863040012121202\n",
      "trial: 2, iter: 6800, curr loss: 1.3860477209091187, avg loss: 1.3862986707687377\n",
      "trial: 2, iter: 7000, curr loss: 1.3862907886505127, avg loss: 1.3863041925430297\n",
      "trial: 2, iter: 7200, curr loss: 1.3863630294799805, avg loss: 1.3862958121299744\n",
      "trial: 2, iter: 7400, curr loss: 1.3863098621368408, avg loss: 1.3862992590665817\n",
      "trial: 2, iter: 7600, curr loss: 1.3862857818603516, avg loss: 1.3863095736503601\n",
      "trial: 2, iter: 7800, curr loss: 1.386296272277832, avg loss: 1.3862987530231476\n",
      "trial: 2, iter: 8000, curr loss: 1.386262059211731, avg loss: 1.3862973743677138\n",
      "trial: 2, iter: 8200, curr loss: 1.3862515687942505, avg loss: 1.3862942892313004\n",
      "trial: 2, iter: 8400, curr loss: 1.386291742324829, avg loss: 1.3862932896614075\n",
      "trial: 2, iter: 8600, curr loss: 1.3862769603729248, avg loss: 1.386301290988922\n",
      "trial: 2, iter: 8800, curr loss: 1.38628089427948, avg loss: 1.386295714378357\n",
      "trial: 2, iter: 9000, curr loss: 1.3864378929138184, avg loss: 1.3862929421663284\n",
      "trial: 2, iter: 9200, curr loss: 1.3860515356063843, avg loss: 1.3863016331195832\n",
      "trial: 2, iter: 9400, curr loss: 1.385597825050354, avg loss: 1.3863143175840378\n",
      "trial: 2, iter: 9600, curr loss: 1.386244297027588, avg loss: 1.3862952184677124\n",
      "trial: 2, iter: 9800, curr loss: 1.3861016035079956, avg loss: 1.3863068693876266\n",
      "trial: 2, iter: 10000, curr loss: 1.3862805366516113, avg loss: 1.3862994301319123\n",
      "trial: 2, iter: 10200, curr loss: 1.3862605094909668, avg loss: 1.3862981688976288\n",
      "trial: 2, iter: 10400, curr loss: 1.3863837718963623, avg loss: 1.3862952345609665\n",
      "trial: 2, iter: 10600, curr loss: 1.3862824440002441, avg loss: 1.3862958294153214\n",
      "trial: 2, iter: 10800, curr loss: 1.3863186836242676, avg loss: 1.3862958091497422\n",
      "trial: 2, iter: 11000, curr loss: 1.3862916231155396, avg loss: 1.3863010644912719\n",
      "trial: 2, iter: 11200, curr loss: 1.3862624168395996, avg loss: 1.3862954813241959\n",
      "trial: 2, iter: 11400, curr loss: 1.3861063718795776, avg loss: 1.386292725801468\n",
      "trial: 2, iter: 11600, curr loss: 1.3861310482025146, avg loss: 1.3862993717193604\n",
      "trial: 2, iter: 11800, curr loss: 1.386352300643921, avg loss: 1.3862874621152879\n",
      "trial: 2, iter: 12000, curr loss: 1.3863211870193481, avg loss: 1.3863090604543686\n",
      "trial: 2, iter: 12200, curr loss: 1.3862236738204956, avg loss: 1.3862926292419433\n",
      "trial: 2, iter: 12400, curr loss: 1.386350393295288, avg loss: 1.3863014036417007\n",
      "trial: 2, iter: 12600, curr loss: 1.3862693309783936, avg loss: 1.3862948954105376\n",
      "trial: 2, iter: 12800, curr loss: 1.3863023519515991, avg loss: 1.386297117471695\n",
      "trial: 2, iter: 13000, curr loss: 1.38628351688385, avg loss: 1.386296865940094\n",
      "trial: 2, iter: 13200, curr loss: 1.386301875114441, avg loss: 1.38629270195961\n",
      "trial: 2, iter: 13400, curr loss: 1.3864887952804565, avg loss: 1.3862990379333495\n",
      "trial: 2, iter: 13600, curr loss: 1.3864866495132446, avg loss: 1.3862923228740691\n",
      "trial: 2, iter: 13800, curr loss: 1.3863064050674438, avg loss: 1.3863027292490004\n",
      "trial: 2, iter: 14000, curr loss: 1.3862897157669067, avg loss: 1.3862973767518998\n",
      "trial: 2, iter: 14200, curr loss: 1.3862675428390503, avg loss: 1.3862955451011658\n",
      "trial: 2, iter: 14400, curr loss: 1.3862727880477905, avg loss: 1.3862944477796555\n",
      "trial: 2, iter: 14600, curr loss: 1.3862723112106323, avg loss: 1.3862964987754822\n",
      "trial: 2, iter: 14800, curr loss: 1.3863167762756348, avg loss: 1.3862932312488556\n",
      "trial: 2, iter: 15000, curr loss: 1.3862942457199097, avg loss: 1.3862914806604385\n",
      "trial: 2, iter: 15200, curr loss: 1.3862982988357544, avg loss: 1.3862944269180297\n",
      "trial: 2, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.386294709444046\n",
      "trial: 2, iter: 15600, curr loss: 1.3862942457199097, avg loss: 1.386294226050377\n",
      "trial: 2, ldr: -4.310657459427603e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3847308158874512, avg loss: 1.3872732907533645\n",
      "trial: 3, iter: 400, curr loss: 1.3860341310501099, avg loss: 1.386659061908722\n",
      "trial: 3, iter: 600, curr loss: 1.3877164125442505, avg loss: 1.3865657591819762\n",
      "trial: 3, iter: 800, curr loss: 1.3877071142196655, avg loss: 1.3866282498836517\n",
      "trial: 3, iter: 1000, curr loss: 1.3904188871383667, avg loss: 1.3864505517482757\n",
      "trial: 3, iter: 1200, curr loss: 1.3856189250946045, avg loss: 1.386565199494362\n",
      "trial: 3, iter: 1400, curr loss: 1.3872593641281128, avg loss: 1.3865429496765136\n",
      "trial: 3, iter: 1600, curr loss: 1.38523268699646, avg loss: 1.386409788131714\n",
      "trial: 3, iter: 1800, curr loss: 1.3879122734069824, avg loss: 1.3864115643501282\n",
      "trial: 3, iter: 2000, curr loss: 1.3854882717132568, avg loss: 1.3863597899675368\n",
      "trial: 3, iter: 2200, curr loss: 1.3861967325210571, avg loss: 1.386445142030716\n",
      "trial: 3, iter: 2400, curr loss: 1.3852496147155762, avg loss: 1.386412215232849\n",
      "trial: 3, iter: 2600, curr loss: 1.387405514717102, avg loss: 1.3863554620742797\n",
      "trial: 3, iter: 2800, curr loss: 1.3867945671081543, avg loss: 1.3864633184671402\n",
      "trial: 3, iter: 3000, curr loss: 1.3871018886566162, avg loss: 1.3864563900232314\n",
      "trial: 3, iter: 3200, curr loss: 1.3862595558166504, avg loss: 1.3863644427061081\n",
      "trial: 3, iter: 3400, curr loss: 1.3854265213012695, avg loss: 1.386334987282753\n",
      "trial: 3, iter: 3600, curr loss: 1.387053370475769, avg loss: 1.3863995653390884\n",
      "trial: 3, iter: 3800, curr loss: 1.3860753774642944, avg loss: 1.386337770819664\n",
      "trial: 3, iter: 4000, curr loss: 1.3867015838623047, avg loss: 1.386423266530037\n",
      "trial: 3, iter: 4200, curr loss: 1.385326862335205, avg loss: 1.3863634592294694\n",
      "trial: 3, iter: 4400, curr loss: 1.386559247970581, avg loss: 1.386399165391922\n",
      "trial: 3, iter: 4600, curr loss: 1.3860541582107544, avg loss: 1.3863396793603897\n",
      "trial: 3, iter: 4800, curr loss: 1.3866946697235107, avg loss: 1.386289895772934\n",
      "trial: 3, iter: 5000, curr loss: 1.3855352401733398, avg loss: 1.3864206367731093\n",
      "trial: 3, iter: 5200, curr loss: 1.3859012126922607, avg loss: 1.386314709186554\n",
      "trial: 3, iter: 5400, curr loss: 1.3863022327423096, avg loss: 1.3863615709543229\n",
      "trial: 3, iter: 5600, curr loss: 1.3869084119796753, avg loss: 1.3863329184055329\n",
      "trial: 3, iter: 5800, curr loss: 1.386214017868042, avg loss: 1.386341627240181\n",
      "trial: 3, iter: 6000, curr loss: 1.3860937356948853, avg loss: 1.3863002187013627\n",
      "trial: 3, iter: 6200, curr loss: 1.386479377746582, avg loss: 1.386336213350296\n",
      "trial: 3, iter: 6400, curr loss: 1.3852369785308838, avg loss: 1.3863153541088105\n",
      "trial: 3, iter: 6600, curr loss: 1.3863005638122559, avg loss: 1.38637724339962\n",
      "trial: 3, iter: 6800, curr loss: 1.385361671447754, avg loss: 1.38627905189991\n",
      "trial: 3, iter: 7000, curr loss: 1.3866710662841797, avg loss: 1.3863000363111495\n",
      "trial: 3, iter: 7200, curr loss: 1.3857864141464233, avg loss: 1.3863231879472733\n",
      "trial: 3, iter: 7400, curr loss: 1.3863080739974976, avg loss: 1.386360183954239\n",
      "trial: 3, iter: 7600, curr loss: 1.3864622116088867, avg loss: 1.386285207271576\n",
      "trial: 3, iter: 7800, curr loss: 1.387040376663208, avg loss: 1.3863214021921157\n",
      "trial: 3, iter: 8000, curr loss: 1.3865041732788086, avg loss: 1.3863143664598465\n",
      "trial: 3, iter: 8200, curr loss: 1.384886384010315, avg loss: 1.3862339508533479\n",
      "trial: 3, iter: 8400, curr loss: 1.3862202167510986, avg loss: 1.3863600158691407\n",
      "trial: 3, iter: 8600, curr loss: 1.3867223262786865, avg loss: 1.386291132569313\n",
      "trial: 3, iter: 8800, curr loss: 1.3863658905029297, avg loss: 1.3863315123319626\n",
      "trial: 3, iter: 9000, curr loss: 1.3864620923995972, avg loss: 1.3862856274843216\n",
      "trial: 3, iter: 9200, curr loss: 1.3863887786865234, avg loss: 1.386290612220764\n",
      "trial: 3, iter: 9400, curr loss: 1.3862899541854858, avg loss: 1.38631432056427\n",
      "trial: 3, iter: 9600, curr loss: 1.3863635063171387, avg loss: 1.3862843710184096\n",
      "trial: 3, iter: 9800, curr loss: 1.3864696025848389, avg loss: 1.3863066643476487\n",
      "trial: 3, iter: 10000, curr loss: 1.3862088918685913, avg loss: 1.3863086998462677\n",
      "trial: 3, iter: 10200, curr loss: 1.3863688707351685, avg loss: 1.3862979006767273\n",
      "trial: 3, iter: 10400, curr loss: 1.3865196704864502, avg loss: 1.3862935256958009\n",
      "trial: 3, iter: 10600, curr loss: 1.3863930702209473, avg loss: 1.3863009339571\n",
      "trial: 3, iter: 10800, curr loss: 1.386350154876709, avg loss: 1.386301690340042\n",
      "trial: 3, iter: 11000, curr loss: 1.3862793445587158, avg loss: 1.3862953543663026\n",
      "trial: 3, iter: 11200, curr loss: 1.3863849639892578, avg loss: 1.3862961703538894\n",
      "trial: 3, iter: 11400, curr loss: 1.3862754106521606, avg loss: 1.3862980043888091\n",
      "trial: 3, iter: 11600, curr loss: 1.3864072561264038, avg loss: 1.3862926006317138\n",
      "trial: 3, iter: 11800, curr loss: 1.386298418045044, avg loss: 1.386298045516014\n",
      "trial: 3, iter: 12000, curr loss: 1.3862234354019165, avg loss: 1.3862978345155716\n",
      "trial: 3, iter: 12200, curr loss: 1.3862497806549072, avg loss: 1.3862962645292283\n",
      "trial: 3, iter: 12400, curr loss: 1.3863074779510498, avg loss: 1.3862863451242446\n",
      "trial: 3, iter: 12600, curr loss: 1.3861479759216309, avg loss: 1.386303772330284\n",
      "trial: 3, iter: 12800, curr loss: 1.3863645792007446, avg loss: 1.386294829249382\n",
      "trial: 3, iter: 13000, curr loss: 1.3861178159713745, avg loss: 1.3862953740358352\n",
      "trial: 3, iter: 13200, curr loss: 1.3862439393997192, avg loss: 1.3863016670942307\n",
      "trial: 3, iter: 13400, curr loss: 1.3859988451004028, avg loss: 1.3862875503301622\n",
      "trial: 3, iter: 13600, curr loss: 1.3866746425628662, avg loss: 1.386255938410759\n",
      "trial: 3, iter: 13800, curr loss: 1.3865141868591309, avg loss: 1.3863260579109191\n",
      "trial: 3, iter: 14000, curr loss: 1.3862534761428833, avg loss: 1.386300529241562\n",
      "trial: 3, iter: 14200, curr loss: 1.3863798379898071, avg loss: 1.3863055795431136\n",
      "trial: 3, iter: 14400, curr loss: 1.3861738443374634, avg loss: 1.3862910544872284\n",
      "trial: 3, iter: 14600, curr loss: 1.3863153457641602, avg loss: 1.386302922964096\n",
      "trial: 3, iter: 14800, curr loss: 1.3863061666488647, avg loss: 1.3862933373451234\n",
      "trial: 3, iter: 15000, curr loss: 1.3863155841827393, avg loss: 1.3862858176231385\n",
      "trial: 3, iter: 15200, curr loss: 1.386314868927002, avg loss: 1.3863100039958953\n",
      "trial: 3, iter: 15400, curr loss: 1.3862943649291992, avg loss: 1.3862951958179475\n",
      "trial: 3, iter: 15600, curr loss: 1.3862944841384888, avg loss: 1.3863016921281814\n",
      "trial: 3, ldr: -4.12435338148498e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860994577407837, avg loss: 1.3871018868684768\n",
      "trial: 4, iter: 400, curr loss: 1.387326717376709, avg loss: 1.386549084186554\n",
      "trial: 4, iter: 600, curr loss: 1.385967493057251, avg loss: 1.386622673869133\n",
      "trial: 4, iter: 800, curr loss: 1.3856674432754517, avg loss: 1.3864192271232605\n",
      "trial: 4, iter: 1000, curr loss: 1.3880923986434937, avg loss: 1.3864109241962432\n",
      "trial: 4, iter: 1200, curr loss: 1.385661244392395, avg loss: 1.3864338666200637\n",
      "trial: 4, iter: 1400, curr loss: 1.3853968381881714, avg loss: 1.3864040398597717\n",
      "trial: 4, iter: 1600, curr loss: 1.3872393369674683, avg loss: 1.3862971830368043\n",
      "trial: 4, iter: 1800, curr loss: 1.3862662315368652, avg loss: 1.3864153850078582\n",
      "trial: 4, iter: 2000, curr loss: 1.3856889009475708, avg loss: 1.3863645315170288\n",
      "trial: 4, iter: 2200, curr loss: 1.3865375518798828, avg loss: 1.3864188420772552\n",
      "trial: 4, iter: 2400, curr loss: 1.3859508037567139, avg loss: 1.3864040154218673\n",
      "trial: 4, iter: 2600, curr loss: 1.385854959487915, avg loss: 1.3863850498199464\n",
      "trial: 4, iter: 2800, curr loss: 1.3866385221481323, avg loss: 1.386374716758728\n",
      "trial: 4, iter: 3000, curr loss: 1.387342929840088, avg loss: 1.3863264310359955\n",
      "trial: 4, iter: 3200, curr loss: 1.385715126991272, avg loss: 1.3863150209188462\n",
      "trial: 4, iter: 3400, curr loss: 1.387001872062683, avg loss: 1.3863922983407975\n",
      "trial: 4, iter: 3600, curr loss: 1.3866685628890991, avg loss: 1.386310738325119\n",
      "trial: 4, iter: 3800, curr loss: 1.385969877243042, avg loss: 1.3863644862174989\n",
      "trial: 4, iter: 4000, curr loss: 1.386393666267395, avg loss: 1.3863298112154008\n",
      "trial: 4, iter: 4200, curr loss: 1.3867050409317017, avg loss: 1.3863249105215072\n",
      "trial: 4, iter: 4400, curr loss: 1.386582374572754, avg loss: 1.3863239783048629\n",
      "trial: 4, iter: 4600, curr loss: 1.38576078414917, avg loss: 1.3863040012121202\n",
      "trial: 4, iter: 4800, curr loss: 1.3860619068145752, avg loss: 1.3863305532932282\n",
      "trial: 4, iter: 5000, curr loss: 1.385298252105713, avg loss: 1.3862719851732255\n",
      "trial: 4, iter: 5200, curr loss: 1.3862203359603882, avg loss: 1.3863590598106383\n",
      "trial: 4, iter: 5400, curr loss: 1.3869726657867432, avg loss: 1.3862817311286926\n",
      "trial: 4, iter: 5600, curr loss: 1.3867660760879517, avg loss: 1.3863479655981064\n",
      "trial: 4, iter: 5800, curr loss: 1.3862849473953247, avg loss: 1.3863035118579865\n",
      "trial: 4, iter: 6000, curr loss: 1.3860746622085571, avg loss: 1.3863077861070634\n",
      "trial: 4, iter: 6200, curr loss: 1.3863773345947266, avg loss: 1.3863279515504836\n",
      "trial: 4, iter: 6400, curr loss: 1.3863506317138672, avg loss: 1.3863060927391053\n",
      "trial: 4, iter: 6600, curr loss: 1.386223316192627, avg loss: 1.3863058030605315\n",
      "trial: 4, iter: 6800, curr loss: 1.38653564453125, avg loss: 1.3862821465730668\n",
      "trial: 4, iter: 7000, curr loss: 1.385927677154541, avg loss: 1.3863061791658402\n",
      "trial: 4, iter: 7200, curr loss: 1.3861100673675537, avg loss: 1.3862968134880065\n",
      "trial: 4, iter: 7400, curr loss: 1.386147141456604, avg loss: 1.3862927377223968\n",
      "trial: 4, iter: 7600, curr loss: 1.3862420320510864, avg loss: 1.3863550233840942\n",
      "trial: 4, iter: 7800, curr loss: 1.3865094184875488, avg loss: 1.3863467824459077\n",
      "trial: 4, iter: 8000, curr loss: 1.3864256143569946, avg loss: 1.3862866526842117\n",
      "trial: 4, iter: 8200, curr loss: 1.3862972259521484, avg loss: 1.3863258159160614\n",
      "trial: 4, iter: 8400, curr loss: 1.386386513710022, avg loss: 1.3862958008050918\n",
      "trial: 4, iter: 8600, curr loss: 1.3860981464385986, avg loss: 1.3863078504800797\n",
      "trial: 4, iter: 8800, curr loss: 1.3860857486724854, avg loss: 1.3863096582889556\n",
      "trial: 4, iter: 9000, curr loss: 1.3863418102264404, avg loss: 1.3863065326213837\n",
      "trial: 4, iter: 9200, curr loss: 1.3860156536102295, avg loss: 1.3862919676303864\n",
      "trial: 4, iter: 9400, curr loss: 1.3862183094024658, avg loss: 1.3863037657737731\n",
      "trial: 4, iter: 9600, curr loss: 1.3864244222640991, avg loss: 1.3862909787893296\n",
      "trial: 4, iter: 9800, curr loss: 1.3864797353744507, avg loss: 1.3862740510702134\n",
      "trial: 4, iter: 10000, curr loss: 1.386327862739563, avg loss: 1.3863273578882218\n",
      "trial: 4, iter: 10200, curr loss: 1.3864927291870117, avg loss: 1.3863286888599395\n",
      "trial: 4, iter: 10400, curr loss: 1.3863273859024048, avg loss: 1.3863083398342133\n",
      "trial: 4, iter: 10600, curr loss: 1.3862167596817017, avg loss: 1.386313579082489\n",
      "trial: 4, iter: 10800, curr loss: 1.386235237121582, avg loss: 1.38629598736763\n",
      "trial: 4, iter: 11000, curr loss: 1.3863050937652588, avg loss: 1.3862996739149094\n",
      "trial: 4, iter: 11200, curr loss: 1.3863989114761353, avg loss: 1.3862997490167617\n",
      "trial: 4, iter: 11400, curr loss: 1.386266827583313, avg loss: 1.3863016450405121\n",
      "trial: 4, iter: 11600, curr loss: 1.386244297027588, avg loss: 1.386287426352501\n",
      "trial: 4, iter: 11800, curr loss: 1.3862457275390625, avg loss: 1.3863077145814895\n",
      "trial: 4, iter: 12000, curr loss: 1.3862402439117432, avg loss: 1.3862927693128586\n",
      "trial: 4, iter: 12200, curr loss: 1.386184573173523, avg loss: 1.3862938779592513\n",
      "trial: 4, iter: 12400, curr loss: 1.3864833116531372, avg loss: 1.3862911009788512\n",
      "trial: 4, iter: 12600, curr loss: 1.3856598138809204, avg loss: 1.386250073313713\n",
      "trial: 4, iter: 12800, curr loss: 1.3861709833145142, avg loss: 1.386335656642914\n",
      "trial: 4, iter: 13000, curr loss: 1.386553168296814, avg loss: 1.3862913709878921\n",
      "trial: 4, iter: 13200, curr loss: 1.3860986232757568, avg loss: 1.3863097959756852\n",
      "trial: 4, iter: 13400, curr loss: 1.3860422372817993, avg loss: 1.3862796384096145\n",
      "trial: 4, iter: 13600, curr loss: 1.3860538005828857, avg loss: 1.3862918847799302\n",
      "trial: 4, iter: 13800, curr loss: 1.386299967765808, avg loss: 1.3863208758831025\n",
      "trial: 4, iter: 14000, curr loss: 1.3859825134277344, avg loss: 1.386292495727539\n",
      "trial: 4, iter: 14200, curr loss: 1.3863129615783691, avg loss: 1.3863089555501937\n",
      "trial: 4, iter: 14400, curr loss: 1.386289358139038, avg loss: 1.3863010555505753\n",
      "trial: 4, iter: 14600, curr loss: 1.3863439559936523, avg loss: 1.3863024586439132\n",
      "trial: 4, iter: 14800, curr loss: 1.3863415718078613, avg loss: 1.3862991636991502\n",
      "trial: 4, iter: 15000, curr loss: 1.3862417936325073, avg loss: 1.3863014382123948\n",
      "trial: 4, iter: 15200, curr loss: 1.3864802122116089, avg loss: 1.3862960451841355\n",
      "trial: 4, iter: 15400, curr loss: 1.3864710330963135, avg loss: 1.386287687420845\n",
      "trial: 4, iter: 15600, curr loss: 1.3864115476608276, avg loss: 1.3863062274456024\n",
      "trial: 4, ldr: -6.208629929460585e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3883376121520996, avg loss: 1.3875146061182022\n",
      "trial: 5, iter: 400, curr loss: 1.3876712322235107, avg loss: 1.38670678794384\n",
      "trial: 5, iter: 600, curr loss: 1.387403964996338, avg loss: 1.3865746802091599\n",
      "trial: 5, iter: 800, curr loss: 1.3862297534942627, avg loss: 1.3865287959575654\n",
      "trial: 5, iter: 1000, curr loss: 1.3842754364013672, avg loss: 1.3864573526382447\n",
      "trial: 5, iter: 1200, curr loss: 1.3862072229385376, avg loss: 1.3864600765705108\n",
      "trial: 5, iter: 1400, curr loss: 1.3857955932617188, avg loss: 1.3863453072309495\n",
      "trial: 5, iter: 1600, curr loss: 1.3861517906188965, avg loss: 1.3864334017038344\n",
      "trial: 5, iter: 1800, curr loss: 1.385704755783081, avg loss: 1.3863775056600571\n",
      "trial: 5, iter: 2000, curr loss: 1.386478066444397, avg loss: 1.3863842916488647\n",
      "trial: 5, iter: 2200, curr loss: 1.385489821434021, avg loss: 1.3864727890491486\n",
      "trial: 5, iter: 2400, curr loss: 1.387294054031372, avg loss: 1.3864345103502274\n",
      "trial: 5, iter: 2600, curr loss: 1.3877161741256714, avg loss: 1.386423755288124\n",
      "trial: 5, iter: 2800, curr loss: 1.3865293264389038, avg loss: 1.3863782650232315\n",
      "trial: 5, iter: 3000, curr loss: 1.3861275911331177, avg loss: 1.3864000636339187\n",
      "trial: 5, iter: 3200, curr loss: 1.3864375352859497, avg loss: 1.3863836497068405\n",
      "trial: 5, iter: 3400, curr loss: 1.3863086700439453, avg loss: 1.3863433420658111\n",
      "trial: 5, iter: 3600, curr loss: 1.386041522026062, avg loss: 1.3863125610351563\n",
      "trial: 5, iter: 3800, curr loss: 1.3863575458526611, avg loss: 1.386351858973503\n",
      "trial: 5, iter: 4000, curr loss: 1.3872464895248413, avg loss: 1.3863035553693772\n",
      "trial: 5, iter: 4200, curr loss: 1.3859367370605469, avg loss: 1.3863487637043\n",
      "trial: 5, iter: 4400, curr loss: 1.386318325996399, avg loss: 1.3863583296537398\n",
      "trial: 5, iter: 4600, curr loss: 1.3866819143295288, avg loss: 1.3863641142845153\n",
      "trial: 5, iter: 4800, curr loss: 1.3861103057861328, avg loss: 1.3862936812639237\n",
      "trial: 5, iter: 5000, curr loss: 1.3861238956451416, avg loss: 1.3863121503591538\n",
      "trial: 5, iter: 5200, curr loss: 1.3865718841552734, avg loss: 1.386322665810585\n",
      "trial: 5, iter: 5400, curr loss: 1.3863904476165771, avg loss: 1.3863097542524339\n",
      "trial: 5, iter: 5600, curr loss: 1.3865652084350586, avg loss: 1.3863006621599196\n",
      "trial: 5, iter: 5800, curr loss: 1.3865001201629639, avg loss: 1.3862983614206315\n",
      "trial: 5, iter: 6000, curr loss: 1.3862786293029785, avg loss: 1.3863051450252533\n",
      "trial: 5, iter: 6200, curr loss: 1.3863592147827148, avg loss: 1.3863087731599808\n",
      "trial: 5, iter: 6400, curr loss: 1.386131763458252, avg loss: 1.3863124936819076\n",
      "trial: 5, iter: 6600, curr loss: 1.3866828680038452, avg loss: 1.386300377845764\n",
      "trial: 5, iter: 6800, curr loss: 1.3858635425567627, avg loss: 1.3862949073314668\n",
      "trial: 5, iter: 7000, curr loss: 1.3862946033477783, avg loss: 1.386330337524414\n",
      "trial: 5, iter: 7200, curr loss: 1.386286735534668, avg loss: 1.3862919974327088\n",
      "trial: 5, iter: 7400, curr loss: 1.38629150390625, avg loss: 1.3862959456443786\n",
      "trial: 5, iter: 7600, curr loss: 1.3862990140914917, avg loss: 1.3863125151395799\n",
      "trial: 5, iter: 7800, curr loss: 1.3862942457199097, avg loss: 1.3862964278459549\n",
      "trial: 5, iter: 8000, curr loss: 1.3862866163253784, avg loss: 1.3862952530384063\n",
      "trial: 5, iter: 8200, curr loss: 1.3862941265106201, avg loss: 1.3862950968742371\n",
      "trial: 5, iter: 8400, curr loss: 1.3863095045089722, avg loss: 1.3862939351797103\n",
      "trial: 5, iter: 8600, curr loss: 1.3862979412078857, avg loss: 1.3863590216636659\n",
      "trial: 5, iter: 8800, curr loss: 1.3863070011138916, avg loss: 1.386293909549713\n",
      "trial: 5, iter: 9000, curr loss: 1.3863227367401123, avg loss: 1.3862962657213211\n",
      "trial: 5, iter: 9200, curr loss: 1.3859857320785522, avg loss: 1.386313439011574\n",
      "trial: 5, iter: 9400, curr loss: 1.386293649673462, avg loss: 1.3862906754016877\n",
      "trial: 5, iter: 9600, curr loss: 1.3862944841384888, avg loss: 1.3862935316562652\n",
      "trial: 5, iter: 9800, curr loss: 1.3863251209259033, avg loss: 1.3862984097003936\n",
      "trial: 5, iter: 10000, curr loss: 1.3862942457199097, avg loss: 1.3862931108474732\n",
      "trial: 5, iter: 10200, curr loss: 1.3862942457199097, avg loss: 1.3862939298152923\n",
      "trial: 5, iter: 10400, curr loss: 1.3862941265106201, avg loss: 1.3862939196825028\n",
      "trial: 5, iter: 10600, curr loss: 1.3863016366958618, avg loss: 1.386293401122093\n",
      "trial: 5, iter: 10800, curr loss: 1.3862943649291992, avg loss: 1.3862958765029907\n",
      "trial: 5, iter: 11000, curr loss: 1.3862942457199097, avg loss: 1.3862929838895797\n",
      "trial: 5, iter: 11200, curr loss: 1.3862943649291992, avg loss: 1.3862964338064194\n",
      "trial: 5, iter: 11400, curr loss: 1.3862943649291992, avg loss: 1.386294154524803\n",
      "trial: 5, iter: 11600, curr loss: 1.3862943649291992, avg loss: 1.3862951481342316\n",
      "trial: 5, iter: 11800, curr loss: 1.3862941265106201, avg loss: 1.3862952619791031\n",
      "trial: 5, iter: 12000, curr loss: 1.3862943649291992, avg loss: 1.38629437148571\n",
      "trial: 5, iter: 12200, curr loss: 1.3862942457199097, avg loss: 1.3862943011522293\n",
      "trial: 5, iter: 12400, curr loss: 1.3862941265106201, avg loss: 1.3862950164079666\n",
      "trial: 5, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.386295195221901\n",
      "trial: 5, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.386294612288475\n",
      "trial: 5, iter: 13000, curr loss: 1.3862941265106201, avg loss: 1.3862953281402588\n",
      "trial: 5, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.3862946927547455\n",
      "trial: 5, iter: 13400, curr loss: 1.3862942457199097, avg loss: 1.3862944203615188\n",
      "trial: 5, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.3862947422266005\n",
      "trial: 5, iter: 13800, curr loss: 1.3862946033477783, avg loss: 1.3862946581840516\n",
      "trial: 5, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.3862950384616852\n",
      "trial: 5, iter: 14200, curr loss: 1.3862943649291992, avg loss: 1.3862944823503494\n",
      "trial: 5, iter: 14400, curr loss: 1.3862943649291992, avg loss: 1.386294493675232\n",
      "trial: 5, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.3862948334217071\n",
      "trial: 5, iter: 14800, curr loss: 1.3862944841384888, avg loss: 1.3862950378656387\n",
      "trial: 5, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294674873352\n",
      "trial: 5, iter: 15200, curr loss: 1.3862943649291992, avg loss: 1.386294721364975\n",
      "trial: 5, iter: 15400, curr loss: 1.3862946033477783, avg loss: 1.3862945067882537\n",
      "trial: 5, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862948393821717\n",
      "trial: 5, ldr: 0.00028363295132294297\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -6.972845740165212e-05\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3835259675979614, avg loss: 1.3871152836084366\n",
      "trial: 1, iter: 400, curr loss: 1.3858989477157593, avg loss: 1.3869346606731414\n",
      "trial: 1, iter: 600, curr loss: 1.3860960006713867, avg loss: 1.3865596437454224\n",
      "trial: 1, iter: 800, curr loss: 1.3875582218170166, avg loss: 1.386657527089119\n",
      "trial: 1, iter: 1000, curr loss: 1.386890172958374, avg loss: 1.3864559799432754\n",
      "trial: 1, iter: 1200, curr loss: 1.3884427547454834, avg loss: 1.3864098942279817\n",
      "trial: 1, iter: 1400, curr loss: 1.3845486640930176, avg loss: 1.3864011085033416\n",
      "trial: 1, iter: 1600, curr loss: 1.3868238925933838, avg loss: 1.386461981534958\n",
      "trial: 1, iter: 1800, curr loss: 1.38633394241333, avg loss: 1.3863676059246064\n",
      "trial: 1, iter: 2000, curr loss: 1.3868014812469482, avg loss: 1.3863715583086014\n",
      "trial: 1, iter: 2200, curr loss: 1.3860459327697754, avg loss: 1.3863707345724106\n",
      "trial: 1, iter: 2400, curr loss: 1.3861160278320312, avg loss: 1.3864317923784255\n",
      "trial: 1, iter: 2600, curr loss: 1.3855748176574707, avg loss: 1.386295222043991\n",
      "trial: 1, iter: 2800, curr loss: 1.3848226070404053, avg loss: 1.3863182091712951\n",
      "trial: 1, iter: 3000, curr loss: 1.3857183456420898, avg loss: 1.3864255523681641\n",
      "trial: 1, iter: 3200, curr loss: 1.3860490322113037, avg loss: 1.3863831043243409\n",
      "trial: 1, iter: 3400, curr loss: 1.3854292631149292, avg loss: 1.3862834113836289\n",
      "trial: 1, iter: 3600, curr loss: 1.3850789070129395, avg loss: 1.3862869572639465\n",
      "trial: 1, iter: 3800, curr loss: 1.3863729238510132, avg loss: 1.3863825976848603\n",
      "trial: 1, iter: 4000, curr loss: 1.386291742324829, avg loss: 1.3863484698534012\n",
      "trial: 1, iter: 4200, curr loss: 1.3869988918304443, avg loss: 1.3863498216867447\n",
      "trial: 1, iter: 4400, curr loss: 1.3858275413513184, avg loss: 1.3863190335035325\n",
      "trial: 1, iter: 4600, curr loss: 1.3870736360549927, avg loss: 1.3864065045118332\n",
      "trial: 1, iter: 4800, curr loss: 1.3870140314102173, avg loss: 1.3863725471496582\n",
      "trial: 1, iter: 5000, curr loss: 1.3870627880096436, avg loss: 1.3863685828447343\n",
      "trial: 1, iter: 5200, curr loss: 1.3863705396652222, avg loss: 1.3863669538497925\n",
      "trial: 1, iter: 5400, curr loss: 1.3864521980285645, avg loss: 1.3863063496351242\n",
      "trial: 1, iter: 5600, curr loss: 1.3865220546722412, avg loss: 1.3863572138547897\n",
      "trial: 1, iter: 5800, curr loss: 1.385972499847412, avg loss: 1.386340314745903\n",
      "trial: 1, iter: 6000, curr loss: 1.3861271142959595, avg loss: 1.3863280248641967\n",
      "trial: 1, iter: 6200, curr loss: 1.385472059249878, avg loss: 1.386252487897873\n",
      "trial: 1, iter: 6400, curr loss: 1.3864994049072266, avg loss: 1.3863472735881806\n",
      "trial: 1, iter: 6600, curr loss: 1.387093186378479, avg loss: 1.3864409565925597\n",
      "trial: 1, iter: 6800, curr loss: 1.3857848644256592, avg loss: 1.3864250141382217\n",
      "trial: 1, iter: 7000, curr loss: 1.3866769075393677, avg loss: 1.3863669633865356\n",
      "trial: 1, iter: 7200, curr loss: 1.3863555192947388, avg loss: 1.3862796175479888\n",
      "trial: 1, iter: 7400, curr loss: 1.3865965604782104, avg loss: 1.3863337117433547\n",
      "trial: 1, iter: 7600, curr loss: 1.3854926824569702, avg loss: 1.3863125765323638\n",
      "trial: 1, iter: 7800, curr loss: 1.387040615081787, avg loss: 1.3863203036785126\n",
      "trial: 1, iter: 8000, curr loss: 1.3865960836410522, avg loss: 1.3863460117578505\n",
      "trial: 1, iter: 8200, curr loss: 1.3866207599639893, avg loss: 1.3863344210386277\n",
      "trial: 1, iter: 8400, curr loss: 1.3863635063171387, avg loss: 1.3863222813606262\n",
      "trial: 1, iter: 8600, curr loss: 1.3863710165023804, avg loss: 1.386315479874611\n",
      "trial: 1, iter: 8800, curr loss: 1.3863908052444458, avg loss: 1.386326249241829\n",
      "trial: 1, iter: 9000, curr loss: 1.3865152597427368, avg loss: 1.3863095819950104\n",
      "trial: 1, iter: 9200, curr loss: 1.3874799013137817, avg loss: 1.3862221878767014\n",
      "trial: 1, iter: 9400, curr loss: 1.3865697383880615, avg loss: 1.3863335329294204\n",
      "trial: 1, iter: 9600, curr loss: 1.3863328695297241, avg loss: 1.386340037584305\n",
      "trial: 1, iter: 9800, curr loss: 1.3869127035140991, avg loss: 1.3862985694408416\n",
      "trial: 1, iter: 10000, curr loss: 1.3861829042434692, avg loss: 1.3863422620296477\n",
      "trial: 1, iter: 10200, curr loss: 1.3866591453552246, avg loss: 1.3862971645593642\n",
      "trial: 1, iter: 10400, curr loss: 1.3862574100494385, avg loss: 1.3863217675685882\n",
      "trial: 1, iter: 10600, curr loss: 1.3862195014953613, avg loss: 1.3863098698854446\n",
      "trial: 1, iter: 10800, curr loss: 1.3862141370773315, avg loss: 1.3863035410642623\n",
      "trial: 1, iter: 11000, curr loss: 1.386193871498108, avg loss: 1.3863003331422805\n",
      "trial: 1, iter: 11200, curr loss: 1.3859553337097168, avg loss: 1.386286454796791\n",
      "trial: 1, iter: 11400, curr loss: 1.3863112926483154, avg loss: 1.3863492846488952\n",
      "trial: 1, iter: 11600, curr loss: 1.3858729600906372, avg loss: 1.3863506364822387\n",
      "trial: 1, iter: 11800, curr loss: 1.386075735092163, avg loss: 1.3863625258207322\n",
      "trial: 1, iter: 12000, curr loss: 1.3861658573150635, avg loss: 1.386266211271286\n",
      "trial: 1, iter: 12200, curr loss: 1.3863747119903564, avg loss: 1.3863490706682204\n",
      "trial: 1, iter: 12400, curr loss: 1.3864092826843262, avg loss: 1.3863184863328935\n",
      "trial: 1, iter: 12600, curr loss: 1.3862119913101196, avg loss: 1.3863008666038512\n",
      "trial: 1, iter: 12800, curr loss: 1.3861998319625854, avg loss: 1.3863061940670014\n",
      "trial: 1, iter: 13000, curr loss: 1.386559009552002, avg loss: 1.3862970799207688\n",
      "trial: 1, iter: 13200, curr loss: 1.3863422870635986, avg loss: 1.3863131946325302\n",
      "trial: 1, iter: 13400, curr loss: 1.3870075941085815, avg loss: 1.386343743801117\n",
      "trial: 1, iter: 13600, curr loss: 1.3865914344787598, avg loss: 1.3863456362485886\n",
      "trial: 1, iter: 13800, curr loss: 1.3866153955459595, avg loss: 1.3863350182771683\n",
      "trial: 1, iter: 14000, curr loss: 1.3864463567733765, avg loss: 1.3863140445947648\n",
      "trial: 1, iter: 14200, curr loss: 1.386406660079956, avg loss: 1.386312153339386\n",
      "trial: 1, iter: 14400, curr loss: 1.3860805034637451, avg loss: 1.3863000017404556\n",
      "trial: 1, iter: 14600, curr loss: 1.386460304260254, avg loss: 1.3863073444366456\n",
      "trial: 1, iter: 14800, curr loss: 1.3861666917800903, avg loss: 1.3863062500953673\n",
      "trial: 1, iter: 15000, curr loss: 1.3862102031707764, avg loss: 1.386308384537697\n",
      "trial: 1, iter: 15200, curr loss: 1.38633131980896, avg loss: 1.3862929397821426\n",
      "trial: 1, iter: 15400, curr loss: 1.386112093925476, avg loss: 1.386302309036255\n",
      "trial: 1, iter: 15600, curr loss: 1.3863887786865234, avg loss: 1.3863260406255722\n",
      "trial: 1, ldr: -0.0007108185673132539\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3848350048065186, avg loss: 1.3876774621009826\n",
      "trial: 2, iter: 400, curr loss: 1.3874050378799438, avg loss: 1.3866447365283967\n",
      "trial: 2, iter: 600, curr loss: 1.3860489130020142, avg loss: 1.3865941739082337\n",
      "trial: 2, iter: 800, curr loss: 1.3866153955459595, avg loss: 1.3865419417619704\n",
      "trial: 2, iter: 1000, curr loss: 1.3863786458969116, avg loss: 1.3864887487888335\n",
      "trial: 2, iter: 1200, curr loss: 1.3879474401474, avg loss: 1.3863976502418518\n",
      "trial: 2, iter: 1400, curr loss: 1.3859503269195557, avg loss: 1.3863954609632492\n",
      "trial: 2, iter: 1600, curr loss: 1.3867560625076294, avg loss: 1.3863587349653244\n",
      "trial: 2, iter: 1800, curr loss: 1.3890503644943237, avg loss: 1.3863418877124787\n",
      "trial: 2, iter: 2000, curr loss: 1.3853094577789307, avg loss: 1.3864616340398788\n",
      "trial: 2, iter: 2200, curr loss: 1.3879395723342896, avg loss: 1.386556888818741\n",
      "trial: 2, iter: 2400, curr loss: 1.3853981494903564, avg loss: 1.3863674420118333\n",
      "trial: 2, iter: 2600, curr loss: 1.3861535787582397, avg loss: 1.3864130157232284\n",
      "trial: 2, iter: 2800, curr loss: 1.3859776258468628, avg loss: 1.3864396125078202\n",
      "trial: 2, iter: 3000, curr loss: 1.3869905471801758, avg loss: 1.3864108020067214\n",
      "trial: 2, iter: 3200, curr loss: 1.3868995904922485, avg loss: 1.3862658339738845\n",
      "trial: 2, iter: 3400, curr loss: 1.3875008821487427, avg loss: 1.3864343684911729\n",
      "trial: 2, iter: 3600, curr loss: 1.3862336874008179, avg loss: 1.3864322477579116\n",
      "trial: 2, iter: 3800, curr loss: 1.3863686323165894, avg loss: 1.386441433429718\n",
      "trial: 2, iter: 4000, curr loss: 1.3866169452667236, avg loss: 1.3863745146989823\n",
      "trial: 2, iter: 4200, curr loss: 1.3860273361206055, avg loss: 1.3863604044914246\n",
      "trial: 2, iter: 4400, curr loss: 1.38582444190979, avg loss: 1.386358996629715\n",
      "trial: 2, iter: 4600, curr loss: 1.3857131004333496, avg loss: 1.386305291056633\n",
      "trial: 2, iter: 4800, curr loss: 1.386214256286621, avg loss: 1.3863375860452651\n",
      "trial: 2, iter: 5000, curr loss: 1.3858586549758911, avg loss: 1.386287977695465\n",
      "trial: 2, iter: 5200, curr loss: 1.3866336345672607, avg loss: 1.386362412571907\n",
      "trial: 2, iter: 5400, curr loss: 1.385711669921875, avg loss: 1.386315650343895\n",
      "trial: 2, iter: 5600, curr loss: 1.3859204053878784, avg loss: 1.3863177919387817\n",
      "trial: 2, iter: 5800, curr loss: 1.3865660429000854, avg loss: 1.3862845593690871\n",
      "trial: 2, iter: 6000, curr loss: 1.3862078189849854, avg loss: 1.386329923272133\n",
      "trial: 2, iter: 6200, curr loss: 1.3865078687667847, avg loss: 1.386317745447159\n",
      "trial: 2, iter: 6400, curr loss: 1.3863415718078613, avg loss: 1.3862988662719726\n",
      "trial: 2, iter: 6600, curr loss: 1.3863561153411865, avg loss: 1.3863249021768569\n",
      "trial: 2, iter: 6800, curr loss: 1.3866865634918213, avg loss: 1.3863761842250824\n",
      "trial: 2, iter: 7000, curr loss: 1.3855586051940918, avg loss: 1.386345037817955\n",
      "trial: 2, iter: 7200, curr loss: 1.386762261390686, avg loss: 1.386339647769928\n",
      "trial: 2, iter: 7400, curr loss: 1.386710286140442, avg loss: 1.3863371014595032\n",
      "trial: 2, iter: 7600, curr loss: 1.385565996170044, avg loss: 1.3863504898548127\n",
      "trial: 2, iter: 7800, curr loss: 1.3869966268539429, avg loss: 1.3863183915615083\n",
      "trial: 2, iter: 8000, curr loss: 1.3862301111221313, avg loss: 1.3863157057762145\n",
      "trial: 2, iter: 8200, curr loss: 1.3860150575637817, avg loss: 1.3863018721342086\n",
      "trial: 2, iter: 8400, curr loss: 1.3863263130187988, avg loss: 1.3862977051734924\n",
      "trial: 2, iter: 8600, curr loss: 1.3863376379013062, avg loss: 1.3862988597154617\n",
      "trial: 2, iter: 8800, curr loss: 1.3866519927978516, avg loss: 1.3863019371032714\n",
      "trial: 2, iter: 9000, curr loss: 1.386825680732727, avg loss: 1.3862536233663558\n",
      "trial: 2, iter: 9200, curr loss: 1.3862348794937134, avg loss: 1.3863483506441117\n",
      "trial: 2, iter: 9400, curr loss: 1.3867520093917847, avg loss: 1.3862922674417495\n",
      "trial: 2, iter: 9600, curr loss: 1.3864930868148804, avg loss: 1.3862959641218184\n",
      "trial: 2, iter: 9800, curr loss: 1.3863496780395508, avg loss: 1.3863153594732285\n",
      "trial: 2, iter: 10000, curr loss: 1.3865724802017212, avg loss: 1.3863141590356827\n",
      "trial: 2, iter: 10200, curr loss: 1.3862664699554443, avg loss: 1.386301610469818\n",
      "trial: 2, iter: 10400, curr loss: 1.386518120765686, avg loss: 1.3863146501779555\n",
      "trial: 2, iter: 10600, curr loss: 1.3866326808929443, avg loss: 1.3862665289640426\n",
      "trial: 2, iter: 10800, curr loss: 1.3863235712051392, avg loss: 1.3863105112314225\n",
      "trial: 2, iter: 11000, curr loss: 1.3856751918792725, avg loss: 1.3862918323278428\n",
      "trial: 2, iter: 11200, curr loss: 1.386189341545105, avg loss: 1.3863011997938157\n",
      "trial: 2, iter: 11400, curr loss: 1.3862169981002808, avg loss: 1.3863066136837006\n",
      "trial: 2, iter: 11600, curr loss: 1.3861197233200073, avg loss: 1.3862975478172301\n",
      "trial: 2, iter: 11800, curr loss: 1.386161208152771, avg loss: 1.3862689566612243\n",
      "trial: 2, iter: 12000, curr loss: 1.3862618207931519, avg loss: 1.3862768226861955\n",
      "trial: 2, iter: 12200, curr loss: 1.3863568305969238, avg loss: 1.3863170462846757\n",
      "trial: 2, iter: 12400, curr loss: 1.3863755464553833, avg loss: 1.386298572421074\n",
      "trial: 2, iter: 12600, curr loss: 1.3863070011138916, avg loss: 1.3863090872764587\n",
      "trial: 2, iter: 12800, curr loss: 1.3862158060073853, avg loss: 1.3862895947694778\n",
      "trial: 2, iter: 13000, curr loss: 1.3862861394882202, avg loss: 1.3863008069992064\n",
      "trial: 2, iter: 13200, curr loss: 1.386319637298584, avg loss: 1.3862900799512863\n",
      "trial: 2, iter: 13400, curr loss: 1.3864991664886475, avg loss: 1.3863027846813203\n",
      "trial: 2, iter: 13600, curr loss: 1.3863524198532104, avg loss: 1.3862972128391267\n",
      "trial: 2, iter: 13800, curr loss: 1.386290431022644, avg loss: 1.386302005648613\n",
      "trial: 2, iter: 14000, curr loss: 1.3862344026565552, avg loss: 1.386296438574791\n",
      "trial: 2, iter: 14200, curr loss: 1.3862714767456055, avg loss: 1.3863118982315064\n",
      "trial: 2, iter: 14400, curr loss: 1.386199712753296, avg loss: 1.3862936317920684\n",
      "trial: 2, iter: 14600, curr loss: 1.3862605094909668, avg loss: 1.386297226548195\n",
      "trial: 2, iter: 14800, curr loss: 1.386224389076233, avg loss: 1.386295691728592\n",
      "trial: 2, iter: 15000, curr loss: 1.3862943649291992, avg loss: 1.386291868686676\n",
      "trial: 2, iter: 15200, curr loss: 1.3862468004226685, avg loss: 1.3862962889671326\n",
      "trial: 2, iter: 15400, curr loss: 1.3863002061843872, avg loss: 1.386294790506363\n",
      "trial: 2, iter: 15600, curr loss: 1.3862942457199097, avg loss: 1.3862950587272644\n",
      "trial: 2, ldr: -5.427659743872937e-06\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.38633394241333, avg loss: 1.3875687968730928\n",
      "trial: 3, iter: 400, curr loss: 1.3849899768829346, avg loss: 1.3865471029281615\n",
      "trial: 3, iter: 600, curr loss: 1.3881226778030396, avg loss: 1.3866262316703797\n",
      "trial: 3, iter: 800, curr loss: 1.3850287199020386, avg loss: 1.3865835601091385\n",
      "trial: 3, iter: 1000, curr loss: 1.3855476379394531, avg loss: 1.3864636129140855\n",
      "trial: 3, iter: 1200, curr loss: 1.3868820667266846, avg loss: 1.3865086483955382\n",
      "trial: 3, iter: 1400, curr loss: 1.3864861726760864, avg loss: 1.3864353024959564\n",
      "trial: 3, iter: 1600, curr loss: 1.3875356912612915, avg loss: 1.3864759832620621\n",
      "trial: 3, iter: 1800, curr loss: 1.3859857320785522, avg loss: 1.3864959037303926\n",
      "trial: 3, iter: 2000, curr loss: 1.3862149715423584, avg loss: 1.3863954192399979\n",
      "trial: 3, iter: 2200, curr loss: 1.3854740858078003, avg loss: 1.386336439847946\n",
      "trial: 3, iter: 2400, curr loss: 1.386569619178772, avg loss: 1.3863866168260575\n",
      "trial: 3, iter: 2600, curr loss: 1.386674404144287, avg loss: 1.3863980150222779\n",
      "trial: 3, iter: 2800, curr loss: 1.3863238096237183, avg loss: 1.3863648772239685\n",
      "trial: 3, iter: 3000, curr loss: 1.386952519416809, avg loss: 1.3862882518768311\n",
      "trial: 3, iter: 3200, curr loss: 1.3859126567840576, avg loss: 1.3864034396409988\n",
      "trial: 3, iter: 3400, curr loss: 1.3873777389526367, avg loss: 1.3863498067855835\n",
      "trial: 3, iter: 3600, curr loss: 1.3857760429382324, avg loss: 1.3863659387826919\n",
      "trial: 3, iter: 3800, curr loss: 1.3859834671020508, avg loss: 1.3863687372207643\n",
      "trial: 3, iter: 4000, curr loss: 1.3861943483352661, avg loss: 1.386323127746582\n",
      "trial: 3, iter: 4200, curr loss: 1.385949969291687, avg loss: 1.3863607716560364\n",
      "trial: 3, iter: 4400, curr loss: 1.3851715326309204, avg loss: 1.3863865888118745\n",
      "trial: 3, iter: 4600, curr loss: 1.3863227367401123, avg loss: 1.386414921283722\n",
      "trial: 3, iter: 4800, curr loss: 1.3872817754745483, avg loss: 1.3863634836673737\n",
      "trial: 3, iter: 5000, curr loss: 1.3854690790176392, avg loss: 1.3864144974946975\n",
      "trial: 3, iter: 5200, curr loss: 1.385542631149292, avg loss: 1.386297668814659\n",
      "trial: 3, iter: 5400, curr loss: 1.38717520236969, avg loss: 1.38637388586998\n",
      "trial: 3, iter: 5600, curr loss: 1.3861178159713745, avg loss: 1.386315940618515\n",
      "trial: 3, iter: 5800, curr loss: 1.3862463235855103, avg loss: 1.386355949640274\n",
      "trial: 3, iter: 6000, curr loss: 1.387141466140747, avg loss: 1.3862872356176377\n",
      "trial: 3, iter: 6200, curr loss: 1.386067509651184, avg loss: 1.3863262951374054\n",
      "trial: 3, iter: 6400, curr loss: 1.3861243724822998, avg loss: 1.3863186579942703\n",
      "trial: 3, iter: 6600, curr loss: 1.3863478899002075, avg loss: 1.3863421010971069\n",
      "trial: 3, iter: 6800, curr loss: 1.386987566947937, avg loss: 1.386315283179283\n",
      "trial: 3, iter: 7000, curr loss: 1.3857676982879639, avg loss: 1.3863181138038636\n",
      "trial: 3, iter: 7200, curr loss: 1.3866685628890991, avg loss: 1.3863407808542252\n",
      "trial: 3, iter: 7400, curr loss: 1.386423110961914, avg loss: 1.386305341720581\n",
      "trial: 3, iter: 7600, curr loss: 1.386265516281128, avg loss: 1.3862996536493302\n",
      "trial: 3, iter: 7800, curr loss: 1.3866926431655884, avg loss: 1.3863497215509415\n",
      "trial: 3, iter: 8000, curr loss: 1.3868449926376343, avg loss: 1.3863164627552031\n",
      "trial: 3, iter: 8200, curr loss: 1.386329174041748, avg loss: 1.386351103782654\n",
      "trial: 3, iter: 8400, curr loss: 1.3868327140808105, avg loss: 1.3863352423906325\n",
      "trial: 3, iter: 8600, curr loss: 1.3865230083465576, avg loss: 1.3863552564382553\n",
      "trial: 3, iter: 8800, curr loss: 1.386482834815979, avg loss: 1.3863357591629029\n",
      "trial: 3, iter: 9000, curr loss: 1.3862823247909546, avg loss: 1.3863109570741654\n",
      "trial: 3, iter: 9200, curr loss: 1.3861606121063232, avg loss: 1.3863261014223098\n",
      "trial: 3, iter: 9400, curr loss: 1.3866798877716064, avg loss: 1.3862977367639542\n",
      "trial: 3, iter: 9600, curr loss: 1.3862558603286743, avg loss: 1.3863149774074555\n",
      "trial: 3, iter: 9800, curr loss: 1.3862543106079102, avg loss: 1.3862928599119186\n",
      "trial: 3, iter: 10000, curr loss: 1.3861560821533203, avg loss: 1.3862900018692017\n",
      "trial: 3, iter: 10200, curr loss: 1.386418342590332, avg loss: 1.386323236823082\n",
      "trial: 3, iter: 10400, curr loss: 1.3866316080093384, avg loss: 1.3862981843948363\n",
      "trial: 3, iter: 10600, curr loss: 1.3858381509780884, avg loss: 1.38631986618042\n",
      "trial: 3, iter: 10800, curr loss: 1.3864611387252808, avg loss: 1.386342539191246\n",
      "trial: 3, iter: 11000, curr loss: 1.3868591785430908, avg loss: 1.3863021451234818\n",
      "trial: 3, iter: 11200, curr loss: 1.3857091665267944, avg loss: 1.3862871116399764\n",
      "trial: 3, iter: 11400, curr loss: 1.3863903284072876, avg loss: 1.3863042044639586\n",
      "trial: 3, iter: 11600, curr loss: 1.3862205743789673, avg loss: 1.386341946721077\n",
      "trial: 3, iter: 11800, curr loss: 1.3863520622253418, avg loss: 1.3863210374116897\n",
      "trial: 3, iter: 12000, curr loss: 1.385792851448059, avg loss: 1.3862711000442505\n",
      "trial: 3, iter: 12200, curr loss: 1.3863431215286255, avg loss: 1.3863388246297836\n",
      "trial: 3, iter: 12400, curr loss: 1.3861877918243408, avg loss: 1.3863085198402405\n",
      "trial: 3, iter: 12600, curr loss: 1.3862566947937012, avg loss: 1.3863077974319458\n",
      "trial: 3, iter: 12800, curr loss: 1.3861783742904663, avg loss: 1.3863065367937089\n",
      "trial: 3, iter: 13000, curr loss: 1.386212944984436, avg loss: 1.3863024121522904\n",
      "trial: 3, iter: 13200, curr loss: 1.3860448598861694, avg loss: 1.3863157385587692\n",
      "trial: 3, iter: 13400, curr loss: 1.3867177963256836, avg loss: 1.3862890815734863\n",
      "trial: 3, iter: 13600, curr loss: 1.3858710527420044, avg loss: 1.3862910968065263\n",
      "trial: 3, iter: 13800, curr loss: 1.386834979057312, avg loss: 1.3863032257556915\n",
      "trial: 3, iter: 14000, curr loss: 1.3860787153244019, avg loss: 1.3862708604335785\n",
      "trial: 3, iter: 14200, curr loss: 1.3862184286117554, avg loss: 1.3863122779130936\n",
      "trial: 3, iter: 14400, curr loss: 1.386297345161438, avg loss: 1.386308292746544\n",
      "trial: 3, iter: 14600, curr loss: 1.3863458633422852, avg loss: 1.3862943363189697\n",
      "trial: 3, iter: 14800, curr loss: 1.3863033056259155, avg loss: 1.3862992399930953\n",
      "trial: 3, iter: 15000, curr loss: 1.3862745761871338, avg loss: 1.3862995517253875\n",
      "trial: 3, iter: 15200, curr loss: 1.3862853050231934, avg loss: 1.3862899947166443\n",
      "trial: 3, iter: 15400, curr loss: 1.3862003087997437, avg loss: 1.386295308470726\n",
      "trial: 3, iter: 15600, curr loss: 1.3863095045089722, avg loss: 1.3863078689575195\n",
      "trial: 3, ldr: -8.493682980770245e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3879708051681519, avg loss: 1.3873354172706605\n",
      "trial: 4, iter: 400, curr loss: 1.3869221210479736, avg loss: 1.3867983907461165\n",
      "trial: 4, iter: 600, curr loss: 1.3870282173156738, avg loss: 1.386522931456566\n",
      "trial: 4, iter: 800, curr loss: 1.3847841024398804, avg loss: 1.386543419957161\n",
      "trial: 4, iter: 1000, curr loss: 1.3863378763198853, avg loss: 1.3865506464242936\n",
      "trial: 4, iter: 1200, curr loss: 1.3863192796707153, avg loss: 1.3865451276302339\n",
      "trial: 4, iter: 1400, curr loss: 1.3869311809539795, avg loss: 1.3865401118993759\n",
      "trial: 4, iter: 1600, curr loss: 1.3845109939575195, avg loss: 1.3863964599370957\n",
      "trial: 4, iter: 1800, curr loss: 1.3857918977737427, avg loss: 1.3863960522413254\n",
      "trial: 4, iter: 2000, curr loss: 1.3862042427062988, avg loss: 1.3863957142829895\n",
      "trial: 4, iter: 2200, curr loss: 1.3861628770828247, avg loss: 1.3864638477563858\n",
      "trial: 4, iter: 2400, curr loss: 1.3857080936431885, avg loss: 1.3863220453262328\n",
      "trial: 4, iter: 2600, curr loss: 1.3877968788146973, avg loss: 1.3864467638731002\n",
      "trial: 4, iter: 2800, curr loss: 1.387352466583252, avg loss: 1.3863735419511796\n",
      "trial: 4, iter: 3000, curr loss: 1.3872694969177246, avg loss: 1.3863435554504395\n",
      "trial: 4, iter: 3200, curr loss: 1.386275053024292, avg loss: 1.3863765293359755\n",
      "trial: 4, iter: 3400, curr loss: 1.385941743850708, avg loss: 1.3863612473011018\n",
      "trial: 4, iter: 3600, curr loss: 1.3852919340133667, avg loss: 1.386295909881592\n",
      "trial: 4, iter: 3800, curr loss: 1.3865652084350586, avg loss: 1.3863198953866958\n",
      "trial: 4, iter: 4000, curr loss: 1.3864271640777588, avg loss: 1.3863343226909637\n",
      "trial: 4, iter: 4200, curr loss: 1.3856362104415894, avg loss: 1.3863240426778793\n",
      "trial: 4, iter: 4400, curr loss: 1.386685848236084, avg loss: 1.3863956260681152\n",
      "trial: 4, iter: 4600, curr loss: 1.3861628770828247, avg loss: 1.3862614798545838\n",
      "trial: 4, iter: 4800, curr loss: 1.3858088254928589, avg loss: 1.3863293653726578\n",
      "trial: 4, iter: 5000, curr loss: 1.3867894411087036, avg loss: 1.3863240015506744\n",
      "trial: 4, iter: 5200, curr loss: 1.3859378099441528, avg loss: 1.3863291764259338\n",
      "trial: 4, iter: 5400, curr loss: 1.3855987787246704, avg loss: 1.386297636628151\n",
      "trial: 4, iter: 5600, curr loss: 1.3861209154129028, avg loss: 1.386363839507103\n",
      "trial: 4, iter: 5800, curr loss: 1.386401653289795, avg loss: 1.386352880001068\n",
      "trial: 4, iter: 6000, curr loss: 1.386190414428711, avg loss: 1.3863308316469192\n",
      "trial: 4, iter: 6200, curr loss: 1.3861721754074097, avg loss: 1.386292612552643\n",
      "trial: 4, iter: 6400, curr loss: 1.386201024055481, avg loss: 1.3863190633058549\n",
      "trial: 4, iter: 6600, curr loss: 1.3862643241882324, avg loss: 1.386320879459381\n",
      "trial: 4, iter: 6800, curr loss: 1.3858728408813477, avg loss: 1.3862989223003388\n",
      "trial: 4, iter: 7000, curr loss: 1.3863502740859985, avg loss: 1.3862991005182266\n",
      "trial: 4, iter: 7200, curr loss: 1.386327862739563, avg loss: 1.3863174730539323\n",
      "trial: 4, iter: 7400, curr loss: 1.3858840465545654, avg loss: 1.3862572801113129\n",
      "trial: 4, iter: 7600, curr loss: 1.3862167596817017, avg loss: 1.3863108938932418\n",
      "trial: 4, iter: 7800, curr loss: 1.3863189220428467, avg loss: 1.3863096356391906\n",
      "trial: 4, iter: 8000, curr loss: 1.3862504959106445, avg loss: 1.386290447115898\n",
      "trial: 4, iter: 8200, curr loss: 1.3862910270690918, avg loss: 1.386309729218483\n",
      "trial: 4, iter: 8400, curr loss: 1.3862887620925903, avg loss: 1.3863019728660584\n",
      "trial: 4, iter: 8600, curr loss: 1.3863131999969482, avg loss: 1.3862992531061173\n",
      "trial: 4, iter: 8800, curr loss: 1.3863117694854736, avg loss: 1.3862933498620986\n",
      "trial: 4, iter: 9000, curr loss: 1.385927438735962, avg loss: 1.3862949687242507\n",
      "trial: 4, iter: 9200, curr loss: 1.3859623670578003, avg loss: 1.3863205194473267\n",
      "trial: 4, iter: 9400, curr loss: 1.3862148523330688, avg loss: 1.3863196885585785\n",
      "trial: 4, iter: 9600, curr loss: 1.3866257667541504, avg loss: 1.3862863337993623\n",
      "trial: 4, iter: 9800, curr loss: 1.3862395286560059, avg loss: 1.386300706267357\n",
      "trial: 4, iter: 10000, curr loss: 1.3865013122558594, avg loss: 1.3862928366661071\n",
      "trial: 4, iter: 10200, curr loss: 1.3862903118133545, avg loss: 1.3863091772794724\n",
      "trial: 4, iter: 10400, curr loss: 1.3861494064331055, avg loss: 1.386285440325737\n",
      "trial: 4, iter: 10600, curr loss: 1.3861994743347168, avg loss: 1.3863023221492767\n",
      "trial: 4, iter: 10800, curr loss: 1.3862515687942505, avg loss: 1.386320184469223\n",
      "trial: 4, iter: 11000, curr loss: 1.386122465133667, avg loss: 1.3863393920660019\n",
      "trial: 4, iter: 11200, curr loss: 1.3860281705856323, avg loss: 1.3863179624080657\n",
      "trial: 4, iter: 11400, curr loss: 1.386297583580017, avg loss: 1.3863621455430986\n",
      "trial: 4, iter: 11600, curr loss: 1.3859206438064575, avg loss: 1.3862960064411163\n",
      "trial: 4, iter: 11800, curr loss: 1.3864445686340332, avg loss: 1.3863195246458053\n",
      "trial: 4, iter: 12000, curr loss: 1.386256456375122, avg loss: 1.3863012278079987\n",
      "trial: 4, iter: 12200, curr loss: 1.3864433765411377, avg loss: 1.3862963891029358\n",
      "trial: 4, iter: 12400, curr loss: 1.3863872289657593, avg loss: 1.3863088977336884\n",
      "trial: 4, iter: 12600, curr loss: 1.3862508535385132, avg loss: 1.386304412484169\n",
      "trial: 4, iter: 12800, curr loss: 1.3862388134002686, avg loss: 1.3862849533557893\n",
      "trial: 4, iter: 13000, curr loss: 1.3862943649291992, avg loss: 1.386310784816742\n",
      "trial: 4, iter: 13200, curr loss: 1.386445164680481, avg loss: 1.3862977886199952\n",
      "trial: 4, iter: 13400, curr loss: 1.386379599571228, avg loss: 1.3862986129522323\n",
      "trial: 4, iter: 13600, curr loss: 1.38650643825531, avg loss: 1.3862956553697585\n",
      "trial: 4, iter: 13800, curr loss: 1.386308193206787, avg loss: 1.386319659948349\n",
      "trial: 4, iter: 14000, curr loss: 1.386478304862976, avg loss: 1.3863040596246718\n",
      "trial: 4, iter: 14200, curr loss: 1.386359453201294, avg loss: 1.3863133031129837\n",
      "trial: 4, iter: 14400, curr loss: 1.386263370513916, avg loss: 1.386294138431549\n",
      "trial: 4, iter: 14600, curr loss: 1.3861756324768066, avg loss: 1.3862821495532989\n",
      "trial: 4, iter: 14800, curr loss: 1.3863292932510376, avg loss: 1.3863196349143982\n",
      "trial: 4, iter: 15000, curr loss: 1.3862788677215576, avg loss: 1.3862979978322982\n",
      "trial: 4, iter: 15200, curr loss: 1.3862594366073608, avg loss: 1.3862932687997818\n",
      "trial: 4, iter: 15400, curr loss: 1.3867952823638916, avg loss: 1.386265589594841\n",
      "trial: 4, iter: 15600, curr loss: 1.3861610889434814, avg loss: 1.3863304495811462\n",
      "trial: 4, ldr: 0.006006308365613222\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3879616260528564, avg loss: 1.3872657078504562\n",
      "trial: 5, iter: 400, curr loss: 1.3863029479980469, avg loss: 1.386573812365532\n",
      "trial: 5, iter: 600, curr loss: 1.3858251571655273, avg loss: 1.3865187710523605\n",
      "trial: 5, iter: 800, curr loss: 1.3871159553527832, avg loss: 1.3865094923973083\n",
      "trial: 5, iter: 1000, curr loss: 1.3879680633544922, avg loss: 1.3865850287675858\n",
      "trial: 5, iter: 1200, curr loss: 1.3872860670089722, avg loss: 1.3864135479927062\n",
      "trial: 5, iter: 1400, curr loss: 1.3860962390899658, avg loss: 1.3864346963167191\n",
      "trial: 5, iter: 1600, curr loss: 1.3868846893310547, avg loss: 1.386413558125496\n",
      "trial: 5, iter: 1800, curr loss: 1.386032223701477, avg loss: 1.3863422709703446\n",
      "trial: 5, iter: 2000, curr loss: 1.3861578702926636, avg loss: 1.3864087963104248\n",
      "trial: 5, iter: 2200, curr loss: 1.3867534399032593, avg loss: 1.3864437824487685\n",
      "trial: 5, iter: 2400, curr loss: 1.3872900009155273, avg loss: 1.3864282864332198\n",
      "trial: 5, iter: 2600, curr loss: 1.385738492012024, avg loss: 1.386416301727295\n",
      "trial: 5, iter: 2800, curr loss: 1.3863680362701416, avg loss: 1.3864155173301698\n",
      "trial: 5, iter: 3000, curr loss: 1.3878120183944702, avg loss: 1.3863261753320695\n",
      "trial: 5, iter: 3200, curr loss: 1.38607919216156, avg loss: 1.3864302068948746\n",
      "trial: 5, iter: 3400, curr loss: 1.3868484497070312, avg loss: 1.3863824236392974\n",
      "trial: 5, iter: 3600, curr loss: 1.3863472938537598, avg loss: 1.3863283723592759\n",
      "trial: 5, iter: 3800, curr loss: 1.3862935304641724, avg loss: 1.3863982993364334\n",
      "trial: 5, iter: 4000, curr loss: 1.3871593475341797, avg loss: 1.3863396847248077\n",
      "trial: 5, iter: 4200, curr loss: 1.3868342638015747, avg loss: 1.3863666170835496\n",
      "trial: 5, iter: 4400, curr loss: 1.386502742767334, avg loss: 1.3863143157958984\n",
      "trial: 5, iter: 4600, curr loss: 1.386501431465149, avg loss: 1.386300999522209\n",
      "trial: 5, iter: 4800, curr loss: 1.3868905305862427, avg loss: 1.3863435363769532\n",
      "trial: 5, iter: 5000, curr loss: 1.3861852884292603, avg loss: 1.3863469052314759\n",
      "trial: 5, iter: 5200, curr loss: 1.3863672018051147, avg loss: 1.3862711197137834\n",
      "trial: 5, iter: 5400, curr loss: 1.3862524032592773, avg loss: 1.386390677690506\n",
      "trial: 5, iter: 5600, curr loss: 1.3863334655761719, avg loss: 1.386308177113533\n",
      "trial: 5, iter: 5800, curr loss: 1.3863955736160278, avg loss: 1.3863195008039475\n",
      "trial: 5, iter: 6000, curr loss: 1.3863087892532349, avg loss: 1.3862514996528625\n",
      "trial: 5, iter: 6200, curr loss: 1.3860000371932983, avg loss: 1.3863516968488694\n",
      "trial: 5, iter: 6400, curr loss: 1.3861521482467651, avg loss: 1.3863402646780014\n",
      "trial: 5, iter: 6600, curr loss: 1.386525273323059, avg loss: 1.3863038915395736\n",
      "trial: 5, iter: 6800, curr loss: 1.38637113571167, avg loss: 1.3863204872608186\n",
      "trial: 5, iter: 7000, curr loss: 1.3861814737319946, avg loss: 1.3862938809394836\n",
      "trial: 5, iter: 7200, curr loss: 1.386242151260376, avg loss: 1.3863132125139237\n",
      "trial: 5, iter: 7400, curr loss: 1.3865536451339722, avg loss: 1.3863082760572434\n",
      "trial: 5, iter: 7600, curr loss: 1.38639235496521, avg loss: 1.386311507821083\n",
      "trial: 5, iter: 7800, curr loss: 1.386428713798523, avg loss: 1.3863018161058427\n",
      "trial: 5, iter: 8000, curr loss: 1.3862578868865967, avg loss: 1.3863160341978074\n",
      "trial: 5, iter: 8200, curr loss: 1.3861503601074219, avg loss: 1.3862984412908554\n",
      "trial: 5, iter: 8400, curr loss: 1.3865505456924438, avg loss: 1.3862707757949828\n",
      "trial: 5, iter: 8600, curr loss: 1.3874386548995972, avg loss: 1.3863095921278\n",
      "trial: 5, iter: 8800, curr loss: 1.386373519897461, avg loss: 1.3863139098882675\n",
      "trial: 5, iter: 9000, curr loss: 1.386049509048462, avg loss: 1.3862836873531341\n",
      "trial: 5, iter: 9200, curr loss: 1.386464238166809, avg loss: 1.386308375597\n",
      "trial: 5, iter: 9400, curr loss: 1.3862693309783936, avg loss: 1.3863021749258042\n",
      "trial: 5, iter: 9600, curr loss: 1.3862677812576294, avg loss: 1.386304202079773\n",
      "trial: 5, iter: 9800, curr loss: 1.3862955570220947, avg loss: 1.3862968915700913\n",
      "trial: 5, iter: 10000, curr loss: 1.386289358139038, avg loss: 1.386295296549797\n",
      "trial: 5, iter: 10200, curr loss: 1.3862918615341187, avg loss: 1.3862999039888382\n",
      "trial: 5, iter: 10400, curr loss: 1.3862122297286987, avg loss: 1.3862936037778855\n",
      "trial: 5, iter: 10600, curr loss: 1.3863117694854736, avg loss: 1.3863028985261918\n",
      "trial: 5, iter: 10800, curr loss: 1.3855723142623901, avg loss: 1.3862968134880065\n",
      "trial: 5, iter: 11000, curr loss: 1.3859734535217285, avg loss: 1.3863571429252624\n",
      "trial: 5, iter: 11200, curr loss: 1.386335849761963, avg loss: 1.3863279116153717\n",
      "trial: 5, iter: 11400, curr loss: 1.3863290548324585, avg loss: 1.3863078927993775\n",
      "trial: 5, iter: 11600, curr loss: 1.386306881904602, avg loss: 1.3862978678941726\n",
      "trial: 5, iter: 11800, curr loss: 1.3862711191177368, avg loss: 1.386300654411316\n",
      "trial: 5, iter: 12000, curr loss: 1.3862550258636475, avg loss: 1.3862964153289794\n",
      "trial: 5, iter: 12200, curr loss: 1.386405348777771, avg loss: 1.3862972724437714\n",
      "trial: 5, iter: 12400, curr loss: 1.3863071203231812, avg loss: 1.3862961626052857\n",
      "trial: 5, iter: 12600, curr loss: 1.3862855434417725, avg loss: 1.3862973493337631\n",
      "trial: 5, iter: 12800, curr loss: 1.3863599300384521, avg loss: 1.3862955218553543\n",
      "trial: 5, iter: 13000, curr loss: 1.386283278465271, avg loss: 1.3862993019819259\n",
      "trial: 5, iter: 13200, curr loss: 1.3865171670913696, avg loss: 1.3862896567583085\n",
      "trial: 5, iter: 13400, curr loss: 1.386252522468567, avg loss: 1.3863061982393265\n",
      "trial: 5, iter: 13600, curr loss: 1.3863991498947144, avg loss: 1.386281790137291\n",
      "trial: 5, iter: 13800, curr loss: 1.3863475322723389, avg loss: 1.3862929832935333\n",
      "trial: 5, iter: 14000, curr loss: 1.3862855434417725, avg loss: 1.3863062059879303\n",
      "trial: 5, iter: 14200, curr loss: 1.3865580558776855, avg loss: 1.386306767463684\n",
      "trial: 5, iter: 14400, curr loss: 1.386309266090393, avg loss: 1.3862974631786347\n",
      "trial: 5, iter: 14600, curr loss: 1.3862476348876953, avg loss: 1.3863012605905534\n",
      "trial: 5, iter: 14800, curr loss: 1.386284589767456, avg loss: 1.3862968069314956\n",
      "trial: 5, iter: 15000, curr loss: 1.3863003253936768, avg loss: 1.3862964391708374\n",
      "trial: 5, iter: 15200, curr loss: 1.3863000869750977, avg loss: 1.386295167207718\n",
      "trial: 5, iter: 15400, curr loss: 1.386263370513916, avg loss: 1.386292820572853\n",
      "trial: 5, iter: 15600, curr loss: 1.3859822750091553, avg loss: 1.3862951850891114\n",
      "trial: 5, ldr: -0.00019568120478652418\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0010018888207923738\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3886817693710327, avg loss: 1.3872177702188493\n",
      "trial: 1, iter: 400, curr loss: 1.3877644538879395, avg loss: 1.3870275396108627\n",
      "trial: 1, iter: 600, curr loss: 1.3854422569274902, avg loss: 1.3865606611967087\n",
      "trial: 1, iter: 800, curr loss: 1.3870856761932373, avg loss: 1.3866070306301117\n",
      "trial: 1, iter: 1000, curr loss: 1.386611819267273, avg loss: 1.3865162605047225\n",
      "trial: 1, iter: 1200, curr loss: 1.38789701461792, avg loss: 1.3865392583608627\n",
      "trial: 1, iter: 1400, curr loss: 1.3884861469268799, avg loss: 1.3865360182523727\n",
      "trial: 1, iter: 1600, curr loss: 1.3865705728530884, avg loss: 1.3863826942443849\n",
      "trial: 1, iter: 1800, curr loss: 1.3862249851226807, avg loss: 1.3864624100923537\n",
      "trial: 1, iter: 2000, curr loss: 1.3868398666381836, avg loss: 1.3863512873649597\n",
      "trial: 1, iter: 2200, curr loss: 1.3841750621795654, avg loss: 1.3864029544591903\n",
      "trial: 1, iter: 2400, curr loss: 1.386207103729248, avg loss: 1.3863336950540543\n",
      "trial: 1, iter: 2600, curr loss: 1.3867264986038208, avg loss: 1.3864475470781326\n",
      "trial: 1, iter: 2800, curr loss: 1.387376070022583, avg loss: 1.386376929283142\n",
      "trial: 1, iter: 3000, curr loss: 1.3861839771270752, avg loss: 1.3863266372680665\n",
      "trial: 1, iter: 3200, curr loss: 1.3865071535110474, avg loss: 1.3863173818588257\n",
      "trial: 1, iter: 3400, curr loss: 1.3858519792556763, avg loss: 1.3863153964281083\n",
      "trial: 1, iter: 3600, curr loss: 1.3866599798202515, avg loss: 1.3864006352424623\n",
      "trial: 1, iter: 3800, curr loss: 1.3861618041992188, avg loss: 1.3863619101047515\n",
      "trial: 1, iter: 4000, curr loss: 1.3843410015106201, avg loss: 1.3863143849372863\n",
      "trial: 1, iter: 4200, curr loss: 1.386246919631958, avg loss: 1.3864445704221726\n",
      "trial: 1, iter: 4400, curr loss: 1.386509656906128, avg loss: 1.3862937915325164\n",
      "trial: 1, iter: 4600, curr loss: 1.3867558240890503, avg loss: 1.3863280183076858\n",
      "trial: 1, iter: 4800, curr loss: 1.3863961696624756, avg loss: 1.3863370925188065\n",
      "trial: 1, iter: 5000, curr loss: 1.3862508535385132, avg loss: 1.386309734582901\n",
      "trial: 1, iter: 5200, curr loss: 1.386085033416748, avg loss: 1.3863048720359803\n",
      "trial: 1, iter: 5400, curr loss: 1.3866318464279175, avg loss: 1.3863065218925477\n",
      "trial: 1, iter: 5600, curr loss: 1.3863195180892944, avg loss: 1.3863012403249741\n",
      "trial: 1, iter: 5800, curr loss: 1.386205792427063, avg loss: 1.3863182950019837\n",
      "trial: 1, iter: 6000, curr loss: 1.3863283395767212, avg loss: 1.3863096356391906\n",
      "trial: 1, iter: 6200, curr loss: 1.3862968683242798, avg loss: 1.3863000786304474\n",
      "trial: 1, iter: 6400, curr loss: 1.3863211870193481, avg loss: 1.3863059544563294\n",
      "trial: 1, iter: 6600, curr loss: 1.3859310150146484, avg loss: 1.3862838804721833\n",
      "trial: 1, iter: 6800, curr loss: 1.3860887289047241, avg loss: 1.3862562668323517\n",
      "trial: 1, iter: 7000, curr loss: 1.3862487077713013, avg loss: 1.3863262861967087\n",
      "trial: 1, iter: 7200, curr loss: 1.3862452507019043, avg loss: 1.38629047870636\n",
      "trial: 1, iter: 7400, curr loss: 1.3862699270248413, avg loss: 1.3863014853000641\n",
      "trial: 1, iter: 7600, curr loss: 1.3862130641937256, avg loss: 1.3862923043966293\n",
      "trial: 1, iter: 7800, curr loss: 1.3862910270690918, avg loss: 1.3862998169660568\n",
      "trial: 1, iter: 8000, curr loss: 1.3860727548599243, avg loss: 1.3862716203927994\n",
      "trial: 1, iter: 8200, curr loss: 1.38633131980896, avg loss: 1.3863077187538146\n",
      "trial: 1, iter: 8400, curr loss: 1.3861949443817139, avg loss: 1.3862974792718887\n",
      "trial: 1, iter: 8600, curr loss: 1.3865147829055786, avg loss: 1.3862989753484727\n",
      "trial: 1, iter: 8800, curr loss: 1.3858789205551147, avg loss: 1.386266598701477\n",
      "trial: 1, iter: 9000, curr loss: 1.3867145776748657, avg loss: 1.3863066387176515\n",
      "trial: 1, iter: 9200, curr loss: 1.3862395286560059, avg loss: 1.386310641169548\n",
      "trial: 1, iter: 9400, curr loss: 1.3862942457199097, avg loss: 1.3862978410720825\n",
      "trial: 1, iter: 9600, curr loss: 1.3862943649291992, avg loss: 1.3862951451539993\n",
      "trial: 1, iter: 9800, curr loss: 1.3862941265106201, avg loss: 1.386293573975563\n",
      "trial: 1, iter: 10000, curr loss: 1.3862946033477783, avg loss: 1.3862932634353637\n",
      "trial: 1, iter: 10200, curr loss: 1.3862944841384888, avg loss: 1.3863024395704269\n",
      "trial: 1, iter: 10400, curr loss: 1.3862959146499634, avg loss: 1.3862951320409775\n",
      "trial: 1, iter: 10600, curr loss: 1.3862942457199097, avg loss: 1.3862942498922348\n",
      "trial: 1, iter: 10800, curr loss: 1.3862944841384888, avg loss: 1.3862934124469757\n",
      "trial: 1, iter: 11000, curr loss: 1.386276364326477, avg loss: 1.38628892660141\n",
      "trial: 1, iter: 11200, curr loss: 1.3862864971160889, avg loss: 1.3862970823049545\n",
      "trial: 1, iter: 11400, curr loss: 1.3862941265106201, avg loss: 1.3862877094745636\n",
      "trial: 1, iter: 11600, curr loss: 1.386308193206787, avg loss: 1.3863144838809967\n",
      "trial: 1, iter: 11800, curr loss: 1.3862944841384888, avg loss: 1.3862940472364427\n",
      "trial: 1, iter: 12000, curr loss: 1.3862944841384888, avg loss: 1.386296266913414\n",
      "trial: 1, iter: 12200, curr loss: 1.3862948417663574, avg loss: 1.386291063427925\n",
      "trial: 1, iter: 12400, curr loss: 1.3862944841384888, avg loss: 1.3862906223535538\n",
      "trial: 1, iter: 12600, curr loss: 1.3862944841384888, avg loss: 1.3862989658117295\n",
      "trial: 1, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.386294772028923\n",
      "trial: 1, iter: 13000, curr loss: 1.3862943649291992, avg loss: 1.3863023591041566\n",
      "trial: 1, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.3862945103645326\n",
      "trial: 1, iter: 13400, curr loss: 1.3862947225570679, avg loss: 1.386294919848442\n",
      "trial: 1, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.3862949073314668\n",
      "trial: 1, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 14000, curr loss: 1.3862946033477783, avg loss: 1.386294949054718\n",
      "trial: 1, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.3862949424982072\n",
      "trial: 1, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.3862949603796004\n",
      "trial: 1, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.3862949526309967\n",
      "trial: 1, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.3862949234247208\n",
      "trial: 1, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862949442863464\n",
      "trial: 1, ldr: 1.1920928244535389e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3857345581054688, avg loss: 1.3873758172988893\n",
      "trial: 2, iter: 400, curr loss: 1.3827778100967407, avg loss: 1.386609456539154\n",
      "trial: 2, iter: 600, curr loss: 1.3873828649520874, avg loss: 1.3867203724384307\n",
      "trial: 2, iter: 800, curr loss: 1.3867641687393188, avg loss: 1.3865221136808394\n",
      "trial: 2, iter: 1000, curr loss: 1.3865185976028442, avg loss: 1.3864316934347152\n",
      "trial: 2, iter: 1200, curr loss: 1.3857725858688354, avg loss: 1.3864198845624924\n",
      "trial: 2, iter: 1400, curr loss: 1.3872690200805664, avg loss: 1.3864090728759766\n",
      "trial: 2, iter: 1600, curr loss: 1.3854972124099731, avg loss: 1.3864200979471206\n",
      "trial: 2, iter: 1800, curr loss: 1.3850942850112915, avg loss: 1.3863733047246933\n",
      "trial: 2, iter: 2000, curr loss: 1.386820673942566, avg loss: 1.386448668241501\n",
      "trial: 2, iter: 2200, curr loss: 1.3871142864227295, avg loss: 1.3864161652326583\n",
      "trial: 2, iter: 2400, curr loss: 1.3864943981170654, avg loss: 1.386346411705017\n",
      "trial: 2, iter: 2600, curr loss: 1.3850226402282715, avg loss: 1.3864180397987367\n",
      "trial: 2, iter: 2800, curr loss: 1.3885087966918945, avg loss: 1.3863860481977464\n",
      "trial: 2, iter: 3000, curr loss: 1.3867391347885132, avg loss: 1.3863797992467881\n",
      "trial: 2, iter: 3200, curr loss: 1.38618803024292, avg loss: 1.3863802748918532\n",
      "trial: 2, iter: 3400, curr loss: 1.3869802951812744, avg loss: 1.3863989949226379\n",
      "trial: 2, iter: 3600, curr loss: 1.3871300220489502, avg loss: 1.3864016425609589\n",
      "trial: 2, iter: 3800, curr loss: 1.3871265649795532, avg loss: 1.3863212090730668\n",
      "trial: 2, iter: 4000, curr loss: 1.387170433998108, avg loss: 1.3863039618730546\n",
      "trial: 2, iter: 4200, curr loss: 1.3860828876495361, avg loss: 1.3864181679487229\n",
      "trial: 2, iter: 4400, curr loss: 1.3863203525543213, avg loss: 1.386410766839981\n",
      "trial: 2, iter: 4600, curr loss: 1.3863732814788818, avg loss: 1.3862880796194077\n",
      "trial: 2, iter: 4800, curr loss: 1.3861124515533447, avg loss: 1.386363570690155\n",
      "trial: 2, iter: 5000, curr loss: 1.386772632598877, avg loss: 1.3863192903995514\n",
      "trial: 2, iter: 5200, curr loss: 1.3846112489700317, avg loss: 1.3863276994228364\n",
      "trial: 2, iter: 5400, curr loss: 1.3862653970718384, avg loss: 1.3863477766513825\n",
      "trial: 2, iter: 5600, curr loss: 1.3855208158493042, avg loss: 1.3863315534591676\n",
      "trial: 2, iter: 5800, curr loss: 1.3857293128967285, avg loss: 1.3863743871450425\n",
      "trial: 2, iter: 6000, curr loss: 1.3863919973373413, avg loss: 1.3863768619298935\n",
      "trial: 2, iter: 6200, curr loss: 1.3871279954910278, avg loss: 1.3863256603479386\n",
      "trial: 2, iter: 6400, curr loss: 1.3869318962097168, avg loss: 1.3863638401031495\n",
      "trial: 2, iter: 6600, curr loss: 1.3861074447631836, avg loss: 1.3863273453712464\n",
      "trial: 2, iter: 6800, curr loss: 1.3872309923171997, avg loss: 1.3862994664907455\n",
      "trial: 2, iter: 7000, curr loss: 1.386821985244751, avg loss: 1.3863056498765944\n",
      "trial: 2, iter: 7200, curr loss: 1.3862841129302979, avg loss: 1.3863473200798035\n",
      "trial: 2, iter: 7400, curr loss: 1.3866431713104248, avg loss: 1.386291190981865\n",
      "trial: 2, iter: 7600, curr loss: 1.3864951133728027, avg loss: 1.3863246929645539\n",
      "trial: 2, iter: 7800, curr loss: 1.3866312503814697, avg loss: 1.386300128698349\n",
      "trial: 2, iter: 8000, curr loss: 1.3863273859024048, avg loss: 1.3862894213199615\n",
      "trial: 2, iter: 8200, curr loss: 1.385932445526123, avg loss: 1.38630739569664\n",
      "trial: 2, iter: 8400, curr loss: 1.3863623142242432, avg loss: 1.386325052380562\n",
      "trial: 2, iter: 8600, curr loss: 1.3861465454101562, avg loss: 1.3863204008340835\n",
      "trial: 2, iter: 8800, curr loss: 1.3862053155899048, avg loss: 1.3863127899169922\n",
      "trial: 2, iter: 9000, curr loss: 1.3862403631210327, avg loss: 1.3863131427764892\n",
      "trial: 2, iter: 9200, curr loss: 1.3865270614624023, avg loss: 1.3863045448064804\n",
      "trial: 2, iter: 9400, curr loss: 1.3865629434585571, avg loss: 1.386308273077011\n",
      "trial: 2, iter: 9600, curr loss: 1.3862730264663696, avg loss: 1.3863123703002929\n",
      "trial: 2, iter: 9800, curr loss: 1.3862018585205078, avg loss: 1.3863077712059022\n",
      "trial: 2, iter: 10000, curr loss: 1.3862290382385254, avg loss: 1.3863049495220183\n",
      "trial: 2, iter: 10200, curr loss: 1.3863580226898193, avg loss: 1.3863005125522614\n",
      "trial: 2, iter: 10400, curr loss: 1.3862953186035156, avg loss: 1.386297367811203\n",
      "trial: 2, iter: 10600, curr loss: 1.3862619400024414, avg loss: 1.3862944984436034\n",
      "trial: 2, iter: 10800, curr loss: 1.3864158391952515, avg loss: 1.3862975972890854\n",
      "trial: 2, iter: 11000, curr loss: 1.3864034414291382, avg loss: 1.386295673251152\n",
      "trial: 2, iter: 11200, curr loss: 1.3866342306137085, avg loss: 1.386276406645775\n",
      "trial: 2, iter: 11400, curr loss: 1.3859797716140747, avg loss: 1.3862942427396774\n",
      "trial: 2, iter: 11600, curr loss: 1.3861632347106934, avg loss: 1.3863238269090652\n",
      "trial: 2, iter: 11800, curr loss: 1.3861870765686035, avg loss: 1.3862975603342056\n",
      "trial: 2, iter: 12000, curr loss: 1.386291265487671, avg loss: 1.386309010386467\n",
      "trial: 2, iter: 12200, curr loss: 1.3862789869308472, avg loss: 1.3862932509183883\n",
      "trial: 2, iter: 12400, curr loss: 1.386215090751648, avg loss: 1.3862991070747375\n",
      "trial: 2, iter: 12600, curr loss: 1.3862926959991455, avg loss: 1.386303614974022\n",
      "trial: 2, iter: 12800, curr loss: 1.3864885568618774, avg loss: 1.386291068792343\n",
      "trial: 2, iter: 13000, curr loss: 1.3866901397705078, avg loss: 1.3862959653139115\n",
      "trial: 2, iter: 13200, curr loss: 1.3865182399749756, avg loss: 1.3862740272283554\n",
      "trial: 2, iter: 13400, curr loss: 1.386404275894165, avg loss: 1.3863135582208634\n",
      "trial: 2, iter: 13600, curr loss: 1.386584997177124, avg loss: 1.386295307278633\n",
      "trial: 2, iter: 13800, curr loss: 1.3863846063613892, avg loss: 1.3863081270456314\n",
      "trial: 2, iter: 14000, curr loss: 1.3862018585205078, avg loss: 1.386323916912079\n",
      "trial: 2, iter: 14200, curr loss: 1.3862295150756836, avg loss: 1.3863063478469848\n",
      "trial: 2, iter: 14400, curr loss: 1.386331558227539, avg loss: 1.386294636130333\n",
      "trial: 2, iter: 14600, curr loss: 1.3862487077713013, avg loss: 1.386299416422844\n",
      "trial: 2, iter: 14800, curr loss: 1.386288046836853, avg loss: 1.3862900751829148\n",
      "trial: 2, iter: 15000, curr loss: 1.3862224817276, avg loss: 1.386296124458313\n",
      "trial: 2, iter: 15200, curr loss: 1.3864933252334595, avg loss: 1.3863374441862106\n",
      "trial: 2, iter: 15400, curr loss: 1.3861058950424194, avg loss: 1.3863117432594299\n",
      "trial: 2, iter: 15600, curr loss: 1.386407494544983, avg loss: 1.3863105165958405\n",
      "trial: 2, ldr: -0.0028146838303655386\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3856806755065918, avg loss: 1.3873089843988418\n",
      "trial: 3, iter: 400, curr loss: 1.3843514919281006, avg loss: 1.3867045837640761\n",
      "trial: 3, iter: 600, curr loss: 1.3867161273956299, avg loss: 1.3865818530321121\n",
      "trial: 3, iter: 800, curr loss: 1.386244773864746, avg loss: 1.3863602954149246\n",
      "trial: 3, iter: 1000, curr loss: 1.387629747390747, avg loss: 1.3866007488965988\n",
      "trial: 3, iter: 1200, curr loss: 1.386273980140686, avg loss: 1.386558843255043\n",
      "trial: 3, iter: 1400, curr loss: 1.3866069316864014, avg loss: 1.386422824859619\n",
      "trial: 3, iter: 1600, curr loss: 1.3876776695251465, avg loss: 1.3863334000110625\n",
      "trial: 3, iter: 1800, curr loss: 1.386613130569458, avg loss: 1.3864260071516037\n",
      "trial: 3, iter: 2000, curr loss: 1.3868184089660645, avg loss: 1.3864411503076552\n",
      "trial: 3, iter: 2200, curr loss: 1.384576439857483, avg loss: 1.3864365005493164\n",
      "trial: 3, iter: 2400, curr loss: 1.3857277631759644, avg loss: 1.3864845085144042\n",
      "trial: 3, iter: 2600, curr loss: 1.3866759538650513, avg loss: 1.3865128564834595\n",
      "trial: 3, iter: 2800, curr loss: 1.3875619173049927, avg loss: 1.3865216708183288\n",
      "trial: 3, iter: 3000, curr loss: 1.3866668939590454, avg loss: 1.3863956475257873\n",
      "trial: 3, iter: 3200, curr loss: 1.3867782354354858, avg loss: 1.3864561939239501\n",
      "trial: 3, iter: 3400, curr loss: 1.3866623640060425, avg loss: 1.3863380396366118\n",
      "trial: 3, iter: 3600, curr loss: 1.386146068572998, avg loss: 1.3864006280899048\n",
      "trial: 3, iter: 3800, curr loss: 1.3867661952972412, avg loss: 1.386316306591034\n",
      "trial: 3, iter: 4000, curr loss: 1.3855900764465332, avg loss: 1.386395657658577\n",
      "trial: 3, iter: 4200, curr loss: 1.3867019414901733, avg loss: 1.3863595628738403\n",
      "trial: 3, iter: 4400, curr loss: 1.3872113227844238, avg loss: 1.3863701629638672\n",
      "trial: 3, iter: 4600, curr loss: 1.3853554725646973, avg loss: 1.3863057452440262\n",
      "trial: 3, iter: 4800, curr loss: 1.3857872486114502, avg loss: 1.386327520608902\n",
      "trial: 3, iter: 5000, curr loss: 1.3845844268798828, avg loss: 1.3863466209173203\n",
      "trial: 3, iter: 5200, curr loss: 1.387169361114502, avg loss: 1.3864031052589416\n",
      "trial: 3, iter: 5400, curr loss: 1.3870874643325806, avg loss: 1.3864258635044098\n",
      "trial: 3, iter: 5600, curr loss: 1.3871489763259888, avg loss: 1.3863509184122085\n",
      "trial: 3, iter: 5800, curr loss: 1.3866758346557617, avg loss: 1.38628246486187\n",
      "trial: 3, iter: 6000, curr loss: 1.3865777254104614, avg loss: 1.3863920122385025\n",
      "trial: 3, iter: 6200, curr loss: 1.3863129615783691, avg loss: 1.3863751167058944\n",
      "trial: 3, iter: 6400, curr loss: 1.386086344718933, avg loss: 1.386332117319107\n",
      "trial: 3, iter: 6600, curr loss: 1.3865376710891724, avg loss: 1.3862992572784423\n",
      "trial: 3, iter: 6800, curr loss: 1.3861932754516602, avg loss: 1.3863349664211273\n",
      "trial: 3, iter: 7000, curr loss: 1.386352300643921, avg loss: 1.386325876712799\n",
      "trial: 3, iter: 7200, curr loss: 1.3865599632263184, avg loss: 1.3862851661443711\n",
      "trial: 3, iter: 7400, curr loss: 1.3862695693969727, avg loss: 1.3863025736808776\n",
      "trial: 3, iter: 7600, curr loss: 1.3863471746444702, avg loss: 1.3863179528713225\n",
      "trial: 3, iter: 7800, curr loss: 1.3856587409973145, avg loss: 1.3863121366500855\n",
      "trial: 3, iter: 8000, curr loss: 1.3861591815948486, avg loss: 1.3863540893793107\n",
      "trial: 3, iter: 8200, curr loss: 1.385547161102295, avg loss: 1.3862833601236344\n",
      "trial: 3, iter: 8400, curr loss: 1.3864036798477173, avg loss: 1.386333142518997\n",
      "trial: 3, iter: 8600, curr loss: 1.3859909772872925, avg loss: 1.3863406813144683\n",
      "trial: 3, iter: 8800, curr loss: 1.3878657817840576, avg loss: 1.3863279634714127\n",
      "trial: 3, iter: 9000, curr loss: 1.385366439819336, avg loss: 1.3863545989990234\n",
      "trial: 3, iter: 9200, curr loss: 1.3867745399475098, avg loss: 1.3863258892297745\n",
      "trial: 3, iter: 9400, curr loss: 1.386263132095337, avg loss: 1.3863196790218353\n",
      "trial: 3, iter: 9600, curr loss: 1.3865458965301514, avg loss: 1.3863072454929353\n",
      "trial: 3, iter: 9800, curr loss: 1.3862882852554321, avg loss: 1.3863122379779815\n",
      "trial: 3, iter: 10000, curr loss: 1.3862987756729126, avg loss: 1.3863014906644822\n",
      "trial: 3, iter: 10200, curr loss: 1.3860316276550293, avg loss: 1.3862988072633744\n",
      "trial: 3, iter: 10400, curr loss: 1.3858662843704224, avg loss: 1.3862887239456176\n",
      "trial: 3, iter: 10600, curr loss: 1.3859951496124268, avg loss: 1.3862647444009781\n",
      "trial: 3, iter: 10800, curr loss: 1.386399745941162, avg loss: 1.3863142681121827\n",
      "trial: 3, iter: 11000, curr loss: 1.3865242004394531, avg loss: 1.3862993282079696\n",
      "trial: 3, iter: 11200, curr loss: 1.3862978219985962, avg loss: 1.3863099807500838\n",
      "trial: 3, iter: 11400, curr loss: 1.3859201669692993, avg loss: 1.3862554371356963\n",
      "trial: 3, iter: 11600, curr loss: 1.3862634897232056, avg loss: 1.386314389705658\n",
      "trial: 3, iter: 11800, curr loss: 1.38619065284729, avg loss: 1.3862916189432144\n",
      "trial: 3, iter: 12000, curr loss: 1.386195421218872, avg loss: 1.3863364464044572\n",
      "trial: 3, iter: 12200, curr loss: 1.3864353895187378, avg loss: 1.3863078701496123\n",
      "trial: 3, iter: 12400, curr loss: 1.386352777481079, avg loss: 1.3863020300865174\n",
      "trial: 3, iter: 12600, curr loss: 1.3863272666931152, avg loss: 1.3863003647327423\n",
      "trial: 3, iter: 12800, curr loss: 1.3861863613128662, avg loss: 1.3862974810600281\n",
      "trial: 3, iter: 13000, curr loss: 1.386254906654358, avg loss: 1.3862889945507049\n",
      "trial: 3, iter: 13200, curr loss: 1.386366844177246, avg loss: 1.3863151329755783\n",
      "trial: 3, iter: 13400, curr loss: 1.3861490488052368, avg loss: 1.3862908881902696\n",
      "trial: 3, iter: 13600, curr loss: 1.3862487077713013, avg loss: 1.3862939077615737\n",
      "trial: 3, iter: 13800, curr loss: 1.3859046697616577, avg loss: 1.386297397017479\n",
      "trial: 3, iter: 14000, curr loss: 1.38642418384552, avg loss: 1.3863176089525222\n",
      "trial: 3, iter: 14200, curr loss: 1.3861982822418213, avg loss: 1.3863003969192504\n",
      "trial: 3, iter: 14400, curr loss: 1.3860305547714233, avg loss: 1.3862957447767257\n",
      "trial: 3, iter: 14600, curr loss: 1.386568546295166, avg loss: 1.3863025403022766\n",
      "trial: 3, iter: 14800, curr loss: 1.3860958814620972, avg loss: 1.3863004207611085\n",
      "trial: 3, iter: 15000, curr loss: 1.3862346410751343, avg loss: 1.3863059186935425\n",
      "trial: 3, iter: 15200, curr loss: 1.3863492012023926, avg loss: 1.386298540830612\n",
      "trial: 3, iter: 15400, curr loss: 1.3862558603286743, avg loss: 1.3862950503826141\n",
      "trial: 3, iter: 15600, curr loss: 1.3862402439117432, avg loss: 1.386295171380043\n",
      "trial: 3, ldr: 0.0006539190653711557\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3872147798538208, avg loss: 1.3874402463436126\n",
      "trial: 4, iter: 400, curr loss: 1.3864606618881226, avg loss: 1.3865421193838119\n",
      "trial: 4, iter: 600, curr loss: 1.3876487016677856, avg loss: 1.3864452034235\n",
      "trial: 4, iter: 800, curr loss: 1.3867119550704956, avg loss: 1.3864467680454253\n",
      "trial: 4, iter: 1000, curr loss: 1.3865634202957153, avg loss: 1.3863846033811569\n",
      "trial: 4, iter: 1200, curr loss: 1.387852430343628, avg loss: 1.3864141660928726\n",
      "trial: 4, iter: 1400, curr loss: 1.3881382942199707, avg loss: 1.3863888436555862\n",
      "trial: 4, iter: 1600, curr loss: 1.3866479396820068, avg loss: 1.3864176893234252\n",
      "trial: 4, iter: 1800, curr loss: 1.3880236148834229, avg loss: 1.3866003185510636\n",
      "trial: 4, iter: 2000, curr loss: 1.3862696886062622, avg loss: 1.3864832592010499\n",
      "trial: 4, iter: 2200, curr loss: 1.386926293373108, avg loss: 1.386426385641098\n",
      "trial: 4, iter: 2400, curr loss: 1.3864842653274536, avg loss: 1.3863693177700043\n",
      "trial: 4, iter: 2600, curr loss: 1.3861724138259888, avg loss: 1.3863420343399049\n",
      "trial: 4, iter: 2800, curr loss: 1.3863111734390259, avg loss: 1.3863046616315842\n",
      "trial: 4, iter: 3000, curr loss: 1.3864377737045288, avg loss: 1.386293134689331\n",
      "trial: 4, iter: 3200, curr loss: 1.3852734565734863, avg loss: 1.3863254684209823\n",
      "trial: 4, iter: 3400, curr loss: 1.3862857818603516, avg loss: 1.3863714456558227\n",
      "trial: 4, iter: 3600, curr loss: 1.3871488571166992, avg loss: 1.3863578099012375\n",
      "trial: 4, iter: 3800, curr loss: 1.3868534564971924, avg loss: 1.3863783591985703\n",
      "trial: 4, iter: 4000, curr loss: 1.3862513303756714, avg loss: 1.3863518023490906\n",
      "trial: 4, iter: 4200, curr loss: 1.3866547346115112, avg loss: 1.3863176023960113\n",
      "trial: 4, iter: 4400, curr loss: 1.3873929977416992, avg loss: 1.386314703822136\n",
      "trial: 4, iter: 4600, curr loss: 1.387740135192871, avg loss: 1.3863782852888107\n",
      "trial: 4, iter: 4800, curr loss: 1.3862297534942627, avg loss: 1.386409081220627\n",
      "trial: 4, iter: 5000, curr loss: 1.3864083290100098, avg loss: 1.38639877140522\n",
      "trial: 4, iter: 5200, curr loss: 1.3870528936386108, avg loss: 1.3864013075828552\n",
      "trial: 4, iter: 5400, curr loss: 1.3869010210037231, avg loss: 1.3863452696800231\n",
      "trial: 4, iter: 5600, curr loss: 1.3862457275390625, avg loss: 1.3863533037900924\n",
      "trial: 4, iter: 5800, curr loss: 1.385608434677124, avg loss: 1.3863360714912414\n",
      "trial: 4, iter: 6000, curr loss: 1.3862720727920532, avg loss: 1.3863193517923356\n",
      "trial: 4, iter: 6200, curr loss: 1.3863766193389893, avg loss: 1.3863289880752563\n",
      "trial: 4, iter: 6400, curr loss: 1.38607919216156, avg loss: 1.3863256454467774\n",
      "trial: 4, iter: 6600, curr loss: 1.386556625366211, avg loss: 1.3863225013017655\n",
      "trial: 4, iter: 6800, curr loss: 1.3864020109176636, avg loss: 1.386297801733017\n",
      "trial: 4, iter: 7000, curr loss: 1.3859143257141113, avg loss: 1.3863149762153626\n",
      "trial: 4, iter: 7200, curr loss: 1.386267066001892, avg loss: 1.3863031697273254\n",
      "trial: 4, iter: 7400, curr loss: 1.3862534761428833, avg loss: 1.386309992671013\n",
      "trial: 4, iter: 7600, curr loss: 1.3859169483184814, avg loss: 1.3863089215755462\n",
      "trial: 4, iter: 7800, curr loss: 1.3862727880477905, avg loss: 1.3862935322523118\n",
      "trial: 4, iter: 8000, curr loss: 1.3865807056427002, avg loss: 1.3863423544168472\n",
      "trial: 4, iter: 8200, curr loss: 1.3864059448242188, avg loss: 1.3863444083929062\n",
      "trial: 4, iter: 8400, curr loss: 1.3863461017608643, avg loss: 1.3863154029846192\n",
      "trial: 4, iter: 8600, curr loss: 1.3864326477050781, avg loss: 1.3863039362430571\n",
      "trial: 4, iter: 8800, curr loss: 1.386121153831482, avg loss: 1.3862778323888778\n",
      "trial: 4, iter: 9000, curr loss: 1.3854103088378906, avg loss: 1.3862617492675782\n",
      "trial: 4, iter: 9200, curr loss: 1.3865197896957397, avg loss: 1.38634785592556\n",
      "trial: 4, iter: 9400, curr loss: 1.386375069618225, avg loss: 1.3862959223985671\n",
      "trial: 4, iter: 9600, curr loss: 1.3863872289657593, avg loss: 1.386310828924179\n",
      "trial: 4, iter: 9800, curr loss: 1.386289358139038, avg loss: 1.3862998604774475\n",
      "trial: 4, iter: 10000, curr loss: 1.3861745595932007, avg loss: 1.386305252313614\n",
      "trial: 4, iter: 10200, curr loss: 1.3864253759384155, avg loss: 1.3862918657064438\n",
      "trial: 4, iter: 10400, curr loss: 1.3862313032150269, avg loss: 1.386302889585495\n",
      "trial: 4, iter: 10600, curr loss: 1.386292576789856, avg loss: 1.3863047128915786\n",
      "trial: 4, iter: 10800, curr loss: 1.3862231969833374, avg loss: 1.386290983557701\n",
      "trial: 4, iter: 11000, curr loss: 1.3863353729248047, avg loss: 1.3863060003519059\n",
      "trial: 4, iter: 11200, curr loss: 1.386184573173523, avg loss: 1.3863001728057862\n",
      "trial: 4, iter: 11400, curr loss: 1.3862113952636719, avg loss: 1.3863075906038285\n",
      "trial: 4, iter: 11600, curr loss: 1.386367917060852, avg loss: 1.386299947500229\n",
      "trial: 4, iter: 11800, curr loss: 1.3862767219543457, avg loss: 1.3862952071428298\n",
      "trial: 4, iter: 12000, curr loss: 1.3862406015396118, avg loss: 1.3862993144989013\n",
      "trial: 4, iter: 12200, curr loss: 1.3862920999526978, avg loss: 1.386300243139267\n",
      "trial: 4, iter: 12400, curr loss: 1.3861877918243408, avg loss: 1.3862921440601348\n",
      "trial: 4, iter: 12600, curr loss: 1.3861430883407593, avg loss: 1.3862910717725754\n",
      "trial: 4, iter: 12800, curr loss: 1.3863171339035034, avg loss: 1.386348721385002\n",
      "trial: 4, iter: 13000, curr loss: 1.385909914970398, avg loss: 1.3863565886020661\n",
      "trial: 4, iter: 13200, curr loss: 1.3863520622253418, avg loss: 1.3863088929653167\n",
      "trial: 4, iter: 13400, curr loss: 1.386237382888794, avg loss: 1.3863168883323669\n",
      "trial: 4, iter: 13600, curr loss: 1.3862762451171875, avg loss: 1.3863235384225845\n",
      "trial: 4, iter: 13800, curr loss: 1.3863848447799683, avg loss: 1.3863045287132263\n",
      "trial: 4, iter: 14000, curr loss: 1.386064052581787, avg loss: 1.3862880516052245\n",
      "trial: 4, iter: 14200, curr loss: 1.3857059478759766, avg loss: 1.3863234037160874\n",
      "trial: 4, iter: 14400, curr loss: 1.3860317468643188, avg loss: 1.3863232576847075\n",
      "trial: 4, iter: 14600, curr loss: 1.3861963748931885, avg loss: 1.3863041985034943\n",
      "trial: 4, iter: 14800, curr loss: 1.3868788480758667, avg loss: 1.3862782996892928\n",
      "trial: 4, iter: 15000, curr loss: 1.3861688375473022, avg loss: 1.3862976372241973\n",
      "trial: 4, iter: 15200, curr loss: 1.3861887454986572, avg loss: 1.386315484046936\n",
      "trial: 4, iter: 15400, curr loss: 1.3864060640335083, avg loss: 1.3863064163923264\n",
      "trial: 4, iter: 15600, curr loss: 1.386317491531372, avg loss: 1.3862978363037108\n",
      "trial: 4, ldr: -0.0004881744389422238\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385780930519104, avg loss: 1.3871030378341676\n",
      "trial: 5, iter: 400, curr loss: 1.386584758758545, avg loss: 1.386741880774498\n",
      "trial: 5, iter: 600, curr loss: 1.3853689432144165, avg loss: 1.3865022534132003\n",
      "trial: 5, iter: 800, curr loss: 1.387341856956482, avg loss: 1.3864507645368576\n",
      "trial: 5, iter: 1000, curr loss: 1.3869259357452393, avg loss: 1.3864657652378083\n",
      "trial: 5, iter: 1200, curr loss: 1.3857649564743042, avg loss: 1.3865480160713195\n",
      "trial: 5, iter: 1400, curr loss: 1.3848693370819092, avg loss: 1.3864643913507462\n",
      "trial: 5, iter: 1600, curr loss: 1.3856855630874634, avg loss: 1.386448483467102\n",
      "trial: 5, iter: 1800, curr loss: 1.3862262964248657, avg loss: 1.3863744783401488\n",
      "trial: 5, iter: 2000, curr loss: 1.3859448432922363, avg loss: 1.3862680029869079\n",
      "trial: 5, iter: 2200, curr loss: 1.3861513137817383, avg loss: 1.3864458417892456\n",
      "trial: 5, iter: 2400, curr loss: 1.3868114948272705, avg loss: 1.3863796728849411\n",
      "trial: 5, iter: 2600, curr loss: 1.3855679035186768, avg loss: 1.386357786655426\n",
      "trial: 5, iter: 2800, curr loss: 1.3864871263504028, avg loss: 1.3863362765312195\n",
      "trial: 5, iter: 3000, curr loss: 1.3868192434310913, avg loss: 1.3862885004281997\n",
      "trial: 5, iter: 3200, curr loss: 1.3862730264663696, avg loss: 1.3864178562164307\n",
      "trial: 5, iter: 3400, curr loss: 1.3872802257537842, avg loss: 1.3863651484251023\n",
      "trial: 5, iter: 3600, curr loss: 1.3856126070022583, avg loss: 1.386319301724434\n",
      "trial: 5, iter: 3800, curr loss: 1.3862277269363403, avg loss: 1.3863405686616899\n",
      "trial: 5, iter: 4000, curr loss: 1.3864697217941284, avg loss: 1.3862661492824555\n",
      "trial: 5, iter: 4200, curr loss: 1.386359691619873, avg loss: 1.3863587391376495\n",
      "trial: 5, iter: 4400, curr loss: 1.3859224319458008, avg loss: 1.386289929151535\n",
      "trial: 5, iter: 4600, curr loss: 1.3867626190185547, avg loss: 1.3863640189170838\n",
      "trial: 5, iter: 4800, curr loss: 1.3864504098892212, avg loss: 1.3863946521282196\n",
      "trial: 5, iter: 5000, curr loss: 1.387497901916504, avg loss: 1.3863487112522126\n",
      "trial: 5, iter: 5200, curr loss: 1.3864740133285522, avg loss: 1.3863594579696654\n",
      "trial: 5, iter: 5400, curr loss: 1.3864567279815674, avg loss: 1.386321781873703\n",
      "trial: 5, iter: 5600, curr loss: 1.3860633373260498, avg loss: 1.3862871026992798\n",
      "trial: 5, iter: 5800, curr loss: 1.386541485786438, avg loss: 1.3863397610187531\n",
      "trial: 5, iter: 6000, curr loss: 1.386470079421997, avg loss: 1.3862947261333465\n",
      "trial: 5, iter: 6200, curr loss: 1.3861181735992432, avg loss: 1.3863436311483384\n",
      "trial: 5, iter: 6400, curr loss: 1.3862224817276, avg loss: 1.3863044095039367\n",
      "trial: 5, iter: 6600, curr loss: 1.3861786127090454, avg loss: 1.3863102555274964\n",
      "trial: 5, iter: 6800, curr loss: 1.3863353729248047, avg loss: 1.386321458220482\n",
      "trial: 5, iter: 7000, curr loss: 1.3865535259246826, avg loss: 1.3862901562452317\n",
      "trial: 5, iter: 7200, curr loss: 1.3864870071411133, avg loss: 1.3863057392835616\n",
      "trial: 5, iter: 7400, curr loss: 1.3864420652389526, avg loss: 1.3862992352247239\n",
      "trial: 5, iter: 7600, curr loss: 1.3862675428390503, avg loss: 1.3863036113977432\n",
      "trial: 5, iter: 7800, curr loss: 1.3862576484680176, avg loss: 1.386297419667244\n",
      "trial: 5, iter: 8000, curr loss: 1.3862208127975464, avg loss: 1.3862998920679093\n",
      "trial: 5, iter: 8200, curr loss: 1.3864864110946655, avg loss: 1.3862900829315186\n",
      "trial: 5, iter: 8400, curr loss: 1.3858510255813599, avg loss: 1.3863015830516816\n",
      "trial: 5, iter: 8600, curr loss: 1.386107325553894, avg loss: 1.3863073927164078\n",
      "trial: 5, iter: 8800, curr loss: 1.3856672048568726, avg loss: 1.3862820613384246\n",
      "trial: 5, iter: 9000, curr loss: 1.386274814605713, avg loss: 1.3863324201107026\n",
      "trial: 5, iter: 9200, curr loss: 1.3864246606826782, avg loss: 1.3863718992471694\n",
      "trial: 5, iter: 9400, curr loss: 1.3862674236297607, avg loss: 1.3863121831417085\n",
      "trial: 5, iter: 9600, curr loss: 1.3863765001296997, avg loss: 1.3862952548265457\n",
      "trial: 5, iter: 9800, curr loss: 1.3862992525100708, avg loss: 1.3862960320711135\n",
      "trial: 5, iter: 10000, curr loss: 1.386273980140686, avg loss: 1.3862942636013031\n",
      "trial: 5, iter: 10200, curr loss: 1.386387825012207, avg loss: 1.3863164269924164\n",
      "trial: 5, iter: 10400, curr loss: 1.3862788677215576, avg loss: 1.3863052701950074\n",
      "trial: 5, iter: 10600, curr loss: 1.3861907720565796, avg loss: 1.386275541782379\n",
      "trial: 5, iter: 10800, curr loss: 1.3862990140914917, avg loss: 1.3863221859931947\n",
      "trial: 5, iter: 11000, curr loss: 1.3862756490707397, avg loss: 1.3862990283966063\n",
      "trial: 5, iter: 11200, curr loss: 1.3863736391067505, avg loss: 1.3862924194335937\n",
      "trial: 5, iter: 11400, curr loss: 1.3863041400909424, avg loss: 1.386297853589058\n",
      "trial: 5, iter: 11600, curr loss: 1.386358380317688, avg loss: 1.386298062801361\n",
      "trial: 5, iter: 11800, curr loss: 1.386510968208313, avg loss: 1.3862825274467467\n",
      "trial: 5, iter: 12000, curr loss: 1.3863474130630493, avg loss: 1.3863102161884309\n",
      "trial: 5, iter: 12200, curr loss: 1.3863747119903564, avg loss: 1.3863006764650345\n",
      "trial: 5, iter: 12400, curr loss: 1.3863261938095093, avg loss: 1.3862974393367766\n",
      "trial: 5, iter: 12600, curr loss: 1.3861706256866455, avg loss: 1.3862940394878387\n",
      "trial: 5, iter: 12800, curr loss: 1.3862974643707275, avg loss: 1.3862999510765075\n",
      "trial: 5, iter: 13000, curr loss: 1.3863019943237305, avg loss: 1.3862964230775834\n",
      "trial: 5, iter: 13200, curr loss: 1.3862963914871216, avg loss: 1.3862952554225922\n",
      "trial: 5, iter: 13400, curr loss: 1.3862876892089844, avg loss: 1.3862934774160385\n",
      "trial: 5, iter: 13600, curr loss: 1.386307954788208, avg loss: 1.3862943458557129\n",
      "trial: 5, iter: 13800, curr loss: 1.3862930536270142, avg loss: 1.3862947857379913\n",
      "trial: 5, iter: 14000, curr loss: 1.386293649673462, avg loss: 1.3862943822145462\n",
      "trial: 5, iter: 14200, curr loss: 1.3863093852996826, avg loss: 1.3862943792343139\n",
      "trial: 5, iter: 14400, curr loss: 1.3863221406936646, avg loss: 1.3862943291664123\n",
      "trial: 5, iter: 14600, curr loss: 1.3862946033477783, avg loss: 1.3862956386804581\n",
      "trial: 5, iter: 14800, curr loss: 1.3862948417663574, avg loss: 1.3862954181432725\n",
      "trial: 5, iter: 15000, curr loss: 1.386303186416626, avg loss: 1.3862948459386826\n",
      "trial: 5, iter: 15200, curr loss: 1.3862941265106201, avg loss: 1.3862949073314668\n",
      "trial: 5, iter: 15400, curr loss: 1.3862944841384888, avg loss: 1.386293744444847\n",
      "trial: 5, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294726729393\n",
      "trial: 5, ldr: -1.2734139431813674e-07\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0005297894672096959\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3869692087173462, avg loss: 1.3871841305494308\n",
      "trial: 1, iter: 400, curr loss: 1.3874036073684692, avg loss: 1.3866402471065522\n",
      "trial: 1, iter: 600, curr loss: 1.3857632875442505, avg loss: 1.3866246592998506\n",
      "trial: 1, iter: 800, curr loss: 1.3867257833480835, avg loss: 1.3864332902431489\n",
      "trial: 1, iter: 1000, curr loss: 1.3838695287704468, avg loss: 1.3864076310396194\n",
      "trial: 1, iter: 1200, curr loss: 1.3866300582885742, avg loss: 1.3864458853006363\n",
      "trial: 1, iter: 1400, curr loss: 1.3859378099441528, avg loss: 1.3864264160394668\n",
      "trial: 1, iter: 1600, curr loss: 1.3858497142791748, avg loss: 1.3863563966751098\n",
      "trial: 1, iter: 1800, curr loss: 1.3836005926132202, avg loss: 1.3863926190137863\n",
      "trial: 1, iter: 2000, curr loss: 1.3854130506515503, avg loss: 1.3864789962768556\n",
      "trial: 1, iter: 2200, curr loss: 1.3860899209976196, avg loss: 1.3864707642793654\n",
      "trial: 1, iter: 2400, curr loss: 1.3862063884735107, avg loss: 1.3863949835300446\n",
      "trial: 1, iter: 2600, curr loss: 1.386771559715271, avg loss: 1.3863340890407563\n",
      "trial: 1, iter: 2800, curr loss: 1.3866552114486694, avg loss: 1.3863945734500884\n",
      "trial: 1, iter: 3000, curr loss: 1.3867261409759521, avg loss: 1.386380215883255\n",
      "trial: 1, iter: 3200, curr loss: 1.3863525390625, avg loss: 1.3863465422391892\n",
      "trial: 1, iter: 3400, curr loss: 1.3867158889770508, avg loss: 1.3863698101043702\n",
      "trial: 1, iter: 3600, curr loss: 1.3860795497894287, avg loss: 1.3863357895612716\n",
      "trial: 1, iter: 3800, curr loss: 1.3858137130737305, avg loss: 1.3863429021835327\n",
      "trial: 1, iter: 4000, curr loss: 1.386557936668396, avg loss: 1.3863266080617904\n",
      "trial: 1, iter: 4200, curr loss: 1.386778712272644, avg loss: 1.3862900614738465\n",
      "trial: 1, iter: 4400, curr loss: 1.3864911794662476, avg loss: 1.3863406050205231\n",
      "trial: 1, iter: 4600, curr loss: 1.386626124382019, avg loss: 1.386339666247368\n",
      "trial: 1, iter: 4800, curr loss: 1.3862453699111938, avg loss: 1.386296393275261\n",
      "trial: 1, iter: 5000, curr loss: 1.386316180229187, avg loss: 1.3863032919168472\n",
      "trial: 1, iter: 5200, curr loss: 1.3857336044311523, avg loss: 1.3863400077819825\n",
      "trial: 1, iter: 5400, curr loss: 1.3871217966079712, avg loss: 1.386297658085823\n",
      "trial: 1, iter: 5600, curr loss: 1.385984182357788, avg loss: 1.3863036113977432\n",
      "trial: 1, iter: 5800, curr loss: 1.387338638305664, avg loss: 1.3863130068778993\n",
      "trial: 1, iter: 6000, curr loss: 1.3856730461120605, avg loss: 1.3863403367996217\n",
      "trial: 1, iter: 6200, curr loss: 1.3866809606552124, avg loss: 1.3863750183582306\n",
      "trial: 1, iter: 6400, curr loss: 1.3861944675445557, avg loss: 1.3862856018543244\n",
      "trial: 1, iter: 6600, curr loss: 1.3861243724822998, avg loss: 1.3863480389118195\n",
      "trial: 1, iter: 6800, curr loss: 1.3862029314041138, avg loss: 1.3863147222995758\n",
      "trial: 1, iter: 7000, curr loss: 1.3863413333892822, avg loss: 1.3862989008426667\n",
      "trial: 1, iter: 7200, curr loss: 1.3862537145614624, avg loss: 1.3863116401433944\n",
      "trial: 1, iter: 7400, curr loss: 1.3862617015838623, avg loss: 1.3863198065757751\n",
      "trial: 1, iter: 7600, curr loss: 1.3863329887390137, avg loss: 1.3863316589593888\n",
      "trial: 1, iter: 7800, curr loss: 1.3864848613739014, avg loss: 1.3862963181734085\n",
      "trial: 1, iter: 8000, curr loss: 1.3863011598587036, avg loss: 1.3863153600692748\n",
      "trial: 1, iter: 8200, curr loss: 1.3864903450012207, avg loss: 1.3862956774234771\n",
      "trial: 1, iter: 8400, curr loss: 1.386345386505127, avg loss: 1.3863884937763213\n",
      "trial: 1, iter: 8600, curr loss: 1.3864496946334839, avg loss: 1.3863224321603775\n",
      "trial: 1, iter: 8800, curr loss: 1.386157751083374, avg loss: 1.3863052290678024\n",
      "trial: 1, iter: 9000, curr loss: 1.3867039680480957, avg loss: 1.386274738907814\n",
      "trial: 1, iter: 9200, curr loss: 1.3864625692367554, avg loss: 1.3863248825073242\n",
      "trial: 1, iter: 9400, curr loss: 1.3860360383987427, avg loss: 1.3862950217723846\n",
      "trial: 1, iter: 9600, curr loss: 1.3863016366958618, avg loss: 1.3862960827350617\n",
      "trial: 1, iter: 9800, curr loss: 1.3860125541687012, avg loss: 1.3862800586223603\n",
      "trial: 1, iter: 10000, curr loss: 1.3866313695907593, avg loss: 1.386301161646843\n",
      "trial: 1, iter: 10200, curr loss: 1.386415958404541, avg loss: 1.3863017183542252\n",
      "trial: 1, iter: 10400, curr loss: 1.3860782384872437, avg loss: 1.3862902408838271\n",
      "trial: 1, iter: 10600, curr loss: 1.3860726356506348, avg loss: 1.3863043653964997\n",
      "trial: 1, iter: 10800, curr loss: 1.3861466646194458, avg loss: 1.3862498170137405\n",
      "trial: 1, iter: 11000, curr loss: 1.386286973953247, avg loss: 1.3863109540939331\n",
      "trial: 1, iter: 11200, curr loss: 1.3875067234039307, avg loss: 1.3863078105449675\n",
      "trial: 1, iter: 11400, curr loss: 1.3863120079040527, avg loss: 1.3863022488355636\n",
      "trial: 1, iter: 11600, curr loss: 1.3863343000411987, avg loss: 1.3862954199314117\n",
      "trial: 1, iter: 11800, curr loss: 1.3863005638122559, avg loss: 1.3862955021858214\n",
      "trial: 1, iter: 12000, curr loss: 1.3863035440444946, avg loss: 1.3862946367263793\n",
      "trial: 1, iter: 12200, curr loss: 1.386303186416626, avg loss: 1.3862953239679336\n",
      "trial: 1, iter: 12400, curr loss: 1.3862946033477783, avg loss: 1.3862949109077454\n",
      "trial: 1, iter: 12600, curr loss: 1.3862943649291992, avg loss: 1.386294669508934\n",
      "trial: 1, iter: 12800, curr loss: 1.3862946033477783, avg loss: 1.3862948024272919\n",
      "trial: 1, iter: 13000, curr loss: 1.3862944841384888, avg loss: 1.386294658780098\n",
      "trial: 1, iter: 13200, curr loss: 1.3862944841384888, avg loss: 1.3862949043512345\n",
      "trial: 1, iter: 13400, curr loss: 1.3862946033477783, avg loss: 1.386294548511505\n",
      "trial: 1, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.3862946379184722\n",
      "trial: 1, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.3862947642803192\n",
      "trial: 1, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.3862948483228683\n",
      "trial: 1, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.3862948977947236\n",
      "trial: 1, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.3862948822975159\n",
      "trial: 1, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.3862949180603028\n",
      "trial: 1, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 1, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862949097156525\n",
      "trial: 1, ldr: 2.8610209687474075e-11\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875912427902222, avg loss: 1.3872501075267791\n",
      "trial: 2, iter: 400, curr loss: 1.3902755975723267, avg loss: 1.386655057668686\n",
      "trial: 2, iter: 600, curr loss: 1.3863561153411865, avg loss: 1.386687951683998\n",
      "trial: 2, iter: 800, curr loss: 1.386474847793579, avg loss: 1.3866499161720276\n",
      "trial: 2, iter: 1000, curr loss: 1.3866630792617798, avg loss: 1.386647691130638\n",
      "trial: 2, iter: 1200, curr loss: 1.3889309167861938, avg loss: 1.3866097521781922\n",
      "trial: 2, iter: 1400, curr loss: 1.3874627351760864, avg loss: 1.3865077424049377\n",
      "trial: 2, iter: 1600, curr loss: 1.3873491287231445, avg loss: 1.386421703696251\n",
      "trial: 2, iter: 1800, curr loss: 1.3865333795547485, avg loss: 1.3864595019817352\n",
      "trial: 2, iter: 2000, curr loss: 1.3857547044754028, avg loss: 1.38639353454113\n",
      "trial: 2, iter: 2200, curr loss: 1.386252760887146, avg loss: 1.386396942138672\n",
      "trial: 2, iter: 2400, curr loss: 1.3863917589187622, avg loss: 1.3862571227550506\n",
      "trial: 2, iter: 2600, curr loss: 1.3875694274902344, avg loss: 1.386346043944359\n",
      "trial: 2, iter: 2800, curr loss: 1.386550784111023, avg loss: 1.3864281982183457\n",
      "trial: 2, iter: 3000, curr loss: 1.3864212036132812, avg loss: 1.3863896507024764\n",
      "trial: 2, iter: 3200, curr loss: 1.385608196258545, avg loss: 1.3863173806667328\n",
      "trial: 2, iter: 3400, curr loss: 1.3859671354293823, avg loss: 1.3863389974832534\n",
      "trial: 2, iter: 3600, curr loss: 1.386091709136963, avg loss: 1.3863158959150315\n",
      "trial: 2, iter: 3800, curr loss: 1.386083960533142, avg loss: 1.386369252204895\n",
      "trial: 2, iter: 4000, curr loss: 1.3865184783935547, avg loss: 1.3863435512781144\n",
      "trial: 2, iter: 4200, curr loss: 1.3864206075668335, avg loss: 1.386291688680649\n",
      "trial: 2, iter: 4400, curr loss: 1.386003851890564, avg loss: 1.3863389712572098\n",
      "trial: 2, iter: 4600, curr loss: 1.3862273693084717, avg loss: 1.3863135588169098\n",
      "trial: 2, iter: 4800, curr loss: 1.3863590955734253, avg loss: 1.386384614109993\n",
      "trial: 2, iter: 5000, curr loss: 1.3859994411468506, avg loss: 1.3863014221191405\n",
      "trial: 2, iter: 5200, curr loss: 1.3858546018600464, avg loss: 1.3863000446557998\n",
      "trial: 2, iter: 5400, curr loss: 1.386688470840454, avg loss: 1.386332870721817\n",
      "trial: 2, iter: 5600, curr loss: 1.3870028257369995, avg loss: 1.3863448429107665\n",
      "trial: 2, iter: 5800, curr loss: 1.385931134223938, avg loss: 1.3863449728488921\n",
      "trial: 2, iter: 6000, curr loss: 1.3861690759658813, avg loss: 1.3863357895612716\n",
      "trial: 2, iter: 6200, curr loss: 1.3856565952301025, avg loss: 1.3863250017166138\n",
      "trial: 2, iter: 6400, curr loss: 1.386062502861023, avg loss: 1.3863084292411805\n",
      "trial: 2, iter: 6600, curr loss: 1.3868657350540161, avg loss: 1.3863107758760451\n",
      "trial: 2, iter: 6800, curr loss: 1.3862539529800415, avg loss: 1.386323328614235\n",
      "trial: 2, iter: 7000, curr loss: 1.3861075639724731, avg loss: 1.386337314248085\n",
      "trial: 2, iter: 7200, curr loss: 1.386470913887024, avg loss: 1.3863337641954423\n",
      "trial: 2, iter: 7400, curr loss: 1.3864073753356934, avg loss: 1.3863183623552322\n",
      "trial: 2, iter: 7600, curr loss: 1.3859788179397583, avg loss: 1.3863645327091216\n",
      "trial: 2, iter: 7800, curr loss: 1.3859374523162842, avg loss: 1.3862988942861556\n",
      "trial: 2, iter: 8000, curr loss: 1.3862361907958984, avg loss: 1.3863434094190596\n",
      "trial: 2, iter: 8200, curr loss: 1.3860384225845337, avg loss: 1.386281059384346\n",
      "trial: 2, iter: 8400, curr loss: 1.3869209289550781, avg loss: 1.3862994122505188\n",
      "trial: 2, iter: 8600, curr loss: 1.3864918947219849, avg loss: 1.386325477361679\n",
      "trial: 2, iter: 8800, curr loss: 1.3865776062011719, avg loss: 1.3863130921125413\n",
      "trial: 2, iter: 9000, curr loss: 1.3863962888717651, avg loss: 1.3863033068180084\n",
      "trial: 2, iter: 9200, curr loss: 1.3859394788742065, avg loss: 1.386309649348259\n",
      "trial: 2, iter: 9400, curr loss: 1.3867249488830566, avg loss: 1.3863098156452178\n",
      "trial: 2, iter: 9600, curr loss: 1.386313796043396, avg loss: 1.3863079822063447\n",
      "trial: 2, iter: 9800, curr loss: 1.3873358964920044, avg loss: 1.3862934774160385\n",
      "trial: 2, iter: 10000, curr loss: 1.3863203525543213, avg loss: 1.386300315260887\n",
      "trial: 2, iter: 10200, curr loss: 1.3858338594436646, avg loss: 1.386291237473488\n",
      "trial: 2, iter: 10400, curr loss: 1.3864758014678955, avg loss: 1.3862783235311509\n",
      "trial: 2, iter: 10600, curr loss: 1.3855924606323242, avg loss: 1.3862901687622071\n",
      "trial: 2, iter: 10800, curr loss: 1.3865365982055664, avg loss: 1.3863010501861572\n",
      "trial: 2, iter: 11000, curr loss: 1.3865123987197876, avg loss: 1.3863129192590713\n",
      "trial: 2, iter: 11200, curr loss: 1.3862498998641968, avg loss: 1.3863154435157776\n",
      "trial: 2, iter: 11400, curr loss: 1.3862032890319824, avg loss: 1.3862900340557098\n",
      "trial: 2, iter: 11600, curr loss: 1.3866541385650635, avg loss: 1.3862966233491898\n",
      "trial: 2, iter: 11800, curr loss: 1.386335015296936, avg loss: 1.3862993496656417\n",
      "trial: 2, iter: 12000, curr loss: 1.3862839937210083, avg loss: 1.3863163465261459\n",
      "trial: 2, iter: 12200, curr loss: 1.3863635063171387, avg loss: 1.3862938368320465\n",
      "trial: 2, iter: 12400, curr loss: 1.3863062858581543, avg loss: 1.3862956887483597\n",
      "trial: 2, iter: 12600, curr loss: 1.3862578868865967, avg loss: 1.3862989950180054\n",
      "trial: 2, iter: 12800, curr loss: 1.3865426778793335, avg loss: 1.3863275915384292\n",
      "trial: 2, iter: 13000, curr loss: 1.386386513710022, avg loss: 1.3863019388914108\n",
      "trial: 2, iter: 13200, curr loss: 1.3867067098617554, avg loss: 1.3862806940078736\n",
      "trial: 2, iter: 13400, curr loss: 1.386234164237976, avg loss: 1.3863121783733368\n",
      "trial: 2, iter: 13600, curr loss: 1.3864805698394775, avg loss: 1.386304018497467\n",
      "trial: 2, iter: 13800, curr loss: 1.3863568305969238, avg loss: 1.3862931716442108\n",
      "trial: 2, iter: 14000, curr loss: 1.3862816095352173, avg loss: 1.3862923008203507\n",
      "trial: 2, iter: 14200, curr loss: 1.3862096071243286, avg loss: 1.386308516263962\n",
      "trial: 2, iter: 14400, curr loss: 1.3861438035964966, avg loss: 1.3863001203536987\n",
      "trial: 2, iter: 14600, curr loss: 1.3862390518188477, avg loss: 1.3863065260648728\n",
      "trial: 2, iter: 14800, curr loss: 1.3861844539642334, avg loss: 1.3863011699914933\n",
      "trial: 2, iter: 15000, curr loss: 1.386355996131897, avg loss: 1.3862971371412278\n",
      "trial: 2, iter: 15200, curr loss: 1.386311650276184, avg loss: 1.3863037532567979\n",
      "trial: 2, iter: 15400, curr loss: 1.3863651752471924, avg loss: 1.3863040137290954\n",
      "trial: 2, iter: 15600, curr loss: 1.3864203691482544, avg loss: 1.3863179332017899\n",
      "trial: 2, ldr: -0.000995182665064931\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3846818208694458, avg loss: 1.3874036628007889\n",
      "trial: 3, iter: 400, curr loss: 1.3855981826782227, avg loss: 1.3868374884128571\n",
      "trial: 3, iter: 600, curr loss: 1.3858596086502075, avg loss: 1.3866547906398774\n",
      "trial: 3, iter: 800, curr loss: 1.3864505290985107, avg loss: 1.386378442645073\n",
      "trial: 3, iter: 1000, curr loss: 1.3873956203460693, avg loss: 1.3866350197792052\n",
      "trial: 3, iter: 1200, curr loss: 1.387534737586975, avg loss: 1.3864573794603348\n",
      "trial: 3, iter: 1400, curr loss: 1.3856507539749146, avg loss: 1.3863301008939743\n",
      "trial: 3, iter: 1600, curr loss: 1.3832943439483643, avg loss: 1.386276621222496\n",
      "trial: 3, iter: 1800, curr loss: 1.3867076635360718, avg loss: 1.3863961666822433\n",
      "trial: 3, iter: 2000, curr loss: 1.3861929178237915, avg loss: 1.386371608376503\n",
      "trial: 3, iter: 2200, curr loss: 1.3862552642822266, avg loss: 1.3863467198610306\n",
      "trial: 3, iter: 2400, curr loss: 1.386428713798523, avg loss: 1.3864202886819839\n",
      "trial: 3, iter: 2600, curr loss: 1.3868427276611328, avg loss: 1.386369931101799\n",
      "trial: 3, iter: 2800, curr loss: 1.3858627080917358, avg loss: 1.3863017976284027\n",
      "trial: 3, iter: 3000, curr loss: 1.3868790864944458, avg loss: 1.3863652378320694\n",
      "trial: 3, iter: 3200, curr loss: 1.386117696762085, avg loss: 1.3864018952846526\n",
      "trial: 3, iter: 3400, curr loss: 1.386785864830017, avg loss: 1.3863507759571077\n",
      "trial: 3, iter: 3600, curr loss: 1.3857686519622803, avg loss: 1.3863506078720094\n",
      "trial: 3, iter: 3800, curr loss: 1.3875702619552612, avg loss: 1.3863139629364014\n",
      "trial: 3, iter: 4000, curr loss: 1.3860363960266113, avg loss: 1.3863368153572082\n",
      "trial: 3, iter: 4200, curr loss: 1.3857717514038086, avg loss: 1.386267410516739\n",
      "trial: 3, iter: 4400, curr loss: 1.3864599466323853, avg loss: 1.3864628374576569\n",
      "trial: 3, iter: 4600, curr loss: 1.3875526189804077, avg loss: 1.3864272034168243\n",
      "trial: 3, iter: 4800, curr loss: 1.385419249534607, avg loss: 1.3864007329940795\n",
      "trial: 3, iter: 5000, curr loss: 1.386014699935913, avg loss: 1.3863687670230866\n",
      "trial: 3, iter: 5200, curr loss: 1.3848745822906494, avg loss: 1.3863695722818374\n",
      "trial: 3, iter: 5400, curr loss: 1.3868569135665894, avg loss: 1.3863919734954835\n",
      "trial: 3, iter: 5600, curr loss: 1.3862793445587158, avg loss: 1.3863786327838898\n",
      "trial: 3, iter: 5800, curr loss: 1.3857507705688477, avg loss: 1.3863386344909667\n",
      "trial: 3, iter: 6000, curr loss: 1.386545181274414, avg loss: 1.3863378888368607\n",
      "trial: 3, iter: 6200, curr loss: 1.386474370956421, avg loss: 1.3863606017827987\n",
      "trial: 3, iter: 6400, curr loss: 1.3863747119903564, avg loss: 1.3863397777080535\n",
      "trial: 3, iter: 6600, curr loss: 1.385928750038147, avg loss: 1.386283060312271\n",
      "trial: 3, iter: 6800, curr loss: 1.3863351345062256, avg loss: 1.3863201874494553\n",
      "trial: 3, iter: 7000, curr loss: 1.3865553140640259, avg loss: 1.3863057029247283\n",
      "trial: 3, iter: 7200, curr loss: 1.3863589763641357, avg loss: 1.3862838435173035\n",
      "trial: 3, iter: 7400, curr loss: 1.3862117528915405, avg loss: 1.3863219594955445\n",
      "trial: 3, iter: 7600, curr loss: 1.38638174533844, avg loss: 1.386296157836914\n",
      "trial: 3, iter: 7800, curr loss: 1.3863129615783691, avg loss: 1.3863213247060775\n",
      "trial: 3, iter: 8000, curr loss: 1.3865628242492676, avg loss: 1.386299141049385\n",
      "trial: 3, iter: 8200, curr loss: 1.3862218856811523, avg loss: 1.3863072633743285\n",
      "trial: 3, iter: 8400, curr loss: 1.385788083076477, avg loss: 1.3862886589765548\n",
      "trial: 3, iter: 8600, curr loss: 1.387141466140747, avg loss: 1.3863654553890228\n",
      "trial: 3, iter: 8800, curr loss: 1.385896921157837, avg loss: 1.3863718390464783\n",
      "trial: 3, iter: 9000, curr loss: 1.3870232105255127, avg loss: 1.3864012098312377\n",
      "trial: 3, iter: 9200, curr loss: 1.38609778881073, avg loss: 1.3863394862413407\n",
      "trial: 3, iter: 9400, curr loss: 1.386299729347229, avg loss: 1.3863537174463272\n",
      "trial: 3, iter: 9600, curr loss: 1.3862190246582031, avg loss: 1.3862727355957032\n",
      "trial: 3, iter: 9800, curr loss: 1.3868745565414429, avg loss: 1.3863585412502288\n",
      "trial: 3, iter: 10000, curr loss: 1.38667893409729, avg loss: 1.3862735164165496\n",
      "trial: 3, iter: 10200, curr loss: 1.3874679803848267, avg loss: 1.3863384038209916\n",
      "trial: 3, iter: 10400, curr loss: 1.3871362209320068, avg loss: 1.3863543522357942\n",
      "trial: 3, iter: 10600, curr loss: 1.385913372039795, avg loss: 1.3863884073495865\n",
      "trial: 3, iter: 10800, curr loss: 1.3862955570220947, avg loss: 1.3863172572851181\n",
      "trial: 3, iter: 11000, curr loss: 1.3857531547546387, avg loss: 1.3863181430101394\n",
      "trial: 3, iter: 11200, curr loss: 1.3860671520233154, avg loss: 1.3863540518283843\n",
      "trial: 3, iter: 11400, curr loss: 1.3860678672790527, avg loss: 1.386282839179039\n",
      "trial: 3, iter: 11600, curr loss: 1.385905146598816, avg loss: 1.386315776705742\n",
      "trial: 3, iter: 11800, curr loss: 1.3860336542129517, avg loss: 1.386300578713417\n",
      "trial: 3, iter: 12000, curr loss: 1.3864446878433228, avg loss: 1.3862941986322403\n",
      "trial: 3, iter: 12200, curr loss: 1.3865729570388794, avg loss: 1.3863197314739226\n",
      "trial: 3, iter: 12400, curr loss: 1.3864922523498535, avg loss: 1.3863176757097244\n",
      "trial: 3, iter: 12600, curr loss: 1.3862385749816895, avg loss: 1.3862985962629317\n",
      "trial: 3, iter: 12800, curr loss: 1.3862488269805908, avg loss: 1.3863086676597596\n",
      "trial: 3, iter: 13000, curr loss: 1.3863052129745483, avg loss: 1.3862990188598632\n",
      "trial: 3, iter: 13200, curr loss: 1.3860609531402588, avg loss: 1.3862935715913773\n",
      "trial: 3, iter: 13400, curr loss: 1.3862082958221436, avg loss: 1.3863154596090317\n",
      "trial: 3, iter: 13600, curr loss: 1.3862957954406738, avg loss: 1.3863089096546173\n",
      "trial: 3, iter: 13800, curr loss: 1.3862614631652832, avg loss: 1.386293088197708\n",
      "trial: 3, iter: 14000, curr loss: 1.3861277103424072, avg loss: 1.3862931048870086\n",
      "trial: 3, iter: 14200, curr loss: 1.3862769603729248, avg loss: 1.3863048434257508\n",
      "trial: 3, iter: 14400, curr loss: 1.3862658739089966, avg loss: 1.3863033694028855\n",
      "trial: 3, iter: 14600, curr loss: 1.3863050937652588, avg loss: 1.3862975203990937\n",
      "trial: 3, iter: 14800, curr loss: 1.3862550258636475, avg loss: 1.3862950706481934\n",
      "trial: 3, iter: 15000, curr loss: 1.3863815069198608, avg loss: 1.3862995010614396\n",
      "trial: 3, iter: 15200, curr loss: 1.3863451480865479, avg loss: 1.3862952584028243\n",
      "trial: 3, iter: 15400, curr loss: 1.3863025903701782, avg loss: 1.3862945854663848\n",
      "trial: 3, iter: 15600, curr loss: 1.386170506477356, avg loss: 1.3863139581680297\n",
      "trial: 3, ldr: 0.00104785175062716\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3876986503601074, avg loss: 1.3874233591556548\n",
      "trial: 4, iter: 400, curr loss: 1.3858709335327148, avg loss: 1.3868025708198548\n",
      "trial: 4, iter: 600, curr loss: 1.3865925073623657, avg loss: 1.3867357975244523\n",
      "trial: 4, iter: 800, curr loss: 1.3854941129684448, avg loss: 1.3865236926078797\n",
      "trial: 4, iter: 1000, curr loss: 1.3866679668426514, avg loss: 1.3864574503898621\n",
      "trial: 4, iter: 1200, curr loss: 1.3857451677322388, avg loss: 1.3864190900325775\n",
      "trial: 4, iter: 1400, curr loss: 1.385627269744873, avg loss: 1.3864843314886093\n",
      "trial: 4, iter: 1600, curr loss: 1.3836796283721924, avg loss: 1.3863545089960099\n",
      "trial: 4, iter: 1800, curr loss: 1.386894702911377, avg loss: 1.3863690268993378\n",
      "trial: 4, iter: 2000, curr loss: 1.3859635591506958, avg loss: 1.3864500135183335\n",
      "trial: 4, iter: 2200, curr loss: 1.3856407403945923, avg loss: 1.3863850957155228\n",
      "trial: 4, iter: 2400, curr loss: 1.3870526552200317, avg loss: 1.3865053606033326\n",
      "trial: 4, iter: 2600, curr loss: 1.386479377746582, avg loss: 1.3863612693548202\n",
      "trial: 4, iter: 2800, curr loss: 1.3869400024414062, avg loss: 1.3863870304822923\n",
      "trial: 4, iter: 3000, curr loss: 1.386290431022644, avg loss: 1.3864231044054032\n",
      "trial: 4, iter: 3200, curr loss: 1.386982798576355, avg loss: 1.3863998335599899\n",
      "trial: 4, iter: 3400, curr loss: 1.3878000974655151, avg loss: 1.3863235384225845\n",
      "trial: 4, iter: 3600, curr loss: 1.3866900205612183, avg loss: 1.3864491099119187\n",
      "trial: 4, iter: 3800, curr loss: 1.386689305305481, avg loss: 1.3863526886701585\n",
      "trial: 4, iter: 4000, curr loss: 1.3859044313430786, avg loss: 1.3864659821987153\n",
      "trial: 4, iter: 4200, curr loss: 1.386461853981018, avg loss: 1.3863775128126143\n",
      "trial: 4, iter: 4400, curr loss: 1.3860145807266235, avg loss: 1.386329516172409\n",
      "trial: 4, iter: 4600, curr loss: 1.3862199783325195, avg loss: 1.3863411408662796\n",
      "trial: 4, iter: 4800, curr loss: 1.386511206626892, avg loss: 1.3863701379299165\n",
      "trial: 4, iter: 5000, curr loss: 1.3867031335830688, avg loss: 1.38631871342659\n",
      "trial: 4, iter: 5200, curr loss: 1.386154294013977, avg loss: 1.3863050985336303\n",
      "trial: 4, iter: 5400, curr loss: 1.386091947555542, avg loss: 1.3862636595964433\n",
      "trial: 4, iter: 5600, curr loss: 1.3863815069198608, avg loss: 1.3863571310043334\n",
      "trial: 4, iter: 5800, curr loss: 1.3863252401351929, avg loss: 1.3863384538888932\n",
      "trial: 4, iter: 6000, curr loss: 1.3861160278320312, avg loss: 1.3863345295190812\n",
      "trial: 4, iter: 6200, curr loss: 1.3870781660079956, avg loss: 1.3862929081916808\n",
      "trial: 4, iter: 6400, curr loss: 1.3861610889434814, avg loss: 1.3863296502828597\n",
      "trial: 4, iter: 6600, curr loss: 1.3862411975860596, avg loss: 1.3863112711906433\n",
      "trial: 4, iter: 6800, curr loss: 1.3865816593170166, avg loss: 1.3863014161586762\n",
      "trial: 4, iter: 7000, curr loss: 1.3859562873840332, avg loss: 1.3863055098056793\n",
      "trial: 4, iter: 7200, curr loss: 1.3859453201293945, avg loss: 1.3862948626279832\n",
      "trial: 4, iter: 7400, curr loss: 1.3861083984375, avg loss: 1.38630277633667\n",
      "trial: 4, iter: 7600, curr loss: 1.3873058557510376, avg loss: 1.386295000910759\n",
      "trial: 4, iter: 7800, curr loss: 1.386125922203064, avg loss: 1.3863380789756774\n",
      "trial: 4, iter: 8000, curr loss: 1.3863615989685059, avg loss: 1.3863208228349686\n",
      "trial: 4, iter: 8200, curr loss: 1.3861494064331055, avg loss: 1.386295846104622\n",
      "trial: 4, iter: 8400, curr loss: 1.3862755298614502, avg loss: 1.3863081765174865\n",
      "trial: 4, iter: 8600, curr loss: 1.3863041400909424, avg loss: 1.3863116359710694\n",
      "trial: 4, iter: 8800, curr loss: 1.3861160278320312, avg loss: 1.386307944059372\n",
      "trial: 4, iter: 9000, curr loss: 1.3862812519073486, avg loss: 1.3863132464885712\n",
      "trial: 4, iter: 9200, curr loss: 1.3868273496627808, avg loss: 1.3863145077228547\n",
      "trial: 4, iter: 9400, curr loss: 1.3866029977798462, avg loss: 1.3863477283716201\n",
      "trial: 4, iter: 9600, curr loss: 1.3863815069198608, avg loss: 1.3863131153583526\n",
      "trial: 4, iter: 9800, curr loss: 1.3863531351089478, avg loss: 1.3862950557470322\n",
      "trial: 4, iter: 10000, curr loss: 1.3865647315979004, avg loss: 1.386305974125862\n",
      "trial: 4, iter: 10200, curr loss: 1.3860503435134888, avg loss: 1.386304305791855\n",
      "trial: 4, iter: 10400, curr loss: 1.3865175247192383, avg loss: 1.3862950718402862\n",
      "trial: 4, iter: 10600, curr loss: 1.3862775564193726, avg loss: 1.3863072538375854\n",
      "trial: 4, iter: 10800, curr loss: 1.3863261938095093, avg loss: 1.3862937080860138\n",
      "trial: 4, iter: 11000, curr loss: 1.3862686157226562, avg loss: 1.3862966424226761\n",
      "trial: 4, iter: 11200, curr loss: 1.38620924949646, avg loss: 1.3863040310144426\n",
      "trial: 4, iter: 11400, curr loss: 1.3864195346832275, avg loss: 1.386304339170456\n",
      "trial: 4, iter: 11600, curr loss: 1.3869616985321045, avg loss: 1.3863215589523314\n",
      "trial: 4, iter: 11800, curr loss: 1.3861503601074219, avg loss: 1.3863758009672165\n",
      "trial: 4, iter: 12000, curr loss: 1.386534571647644, avg loss: 1.3863647347688675\n",
      "trial: 4, iter: 12200, curr loss: 1.3859949111938477, avg loss: 1.386325690150261\n",
      "trial: 4, iter: 12400, curr loss: 1.386440634727478, avg loss: 1.386365715265274\n",
      "trial: 4, iter: 12600, curr loss: 1.3864284753799438, avg loss: 1.3863238131999969\n",
      "trial: 4, iter: 12800, curr loss: 1.3864189386367798, avg loss: 1.386322768330574\n",
      "trial: 4, iter: 13000, curr loss: 1.386216163635254, avg loss: 1.3863153195381164\n",
      "trial: 4, iter: 13200, curr loss: 1.3865548372268677, avg loss: 1.3862952131032944\n",
      "trial: 4, iter: 13400, curr loss: 1.3862769603729248, avg loss: 1.38629299223423\n",
      "trial: 4, iter: 13600, curr loss: 1.386630654335022, avg loss: 1.3862894070148468\n",
      "trial: 4, iter: 13800, curr loss: 1.3862632513046265, avg loss: 1.3863031893968583\n",
      "trial: 4, iter: 14000, curr loss: 1.386215329170227, avg loss: 1.3863115966320039\n",
      "trial: 4, iter: 14200, curr loss: 1.386275053024292, avg loss: 1.3863135969638825\n",
      "trial: 4, iter: 14400, curr loss: 1.3863407373428345, avg loss: 1.3863015776872636\n",
      "trial: 4, iter: 14600, curr loss: 1.386073112487793, avg loss: 1.386276851296425\n",
      "trial: 4, iter: 14800, curr loss: 1.386269450187683, avg loss: 1.3863074839115144\n",
      "trial: 4, iter: 15000, curr loss: 1.3859022855758667, avg loss: 1.3862905138731003\n",
      "trial: 4, iter: 15200, curr loss: 1.3861467838287354, avg loss: 1.3862891060113907\n",
      "trial: 4, iter: 15400, curr loss: 1.3862857818603516, avg loss: 1.3863291376829148\n",
      "trial: 4, iter: 15600, curr loss: 1.3862112760543823, avg loss: 1.3862940680980682\n",
      "trial: 4, ldr: -0.0021014069207012653\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387211561203003, avg loss: 1.3873932319879532\n",
      "trial: 5, iter: 400, curr loss: 1.3874588012695312, avg loss: 1.3866421777009963\n",
      "trial: 5, iter: 600, curr loss: 1.3864741325378418, avg loss: 1.3867323750257492\n",
      "trial: 5, iter: 800, curr loss: 1.38624107837677, avg loss: 1.3865608149766921\n",
      "trial: 5, iter: 1000, curr loss: 1.3865774869918823, avg loss: 1.3866319561004639\n",
      "trial: 5, iter: 1200, curr loss: 1.3875946998596191, avg loss: 1.3864798903465272\n",
      "trial: 5, iter: 1400, curr loss: 1.3876409530639648, avg loss: 1.3863975208997728\n",
      "trial: 5, iter: 1600, curr loss: 1.3857234716415405, avg loss: 1.3864615535736085\n",
      "trial: 5, iter: 1800, curr loss: 1.3863555192947388, avg loss: 1.386452504992485\n",
      "trial: 5, iter: 2000, curr loss: 1.3857096433639526, avg loss: 1.3863654744625091\n",
      "trial: 5, iter: 2200, curr loss: 1.3846826553344727, avg loss: 1.3862668532133102\n",
      "trial: 5, iter: 2400, curr loss: 1.38588285446167, avg loss: 1.3865329933166504\n",
      "trial: 5, iter: 2600, curr loss: 1.3854843378067017, avg loss: 1.3862838965654374\n",
      "trial: 5, iter: 2800, curr loss: 1.3867233991622925, avg loss: 1.3864480394124985\n",
      "trial: 5, iter: 3000, curr loss: 1.3862602710723877, avg loss: 1.3863779801130294\n",
      "trial: 5, iter: 3200, curr loss: 1.3861819505691528, avg loss: 1.3863766568899154\n",
      "trial: 5, iter: 3400, curr loss: 1.3864617347717285, avg loss: 1.386296117901802\n",
      "trial: 5, iter: 3600, curr loss: 1.386204481124878, avg loss: 1.3863107252120972\n",
      "trial: 5, iter: 3800, curr loss: 1.3870054483413696, avg loss: 1.386271092891693\n",
      "trial: 5, iter: 4000, curr loss: 1.3852055072784424, avg loss: 1.3863229525089265\n",
      "trial: 5, iter: 4200, curr loss: 1.386385440826416, avg loss: 1.3863348680734635\n",
      "trial: 5, iter: 4400, curr loss: 1.3857625722885132, avg loss: 1.3862951481342316\n",
      "trial: 5, iter: 4600, curr loss: 1.3872640132904053, avg loss: 1.3862690150737762\n",
      "trial: 5, iter: 4800, curr loss: 1.3873504400253296, avg loss: 1.3862720876932144\n",
      "trial: 5, iter: 5000, curr loss: 1.386098861694336, avg loss: 1.3864260911941528\n",
      "trial: 5, iter: 5200, curr loss: 1.386932611465454, avg loss: 1.386377718448639\n",
      "trial: 5, iter: 5400, curr loss: 1.3867686986923218, avg loss: 1.3863190239667893\n",
      "trial: 5, iter: 5600, curr loss: 1.3862717151641846, avg loss: 1.3863713139295577\n",
      "trial: 5, iter: 5800, curr loss: 1.3863002061843872, avg loss: 1.3863522732257842\n",
      "trial: 5, iter: 6000, curr loss: 1.3862850666046143, avg loss: 1.3862899589538573\n",
      "trial: 5, iter: 6200, curr loss: 1.3862046003341675, avg loss: 1.3862981981039046\n",
      "trial: 5, iter: 6400, curr loss: 1.3860944509506226, avg loss: 1.3863145971298219\n",
      "trial: 5, iter: 6600, curr loss: 1.3866654634475708, avg loss: 1.38627736389637\n",
      "trial: 5, iter: 6800, curr loss: 1.3868221044540405, avg loss: 1.3863174825906754\n",
      "trial: 5, iter: 7000, curr loss: 1.3865140676498413, avg loss: 1.386309059858322\n",
      "trial: 5, iter: 7200, curr loss: 1.3862608671188354, avg loss: 1.386334388256073\n",
      "trial: 5, iter: 7400, curr loss: 1.3862168788909912, avg loss: 1.3862990093231202\n",
      "trial: 5, iter: 7600, curr loss: 1.3865771293640137, avg loss: 1.3862814551591873\n",
      "trial: 5, iter: 7800, curr loss: 1.3867852687835693, avg loss: 1.3863182908296585\n",
      "trial: 5, iter: 8000, curr loss: 1.3862709999084473, avg loss: 1.3863210850954055\n",
      "trial: 5, iter: 8200, curr loss: 1.3864754438400269, avg loss: 1.386310349702835\n",
      "trial: 5, iter: 8400, curr loss: 1.3858696222305298, avg loss: 1.3863002842664718\n",
      "trial: 5, iter: 8600, curr loss: 1.3870047330856323, avg loss: 1.3862768757343291\n",
      "trial: 5, iter: 8800, curr loss: 1.3859481811523438, avg loss: 1.3862728089094163\n",
      "trial: 5, iter: 9000, curr loss: 1.3867549896240234, avg loss: 1.386316821575165\n",
      "trial: 5, iter: 9200, curr loss: 1.3852200508117676, avg loss: 1.3863051927089691\n",
      "trial: 5, iter: 9400, curr loss: 1.38559889793396, avg loss: 1.3863008403778077\n",
      "trial: 5, iter: 9600, curr loss: 1.386419653892517, avg loss: 1.3863821291923524\n",
      "trial: 5, iter: 9800, curr loss: 1.3861706256866455, avg loss: 1.3863200849294663\n",
      "trial: 5, iter: 10000, curr loss: 1.3869342803955078, avg loss: 1.3862971311807633\n",
      "trial: 5, iter: 10200, curr loss: 1.3865344524383545, avg loss: 1.3862988770008087\n",
      "trial: 5, iter: 10400, curr loss: 1.385859727859497, avg loss: 1.386297641992569\n",
      "trial: 5, iter: 10600, curr loss: 1.3860807418823242, avg loss: 1.3863155156373979\n",
      "trial: 5, iter: 10800, curr loss: 1.386077880859375, avg loss: 1.3863301664590835\n",
      "trial: 5, iter: 11000, curr loss: 1.3862440586090088, avg loss: 1.386325359940529\n",
      "trial: 5, iter: 11200, curr loss: 1.3862625360488892, avg loss: 1.3863045245409011\n",
      "trial: 5, iter: 11400, curr loss: 1.3862431049346924, avg loss: 1.386283289194107\n",
      "trial: 5, iter: 11600, curr loss: 1.3867158889770508, avg loss: 1.3862884598970413\n",
      "trial: 5, iter: 11800, curr loss: 1.3874152898788452, avg loss: 1.3863045048713685\n",
      "trial: 5, iter: 12000, curr loss: 1.3861130475997925, avg loss: 1.3863919347524643\n",
      "trial: 5, iter: 12200, curr loss: 1.3861726522445679, avg loss: 1.386278322339058\n",
      "trial: 5, iter: 12400, curr loss: 1.3869547843933105, avg loss: 1.38633374273777\n",
      "trial: 5, iter: 12600, curr loss: 1.386957049369812, avg loss: 1.3863053333759308\n",
      "trial: 5, iter: 12800, curr loss: 1.385974407196045, avg loss: 1.3863068813085555\n",
      "trial: 5, iter: 13000, curr loss: 1.3869976997375488, avg loss: 1.386323071718216\n",
      "trial: 5, iter: 13200, curr loss: 1.386331558227539, avg loss: 1.386325739622116\n",
      "trial: 5, iter: 13400, curr loss: 1.3859939575195312, avg loss: 1.386307333111763\n",
      "trial: 5, iter: 13600, curr loss: 1.38625967502594, avg loss: 1.3863110488653183\n",
      "trial: 5, iter: 13800, curr loss: 1.3863693475723267, avg loss: 1.3863252985477448\n",
      "trial: 5, iter: 14000, curr loss: 1.3863608837127686, avg loss: 1.3863077813386917\n",
      "trial: 5, iter: 14200, curr loss: 1.3860677480697632, avg loss: 1.3862610208988189\n",
      "trial: 5, iter: 14400, curr loss: 1.3870859146118164, avg loss: 1.3863021302223206\n",
      "trial: 5, iter: 14600, curr loss: 1.3865658044815063, avg loss: 1.3863075113296508\n",
      "trial: 5, iter: 14800, curr loss: 1.3864182233810425, avg loss: 1.386320035457611\n",
      "trial: 5, iter: 15000, curr loss: 1.3862251043319702, avg loss: 1.3863121807575225\n",
      "trial: 5, iter: 15200, curr loss: 1.386311411857605, avg loss: 1.3863019466400146\n",
      "trial: 5, iter: 15400, curr loss: 1.3861085176467896, avg loss: 1.386312700510025\n",
      "trial: 5, iter: 15600, curr loss: 1.3862786293029785, avg loss: 1.3862992852926255\n",
      "trial: 5, ldr: -0.0016350619262084365\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0007367599465474526\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3865102529525757, avg loss: 1.3874025362730027\n",
      "trial: 1, iter: 400, curr loss: 1.3887135982513428, avg loss: 1.3866722708940507\n",
      "trial: 1, iter: 600, curr loss: 1.3857991695404053, avg loss: 1.3865518450737\n",
      "trial: 1, iter: 800, curr loss: 1.3836921453475952, avg loss: 1.3863433802127838\n",
      "trial: 1, iter: 1000, curr loss: 1.3858790397644043, avg loss: 1.386611180305481\n",
      "trial: 1, iter: 1200, curr loss: 1.3873361349105835, avg loss: 1.3864694041013719\n",
      "trial: 1, iter: 1400, curr loss: 1.3865141868591309, avg loss: 1.386417109966278\n",
      "trial: 1, iter: 1600, curr loss: 1.3865444660186768, avg loss: 1.386451136469841\n",
      "trial: 1, iter: 1800, curr loss: 1.3865834474563599, avg loss: 1.3864130771160126\n",
      "trial: 1, iter: 2000, curr loss: 1.3887580633163452, avg loss: 1.386435484290123\n",
      "trial: 1, iter: 2200, curr loss: 1.3859713077545166, avg loss: 1.3863240694999694\n",
      "trial: 1, iter: 2400, curr loss: 1.3869167566299438, avg loss: 1.3864081543684006\n",
      "trial: 1, iter: 2600, curr loss: 1.387250542640686, avg loss: 1.3863724821805954\n",
      "trial: 1, iter: 2800, curr loss: 1.3863462209701538, avg loss: 1.3864513283967972\n",
      "trial: 1, iter: 3000, curr loss: 1.38671875, avg loss: 1.3863157993555069\n",
      "trial: 1, iter: 3200, curr loss: 1.3880313634872437, avg loss: 1.3863878816366195\n",
      "trial: 1, iter: 3400, curr loss: 1.3865238428115845, avg loss: 1.3863909298181534\n",
      "trial: 1, iter: 3600, curr loss: 1.385834813117981, avg loss: 1.3863705694675446\n",
      "trial: 1, iter: 3800, curr loss: 1.3862969875335693, avg loss: 1.3863901060819626\n",
      "trial: 1, iter: 4000, curr loss: 1.3865605592727661, avg loss: 1.3863153052330017\n",
      "trial: 1, iter: 4200, curr loss: 1.3865392208099365, avg loss: 1.38631691634655\n",
      "trial: 1, iter: 4400, curr loss: 1.3860204219818115, avg loss: 1.3863002794981003\n",
      "trial: 1, iter: 4600, curr loss: 1.3858591318130493, avg loss: 1.3863173735141754\n",
      "trial: 1, iter: 4800, curr loss: 1.3857285976409912, avg loss: 1.3863409042358399\n",
      "trial: 1, iter: 5000, curr loss: 1.3864126205444336, avg loss: 1.3863311147689819\n",
      "trial: 1, iter: 5200, curr loss: 1.3863980770111084, avg loss: 1.3863151502609252\n",
      "trial: 1, iter: 5400, curr loss: 1.3862850666046143, avg loss: 1.3862904292345046\n",
      "trial: 1, iter: 5600, curr loss: 1.3862134218215942, avg loss: 1.386340616941452\n",
      "trial: 1, iter: 5800, curr loss: 1.3865467309951782, avg loss: 1.3863060188293457\n",
      "trial: 1, iter: 6000, curr loss: 1.3868491649627686, avg loss: 1.3862788033485414\n",
      "trial: 1, iter: 6200, curr loss: 1.385977029800415, avg loss: 1.3863350641727448\n",
      "trial: 1, iter: 6400, curr loss: 1.3857958316802979, avg loss: 1.3863011294603347\n",
      "trial: 1, iter: 6600, curr loss: 1.386175274848938, avg loss: 1.386362953186035\n",
      "trial: 1, iter: 6800, curr loss: 1.3860511779785156, avg loss: 1.3863415616750716\n",
      "trial: 1, iter: 7000, curr loss: 1.3870363235473633, avg loss: 1.3864036816358567\n",
      "trial: 1, iter: 7200, curr loss: 1.386070728302002, avg loss: 1.386333014369011\n",
      "trial: 1, iter: 7400, curr loss: 1.3860318660736084, avg loss: 1.3863068336248399\n",
      "trial: 1, iter: 7600, curr loss: 1.3862674236297607, avg loss: 1.3863172781467439\n",
      "trial: 1, iter: 7800, curr loss: 1.3853098154067993, avg loss: 1.386232203245163\n",
      "trial: 1, iter: 8000, curr loss: 1.3865081071853638, avg loss: 1.3863843595981598\n",
      "trial: 1, iter: 8200, curr loss: 1.386473536491394, avg loss: 1.3862946474552154\n",
      "trial: 1, iter: 8400, curr loss: 1.3856631517410278, avg loss: 1.3863174891471863\n",
      "trial: 1, iter: 8600, curr loss: 1.386596918106079, avg loss: 1.3863071537017821\n",
      "trial: 1, iter: 8800, curr loss: 1.386575698852539, avg loss: 1.386325945854187\n",
      "trial: 1, iter: 9000, curr loss: 1.3865357637405396, avg loss: 1.3862997990846635\n",
      "trial: 1, iter: 9200, curr loss: 1.3862165212631226, avg loss: 1.3863160890340804\n",
      "trial: 1, iter: 9400, curr loss: 1.3867326974868774, avg loss: 1.3862983018159867\n",
      "trial: 1, iter: 9600, curr loss: 1.3863990306854248, avg loss: 1.386292062997818\n",
      "trial: 1, iter: 9800, curr loss: 1.3863731622695923, avg loss: 1.3863744807243348\n",
      "trial: 1, iter: 10000, curr loss: 1.3865123987197876, avg loss: 1.3863252168893814\n",
      "trial: 1, iter: 10200, curr loss: 1.3858487606048584, avg loss: 1.3863064551353455\n",
      "trial: 1, iter: 10400, curr loss: 1.3862524032592773, avg loss: 1.3863078743219375\n",
      "trial: 1, iter: 10600, curr loss: 1.3863379955291748, avg loss: 1.38630923807621\n",
      "trial: 1, iter: 10800, curr loss: 1.3863558769226074, avg loss: 1.3862901479005814\n",
      "trial: 1, iter: 11000, curr loss: 1.387032151222229, avg loss: 1.3863143938779832\n",
      "trial: 1, iter: 11200, curr loss: 1.385825514793396, avg loss: 1.386379063129425\n",
      "trial: 1, iter: 11400, curr loss: 1.3863285779953003, avg loss: 1.386303755044937\n",
      "trial: 1, iter: 11600, curr loss: 1.3864185810089111, avg loss: 1.38636723279953\n",
      "trial: 1, iter: 11800, curr loss: 1.3864920139312744, avg loss: 1.3862872159481048\n",
      "trial: 1, iter: 12000, curr loss: 1.3858987092971802, avg loss: 1.3863010591268539\n",
      "trial: 1, iter: 12200, curr loss: 1.3862437009811401, avg loss: 1.3863076001405716\n",
      "trial: 1, iter: 12400, curr loss: 1.386254072189331, avg loss: 1.3863074880838395\n",
      "trial: 1, iter: 12600, curr loss: 1.3861234188079834, avg loss: 1.3862886732816697\n",
      "trial: 1, iter: 12800, curr loss: 1.3863991498947144, avg loss: 1.3862894701957702\n",
      "trial: 1, iter: 13000, curr loss: 1.3859845399856567, avg loss: 1.3863027530908585\n",
      "trial: 1, iter: 13200, curr loss: 1.3860243558883667, avg loss: 1.3863096225261688\n",
      "trial: 1, iter: 13400, curr loss: 1.3863606452941895, avg loss: 1.3863053649663926\n",
      "trial: 1, iter: 13600, curr loss: 1.3862284421920776, avg loss: 1.3862960410118104\n",
      "trial: 1, iter: 13800, curr loss: 1.3862364292144775, avg loss: 1.3862960129976272\n",
      "trial: 1, iter: 14000, curr loss: 1.3862438201904297, avg loss: 1.3863101822137833\n",
      "trial: 1, iter: 14200, curr loss: 1.386683702468872, avg loss: 1.3862896692752837\n",
      "trial: 1, iter: 14400, curr loss: 1.3862940073013306, avg loss: 1.386295285820961\n",
      "trial: 1, iter: 14600, curr loss: 1.3862944841384888, avg loss: 1.3862946009635926\n",
      "trial: 1, iter: 14800, curr loss: 1.3862944841384888, avg loss: 1.3862948578596115\n",
      "trial: 1, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.3862944555282593\n",
      "trial: 1, iter: 15200, curr loss: 1.3862782716751099, avg loss: 1.386294471025467\n",
      "trial: 1, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294754743576\n",
      "trial: 1, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862947964668273\n",
      "trial: 1, ldr: 1.506162661257804e-08\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3869662284851074, avg loss: 1.3876511424779892\n",
      "trial: 2, iter: 400, curr loss: 1.3875070810317993, avg loss: 1.386687500476837\n",
      "trial: 2, iter: 600, curr loss: 1.389326810836792, avg loss: 1.3864750206470489\n",
      "trial: 2, iter: 800, curr loss: 1.386968970298767, avg loss: 1.3868833541870118\n",
      "trial: 2, iter: 1000, curr loss: 1.3865993022918701, avg loss: 1.38657252907753\n",
      "trial: 2, iter: 1200, curr loss: 1.3862276077270508, avg loss: 1.3865222257375718\n",
      "trial: 2, iter: 1400, curr loss: 1.3860626220703125, avg loss: 1.3864430397748948\n",
      "trial: 2, iter: 1600, curr loss: 1.3894503116607666, avg loss: 1.386493130326271\n",
      "trial: 2, iter: 1800, curr loss: 1.387844204902649, avg loss: 1.3864365744590759\n",
      "trial: 2, iter: 2000, curr loss: 1.3856403827667236, avg loss: 1.3865604519844055\n",
      "trial: 2, iter: 2200, curr loss: 1.3881776332855225, avg loss: 1.3865268784761429\n",
      "trial: 2, iter: 2400, curr loss: 1.387175440788269, avg loss: 1.3864735436439515\n",
      "trial: 2, iter: 2600, curr loss: 1.3869385719299316, avg loss: 1.386404748558998\n",
      "trial: 2, iter: 2800, curr loss: 1.3861267566680908, avg loss: 1.3863729798793794\n",
      "trial: 2, iter: 3000, curr loss: 1.3873186111450195, avg loss: 1.3864195942878723\n",
      "trial: 2, iter: 3200, curr loss: 1.3875577449798584, avg loss: 1.386347504258156\n",
      "trial: 2, iter: 3400, curr loss: 1.3871021270751953, avg loss: 1.3863836538791656\n",
      "trial: 2, iter: 3600, curr loss: 1.3858492374420166, avg loss: 1.3863360273838043\n",
      "trial: 2, iter: 3800, curr loss: 1.387158751487732, avg loss: 1.3863296180963516\n",
      "trial: 2, iter: 4000, curr loss: 1.3864504098892212, avg loss: 1.3863593137264252\n",
      "trial: 2, iter: 4200, curr loss: 1.3870866298675537, avg loss: 1.3863285022974015\n",
      "trial: 2, iter: 4400, curr loss: 1.3867313861846924, avg loss: 1.3863201051950456\n",
      "trial: 2, iter: 4600, curr loss: 1.3862534761428833, avg loss: 1.3863271600008011\n",
      "trial: 2, iter: 4800, curr loss: 1.3855321407318115, avg loss: 1.3863113206624984\n",
      "trial: 2, iter: 5000, curr loss: 1.3861682415008545, avg loss: 1.3863058722019195\n",
      "trial: 2, iter: 5200, curr loss: 1.3861994743347168, avg loss: 1.3862943428754806\n",
      "trial: 2, iter: 5400, curr loss: 1.3860762119293213, avg loss: 1.3863461297750472\n",
      "trial: 2, iter: 5600, curr loss: 1.386340618133545, avg loss: 1.3863067299127578\n",
      "trial: 2, iter: 5800, curr loss: 1.3864028453826904, avg loss: 1.3862879359722138\n",
      "trial: 2, iter: 6000, curr loss: 1.3863892555236816, avg loss: 1.3863383889198304\n",
      "trial: 2, iter: 6200, curr loss: 1.3867038488388062, avg loss: 1.3863119584321977\n",
      "trial: 2, iter: 6400, curr loss: 1.386112928390503, avg loss: 1.3863090229034425\n",
      "trial: 2, iter: 6600, curr loss: 1.3862332105636597, avg loss: 1.3863207221031189\n",
      "trial: 2, iter: 6800, curr loss: 1.3863178491592407, avg loss: 1.3863160675764084\n",
      "trial: 2, iter: 7000, curr loss: 1.3862963914871216, avg loss: 1.386308507323265\n",
      "trial: 2, iter: 7200, curr loss: 1.386344075202942, avg loss: 1.386303689479828\n",
      "trial: 2, iter: 7400, curr loss: 1.3862375020980835, avg loss: 1.38630444586277\n",
      "trial: 2, iter: 7600, curr loss: 1.386256217956543, avg loss: 1.386299533843994\n",
      "trial: 2, iter: 7800, curr loss: 1.3863126039505005, avg loss: 1.386303552389145\n",
      "trial: 2, iter: 8000, curr loss: 1.3860708475112915, avg loss: 1.386297277212143\n",
      "trial: 2, iter: 8200, curr loss: 1.386336088180542, avg loss: 1.3863318359851837\n",
      "trial: 2, iter: 8400, curr loss: 1.385683298110962, avg loss: 1.3864344495534897\n",
      "trial: 2, iter: 8600, curr loss: 1.3862427473068237, avg loss: 1.386349892616272\n",
      "trial: 2, iter: 8800, curr loss: 1.386702060699463, avg loss: 1.3863260477781296\n",
      "trial: 2, iter: 9000, curr loss: 1.386286735534668, avg loss: 1.3863457947969438\n",
      "trial: 2, iter: 9200, curr loss: 1.3860517740249634, avg loss: 1.3862803637981416\n",
      "trial: 2, iter: 9400, curr loss: 1.3866584300994873, avg loss: 1.3863114464282988\n",
      "trial: 2, iter: 9600, curr loss: 1.3864574432373047, avg loss: 1.3863330334424973\n",
      "trial: 2, iter: 9800, curr loss: 1.386845350265503, avg loss: 1.3862872260808945\n",
      "trial: 2, iter: 10000, curr loss: 1.3870147466659546, avg loss: 1.3863191598653792\n",
      "trial: 2, iter: 10200, curr loss: 1.3864132165908813, avg loss: 1.3863135802745818\n",
      "trial: 2, iter: 10400, curr loss: 1.3864010572433472, avg loss: 1.3862897235155105\n",
      "trial: 2, iter: 10600, curr loss: 1.3860604763031006, avg loss: 1.3863049000501633\n",
      "trial: 2, iter: 10800, curr loss: 1.3861149549484253, avg loss: 1.386307184100151\n",
      "trial: 2, iter: 11000, curr loss: 1.3856903314590454, avg loss: 1.3862978267669677\n",
      "trial: 2, iter: 11200, curr loss: 1.386115550994873, avg loss: 1.3862964391708374\n",
      "trial: 2, iter: 11400, curr loss: 1.3862491846084595, avg loss: 1.3863002723455429\n",
      "trial: 2, iter: 11600, curr loss: 1.3863451480865479, avg loss: 1.3862921673059463\n",
      "trial: 2, iter: 11800, curr loss: 1.3863221406936646, avg loss: 1.386319529414177\n",
      "trial: 2, iter: 12000, curr loss: 1.386226773262024, avg loss: 1.3862969863414765\n",
      "trial: 2, iter: 12200, curr loss: 1.3861347436904907, avg loss: 1.386277238726616\n",
      "trial: 2, iter: 12400, curr loss: 1.3862481117248535, avg loss: 1.3863008564710617\n",
      "trial: 2, iter: 12600, curr loss: 1.3863370418548584, avg loss: 1.386296632885933\n",
      "trial: 2, iter: 12800, curr loss: 1.3862814903259277, avg loss: 1.3863058441877365\n",
      "trial: 2, iter: 13000, curr loss: 1.3867061138153076, avg loss: 1.3862815952301026\n",
      "trial: 2, iter: 13200, curr loss: 1.3862971067428589, avg loss: 1.386303601861\n",
      "trial: 2, iter: 13400, curr loss: 1.3860894441604614, avg loss: 1.3862983250617982\n",
      "trial: 2, iter: 13600, curr loss: 1.3862468004226685, avg loss: 1.3863047802448272\n",
      "trial: 2, iter: 13800, curr loss: 1.3862972259521484, avg loss: 1.3862843143939971\n",
      "trial: 2, iter: 14000, curr loss: 1.3864911794662476, avg loss: 1.3863199669122697\n",
      "trial: 2, iter: 14200, curr loss: 1.386255145072937, avg loss: 1.3863090080022813\n",
      "trial: 2, iter: 14400, curr loss: 1.386559247970581, avg loss: 1.3862973326444625\n",
      "trial: 2, iter: 14600, curr loss: 1.3862711191177368, avg loss: 1.3862919503450393\n",
      "trial: 2, iter: 14800, curr loss: 1.3863539695739746, avg loss: 1.3863164293766022\n",
      "trial: 2, iter: 15000, curr loss: 1.387256383895874, avg loss: 1.386282063126564\n",
      "trial: 2, iter: 15200, curr loss: 1.3860849142074585, avg loss: 1.3863041198253632\n",
      "trial: 2, iter: 15400, curr loss: 1.3863778114318848, avg loss: 1.3863080328702926\n",
      "trial: 2, iter: 15600, curr loss: 1.3861663341522217, avg loss: 1.3862945193052292\n",
      "trial: 2, ldr: 0.0004940857761539519\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.384902000427246, avg loss: 1.3873919969797135\n",
      "trial: 3, iter: 400, curr loss: 1.386746883392334, avg loss: 1.3867834216356278\n",
      "trial: 3, iter: 600, curr loss: 1.3863059282302856, avg loss: 1.386667672395706\n",
      "trial: 3, iter: 800, curr loss: 1.3857508897781372, avg loss: 1.3864683520793915\n",
      "trial: 3, iter: 1000, curr loss: 1.386945366859436, avg loss: 1.3864195865392686\n",
      "trial: 3, iter: 1200, curr loss: 1.3840999603271484, avg loss: 1.3864570516347885\n",
      "trial: 3, iter: 1400, curr loss: 1.387506127357483, avg loss: 1.3865196460485458\n",
      "trial: 3, iter: 1600, curr loss: 1.3862969875335693, avg loss: 1.386434282064438\n",
      "trial: 3, iter: 1800, curr loss: 1.3859047889709473, avg loss: 1.3863499838113784\n",
      "trial: 3, iter: 2000, curr loss: 1.3866993188858032, avg loss: 1.3865101099014283\n",
      "trial: 3, iter: 2200, curr loss: 1.3853342533111572, avg loss: 1.3862906175851821\n",
      "trial: 3, iter: 2400, curr loss: 1.387294888496399, avg loss: 1.3863627272844314\n",
      "trial: 3, iter: 2600, curr loss: 1.3887238502502441, avg loss: 1.3864233255386353\n",
      "trial: 3, iter: 2800, curr loss: 1.3869407176971436, avg loss: 1.3863722789287567\n",
      "trial: 3, iter: 3000, curr loss: 1.3847380876541138, avg loss: 1.3863920468091964\n",
      "trial: 3, iter: 3200, curr loss: 1.3880047798156738, avg loss: 1.386465961933136\n",
      "trial: 3, iter: 3400, curr loss: 1.3850855827331543, avg loss: 1.386471980214119\n",
      "trial: 3, iter: 3600, curr loss: 1.385711431503296, avg loss: 1.3864341866970062\n",
      "trial: 3, iter: 3800, curr loss: 1.3857395648956299, avg loss: 1.386358540058136\n",
      "trial: 3, iter: 4000, curr loss: 1.3871080875396729, avg loss: 1.3863893365859985\n",
      "trial: 3, iter: 4200, curr loss: 1.386692762374878, avg loss: 1.386327887773514\n",
      "trial: 3, iter: 4400, curr loss: 1.3865216970443726, avg loss: 1.3863650619983674\n",
      "trial: 3, iter: 4600, curr loss: 1.3866078853607178, avg loss: 1.386339800953865\n",
      "trial: 3, iter: 4800, curr loss: 1.3858400583267212, avg loss: 1.3863021671772002\n",
      "trial: 3, iter: 5000, curr loss: 1.3864177465438843, avg loss: 1.3863234740495682\n",
      "trial: 3, iter: 5200, curr loss: 1.3859602212905884, avg loss: 1.3863289946317672\n",
      "trial: 3, iter: 5400, curr loss: 1.3862913846969604, avg loss: 1.3863398814201355\n",
      "trial: 3, iter: 5600, curr loss: 1.385933518409729, avg loss: 1.38632976770401\n",
      "trial: 3, iter: 5800, curr loss: 1.3858397006988525, avg loss: 1.3863075280189514\n",
      "trial: 3, iter: 6000, curr loss: 1.386465072631836, avg loss: 1.3863626545667649\n",
      "trial: 3, iter: 6200, curr loss: 1.3862831592559814, avg loss: 1.3863744789361954\n",
      "trial: 3, iter: 6400, curr loss: 1.387036919593811, avg loss: 1.386341940164566\n",
      "trial: 3, iter: 6600, curr loss: 1.3864113092422485, avg loss: 1.3863259959220886\n",
      "trial: 3, iter: 6800, curr loss: 1.386706829071045, avg loss: 1.386304522752762\n",
      "trial: 3, iter: 7000, curr loss: 1.3864119052886963, avg loss: 1.3863067293167115\n",
      "trial: 3, iter: 7200, curr loss: 1.3860867023468018, avg loss: 1.386321268081665\n",
      "trial: 3, iter: 7400, curr loss: 1.386375904083252, avg loss: 1.3863037252426147\n",
      "trial: 3, iter: 7600, curr loss: 1.3859353065490723, avg loss: 1.3863304352760315\n",
      "trial: 3, iter: 7800, curr loss: 1.387049913406372, avg loss: 1.386320834159851\n",
      "trial: 3, iter: 8000, curr loss: 1.3859477043151855, avg loss: 1.3863326579332351\n",
      "trial: 3, iter: 8200, curr loss: 1.3864853382110596, avg loss: 1.3863199687004089\n",
      "trial: 3, iter: 8400, curr loss: 1.3865125179290771, avg loss: 1.386269017457962\n",
      "trial: 3, iter: 8600, curr loss: 1.3866238594055176, avg loss: 1.3863091492652893\n",
      "trial: 3, iter: 8800, curr loss: 1.3864006996154785, avg loss: 1.3864235562086105\n",
      "trial: 3, iter: 9000, curr loss: 1.3875235319137573, avg loss: 1.3863059574365615\n",
      "trial: 3, iter: 9200, curr loss: 1.3857483863830566, avg loss: 1.3863004845380784\n",
      "trial: 3, iter: 9400, curr loss: 1.3863548040390015, avg loss: 1.3863210088014604\n",
      "trial: 3, iter: 9600, curr loss: 1.3866313695907593, avg loss: 1.3863193970918655\n",
      "trial: 3, iter: 9800, curr loss: 1.3860446214675903, avg loss: 1.3863870316743852\n",
      "trial: 3, iter: 10000, curr loss: 1.386263370513916, avg loss: 1.3863395708799362\n",
      "trial: 3, iter: 10200, curr loss: 1.3866392374038696, avg loss: 1.386319574713707\n",
      "trial: 3, iter: 10400, curr loss: 1.3864659070968628, avg loss: 1.3863108724355697\n",
      "trial: 3, iter: 10600, curr loss: 1.3863205909729004, avg loss: 1.386266120672226\n",
      "trial: 3, iter: 10800, curr loss: 1.3859859704971313, avg loss: 1.3863422644138337\n",
      "trial: 3, iter: 11000, curr loss: 1.386225700378418, avg loss: 1.3862975072860717\n",
      "trial: 3, iter: 11200, curr loss: 1.3865381479263306, avg loss: 1.3863365733623505\n",
      "trial: 3, iter: 11400, curr loss: 1.3859442472457886, avg loss: 1.3862986218929292\n",
      "trial: 3, iter: 11600, curr loss: 1.3864097595214844, avg loss: 1.386285880804062\n",
      "trial: 3, iter: 11800, curr loss: 1.3867590427398682, avg loss: 1.3863242822885513\n",
      "trial: 3, iter: 12000, curr loss: 1.386823058128357, avg loss: 1.3862960636615753\n",
      "trial: 3, iter: 12200, curr loss: 1.385947346687317, avg loss: 1.3863027995824815\n",
      "trial: 3, iter: 12400, curr loss: 1.3859754800796509, avg loss: 1.386309276819229\n",
      "trial: 3, iter: 12600, curr loss: 1.3863962888717651, avg loss: 1.3863032048940658\n",
      "trial: 3, iter: 12800, curr loss: 1.3864688873291016, avg loss: 1.3863100188970565\n",
      "trial: 3, iter: 13000, curr loss: 1.3862810134887695, avg loss: 1.386305883526802\n",
      "trial: 3, iter: 13200, curr loss: 1.3864432573318481, avg loss: 1.3862927442789077\n",
      "trial: 3, iter: 13400, curr loss: 1.3862273693084717, avg loss: 1.386293688416481\n",
      "trial: 3, iter: 13600, curr loss: 1.3861628770828247, avg loss: 1.3863021141290666\n",
      "trial: 3, iter: 13800, curr loss: 1.3862700462341309, avg loss: 1.3863002693653106\n",
      "trial: 3, iter: 14000, curr loss: 1.3862426280975342, avg loss: 1.3862917125225067\n",
      "trial: 3, iter: 14200, curr loss: 1.3862907886505127, avg loss: 1.3863057780265808\n",
      "trial: 3, iter: 14400, curr loss: 1.3862550258636475, avg loss: 1.3862944436073303\n",
      "trial: 3, iter: 14600, curr loss: 1.386258840560913, avg loss: 1.3862926471233368\n",
      "trial: 3, iter: 14800, curr loss: 1.3860634565353394, avg loss: 1.38628342628479\n",
      "trial: 3, iter: 15000, curr loss: 1.3862377405166626, avg loss: 1.3863240629434586\n",
      "trial: 3, iter: 15200, curr loss: 1.386269450187683, avg loss: 1.386296371817589\n",
      "trial: 3, iter: 15400, curr loss: 1.3862673044204712, avg loss: 1.3863005924224854\n",
      "trial: 3, iter: 15600, curr loss: 1.386588454246521, avg loss: 1.3863009375333786\n",
      "trial: 3, ldr: 0.000692412257194519\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3870043754577637, avg loss: 1.3873842072486877\n",
      "trial: 4, iter: 400, curr loss: 1.386176586151123, avg loss: 1.3867098951339722\n",
      "trial: 4, iter: 600, curr loss: 1.3846238851547241, avg loss: 1.3864702093601227\n",
      "trial: 4, iter: 800, curr loss: 1.3884905576705933, avg loss: 1.3864776664972305\n",
      "trial: 4, iter: 1000, curr loss: 1.3853932619094849, avg loss: 1.386347616314888\n",
      "trial: 4, iter: 1200, curr loss: 1.3867409229278564, avg loss: 1.386420939564705\n",
      "trial: 4, iter: 1400, curr loss: 1.3865267038345337, avg loss: 1.3865384566783905\n",
      "trial: 4, iter: 1600, curr loss: 1.3865633010864258, avg loss: 1.3864397782087325\n",
      "trial: 4, iter: 1800, curr loss: 1.3861091136932373, avg loss: 1.3864845252037048\n",
      "trial: 4, iter: 2000, curr loss: 1.3858447074890137, avg loss: 1.3863821589946748\n",
      "trial: 4, iter: 2200, curr loss: 1.3851208686828613, avg loss: 1.3862727737426759\n",
      "trial: 4, iter: 2400, curr loss: 1.3860831260681152, avg loss: 1.3864410144090653\n",
      "trial: 4, iter: 2600, curr loss: 1.3846904039382935, avg loss: 1.3863616114854813\n",
      "trial: 4, iter: 2800, curr loss: 1.3866151571273804, avg loss: 1.3864477860927582\n",
      "trial: 4, iter: 3000, curr loss: 1.38640296459198, avg loss: 1.3864184933900834\n",
      "trial: 4, iter: 3200, curr loss: 1.3864655494689941, avg loss: 1.386331154704094\n",
      "trial: 4, iter: 3400, curr loss: 1.3860467672348022, avg loss: 1.3863560271263122\n",
      "trial: 4, iter: 3600, curr loss: 1.3864115476608276, avg loss: 1.386352730989456\n",
      "trial: 4, iter: 3800, curr loss: 1.3859786987304688, avg loss: 1.3864210188388824\n",
      "trial: 4, iter: 4000, curr loss: 1.386577844619751, avg loss: 1.3863029432296754\n",
      "trial: 4, iter: 4200, curr loss: 1.3869754076004028, avg loss: 1.3863610601425171\n",
      "trial: 4, iter: 4400, curr loss: 1.3862296342849731, avg loss: 1.3863255137205124\n",
      "trial: 4, iter: 4600, curr loss: 1.3854860067367554, avg loss: 1.3863405627012253\n",
      "trial: 4, iter: 4800, curr loss: 1.3860812187194824, avg loss: 1.386314561367035\n",
      "trial: 4, iter: 5000, curr loss: 1.386291742324829, avg loss: 1.386363952755928\n",
      "trial: 4, iter: 5200, curr loss: 1.3860489130020142, avg loss: 1.3863197630643844\n",
      "trial: 4, iter: 5400, curr loss: 1.3864010572433472, avg loss: 1.386307419538498\n",
      "trial: 4, iter: 5600, curr loss: 1.3863883018493652, avg loss: 1.3863147288560866\n",
      "trial: 4, iter: 5800, curr loss: 1.3864786624908447, avg loss: 1.386340634226799\n",
      "trial: 4, iter: 6000, curr loss: 1.3863402605056763, avg loss: 1.3863002282381058\n",
      "trial: 4, iter: 6200, curr loss: 1.3861589431762695, avg loss: 1.3863258504867553\n",
      "trial: 4, iter: 6400, curr loss: 1.3863085508346558, avg loss: 1.3863307070732116\n",
      "trial: 4, iter: 6600, curr loss: 1.3866767883300781, avg loss: 1.3863078987598418\n",
      "trial: 4, iter: 6800, curr loss: 1.3859649896621704, avg loss: 1.386294195652008\n",
      "trial: 4, iter: 7000, curr loss: 1.3862944841384888, avg loss: 1.3862758296728135\n",
      "trial: 4, iter: 7200, curr loss: 1.386008858680725, avg loss: 1.3863058573007583\n",
      "trial: 4, iter: 7400, curr loss: 1.3859196901321411, avg loss: 1.386323846578598\n",
      "trial: 4, iter: 7600, curr loss: 1.386193871498108, avg loss: 1.3863078182935715\n",
      "trial: 4, iter: 7800, curr loss: 1.3863290548324585, avg loss: 1.3863041108846665\n",
      "trial: 4, iter: 8000, curr loss: 1.3863087892532349, avg loss: 1.3862996298074721\n",
      "trial: 4, iter: 8200, curr loss: 1.3873385190963745, avg loss: 1.3862852561473846\n",
      "trial: 4, iter: 8400, curr loss: 1.3860268592834473, avg loss: 1.386318942308426\n",
      "trial: 4, iter: 8600, curr loss: 1.386518120765686, avg loss: 1.386298150420189\n",
      "trial: 4, iter: 8800, curr loss: 1.3871841430664062, avg loss: 1.386306688785553\n",
      "trial: 4, iter: 9000, curr loss: 1.3867805004119873, avg loss: 1.3863198941946029\n",
      "trial: 4, iter: 9200, curr loss: 1.3863720893859863, avg loss: 1.3863238024711608\n",
      "trial: 4, iter: 9400, curr loss: 1.3867366313934326, avg loss: 1.3863080060482025\n",
      "trial: 4, iter: 9600, curr loss: 1.3865511417388916, avg loss: 1.386280943751335\n",
      "trial: 4, iter: 9800, curr loss: 1.386041283607483, avg loss: 1.3862732124328614\n",
      "trial: 4, iter: 10000, curr loss: 1.3860969543457031, avg loss: 1.3863322830200195\n",
      "trial: 4, iter: 10200, curr loss: 1.3865203857421875, avg loss: 1.3863122987747192\n",
      "trial: 4, iter: 10400, curr loss: 1.3859577178955078, avg loss: 1.3862985742092133\n",
      "trial: 4, iter: 10600, curr loss: 1.3865982294082642, avg loss: 1.386294083595276\n",
      "trial: 4, iter: 10800, curr loss: 1.386367678642273, avg loss: 1.3863068878650666\n",
      "trial: 4, iter: 11000, curr loss: 1.3863348960876465, avg loss: 1.3862942802906035\n",
      "trial: 4, iter: 11200, curr loss: 1.3862993717193604, avg loss: 1.386300619840622\n",
      "trial: 4, iter: 11400, curr loss: 1.386226773262024, avg loss: 1.3863024413585663\n",
      "trial: 4, iter: 11600, curr loss: 1.386248230934143, avg loss: 1.3863009452819823\n",
      "trial: 4, iter: 11800, curr loss: 1.3864113092422485, avg loss: 1.3862938660383224\n",
      "trial: 4, iter: 12000, curr loss: 1.3863500356674194, avg loss: 1.3862967425584793\n",
      "trial: 4, iter: 12200, curr loss: 1.386251449584961, avg loss: 1.386295199394226\n",
      "trial: 4, iter: 12400, curr loss: 1.386276125907898, avg loss: 1.3862994748353958\n",
      "trial: 4, iter: 12600, curr loss: 1.3862948417663574, avg loss: 1.386294704079628\n",
      "trial: 4, iter: 12800, curr loss: 1.3862981796264648, avg loss: 1.3862946224212647\n",
      "trial: 4, iter: 13000, curr loss: 1.3862946033477783, avg loss: 1.3862947058677673\n",
      "trial: 4, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.3862947189807893\n",
      "trial: 4, iter: 13400, curr loss: 1.3862944841384888, avg loss: 1.3862947672605515\n",
      "trial: 4, iter: 13600, curr loss: 1.3862829208374023, avg loss: 1.3862960457801818\n",
      "trial: 4, iter: 13800, curr loss: 1.3864786624908447, avg loss: 1.386302257180214\n",
      "trial: 4, iter: 14000, curr loss: 1.3862676620483398, avg loss: 1.38630251288414\n",
      "trial: 4, iter: 14200, curr loss: 1.3862991333007812, avg loss: 1.3862966710329057\n",
      "trial: 4, iter: 14400, curr loss: 1.3862812519073486, avg loss: 1.3862949335575103\n",
      "trial: 4, iter: 14600, curr loss: 1.386285424232483, avg loss: 1.386294822692871\n",
      "trial: 4, iter: 14800, curr loss: 1.3862985372543335, avg loss: 1.3862942987680436\n",
      "trial: 4, iter: 15000, curr loss: 1.3863006830215454, avg loss: 1.3862950330972672\n",
      "trial: 4, iter: 15200, curr loss: 1.3862988948822021, avg loss: 1.3862946474552154\n",
      "trial: 4, iter: 15400, curr loss: 1.3863024711608887, avg loss: 1.386294662952423\n",
      "trial: 4, iter: 15600, curr loss: 1.3862656354904175, avg loss: 1.386293932199478\n",
      "trial: 4, ldr: 0.000270432501565665\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3871499300003052, avg loss: 1.3870687568187714\n",
      "trial: 5, iter: 400, curr loss: 1.3871978521347046, avg loss: 1.386521167755127\n",
      "trial: 5, iter: 600, curr loss: 1.3867026567459106, avg loss: 1.3865521460771562\n",
      "trial: 5, iter: 800, curr loss: 1.3852933645248413, avg loss: 1.386421536207199\n",
      "trial: 5, iter: 1000, curr loss: 1.3869136571884155, avg loss: 1.3864899468421936\n",
      "trial: 5, iter: 1200, curr loss: 1.3850706815719604, avg loss: 1.3864308649301529\n",
      "trial: 5, iter: 1400, curr loss: 1.3849955797195435, avg loss: 1.3863464379310608\n",
      "trial: 5, iter: 1600, curr loss: 1.3854392766952515, avg loss: 1.3863547962903977\n",
      "trial: 5, iter: 1800, curr loss: 1.3872889280319214, avg loss: 1.3864378160238267\n",
      "trial: 5, iter: 2000, curr loss: 1.3865904808044434, avg loss: 1.3863325530290604\n",
      "trial: 5, iter: 2200, curr loss: 1.3870261907577515, avg loss: 1.3864523828029633\n",
      "trial: 5, iter: 2400, curr loss: 1.3863904476165771, avg loss: 1.3863215851783752\n",
      "trial: 5, iter: 2600, curr loss: 1.3875473737716675, avg loss: 1.386417064666748\n",
      "trial: 5, iter: 2800, curr loss: 1.38557767868042, avg loss: 1.3864077669382096\n",
      "trial: 5, iter: 3000, curr loss: 1.3867632150650024, avg loss: 1.3863483703136443\n",
      "trial: 5, iter: 3200, curr loss: 1.3863041400909424, avg loss: 1.3863937211036683\n",
      "trial: 5, iter: 3400, curr loss: 1.38661527633667, avg loss: 1.3863776230812073\n",
      "trial: 5, iter: 3600, curr loss: 1.3862366676330566, avg loss: 1.3863327187299728\n",
      "trial: 5, iter: 3800, curr loss: 1.3870209455490112, avg loss: 1.3863747090101242\n",
      "trial: 5, iter: 4000, curr loss: 1.3862459659576416, avg loss: 1.3863100266456605\n",
      "trial: 5, iter: 4200, curr loss: 1.3861368894577026, avg loss: 1.3863510650396347\n",
      "trial: 5, iter: 4400, curr loss: 1.3863495588302612, avg loss: 1.386360791325569\n",
      "trial: 5, iter: 4600, curr loss: 1.386357069015503, avg loss: 1.386292725801468\n",
      "trial: 5, iter: 4800, curr loss: 1.3861947059631348, avg loss: 1.3863380479812621\n",
      "trial: 5, iter: 5000, curr loss: 1.38638174533844, avg loss: 1.386322278380394\n",
      "trial: 5, iter: 5200, curr loss: 1.386366605758667, avg loss: 1.3863682174682617\n",
      "trial: 5, iter: 5400, curr loss: 1.3864951133728027, avg loss: 1.386328912973404\n",
      "trial: 5, iter: 5600, curr loss: 1.3865041732788086, avg loss: 1.3863613426685333\n",
      "trial: 5, iter: 5800, curr loss: 1.3862963914871216, avg loss: 1.3863172882795334\n",
      "trial: 5, iter: 6000, curr loss: 1.3863437175750732, avg loss: 1.3863143795728683\n",
      "trial: 5, iter: 6200, curr loss: 1.386314034461975, avg loss: 1.3862866920232773\n",
      "trial: 5, iter: 6400, curr loss: 1.3864614963531494, avg loss: 1.3863154911994935\n",
      "trial: 5, iter: 6600, curr loss: 1.3865299224853516, avg loss: 1.3863315308094024\n",
      "trial: 5, iter: 6800, curr loss: 1.3859941959381104, avg loss: 1.3863271224498748\n",
      "trial: 5, iter: 7000, curr loss: 1.3861117362976074, avg loss: 1.3862931060791015\n",
      "trial: 5, iter: 7200, curr loss: 1.386260747909546, avg loss: 1.3863269925117492\n",
      "trial: 5, iter: 7400, curr loss: 1.3864375352859497, avg loss: 1.3863307386636734\n",
      "trial: 5, iter: 7600, curr loss: 1.3862816095352173, avg loss: 1.3863149678707123\n",
      "trial: 5, iter: 7800, curr loss: 1.3862494230270386, avg loss: 1.3863003253936768\n",
      "trial: 5, iter: 8000, curr loss: 1.3863108158111572, avg loss: 1.3862964552640915\n",
      "trial: 5, iter: 8200, curr loss: 1.3863197565078735, avg loss: 1.386300509572029\n",
      "trial: 5, iter: 8400, curr loss: 1.3862656354904175, avg loss: 1.3862960678339005\n",
      "trial: 5, iter: 8600, curr loss: 1.386209487915039, avg loss: 1.386295610666275\n",
      "trial: 5, iter: 8800, curr loss: 1.3862614631652832, avg loss: 1.3862937289476394\n",
      "trial: 5, iter: 9000, curr loss: 1.3863064050674438, avg loss: 1.386304184794426\n",
      "trial: 5, iter: 9200, curr loss: 1.3864855766296387, avg loss: 1.3863005363941192\n",
      "trial: 5, iter: 9400, curr loss: 1.3862872123718262, avg loss: 1.3863006484508515\n",
      "trial: 5, iter: 9600, curr loss: 1.3864539861679077, avg loss: 1.3862920588254928\n",
      "trial: 5, iter: 9800, curr loss: 1.3861494064331055, avg loss: 1.386303235888481\n",
      "trial: 5, iter: 10000, curr loss: 1.3862348794937134, avg loss: 1.3863007360696793\n",
      "trial: 5, iter: 10200, curr loss: 1.3862948417663574, avg loss: 1.3862986356019973\n",
      "trial: 5, iter: 10400, curr loss: 1.3862619400024414, avg loss: 1.3862980431318284\n",
      "trial: 5, iter: 10600, curr loss: 1.3863246440887451, avg loss: 1.3863196128606796\n",
      "trial: 5, iter: 10800, curr loss: 1.3866697549819946, avg loss: 1.3863261234760285\n",
      "trial: 5, iter: 11000, curr loss: 1.3862518072128296, avg loss: 1.3863236790895461\n",
      "trial: 5, iter: 11200, curr loss: 1.3862218856811523, avg loss: 1.3863186794519424\n",
      "trial: 5, iter: 11400, curr loss: 1.3865456581115723, avg loss: 1.3862957102060318\n",
      "trial: 5, iter: 11600, curr loss: 1.386244297027588, avg loss: 1.3862889635562896\n",
      "trial: 5, iter: 11800, curr loss: 1.3863035440444946, avg loss: 1.386315968632698\n",
      "trial: 5, iter: 12000, curr loss: 1.3864659070968628, avg loss: 1.3862928515672683\n",
      "trial: 5, iter: 12200, curr loss: 1.3863445520401, avg loss: 1.3863139712810517\n",
      "trial: 5, iter: 12400, curr loss: 1.3861416578292847, avg loss: 1.3863153165578843\n",
      "trial: 5, iter: 12600, curr loss: 1.3863298892974854, avg loss: 1.3863236069679261\n",
      "trial: 5, iter: 12800, curr loss: 1.3863816261291504, avg loss: 1.386290988922119\n",
      "trial: 5, iter: 13000, curr loss: 1.3864316940307617, avg loss: 1.3863061720132828\n",
      "trial: 5, iter: 13200, curr loss: 1.3863341808319092, avg loss: 1.3862904661893845\n",
      "trial: 5, iter: 13400, curr loss: 1.3858897686004639, avg loss: 1.3862817668914795\n",
      "trial: 5, iter: 13600, curr loss: 1.3863869905471802, avg loss: 1.386316739320755\n",
      "trial: 5, iter: 13800, curr loss: 1.3862361907958984, avg loss: 1.3863007628917694\n",
      "trial: 5, iter: 14000, curr loss: 1.3863215446472168, avg loss: 1.3863038975000381\n",
      "trial: 5, iter: 14200, curr loss: 1.3862638473510742, avg loss: 1.3862979650497436\n",
      "trial: 5, iter: 14400, curr loss: 1.386272668838501, avg loss: 1.3862968307733536\n",
      "trial: 5, iter: 14600, curr loss: 1.3863071203231812, avg loss: 1.386297155022621\n",
      "trial: 5, iter: 14800, curr loss: 1.3862743377685547, avg loss: 1.3862972086668015\n",
      "trial: 5, iter: 15000, curr loss: 1.3862676620483398, avg loss: 1.38629552423954\n",
      "trial: 5, iter: 15200, curr loss: 1.386343240737915, avg loss: 1.3862946873903275\n",
      "trial: 5, iter: 15400, curr loss: 1.387468934059143, avg loss: 1.3862471014261246\n",
      "trial: 5, iter: 15600, curr loss: 1.3862195014953613, avg loss: 1.3863387876749038\n",
      "trial: 5, ldr: 0.0035123727284371853\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0009938636649955868\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3883531093597412, avg loss: 1.387397025823593\n",
      "trial: 1, iter: 400, curr loss: 1.3863698244094849, avg loss: 1.3866952461004258\n",
      "trial: 1, iter: 600, curr loss: 1.386124610900879, avg loss: 1.386751093864441\n",
      "trial: 1, iter: 800, curr loss: 1.3860161304473877, avg loss: 1.3864985942840575\n",
      "trial: 1, iter: 1000, curr loss: 1.3865337371826172, avg loss: 1.3863766396045685\n",
      "trial: 1, iter: 1200, curr loss: 1.3857048749923706, avg loss: 1.386491038799286\n",
      "trial: 1, iter: 1400, curr loss: 1.3856985569000244, avg loss: 1.3864730924367905\n",
      "trial: 1, iter: 1600, curr loss: 1.3865591287612915, avg loss: 1.386534993648529\n",
      "trial: 1, iter: 1800, curr loss: 1.3857985734939575, avg loss: 1.3863653510808944\n",
      "trial: 1, iter: 2000, curr loss: 1.3859378099441528, avg loss: 1.3864108318090438\n",
      "trial: 1, iter: 2200, curr loss: 1.3861061334609985, avg loss: 1.3863932055234909\n",
      "trial: 1, iter: 2400, curr loss: 1.3854151964187622, avg loss: 1.386440150141716\n",
      "trial: 1, iter: 2600, curr loss: 1.3870362043380737, avg loss: 1.3863532418012618\n",
      "trial: 1, iter: 2800, curr loss: 1.388352632522583, avg loss: 1.3863972127437592\n",
      "trial: 1, iter: 3000, curr loss: 1.385988712310791, avg loss: 1.3863752096891404\n",
      "trial: 1, iter: 3200, curr loss: 1.386405110359192, avg loss: 1.386348608136177\n",
      "trial: 1, iter: 3400, curr loss: 1.3867883682250977, avg loss: 1.3863118541240693\n",
      "trial: 1, iter: 3600, curr loss: 1.3864551782608032, avg loss: 1.3863471531867981\n",
      "trial: 1, iter: 3800, curr loss: 1.3864655494689941, avg loss: 1.3863309174776077\n",
      "trial: 1, iter: 4000, curr loss: 1.3866952657699585, avg loss: 1.3863263320922852\n",
      "trial: 1, iter: 4200, curr loss: 1.3862446546554565, avg loss: 1.3863776636123657\n",
      "trial: 1, iter: 4400, curr loss: 1.3863707780838013, avg loss: 1.3862988430261611\n",
      "trial: 1, iter: 4600, curr loss: 1.386337399482727, avg loss: 1.3863241481781006\n",
      "trial: 1, iter: 4800, curr loss: 1.3859937191009521, avg loss: 1.38636554479599\n",
      "trial: 1, iter: 5000, curr loss: 1.3857933282852173, avg loss: 1.3862887454032897\n",
      "trial: 1, iter: 5200, curr loss: 1.3861522674560547, avg loss: 1.3863447576761245\n",
      "trial: 1, iter: 5400, curr loss: 1.38627028465271, avg loss: 1.3863274723291397\n",
      "trial: 1, iter: 5600, curr loss: 1.3860355615615845, avg loss: 1.3863148480653762\n",
      "trial: 1, iter: 5800, curr loss: 1.386549711227417, avg loss: 1.3863458228111267\n",
      "trial: 1, iter: 6000, curr loss: 1.3864635229110718, avg loss: 1.386316893696785\n",
      "trial: 1, iter: 6200, curr loss: 1.3863732814788818, avg loss: 1.3863047236204147\n",
      "trial: 1, iter: 6400, curr loss: 1.3862897157669067, avg loss: 1.3863419389724732\n",
      "trial: 1, iter: 6600, curr loss: 1.3858529329299927, avg loss: 1.386298243999481\n",
      "trial: 1, iter: 6800, curr loss: 1.386099934577942, avg loss: 1.3863673669099807\n",
      "trial: 1, iter: 7000, curr loss: 1.3867710828781128, avg loss: 1.3862968081235885\n",
      "trial: 1, iter: 7200, curr loss: 1.3863401412963867, avg loss: 1.3863111501932144\n",
      "trial: 1, iter: 7400, curr loss: 1.3865057229995728, avg loss: 1.3863167172670365\n",
      "trial: 1, iter: 7600, curr loss: 1.3863171339035034, avg loss: 1.386309059858322\n",
      "trial: 1, iter: 7800, curr loss: 1.3867123126983643, avg loss: 1.3863006061315537\n",
      "trial: 1, iter: 8000, curr loss: 1.3864439725875854, avg loss: 1.3863174569606782\n",
      "trial: 1, iter: 8200, curr loss: 1.3862636089324951, avg loss: 1.3863149923086167\n",
      "trial: 1, iter: 8400, curr loss: 1.3862913846969604, avg loss: 1.3862970888614654\n",
      "trial: 1, iter: 8600, curr loss: 1.386304497718811, avg loss: 1.386301344037056\n",
      "trial: 1, iter: 8800, curr loss: 1.3863096237182617, avg loss: 1.3862992662191391\n",
      "trial: 1, iter: 9000, curr loss: 1.3863043785095215, avg loss: 1.386294243335724\n",
      "trial: 1, iter: 9200, curr loss: 1.386287808418274, avg loss: 1.3862998706102372\n",
      "trial: 1, iter: 9400, curr loss: 1.3868049383163452, avg loss: 1.3863523495197296\n",
      "trial: 1, iter: 9600, curr loss: 1.3868643045425415, avg loss: 1.386314269900322\n",
      "trial: 1, iter: 9800, curr loss: 1.3866581916809082, avg loss: 1.3862791121006013\n",
      "trial: 1, iter: 10000, curr loss: 1.3869248628616333, avg loss: 1.3863376480340959\n",
      "trial: 1, iter: 10200, curr loss: 1.386048436164856, avg loss: 1.3863244450092316\n",
      "trial: 1, iter: 10400, curr loss: 1.3866022825241089, avg loss: 1.386310316324234\n",
      "trial: 1, iter: 10600, curr loss: 1.385030746459961, avg loss: 1.3863035660982133\n",
      "trial: 1, iter: 10800, curr loss: 1.3869678974151611, avg loss: 1.386389535665512\n",
      "trial: 1, iter: 11000, curr loss: 1.3864281177520752, avg loss: 1.3863163989782334\n",
      "trial: 1, iter: 11200, curr loss: 1.386281132698059, avg loss: 1.38634401679039\n",
      "trial: 1, iter: 11400, curr loss: 1.3874489068984985, avg loss: 1.3862957113981247\n",
      "trial: 1, iter: 11600, curr loss: 1.38649320602417, avg loss: 1.386307088136673\n",
      "trial: 1, iter: 11800, curr loss: 1.386196255683899, avg loss: 1.3863129812479018\n",
      "trial: 1, iter: 12000, curr loss: 1.3857266902923584, avg loss: 1.386294006705284\n",
      "trial: 1, iter: 12200, curr loss: 1.3870121240615845, avg loss: 1.3863003474473954\n",
      "trial: 1, iter: 12400, curr loss: 1.3863415718078613, avg loss: 1.3863354170322417\n",
      "trial: 1, iter: 12600, curr loss: 1.3864082098007202, avg loss: 1.3863169157505035\n",
      "trial: 1, iter: 12800, curr loss: 1.386170506477356, avg loss: 1.3862895905971526\n",
      "trial: 1, iter: 13000, curr loss: 1.3862336874008179, avg loss: 1.3862772578001021\n",
      "trial: 1, iter: 13200, curr loss: 1.386718511581421, avg loss: 1.3863204783201217\n",
      "trial: 1, iter: 13400, curr loss: 1.3862581253051758, avg loss: 1.3863091224431991\n",
      "trial: 1, iter: 13600, curr loss: 1.3865128755569458, avg loss: 1.3862882137298584\n",
      "trial: 1, iter: 13800, curr loss: 1.3867778778076172, avg loss: 1.3863025814294816\n",
      "trial: 1, iter: 14000, curr loss: 1.3863385915756226, avg loss: 1.3863252347707749\n",
      "trial: 1, iter: 14200, curr loss: 1.3861429691314697, avg loss: 1.386297464966774\n",
      "trial: 1, iter: 14400, curr loss: 1.3861502408981323, avg loss: 1.3863036721944808\n",
      "trial: 1, iter: 14600, curr loss: 1.3866591453552246, avg loss: 1.386278600692749\n",
      "trial: 1, iter: 14800, curr loss: 1.3868012428283691, avg loss: 1.3863171964883805\n",
      "trial: 1, iter: 15000, curr loss: 1.386473298072815, avg loss: 1.3862920796871185\n",
      "trial: 1, iter: 15200, curr loss: 1.3860756158828735, avg loss: 1.3863053154945373\n",
      "trial: 1, iter: 15400, curr loss: 1.3862884044647217, avg loss: 1.3862928712368012\n",
      "trial: 1, iter: 15600, curr loss: 1.3860588073730469, avg loss: 1.386295136809349\n",
      "trial: 1, ldr: -0.0012453676899895072\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3861472606658936, avg loss: 1.3872724056243897\n",
      "trial: 2, iter: 400, curr loss: 1.3871681690216064, avg loss: 1.3866873860359192\n",
      "trial: 2, iter: 600, curr loss: 1.3851364850997925, avg loss: 1.3865437752008438\n",
      "trial: 2, iter: 800, curr loss: 1.3849750757217407, avg loss: 1.386536266207695\n",
      "trial: 2, iter: 1000, curr loss: 1.3879618644714355, avg loss: 1.3864036655426026\n",
      "trial: 2, iter: 1200, curr loss: 1.3863391876220703, avg loss: 1.3864992189407348\n",
      "trial: 2, iter: 1400, curr loss: 1.3857531547546387, avg loss: 1.3864030081033707\n",
      "trial: 2, iter: 1600, curr loss: 1.3853096961975098, avg loss: 1.3864202910661698\n",
      "trial: 2, iter: 1800, curr loss: 1.38656747341156, avg loss: 1.3863640081882478\n",
      "trial: 2, iter: 2000, curr loss: 1.3861134052276611, avg loss: 1.3864207249879836\n",
      "trial: 2, iter: 2200, curr loss: 1.387975811958313, avg loss: 1.3863500905036927\n",
      "trial: 2, iter: 2400, curr loss: 1.3861157894134521, avg loss: 1.3863870787620545\n",
      "trial: 2, iter: 2600, curr loss: 1.3868694305419922, avg loss: 1.3863875275850297\n",
      "trial: 2, iter: 2800, curr loss: 1.3867007493972778, avg loss: 1.3863329088687897\n",
      "trial: 2, iter: 3000, curr loss: 1.385321021080017, avg loss: 1.386350769996643\n",
      "trial: 2, iter: 3200, curr loss: 1.3869006633758545, avg loss: 1.3863228905200957\n",
      "trial: 2, iter: 3400, curr loss: 1.385399580001831, avg loss: 1.3863238286972046\n",
      "trial: 2, iter: 3600, curr loss: 1.3863507509231567, avg loss: 1.3863093608617783\n",
      "trial: 2, iter: 3800, curr loss: 1.3883190155029297, avg loss: 1.386365219950676\n",
      "trial: 2, iter: 4000, curr loss: 1.3876081705093384, avg loss: 1.386559202671051\n",
      "trial: 2, iter: 4200, curr loss: 1.386634349822998, avg loss: 1.3862406140565873\n",
      "trial: 2, iter: 4400, curr loss: 1.3866431713104248, avg loss: 1.3863912492990493\n",
      "trial: 2, iter: 4600, curr loss: 1.3863677978515625, avg loss: 1.386373274922371\n",
      "trial: 2, iter: 4800, curr loss: 1.3861355781555176, avg loss: 1.3863068956136704\n",
      "trial: 2, iter: 5000, curr loss: 1.386400580406189, avg loss: 1.3863374978303908\n",
      "trial: 2, iter: 5200, curr loss: 1.386744737625122, avg loss: 1.3863567179441452\n",
      "trial: 2, iter: 5400, curr loss: 1.386237621307373, avg loss: 1.3863310581445694\n",
      "trial: 2, iter: 5600, curr loss: 1.3862508535385132, avg loss: 1.386319026350975\n",
      "trial: 2, iter: 5800, curr loss: 1.3865455389022827, avg loss: 1.38634408056736\n",
      "trial: 2, iter: 6000, curr loss: 1.3864589929580688, avg loss: 1.3863244402408599\n",
      "trial: 2, iter: 6200, curr loss: 1.3862162828445435, avg loss: 1.3863314640522004\n",
      "trial: 2, iter: 6400, curr loss: 1.3863465785980225, avg loss: 1.3863112479448318\n",
      "trial: 2, iter: 6600, curr loss: 1.3858819007873535, avg loss: 1.3862826502323151\n",
      "trial: 2, iter: 6800, curr loss: 1.3858160972595215, avg loss: 1.3863102060556411\n",
      "trial: 2, iter: 7000, curr loss: 1.3855712413787842, avg loss: 1.386299786567688\n",
      "trial: 2, iter: 7200, curr loss: 1.3865694999694824, avg loss: 1.38634017765522\n",
      "trial: 2, iter: 7400, curr loss: 1.3863639831542969, avg loss: 1.3863105952739716\n",
      "trial: 2, iter: 7600, curr loss: 1.3861768245697021, avg loss: 1.3863064217567445\n",
      "trial: 2, iter: 7800, curr loss: 1.3866603374481201, avg loss: 1.3862910425662995\n",
      "trial: 2, iter: 8000, curr loss: 1.388071894645691, avg loss: 1.386321216225624\n",
      "trial: 2, iter: 8200, curr loss: 1.387336254119873, avg loss: 1.386386883854866\n",
      "trial: 2, iter: 8400, curr loss: 1.3859977722167969, avg loss: 1.38632841527462\n",
      "trial: 2, iter: 8600, curr loss: 1.3865482807159424, avg loss: 1.3863174086809158\n",
      "trial: 2, iter: 8800, curr loss: 1.3859366178512573, avg loss: 1.3863139998912812\n",
      "trial: 2, iter: 9000, curr loss: 1.3862228393554688, avg loss: 1.3863129389286042\n",
      "trial: 2, iter: 9200, curr loss: 1.3861342668533325, avg loss: 1.3862979358434677\n",
      "trial: 2, iter: 9400, curr loss: 1.386192798614502, avg loss: 1.3863053339719773\n",
      "trial: 2, iter: 9600, curr loss: 1.3863258361816406, avg loss: 1.3863127875328063\n",
      "trial: 2, iter: 9800, curr loss: 1.386277198791504, avg loss: 1.386300573348999\n",
      "trial: 2, iter: 10000, curr loss: 1.3861836194992065, avg loss: 1.3863079649209977\n",
      "trial: 2, iter: 10200, curr loss: 1.3862946033477783, avg loss: 1.3863000160455703\n",
      "trial: 2, iter: 10400, curr loss: 1.3862943649291992, avg loss: 1.386294201016426\n",
      "trial: 2, iter: 10600, curr loss: 1.3863617181777954, avg loss: 1.3862943267822265\n",
      "trial: 2, iter: 10800, curr loss: 1.386298656463623, avg loss: 1.3863049834966659\n",
      "trial: 2, iter: 11000, curr loss: 1.3862955570220947, avg loss: 1.3862896138429641\n",
      "trial: 2, iter: 11200, curr loss: 1.386294960975647, avg loss: 1.386294754743576\n",
      "trial: 2, iter: 11400, curr loss: 1.3862947225570679, avg loss: 1.3862945550680161\n",
      "trial: 2, iter: 11600, curr loss: 1.3862942457199097, avg loss: 1.3862961500883102\n",
      "trial: 2, iter: 11800, curr loss: 1.386294960975647, avg loss: 1.3862947297096253\n",
      "trial: 2, iter: 12000, curr loss: 1.386294960975647, avg loss: 1.3862945461273193\n",
      "trial: 2, iter: 12200, curr loss: 1.3862946033477783, avg loss: 1.3862946516275405\n",
      "trial: 2, iter: 12400, curr loss: 1.3862943649291992, avg loss: 1.386295160651207\n",
      "trial: 2, iter: 12600, curr loss: 1.386294960975647, avg loss: 1.386294785141945\n",
      "trial: 2, iter: 12800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13000, curr loss: 1.3862946033477783, avg loss: 1.3862947314977645\n",
      "trial: 2, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.3862947964668273\n",
      "trial: 2, iter: 13400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15000, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15200, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15400, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.386294960975647\n",
      "trial: 2, ldr: -1.1920930376163597e-07\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3849966526031494, avg loss: 1.387415667772293\n",
      "trial: 3, iter: 400, curr loss: 1.389078974723816, avg loss: 1.3867329955101013\n",
      "trial: 3, iter: 600, curr loss: 1.385981559753418, avg loss: 1.3865431517362594\n",
      "trial: 3, iter: 800, curr loss: 1.3852676153182983, avg loss: 1.3864917254447937\n",
      "trial: 3, iter: 1000, curr loss: 1.3867826461791992, avg loss: 1.3863454949855805\n",
      "trial: 3, iter: 1200, curr loss: 1.3875740766525269, avg loss: 1.3864952033758164\n",
      "trial: 3, iter: 1400, curr loss: 1.3862345218658447, avg loss: 1.386518047451973\n",
      "trial: 3, iter: 1600, curr loss: 1.3869719505310059, avg loss: 1.3865483337640763\n",
      "trial: 3, iter: 1800, curr loss: 1.3864651918411255, avg loss: 1.3863754725456239\n",
      "trial: 3, iter: 2000, curr loss: 1.3858040571212769, avg loss: 1.386335020661354\n",
      "trial: 3, iter: 2200, curr loss: 1.386090636253357, avg loss: 1.3864008587598802\n",
      "trial: 3, iter: 2400, curr loss: 1.3864017724990845, avg loss: 1.3863253861665725\n",
      "trial: 3, iter: 2600, curr loss: 1.3863970041275024, avg loss: 1.3863110333681106\n",
      "trial: 3, iter: 2800, curr loss: 1.3866944313049316, avg loss: 1.3863258028030396\n",
      "trial: 3, iter: 3000, curr loss: 1.3866173028945923, avg loss: 1.3863014906644822\n",
      "trial: 3, iter: 3200, curr loss: 1.3864400386810303, avg loss: 1.3863104516267777\n",
      "trial: 3, iter: 3400, curr loss: 1.3864871263504028, avg loss: 1.3863098925352098\n",
      "trial: 3, iter: 3600, curr loss: 1.3859667778015137, avg loss: 1.3863227826356888\n",
      "trial: 3, iter: 3800, curr loss: 1.386353850364685, avg loss: 1.3863278937339782\n",
      "trial: 3, iter: 4000, curr loss: 1.3869836330413818, avg loss: 1.386272611618042\n",
      "trial: 3, iter: 4200, curr loss: 1.385461449623108, avg loss: 1.3863052123785018\n",
      "trial: 3, iter: 4400, curr loss: 1.3866596221923828, avg loss: 1.3863607138395309\n",
      "trial: 3, iter: 4600, curr loss: 1.3863006830215454, avg loss: 1.386311297416687\n",
      "trial: 3, iter: 4800, curr loss: 1.386912226676941, avg loss: 1.3864371937513351\n",
      "trial: 3, iter: 5000, curr loss: 1.3849711418151855, avg loss: 1.3863276588916777\n",
      "trial: 3, iter: 5200, curr loss: 1.3872721195220947, avg loss: 1.3863986611366272\n",
      "trial: 3, iter: 5400, curr loss: 1.3864847421646118, avg loss: 1.3863253504037858\n",
      "trial: 3, iter: 5600, curr loss: 1.386037826538086, avg loss: 1.3862987810373306\n",
      "trial: 3, iter: 5800, curr loss: 1.3859621286392212, avg loss: 1.3862908446788789\n",
      "trial: 3, iter: 6000, curr loss: 1.38603675365448, avg loss: 1.386316088438034\n",
      "trial: 3, iter: 6200, curr loss: 1.3861198425292969, avg loss: 1.3863006043434143\n",
      "trial: 3, iter: 6400, curr loss: 1.3865396976470947, avg loss: 1.386303391456604\n",
      "trial: 3, iter: 6600, curr loss: 1.3857970237731934, avg loss: 1.3863145619630814\n",
      "trial: 3, iter: 6800, curr loss: 1.3862613439559937, avg loss: 1.3863064986467362\n",
      "trial: 3, iter: 7000, curr loss: 1.386489987373352, avg loss: 1.386294652223587\n",
      "trial: 3, iter: 7200, curr loss: 1.386017084121704, avg loss: 1.386285231113434\n",
      "trial: 3, iter: 7400, curr loss: 1.3864459991455078, avg loss: 1.3862998932600021\n",
      "trial: 3, iter: 7600, curr loss: 1.3861302137374878, avg loss: 1.386337507367134\n",
      "trial: 3, iter: 7800, curr loss: 1.3867700099945068, avg loss: 1.3862919694185256\n",
      "trial: 3, iter: 8000, curr loss: 1.3860204219818115, avg loss: 1.3863248187303543\n",
      "trial: 3, iter: 8200, curr loss: 1.3866938352584839, avg loss: 1.3863040500879287\n",
      "trial: 3, iter: 8400, curr loss: 1.3862600326538086, avg loss: 1.3862966287136078\n",
      "trial: 3, iter: 8600, curr loss: 1.3861792087554932, avg loss: 1.3862962114810944\n",
      "trial: 3, iter: 8800, curr loss: 1.386396050453186, avg loss: 1.3862994611263275\n",
      "trial: 3, iter: 9000, curr loss: 1.386927604675293, avg loss: 1.3863063341379165\n",
      "trial: 3, iter: 9200, curr loss: 1.3859901428222656, avg loss: 1.386305565237999\n",
      "trial: 3, iter: 9400, curr loss: 1.3861855268478394, avg loss: 1.3862958854436875\n",
      "trial: 3, iter: 9600, curr loss: 1.3862800598144531, avg loss: 1.3863098472356796\n",
      "trial: 3, iter: 9800, curr loss: 1.3863333463668823, avg loss: 1.3862925642728805\n",
      "trial: 3, iter: 10000, curr loss: 1.3866912126541138, avg loss: 1.3862786185741425\n",
      "trial: 3, iter: 10200, curr loss: 1.3863203525543213, avg loss: 1.386305855512619\n",
      "trial: 3, iter: 10400, curr loss: 1.3862959146499634, avg loss: 1.3862999469041823\n",
      "trial: 3, iter: 10600, curr loss: 1.3863214254379272, avg loss: 1.3863015407323838\n",
      "trial: 3, iter: 10800, curr loss: 1.3862884044647217, avg loss: 1.3863156408071518\n",
      "trial: 3, iter: 11000, curr loss: 1.3862780332565308, avg loss: 1.3862941807508469\n",
      "trial: 3, iter: 11200, curr loss: 1.3863027095794678, avg loss: 1.3862964475154878\n",
      "trial: 3, iter: 11400, curr loss: 1.3862740993499756, avg loss: 1.386294790506363\n",
      "trial: 3, iter: 11600, curr loss: 1.3862802982330322, avg loss: 1.3862947821617126\n",
      "trial: 3, iter: 11800, curr loss: 1.3862658739089966, avg loss: 1.3862931329011916\n",
      "trial: 3, iter: 12000, curr loss: 1.3864374160766602, avg loss: 1.3862944048643113\n",
      "trial: 3, iter: 12200, curr loss: 1.3862580060958862, avg loss: 1.386288143992424\n",
      "trial: 3, iter: 12400, curr loss: 1.386279582977295, avg loss: 1.3863072800636291\n",
      "trial: 3, iter: 12600, curr loss: 1.3863667249679565, avg loss: 1.3862990164756774\n",
      "trial: 3, iter: 12800, curr loss: 1.386252999305725, avg loss: 1.3862969392538071\n",
      "trial: 3, iter: 13000, curr loss: 1.3862136602401733, avg loss: 1.3862956553697585\n",
      "trial: 3, iter: 13200, curr loss: 1.3863555192947388, avg loss: 1.386295831799507\n",
      "trial: 3, iter: 13400, curr loss: 1.3863093852996826, avg loss: 1.386294927597046\n",
      "trial: 3, iter: 13600, curr loss: 1.386271595954895, avg loss: 1.386296382546425\n",
      "trial: 3, iter: 13800, curr loss: 1.3862911462783813, avg loss: 1.3862948220968248\n",
      "trial: 3, iter: 14000, curr loss: 1.386213779449463, avg loss: 1.3862950384616852\n",
      "trial: 3, iter: 14200, curr loss: 1.386336326599121, avg loss: 1.3862973421812057\n",
      "trial: 3, iter: 14400, curr loss: 1.3863369226455688, avg loss: 1.3862962436676025\n",
      "trial: 3, iter: 14600, curr loss: 1.3862502574920654, avg loss: 1.3862919503450393\n",
      "trial: 3, iter: 14800, curr loss: 1.3862932920455933, avg loss: 1.3862989282608031\n",
      "trial: 3, iter: 15000, curr loss: 1.3862866163253784, avg loss: 1.3862967771291732\n",
      "trial: 3, iter: 15200, curr loss: 1.3862502574920654, avg loss: 1.3862916988134384\n",
      "trial: 3, iter: 15400, curr loss: 1.3862693309783936, avg loss: 1.386297471523285\n",
      "trial: 3, iter: 15600, curr loss: 1.3863279819488525, avg loss: 1.3862885576486588\n",
      "trial: 3, ldr: -0.0003409365890547633\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3894264698028564, avg loss: 1.3872573399543762\n",
      "trial: 4, iter: 400, curr loss: 1.3862767219543457, avg loss: 1.3867008179426192\n",
      "trial: 4, iter: 600, curr loss: 1.38925039768219, avg loss: 1.3865683662891388\n",
      "trial: 4, iter: 800, curr loss: 1.3877975940704346, avg loss: 1.3864738112688064\n",
      "trial: 4, iter: 1000, curr loss: 1.3862357139587402, avg loss: 1.3864786261320114\n",
      "trial: 4, iter: 1200, curr loss: 1.3873510360717773, avg loss: 1.3864822262525558\n",
      "trial: 4, iter: 1400, curr loss: 1.3871008157730103, avg loss: 1.3864002639055253\n",
      "trial: 4, iter: 1600, curr loss: 1.385947585105896, avg loss: 1.3863427358865739\n",
      "trial: 4, iter: 1800, curr loss: 1.3863459825515747, avg loss: 1.386347360610962\n",
      "trial: 4, iter: 2000, curr loss: 1.3855187892913818, avg loss: 1.3863791394233704\n",
      "trial: 4, iter: 2200, curr loss: 1.38582181930542, avg loss: 1.3864510732889175\n",
      "trial: 4, iter: 2400, curr loss: 1.385717749595642, avg loss: 1.3863561671972275\n",
      "trial: 4, iter: 2600, curr loss: 1.388136386871338, avg loss: 1.3863868778944015\n",
      "trial: 4, iter: 2800, curr loss: 1.3849018812179565, avg loss: 1.3863245791196823\n",
      "trial: 4, iter: 3000, curr loss: 1.387114405632019, avg loss: 1.386442494392395\n",
      "trial: 4, iter: 3200, curr loss: 1.3860245943069458, avg loss: 1.386351249217987\n",
      "trial: 4, iter: 3400, curr loss: 1.3854937553405762, avg loss: 1.3863454645872115\n",
      "trial: 4, iter: 3600, curr loss: 1.3862807750701904, avg loss: 1.3863823843002319\n",
      "trial: 4, iter: 3800, curr loss: 1.3865042924880981, avg loss: 1.3863524425029754\n",
      "trial: 4, iter: 4000, curr loss: 1.3862935304641724, avg loss: 1.3862983465194703\n",
      "trial: 4, iter: 4200, curr loss: 1.386728286743164, avg loss: 1.3862968695163727\n",
      "trial: 4, iter: 4400, curr loss: 1.3858814239501953, avg loss: 1.3863216984272002\n",
      "trial: 4, iter: 4600, curr loss: 1.3860596418380737, avg loss: 1.386291233897209\n",
      "trial: 4, iter: 4800, curr loss: 1.3861945867538452, avg loss: 1.3863201731443404\n",
      "trial: 4, iter: 5000, curr loss: 1.3862746953964233, avg loss: 1.3863234716653823\n",
      "trial: 4, iter: 5200, curr loss: 1.3859890699386597, avg loss: 1.3863019853830338\n",
      "trial: 4, iter: 5400, curr loss: 1.3865221738815308, avg loss: 1.3863207644224167\n",
      "trial: 4, iter: 5600, curr loss: 1.3860234022140503, avg loss: 1.3862952017784118\n",
      "trial: 4, iter: 5800, curr loss: 1.3864041566848755, avg loss: 1.3863079816102981\n",
      "trial: 4, iter: 6000, curr loss: 1.386307716369629, avg loss: 1.38630552649498\n",
      "trial: 4, iter: 6200, curr loss: 1.3862916231155396, avg loss: 1.386305221915245\n",
      "trial: 4, iter: 6400, curr loss: 1.3864221572875977, avg loss: 1.3863107258081435\n",
      "trial: 4, iter: 6600, curr loss: 1.386254906654358, avg loss: 1.3862951374053956\n",
      "trial: 4, iter: 6800, curr loss: 1.3863227367401123, avg loss: 1.3863128733634948\n",
      "trial: 4, iter: 7000, curr loss: 1.3861998319625854, avg loss: 1.3863155668973923\n",
      "trial: 4, iter: 7200, curr loss: 1.3864282369613647, avg loss: 1.3862976491451264\n",
      "trial: 4, iter: 7400, curr loss: 1.3859935998916626, avg loss: 1.3863133895397186\n",
      "trial: 4, iter: 7600, curr loss: 1.3865574598312378, avg loss: 1.3862982857227326\n",
      "trial: 4, iter: 7800, curr loss: 1.3861486911773682, avg loss: 1.3862978112697601\n",
      "trial: 4, iter: 8000, curr loss: 1.386665940284729, avg loss: 1.3863234955072403\n",
      "trial: 4, iter: 8200, curr loss: 1.3858619928359985, avg loss: 1.3862943863868713\n",
      "trial: 4, iter: 8400, curr loss: 1.3855010271072388, avg loss: 1.3862675666809081\n",
      "trial: 4, iter: 8600, curr loss: 1.3865092992782593, avg loss: 1.3863191902637482\n",
      "trial: 4, iter: 8800, curr loss: 1.3866150379180908, avg loss: 1.3862909108400345\n",
      "trial: 4, iter: 9000, curr loss: 1.3861122131347656, avg loss: 1.3863346564769745\n",
      "trial: 4, iter: 9200, curr loss: 1.3867521286010742, avg loss: 1.3863087385892867\n",
      "trial: 4, iter: 9400, curr loss: 1.3862066268920898, avg loss: 1.3862962174415587\n",
      "trial: 4, iter: 9600, curr loss: 1.3865339756011963, avg loss: 1.3863061606884002\n",
      "trial: 4, iter: 9800, curr loss: 1.3862519264221191, avg loss: 1.3862904334068298\n",
      "trial: 4, iter: 10000, curr loss: 1.3869054317474365, avg loss: 1.3862978130578996\n",
      "trial: 4, iter: 10200, curr loss: 1.386157512664795, avg loss: 1.3862874126434326\n",
      "trial: 4, iter: 10400, curr loss: 1.386304497718811, avg loss: 1.3863199949264526\n",
      "trial: 4, iter: 10600, curr loss: 1.3863025903701782, avg loss: 1.3862986302375793\n",
      "trial: 4, iter: 10800, curr loss: 1.386081337928772, avg loss: 1.3862968629598618\n",
      "trial: 4, iter: 11000, curr loss: 1.3862228393554688, avg loss: 1.3862976801395417\n",
      "trial: 4, iter: 11200, curr loss: 1.3862977027893066, avg loss: 1.3862948346138\n",
      "trial: 4, iter: 11400, curr loss: 1.3862991333007812, avg loss: 1.386294845342636\n",
      "trial: 4, iter: 11600, curr loss: 1.3862940073013306, avg loss: 1.3862947243452073\n",
      "trial: 4, iter: 11800, curr loss: 1.3862833976745605, avg loss: 1.3862945026159286\n",
      "trial: 4, iter: 12000, curr loss: 1.386293649673462, avg loss: 1.3862944430112838\n",
      "trial: 4, iter: 12200, curr loss: 1.386292815208435, avg loss: 1.386294378042221\n",
      "trial: 4, iter: 12400, curr loss: 1.3862947225570679, avg loss: 1.3862944877147674\n",
      "trial: 4, iter: 12600, curr loss: 1.3862944841384888, avg loss: 1.3862943410873414\n",
      "trial: 4, iter: 12800, curr loss: 1.3862947225570679, avg loss: 1.3862941735982894\n",
      "trial: 4, iter: 13000, curr loss: 1.3862919807434082, avg loss: 1.3862943881750107\n",
      "trial: 4, iter: 13200, curr loss: 1.386294960975647, avg loss: 1.386294224858284\n",
      "trial: 4, iter: 13400, curr loss: 1.3862946033477783, avg loss: 1.3862942242622376\n",
      "trial: 4, iter: 13600, curr loss: 1.3862948417663574, avg loss: 1.3862948352098465\n",
      "trial: 4, iter: 13800, curr loss: 1.386294960975647, avg loss: 1.3862948340177537\n",
      "trial: 4, iter: 14000, curr loss: 1.386294960975647, avg loss: 1.3862947070598601\n",
      "trial: 4, iter: 14200, curr loss: 1.386294960975647, avg loss: 1.3862949347496032\n",
      "trial: 4, iter: 14400, curr loss: 1.386294960975647, avg loss: 1.386294875741005\n",
      "trial: 4, iter: 14600, curr loss: 1.386294960975647, avg loss: 1.3862946897745132\n",
      "trial: 4, iter: 14800, curr loss: 1.386294960975647, avg loss: 1.3862948590517044\n",
      "trial: 4, iter: 15000, curr loss: 1.3862942457199097, avg loss: 1.386294772028923\n",
      "trial: 4, iter: 15200, curr loss: 1.3862944841384888, avg loss: 1.3862947273254393\n",
      "trial: 4, iter: 15400, curr loss: 1.3862947225570679, avg loss: 1.3862948006391524\n",
      "trial: 4, iter: 15600, curr loss: 1.386294960975647, avg loss: 1.3862947255373002\n",
      "trial: 4, ldr: -8.569028153715408e-08\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860673904418945, avg loss: 1.3871733969449997\n",
      "trial: 5, iter: 400, curr loss: 1.3863022327423096, avg loss: 1.386721875667572\n",
      "trial: 5, iter: 600, curr loss: 1.3864177465438843, avg loss: 1.386452876329422\n",
      "trial: 5, iter: 800, curr loss: 1.3872532844543457, avg loss: 1.3864273363351822\n",
      "trial: 5, iter: 1000, curr loss: 1.3857470750808716, avg loss: 1.3865832841396333\n",
      "trial: 5, iter: 1200, curr loss: 1.3879836797714233, avg loss: 1.386478231549263\n",
      "trial: 5, iter: 1400, curr loss: 1.388117790222168, avg loss: 1.3863902086019515\n",
      "trial: 5, iter: 1600, curr loss: 1.3864550590515137, avg loss: 1.3866077536344528\n",
      "trial: 5, iter: 1800, curr loss: 1.3867155313491821, avg loss: 1.3864469003677369\n",
      "trial: 5, iter: 2000, curr loss: 1.3860689401626587, avg loss: 1.3865000396966933\n",
      "trial: 5, iter: 2200, curr loss: 1.3864192962646484, avg loss: 1.3864124077558517\n",
      "trial: 5, iter: 2400, curr loss: 1.3872014284133911, avg loss: 1.3863404315710068\n",
      "trial: 5, iter: 2600, curr loss: 1.3862318992614746, avg loss: 1.3863661217689514\n",
      "trial: 5, iter: 2800, curr loss: 1.3869705200195312, avg loss: 1.386394744515419\n",
      "trial: 5, iter: 3000, curr loss: 1.3882269859313965, avg loss: 1.386299745440483\n",
      "trial: 5, iter: 3200, curr loss: 1.3864485025405884, avg loss: 1.3863873851299287\n",
      "trial: 5, iter: 3400, curr loss: 1.3862888813018799, avg loss: 1.38634828209877\n",
      "trial: 5, iter: 3600, curr loss: 1.386818289756775, avg loss: 1.3863048702478409\n",
      "trial: 5, iter: 3800, curr loss: 1.388016939163208, avg loss: 1.3863037234544755\n",
      "trial: 5, iter: 4000, curr loss: 1.386130690574646, avg loss: 1.3864021843671799\n",
      "trial: 5, iter: 4200, curr loss: 1.3881590366363525, avg loss: 1.3864287447929382\n",
      "trial: 5, iter: 4400, curr loss: 1.3873180150985718, avg loss: 1.3863544994592667\n",
      "trial: 5, iter: 4600, curr loss: 1.387608528137207, avg loss: 1.3863667529821395\n",
      "trial: 5, iter: 4800, curr loss: 1.386426329612732, avg loss: 1.386432297229767\n",
      "trial: 5, iter: 5000, curr loss: 1.3870970010757446, avg loss: 1.3863783544301986\n",
      "trial: 5, iter: 5200, curr loss: 1.386461853981018, avg loss: 1.3863555133342742\n",
      "trial: 5, iter: 5400, curr loss: 1.3863210678100586, avg loss: 1.38635637819767\n",
      "trial: 5, iter: 5600, curr loss: 1.3863248825073242, avg loss: 1.3863290768861771\n",
      "trial: 5, iter: 5800, curr loss: 1.386127233505249, avg loss: 1.3863126629590987\n",
      "trial: 5, iter: 6000, curr loss: 1.3859515190124512, avg loss: 1.3863259822130203\n",
      "trial: 5, iter: 6200, curr loss: 1.3867460489273071, avg loss: 1.3863428717851638\n",
      "trial: 5, iter: 6400, curr loss: 1.385434865951538, avg loss: 1.3863160634040832\n",
      "trial: 5, iter: 6600, curr loss: 1.38632333278656, avg loss: 1.386309602856636\n",
      "trial: 5, iter: 6800, curr loss: 1.3868303298950195, avg loss: 1.3863315838575363\n",
      "trial: 5, iter: 7000, curr loss: 1.38607656955719, avg loss: 1.3863089448213577\n",
      "trial: 5, iter: 7200, curr loss: 1.385737657546997, avg loss: 1.3863245087862015\n",
      "trial: 5, iter: 7400, curr loss: 1.386641263961792, avg loss: 1.3863105285167694\n",
      "trial: 5, iter: 7600, curr loss: 1.3860923051834106, avg loss: 1.3863458335399628\n",
      "trial: 5, iter: 7800, curr loss: 1.3863224983215332, avg loss: 1.386308427453041\n",
      "trial: 5, iter: 8000, curr loss: 1.385847806930542, avg loss: 1.3862582099437715\n",
      "trial: 5, iter: 8200, curr loss: 1.3861818313598633, avg loss: 1.3863388997316362\n",
      "trial: 5, iter: 8400, curr loss: 1.3862544298171997, avg loss: 1.3863364517688752\n",
      "trial: 5, iter: 8600, curr loss: 1.3861980438232422, avg loss: 1.386319836974144\n",
      "trial: 5, iter: 8800, curr loss: 1.3861228227615356, avg loss: 1.3863076287508012\n",
      "trial: 5, iter: 9000, curr loss: 1.3864445686340332, avg loss: 1.3862955778837205\n",
      "trial: 5, iter: 9200, curr loss: 1.387174367904663, avg loss: 1.3862889009714126\n",
      "trial: 5, iter: 9400, curr loss: 1.3863377571105957, avg loss: 1.3863284939527512\n",
      "trial: 5, iter: 9600, curr loss: 1.3874812126159668, avg loss: 1.386317539215088\n",
      "trial: 5, iter: 9800, curr loss: 1.3859065771102905, avg loss: 1.3863835698366165\n",
      "trial: 5, iter: 10000, curr loss: 1.386330008506775, avg loss: 1.3864026510715484\n",
      "trial: 5, iter: 10200, curr loss: 1.3865429162979126, avg loss: 1.3863195145130158\n",
      "trial: 5, iter: 10400, curr loss: 1.386206865310669, avg loss: 1.386298832297325\n",
      "trial: 5, iter: 10600, curr loss: 1.3863680362701416, avg loss: 1.3863070106506348\n",
      "trial: 5, iter: 10800, curr loss: 1.3870915174484253, avg loss: 1.3862843418121338\n",
      "trial: 5, iter: 11000, curr loss: 1.3862109184265137, avg loss: 1.3862856179475784\n",
      "trial: 5, iter: 11200, curr loss: 1.386144995689392, avg loss: 1.386293637752533\n",
      "trial: 5, iter: 11400, curr loss: 1.3862038850784302, avg loss: 1.386300819516182\n",
      "trial: 5, iter: 11600, curr loss: 1.3865878582000732, avg loss: 1.3862940859794617\n",
      "trial: 5, iter: 11800, curr loss: 1.386074185371399, avg loss: 1.3863138353824616\n",
      "trial: 5, iter: 12000, curr loss: 1.3861209154129028, avg loss: 1.3863120198249816\n",
      "trial: 5, iter: 12200, curr loss: 1.3865752220153809, avg loss: 1.3862985146045685\n",
      "trial: 5, iter: 12400, curr loss: 1.3863732814788818, avg loss: 1.3862974178791045\n",
      "trial: 5, iter: 12600, curr loss: 1.3863120079040527, avg loss: 1.38630389213562\n",
      "trial: 5, iter: 12800, curr loss: 1.386156439781189, avg loss: 1.386292274594307\n",
      "trial: 5, iter: 13000, curr loss: 1.386178731918335, avg loss: 1.3862979102134705\n",
      "trial: 5, iter: 13200, curr loss: 1.3862696886062622, avg loss: 1.3863017916679383\n",
      "trial: 5, iter: 13400, curr loss: 1.3861545324325562, avg loss: 1.3862923353910446\n",
      "trial: 5, iter: 13600, curr loss: 1.3864598274230957, avg loss: 1.3862935197353363\n",
      "trial: 5, iter: 13800, curr loss: 1.3863682746887207, avg loss: 1.3863044703006744\n",
      "trial: 5, iter: 14000, curr loss: 1.386299729347229, avg loss: 1.3862941753864289\n",
      "trial: 5, iter: 14200, curr loss: 1.3863130807876587, avg loss: 1.3863077306747436\n",
      "trial: 5, iter: 14400, curr loss: 1.3866318464279175, avg loss: 1.3863668781518936\n",
      "trial: 5, iter: 14600, curr loss: 1.386344075202942, avg loss: 1.3862987595796585\n",
      "trial: 5, iter: 14800, curr loss: 1.3862507343292236, avg loss: 1.3862938928604125\n",
      "trial: 5, iter: 15000, curr loss: 1.3861740827560425, avg loss: 1.386313447356224\n",
      "trial: 5, iter: 15200, curr loss: 1.386385440826416, avg loss: 1.3863131392002106\n",
      "trial: 5, iter: 15400, curr loss: 1.3863122463226318, avg loss: 1.3862942773103715\n",
      "trial: 5, iter: 15600, curr loss: 1.3857353925704956, avg loss: 1.3862902277708054\n",
      "trial: 5, ldr: 0.0005387016572058201\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00020956150428474984\n",
      "Experiment done with data path: ./data/catNon-lin-NI_20/data.50k.dz200.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_18/data.10k.dz200.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38521146774292, avg loss: 1.3872253555059433\n",
      "trial: 1, iter: 400, curr loss: 1.3859294652938843, avg loss: 1.3866998225450515\n",
      "trial: 1, iter: 600, curr loss: 1.3879404067993164, avg loss: 1.3864420175552368\n",
      "trial: 1, iter: 800, curr loss: 1.3857407569885254, avg loss: 1.3864906817674636\n",
      "trial: 1, iter: 1000, curr loss: 1.385638952255249, avg loss: 1.3864412713050842\n",
      "trial: 1, iter: 1200, curr loss: 1.387436032295227, avg loss: 1.386507814526558\n",
      "trial: 1, iter: 1400, curr loss: 1.3868523836135864, avg loss: 1.386462649703026\n",
      "trial: 1, iter: 1600, curr loss: 1.3875843286514282, avg loss: 1.3863827234506607\n",
      "trial: 1, iter: 1800, curr loss: 1.3859714269638062, avg loss: 1.3864597511291503\n",
      "trial: 1, iter: 2000, curr loss: 1.3868739604949951, avg loss: 1.3863615638017655\n",
      "trial: 1, iter: 2200, curr loss: 1.3868229389190674, avg loss: 1.3863268369436264\n",
      "trial: 1, iter: 2400, curr loss: 1.3869540691375732, avg loss: 1.386448021531105\n",
      "trial: 1, iter: 2600, curr loss: 1.386382818222046, avg loss: 1.3863710457086562\n",
      "trial: 1, iter: 2800, curr loss: 1.386690616607666, avg loss: 1.3863443571329117\n",
      "trial: 1, iter: 3000, curr loss: 1.3873205184936523, avg loss: 1.3862952315807342\n",
      "trial: 1, ldr: 0.0028754735831171274\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.389962077140808, avg loss: 1.3871887934207916\n",
      "trial: 2, iter: 400, curr loss: 1.3861268758773804, avg loss: 1.3866646605730057\n",
      "trial: 2, iter: 600, curr loss: 1.3874485492706299, avg loss: 1.3864700251817703\n",
      "trial: 2, iter: 800, curr loss: 1.3847354650497437, avg loss: 1.386478437781334\n",
      "trial: 2, iter: 1000, curr loss: 1.387251377105713, avg loss: 1.386594704389572\n",
      "trial: 2, iter: 1200, curr loss: 1.3885024785995483, avg loss: 1.3865304791927338\n",
      "trial: 2, iter: 1400, curr loss: 1.386369228363037, avg loss: 1.3865402644872666\n",
      "trial: 2, iter: 1600, curr loss: 1.385237455368042, avg loss: 1.3864110845327378\n",
      "trial: 2, iter: 1800, curr loss: 1.387050747871399, avg loss: 1.3863319671154022\n",
      "trial: 2, iter: 2000, curr loss: 1.3867746591567993, avg loss: 1.386374020576477\n",
      "trial: 2, iter: 2200, curr loss: 1.3861067295074463, avg loss: 1.386404892206192\n",
      "trial: 2, iter: 2400, curr loss: 1.3865690231323242, avg loss: 1.386392557621002\n",
      "trial: 2, iter: 2600, curr loss: 1.385269045829773, avg loss: 1.3863573968410492\n",
      "trial: 2, iter: 2800, curr loss: 1.3860315084457397, avg loss: 1.3864281272888184\n",
      "trial: 2, iter: 3000, curr loss: 1.3862831592559814, avg loss: 1.3863627070188522\n",
      "trial: 2, ldr: -0.01036678347736597\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3880492448806763, avg loss: 1.387343003153801\n",
      "trial: 3, iter: 400, curr loss: 1.3893595933914185, avg loss: 1.3867624616622924\n",
      "trial: 3, iter: 600, curr loss: 1.3863251209259033, avg loss: 1.3865711683034896\n",
      "trial: 3, iter: 800, curr loss: 1.3848146200180054, avg loss: 1.38649444937706\n",
      "trial: 3, iter: 1000, curr loss: 1.3872483968734741, avg loss: 1.38651454269886\n",
      "trial: 3, iter: 1200, curr loss: 1.386744499206543, avg loss: 1.386471644639969\n",
      "trial: 3, iter: 1400, curr loss: 1.3855674266815186, avg loss: 1.386418069601059\n",
      "trial: 3, iter: 1600, curr loss: 1.3872311115264893, avg loss: 1.3865363484621047\n",
      "trial: 3, iter: 1800, curr loss: 1.3860950469970703, avg loss: 1.3863959997892379\n",
      "trial: 3, iter: 2000, curr loss: 1.3866329193115234, avg loss: 1.3864618247747422\n",
      "trial: 3, iter: 2200, curr loss: 1.3862683773040771, avg loss: 1.3864124697446822\n",
      "trial: 3, iter: 2400, curr loss: 1.386074185371399, avg loss: 1.3863673949241637\n",
      "trial: 3, iter: 2600, curr loss: 1.3863766193389893, avg loss: 1.3864297246932984\n",
      "trial: 3, iter: 2800, curr loss: 1.3873707056045532, avg loss: 1.3863113528490068\n",
      "trial: 3, iter: 3000, curr loss: 1.3864212036132812, avg loss: 1.3862874621152879\n",
      "trial: 3, ldr: -0.005826866719871759\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.382979393005371, avg loss: 1.3869837188720704\n",
      "trial: 4, iter: 400, curr loss: 1.3865982294082642, avg loss: 1.386691589951515\n",
      "trial: 4, iter: 600, curr loss: 1.3878483772277832, avg loss: 1.3865503996610642\n",
      "trial: 4, iter: 800, curr loss: 1.387291669845581, avg loss: 1.3864524912834169\n",
      "trial: 4, iter: 1000, curr loss: 1.3876097202301025, avg loss: 1.3864470046758652\n",
      "trial: 4, iter: 1200, curr loss: 1.3871593475341797, avg loss: 1.3865268015861512\n",
      "trial: 4, iter: 1400, curr loss: 1.3862667083740234, avg loss: 1.3864093792438508\n",
      "trial: 4, iter: 1600, curr loss: 1.3877016305923462, avg loss: 1.3863980454206466\n",
      "trial: 4, iter: 1800, curr loss: 1.38737154006958, avg loss: 1.3864324432611466\n",
      "trial: 4, iter: 2000, curr loss: 1.386506199836731, avg loss: 1.3863973540067673\n",
      "trial: 4, iter: 2200, curr loss: 1.3856693506240845, avg loss: 1.3864214289188386\n",
      "trial: 4, iter: 2400, curr loss: 1.3864798545837402, avg loss: 1.386403957605362\n",
      "trial: 4, iter: 2600, curr loss: 1.3871214389801025, avg loss: 1.3863388723134995\n",
      "trial: 4, iter: 2800, curr loss: 1.3859881162643433, avg loss: 1.3863301241397858\n",
      "trial: 4, iter: 3000, curr loss: 1.3856185674667358, avg loss: 1.38639839887619\n",
      "trial: 4, ldr: 0.0077747260220348835\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3846641778945923, avg loss: 1.3873862189054489\n",
      "trial: 5, iter: 400, curr loss: 1.387182354927063, avg loss: 1.3868113523721695\n",
      "trial: 5, iter: 600, curr loss: 1.3860589265823364, avg loss: 1.3864976072311401\n",
      "trial: 5, iter: 800, curr loss: 1.3862963914871216, avg loss: 1.386488637328148\n",
      "trial: 5, iter: 1000, curr loss: 1.3838614225387573, avg loss: 1.38645447909832\n",
      "trial: 5, iter: 1200, curr loss: 1.3856257200241089, avg loss: 1.3863882821798326\n",
      "trial: 5, iter: 1400, curr loss: 1.3869580030441284, avg loss: 1.386455397605896\n",
      "trial: 5, iter: 1600, curr loss: 1.3864943981170654, avg loss: 1.3863872826099395\n",
      "trial: 5, iter: 1800, curr loss: 1.38582444190979, avg loss: 1.3864831990003585\n",
      "trial: 5, iter: 2000, curr loss: 1.3870277404785156, avg loss: 1.3863422191143036\n",
      "trial: 5, iter: 2200, curr loss: 1.3875362873077393, avg loss: 1.3863924503326417\n",
      "trial: 5, iter: 2400, curr loss: 1.3866667747497559, avg loss: 1.3863867688179017\n",
      "trial: 5, iter: 2600, curr loss: 1.3873388767242432, avg loss: 1.3863419955968856\n",
      "trial: 5, iter: 2800, curr loss: 1.3861392736434937, avg loss: 1.3864295148849488\n",
      "trial: 5, iter: 3000, curr loss: 1.3865582942962646, avg loss: 1.3863743245601654\n",
      "trial: 5, ldr: -0.009743090718984604\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0030573082622140646\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386344075202942, avg loss: 1.3871711200475694\n",
      "trial: 1, iter: 400, curr loss: 1.3871920108795166, avg loss: 1.3867706835269928\n",
      "trial: 1, iter: 600, curr loss: 1.386181354522705, avg loss: 1.3864637893438339\n",
      "trial: 1, iter: 800, curr loss: 1.3865898847579956, avg loss: 1.3865726029872893\n",
      "trial: 1, iter: 1000, curr loss: 1.3876049518585205, avg loss: 1.3864971178770065\n",
      "trial: 1, iter: 1200, curr loss: 1.3856709003448486, avg loss: 1.3864257282018662\n",
      "trial: 1, iter: 1400, curr loss: 1.3875967264175415, avg loss: 1.3864404809474946\n",
      "trial: 1, iter: 1600, curr loss: 1.3862096071243286, avg loss: 1.386372155547142\n",
      "trial: 1, iter: 1800, curr loss: 1.3852263689041138, avg loss: 1.3863242882490159\n",
      "trial: 1, iter: 2000, curr loss: 1.387174367904663, avg loss: 1.386414315700531\n",
      "trial: 1, iter: 2200, curr loss: 1.3867212533950806, avg loss: 1.3864468711614608\n",
      "trial: 1, iter: 2400, curr loss: 1.386287808418274, avg loss: 1.3864138334989549\n",
      "trial: 1, iter: 2600, curr loss: 1.3874790668487549, avg loss: 1.3863065344095231\n",
      "trial: 1, iter: 2800, curr loss: 1.3864651918411255, avg loss: 1.3864654570817947\n",
      "trial: 1, iter: 3000, curr loss: 1.3864812850952148, avg loss: 1.3863223379850387\n",
      "trial: 1, ldr: 0.02432607114315033\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3846921920776367, avg loss: 1.3873268586397172\n",
      "trial: 2, iter: 400, curr loss: 1.385941505432129, avg loss: 1.3867674738168716\n",
      "trial: 2, iter: 600, curr loss: 1.3874980211257935, avg loss: 1.3865303659439088\n",
      "trial: 2, iter: 800, curr loss: 1.385551929473877, avg loss: 1.3864899814128875\n",
      "trial: 2, iter: 1000, curr loss: 1.3863110542297363, avg loss: 1.3864621067047118\n",
      "trial: 2, iter: 1200, curr loss: 1.3862088918685913, avg loss: 1.3863877707719803\n",
      "trial: 2, iter: 1400, curr loss: 1.3865302801132202, avg loss: 1.3863728725910187\n",
      "trial: 2, iter: 1600, curr loss: 1.38666832447052, avg loss: 1.3864089679718017\n",
      "trial: 2, iter: 1800, curr loss: 1.3868601322174072, avg loss: 1.3863568586111068\n",
      "trial: 2, iter: 2000, curr loss: 1.3836053609848022, avg loss: 1.3862960708141328\n",
      "trial: 2, iter: 2200, curr loss: 1.385343074798584, avg loss: 1.386310248374939\n",
      "trial: 2, iter: 2400, curr loss: 1.387152075767517, avg loss: 1.3864845466613769\n",
      "trial: 2, iter: 2600, curr loss: 1.387917399406433, avg loss: 1.3864828717708588\n",
      "trial: 2, iter: 2800, curr loss: 1.3853400945663452, avg loss: 1.3865283477306365\n",
      "trial: 2, iter: 3000, curr loss: 1.3875259160995483, avg loss: 1.3863342344760894\n",
      "trial: 2, ldr: 0.0056875478476285934\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3838342428207397, avg loss: 1.3870808619260788\n",
      "trial: 3, iter: 400, curr loss: 1.3873064517974854, avg loss: 1.3867571210861207\n",
      "trial: 3, iter: 600, curr loss: 1.3864078521728516, avg loss: 1.3864875525236129\n",
      "trial: 3, iter: 800, curr loss: 1.3875527381896973, avg loss: 1.3865038800239562\n",
      "trial: 3, iter: 1000, curr loss: 1.3866633176803589, avg loss: 1.3866300922632218\n",
      "trial: 3, iter: 1200, curr loss: 1.386289119720459, avg loss: 1.3864520591497422\n",
      "trial: 3, iter: 1400, curr loss: 1.3861089944839478, avg loss: 1.3864494860172272\n",
      "trial: 3, iter: 1600, curr loss: 1.3867409229278564, avg loss: 1.3863877642154694\n",
      "trial: 3, iter: 1800, curr loss: 1.3865067958831787, avg loss: 1.3863676941394807\n",
      "trial: 3, iter: 2000, curr loss: 1.387715220451355, avg loss: 1.3863818407058717\n",
      "trial: 3, iter: 2200, curr loss: 1.384752869606018, avg loss: 1.3863866567611693\n",
      "trial: 3, iter: 2400, curr loss: 1.3865858316421509, avg loss: 1.386470338702202\n",
      "trial: 3, iter: 2600, curr loss: 1.385373830795288, avg loss: 1.3863935977220536\n",
      "trial: 3, iter: 2800, curr loss: 1.3862329721450806, avg loss: 1.386310003399849\n",
      "trial: 3, iter: 3000, curr loss: 1.3866188526153564, avg loss: 1.3863718700408936\n",
      "trial: 3, ldr: 0.013204007409512997\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860470056533813, avg loss: 1.3873601818084718\n",
      "trial: 4, iter: 400, curr loss: 1.386430025100708, avg loss: 1.3866935795545579\n",
      "trial: 4, iter: 600, curr loss: 1.3855897188186646, avg loss: 1.386593949198723\n",
      "trial: 4, iter: 800, curr loss: 1.3870500326156616, avg loss: 1.3864009124040604\n",
      "trial: 4, iter: 1000, curr loss: 1.3868718147277832, avg loss: 1.3864117127656936\n",
      "trial: 4, iter: 1200, curr loss: 1.3868367671966553, avg loss: 1.3865110224485397\n",
      "trial: 4, iter: 1400, curr loss: 1.3885536193847656, avg loss: 1.386605835556984\n",
      "trial: 4, iter: 1600, curr loss: 1.3864835500717163, avg loss: 1.3863447278738021\n",
      "trial: 4, iter: 1800, curr loss: 1.3887559175491333, avg loss: 1.386325100660324\n",
      "trial: 4, iter: 2000, curr loss: 1.385298490524292, avg loss: 1.3865621370077132\n",
      "trial: 4, iter: 2200, curr loss: 1.3845641613006592, avg loss: 1.3864231777191163\n",
      "trial: 4, iter: 2400, curr loss: 1.3879101276397705, avg loss: 1.386392560005188\n",
      "trial: 4, iter: 2600, curr loss: 1.3856701850891113, avg loss: 1.386400830745697\n",
      "trial: 4, iter: 2800, curr loss: 1.3862470388412476, avg loss: 1.3864308857917786\n",
      "trial: 4, iter: 3000, curr loss: 1.386049509048462, avg loss: 1.3863799726963044\n",
      "trial: 4, ldr: -0.008739764802157879\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3890272378921509, avg loss: 1.3871738123893738\n",
      "trial: 5, iter: 400, curr loss: 1.3866852521896362, avg loss: 1.386694642305374\n",
      "trial: 5, iter: 600, curr loss: 1.385384440422058, avg loss: 1.3865663439035416\n",
      "trial: 5, iter: 800, curr loss: 1.3858089447021484, avg loss: 1.3865687882900237\n",
      "trial: 5, iter: 1000, curr loss: 1.385847568511963, avg loss: 1.3865657424926758\n",
      "trial: 5, iter: 1200, curr loss: 1.3843655586242676, avg loss: 1.3863846117258072\n",
      "trial: 5, iter: 1400, curr loss: 1.3861042261123657, avg loss: 1.3864449602365494\n",
      "trial: 5, iter: 1600, curr loss: 1.38667893409729, avg loss: 1.3863982731103897\n",
      "trial: 5, iter: 1800, curr loss: 1.3866870403289795, avg loss: 1.38635218501091\n",
      "trial: 5, iter: 2000, curr loss: 1.3851759433746338, avg loss: 1.3862777388095855\n",
      "trial: 5, iter: 2200, curr loss: 1.3865113258361816, avg loss: 1.3864314150810242\n",
      "trial: 5, iter: 2400, curr loss: 1.3858591318130493, avg loss: 1.3864045017957687\n",
      "trial: 5, iter: 2600, curr loss: 1.3875343799591064, avg loss: 1.3863722801208496\n",
      "trial: 5, iter: 2800, curr loss: 1.386976957321167, avg loss: 1.3863975250720977\n",
      "trial: 5, iter: 3000, curr loss: 1.3858286142349243, avg loss: 1.3864284551143646\n",
      "trial: 5, ldr: 0.01448778249323368\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.009793128818273544\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3884066343307495, avg loss: 1.3874801814556121\n",
      "trial: 1, iter: 400, curr loss: 1.3858747482299805, avg loss: 1.3866561019420625\n",
      "trial: 1, iter: 600, curr loss: 1.3860809803009033, avg loss: 1.3865709215402604\n",
      "trial: 1, iter: 800, curr loss: 1.3862950801849365, avg loss: 1.3864402985572815\n",
      "trial: 1, iter: 1000, curr loss: 1.3859343528747559, avg loss: 1.3865544599294664\n",
      "trial: 1, iter: 1200, curr loss: 1.3858340978622437, avg loss: 1.3865233951807021\n",
      "trial: 1, iter: 1400, curr loss: 1.3872466087341309, avg loss: 1.386377604007721\n",
      "trial: 1, iter: 1600, curr loss: 1.3858733177185059, avg loss: 1.3864395415782929\n",
      "trial: 1, iter: 1800, curr loss: 1.3860654830932617, avg loss: 1.3863989567756654\n",
      "trial: 1, iter: 2000, curr loss: 1.3849092721939087, avg loss: 1.3863616865873336\n",
      "trial: 1, iter: 2200, curr loss: 1.3855797052383423, avg loss: 1.3864723855257035\n",
      "trial: 1, iter: 2400, curr loss: 1.3854632377624512, avg loss: 1.38633858025074\n",
      "trial: 1, iter: 2600, curr loss: 1.3862718343734741, avg loss: 1.38639952480793\n",
      "trial: 1, iter: 2800, curr loss: 1.3862686157226562, avg loss: 1.3863467782735825\n",
      "trial: 1, iter: 3000, curr loss: 1.3863804340362549, avg loss: 1.3863364189863205\n",
      "trial: 1, ldr: 0.004215556662529707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.390849232673645, avg loss: 1.3869245195388793\n",
      "trial: 2, iter: 400, curr loss: 1.384692668914795, avg loss: 1.3866273713111879\n",
      "trial: 2, iter: 600, curr loss: 1.38739812374115, avg loss: 1.3864805263280868\n",
      "trial: 2, iter: 800, curr loss: 1.3861746788024902, avg loss: 1.386512832045555\n",
      "trial: 2, iter: 1000, curr loss: 1.3852497339248657, avg loss: 1.3864653044939041\n",
      "trial: 2, iter: 1200, curr loss: 1.386093020439148, avg loss: 1.3864644432067872\n",
      "trial: 2, iter: 1400, curr loss: 1.3860276937484741, avg loss: 1.3864035356044768\n",
      "trial: 2, iter: 1600, curr loss: 1.3867230415344238, avg loss: 1.386384283900261\n",
      "trial: 2, iter: 1800, curr loss: 1.387217402458191, avg loss: 1.386377311348915\n",
      "trial: 2, iter: 2000, curr loss: 1.3871443271636963, avg loss: 1.386332977414131\n",
      "trial: 2, iter: 2200, curr loss: 1.386925458908081, avg loss: 1.3863806688785554\n",
      "trial: 2, iter: 2400, curr loss: 1.3874821662902832, avg loss: 1.3863280892372132\n",
      "trial: 2, iter: 2600, curr loss: 1.3871142864227295, avg loss: 1.3863505935668945\n",
      "trial: 2, iter: 2800, curr loss: 1.386888861656189, avg loss: 1.3863662654161453\n",
      "trial: 2, iter: 3000, curr loss: 1.3866052627563477, avg loss: 1.3863495838642121\n",
      "trial: 2, ldr: 0.0013211751356720924\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3840121030807495, avg loss: 1.38713753759861\n",
      "trial: 3, iter: 400, curr loss: 1.3868765830993652, avg loss: 1.3865072602033615\n",
      "trial: 3, iter: 600, curr loss: 1.387804388999939, avg loss: 1.3866849184036254\n",
      "trial: 3, iter: 800, curr loss: 1.38829505443573, avg loss: 1.3864680486917496\n",
      "trial: 3, iter: 1000, curr loss: 1.3876687288284302, avg loss: 1.3863714116811752\n",
      "trial: 3, iter: 1200, curr loss: 1.3868649005889893, avg loss: 1.386354067325592\n",
      "trial: 3, iter: 1400, curr loss: 1.3867756128311157, avg loss: 1.3864957082271576\n",
      "trial: 3, iter: 1600, curr loss: 1.3859970569610596, avg loss: 1.386405018568039\n",
      "trial: 3, iter: 1800, curr loss: 1.3862098455429077, avg loss: 1.3863836807012557\n",
      "trial: 3, iter: 2000, curr loss: 1.3868752717971802, avg loss: 1.386382024884224\n",
      "trial: 3, iter: 2200, curr loss: 1.3877242803573608, avg loss: 1.3864147514104843\n",
      "trial: 3, iter: 2400, curr loss: 1.3850653171539307, avg loss: 1.3863418310880662\n",
      "trial: 3, iter: 2600, curr loss: 1.386358380317688, avg loss: 1.3863479447364808\n",
      "trial: 3, iter: 2800, curr loss: 1.386178731918335, avg loss: 1.3863436323404312\n",
      "trial: 3, iter: 3000, curr loss: 1.3861995935440063, avg loss: 1.3863454407453537\n",
      "trial: 3, ldr: -0.021276313811540604\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.383512020111084, avg loss: 1.3870398741960526\n",
      "trial: 4, iter: 400, curr loss: 1.386519193649292, avg loss: 1.3867789196968079\n",
      "trial: 4, iter: 600, curr loss: 1.3868660926818848, avg loss: 1.3865495455265044\n",
      "trial: 4, iter: 800, curr loss: 1.3859102725982666, avg loss: 1.3863716810941695\n",
      "trial: 4, iter: 1000, curr loss: 1.3863941431045532, avg loss: 1.3864669293165206\n",
      "trial: 4, iter: 1200, curr loss: 1.3856269121170044, avg loss: 1.3863948667049408\n",
      "trial: 4, iter: 1400, curr loss: 1.3869059085845947, avg loss: 1.3864389508962631\n",
      "trial: 4, iter: 1600, curr loss: 1.3866444826126099, avg loss: 1.3863410514593124\n",
      "trial: 4, iter: 1800, curr loss: 1.3869659900665283, avg loss: 1.386382573246956\n",
      "trial: 4, iter: 2000, curr loss: 1.385170340538025, avg loss: 1.386480494737625\n",
      "trial: 4, iter: 2200, curr loss: 1.386271595954895, avg loss: 1.3864049512147902\n",
      "trial: 4, iter: 2400, curr loss: 1.3895466327667236, avg loss: 1.3864657777547835\n",
      "trial: 4, iter: 2600, curr loss: 1.386749505996704, avg loss: 1.3865156853199005\n",
      "trial: 4, iter: 2800, curr loss: 1.3866348266601562, avg loss: 1.386392051577568\n",
      "trial: 4, iter: 3000, curr loss: 1.386396050453186, avg loss: 1.3864262008666992\n",
      "trial: 4, ldr: -0.012225470505654812\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860443830490112, avg loss: 1.3874679100513458\n",
      "trial: 5, iter: 400, curr loss: 1.3879482746124268, avg loss: 1.3865423321723938\n",
      "trial: 5, iter: 600, curr loss: 1.3864861726760864, avg loss: 1.3864802813529968\n",
      "trial: 5, iter: 800, curr loss: 1.3863964080810547, avg loss: 1.3865344965457915\n",
      "trial: 5, iter: 1000, curr loss: 1.386185884475708, avg loss: 1.3865235447883606\n",
      "trial: 5, iter: 1200, curr loss: 1.3858178853988647, avg loss: 1.3864231324195861\n",
      "trial: 5, iter: 1400, curr loss: 1.3851655721664429, avg loss: 1.3863609528541565\n",
      "trial: 5, iter: 1600, curr loss: 1.3859210014343262, avg loss: 1.3864660823345185\n",
      "trial: 5, iter: 1800, curr loss: 1.385664463043213, avg loss: 1.3863821655511857\n",
      "trial: 5, iter: 2000, curr loss: 1.3864166736602783, avg loss: 1.3863747662305832\n",
      "trial: 5, iter: 2200, curr loss: 1.3869150876998901, avg loss: 1.3864086711406707\n",
      "trial: 5, iter: 2400, curr loss: 1.38678777217865, avg loss: 1.3863556730747222\n",
      "trial: 5, iter: 2600, curr loss: 1.3861702680587769, avg loss: 1.3864003020524978\n",
      "trial: 5, iter: 2800, curr loss: 1.3869826793670654, avg loss: 1.3863347208499908\n",
      "trial: 5, iter: 3000, curr loss: 1.3865407705307007, avg loss: 1.3863871151208877\n",
      "trial: 5, ldr: 0.0013316948898136616\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.005326671525835991\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3869761228561401, avg loss: 1.3874264585971832\n",
      "trial: 1, iter: 400, curr loss: 1.385979413986206, avg loss: 1.3868706119060517\n",
      "trial: 1, iter: 600, curr loss: 1.3870084285736084, avg loss: 1.3865090477466584\n",
      "trial: 1, iter: 800, curr loss: 1.3861191272735596, avg loss: 1.386458792090416\n",
      "trial: 1, iter: 1000, curr loss: 1.386929988861084, avg loss: 1.3864158475399018\n",
      "trial: 1, iter: 1200, curr loss: 1.3855648040771484, avg loss: 1.3864949995279312\n",
      "trial: 1, iter: 1400, curr loss: 1.3867788314819336, avg loss: 1.3863986283540726\n",
      "trial: 1, iter: 1600, curr loss: 1.3858073949813843, avg loss: 1.3865303033590317\n",
      "trial: 1, iter: 1800, curr loss: 1.3848246335983276, avg loss: 1.386389709711075\n",
      "trial: 1, iter: 2000, curr loss: 1.3830446004867554, avg loss: 1.3864097982645034\n",
      "trial: 1, iter: 2200, curr loss: 1.3861678838729858, avg loss: 1.3864984625577927\n",
      "trial: 1, iter: 2400, curr loss: 1.385852336883545, avg loss: 1.3864284086227416\n",
      "trial: 1, iter: 2600, curr loss: 1.3862107992172241, avg loss: 1.3864416921138762\n",
      "trial: 1, iter: 2800, curr loss: 1.3869167566299438, avg loss: 1.3864038181304932\n",
      "trial: 1, iter: 3000, curr loss: 1.3867714405059814, avg loss: 1.3863565301895142\n",
      "trial: 1, ldr: 0.016004160046577454\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3886066675186157, avg loss: 1.3872525000572205\n",
      "trial: 2, iter: 400, curr loss: 1.387644648551941, avg loss: 1.3866713237762451\n",
      "trial: 2, iter: 600, curr loss: 1.3890087604522705, avg loss: 1.3863592529296875\n",
      "trial: 2, iter: 800, curr loss: 1.385852575302124, avg loss: 1.3864871233701705\n",
      "trial: 2, iter: 1000, curr loss: 1.386815071105957, avg loss: 1.3864711248874664\n",
      "trial: 2, iter: 1200, curr loss: 1.3892332315444946, avg loss: 1.3865776056051253\n",
      "trial: 2, iter: 1400, curr loss: 1.3880122900009155, avg loss: 1.3864808702468872\n",
      "trial: 2, iter: 1600, curr loss: 1.3855451345443726, avg loss: 1.3864788150787353\n",
      "trial: 2, iter: 1800, curr loss: 1.383958101272583, avg loss: 1.3864497065544128\n",
      "trial: 2, iter: 2000, curr loss: 1.386469841003418, avg loss: 1.38651684820652\n",
      "trial: 2, iter: 2200, curr loss: 1.3863000869750977, avg loss: 1.3864063555002213\n",
      "trial: 2, iter: 2400, curr loss: 1.3864747285842896, avg loss: 1.386449806690216\n",
      "trial: 2, iter: 2600, curr loss: 1.386240839958191, avg loss: 1.3864299750328064\n",
      "trial: 2, iter: 2800, curr loss: 1.3861433267593384, avg loss: 1.3863016533851624\n",
      "trial: 2, iter: 3000, curr loss: 1.3861883878707886, avg loss: 1.3863611376285554\n",
      "trial: 2, ldr: -0.02579832449555397\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3880128860473633, avg loss: 1.3871692538261413\n",
      "trial: 3, iter: 400, curr loss: 1.3863470554351807, avg loss: 1.386582002043724\n",
      "trial: 3, iter: 600, curr loss: 1.3861929178237915, avg loss: 1.386396295428276\n",
      "trial: 3, iter: 800, curr loss: 1.3843458890914917, avg loss: 1.3862734287977219\n",
      "trial: 3, iter: 1000, curr loss: 1.3878445625305176, avg loss: 1.386527690887451\n",
      "trial: 3, iter: 1200, curr loss: 1.3859506845474243, avg loss: 1.3863815021514894\n",
      "trial: 3, iter: 1400, curr loss: 1.3859862089157104, avg loss: 1.386367376446724\n",
      "trial: 3, iter: 1600, curr loss: 1.3864191770553589, avg loss: 1.3863566786050796\n",
      "trial: 3, iter: 1800, curr loss: 1.3854817152023315, avg loss: 1.3863675624132157\n",
      "trial: 3, iter: 2000, curr loss: 1.3864892721176147, avg loss: 1.38645090341568\n",
      "trial: 3, iter: 2200, curr loss: 1.3864686489105225, avg loss: 1.3863524293899536\n",
      "trial: 3, iter: 2400, curr loss: 1.3856794834136963, avg loss: 1.386304190158844\n",
      "trial: 3, iter: 2600, curr loss: 1.3861637115478516, avg loss: 1.386352201104164\n",
      "trial: 3, iter: 2800, curr loss: 1.3862301111221313, avg loss: 1.3863674503564836\n",
      "trial: 3, iter: 3000, curr loss: 1.3871015310287476, avg loss: 1.3863711071014404\n",
      "trial: 3, ldr: -0.006539386697113514\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3848270177841187, avg loss: 1.3872733825445176\n",
      "trial: 4, iter: 400, curr loss: 1.3860725164413452, avg loss: 1.3867147678136826\n",
      "trial: 4, iter: 600, curr loss: 1.3865011930465698, avg loss: 1.386512838602066\n",
      "trial: 4, iter: 800, curr loss: 1.3879488706588745, avg loss: 1.3865420883893966\n",
      "trial: 4, iter: 1000, curr loss: 1.3862195014953613, avg loss: 1.3865322476625443\n",
      "trial: 4, iter: 1200, curr loss: 1.3864041566848755, avg loss: 1.3863659900426866\n",
      "trial: 4, iter: 1400, curr loss: 1.386502981185913, avg loss: 1.3864073073863983\n",
      "trial: 4, iter: 1600, curr loss: 1.3862842321395874, avg loss: 1.3864003747701645\n",
      "trial: 4, iter: 1800, curr loss: 1.3853425979614258, avg loss: 1.386419512629509\n",
      "trial: 4, iter: 2000, curr loss: 1.386518120765686, avg loss: 1.3864145654439926\n",
      "trial: 4, iter: 2200, curr loss: 1.385064959526062, avg loss: 1.3865029430389404\n",
      "trial: 4, iter: 2400, curr loss: 1.3860728740692139, avg loss: 1.386360896229744\n",
      "trial: 4, iter: 2600, curr loss: 1.3863404989242554, avg loss: 1.3863953721523286\n",
      "trial: 4, iter: 2800, curr loss: 1.3868786096572876, avg loss: 1.3863888317346573\n",
      "trial: 4, iter: 3000, curr loss: 1.3848687410354614, avg loss: 1.3863356924057006\n",
      "trial: 4, ldr: 0.006561499089002609\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3893364667892456, avg loss: 1.3872832703590392\n",
      "trial: 5, iter: 400, curr loss: 1.3886127471923828, avg loss: 1.3866134905815124\n",
      "trial: 5, iter: 600, curr loss: 1.3900402784347534, avg loss: 1.3865907514095306\n",
      "trial: 5, iter: 800, curr loss: 1.3857313394546509, avg loss: 1.3865151971578598\n",
      "trial: 5, iter: 1000, curr loss: 1.3859299421310425, avg loss: 1.386469480395317\n",
      "trial: 5, iter: 1200, curr loss: 1.3865134716033936, avg loss: 1.386383183002472\n",
      "trial: 5, iter: 1400, curr loss: 1.3890279531478882, avg loss: 1.386401705145836\n",
      "trial: 5, iter: 1600, curr loss: 1.3870110511779785, avg loss: 1.3864418083429337\n",
      "trial: 5, iter: 1800, curr loss: 1.3878999948501587, avg loss: 1.3863790160417557\n",
      "trial: 5, iter: 2000, curr loss: 1.3864376544952393, avg loss: 1.3864037919044494\n",
      "trial: 5, iter: 2200, curr loss: 1.386586308479309, avg loss: 1.3864172065258027\n",
      "trial: 5, iter: 2400, curr loss: 1.3863149881362915, avg loss: 1.3863343495130538\n",
      "trial: 5, iter: 2600, curr loss: 1.3872177600860596, avg loss: 1.3863889640569687\n",
      "trial: 5, iter: 2800, curr loss: 1.3850791454315186, avg loss: 1.3863915127515793\n",
      "trial: 5, iter: 3000, curr loss: 1.3862327337265015, avg loss: 1.3864111244678496\n",
      "trial: 5, ldr: 0.021336784586310387\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.002312946505844593\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3869801759719849, avg loss: 1.3871609711647033\n",
      "trial: 1, iter: 400, curr loss: 1.3874441385269165, avg loss: 1.3868158972263336\n",
      "trial: 1, iter: 600, curr loss: 1.384468913078308, avg loss: 1.3865950828790665\n",
      "trial: 1, iter: 800, curr loss: 1.3863153457641602, avg loss: 1.386558293700218\n",
      "trial: 1, iter: 1000, curr loss: 1.387689471244812, avg loss: 1.3865153270959854\n",
      "trial: 1, iter: 1200, curr loss: 1.3849668502807617, avg loss: 1.3864712089300155\n",
      "trial: 1, iter: 1400, curr loss: 1.3869025707244873, avg loss: 1.386397926211357\n",
      "trial: 1, iter: 1600, curr loss: 1.38643217086792, avg loss: 1.3863989049196244\n",
      "trial: 1, iter: 1800, curr loss: 1.3871430158615112, avg loss: 1.3864052045345305\n",
      "trial: 1, iter: 2000, curr loss: 1.3858247995376587, avg loss: 1.3864066803455353\n",
      "trial: 1, iter: 2200, curr loss: 1.3860243558883667, avg loss: 1.3863958787918091\n",
      "trial: 1, iter: 2400, curr loss: 1.3865917921066284, avg loss: 1.3864045864343644\n",
      "trial: 1, iter: 2600, curr loss: 1.3875998258590698, avg loss: 1.3863393312692642\n",
      "trial: 1, iter: 2800, curr loss: 1.384531855583191, avg loss: 1.3863191056251525\n",
      "trial: 1, iter: 3000, curr loss: 1.3859188556671143, avg loss: 1.3864131927490235\n",
      "trial: 1, ldr: -0.005354017019271851\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3910404443740845, avg loss: 1.3871016865968704\n",
      "trial: 2, iter: 400, curr loss: 1.3864845037460327, avg loss: 1.386572242975235\n",
      "trial: 2, iter: 600, curr loss: 1.387394905090332, avg loss: 1.3864202708005906\n",
      "trial: 2, iter: 800, curr loss: 1.3871949911117554, avg loss: 1.3863983720541\n",
      "trial: 2, iter: 1000, curr loss: 1.38837468624115, avg loss: 1.3864980149269104\n",
      "trial: 2, iter: 1200, curr loss: 1.3858062028884888, avg loss: 1.3863422816991806\n",
      "trial: 2, iter: 1400, curr loss: 1.3854320049285889, avg loss: 1.3863788640499115\n",
      "trial: 2, iter: 1600, curr loss: 1.3875871896743774, avg loss: 1.3863408648967743\n",
      "trial: 2, iter: 1800, curr loss: 1.3860334157943726, avg loss: 1.3863432258367538\n",
      "trial: 2, iter: 2000, curr loss: 1.3861697912216187, avg loss: 1.3864171212911607\n",
      "trial: 2, iter: 2200, curr loss: 1.386637568473816, avg loss: 1.386413387656212\n",
      "trial: 2, iter: 2400, curr loss: 1.387524962425232, avg loss: 1.3863597798347473\n",
      "trial: 2, iter: 2600, curr loss: 1.3868930339813232, avg loss: 1.386360723376274\n",
      "trial: 2, iter: 2800, curr loss: 1.3866387605667114, avg loss: 1.386418735384941\n",
      "trial: 2, iter: 3000, curr loss: 1.38654625415802, avg loss: 1.3863474369049071\n",
      "trial: 2, ldr: 0.0015351754846051335\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3886240720748901, avg loss: 1.3875617980957031\n",
      "trial: 3, iter: 400, curr loss: 1.3865147829055786, avg loss: 1.3865771675109864\n",
      "trial: 3, iter: 600, curr loss: 1.3851395845413208, avg loss: 1.3864859765768052\n",
      "trial: 3, iter: 800, curr loss: 1.3869483470916748, avg loss: 1.3864270043373108\n",
      "trial: 3, iter: 1000, curr loss: 1.385947823524475, avg loss: 1.3863921535015107\n",
      "trial: 3, iter: 1200, curr loss: 1.3880398273468018, avg loss: 1.3864503121376037\n",
      "trial: 3, iter: 1400, curr loss: 1.3865044116973877, avg loss: 1.3864770352840423\n",
      "trial: 3, iter: 1600, curr loss: 1.387680172920227, avg loss: 1.3864626443386079\n",
      "trial: 3, iter: 1800, curr loss: 1.386211633682251, avg loss: 1.3864262419939042\n",
      "trial: 3, iter: 2000, curr loss: 1.3868920803070068, avg loss: 1.3864165514707565\n",
      "trial: 3, iter: 2200, curr loss: 1.3858437538146973, avg loss: 1.3863226062059402\n",
      "trial: 3, iter: 2400, curr loss: 1.3871417045593262, avg loss: 1.3863169860839843\n",
      "trial: 3, iter: 2600, curr loss: 1.3862967491149902, avg loss: 1.386317071914673\n",
      "trial: 3, iter: 2800, curr loss: 1.3861569166183472, avg loss: 1.3863323241472245\n",
      "trial: 3, iter: 3000, curr loss: 1.3871420621871948, avg loss: 1.38634504199028\n",
      "trial: 3, ldr: 0.010231876745820045\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.387089729309082, avg loss: 1.3874070978164672\n",
      "trial: 4, iter: 400, curr loss: 1.385848879814148, avg loss: 1.3867764669656752\n",
      "trial: 4, iter: 600, curr loss: 1.3859862089157104, avg loss: 1.386642283797264\n",
      "trial: 4, iter: 800, curr loss: 1.387079119682312, avg loss: 1.3865501588582994\n",
      "trial: 4, iter: 1000, curr loss: 1.385076642036438, avg loss: 1.3864366924762725\n",
      "trial: 4, iter: 1200, curr loss: 1.386190414428711, avg loss: 1.3864381122589111\n",
      "trial: 4, iter: 1400, curr loss: 1.3851540088653564, avg loss: 1.3864484697580337\n",
      "trial: 4, iter: 1600, curr loss: 1.386605978012085, avg loss: 1.3863798201084137\n",
      "trial: 4, iter: 1800, curr loss: 1.3869985342025757, avg loss: 1.3865021723508835\n",
      "trial: 4, iter: 2000, curr loss: 1.3881648778915405, avg loss: 1.3864496862888336\n",
      "trial: 4, iter: 2200, curr loss: 1.38668954372406, avg loss: 1.3864698833227158\n",
      "trial: 4, iter: 2400, curr loss: 1.3862923383712769, avg loss: 1.3864102059602736\n",
      "trial: 4, iter: 2600, curr loss: 1.3878496885299683, avg loss: 1.3863651913404464\n",
      "trial: 4, iter: 2800, curr loss: 1.387495756149292, avg loss: 1.386340942978859\n",
      "trial: 4, iter: 3000, curr loss: 1.387200951576233, avg loss: 1.3864173674583435\n",
      "trial: 4, ldr: -0.0023445014376193285\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3909605741500854, avg loss: 1.387028535604477\n",
      "trial: 5, iter: 400, curr loss: 1.3877854347229004, avg loss: 1.3867417591810227\n",
      "trial: 5, iter: 600, curr loss: 1.3863624334335327, avg loss: 1.3864231199026107\n",
      "trial: 5, iter: 800, curr loss: 1.3873026371002197, avg loss: 1.3864922028779985\n",
      "trial: 5, iter: 1000, curr loss: 1.3865031003952026, avg loss: 1.3865064764022828\n",
      "trial: 5, iter: 1200, curr loss: 1.3876373767852783, avg loss: 1.3866148161888123\n",
      "trial: 5, iter: 1400, curr loss: 1.3874276876449585, avg loss: 1.3864088660478593\n",
      "trial: 5, iter: 1600, curr loss: 1.387081265449524, avg loss: 1.3864103132486343\n",
      "trial: 5, iter: 1800, curr loss: 1.3859472274780273, avg loss: 1.38642590880394\n",
      "trial: 5, iter: 2000, curr loss: 1.3872475624084473, avg loss: 1.386423301100731\n",
      "trial: 5, iter: 2200, curr loss: 1.3880635499954224, avg loss: 1.386351590156555\n",
      "trial: 5, iter: 2400, curr loss: 1.3865002393722534, avg loss: 1.3863907170295715\n",
      "trial: 5, iter: 2600, curr loss: 1.3863749504089355, avg loss: 1.386405046582222\n",
      "trial: 5, iter: 2800, curr loss: 1.3868494033813477, avg loss: 1.3863464283943177\n",
      "trial: 5, iter: 3000, curr loss: 1.3858689069747925, avg loss: 1.3863557124137877\n",
      "trial: 5, ldr: -0.008266889490187168\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0008396711433306337\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38588285446167, avg loss: 1.3870396983623505\n",
      "trial: 1, iter: 400, curr loss: 1.3876283168792725, avg loss: 1.38664504468441\n",
      "trial: 1, iter: 600, curr loss: 1.3863520622253418, avg loss: 1.3863707673549652\n",
      "trial: 1, iter: 800, curr loss: 1.3861641883850098, avg loss: 1.3864534515142442\n",
      "trial: 1, iter: 1000, curr loss: 1.385405421257019, avg loss: 1.3865038853883744\n",
      "trial: 1, iter: 1200, curr loss: 1.3854376077651978, avg loss: 1.3864821755886079\n",
      "trial: 1, iter: 1400, curr loss: 1.3861663341522217, avg loss: 1.3864392405748367\n",
      "trial: 1, iter: 1600, curr loss: 1.386715054512024, avg loss: 1.386447920203209\n",
      "trial: 1, iter: 1800, curr loss: 1.3864083290100098, avg loss: 1.386363341808319\n",
      "trial: 1, iter: 2000, curr loss: 1.3857065439224243, avg loss: 1.3864170682430268\n",
      "trial: 1, iter: 2200, curr loss: 1.387268304824829, avg loss: 1.386365162730217\n",
      "trial: 1, iter: 2400, curr loss: 1.3857409954071045, avg loss: 1.3863231915235519\n",
      "trial: 1, iter: 2600, curr loss: 1.3854303359985352, avg loss: 1.3863776516914368\n",
      "trial: 1, iter: 2800, curr loss: 1.3865340948104858, avg loss: 1.3863641089200973\n",
      "trial: 1, iter: 3000, curr loss: 1.3865876197814941, avg loss: 1.3863709622621536\n",
      "trial: 1, ldr: 0.001742873340845108\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3900480270385742, avg loss: 1.387237659096718\n",
      "trial: 2, iter: 400, curr loss: 1.3881434202194214, avg loss: 1.3866328769922256\n",
      "trial: 2, iter: 600, curr loss: 1.386244535446167, avg loss: 1.3864697760343552\n",
      "trial: 2, iter: 800, curr loss: 1.3861157894134521, avg loss: 1.3866152739524842\n",
      "trial: 2, iter: 1000, curr loss: 1.3853956460952759, avg loss: 1.3863881653547288\n",
      "trial: 2, iter: 1200, curr loss: 1.3869003057479858, avg loss: 1.386410700082779\n",
      "trial: 2, iter: 1400, curr loss: 1.385738492012024, avg loss: 1.3863740700483322\n",
      "trial: 2, iter: 1600, curr loss: 1.3867303133010864, avg loss: 1.3864087218046188\n",
      "trial: 2, iter: 1800, curr loss: 1.3863060474395752, avg loss: 1.3864749675989152\n",
      "trial: 2, iter: 2000, curr loss: 1.38523268699646, avg loss: 1.3863726955652238\n",
      "trial: 2, iter: 2200, curr loss: 1.3885772228240967, avg loss: 1.3864104068279266\n",
      "trial: 2, iter: 2400, curr loss: 1.3872778415679932, avg loss: 1.386418479681015\n",
      "trial: 2, iter: 2600, curr loss: 1.3865922689437866, avg loss: 1.3864569109678269\n",
      "trial: 2, iter: 2800, curr loss: 1.3855640888214111, avg loss: 1.3863408082723618\n",
      "trial: 2, iter: 3000, curr loss: 1.3857576847076416, avg loss: 1.3863801914453506\n",
      "trial: 2, ldr: 0.00459858076646924\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3862890005111694, avg loss: 1.387393508553505\n",
      "trial: 3, iter: 400, curr loss: 1.3853983879089355, avg loss: 1.3866203778982162\n",
      "trial: 3, iter: 600, curr loss: 1.38424551486969, avg loss: 1.386611313223839\n",
      "trial: 3, iter: 800, curr loss: 1.3892747163772583, avg loss: 1.3865346455574035\n",
      "trial: 3, iter: 1000, curr loss: 1.3859455585479736, avg loss: 1.3863978010416032\n",
      "trial: 3, iter: 1200, curr loss: 1.3876174688339233, avg loss: 1.3865504622459413\n",
      "trial: 3, iter: 1400, curr loss: 1.3872641324996948, avg loss: 1.3865155702829361\n",
      "trial: 3, iter: 1600, curr loss: 1.3868157863616943, avg loss: 1.3864589589834213\n",
      "trial: 3, iter: 1800, curr loss: 1.3854650259017944, avg loss: 1.3864111888408661\n",
      "trial: 3, iter: 2000, curr loss: 1.3859803676605225, avg loss: 1.3863513785600663\n",
      "trial: 3, iter: 2200, curr loss: 1.3858275413513184, avg loss: 1.386443909406662\n",
      "trial: 3, iter: 2400, curr loss: 1.3872568607330322, avg loss: 1.3863901138305663\n",
      "trial: 3, iter: 2600, curr loss: 1.3869669437408447, avg loss: 1.3863888031244278\n",
      "trial: 3, iter: 2800, curr loss: 1.3863519430160522, avg loss: 1.3865186762809754\n",
      "trial: 3, iter: 3000, curr loss: 1.3863868713378906, avg loss: 1.3863471817970277\n",
      "trial: 3, ldr: -0.016047164797782898\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3880650997161865, avg loss: 1.3876576578617097\n",
      "trial: 4, iter: 400, curr loss: 1.3858381509780884, avg loss: 1.386968126296997\n",
      "trial: 4, iter: 600, curr loss: 1.3876277208328247, avg loss: 1.3866042685508728\n",
      "trial: 4, iter: 800, curr loss: 1.386251449584961, avg loss: 1.3863543790578843\n",
      "trial: 4, iter: 1000, curr loss: 1.385158658027649, avg loss: 1.3865717136859894\n",
      "trial: 4, iter: 1200, curr loss: 1.3857626914978027, avg loss: 1.386545478105545\n",
      "trial: 4, iter: 1400, curr loss: 1.3866420984268188, avg loss: 1.3864518845081328\n",
      "trial: 4, iter: 1600, curr loss: 1.3857423067092896, avg loss: 1.3863699519634247\n",
      "trial: 4, iter: 1800, curr loss: 1.3871420621871948, avg loss: 1.3864253067970276\n",
      "trial: 4, iter: 2000, curr loss: 1.3858567476272583, avg loss: 1.3864148753881453\n",
      "trial: 4, iter: 2200, curr loss: 1.3863723278045654, avg loss: 1.386333429813385\n",
      "trial: 4, iter: 2400, curr loss: 1.383897066116333, avg loss: 1.38637979388237\n",
      "trial: 4, iter: 2600, curr loss: 1.3871362209320068, avg loss: 1.386414547562599\n",
      "trial: 4, iter: 2800, curr loss: 1.386670470237732, avg loss: 1.3863990271091462\n",
      "trial: 4, iter: 3000, curr loss: 1.386748194694519, avg loss: 1.3863441944122314\n",
      "trial: 4, ldr: -0.012545976787805557\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3894081115722656, avg loss: 1.3872949981689453\n",
      "trial: 5, iter: 400, curr loss: 1.388416051864624, avg loss: 1.386668387055397\n",
      "trial: 5, iter: 600, curr loss: 1.3861690759658813, avg loss: 1.3866265892982483\n",
      "trial: 5, iter: 800, curr loss: 1.386741042137146, avg loss: 1.3863938170671464\n",
      "trial: 5, iter: 1000, curr loss: 1.3872662782669067, avg loss: 1.3864158976078034\n",
      "trial: 5, iter: 1200, curr loss: 1.3873975276947021, avg loss: 1.386442739367485\n",
      "trial: 5, iter: 1400, curr loss: 1.3863996267318726, avg loss: 1.3864343249797821\n",
      "trial: 5, iter: 1600, curr loss: 1.38685142993927, avg loss: 1.3863745266199112\n",
      "trial: 5, iter: 1800, curr loss: 1.3880494832992554, avg loss: 1.3864103931188583\n",
      "trial: 5, iter: 2000, curr loss: 1.3863868713378906, avg loss: 1.3864303815364838\n",
      "trial: 5, iter: 2200, curr loss: 1.3855949640274048, avg loss: 1.3863685327768325\n",
      "trial: 5, iter: 2400, curr loss: 1.3864315748214722, avg loss: 1.3864062070846557\n",
      "trial: 5, iter: 2600, curr loss: 1.3856905698776245, avg loss: 1.3863531750440599\n",
      "trial: 5, iter: 2800, curr loss: 1.3866467475891113, avg loss: 1.3863926386833192\n",
      "trial: 5, iter: 3000, curr loss: 1.3860435485839844, avg loss: 1.3863451075553894\n",
      "trial: 5, ldr: 0.0027999444864690304\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0038903485983610153\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873413801193237, avg loss: 1.3873291766643525\n",
      "trial: 1, iter: 400, curr loss: 1.3873564004898071, avg loss: 1.3868223804235458\n",
      "trial: 1, iter: 600, curr loss: 1.3875012397766113, avg loss: 1.3865662825107574\n",
      "trial: 1, iter: 800, curr loss: 1.3847670555114746, avg loss: 1.3865680181980133\n",
      "trial: 1, iter: 1000, curr loss: 1.3916364908218384, avg loss: 1.3864405703544618\n",
      "trial: 1, iter: 1200, curr loss: 1.3845967054367065, avg loss: 1.3865350663661957\n",
      "trial: 1, iter: 1400, curr loss: 1.384785771369934, avg loss: 1.3864071518182755\n",
      "trial: 1, iter: 1600, curr loss: 1.3869813680648804, avg loss: 1.3863375610113144\n",
      "trial: 1, iter: 1800, curr loss: 1.3877413272857666, avg loss: 1.3864907801151276\n",
      "trial: 1, iter: 2000, curr loss: 1.3862932920455933, avg loss: 1.3864596444368362\n",
      "trial: 1, iter: 2200, curr loss: 1.3857837915420532, avg loss: 1.386416421532631\n",
      "trial: 1, iter: 2400, curr loss: 1.3859634399414062, avg loss: 1.386428884267807\n",
      "trial: 1, iter: 2600, curr loss: 1.386985421180725, avg loss: 1.3863604819774629\n",
      "trial: 1, iter: 2800, curr loss: 1.3854073286056519, avg loss: 1.3863525134325028\n",
      "trial: 1, iter: 3000, curr loss: 1.386980652809143, avg loss: 1.3863087952136994\n",
      "trial: 1, ldr: -0.016208939254283905\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3841500282287598, avg loss: 1.387456121444702\n",
      "trial: 2, iter: 400, curr loss: 1.3877675533294678, avg loss: 1.386848173737526\n",
      "trial: 2, iter: 600, curr loss: 1.3872462511062622, avg loss: 1.386752457022667\n",
      "trial: 2, iter: 800, curr loss: 1.3847920894622803, avg loss: 1.3865155339241029\n",
      "trial: 2, iter: 1000, curr loss: 1.3871638774871826, avg loss: 1.3865386575460434\n",
      "trial: 2, iter: 1200, curr loss: 1.3872958421707153, avg loss: 1.3864792639017105\n",
      "trial: 2, iter: 1400, curr loss: 1.3865916728973389, avg loss: 1.3864347487688065\n",
      "trial: 2, iter: 1600, curr loss: 1.3860480785369873, avg loss: 1.3863563132286072\n",
      "trial: 2, iter: 1800, curr loss: 1.38628089427948, avg loss: 1.3863262051343919\n",
      "trial: 2, iter: 2000, curr loss: 1.386587381362915, avg loss: 1.3864259731769562\n",
      "trial: 2, iter: 2200, curr loss: 1.3853318691253662, avg loss: 1.3863540780544281\n",
      "trial: 2, iter: 2400, curr loss: 1.386694312095642, avg loss: 1.386312552690506\n",
      "trial: 2, iter: 2600, curr loss: 1.3862807750701904, avg loss: 1.3863878172636033\n",
      "trial: 2, iter: 2800, curr loss: 1.3861535787582397, avg loss: 1.3863382136821747\n",
      "trial: 2, iter: 3000, curr loss: 1.386187195777893, avg loss: 1.3863327568769455\n",
      "trial: 2, ldr: 0.006977955810725689\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3849512338638306, avg loss: 1.3871849250793458\n",
      "trial: 3, iter: 400, curr loss: 1.3850953578948975, avg loss: 1.3864639991521834\n",
      "trial: 3, iter: 600, curr loss: 1.386495590209961, avg loss: 1.3865518015623093\n",
      "trial: 3, iter: 800, curr loss: 1.3879390954971313, avg loss: 1.3864949136972426\n",
      "trial: 3, iter: 1000, curr loss: 1.3863651752471924, avg loss: 1.3864222002029418\n",
      "trial: 3, iter: 1200, curr loss: 1.3866022825241089, avg loss: 1.3865099918842316\n",
      "trial: 3, iter: 1400, curr loss: 1.3872462511062622, avg loss: 1.3863526690006256\n",
      "trial: 3, iter: 1600, curr loss: 1.386133074760437, avg loss: 1.386365339756012\n",
      "trial: 3, iter: 1800, curr loss: 1.3869794607162476, avg loss: 1.386364804506302\n",
      "trial: 3, iter: 2000, curr loss: 1.3858145475387573, avg loss: 1.3863754159212112\n",
      "trial: 3, iter: 2200, curr loss: 1.3864668607711792, avg loss: 1.386371351480484\n",
      "trial: 3, iter: 2400, curr loss: 1.3857389688491821, avg loss: 1.3863327926397324\n",
      "trial: 3, iter: 2600, curr loss: 1.3862920999526978, avg loss: 1.386377071738243\n",
      "trial: 3, iter: 2800, curr loss: 1.3864326477050781, avg loss: 1.3863394564390183\n",
      "trial: 3, iter: 3000, curr loss: 1.3861645460128784, avg loss: 1.386357497572899\n",
      "trial: 3, ldr: 0.0005134054808877409\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3869624137878418, avg loss: 1.387221799492836\n",
      "trial: 4, iter: 400, curr loss: 1.3863478899002075, avg loss: 1.3866581743955613\n",
      "trial: 4, iter: 600, curr loss: 1.387235164642334, avg loss: 1.38662307202816\n",
      "trial: 4, iter: 800, curr loss: 1.387704849243164, avg loss: 1.3865898555517198\n",
      "trial: 4, iter: 1000, curr loss: 1.3859431743621826, avg loss: 1.3865584790706635\n",
      "trial: 4, iter: 1200, curr loss: 1.3874869346618652, avg loss: 1.3864699393510818\n",
      "trial: 4, iter: 1400, curr loss: 1.388447642326355, avg loss: 1.3865257811546325\n",
      "trial: 4, iter: 1600, curr loss: 1.3866603374481201, avg loss: 1.3865225595235824\n",
      "trial: 4, iter: 1800, curr loss: 1.3855501413345337, avg loss: 1.3863435012102128\n",
      "trial: 4, iter: 2000, curr loss: 1.3862934112548828, avg loss: 1.3865140891075134\n",
      "trial: 4, iter: 2200, curr loss: 1.386099100112915, avg loss: 1.386416341662407\n",
      "trial: 4, iter: 2400, curr loss: 1.3868037462234497, avg loss: 1.3863720726966857\n",
      "trial: 4, iter: 2600, curr loss: 1.386559009552002, avg loss: 1.3863712286949157\n",
      "trial: 4, iter: 2800, curr loss: 1.3872449398040771, avg loss: 1.3863120049238205\n",
      "trial: 4, iter: 3000, curr loss: 1.3876850605010986, avg loss: 1.3863702541589737\n",
      "trial: 4, ldr: -0.017479456961154938\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3825219869613647, avg loss: 1.386724744439125\n",
      "trial: 5, iter: 400, curr loss: 1.3868205547332764, avg loss: 1.3868234032392501\n",
      "trial: 5, iter: 600, curr loss: 1.3872216939926147, avg loss: 1.3864094424247742\n",
      "trial: 5, iter: 800, curr loss: 1.3870140314102173, avg loss: 1.386597573161125\n",
      "trial: 5, iter: 1000, curr loss: 1.3864878416061401, avg loss: 1.3864984101057052\n",
      "trial: 5, iter: 1200, curr loss: 1.386281967163086, avg loss: 1.3863617128133774\n",
      "trial: 5, iter: 1400, curr loss: 1.3879261016845703, avg loss: 1.3864314424991608\n",
      "trial: 5, iter: 1600, curr loss: 1.3863948583602905, avg loss: 1.3864285123348237\n",
      "trial: 5, iter: 1800, curr loss: 1.3872088193893433, avg loss: 1.3864046210050582\n",
      "trial: 5, iter: 2000, curr loss: 1.3864737749099731, avg loss: 1.3863829690217973\n",
      "trial: 5, iter: 2200, curr loss: 1.3860712051391602, avg loss: 1.3863850241899491\n",
      "trial: 5, iter: 2400, curr loss: 1.3867360353469849, avg loss: 1.3864116483926774\n",
      "trial: 5, iter: 2600, curr loss: 1.3857418298721313, avg loss: 1.3863846737146377\n",
      "trial: 5, iter: 2800, curr loss: 1.3864234685897827, avg loss: 1.38638401389122\n",
      "trial: 5, iter: 3000, curr loss: 1.3862111568450928, avg loss: 1.386342677474022\n",
      "trial: 5, ldr: -0.01854516752064228\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.008948440488893539\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862632513046265, avg loss: 1.387125450372696\n",
      "trial: 1, iter: 400, curr loss: 1.3858864307403564, avg loss: 1.3866318565607072\n",
      "trial: 1, iter: 600, curr loss: 1.3849915266036987, avg loss: 1.3864111560583114\n",
      "trial: 1, iter: 800, curr loss: 1.3859854936599731, avg loss: 1.386401270031929\n",
      "trial: 1, iter: 1000, curr loss: 1.3873006105422974, avg loss: 1.3864618545770646\n",
      "trial: 1, iter: 1200, curr loss: 1.386367678642273, avg loss: 1.386395691037178\n",
      "trial: 1, iter: 1400, curr loss: 1.3865303993225098, avg loss: 1.3864572954177856\n",
      "trial: 1, iter: 1600, curr loss: 1.385449767112732, avg loss: 1.386342688202858\n",
      "trial: 1, iter: 1800, curr loss: 1.385573148727417, avg loss: 1.386418285369873\n",
      "trial: 1, iter: 2000, curr loss: 1.3859935998916626, avg loss: 1.3863732278347016\n",
      "trial: 1, iter: 2200, curr loss: 1.3869471549987793, avg loss: 1.3864198291301728\n",
      "trial: 1, iter: 2400, curr loss: 1.3866254091262817, avg loss: 1.386358817219734\n",
      "trial: 1, iter: 2600, curr loss: 1.3865336179733276, avg loss: 1.386322363615036\n",
      "trial: 1, iter: 2800, curr loss: 1.3859251737594604, avg loss: 1.3863688480854035\n",
      "trial: 1, iter: 3000, curr loss: 1.386366844177246, avg loss: 1.3863046228885652\n",
      "trial: 1, ldr: 0.0005008954904042184\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3850390911102295, avg loss: 1.3874152302742004\n",
      "trial: 2, iter: 400, curr loss: 1.3893561363220215, avg loss: 1.3865506094694138\n",
      "trial: 2, iter: 600, curr loss: 1.3841227293014526, avg loss: 1.386404367685318\n",
      "trial: 2, iter: 800, curr loss: 1.3859171867370605, avg loss: 1.3865241408348083\n",
      "trial: 2, iter: 1000, curr loss: 1.3856769800186157, avg loss: 1.386451288461685\n",
      "trial: 2, iter: 1200, curr loss: 1.3858968019485474, avg loss: 1.3865317118167877\n",
      "trial: 2, iter: 1400, curr loss: 1.3861879110336304, avg loss: 1.3864396446943283\n",
      "trial: 2, iter: 1600, curr loss: 1.3859403133392334, avg loss: 1.386315519809723\n",
      "trial: 2, iter: 1800, curr loss: 1.3859626054763794, avg loss: 1.3863940066099167\n",
      "trial: 2, iter: 2000, curr loss: 1.3875517845153809, avg loss: 1.3863348656892776\n",
      "trial: 2, iter: 2200, curr loss: 1.3866188526153564, avg loss: 1.3863680547475814\n",
      "trial: 2, iter: 2400, curr loss: 1.3868082761764526, avg loss: 1.386372520327568\n",
      "trial: 2, iter: 2600, curr loss: 1.3855035305023193, avg loss: 1.3863314008712768\n",
      "trial: 2, iter: 2800, curr loss: 1.3856375217437744, avg loss: 1.3863792872428895\n",
      "trial: 2, iter: 3000, curr loss: 1.386053442955017, avg loss: 1.3863266342878342\n",
      "trial: 2, ldr: 0.005054631736129522\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.381577730178833, avg loss: 1.3873538613319396\n",
      "trial: 3, iter: 400, curr loss: 1.3848843574523926, avg loss: 1.387028587460518\n",
      "trial: 3, iter: 600, curr loss: 1.3861312866210938, avg loss: 1.3865596556663513\n",
      "trial: 3, iter: 800, curr loss: 1.386027216911316, avg loss: 1.3865121436119079\n",
      "trial: 3, iter: 1000, curr loss: 1.3873076438903809, avg loss: 1.3865157252550124\n",
      "trial: 3, iter: 1200, curr loss: 1.3872946500778198, avg loss: 1.3863613146543503\n",
      "trial: 3, iter: 1400, curr loss: 1.3874543905258179, avg loss: 1.3864936500787735\n",
      "trial: 3, iter: 1600, curr loss: 1.3857250213623047, avg loss: 1.3864819568395614\n",
      "trial: 3, iter: 1800, curr loss: 1.3863002061843872, avg loss: 1.3864042556285858\n",
      "trial: 3, iter: 2000, curr loss: 1.3885685205459595, avg loss: 1.3863649243116378\n",
      "trial: 3, iter: 2200, curr loss: 1.3869003057479858, avg loss: 1.3863664960861206\n",
      "trial: 3, iter: 2400, curr loss: 1.3861641883850098, avg loss: 1.3863541680574416\n",
      "trial: 3, iter: 2600, curr loss: 1.386588454246521, avg loss: 1.3863366335630416\n",
      "trial: 3, iter: 2800, curr loss: 1.3860517740249634, avg loss: 1.3863653314113618\n",
      "trial: 3, iter: 3000, curr loss: 1.3859648704528809, avg loss: 1.3863392186164856\n",
      "trial: 3, ldr: -0.013252160511910915\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3861359357833862, avg loss: 1.3872482240200044\n",
      "trial: 4, iter: 400, curr loss: 1.3855003118515015, avg loss: 1.3866663444042207\n",
      "trial: 4, iter: 600, curr loss: 1.3863298892974854, avg loss: 1.3864519596099854\n",
      "trial: 4, iter: 800, curr loss: 1.3849595785140991, avg loss: 1.386536122560501\n",
      "trial: 4, iter: 1000, curr loss: 1.3857187032699585, avg loss: 1.3865139865875244\n",
      "trial: 4, iter: 1200, curr loss: 1.385408878326416, avg loss: 1.3864300841093062\n",
      "trial: 4, iter: 1400, curr loss: 1.3852317333221436, avg loss: 1.3864200109243392\n",
      "trial: 4, iter: 1600, curr loss: 1.3860735893249512, avg loss: 1.386413688659668\n",
      "trial: 4, iter: 1800, curr loss: 1.3851439952850342, avg loss: 1.3863670760393143\n",
      "trial: 4, iter: 2000, curr loss: 1.3869247436523438, avg loss: 1.3864535027742386\n",
      "trial: 4, iter: 2200, curr loss: 1.3855656385421753, avg loss: 1.3863726991415024\n",
      "trial: 4, iter: 2400, curr loss: 1.3870220184326172, avg loss: 1.3863380205631257\n",
      "trial: 4, iter: 2600, curr loss: 1.387441873550415, avg loss: 1.386384453177452\n",
      "trial: 4, iter: 2800, curr loss: 1.3868281841278076, avg loss: 1.3864013397693633\n",
      "trial: 4, iter: 3000, curr loss: 1.3871753215789795, avg loss: 1.386341819167137\n",
      "trial: 4, ldr: -0.002761946525424719\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3892638683319092, avg loss: 1.3871196919679643\n",
      "trial: 5, iter: 400, curr loss: 1.3871243000030518, avg loss: 1.3866354084014894\n",
      "trial: 5, iter: 600, curr loss: 1.3851497173309326, avg loss: 1.3865835928916932\n",
      "trial: 5, iter: 800, curr loss: 1.3850963115692139, avg loss: 1.3863979011774064\n",
      "trial: 5, iter: 1000, curr loss: 1.3865352869033813, avg loss: 1.3865499269962311\n",
      "trial: 5, iter: 1200, curr loss: 1.3848921060562134, avg loss: 1.386403682231903\n",
      "trial: 5, iter: 1400, curr loss: 1.3860032558441162, avg loss: 1.3863901996612549\n",
      "trial: 5, iter: 1600, curr loss: 1.3862203359603882, avg loss: 1.38634812772274\n",
      "trial: 5, iter: 1800, curr loss: 1.3861533403396606, avg loss: 1.3863889408111572\n",
      "trial: 5, iter: 2000, curr loss: 1.3857166767120361, avg loss: 1.3863483929634095\n",
      "trial: 5, iter: 2200, curr loss: 1.3852938413619995, avg loss: 1.3864188802242279\n",
      "trial: 5, iter: 2400, curr loss: 1.385454773902893, avg loss: 1.3865195548534393\n",
      "trial: 5, iter: 2600, curr loss: 1.3884034156799316, avg loss: 1.386278664469719\n",
      "trial: 5, iter: 2800, curr loss: 1.3857730627059937, avg loss: 1.3863597589731216\n",
      "trial: 5, iter: 3000, curr loss: 1.3877795934677124, avg loss: 1.386349709033966\n",
      "trial: 5, ldr: 0.019948583096265793\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0018980006570927799\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3875147104263306, avg loss: 1.3875075644254684\n",
      "trial: 1, iter: 400, curr loss: 1.384353518486023, avg loss: 1.386748982667923\n",
      "trial: 1, iter: 600, curr loss: 1.3859084844589233, avg loss: 1.386668546795845\n",
      "trial: 1, iter: 800, curr loss: 1.3855047225952148, avg loss: 1.3863004904985428\n",
      "trial: 1, iter: 1000, curr loss: 1.3870137929916382, avg loss: 1.3866822946071624\n",
      "trial: 1, iter: 1200, curr loss: 1.3855277299880981, avg loss: 1.386449572443962\n",
      "trial: 1, iter: 1400, curr loss: 1.3867186307907104, avg loss: 1.3865626579523087\n",
      "trial: 1, iter: 1600, curr loss: 1.3860771656036377, avg loss: 1.386388322710991\n",
      "trial: 1, iter: 1800, curr loss: 1.3869532346725464, avg loss: 1.3864380437135697\n",
      "trial: 1, iter: 2000, curr loss: 1.3858146667480469, avg loss: 1.3865071761608123\n",
      "trial: 1, iter: 2200, curr loss: 1.385418176651001, avg loss: 1.386384873986244\n",
      "trial: 1, iter: 2400, curr loss: 1.3866991996765137, avg loss: 1.3863638532161713\n",
      "trial: 1, iter: 2600, curr loss: 1.3859407901763916, avg loss: 1.3862940496206284\n",
      "trial: 1, iter: 2800, curr loss: 1.3866467475891113, avg loss: 1.386344839334488\n",
      "trial: 1, iter: 3000, curr loss: 1.3857275247573853, avg loss: 1.3863856047391891\n",
      "trial: 1, ldr: 0.013351705856621265\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866757154464722, avg loss: 1.3874975562095642\n",
      "trial: 2, iter: 400, curr loss: 1.3870935440063477, avg loss: 1.3866795992851257\n",
      "trial: 2, iter: 600, curr loss: 1.3841745853424072, avg loss: 1.386589223742485\n",
      "trial: 2, iter: 800, curr loss: 1.387854814529419, avg loss: 1.3865611636638642\n",
      "trial: 2, iter: 1000, curr loss: 1.3855708837509155, avg loss: 1.3864763379096985\n",
      "trial: 2, iter: 1200, curr loss: 1.3869647979736328, avg loss: 1.3864749139547348\n",
      "trial: 2, iter: 1400, curr loss: 1.3864386081695557, avg loss: 1.3864273726940155\n",
      "trial: 2, iter: 1600, curr loss: 1.3867744207382202, avg loss: 1.3864691042900086\n",
      "trial: 2, iter: 1800, curr loss: 1.3860753774642944, avg loss: 1.3864226758480072\n",
      "trial: 2, iter: 2000, curr loss: 1.3873370885849, avg loss: 1.3864390391111374\n",
      "trial: 2, iter: 2200, curr loss: 1.3860355615615845, avg loss: 1.3864372569322585\n",
      "trial: 2, iter: 2400, curr loss: 1.3870189189910889, avg loss: 1.3863454782962799\n",
      "trial: 2, iter: 2600, curr loss: 1.3861840963363647, avg loss: 1.3864172941446304\n",
      "trial: 2, iter: 2800, curr loss: 1.3861676454544067, avg loss: 1.3863613498210907\n",
      "trial: 2, iter: 3000, curr loss: 1.3863122463226318, avg loss: 1.3864023917913437\n",
      "trial: 2, ldr: 0.015316829085350037\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3864248991012573, avg loss: 1.3873565942049026\n",
      "trial: 3, iter: 400, curr loss: 1.38631010055542, avg loss: 1.3866388952732087\n",
      "trial: 3, iter: 600, curr loss: 1.385136365890503, avg loss: 1.3865171533823013\n",
      "trial: 3, iter: 800, curr loss: 1.386130452156067, avg loss: 1.3866594272851944\n",
      "trial: 3, iter: 1000, curr loss: 1.3870818614959717, avg loss: 1.3866683530807495\n",
      "trial: 3, iter: 1200, curr loss: 1.3856157064437866, avg loss: 1.3864890986680984\n",
      "trial: 3, iter: 1400, curr loss: 1.385509967803955, avg loss: 1.3865600895881653\n",
      "trial: 3, iter: 1600, curr loss: 1.3864730596542358, avg loss: 1.3863952112197877\n",
      "trial: 3, iter: 1800, curr loss: 1.3857358694076538, avg loss: 1.386402018070221\n",
      "trial: 3, iter: 2000, curr loss: 1.3854899406433105, avg loss: 1.3864562910795213\n",
      "trial: 3, iter: 2200, curr loss: 1.3870371580123901, avg loss: 1.3863898926973344\n",
      "trial: 3, iter: 2400, curr loss: 1.3862226009368896, avg loss: 1.386423266530037\n",
      "trial: 3, iter: 2600, curr loss: 1.385875940322876, avg loss: 1.3863643938302994\n",
      "trial: 3, iter: 2800, curr loss: 1.3855286836624146, avg loss: 1.3863847422599793\n",
      "trial: 3, iter: 3000, curr loss: 1.3872153759002686, avg loss: 1.3864094918966294\n",
      "trial: 3, ldr: 0.009404956363141537\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.383389949798584, avg loss: 1.3877759563922882\n",
      "trial: 4, iter: 400, curr loss: 1.3868978023529053, avg loss: 1.3867354410886765\n",
      "trial: 4, iter: 600, curr loss: 1.3861289024353027, avg loss: 1.3865903103351593\n",
      "trial: 4, iter: 800, curr loss: 1.3866605758666992, avg loss: 1.3866019493341446\n",
      "trial: 4, iter: 1000, curr loss: 1.3867837190628052, avg loss: 1.386484831571579\n",
      "trial: 4, iter: 1200, curr loss: 1.3895514011383057, avg loss: 1.3864787244796752\n",
      "trial: 4, iter: 1400, curr loss: 1.3861956596374512, avg loss: 1.3864187288284302\n",
      "trial: 4, iter: 1600, curr loss: 1.386904001235962, avg loss: 1.3864077818393707\n",
      "trial: 4, iter: 1800, curr loss: 1.3846811056137085, avg loss: 1.3863702297210694\n",
      "trial: 4, iter: 2000, curr loss: 1.3874012231826782, avg loss: 1.3864577257633208\n",
      "trial: 4, iter: 2200, curr loss: 1.3859366178512573, avg loss: 1.38643463909626\n",
      "trial: 4, iter: 2400, curr loss: 1.387324571609497, avg loss: 1.3863686567544937\n",
      "trial: 4, iter: 2600, curr loss: 1.385712742805481, avg loss: 1.3863802820444107\n",
      "trial: 4, iter: 2800, curr loss: 1.385991096496582, avg loss: 1.3863602167367934\n",
      "trial: 4, iter: 3000, curr loss: 1.3866214752197266, avg loss: 1.3863759183883666\n",
      "trial: 4, ldr: 0.01044306717813015\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3855527639389038, avg loss: 1.3874050569534302\n",
      "trial: 5, iter: 400, curr loss: 1.3863245248794556, avg loss: 1.3866585558652877\n",
      "trial: 5, iter: 600, curr loss: 1.3853471279144287, avg loss: 1.3864560639858245\n",
      "trial: 5, iter: 800, curr loss: 1.3865257501602173, avg loss: 1.3864596605300903\n",
      "trial: 5, iter: 1000, curr loss: 1.3856475353240967, avg loss: 1.3864878576993942\n",
      "trial: 5, iter: 1200, curr loss: 1.3852139711380005, avg loss: 1.386373594403267\n",
      "trial: 5, iter: 1400, curr loss: 1.3870635032653809, avg loss: 1.3863803750276567\n",
      "trial: 5, iter: 1600, curr loss: 1.3875491619110107, avg loss: 1.3863872653245926\n",
      "trial: 5, iter: 1800, curr loss: 1.3869904279708862, avg loss: 1.3863476818799974\n",
      "trial: 5, iter: 2000, curr loss: 1.3866567611694336, avg loss: 1.3863530087471008\n",
      "trial: 5, iter: 2200, curr loss: 1.3872178792953491, avg loss: 1.3864476084709167\n",
      "trial: 5, iter: 2400, curr loss: 1.386673927307129, avg loss: 1.38634801030159\n",
      "trial: 5, iter: 2600, curr loss: 1.386518955230713, avg loss: 1.3863959580659866\n",
      "trial: 5, iter: 2800, curr loss: 1.3863786458969116, avg loss: 1.3864049708843231\n",
      "trial: 5, iter: 3000, curr loss: 1.3857712745666504, avg loss: 1.386372754573822\n",
      "trial: 5, ldr: -0.02475850284099579\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00475161112844944\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3829072713851929, avg loss: 1.3872274714708328\n",
      "trial: 1, iter: 400, curr loss: 1.3894480466842651, avg loss: 1.3867889374494553\n",
      "trial: 1, iter: 600, curr loss: 1.3870266675949097, avg loss: 1.386557993888855\n",
      "trial: 1, iter: 800, curr loss: 1.3871619701385498, avg loss: 1.3864503622055053\n",
      "trial: 1, iter: 1000, curr loss: 1.3867878913879395, avg loss: 1.386357412338257\n",
      "trial: 1, iter: 1200, curr loss: 1.3866236209869385, avg loss: 1.386399194598198\n",
      "trial: 1, iter: 1400, curr loss: 1.3853076696395874, avg loss: 1.3864425987005233\n",
      "trial: 1, iter: 1600, curr loss: 1.3866803646087646, avg loss: 1.386346390247345\n",
      "trial: 1, iter: 1800, curr loss: 1.3858661651611328, avg loss: 1.386439653635025\n",
      "trial: 1, iter: 2000, curr loss: 1.3858726024627686, avg loss: 1.3864022034406662\n",
      "trial: 1, iter: 2200, curr loss: 1.386087417602539, avg loss: 1.3862965708971025\n",
      "trial: 1, iter: 2400, curr loss: 1.3873151540756226, avg loss: 1.3865068596601486\n",
      "trial: 1, iter: 2600, curr loss: 1.3881150484085083, avg loss: 1.3863673084974288\n",
      "trial: 1, iter: 2800, curr loss: 1.3872416019439697, avg loss: 1.386372219324112\n",
      "trial: 1, iter: 3000, curr loss: 1.3864612579345703, avg loss: 1.3863376742601394\n",
      "trial: 1, ldr: 0.014749082736670971\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.38576340675354, avg loss: 1.3875504839420318\n",
      "trial: 2, iter: 400, curr loss: 1.3893243074417114, avg loss: 1.3866808450222015\n",
      "trial: 2, iter: 600, curr loss: 1.385892629623413, avg loss: 1.3864724677801132\n",
      "trial: 2, iter: 800, curr loss: 1.386925220489502, avg loss: 1.3866235560178757\n",
      "trial: 2, iter: 1000, curr loss: 1.3884004354476929, avg loss: 1.3865251654386521\n",
      "trial: 2, iter: 1200, curr loss: 1.3842854499816895, avg loss: 1.3864582413434983\n",
      "trial: 2, iter: 1400, curr loss: 1.386450171470642, avg loss: 1.3864168018102645\n",
      "trial: 2, iter: 1600, curr loss: 1.386628270149231, avg loss: 1.3863750994205475\n",
      "trial: 2, iter: 1800, curr loss: 1.3870822191238403, avg loss: 1.3864513802528382\n",
      "trial: 2, iter: 2000, curr loss: 1.3860701322555542, avg loss: 1.3863770228624344\n",
      "trial: 2, iter: 2200, curr loss: 1.3856751918792725, avg loss: 1.386443566083908\n",
      "trial: 2, iter: 2400, curr loss: 1.3862215280532837, avg loss: 1.386418736577034\n",
      "trial: 2, iter: 2600, curr loss: 1.3857395648956299, avg loss: 1.3863791185617447\n",
      "trial: 2, iter: 2800, curr loss: 1.3866777420043945, avg loss: 1.386311394572258\n",
      "trial: 2, iter: 3000, curr loss: 1.3862122297286987, avg loss: 1.3864411669969559\n",
      "trial: 2, ldr: -0.007690103258937597\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3857117891311646, avg loss: 1.3874486434459685\n",
      "trial: 3, iter: 400, curr loss: 1.388031005859375, avg loss: 1.3866399693489075\n",
      "trial: 3, iter: 600, curr loss: 1.388380765914917, avg loss: 1.3865079003572465\n",
      "trial: 3, iter: 800, curr loss: 1.3873780965805054, avg loss: 1.3866757655143738\n",
      "trial: 3, iter: 1000, curr loss: 1.3858904838562012, avg loss: 1.3865480548143387\n",
      "trial: 3, iter: 1200, curr loss: 1.3861907720565796, avg loss: 1.3864943635463716\n",
      "trial: 3, iter: 1400, curr loss: 1.3840570449829102, avg loss: 1.3864417254924775\n",
      "trial: 3, iter: 1600, curr loss: 1.3873640298843384, avg loss: 1.3864340728521347\n",
      "trial: 3, iter: 1800, curr loss: 1.3871821165084839, avg loss: 1.386472582221031\n",
      "trial: 3, iter: 2000, curr loss: 1.3878190517425537, avg loss: 1.3863411766290665\n",
      "trial: 3, iter: 2200, curr loss: 1.386674165725708, avg loss: 1.386454616189003\n",
      "trial: 3, iter: 2400, curr loss: 1.3867285251617432, avg loss: 1.3864022666215896\n",
      "trial: 3, iter: 2600, curr loss: 1.3866156339645386, avg loss: 1.3863586056232453\n",
      "trial: 3, iter: 2800, curr loss: 1.386575698852539, avg loss: 1.386348730325699\n",
      "trial: 3, iter: 3000, curr loss: 1.386423945426941, avg loss: 1.3863488429784774\n",
      "trial: 3, ldr: 0.00833839736878872\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3855301141738892, avg loss: 1.3873550778627395\n",
      "trial: 4, iter: 400, curr loss: 1.386637806892395, avg loss: 1.386620619893074\n",
      "trial: 4, iter: 600, curr loss: 1.3859485387802124, avg loss: 1.3864305853843688\n",
      "trial: 4, iter: 800, curr loss: 1.3847414255142212, avg loss: 1.386431072950363\n",
      "trial: 4, iter: 1000, curr loss: 1.3841981887817383, avg loss: 1.3864959931373597\n",
      "trial: 4, iter: 1200, curr loss: 1.3869292736053467, avg loss: 1.3863867896795272\n",
      "trial: 4, iter: 1400, curr loss: 1.3861578702926636, avg loss: 1.386452635526657\n",
      "trial: 4, iter: 1600, curr loss: 1.3870346546173096, avg loss: 1.3864411479234695\n",
      "trial: 4, iter: 1800, curr loss: 1.3863741159439087, avg loss: 1.386412337422371\n",
      "trial: 4, iter: 2000, curr loss: 1.385975956916809, avg loss: 1.3863937199115752\n",
      "trial: 4, iter: 2200, curr loss: 1.3865482807159424, avg loss: 1.3863661360740662\n",
      "trial: 4, iter: 2400, curr loss: 1.385773777961731, avg loss: 1.3863591474294663\n",
      "trial: 4, iter: 2600, curr loss: 1.3862179517745972, avg loss: 1.3863410252332686\n",
      "trial: 4, iter: 2800, curr loss: 1.3869585990905762, avg loss: 1.3863309502601624\n",
      "trial: 4, iter: 3000, curr loss: 1.3864030838012695, avg loss: 1.386328027844429\n",
      "trial: 4, ldr: 0.001315257977694273\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3866370916366577, avg loss: 1.3873913556337356\n",
      "trial: 5, iter: 400, curr loss: 1.385274052619934, avg loss: 1.386566167473793\n",
      "trial: 5, iter: 600, curr loss: 1.385879397392273, avg loss: 1.386498750448227\n",
      "trial: 5, iter: 800, curr loss: 1.3867254257202148, avg loss: 1.3864581191539764\n",
      "trial: 5, iter: 1000, curr loss: 1.3855924606323242, avg loss: 1.3863813072443008\n",
      "trial: 5, iter: 1200, curr loss: 1.3865525722503662, avg loss: 1.386449077129364\n",
      "trial: 5, iter: 1400, curr loss: 1.3871954679489136, avg loss: 1.3863789361715317\n",
      "trial: 5, iter: 1600, curr loss: 1.3862959146499634, avg loss: 1.386363429427147\n",
      "trial: 5, iter: 1800, curr loss: 1.386344075202942, avg loss: 1.386569567322731\n",
      "trial: 5, iter: 2000, curr loss: 1.384758472442627, avg loss: 1.3865533542633057\n",
      "trial: 5, iter: 2200, curr loss: 1.3871471881866455, avg loss: 1.386421618461609\n",
      "trial: 5, iter: 2400, curr loss: 1.3871262073516846, avg loss: 1.3863246458768845\n",
      "trial: 5, iter: 2600, curr loss: 1.3859403133392334, avg loss: 1.386430907845497\n",
      "trial: 5, iter: 2800, curr loss: 1.386675477027893, avg loss: 1.386350547671318\n",
      "trial: 5, iter: 3000, curr loss: 1.3866868019104004, avg loss: 1.386272302865982\n",
      "trial: 5, ldr: 0.008316886611282825\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.005005904287099838\n",
      "Experiment done with data path: ./data/catNon-lin-NI_18/data.10k.dz200.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_6/data.10k.dz20.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3853760957717896, avg loss: 1.387650825381279\n",
      "trial: 1, iter: 400, curr loss: 1.3883169889450073, avg loss: 1.3868019145727157\n",
      "trial: 1, iter: 600, curr loss: 1.3854620456695557, avg loss: 1.3863552242517472\n",
      "trial: 1, iter: 800, curr loss: 1.3848507404327393, avg loss: 1.385953467488289\n",
      "trial: 1, iter: 1000, curr loss: 1.3771817684173584, avg loss: 1.381628857254982\n",
      "trial: 1, iter: 1200, curr loss: 1.3486170768737793, avg loss: 1.3615381574630738\n",
      "trial: 1, iter: 1400, curr loss: 1.3252496719360352, avg loss: 1.3423611533641815\n",
      "trial: 1, iter: 1600, curr loss: 1.3646364212036133, avg loss: 1.3341101348400115\n",
      "trial: 1, iter: 1800, curr loss: 1.336107611656189, avg loss: 1.330264465212822\n",
      "trial: 1, iter: 2000, curr loss: 1.3302645683288574, avg loss: 1.3234004032611848\n",
      "trial: 1, iter: 2200, curr loss: 1.2981120347976685, avg loss: 1.31756298661232\n",
      "trial: 1, iter: 2400, curr loss: 1.3215465545654297, avg loss: 1.3150913977622987\n",
      "trial: 1, iter: 2600, curr loss: 1.3328523635864258, avg loss: 1.3060014748573303\n",
      "trial: 1, iter: 2800, curr loss: 1.3180136680603027, avg loss: 1.301403619647026\n",
      "trial: 1, iter: 3000, curr loss: 1.2559236288070679, avg loss: 1.297083271741867\n",
      "trial: 1, ldr: 0.24415071308612823\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.388397216796875, avg loss: 1.3874828499555587\n",
      "trial: 2, iter: 400, curr loss: 1.3864238262176514, avg loss: 1.386478555202484\n",
      "trial: 2, iter: 600, curr loss: 1.3840761184692383, avg loss: 1.3852330487966538\n",
      "trial: 2, iter: 800, curr loss: 1.3589253425598145, avg loss: 1.3778649443387985\n",
      "trial: 2, iter: 1000, curr loss: 1.366850733757019, avg loss: 1.3554560565948486\n",
      "trial: 2, iter: 1200, curr loss: 1.3315149545669556, avg loss: 1.3409558963775634\n",
      "trial: 2, iter: 1400, curr loss: 1.327639102935791, avg loss: 1.334692177772522\n",
      "trial: 2, iter: 1600, curr loss: 1.3107120990753174, avg loss: 1.3293488723039628\n",
      "trial: 2, iter: 1800, curr loss: 1.328737735748291, avg loss: 1.325280112028122\n",
      "trial: 2, iter: 2000, curr loss: 1.315976858139038, avg loss: 1.3210812109708785\n",
      "trial: 2, iter: 2200, curr loss: 1.3345502614974976, avg loss: 1.3166388791799546\n",
      "trial: 2, iter: 2400, curr loss: 1.3065966367721558, avg loss: 1.3084270906448365\n",
      "trial: 2, iter: 2600, curr loss: 1.3345640897750854, avg loss: 1.3039225083589554\n",
      "trial: 2, iter: 2800, curr loss: 1.2959747314453125, avg loss: 1.3001307600736618\n",
      "trial: 2, iter: 3000, curr loss: 1.3182774782180786, avg loss: 1.2965357679128646\n",
      "trial: 2, ldr: 0.2576034665107727\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3872257471084595, avg loss: 1.3875291043519973\n",
      "trial: 3, iter: 400, curr loss: 1.3888702392578125, avg loss: 1.3867165833711623\n",
      "trial: 3, iter: 600, curr loss: 1.381631851196289, avg loss: 1.3861878627538682\n",
      "trial: 3, iter: 800, curr loss: 1.378974437713623, avg loss: 1.3839195364713668\n",
      "trial: 3, iter: 1000, curr loss: 1.3539021015167236, avg loss: 1.3659735006093978\n",
      "trial: 3, iter: 1200, curr loss: 1.3329205513000488, avg loss: 1.3462765163183212\n",
      "trial: 3, iter: 1400, curr loss: 1.3218822479248047, avg loss: 1.334636652469635\n",
      "trial: 3, iter: 1600, curr loss: 1.3261795043945312, avg loss: 1.331389576792717\n",
      "trial: 3, iter: 1800, curr loss: 1.2980114221572876, avg loss: 1.3252685874700547\n",
      "trial: 3, iter: 2000, curr loss: 1.314063310623169, avg loss: 1.321686288714409\n",
      "trial: 3, iter: 2200, curr loss: 1.2686580419540405, avg loss: 1.3139794439077377\n",
      "trial: 3, iter: 2400, curr loss: 1.2919565439224243, avg loss: 1.308800926208496\n",
      "trial: 3, iter: 2600, curr loss: 1.3184844255447388, avg loss: 1.303070405125618\n",
      "trial: 3, iter: 2800, curr loss: 1.2805612087249756, avg loss: 1.2967632299661636\n",
      "trial: 3, iter: 3000, curr loss: 1.2830801010131836, avg loss: 1.2977925342321397\n",
      "trial: 3, ldr: 0.22958828508853912\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3884265422821045, avg loss: 1.3871520340442658\n",
      "trial: 4, iter: 400, curr loss: 1.3853662014007568, avg loss: 1.3867502844333648\n",
      "trial: 4, iter: 600, curr loss: 1.3878268003463745, avg loss: 1.386378352046013\n",
      "trial: 4, iter: 800, curr loss: 1.3858712911605835, avg loss: 1.3844723784923554\n",
      "trial: 4, iter: 1000, curr loss: 1.3794097900390625, avg loss: 1.3699508041143418\n",
      "trial: 4, iter: 1200, curr loss: 1.3487904071807861, avg loss: 1.3490065097808839\n",
      "trial: 4, iter: 1400, curr loss: 1.350587010383606, avg loss: 1.337094842195511\n",
      "trial: 4, iter: 1600, curr loss: 1.292806625366211, avg loss: 1.333159380555153\n",
      "trial: 4, iter: 1800, curr loss: 1.3321876525878906, avg loss: 1.3243019133806229\n",
      "trial: 4, iter: 2000, curr loss: 1.3015507459640503, avg loss: 1.321165356040001\n",
      "trial: 4, iter: 2200, curr loss: 1.3146562576293945, avg loss: 1.314939928650856\n",
      "trial: 4, iter: 2400, curr loss: 1.318150281906128, avg loss: 1.3119164329767228\n",
      "trial: 4, iter: 2600, curr loss: 1.3249142169952393, avg loss: 1.3032683432102203\n",
      "trial: 4, iter: 2800, curr loss: 1.2926464080810547, avg loss: 1.302663876414299\n",
      "trial: 4, iter: 3000, curr loss: 1.2665917873382568, avg loss: 1.2959577804803848\n",
      "trial: 4, ldr: 0.15009118616580963\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3883403539657593, avg loss: 1.3873326939344406\n",
      "trial: 5, iter: 400, curr loss: 1.3864363431930542, avg loss: 1.3866139543056488\n",
      "trial: 5, iter: 600, curr loss: 1.3856022357940674, avg loss: 1.3867173570394515\n",
      "trial: 5, iter: 800, curr loss: 1.386612892150879, avg loss: 1.3861979520320893\n",
      "trial: 5, iter: 1000, curr loss: 1.3855578899383545, avg loss: 1.3862352299690246\n",
      "trial: 5, iter: 1200, curr loss: 1.387184500694275, avg loss: 1.3835293000936508\n",
      "trial: 5, iter: 1400, curr loss: 1.3570772409439087, avg loss: 1.3650180846452713\n",
      "trial: 5, iter: 1600, curr loss: 1.3499854803085327, avg loss: 1.3437471014261246\n",
      "trial: 5, iter: 1800, curr loss: 1.3616447448730469, avg loss: 1.3371132427453996\n",
      "trial: 5, iter: 2000, curr loss: 1.3140915632247925, avg loss: 1.3306785029172898\n",
      "trial: 5, iter: 2200, curr loss: 1.3431552648544312, avg loss: 1.3255832767486573\n",
      "trial: 5, iter: 2400, curr loss: 1.3345694541931152, avg loss: 1.31962895154953\n",
      "trial: 5, iter: 2600, curr loss: 1.3207476139068604, avg loss: 1.3170188307762145\n",
      "trial: 5, iter: 2800, curr loss: 1.3040863275527954, avg loss: 1.3108651065826415\n",
      "trial: 5, iter: 3000, curr loss: 1.2890594005584717, avg loss: 1.3069025021791458\n",
      "trial: 5, ldr: 0.10636584460735321\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1975598990917206\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862725496292114, avg loss: 1.3875236505270003\n",
      "trial: 1, iter: 400, curr loss: 1.3885884284973145, avg loss: 1.3866743844747544\n",
      "trial: 1, iter: 600, curr loss: 1.3839945793151855, avg loss: 1.3861115872859955\n",
      "trial: 1, iter: 800, curr loss: 1.3825570344924927, avg loss: 1.384068002104759\n",
      "trial: 1, iter: 1000, curr loss: 1.352860927581787, avg loss: 1.3681149673461914\n",
      "trial: 1, iter: 1200, curr loss: 1.357547640800476, avg loss: 1.3484193539619447\n",
      "trial: 1, iter: 1400, curr loss: 1.3617053031921387, avg loss: 1.3414682465791703\n",
      "trial: 1, iter: 1600, curr loss: 1.3280247449874878, avg loss: 1.3388500362634659\n",
      "trial: 1, iter: 1800, curr loss: 1.3168084621429443, avg loss: 1.329256956577301\n",
      "trial: 1, iter: 2000, curr loss: 1.3295528888702393, avg loss: 1.3265817111730576\n",
      "trial: 1, iter: 2200, curr loss: 1.3267778158187866, avg loss: 1.3246611601114273\n",
      "trial: 1, iter: 2400, curr loss: 1.3550660610198975, avg loss: 1.317671586871147\n",
      "trial: 1, iter: 2600, curr loss: 1.322024941444397, avg loss: 1.3144510287046431\n",
      "trial: 1, iter: 2800, curr loss: 1.300976037979126, avg loss: 1.3077531725168228\n",
      "trial: 1, iter: 3000, curr loss: 1.3052198886871338, avg loss: 1.3014052057266234\n",
      "trial: 1, ldr: 0.13469721376895905\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3842616081237793, avg loss: 1.387474940419197\n",
      "trial: 2, iter: 400, curr loss: 1.38153076171875, avg loss: 1.386360032558441\n",
      "trial: 2, iter: 600, curr loss: 1.3847883939743042, avg loss: 1.3853335058689118\n",
      "trial: 2, iter: 800, curr loss: 1.3529136180877686, avg loss: 1.3746418875455857\n",
      "trial: 2, iter: 1000, curr loss: 1.3678122758865356, avg loss: 1.3536972534656524\n",
      "trial: 2, iter: 1200, curr loss: 1.3696606159210205, avg loss: 1.3416308397054673\n",
      "trial: 2, iter: 1400, curr loss: 1.321218729019165, avg loss: 1.3373584794998168\n",
      "trial: 2, iter: 1600, curr loss: 1.317607045173645, avg loss: 1.3324594390392304\n",
      "trial: 2, iter: 1800, curr loss: 1.3178822994232178, avg loss: 1.326258922815323\n",
      "trial: 2, iter: 2000, curr loss: 1.3022115230560303, avg loss: 1.3223449563980103\n",
      "trial: 2, iter: 2200, curr loss: 1.3054805994033813, avg loss: 1.319384651184082\n",
      "trial: 2, iter: 2400, curr loss: 1.2833189964294434, avg loss: 1.3107894760370256\n",
      "trial: 2, iter: 2600, curr loss: 1.3380684852600098, avg loss: 1.3061343598365784\n",
      "trial: 2, iter: 2800, curr loss: 1.2924919128417969, avg loss: 1.29905938744545\n",
      "trial: 2, iter: 3000, curr loss: 1.319107174873352, avg loss: 1.296411325931549\n",
      "trial: 2, ldr: 0.2417183667421341\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3872710466384888, avg loss: 1.3874125462770461\n",
      "trial: 3, iter: 400, curr loss: 1.3890846967697144, avg loss: 1.3869431495666504\n",
      "trial: 3, iter: 600, curr loss: 1.3892056941986084, avg loss: 1.3867046016454696\n",
      "trial: 3, iter: 800, curr loss: 1.3870151042938232, avg loss: 1.3861768108606338\n",
      "trial: 3, iter: 1000, curr loss: 1.3827967643737793, avg loss: 1.3850890129804612\n",
      "trial: 3, iter: 1200, curr loss: 1.3451179265975952, avg loss: 1.3712329006195068\n",
      "trial: 3, iter: 1400, curr loss: 1.3808531761169434, avg loss: 1.3486449420452118\n",
      "trial: 3, iter: 1600, curr loss: 1.3582297563552856, avg loss: 1.3410160946846008\n",
      "trial: 3, iter: 1800, curr loss: 1.327587604522705, avg loss: 1.3328018313646317\n",
      "trial: 3, iter: 2000, curr loss: 1.3101825714111328, avg loss: 1.326462898850441\n",
      "trial: 3, iter: 2200, curr loss: 1.3618783950805664, avg loss: 1.3215569788217545\n",
      "trial: 3, iter: 2400, curr loss: 1.2986750602722168, avg loss: 1.3194529390335084\n",
      "trial: 3, iter: 2600, curr loss: 1.3196418285369873, avg loss: 1.3106960088014603\n",
      "trial: 3, iter: 2800, curr loss: 1.2983900308609009, avg loss: 1.3054123467206955\n",
      "trial: 3, iter: 3000, curr loss: 1.2984791994094849, avg loss: 1.303683163523674\n",
      "trial: 3, ldr: 0.07638677954673767\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3853139877319336, avg loss: 1.3874667054414749\n",
      "trial: 4, iter: 400, curr loss: 1.3857338428497314, avg loss: 1.3866132360696792\n",
      "trial: 4, iter: 600, curr loss: 1.3856515884399414, avg loss: 1.3864552462100983\n",
      "trial: 4, iter: 800, curr loss: 1.3834154605865479, avg loss: 1.38586434841156\n",
      "trial: 4, iter: 1000, curr loss: 1.3665586709976196, avg loss: 1.380163214802742\n",
      "trial: 4, iter: 1200, curr loss: 1.3502447605133057, avg loss: 1.35863765001297\n",
      "trial: 4, iter: 1400, curr loss: 1.3001246452331543, avg loss: 1.3462098550796509\n",
      "trial: 4, iter: 1600, curr loss: 1.3388092517852783, avg loss: 1.3411316925287247\n",
      "trial: 4, iter: 1800, curr loss: 1.3127341270446777, avg loss: 1.335097734928131\n",
      "trial: 4, iter: 2000, curr loss: 1.331904411315918, avg loss: 1.3291773837804794\n",
      "trial: 4, iter: 2200, curr loss: 1.3386197090148926, avg loss: 1.3263642609119415\n",
      "trial: 4, iter: 2400, curr loss: 1.3312476873397827, avg loss: 1.3192623960971832\n",
      "trial: 4, iter: 2600, curr loss: 1.2908782958984375, avg loss: 1.3127471256256102\n",
      "trial: 4, iter: 2800, curr loss: 1.2711806297302246, avg loss: 1.30764064848423\n",
      "trial: 4, iter: 3000, curr loss: 1.2749156951904297, avg loss: 1.299587522149086\n",
      "trial: 4, ldr: 0.19906100630760193\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3846323490142822, avg loss: 1.38731829226017\n",
      "trial: 5, iter: 400, curr loss: 1.3867919445037842, avg loss: 1.3863622212409974\n",
      "trial: 5, iter: 600, curr loss: 1.3841001987457275, avg loss: 1.386245139837265\n",
      "trial: 5, iter: 800, curr loss: 1.3793706893920898, avg loss: 1.3843460762500763\n",
      "trial: 5, iter: 1000, curr loss: 1.3562562465667725, avg loss: 1.3737540179491043\n",
      "trial: 5, iter: 1200, curr loss: 1.3343305587768555, avg loss: 1.3523151141405105\n",
      "trial: 5, iter: 1400, curr loss: 1.3596590757369995, avg loss: 1.3440596181154252\n",
      "trial: 5, iter: 1600, curr loss: 1.326564908027649, avg loss: 1.3414537954330443\n",
      "trial: 5, iter: 1800, curr loss: 1.357587218284607, avg loss: 1.334698385000229\n",
      "trial: 5, iter: 2000, curr loss: 1.2977654933929443, avg loss: 1.3300165635347367\n",
      "trial: 5, iter: 2200, curr loss: 1.3411626815795898, avg loss: 1.3256009459495544\n",
      "trial: 5, iter: 2400, curr loss: 1.3387057781219482, avg loss: 1.320020518898964\n",
      "trial: 5, iter: 2600, curr loss: 1.3169445991516113, avg loss: 1.3141221934556961\n",
      "trial: 5, iter: 2800, curr loss: 1.2922812700271606, avg loss: 1.3111496722698213\n",
      "trial: 5, iter: 3000, curr loss: 1.3095815181732178, avg loss: 1.2993176311254502\n",
      "trial: 5, ldr: 0.11806000024080276\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1539846733212471\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3870258331298828, avg loss: 1.3873198479413986\n",
      "trial: 1, iter: 400, curr loss: 1.3857427835464478, avg loss: 1.3867512995004654\n",
      "trial: 1, iter: 600, curr loss: 1.3831820487976074, avg loss: 1.3855965107679367\n",
      "trial: 1, iter: 800, curr loss: 1.3507198095321655, avg loss: 1.3740204840898513\n",
      "trial: 1, iter: 1000, curr loss: 1.3259215354919434, avg loss: 1.3508160573244095\n",
      "trial: 1, iter: 1200, curr loss: 1.3421664237976074, avg loss: 1.3405793458223343\n",
      "trial: 1, iter: 1400, curr loss: 1.352420449256897, avg loss: 1.3343565577268601\n",
      "trial: 1, iter: 1600, curr loss: 1.325791835784912, avg loss: 1.3307854694128036\n",
      "trial: 1, iter: 1800, curr loss: 1.3079289197921753, avg loss: 1.3233286279439926\n",
      "trial: 1, iter: 2000, curr loss: 1.3106715679168701, avg loss: 1.32312437415123\n",
      "trial: 1, iter: 2200, curr loss: 1.3055695295333862, avg loss: 1.3140450763702392\n",
      "trial: 1, iter: 2400, curr loss: 1.3230937719345093, avg loss: 1.3097345960140228\n",
      "trial: 1, iter: 2600, curr loss: 1.2967981100082397, avg loss: 1.3071070021390916\n",
      "trial: 1, iter: 2800, curr loss: 1.2875908613204956, avg loss: 1.2992828893661499\n",
      "trial: 1, iter: 3000, curr loss: 1.2621372938156128, avg loss: 1.293986871242523\n",
      "trial: 1, ldr: 0.18175694346427917\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3872153759002686, avg loss: 1.3875634825229646\n",
      "trial: 2, iter: 400, curr loss: 1.3839675188064575, avg loss: 1.386612132191658\n",
      "trial: 2, iter: 600, curr loss: 1.3807963132858276, avg loss: 1.3861242216825485\n",
      "trial: 2, iter: 800, curr loss: 1.3778092861175537, avg loss: 1.3844204926490784\n",
      "trial: 2, iter: 1000, curr loss: 1.3818845748901367, avg loss: 1.3758926051855087\n",
      "trial: 2, iter: 1200, curr loss: 1.347758412361145, avg loss: 1.3576170408725738\n",
      "trial: 2, iter: 1400, curr loss: 1.354478120803833, avg loss: 1.3470795327425003\n",
      "trial: 2, iter: 1600, curr loss: 1.3375269174575806, avg loss: 1.3415424227714539\n",
      "trial: 2, iter: 1800, curr loss: 1.3189817667007446, avg loss: 1.3341499638557435\n",
      "trial: 2, iter: 2000, curr loss: 1.3006298542022705, avg loss: 1.328110809326172\n",
      "trial: 2, iter: 2200, curr loss: 1.2877060174942017, avg loss: 1.32851899266243\n",
      "trial: 2, iter: 2400, curr loss: 1.334975242614746, avg loss: 1.3198696130514145\n",
      "trial: 2, iter: 2600, curr loss: 1.3150187730789185, avg loss: 1.3159059220552445\n",
      "trial: 2, iter: 2800, curr loss: 1.320631980895996, avg loss: 1.310586101412773\n",
      "trial: 2, iter: 3000, curr loss: 1.2691490650177002, avg loss: 1.305315564274788\n",
      "trial: 2, ldr: 0.12586283683776855\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3878841400146484, avg loss: 1.387392800450325\n",
      "trial: 3, iter: 400, curr loss: 1.385918378829956, avg loss: 1.3868195605278015\n",
      "trial: 3, iter: 600, curr loss: 1.3865327835083008, avg loss: 1.3862575578689575\n",
      "trial: 3, iter: 800, curr loss: 1.3794618844985962, avg loss: 1.3851905000209808\n",
      "trial: 3, iter: 1000, curr loss: 1.3652310371398926, avg loss: 1.373871427178383\n",
      "trial: 3, iter: 1200, curr loss: 1.3540619611740112, avg loss: 1.3534799307584762\n",
      "trial: 3, iter: 1400, curr loss: 1.358586311340332, avg loss: 1.3434633773565292\n",
      "trial: 3, iter: 1600, curr loss: 1.3486510515213013, avg loss: 1.3373857069015502\n",
      "trial: 3, iter: 1800, curr loss: 1.3537276983261108, avg loss: 1.3367909467220307\n",
      "trial: 3, iter: 2000, curr loss: 1.3311854600906372, avg loss: 1.3328711384534835\n",
      "trial: 3, iter: 2200, curr loss: 1.3121631145477295, avg loss: 1.3261304259300233\n",
      "trial: 3, iter: 2400, curr loss: 1.2982723712921143, avg loss: 1.3234911876916886\n",
      "trial: 3, iter: 2600, curr loss: 1.3378733396530151, avg loss: 1.3173770886659621\n",
      "trial: 3, iter: 2800, curr loss: 1.2815150022506714, avg loss: 1.3150947856903077\n",
      "trial: 3, iter: 3000, curr loss: 1.2899943590164185, avg loss: 1.3087788593769074\n",
      "trial: 3, ldr: 0.12529097497463226\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3856006860733032, avg loss: 1.38729358792305\n",
      "trial: 4, iter: 400, curr loss: 1.3850327730178833, avg loss: 1.386408752799034\n",
      "trial: 4, iter: 600, curr loss: 1.3891382217407227, avg loss: 1.3848963636159897\n",
      "trial: 4, iter: 800, curr loss: 1.3558635711669922, avg loss: 1.377003487944603\n",
      "trial: 4, iter: 1000, curr loss: 1.3570849895477295, avg loss: 1.3561817467212678\n",
      "trial: 4, iter: 1200, curr loss: 1.3591794967651367, avg loss: 1.3466289126873017\n",
      "trial: 4, iter: 1400, curr loss: 1.360939621925354, avg loss: 1.339600327014923\n",
      "trial: 4, iter: 1600, curr loss: 1.341080904006958, avg loss: 1.3338230234384536\n",
      "trial: 4, iter: 1800, curr loss: 1.332794189453125, avg loss: 1.3306487160921097\n",
      "trial: 4, iter: 2000, curr loss: 1.3314261436462402, avg loss: 1.3252977985143661\n",
      "trial: 4, iter: 2200, curr loss: 1.326561450958252, avg loss: 1.3215442961454391\n",
      "trial: 4, iter: 2400, curr loss: 1.3275434970855713, avg loss: 1.317612254023552\n",
      "trial: 4, iter: 2600, curr loss: 1.3111674785614014, avg loss: 1.3127276104688645\n",
      "trial: 4, iter: 2800, curr loss: 1.2976288795471191, avg loss: 1.3097118842601776\n",
      "trial: 4, iter: 3000, curr loss: 1.2802211046218872, avg loss: 1.3039763957262038\n",
      "trial: 4, ldr: 0.12267343699932098\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3862066268920898, avg loss: 1.3871947759389878\n",
      "trial: 5, iter: 400, curr loss: 1.3894915580749512, avg loss: 1.3866998410224916\n",
      "trial: 5, iter: 600, curr loss: 1.3846770524978638, avg loss: 1.3864014220237733\n",
      "trial: 5, iter: 800, curr loss: 1.3867751359939575, avg loss: 1.385178529024124\n",
      "trial: 5, iter: 1000, curr loss: 1.3482871055603027, avg loss: 1.3735682398080826\n",
      "trial: 5, iter: 1200, curr loss: 1.3502660989761353, avg loss: 1.350151821374893\n",
      "trial: 5, iter: 1400, curr loss: 1.3251588344573975, avg loss: 1.3402351981401444\n",
      "trial: 5, iter: 1600, curr loss: 1.3602144718170166, avg loss: 1.335458579659462\n",
      "trial: 5, iter: 1800, curr loss: 1.3308627605438232, avg loss: 1.3317899519205094\n",
      "trial: 5, iter: 2000, curr loss: 1.3277883529663086, avg loss: 1.3264155745506288\n",
      "trial: 5, iter: 2200, curr loss: 1.3172670602798462, avg loss: 1.3232662796974182\n",
      "trial: 5, iter: 2400, curr loss: 1.3192055225372314, avg loss: 1.3119763034582137\n",
      "trial: 5, iter: 2600, curr loss: 1.3110188245773315, avg loss: 1.3072181034088135\n",
      "trial: 5, iter: 2800, curr loss: 1.2791109085083008, avg loss: 1.3021402478218078\n",
      "trial: 5, iter: 3000, curr loss: 1.2761602401733398, avg loss: 1.2950846475362778\n",
      "trial: 5, ldr: 0.16496799886226654\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.14411043822765351\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3879543542861938, avg loss: 1.3871043860912322\n",
      "trial: 1, iter: 400, curr loss: 1.3866777420043945, avg loss: 1.3865234071016312\n",
      "trial: 1, iter: 600, curr loss: 1.387150764465332, avg loss: 1.3863156640529632\n",
      "trial: 1, iter: 800, curr loss: 1.383946418762207, avg loss: 1.3858073103427886\n",
      "trial: 1, iter: 1000, curr loss: 1.3803715705871582, avg loss: 1.3823467421531677\n",
      "trial: 1, iter: 1200, curr loss: 1.362679362297058, avg loss: 1.3761145108938218\n",
      "trial: 1, iter: 1400, curr loss: 1.3420019149780273, avg loss: 1.3590842831134795\n",
      "trial: 1, iter: 1600, curr loss: 1.3553916215896606, avg loss: 1.3449351590871812\n",
      "trial: 1, iter: 1800, curr loss: 1.3337209224700928, avg loss: 1.3376755541563035\n",
      "trial: 1, iter: 2000, curr loss: 1.3465572595596313, avg loss: 1.3296310514211656\n",
      "trial: 1, iter: 2200, curr loss: 1.3349162340164185, avg loss: 1.3240096497535705\n",
      "trial: 1, iter: 2400, curr loss: 1.3035423755645752, avg loss: 1.315902824997902\n",
      "trial: 1, iter: 2600, curr loss: 1.3248870372772217, avg loss: 1.3127489167451858\n",
      "trial: 1, iter: 2800, curr loss: 1.319990873336792, avg loss: 1.306943901181221\n",
      "trial: 1, iter: 3000, curr loss: 1.3242461681365967, avg loss: 1.2995703685283662\n",
      "trial: 1, ldr: 0.10312071442604065\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3881199359893799, avg loss: 1.3877073019742965\n",
      "trial: 2, iter: 400, curr loss: 1.390010118484497, avg loss: 1.3867357474565507\n",
      "trial: 2, iter: 600, curr loss: 1.3841257095336914, avg loss: 1.3862852585315704\n",
      "trial: 2, iter: 800, curr loss: 1.3856862783432007, avg loss: 1.3845337241888047\n",
      "trial: 2, iter: 1000, curr loss: 1.3736258745193481, avg loss: 1.3692332768440247\n",
      "trial: 2, iter: 1200, curr loss: 1.3420239686965942, avg loss: 1.349998664855957\n",
      "trial: 2, iter: 1400, curr loss: 1.3335155248641968, avg loss: 1.342844414114952\n",
      "trial: 2, iter: 1600, curr loss: 1.3414604663848877, avg loss: 1.3384303998947145\n",
      "trial: 2, iter: 1800, curr loss: 1.296723484992981, avg loss: 1.3287367349863053\n",
      "trial: 2, iter: 2000, curr loss: 1.3392443656921387, avg loss: 1.3271187257766723\n",
      "trial: 2, iter: 2200, curr loss: 1.302024006843567, avg loss: 1.3185762459039687\n",
      "trial: 2, iter: 2400, curr loss: 1.3072394132614136, avg loss: 1.3177362179756165\n",
      "trial: 2, iter: 2600, curr loss: 1.3014211654663086, avg loss: 1.309483553171158\n",
      "trial: 2, iter: 2800, curr loss: 1.2952923774719238, avg loss: 1.3061469578742981\n",
      "trial: 2, iter: 3000, curr loss: 1.2752147912979126, avg loss: 1.3003060185909272\n",
      "trial: 2, ldr: 0.13675405085086823\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3876361846923828, avg loss: 1.3873054820299149\n",
      "trial: 3, iter: 400, curr loss: 1.3808913230895996, avg loss: 1.3865037775039672\n",
      "trial: 3, iter: 600, curr loss: 1.3821525573730469, avg loss: 1.3860978323221207\n",
      "trial: 3, iter: 800, curr loss: 1.3763000965118408, avg loss: 1.3831711173057557\n",
      "trial: 3, iter: 1000, curr loss: 1.357743501663208, avg loss: 1.3661425077915192\n",
      "trial: 3, iter: 1200, curr loss: 1.3578013181686401, avg loss: 1.349293410181999\n",
      "trial: 3, iter: 1400, curr loss: 1.3187381029129028, avg loss: 1.3395520597696304\n",
      "trial: 3, iter: 1600, curr loss: 1.3252737522125244, avg loss: 1.3347932493686676\n",
      "trial: 3, iter: 1800, curr loss: 1.3522417545318604, avg loss: 1.3301118969917298\n",
      "trial: 3, iter: 2000, curr loss: 1.2883343696594238, avg loss: 1.3229659861326217\n",
      "trial: 3, iter: 2200, curr loss: 1.3039331436157227, avg loss: 1.3170172560214997\n",
      "trial: 3, iter: 2400, curr loss: 1.3323112726211548, avg loss: 1.312624072432518\n",
      "trial: 3, iter: 2600, curr loss: 1.3604804277420044, avg loss: 1.3098453283309937\n",
      "trial: 3, iter: 2800, curr loss: 1.3004937171936035, avg loss: 1.304518473148346\n",
      "trial: 3, iter: 3000, curr loss: 1.298393964767456, avg loss: 1.298390720486641\n",
      "trial: 3, ldr: 0.08903824537992477\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3845183849334717, avg loss: 1.3871034753322602\n",
      "trial: 4, iter: 400, curr loss: 1.3884329795837402, avg loss: 1.3866821855306626\n",
      "trial: 4, iter: 600, curr loss: 1.3854820728302002, avg loss: 1.3861905485391617\n",
      "trial: 4, iter: 800, curr loss: 1.3783060312271118, avg loss: 1.3848460078239442\n",
      "trial: 4, iter: 1000, curr loss: 1.373284935951233, avg loss: 1.3740200811624528\n",
      "trial: 4, iter: 1200, curr loss: 1.358185887336731, avg loss: 1.3514103186130524\n",
      "trial: 4, iter: 1400, curr loss: 1.3354419469833374, avg loss: 1.341457679271698\n",
      "trial: 4, iter: 1600, curr loss: 1.3177258968353271, avg loss: 1.3323556005954742\n",
      "trial: 4, iter: 1800, curr loss: 1.2891390323638916, avg loss: 1.326484618782997\n",
      "trial: 4, iter: 2000, curr loss: 1.3064123392105103, avg loss: 1.32069558262825\n",
      "trial: 4, iter: 2200, curr loss: 1.3292882442474365, avg loss: 1.3110267007350922\n",
      "trial: 4, iter: 2400, curr loss: 1.301902174949646, avg loss: 1.305267191529274\n",
      "trial: 4, iter: 2600, curr loss: 1.2823479175567627, avg loss: 1.2967345595359803\n",
      "trial: 4, iter: 2800, curr loss: 1.3185752630233765, avg loss: 1.2967054206132889\n",
      "trial: 4, iter: 3000, curr loss: 1.265358805656433, avg loss: 1.2917414808273315\n",
      "trial: 4, ldr: 0.1898326426744461\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3861833810806274, avg loss: 1.3875542479753493\n",
      "trial: 5, iter: 400, curr loss: 1.3838974237442017, avg loss: 1.3867463338375092\n",
      "trial: 5, iter: 600, curr loss: 1.3851240873336792, avg loss: 1.3864396691322327\n",
      "trial: 5, iter: 800, curr loss: 1.3788143396377563, avg loss: 1.3836138868331909\n",
      "trial: 5, iter: 1000, curr loss: 1.3571498394012451, avg loss: 1.3701214808225632\n",
      "trial: 5, iter: 1200, curr loss: 1.3330327272415161, avg loss: 1.3524040114879607\n",
      "trial: 5, iter: 1400, curr loss: 1.3252615928649902, avg loss: 1.3414410328865052\n",
      "trial: 5, iter: 1600, curr loss: 1.3162521123886108, avg loss: 1.3337525081634523\n",
      "trial: 5, iter: 1800, curr loss: 1.3421272039413452, avg loss: 1.329547753930092\n",
      "trial: 5, iter: 2000, curr loss: 1.3317899703979492, avg loss: 1.3216689234972\n",
      "trial: 5, iter: 2200, curr loss: 1.3133022785186768, avg loss: 1.319268568754196\n",
      "trial: 5, iter: 2400, curr loss: 1.3620768785476685, avg loss: 1.3170611071586609\n",
      "trial: 5, iter: 2600, curr loss: 1.2817647457122803, avg loss: 1.3138361251354218\n",
      "trial: 5, iter: 2800, curr loss: 1.3325082063674927, avg loss: 1.3082383048534394\n",
      "trial: 5, iter: 3000, curr loss: 1.3123055696487427, avg loss: 1.305953174829483\n",
      "trial: 5, ldr: 0.11278612166643143\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.12630635499954224\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3866804838180542, avg loss: 1.3873107635974884\n",
      "trial: 1, iter: 400, curr loss: 1.385406494140625, avg loss: 1.386682088971138\n",
      "trial: 1, iter: 600, curr loss: 1.3853020668029785, avg loss: 1.3861689072847367\n",
      "trial: 1, iter: 800, curr loss: 1.3789598941802979, avg loss: 1.3843937891721725\n",
      "trial: 1, iter: 1000, curr loss: 1.361965537071228, avg loss: 1.3665096980333329\n",
      "trial: 1, iter: 1200, curr loss: 1.3424001932144165, avg loss: 1.344904379248619\n",
      "trial: 1, iter: 1400, curr loss: 1.313132643699646, avg loss: 1.337152999639511\n",
      "trial: 1, iter: 1600, curr loss: 1.3393892049789429, avg loss: 1.3315497660636901\n",
      "trial: 1, iter: 1800, curr loss: 1.313010811805725, avg loss: 1.3272592598199844\n",
      "trial: 1, iter: 2000, curr loss: 1.3077417612075806, avg loss: 1.3217061132192611\n",
      "trial: 1, iter: 2200, curr loss: 1.3342235088348389, avg loss: 1.3197178965806962\n",
      "trial: 1, iter: 2400, curr loss: 1.3510315418243408, avg loss: 1.3149967670440674\n",
      "trial: 1, iter: 2600, curr loss: 1.3117152452468872, avg loss: 1.310661995410919\n",
      "trial: 1, iter: 2800, curr loss: 1.3213495016098022, avg loss: 1.3048708325624465\n",
      "trial: 1, iter: 3000, curr loss: 1.2825531959533691, avg loss: 1.2999613881111145\n",
      "trial: 1, ldr: 0.15933075547218323\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3877382278442383, avg loss: 1.3871227145195006\n",
      "trial: 2, iter: 400, curr loss: 1.3884351253509521, avg loss: 1.3863987684249879\n",
      "trial: 2, iter: 600, curr loss: 1.3836872577667236, avg loss: 1.3856625580787658\n",
      "trial: 2, iter: 800, curr loss: 1.3702802658081055, avg loss: 1.3815278261899948\n",
      "trial: 2, iter: 1000, curr loss: 1.3518540859222412, avg loss: 1.36004176735878\n",
      "trial: 2, iter: 1200, curr loss: 1.3189104795455933, avg loss: 1.3439013016223909\n",
      "trial: 2, iter: 1400, curr loss: 1.3350374698638916, avg loss: 1.337586904168129\n",
      "trial: 2, iter: 1600, curr loss: 1.332686185836792, avg loss: 1.333015975356102\n",
      "trial: 2, iter: 1800, curr loss: 1.3372026681900024, avg loss: 1.3278397667407988\n",
      "trial: 2, iter: 2000, curr loss: 1.3134865760803223, avg loss: 1.3247570931911468\n",
      "trial: 2, iter: 2200, curr loss: 1.3400143384933472, avg loss: 1.3189652800559997\n",
      "trial: 2, iter: 2400, curr loss: 1.2919535636901855, avg loss: 1.3138445949554443\n",
      "trial: 2, iter: 2600, curr loss: 1.3247605562210083, avg loss: 1.3068788814544678\n",
      "trial: 2, iter: 2800, curr loss: 1.3353796005249023, avg loss: 1.298513139486313\n",
      "trial: 2, iter: 3000, curr loss: 1.303879737854004, avg loss: 1.2942224872112273\n",
      "trial: 2, ldr: 0.11232971400022507\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3899785280227661, avg loss: 1.387577777504921\n",
      "trial: 3, iter: 400, curr loss: 1.3856168985366821, avg loss: 1.3865655159950256\n",
      "trial: 3, iter: 600, curr loss: 1.3855284452438354, avg loss: 1.3864303785562515\n",
      "trial: 3, iter: 800, curr loss: 1.376800298690796, avg loss: 1.3850179505348206\n",
      "trial: 3, iter: 1000, curr loss: 1.3675427436828613, avg loss: 1.3783878737688064\n",
      "trial: 3, iter: 1200, curr loss: 1.339888334274292, avg loss: 1.353971204161644\n",
      "trial: 3, iter: 1400, curr loss: 1.332730770111084, avg loss: 1.3410603922605515\n",
      "trial: 3, iter: 1600, curr loss: 1.3265230655670166, avg loss: 1.3352441453933717\n",
      "trial: 3, iter: 1800, curr loss: 1.3413630723953247, avg loss: 1.3313537031412124\n",
      "trial: 3, iter: 2000, curr loss: 1.3244205713272095, avg loss: 1.3290205365419387\n",
      "trial: 3, iter: 2200, curr loss: 1.3251625299453735, avg loss: 1.322079690694809\n",
      "trial: 3, iter: 2400, curr loss: 1.324547290802002, avg loss: 1.3151972162723542\n",
      "trial: 3, iter: 2600, curr loss: 1.2846423387527466, avg loss: 1.3113047754764557\n",
      "trial: 3, iter: 2800, curr loss: 1.2803540229797363, avg loss: 1.3073157769441606\n",
      "trial: 3, iter: 3000, curr loss: 1.295719027519226, avg loss: 1.2995432776212692\n",
      "trial: 3, ldr: 0.21610796451568604\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.384093999862671, avg loss: 1.3871910965442658\n",
      "trial: 4, iter: 400, curr loss: 1.3874675035476685, avg loss: 1.3862261998653411\n",
      "trial: 4, iter: 600, curr loss: 1.38108491897583, avg loss: 1.3857085937261582\n",
      "trial: 4, iter: 800, curr loss: 1.3795181512832642, avg loss: 1.3807393324375152\n",
      "trial: 4, iter: 1000, curr loss: 1.3429675102233887, avg loss: 1.3616433280706406\n",
      "trial: 4, iter: 1200, curr loss: 1.3634511232376099, avg loss: 1.3444422090053558\n",
      "trial: 4, iter: 1400, curr loss: 1.3382502794265747, avg loss: 1.336610734462738\n",
      "trial: 4, iter: 1600, curr loss: 1.3178987503051758, avg loss: 1.3313588124513627\n",
      "trial: 4, iter: 1800, curr loss: 1.357283115386963, avg loss: 1.328805080652237\n",
      "trial: 4, iter: 2000, curr loss: 1.3394273519515991, avg loss: 1.326270141005516\n",
      "trial: 4, iter: 2200, curr loss: 1.314738392829895, avg loss: 1.3209681558609008\n",
      "trial: 4, iter: 2400, curr loss: 1.3301767110824585, avg loss: 1.3139146435260773\n",
      "trial: 4, iter: 2600, curr loss: 1.3189444541931152, avg loss: 1.3102797108888626\n",
      "trial: 4, iter: 2800, curr loss: 1.3002394437789917, avg loss: 1.3077906715869902\n",
      "trial: 4, iter: 3000, curr loss: 1.3068567514419556, avg loss: 1.3048815071582793\n",
      "trial: 4, ldr: 0.13469025492668152\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3846924304962158, avg loss: 1.3871578305959702\n",
      "trial: 5, iter: 400, curr loss: 1.3873310089111328, avg loss: 1.3868240648508072\n",
      "trial: 5, iter: 600, curr loss: 1.3891863822937012, avg loss: 1.386254842877388\n",
      "trial: 5, iter: 800, curr loss: 1.3865597248077393, avg loss: 1.3860991942882537\n",
      "trial: 5, iter: 1000, curr loss: 1.3741261959075928, avg loss: 1.3839411461353301\n",
      "trial: 5, iter: 1200, curr loss: 1.378071665763855, avg loss: 1.3704927057027816\n",
      "trial: 5, iter: 1400, curr loss: 1.3442411422729492, avg loss: 1.3525820446014405\n",
      "trial: 5, iter: 1600, curr loss: 1.3042640686035156, avg loss: 1.3399908715486526\n",
      "trial: 5, iter: 1800, curr loss: 1.3419336080551147, avg loss: 1.337964655160904\n",
      "trial: 5, iter: 2000, curr loss: 1.3036434650421143, avg loss: 1.3312265646457673\n",
      "trial: 5, iter: 2200, curr loss: 1.2970625162124634, avg loss: 1.3270199424028397\n",
      "trial: 5, iter: 2400, curr loss: 1.307121992111206, avg loss: 1.3228083568811417\n",
      "trial: 5, iter: 2600, curr loss: 1.3089370727539062, avg loss: 1.31828682243824\n",
      "trial: 5, iter: 2800, curr loss: 1.3175685405731201, avg loss: 1.3132713305950166\n",
      "trial: 5, iter: 3000, curr loss: 1.3201099634170532, avg loss: 1.30541710793972\n",
      "trial: 5, ldr: 0.08152925968170166\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1407975897192955\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3875809907913208, avg loss: 1.3876185262203216\n",
      "trial: 1, iter: 400, curr loss: 1.3815668821334839, avg loss: 1.3867632257938385\n",
      "trial: 1, iter: 600, curr loss: 1.3872519731521606, avg loss: 1.3865293323993684\n",
      "trial: 1, iter: 800, curr loss: 1.3854060173034668, avg loss: 1.3859095305204392\n",
      "trial: 1, iter: 1000, curr loss: 1.3720924854278564, avg loss: 1.3816229474544526\n",
      "trial: 1, iter: 1200, curr loss: 1.368236780166626, avg loss: 1.3621600741147994\n",
      "trial: 1, iter: 1400, curr loss: 1.3396357297897339, avg loss: 1.3464972102642059\n",
      "trial: 1, iter: 1600, curr loss: 1.3427283763885498, avg loss: 1.3369600170850753\n",
      "trial: 1, iter: 1800, curr loss: 1.3270573616027832, avg loss: 1.3307243365049362\n",
      "trial: 1, iter: 2000, curr loss: 1.3369022607803345, avg loss: 1.3271964102983476\n",
      "trial: 1, iter: 2200, curr loss: 1.3275845050811768, avg loss: 1.3225004708766936\n",
      "trial: 1, iter: 2400, curr loss: 1.2961764335632324, avg loss: 1.3168336021900178\n",
      "trial: 1, iter: 2600, curr loss: 1.3449679613113403, avg loss: 1.312465612888336\n",
      "trial: 1, iter: 2800, curr loss: 1.302885890007019, avg loss: 1.3096469980478287\n",
      "trial: 1, iter: 3000, curr loss: 1.287611484527588, avg loss: 1.3048913842439651\n",
      "trial: 1, ldr: 0.17356833815574646\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875685930252075, avg loss: 1.3871327227354049\n",
      "trial: 2, iter: 400, curr loss: 1.3856414556503296, avg loss: 1.3867694556713104\n",
      "trial: 2, iter: 600, curr loss: 1.3848414421081543, avg loss: 1.3862006103992461\n",
      "trial: 2, iter: 800, curr loss: 1.3833545446395874, avg loss: 1.3852855849266053\n",
      "trial: 2, iter: 1000, curr loss: 1.3662885427474976, avg loss: 1.3808861327171327\n",
      "trial: 2, iter: 1200, curr loss: 1.3436099290847778, avg loss: 1.3633012688159942\n",
      "trial: 2, iter: 1400, curr loss: 1.3498209714889526, avg loss: 1.3510128539800643\n",
      "trial: 2, iter: 1600, curr loss: 1.3438496589660645, avg loss: 1.3465148836374283\n",
      "trial: 2, iter: 1800, curr loss: 1.3317652940750122, avg loss: 1.3389184367656708\n",
      "trial: 2, iter: 2000, curr loss: 1.3577144145965576, avg loss: 1.3337487095594407\n",
      "trial: 2, iter: 2200, curr loss: 1.3272101879119873, avg loss: 1.3271299874782563\n",
      "trial: 2, iter: 2400, curr loss: 1.2849528789520264, avg loss: 1.3193650180101395\n",
      "trial: 2, iter: 2600, curr loss: 1.297600269317627, avg loss: 1.3115180778503417\n",
      "trial: 2, iter: 2800, curr loss: 1.2813374996185303, avg loss: 1.3044691902399064\n",
      "trial: 2, iter: 3000, curr loss: 1.2864388227462769, avg loss: 1.300978485941887\n",
      "trial: 2, ldr: 0.16268566250801086\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3848707675933838, avg loss: 1.3873602449893951\n",
      "trial: 3, iter: 400, curr loss: 1.3858685493469238, avg loss: 1.3870525443553925\n",
      "trial: 3, iter: 600, curr loss: 1.3878304958343506, avg loss: 1.3865103280544282\n",
      "trial: 3, iter: 800, curr loss: 1.3857266902923584, avg loss: 1.3860063135623932\n",
      "trial: 3, iter: 1000, curr loss: 1.3723728656768799, avg loss: 1.3822108209133148\n",
      "trial: 3, iter: 1200, curr loss: 1.3555355072021484, avg loss: 1.3648013299703599\n",
      "trial: 3, iter: 1400, curr loss: 1.3407536745071411, avg loss: 1.3493228125572205\n",
      "trial: 3, iter: 1600, curr loss: 1.3271512985229492, avg loss: 1.3398232543468476\n",
      "trial: 3, iter: 1800, curr loss: 1.3262577056884766, avg loss: 1.334364977478981\n",
      "trial: 3, iter: 2000, curr loss: 1.315024495124817, avg loss: 1.3279929560422898\n",
      "trial: 3, iter: 2200, curr loss: 1.3076399564743042, avg loss: 1.3229470080137253\n",
      "trial: 3, iter: 2400, curr loss: 1.3168416023254395, avg loss: 1.3183405995368958\n",
      "trial: 3, iter: 2600, curr loss: 1.3136496543884277, avg loss: 1.3124544656276702\n",
      "trial: 3, iter: 2800, curr loss: 1.288992166519165, avg loss: 1.3095335203409195\n",
      "trial: 3, iter: 3000, curr loss: 1.3358619213104248, avg loss: 1.3030571764707566\n",
      "trial: 3, ldr: 0.12734444439411163\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386335015296936, avg loss: 1.387333972454071\n",
      "trial: 4, iter: 400, curr loss: 1.3842158317565918, avg loss: 1.3863635104894638\n",
      "trial: 4, iter: 600, curr loss: 1.3841631412506104, avg loss: 1.3854560601711272\n",
      "trial: 4, iter: 800, curr loss: 1.3711403608322144, avg loss: 1.3801181888580323\n",
      "trial: 4, iter: 1000, curr loss: 1.346360445022583, avg loss: 1.3597340720891953\n",
      "trial: 4, iter: 1200, curr loss: 1.3183517456054688, avg loss: 1.3469645941257478\n",
      "trial: 4, iter: 1400, curr loss: 1.3405512571334839, avg loss: 1.3419312673807144\n",
      "trial: 4, iter: 1600, curr loss: 1.312869668006897, avg loss: 1.3348519521951676\n",
      "trial: 4, iter: 1800, curr loss: 1.3159950971603394, avg loss: 1.3299837893247604\n",
      "trial: 4, iter: 2000, curr loss: 1.3170920610427856, avg loss: 1.3281708651781081\n",
      "trial: 4, iter: 2200, curr loss: 1.320861577987671, avg loss: 1.3212135869264603\n",
      "trial: 4, iter: 2400, curr loss: 1.3322036266326904, avg loss: 1.3180958354473113\n",
      "trial: 4, iter: 2600, curr loss: 1.3373198509216309, avg loss: 1.315419646501541\n",
      "trial: 4, iter: 2800, curr loss: 1.3349970579147339, avg loss: 1.3123317474126817\n",
      "trial: 4, iter: 3000, curr loss: 1.3196675777435303, avg loss: 1.305294904112816\n",
      "trial: 4, ldr: 0.08643703907728195\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3844630718231201, avg loss: 1.3872532266378403\n",
      "trial: 5, iter: 400, curr loss: 1.387453317642212, avg loss: 1.3863948822021483\n",
      "trial: 5, iter: 600, curr loss: 1.3887884616851807, avg loss: 1.3862923341989517\n",
      "trial: 5, iter: 800, curr loss: 1.3807222843170166, avg loss: 1.3842825710773468\n",
      "trial: 5, iter: 1000, curr loss: 1.3471490144729614, avg loss: 1.3693800634145736\n",
      "trial: 5, iter: 1200, curr loss: 1.3609920740127563, avg loss: 1.348858528137207\n",
      "trial: 5, iter: 1400, curr loss: 1.3650354146957397, avg loss: 1.3377858555316926\n",
      "trial: 5, iter: 1600, curr loss: 1.352095603942871, avg loss: 1.3332607656717301\n",
      "trial: 5, iter: 1800, curr loss: 1.3087540864944458, avg loss: 1.3303668677806855\n",
      "trial: 5, iter: 2000, curr loss: 1.3454781770706177, avg loss: 1.325668088197708\n",
      "trial: 5, iter: 2200, curr loss: 1.3257536888122559, avg loss: 1.3191942417621612\n",
      "trial: 5, iter: 2400, curr loss: 1.291673183441162, avg loss: 1.3139472246170043\n",
      "trial: 5, iter: 2600, curr loss: 1.280848741531372, avg loss: 1.3089030522108078\n",
      "trial: 5, iter: 2800, curr loss: 1.2823089361190796, avg loss: 1.3034751003980636\n",
      "trial: 5, iter: 3000, curr loss: 1.314969778060913, avg loss: 1.298387625813484\n",
      "trial: 5, ldr: 0.1335413157939911\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1367153599858284\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3870131969451904, avg loss: 1.387235198020935\n",
      "trial: 1, iter: 400, curr loss: 1.3861747980117798, avg loss: 1.3868226540088653\n",
      "trial: 1, iter: 600, curr loss: 1.3852996826171875, avg loss: 1.386392543911934\n",
      "trial: 1, iter: 800, curr loss: 1.3855549097061157, avg loss: 1.3861575239896775\n",
      "trial: 1, iter: 1000, curr loss: 1.3866103887557983, avg loss: 1.3852494359016418\n",
      "trial: 1, iter: 1200, curr loss: 1.371669054031372, avg loss: 1.3802360254526138\n",
      "trial: 1, iter: 1400, curr loss: 1.351283311843872, avg loss: 1.366195595264435\n",
      "trial: 1, iter: 1600, curr loss: 1.3552602529525757, avg loss: 1.3495496863126755\n",
      "trial: 1, iter: 1800, curr loss: 1.3597151041030884, avg loss: 1.3431360709667206\n",
      "trial: 1, iter: 2000, curr loss: 1.2883955240249634, avg loss: 1.3372298514842986\n",
      "trial: 1, iter: 2200, curr loss: 1.3303842544555664, avg loss: 1.333525470495224\n",
      "trial: 1, iter: 2400, curr loss: 1.2933861017227173, avg loss: 1.3288705503940583\n",
      "trial: 1, iter: 2600, curr loss: 1.3297410011291504, avg loss: 1.325664159655571\n",
      "trial: 1, iter: 2800, curr loss: 1.293383002281189, avg loss: 1.321582179069519\n",
      "trial: 1, iter: 3000, curr loss: 1.3171950578689575, avg loss: 1.313989131450653\n",
      "trial: 1, ldr: 0.037851981818675995\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849315643310547, avg loss: 1.387288920879364\n",
      "trial: 2, iter: 400, curr loss: 1.3859987258911133, avg loss: 1.386550137400627\n",
      "trial: 2, iter: 600, curr loss: 1.380583643913269, avg loss: 1.386097365617752\n",
      "trial: 2, iter: 800, curr loss: 1.38196861743927, avg loss: 1.3833435815572739\n",
      "trial: 2, iter: 1000, curr loss: 1.3682701587677002, avg loss: 1.3665198969841004\n",
      "trial: 2, iter: 1200, curr loss: 1.3259702920913696, avg loss: 1.3506764090061187\n",
      "trial: 2, iter: 1400, curr loss: 1.3459339141845703, avg loss: 1.3412354177236556\n",
      "trial: 2, iter: 1600, curr loss: 1.3305315971374512, avg loss: 1.3384741097688675\n",
      "trial: 2, iter: 1800, curr loss: 1.3424603939056396, avg loss: 1.3323362565040588\n",
      "trial: 2, iter: 2000, curr loss: 1.319558024406433, avg loss: 1.3303591561317445\n",
      "trial: 2, iter: 2200, curr loss: 1.324122667312622, avg loss: 1.3264169692993164\n",
      "trial: 2, iter: 2400, curr loss: 1.3595118522644043, avg loss: 1.320030870437622\n",
      "trial: 2, iter: 2600, curr loss: 1.3256709575653076, avg loss: 1.3163949429988862\n",
      "trial: 2, iter: 2800, curr loss: 1.3214309215545654, avg loss: 1.3120038568973542\n",
      "trial: 2, iter: 3000, curr loss: 1.3312561511993408, avg loss: 1.3078465169668199\n",
      "trial: 2, ldr: 0.18973314762115479\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3881301879882812, avg loss: 1.3874346208572388\n",
      "trial: 3, iter: 400, curr loss: 1.3842136859893799, avg loss: 1.3865388929843903\n",
      "trial: 3, iter: 600, curr loss: 1.3839900493621826, avg loss: 1.3862787675857544\n",
      "trial: 3, iter: 800, curr loss: 1.387249231338501, avg loss: 1.3860606878995896\n",
      "trial: 3, iter: 1000, curr loss: 1.3646773099899292, avg loss: 1.3809803277254105\n",
      "trial: 3, iter: 1200, curr loss: 1.3524718284606934, avg loss: 1.3586924999952317\n",
      "trial: 3, iter: 1400, curr loss: 1.329734206199646, avg loss: 1.3433768767118455\n",
      "trial: 3, iter: 1600, curr loss: 1.3498210906982422, avg loss: 1.3388067871332168\n",
      "trial: 3, iter: 1800, curr loss: 1.3123136758804321, avg loss: 1.3319729232788087\n",
      "trial: 3, iter: 2000, curr loss: 1.2963697910308838, avg loss: 1.3273915392160416\n",
      "trial: 3, iter: 2200, curr loss: 1.3486571311950684, avg loss: 1.3205389750003815\n",
      "trial: 3, iter: 2400, curr loss: 1.3093597888946533, avg loss: 1.3147985434532166\n",
      "trial: 3, iter: 2600, curr loss: 1.3261536359786987, avg loss: 1.309307062625885\n",
      "trial: 3, iter: 2800, curr loss: 1.3136931657791138, avg loss: 1.3045767223834992\n",
      "trial: 3, iter: 3000, curr loss: 1.3048754930496216, avg loss: 1.2980433106422424\n",
      "trial: 3, ldr: 0.17807142436504364\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3849472999572754, avg loss: 1.3873546278476716\n",
      "trial: 4, iter: 400, curr loss: 1.3872650861740112, avg loss: 1.3866091531515121\n",
      "trial: 4, iter: 600, curr loss: 1.3822153806686401, avg loss: 1.3854125839471818\n",
      "trial: 4, iter: 800, curr loss: 1.3585697412490845, avg loss: 1.372168470621109\n",
      "trial: 4, iter: 1000, curr loss: 1.33644437789917, avg loss: 1.3484040689468384\n",
      "trial: 4, iter: 1200, curr loss: 1.3597438335418701, avg loss: 1.3384668642282487\n",
      "trial: 4, iter: 1400, curr loss: 1.3238849639892578, avg loss: 1.3335115027427673\n",
      "trial: 4, iter: 1600, curr loss: 1.33714759349823, avg loss: 1.3282269710302352\n",
      "trial: 4, iter: 1800, curr loss: 1.3355036973953247, avg loss: 1.3265574449300765\n",
      "trial: 4, iter: 2000, curr loss: 1.3124539852142334, avg loss: 1.3214390921592711\n",
      "trial: 4, iter: 2200, curr loss: 1.3273041248321533, avg loss: 1.3181247788667678\n",
      "trial: 4, iter: 2400, curr loss: 1.2850099802017212, avg loss: 1.3094756662845612\n",
      "trial: 4, iter: 2600, curr loss: 1.3271492719650269, avg loss: 1.3076398223638535\n",
      "trial: 4, iter: 2800, curr loss: 1.2643582820892334, avg loss: 1.3021364152431487\n",
      "trial: 4, iter: 3000, curr loss: 1.311268925666809, avg loss: 1.3012080204486847\n",
      "trial: 4, ldr: 0.15023595094680786\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3904472589492798, avg loss: 1.3873749923706056\n",
      "trial: 5, iter: 400, curr loss: 1.3848986625671387, avg loss: 1.3862936311960221\n",
      "trial: 5, iter: 600, curr loss: 1.3739354610443115, avg loss: 1.3840189039707185\n",
      "trial: 5, iter: 800, curr loss: 1.3516120910644531, avg loss: 1.3704755687713623\n",
      "trial: 5, iter: 1000, curr loss: 1.3283045291900635, avg loss: 1.3498947823047638\n",
      "trial: 5, iter: 1200, curr loss: 1.3338209390640259, avg loss: 1.3408992499113084\n",
      "trial: 5, iter: 1400, curr loss: 1.3255939483642578, avg loss: 1.335650299191475\n",
      "trial: 5, iter: 1600, curr loss: 1.3099943399429321, avg loss: 1.3309582549333572\n",
      "trial: 5, iter: 1800, curr loss: 1.3329558372497559, avg loss: 1.3267869198322295\n",
      "trial: 5, iter: 2000, curr loss: 1.3148531913757324, avg loss: 1.3202337819337844\n",
      "trial: 5, iter: 2200, curr loss: 1.2777514457702637, avg loss: 1.3136914896965026\n",
      "trial: 5, iter: 2400, curr loss: 1.3550490140914917, avg loss: 1.3094130927324295\n",
      "trial: 5, iter: 2600, curr loss: 1.3373305797576904, avg loss: 1.3058675611019135\n",
      "trial: 5, iter: 2800, curr loss: 1.3367908000946045, avg loss: 1.3017953377962113\n",
      "trial: 5, iter: 3000, curr loss: 1.3073959350585938, avg loss: 1.2963851404190063\n",
      "trial: 5, ldr: 0.19267140328884125\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1497127816081047\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3883171081542969, avg loss: 1.3873305439949035\n",
      "trial: 1, iter: 400, curr loss: 1.386980652809143, avg loss: 1.386651229262352\n",
      "trial: 1, iter: 600, curr loss: 1.379919409751892, avg loss: 1.382925078868866\n",
      "trial: 1, iter: 800, curr loss: 1.3573145866394043, avg loss: 1.3704825472831725\n",
      "trial: 1, iter: 1000, curr loss: 1.3418183326721191, avg loss: 1.3517816472053528\n",
      "trial: 1, iter: 1200, curr loss: 1.3230735063552856, avg loss: 1.3386724907159806\n",
      "trial: 1, iter: 1400, curr loss: 1.3453381061553955, avg loss: 1.3335217720270156\n",
      "trial: 1, iter: 1600, curr loss: 1.3465591669082642, avg loss: 1.329754851460457\n",
      "trial: 1, iter: 1800, curr loss: 1.340915322303772, avg loss: 1.3257206851243972\n",
      "trial: 1, iter: 2000, curr loss: 1.3140640258789062, avg loss: 1.3238451814651488\n",
      "trial: 1, iter: 2200, curr loss: 1.338299036026001, avg loss: 1.3168340855836869\n",
      "trial: 1, iter: 2400, curr loss: 1.329175591468811, avg loss: 1.3147030621767044\n",
      "trial: 1, iter: 2600, curr loss: 1.2839996814727783, avg loss: 1.3098388028144836\n",
      "trial: 1, iter: 2800, curr loss: 1.3336409330368042, avg loss: 1.3062415486574173\n",
      "trial: 1, iter: 3000, curr loss: 1.321718692779541, avg loss: 1.3004589951038361\n",
      "trial: 1, ldr: 0.15247021615505219\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3877942562103271, avg loss: 1.3874019449949264\n",
      "trial: 2, iter: 400, curr loss: 1.3918616771697998, avg loss: 1.3868365919589996\n",
      "trial: 2, iter: 600, curr loss: 1.3864911794662476, avg loss: 1.386255180835724\n",
      "trial: 2, iter: 800, curr loss: 1.3854516744613647, avg loss: 1.38508993268013\n",
      "trial: 2, iter: 1000, curr loss: 1.3551450967788696, avg loss: 1.3735786139965058\n",
      "trial: 2, iter: 1200, curr loss: 1.3458576202392578, avg loss: 1.3496715474128722\n",
      "trial: 2, iter: 1400, curr loss: 1.320961833000183, avg loss: 1.3403038787841797\n",
      "trial: 2, iter: 1600, curr loss: 1.349013328552246, avg loss: 1.3329103624820708\n",
      "trial: 2, iter: 1800, curr loss: 1.3089154958724976, avg loss: 1.3295749235153198\n",
      "trial: 2, iter: 2000, curr loss: 1.3209720849990845, avg loss: 1.3228590238094329\n",
      "trial: 2, iter: 2200, curr loss: 1.3024739027023315, avg loss: 1.317638596892357\n",
      "trial: 2, iter: 2400, curr loss: 1.3118298053741455, avg loss: 1.3159061980247497\n",
      "trial: 2, iter: 2600, curr loss: 1.3244600296020508, avg loss: 1.3120122683048248\n",
      "trial: 2, iter: 2800, curr loss: 1.2859123945236206, avg loss: 1.30763160943985\n",
      "trial: 2, iter: 3000, curr loss: 1.3173913955688477, avg loss: 1.3025641202926637\n",
      "trial: 2, ldr: 0.13204841315746307\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3863624334335327, avg loss: 1.3873951762914658\n",
      "trial: 3, iter: 400, curr loss: 1.3844621181488037, avg loss: 1.3867557334899903\n",
      "trial: 3, iter: 600, curr loss: 1.3851319551467896, avg loss: 1.3856576949357986\n",
      "trial: 3, iter: 800, curr loss: 1.3662863969802856, avg loss: 1.3797182047367096\n",
      "trial: 3, iter: 1000, curr loss: 1.376715898513794, avg loss: 1.360754554271698\n",
      "trial: 3, iter: 1200, curr loss: 1.367044448852539, avg loss: 1.3440109086036682\n",
      "trial: 3, iter: 1400, curr loss: 1.3517192602157593, avg loss: 1.3358260214328765\n",
      "trial: 3, iter: 1600, curr loss: 1.3281573057174683, avg loss: 1.3293145394325256\n",
      "trial: 3, iter: 1800, curr loss: 1.3284038305282593, avg loss: 1.3249596333503724\n",
      "trial: 3, iter: 2000, curr loss: 1.2845417261123657, avg loss: 1.3191530472040176\n",
      "trial: 3, iter: 2200, curr loss: 1.3088418245315552, avg loss: 1.315405112504959\n",
      "trial: 3, iter: 2400, curr loss: 1.295301079750061, avg loss: 1.3117931562662124\n",
      "trial: 3, iter: 2600, curr loss: 1.3104268312454224, avg loss: 1.3075570100545884\n",
      "trial: 3, iter: 2800, curr loss: 1.2961395978927612, avg loss: 1.300866431593895\n",
      "trial: 3, iter: 3000, curr loss: 1.3067083358764648, avg loss: 1.3004277855157853\n",
      "trial: 3, ldr: 0.17823714017868042\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3875162601470947, avg loss: 1.3875820922851563\n",
      "trial: 4, iter: 400, curr loss: 1.384897232055664, avg loss: 1.3867123824357988\n",
      "trial: 4, iter: 600, curr loss: 1.3858708143234253, avg loss: 1.3862852787971496\n",
      "trial: 4, iter: 800, curr loss: 1.3836822509765625, avg loss: 1.3842230641841888\n",
      "trial: 4, iter: 1000, curr loss: 1.3700344562530518, avg loss: 1.367777680158615\n",
      "trial: 4, iter: 1200, curr loss: 1.3598185777664185, avg loss: 1.3499239695072174\n",
      "trial: 4, iter: 1400, curr loss: 1.332322597503662, avg loss: 1.340709159374237\n",
      "trial: 4, iter: 1600, curr loss: 1.3104861974716187, avg loss: 1.3345774656534195\n",
      "trial: 4, iter: 1800, curr loss: 1.328233003616333, avg loss: 1.3275066697597504\n",
      "trial: 4, iter: 2000, curr loss: 1.3285715579986572, avg loss: 1.3242331820726394\n",
      "trial: 4, iter: 2200, curr loss: 1.2955739498138428, avg loss: 1.3205892491340636\n",
      "trial: 4, iter: 2400, curr loss: 1.3180077075958252, avg loss: 1.3134389251470566\n",
      "trial: 4, iter: 2600, curr loss: 1.3077244758605957, avg loss: 1.3119901591539382\n",
      "trial: 4, iter: 2800, curr loss: 1.3045222759246826, avg loss: 1.3083958196640015\n",
      "trial: 4, iter: 3000, curr loss: 1.2832914590835571, avg loss: 1.3030517846345901\n",
      "trial: 4, ldr: 0.0746239721775055\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3866602182388306, avg loss: 1.3873934108018875\n",
      "trial: 5, iter: 400, curr loss: 1.3895952701568604, avg loss: 1.3865482437610626\n",
      "trial: 5, iter: 600, curr loss: 1.3800690174102783, avg loss: 1.3856613045930863\n",
      "trial: 5, iter: 800, curr loss: 1.3643828630447388, avg loss: 1.3801631504297256\n",
      "trial: 5, iter: 1000, curr loss: 1.3635010719299316, avg loss: 1.3568014919757843\n",
      "trial: 5, iter: 1200, curr loss: 1.3276464939117432, avg loss: 1.3458983939886093\n",
      "trial: 5, iter: 1400, curr loss: 1.3317633867263794, avg loss: 1.3377557647228242\n",
      "trial: 5, iter: 1600, curr loss: 1.3311007022857666, avg loss: 1.3322093904018402\n",
      "trial: 5, iter: 1800, curr loss: 1.3154537677764893, avg loss: 1.3265573638677597\n",
      "trial: 5, iter: 2000, curr loss: 1.3358997106552124, avg loss: 1.3233940875530243\n",
      "trial: 5, iter: 2200, curr loss: 1.29799222946167, avg loss: 1.3193920260667802\n",
      "trial: 5, iter: 2400, curr loss: 1.316693663597107, avg loss: 1.3150621378421783\n",
      "trial: 5, iter: 2600, curr loss: 1.3236113786697388, avg loss: 1.309727228283882\n",
      "trial: 5, iter: 2800, curr loss: 1.3109763860702515, avg loss: 1.3069033861160277\n",
      "trial: 5, iter: 3000, curr loss: 1.2698609828948975, avg loss: 1.3007710272073745\n",
      "trial: 5, ldr: 0.10919055342674255\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.12931405901908874\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3911693096160889, avg loss: 1.3870688062906265\n",
      "trial: 1, iter: 400, curr loss: 1.385302186012268, avg loss: 1.3866974353790282\n",
      "trial: 1, iter: 600, curr loss: 1.388331651687622, avg loss: 1.3864227503538131\n",
      "trial: 1, iter: 800, curr loss: 1.3875857591629028, avg loss: 1.3861918330192566\n",
      "trial: 1, iter: 1000, curr loss: 1.383481502532959, avg loss: 1.3846524041891097\n",
      "trial: 1, iter: 1200, curr loss: 1.3665426969528198, avg loss: 1.3731022310256957\n",
      "trial: 1, iter: 1400, curr loss: 1.323609709739685, avg loss: 1.351782699227333\n",
      "trial: 1, iter: 1600, curr loss: 1.3451573848724365, avg loss: 1.3420263975858688\n",
      "trial: 1, iter: 1800, curr loss: 1.3455777168273926, avg loss: 1.338122392296791\n",
      "trial: 1, iter: 2000, curr loss: 1.313647747039795, avg loss: 1.3349364244937896\n",
      "trial: 1, iter: 2200, curr loss: 1.3365293741226196, avg loss: 1.329649264216423\n",
      "trial: 1, iter: 2400, curr loss: 1.3141978979110718, avg loss: 1.324061861038208\n",
      "trial: 1, iter: 2600, curr loss: 1.30295991897583, avg loss: 1.3188134795427322\n",
      "trial: 1, iter: 2800, curr loss: 1.3093472719192505, avg loss: 1.3118792194128037\n",
      "trial: 1, iter: 3000, curr loss: 1.290664553642273, avg loss: 1.3038048058748246\n",
      "trial: 1, ldr: 0.18850788474082947\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3847131729125977, avg loss: 1.3874121642112731\n",
      "trial: 2, iter: 400, curr loss: 1.388552188873291, avg loss: 1.386746947169304\n",
      "trial: 2, iter: 600, curr loss: 1.3883253335952759, avg loss: 1.3860925298929214\n",
      "trial: 2, iter: 800, curr loss: 1.3824348449707031, avg loss: 1.3834270638227464\n",
      "trial: 2, iter: 1000, curr loss: 1.345295786857605, avg loss: 1.3620119893550873\n",
      "trial: 2, iter: 1200, curr loss: 1.3423274755477905, avg loss: 1.3422811168432236\n",
      "trial: 2, iter: 1400, curr loss: 1.3424441814422607, avg loss: 1.33665422976017\n",
      "trial: 2, iter: 1600, curr loss: 1.3249729871749878, avg loss: 1.3289119464159012\n",
      "trial: 2, iter: 1800, curr loss: 1.321175456047058, avg loss: 1.326905317902565\n",
      "trial: 2, iter: 2000, curr loss: 1.3335691690444946, avg loss: 1.3222018891572953\n",
      "trial: 2, iter: 2200, curr loss: 1.3270866870880127, avg loss: 1.3177317494153977\n",
      "trial: 2, iter: 2400, curr loss: 1.2996068000793457, avg loss: 1.314214853644371\n",
      "trial: 2, iter: 2600, curr loss: 1.3096858263015747, avg loss: 1.307891947031021\n",
      "trial: 2, iter: 2800, curr loss: 1.282388687133789, avg loss: 1.3050973975658418\n",
      "trial: 2, iter: 3000, curr loss: 1.286596655845642, avg loss: 1.300735016465187\n",
      "trial: 2, ldr: 0.19574102759361267\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3874061107635498, avg loss: 1.3876639997959137\n",
      "trial: 3, iter: 400, curr loss: 1.391532301902771, avg loss: 1.3866332203149796\n",
      "trial: 3, iter: 600, curr loss: 1.384381890296936, avg loss: 1.386243036389351\n",
      "trial: 3, iter: 800, curr loss: 1.378501534461975, avg loss: 1.3842204803228377\n",
      "trial: 3, iter: 1000, curr loss: 1.3526592254638672, avg loss: 1.3726029628515244\n",
      "trial: 3, iter: 1200, curr loss: 1.3469583988189697, avg loss: 1.352022870182991\n",
      "trial: 3, iter: 1400, curr loss: 1.3571699857711792, avg loss: 1.3437857854366302\n",
      "trial: 3, iter: 1600, curr loss: 1.3543095588684082, avg loss: 1.3374838143587113\n",
      "trial: 3, iter: 1800, curr loss: 1.3463243246078491, avg loss: 1.332990425825119\n",
      "trial: 3, iter: 2000, curr loss: 1.3147022724151611, avg loss: 1.324701003432274\n",
      "trial: 3, iter: 2200, curr loss: 1.3037207126617432, avg loss: 1.320221821665764\n",
      "trial: 3, iter: 2400, curr loss: 1.3138461112976074, avg loss: 1.3128375834226609\n",
      "trial: 3, iter: 2600, curr loss: 1.3000116348266602, avg loss: 1.3074842512607574\n",
      "trial: 3, iter: 2800, curr loss: 1.3084220886230469, avg loss: 1.3042466992139816\n",
      "trial: 3, iter: 3000, curr loss: 1.3408722877502441, avg loss: 1.2972784543037414\n",
      "trial: 3, ldr: 0.12190167605876923\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3877427577972412, avg loss: 1.3870857906341554\n",
      "trial: 4, iter: 400, curr loss: 1.3834456205368042, avg loss: 1.3867087358236312\n",
      "trial: 4, iter: 600, curr loss: 1.3877447843551636, avg loss: 1.3863018429279328\n",
      "trial: 4, iter: 800, curr loss: 1.3813246488571167, avg loss: 1.385142093896866\n",
      "trial: 4, iter: 1000, curr loss: 1.3724555969238281, avg loss: 1.3804629528522492\n",
      "trial: 4, iter: 1200, curr loss: 1.3761147260665894, avg loss: 1.362462921142578\n",
      "trial: 4, iter: 1400, curr loss: 1.350804090499878, avg loss: 1.3479305517673492\n",
      "trial: 4, iter: 1600, curr loss: 1.3245480060577393, avg loss: 1.3401052635908126\n",
      "trial: 4, iter: 1800, curr loss: 1.3242818117141724, avg loss: 1.3371343231201172\n",
      "trial: 4, iter: 2000, curr loss: 1.3427958488464355, avg loss: 1.3307776778936387\n",
      "trial: 4, iter: 2200, curr loss: 1.3585222959518433, avg loss: 1.3294901472330094\n",
      "trial: 4, iter: 2400, curr loss: 1.3111621141433716, avg loss: 1.325987452864647\n",
      "trial: 4, iter: 2600, curr loss: 1.2882513999938965, avg loss: 1.3203903204202652\n",
      "trial: 4, iter: 2800, curr loss: 1.2934093475341797, avg loss: 1.315468881726265\n",
      "trial: 4, iter: 3000, curr loss: 1.2530066967010498, avg loss: 1.3100997394323348\n",
      "trial: 4, ldr: 0.06766021996736526\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.388535499572754, avg loss: 1.387366658449173\n",
      "trial: 5, iter: 400, curr loss: 1.3854036331176758, avg loss: 1.3864447981119157\n",
      "trial: 5, iter: 600, curr loss: 1.387499213218689, avg loss: 1.3849953573942184\n",
      "trial: 5, iter: 800, curr loss: 1.3632431030273438, avg loss: 1.3800489330291748\n",
      "trial: 5, iter: 1000, curr loss: 1.3772937059402466, avg loss: 1.3635171526670455\n",
      "trial: 5, iter: 1200, curr loss: 1.345639705657959, avg loss: 1.3462032926082612\n",
      "trial: 5, iter: 1400, curr loss: 1.3374989032745361, avg loss: 1.3410111391544342\n",
      "trial: 5, iter: 1600, curr loss: 1.3305854797363281, avg loss: 1.3323771232366561\n",
      "trial: 5, iter: 1800, curr loss: 1.3200831413269043, avg loss: 1.3268483620882034\n",
      "trial: 5, iter: 2000, curr loss: 1.3127505779266357, avg loss: 1.320566752552986\n",
      "trial: 5, iter: 2200, curr loss: 1.3281922340393066, avg loss: 1.3151850986480713\n",
      "trial: 5, iter: 2400, curr loss: 1.281685471534729, avg loss: 1.3059575825929641\n",
      "trial: 5, iter: 2600, curr loss: 1.2897249460220337, avg loss: 1.300203133225441\n",
      "trial: 5, iter: 2800, curr loss: 1.2423102855682373, avg loss: 1.2941350477933884\n",
      "trial: 5, iter: 3000, curr loss: 1.3043017387390137, avg loss: 1.2952368992567063\n",
      "trial: 5, ldr: 0.30689793825149536\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1761417493224144\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3876049518585205, avg loss: 1.3875779151916503\n",
      "trial: 1, iter: 400, curr loss: 1.383169412612915, avg loss: 1.3865652257204055\n",
      "trial: 1, iter: 600, curr loss: 1.3899420499801636, avg loss: 1.3862833547592164\n",
      "trial: 1, iter: 800, curr loss: 1.3845027685165405, avg loss: 1.3847674173116684\n",
      "trial: 1, iter: 1000, curr loss: 1.3617225885391235, avg loss: 1.3725326693058013\n",
      "trial: 1, iter: 1200, curr loss: 1.348740577697754, avg loss: 1.3528999310731888\n",
      "trial: 1, iter: 1400, curr loss: 1.3506245613098145, avg loss: 1.3449805968999862\n",
      "trial: 1, iter: 1600, curr loss: 1.3033154010772705, avg loss: 1.3371136552095413\n",
      "trial: 1, iter: 1800, curr loss: 1.323299765586853, avg loss: 1.3344693380594252\n",
      "trial: 1, iter: 2000, curr loss: 1.3142850399017334, avg loss: 1.3303937882184982\n",
      "trial: 1, iter: 2200, curr loss: 1.3570877313613892, avg loss: 1.3248004949092864\n",
      "trial: 1, iter: 2400, curr loss: 1.3262888193130493, avg loss: 1.3215896260738373\n",
      "trial: 1, iter: 2600, curr loss: 1.3289923667907715, avg loss: 1.3159316593408585\n",
      "trial: 1, iter: 2800, curr loss: 1.2882195711135864, avg loss: 1.311751309633255\n",
      "trial: 1, iter: 3000, curr loss: 1.3183989524841309, avg loss: 1.3065501761436462\n",
      "trial: 1, ldr: 0.15279297530651093\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875453472137451, avg loss: 1.3870056194067002\n",
      "trial: 2, iter: 400, curr loss: 1.38462495803833, avg loss: 1.3865476751327515\n",
      "trial: 2, iter: 600, curr loss: 1.3849536180496216, avg loss: 1.3865088409185409\n",
      "trial: 2, iter: 800, curr loss: 1.3866709470748901, avg loss: 1.3861925208568573\n",
      "trial: 2, iter: 1000, curr loss: 1.3854150772094727, avg loss: 1.383958456516266\n",
      "trial: 2, iter: 1200, curr loss: 1.3616448640823364, avg loss: 1.3684855902194977\n",
      "trial: 2, iter: 1400, curr loss: 1.316050410270691, avg loss: 1.3490831863880157\n",
      "trial: 2, iter: 1600, curr loss: 1.3362665176391602, avg loss: 1.3397439730167389\n",
      "trial: 2, iter: 1800, curr loss: 1.3642442226409912, avg loss: 1.3313742989301682\n",
      "trial: 2, iter: 2000, curr loss: 1.349704384803772, avg loss: 1.3258406662940978\n",
      "trial: 2, iter: 2200, curr loss: 1.3190521001815796, avg loss: 1.31874183177948\n",
      "trial: 2, iter: 2400, curr loss: 1.3243383169174194, avg loss: 1.312389606833458\n",
      "trial: 2, iter: 2600, curr loss: 1.3133866786956787, avg loss: 1.306629055738449\n",
      "trial: 2, iter: 2800, curr loss: 1.2707942724227905, avg loss: 1.3006306314468383\n",
      "trial: 2, iter: 3000, curr loss: 1.2646994590759277, avg loss: 1.2976503813266753\n",
      "trial: 2, ldr: 0.1843835562467575\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.388113260269165, avg loss: 1.3873118525743484\n",
      "trial: 3, iter: 400, curr loss: 1.3919183015823364, avg loss: 1.3868091404438019\n",
      "trial: 3, iter: 600, curr loss: 1.388037919998169, avg loss: 1.3864331489801407\n",
      "trial: 3, iter: 800, curr loss: 1.3857221603393555, avg loss: 1.385622211098671\n",
      "trial: 3, iter: 1000, curr loss: 1.373104453086853, avg loss: 1.3773803848028183\n",
      "trial: 3, iter: 1200, curr loss: 1.3616832494735718, avg loss: 1.3536628878116608\n",
      "trial: 3, iter: 1400, curr loss: 1.3542611598968506, avg loss: 1.3428440457582473\n",
      "trial: 3, iter: 1600, curr loss: 1.3086738586425781, avg loss: 1.3363649767637253\n",
      "trial: 3, iter: 1800, curr loss: 1.3643637895584106, avg loss: 1.3324261301755904\n",
      "trial: 3, iter: 2000, curr loss: 1.3115125894546509, avg loss: 1.3265176969766617\n",
      "trial: 3, iter: 2200, curr loss: 1.3318774700164795, avg loss: 1.3213220953941345\n",
      "trial: 3, iter: 2400, curr loss: 1.3142592906951904, avg loss: 1.3151184165477752\n",
      "trial: 3, iter: 2600, curr loss: 1.3283756971359253, avg loss: 1.3149511605501174\n",
      "trial: 3, iter: 2800, curr loss: 1.3285409212112427, avg loss: 1.3081702482700348\n",
      "trial: 3, iter: 3000, curr loss: 1.3183238506317139, avg loss: 1.3041156524419784\n",
      "trial: 3, ldr: 0.19698435068130493\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865588903427124, avg loss: 1.3873723876476287\n",
      "trial: 4, iter: 400, curr loss: 1.388664722442627, avg loss: 1.3864482986927031\n",
      "trial: 4, iter: 600, curr loss: 1.3817870616912842, avg loss: 1.385339423418045\n",
      "trial: 4, iter: 800, curr loss: 1.3607864379882812, avg loss: 1.3778505331277848\n",
      "trial: 4, iter: 1000, curr loss: 1.3659048080444336, avg loss: 1.3564525741338729\n",
      "trial: 4, iter: 1200, curr loss: 1.3276618719100952, avg loss: 1.3446669620275498\n",
      "trial: 4, iter: 1400, curr loss: 1.3360464572906494, avg loss: 1.341437196135521\n",
      "trial: 4, iter: 1600, curr loss: 1.3272747993469238, avg loss: 1.3355747717618942\n",
      "trial: 4, iter: 1800, curr loss: 1.3481594324111938, avg loss: 1.3325606846809388\n",
      "trial: 4, iter: 2000, curr loss: 1.304716944694519, avg loss: 1.3276543867588044\n",
      "trial: 4, iter: 2200, curr loss: 1.3175768852233887, avg loss: 1.3212277048826218\n",
      "trial: 4, iter: 2400, curr loss: 1.3501425981521606, avg loss: 1.3132441604137421\n",
      "trial: 4, iter: 2600, curr loss: 1.3132927417755127, avg loss: 1.3144751214981079\n",
      "trial: 4, iter: 2800, curr loss: 1.3346128463745117, avg loss: 1.3058392488956452\n",
      "trial: 4, iter: 3000, curr loss: 1.2807432413101196, avg loss: 1.302489287853241\n",
      "trial: 4, ldr: 0.14885222911834717\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387649416923523, avg loss: 1.3874488604068755\n",
      "trial: 5, iter: 400, curr loss: 1.385851263999939, avg loss: 1.3866769659519196\n",
      "trial: 5, iter: 600, curr loss: 1.386441946029663, avg loss: 1.3865035218000412\n",
      "trial: 5, iter: 800, curr loss: 1.3793103694915771, avg loss: 1.3852626740932465\n",
      "trial: 5, iter: 1000, curr loss: 1.3623343706130981, avg loss: 1.375438666343689\n",
      "trial: 5, iter: 1200, curr loss: 1.331413984298706, avg loss: 1.3541812360286714\n",
      "trial: 5, iter: 1400, curr loss: 1.333143711090088, avg loss: 1.3417209112644195\n",
      "trial: 5, iter: 1600, curr loss: 1.3551836013793945, avg loss: 1.3386130392551423\n",
      "trial: 5, iter: 1800, curr loss: 1.3414558172225952, avg loss: 1.3296947449445724\n",
      "trial: 5, iter: 2000, curr loss: 1.3234683275222778, avg loss: 1.32615718126297\n",
      "trial: 5, iter: 2200, curr loss: 1.3466286659240723, avg loss: 1.3203432434797286\n",
      "trial: 5, iter: 2400, curr loss: 1.3349921703338623, avg loss: 1.3167611104249954\n",
      "trial: 5, iter: 2600, curr loss: 1.2738767862319946, avg loss: 1.3075500351190568\n",
      "trial: 5, iter: 2800, curr loss: 1.2921066284179688, avg loss: 1.3036124515533447\n",
      "trial: 5, iter: 3000, curr loss: 1.266981601715088, avg loss: 1.3004018753767013\n",
      "trial: 5, ldr: 0.2241649180650711\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.18143560588359833\n",
      "Experiment done with data path: ./data/catNon-lin-NI_6/data.10k.dz20.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_3/data.20k.dz10.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873906135559082, avg loss: 1.3873607051372527\n",
      "trial: 1, iter: 400, curr loss: 1.38462495803833, avg loss: 1.3870547723770141\n",
      "trial: 1, iter: 600, curr loss: 1.383890986442566, avg loss: 1.3865290629863738\n",
      "trial: 1, iter: 800, curr loss: 1.3871636390686035, avg loss: 1.3867014849185944\n",
      "trial: 1, iter: 1000, curr loss: 1.385923981666565, avg loss: 1.386437821984291\n",
      "trial: 1, iter: 1200, curr loss: 1.3865607976913452, avg loss: 1.386436442732811\n",
      "trial: 1, iter: 1400, curr loss: 1.38703453540802, avg loss: 1.3864388978481292\n",
      "trial: 1, iter: 1600, curr loss: 1.3872089385986328, avg loss: 1.3864414221048356\n",
      "trial: 1, iter: 1800, curr loss: 1.3873103857040405, avg loss: 1.3863701599836349\n",
      "trial: 1, iter: 2000, curr loss: 1.3866794109344482, avg loss: 1.3863760858774186\n",
      "trial: 1, iter: 2200, curr loss: 1.385263442993164, avg loss: 1.3863308107852936\n",
      "trial: 1, iter: 2400, curr loss: 1.3871912956237793, avg loss: 1.3862188005447387\n",
      "trial: 1, iter: 2600, curr loss: 1.3858082294464111, avg loss: 1.386335961818695\n",
      "trial: 1, iter: 2800, curr loss: 1.3858036994934082, avg loss: 1.38625339448452\n",
      "trial: 1, iter: 3000, curr loss: 1.3876805305480957, avg loss: 1.386344901919365\n",
      "trial: 1, iter: 3200, curr loss: 1.3856152296066284, avg loss: 1.3862604880332947\n",
      "trial: 1, iter: 3400, curr loss: 1.3874412775039673, avg loss: 1.3862673407793045\n",
      "trial: 1, iter: 3600, curr loss: 1.3871386051177979, avg loss: 1.3862310963869096\n",
      "trial: 1, iter: 3800, curr loss: 1.3869391679763794, avg loss: 1.3862127274274827\n",
      "trial: 1, iter: 4000, curr loss: 1.386839509010315, avg loss: 1.3860933607816697\n",
      "trial: 1, iter: 4200, curr loss: 1.3868991136550903, avg loss: 1.386056314110756\n",
      "trial: 1, iter: 4400, curr loss: 1.3846557140350342, avg loss: 1.3858410453796386\n",
      "trial: 1, iter: 4600, curr loss: 1.3892388343811035, avg loss: 1.3857016748189925\n",
      "trial: 1, iter: 4800, curr loss: 1.385265827178955, avg loss: 1.3853942829370498\n",
      "trial: 1, iter: 5000, curr loss: 1.3861881494522095, avg loss: 1.3850207620859145\n",
      "trial: 1, iter: 5200, curr loss: 1.3820288181304932, avg loss: 1.3843359982967376\n",
      "trial: 1, iter: 5400, curr loss: 1.3826018571853638, avg loss: 1.3828894621133805\n",
      "trial: 1, iter: 5600, curr loss: 1.377459168434143, avg loss: 1.381993903517723\n",
      "trial: 1, iter: 5800, curr loss: 1.3733354806900024, avg loss: 1.3801809275150299\n",
      "trial: 1, iter: 6000, curr loss: 1.3795086145401, avg loss: 1.3779915958642959\n",
      "trial: 1, iter: 6200, curr loss: 1.3774611949920654, avg loss: 1.3751246798038483\n",
      "trial: 1, ldr: 0.008271319791674614\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3910175561904907, avg loss: 1.3876339691877364\n",
      "trial: 2, iter: 400, curr loss: 1.386972188949585, avg loss: 1.38708860039711\n",
      "trial: 2, iter: 600, curr loss: 1.3873484134674072, avg loss: 1.386754042506218\n",
      "trial: 2, iter: 800, curr loss: 1.3884176015853882, avg loss: 1.3865944457054138\n",
      "trial: 2, iter: 1000, curr loss: 1.3877216577529907, avg loss: 1.3865819442272187\n",
      "trial: 2, iter: 1200, curr loss: 1.3871444463729858, avg loss: 1.3864680778980256\n",
      "trial: 2, iter: 1400, curr loss: 1.385384202003479, avg loss: 1.3864772588014602\n",
      "trial: 2, iter: 1600, curr loss: 1.3865416049957275, avg loss: 1.3864515149593353\n",
      "trial: 2, iter: 1800, curr loss: 1.3872469663619995, avg loss: 1.386459811925888\n",
      "trial: 2, iter: 2000, curr loss: 1.3868790864944458, avg loss: 1.3863332378864288\n",
      "trial: 2, iter: 2200, curr loss: 1.3855974674224854, avg loss: 1.3863368850946427\n",
      "trial: 2, iter: 2400, curr loss: 1.3875391483306885, avg loss: 1.3863886618614196\n",
      "trial: 2, iter: 2600, curr loss: 1.3865208625793457, avg loss: 1.386401870250702\n",
      "trial: 2, iter: 2800, curr loss: 1.3875316381454468, avg loss: 1.386308714747429\n",
      "trial: 2, iter: 3000, curr loss: 1.3860012292861938, avg loss: 1.3863437336683273\n",
      "trial: 2, iter: 3200, curr loss: 1.3865087032318115, avg loss: 1.3862972658872605\n",
      "trial: 2, iter: 3400, curr loss: 1.3857287168502808, avg loss: 1.3863014549016952\n",
      "trial: 2, iter: 3600, curr loss: 1.3862278461456299, avg loss: 1.3863597828149796\n",
      "trial: 2, iter: 3800, curr loss: 1.3856520652770996, avg loss: 1.386286591887474\n",
      "trial: 2, iter: 4000, curr loss: 1.3863046169281006, avg loss: 1.386266340613365\n",
      "trial: 2, iter: 4200, curr loss: 1.38671875, avg loss: 1.3862759119272232\n",
      "trial: 2, iter: 4400, curr loss: 1.386962652206421, avg loss: 1.3861866760253907\n",
      "trial: 2, iter: 4600, curr loss: 1.3860435485839844, avg loss: 1.3861566925048827\n",
      "trial: 2, iter: 4800, curr loss: 1.3861604928970337, avg loss: 1.386165936589241\n",
      "trial: 2, iter: 5000, curr loss: 1.3849238157272339, avg loss: 1.3860764074325562\n",
      "trial: 2, iter: 5200, curr loss: 1.3844858407974243, avg loss: 1.3858816069364548\n",
      "trial: 2, iter: 5400, curr loss: 1.3859349489212036, avg loss: 1.3855828481912613\n",
      "trial: 2, iter: 5600, curr loss: 1.3844940662384033, avg loss: 1.3851974922418595\n",
      "trial: 2, iter: 5800, curr loss: 1.3831299543380737, avg loss: 1.3844422489404677\n",
      "trial: 2, iter: 6000, curr loss: 1.3827720880508423, avg loss: 1.383773843050003\n",
      "trial: 2, iter: 6200, curr loss: 1.380505919456482, avg loss: 1.3823756688833237\n",
      "trial: 2, ldr: -0.00405772915109992\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3895961046218872, avg loss: 1.3876775699853896\n",
      "trial: 3, iter: 400, curr loss: 1.3875004053115845, avg loss: 1.3869553309679032\n",
      "trial: 3, iter: 600, curr loss: 1.3867112398147583, avg loss: 1.3869077831506729\n",
      "trial: 3, iter: 800, curr loss: 1.3861275911331177, avg loss: 1.3866912013292312\n",
      "trial: 3, iter: 1000, curr loss: 1.3864502906799316, avg loss: 1.3864740991592408\n",
      "trial: 3, iter: 1200, curr loss: 1.383651852607727, avg loss: 1.3865439957380294\n",
      "trial: 3, iter: 1400, curr loss: 1.3858532905578613, avg loss: 1.3865192663669585\n",
      "trial: 3, iter: 1600, curr loss: 1.3866667747497559, avg loss: 1.3863993030786514\n",
      "trial: 3, iter: 1800, curr loss: 1.3860821723937988, avg loss: 1.3864477449655532\n",
      "trial: 3, iter: 2000, curr loss: 1.3860366344451904, avg loss: 1.3863845670223236\n",
      "trial: 3, iter: 2200, curr loss: 1.3846321105957031, avg loss: 1.3863590401411057\n",
      "trial: 3, iter: 2400, curr loss: 1.3852784633636475, avg loss: 1.386389098763466\n",
      "trial: 3, iter: 2600, curr loss: 1.3865423202514648, avg loss: 1.3863327246904373\n",
      "trial: 3, iter: 2800, curr loss: 1.3863928318023682, avg loss: 1.3863638705015182\n",
      "trial: 3, iter: 3000, curr loss: 1.3859188556671143, avg loss: 1.3863476246595383\n",
      "trial: 3, iter: 3200, curr loss: 1.3869394063949585, avg loss: 1.3862929409742355\n",
      "trial: 3, iter: 3400, curr loss: 1.3865166902542114, avg loss: 1.386287018060684\n",
      "trial: 3, iter: 3600, curr loss: 1.3869973421096802, avg loss: 1.3861373794078826\n",
      "trial: 3, iter: 3800, curr loss: 1.3855998516082764, avg loss: 1.386247428059578\n",
      "trial: 3, iter: 4000, curr loss: 1.3871577978134155, avg loss: 1.386239049434662\n",
      "trial: 3, iter: 4200, curr loss: 1.3849222660064697, avg loss: 1.3861351251602172\n",
      "trial: 3, iter: 4400, curr loss: 1.385769009590149, avg loss: 1.3860907357931138\n",
      "trial: 3, iter: 4600, curr loss: 1.3841017484664917, avg loss: 1.385940882563591\n",
      "trial: 3, iter: 4800, curr loss: 1.3857157230377197, avg loss: 1.3857565122842788\n",
      "trial: 3, iter: 5000, curr loss: 1.3860318660736084, avg loss: 1.3856442809104919\n",
      "trial: 3, iter: 5200, curr loss: 1.3848100900650024, avg loss: 1.38513443171978\n",
      "trial: 3, iter: 5400, curr loss: 1.3837684392929077, avg loss: 1.3847834265232086\n",
      "trial: 3, iter: 5600, curr loss: 1.3831814527511597, avg loss: 1.3839887911081314\n",
      "trial: 3, iter: 5800, curr loss: 1.3869966268539429, avg loss: 1.383640221953392\n",
      "trial: 3, iter: 6000, curr loss: 1.384365200996399, avg loss: 1.3822859811782837\n",
      "trial: 3, iter: 6200, curr loss: 1.3801579475402832, avg loss: 1.3812651818990707\n",
      "trial: 3, ldr: -0.0016433963319286704\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860867023468018, avg loss: 1.3875631070137024\n",
      "trial: 4, iter: 400, curr loss: 1.3898940086364746, avg loss: 1.3868270486593246\n",
      "trial: 4, iter: 600, curr loss: 1.3863552808761597, avg loss: 1.386631317138672\n",
      "trial: 4, iter: 800, curr loss: 1.3878668546676636, avg loss: 1.386506679058075\n",
      "trial: 4, iter: 1000, curr loss: 1.3860957622528076, avg loss: 1.386554892063141\n",
      "trial: 4, iter: 1200, curr loss: 1.3855966329574585, avg loss: 1.386498680114746\n",
      "trial: 4, iter: 1400, curr loss: 1.3873119354248047, avg loss: 1.3864296865463257\n",
      "trial: 4, iter: 1600, curr loss: 1.385479211807251, avg loss: 1.386414132118225\n",
      "trial: 4, iter: 1800, curr loss: 1.3880858421325684, avg loss: 1.386340401172638\n",
      "trial: 4, iter: 2000, curr loss: 1.3882553577423096, avg loss: 1.3863769751787185\n",
      "trial: 4, iter: 2200, curr loss: 1.385937213897705, avg loss: 1.386324747800827\n",
      "trial: 4, iter: 2400, curr loss: 1.3858609199523926, avg loss: 1.3863468086719513\n",
      "trial: 4, iter: 2600, curr loss: 1.387272596359253, avg loss: 1.3862483340501786\n",
      "trial: 4, iter: 2800, curr loss: 1.3841294050216675, avg loss: 1.3862075984477997\n",
      "trial: 4, iter: 3000, curr loss: 1.3861535787582397, avg loss: 1.386261910200119\n",
      "trial: 4, iter: 3200, curr loss: 1.3877257108688354, avg loss: 1.385997771024704\n",
      "trial: 4, iter: 3400, curr loss: 1.387137532234192, avg loss: 1.3860433775186538\n",
      "trial: 4, iter: 3600, curr loss: 1.3855236768722534, avg loss: 1.3859050381183624\n",
      "trial: 4, iter: 3800, curr loss: 1.3860465288162231, avg loss: 1.3856624573469163\n",
      "trial: 4, iter: 4000, curr loss: 1.3882704973220825, avg loss: 1.3853191405534744\n",
      "trial: 4, iter: 4200, curr loss: 1.3852572441101074, avg loss: 1.3848606419563294\n",
      "trial: 4, iter: 4400, curr loss: 1.3855550289154053, avg loss: 1.3841751581430435\n",
      "trial: 4, iter: 4600, curr loss: 1.3812633752822876, avg loss: 1.3831112599372863\n",
      "trial: 4, iter: 4800, curr loss: 1.3827747106552124, avg loss: 1.3822276377677918\n",
      "trial: 4, iter: 5000, curr loss: 1.3817635774612427, avg loss: 1.3811234843730926\n",
      "trial: 4, iter: 5200, curr loss: 1.373680591583252, avg loss: 1.3780957466363908\n",
      "trial: 4, iter: 5400, curr loss: 1.3751966953277588, avg loss: 1.3764804726839066\n",
      "trial: 4, iter: 5600, curr loss: 1.3701039552688599, avg loss: 1.3752635258436203\n",
      "trial: 4, iter: 5800, curr loss: 1.367225170135498, avg loss: 1.3717342346906662\n",
      "trial: 4, iter: 6000, curr loss: 1.3698616027832031, avg loss: 1.3689738816022874\n",
      "trial: 4, iter: 6200, curr loss: 1.3726003170013428, avg loss: 1.3664891934394836\n",
      "trial: 4, ldr: -0.0061379289254546165\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3875834941864014, avg loss: 1.3872433757781983\n",
      "trial: 5, iter: 400, curr loss: 1.385085940361023, avg loss: 1.3870844393968582\n",
      "trial: 5, iter: 600, curr loss: 1.3854000568389893, avg loss: 1.3868398886919022\n",
      "trial: 5, iter: 800, curr loss: 1.3865488767623901, avg loss: 1.3866758698225021\n",
      "trial: 5, iter: 1000, curr loss: 1.3869558572769165, avg loss: 1.386552192568779\n",
      "trial: 5, iter: 1200, curr loss: 1.3873467445373535, avg loss: 1.3864324486255646\n",
      "trial: 5, iter: 1400, curr loss: 1.386802315711975, avg loss: 1.3864078682661056\n",
      "trial: 5, iter: 1600, curr loss: 1.3862513303756714, avg loss: 1.386466873884201\n",
      "trial: 5, iter: 1800, curr loss: 1.3857450485229492, avg loss: 1.3863404339551926\n",
      "trial: 5, iter: 2000, curr loss: 1.3858140707015991, avg loss: 1.3863815152645111\n",
      "trial: 5, iter: 2200, curr loss: 1.3868286609649658, avg loss: 1.386333863735199\n",
      "trial: 5, iter: 2400, curr loss: 1.387280821800232, avg loss: 1.3863816857337952\n",
      "trial: 5, iter: 2600, curr loss: 1.3850765228271484, avg loss: 1.3863719940185546\n",
      "trial: 5, iter: 2800, curr loss: 1.3867498636245728, avg loss: 1.3863410025835037\n",
      "trial: 5, iter: 3000, curr loss: 1.3855284452438354, avg loss: 1.3862076473236085\n",
      "trial: 5, iter: 3200, curr loss: 1.3863236904144287, avg loss: 1.3862700217962265\n",
      "trial: 5, iter: 3400, curr loss: 1.3846924304962158, avg loss: 1.3861072450876235\n",
      "trial: 5, iter: 3600, curr loss: 1.3857746124267578, avg loss: 1.3862367796897888\n",
      "trial: 5, iter: 3800, curr loss: 1.3861083984375, avg loss: 1.3862783509492873\n",
      "trial: 5, iter: 4000, curr loss: 1.3869574069976807, avg loss: 1.38621184527874\n",
      "trial: 5, iter: 4200, curr loss: 1.3867528438568115, avg loss: 1.3862484884262085\n",
      "trial: 5, iter: 4400, curr loss: 1.3854873180389404, avg loss: 1.3860878044366836\n",
      "trial: 5, iter: 4600, curr loss: 1.3848388195037842, avg loss: 1.3858964681625365\n",
      "trial: 5, iter: 4800, curr loss: 1.3876805305480957, avg loss: 1.385981346964836\n",
      "trial: 5, iter: 5000, curr loss: 1.384615421295166, avg loss: 1.385811637043953\n",
      "trial: 5, iter: 5200, curr loss: 1.3873505592346191, avg loss: 1.3850901746749877\n",
      "trial: 5, iter: 5400, curr loss: 1.3789849281311035, avg loss: 1.3844123429059982\n",
      "trial: 5, iter: 5600, curr loss: 1.3802345991134644, avg loss: 1.3839490687847138\n",
      "trial: 5, iter: 5800, curr loss: 1.3824620246887207, avg loss: 1.3822732436656953\n",
      "trial: 5, iter: 6000, curr loss: 1.3786382675170898, avg loss: 1.3801300454139709\n",
      "trial: 5, iter: 6200, curr loss: 1.3707338571548462, avg loss: 1.378450757265091\n",
      "trial: 5, ldr: -0.002883081091567874\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0012901631416752934\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.389357089996338, avg loss: 1.387214396595955\n",
      "trial: 1, iter: 400, curr loss: 1.3847477436065674, avg loss: 1.3866823345422745\n",
      "trial: 1, iter: 600, curr loss: 1.3877085447311401, avg loss: 1.3865694338083268\n",
      "trial: 1, iter: 800, curr loss: 1.3876628875732422, avg loss: 1.3865872663259506\n",
      "trial: 1, iter: 1000, curr loss: 1.385422945022583, avg loss: 1.3865600442886352\n",
      "trial: 1, iter: 1200, curr loss: 1.384816288948059, avg loss: 1.3864551621675492\n",
      "trial: 1, iter: 1400, curr loss: 1.3865838050842285, avg loss: 1.3864573580026627\n",
      "trial: 1, iter: 1600, curr loss: 1.3858134746551514, avg loss: 1.3863586223125457\n",
      "trial: 1, iter: 1800, curr loss: 1.3876163959503174, avg loss: 1.3863438671827317\n",
      "trial: 1, iter: 2000, curr loss: 1.385888695716858, avg loss: 1.3863830083608628\n",
      "trial: 1, iter: 2200, curr loss: 1.3852523565292358, avg loss: 1.3864408266544341\n",
      "trial: 1, iter: 2400, curr loss: 1.385932445526123, avg loss: 1.386248230934143\n",
      "trial: 1, iter: 2600, curr loss: 1.3850855827331543, avg loss: 1.3863498562574386\n",
      "trial: 1, iter: 2800, curr loss: 1.386828899383545, avg loss: 1.386277871131897\n",
      "trial: 1, iter: 3000, curr loss: 1.386647343635559, avg loss: 1.386274781227112\n",
      "trial: 1, iter: 3200, curr loss: 1.3865504264831543, avg loss: 1.3863163316249847\n",
      "trial: 1, iter: 3400, curr loss: 1.385933518409729, avg loss: 1.3862562370300293\n",
      "trial: 1, iter: 3600, curr loss: 1.3850312232971191, avg loss: 1.386255704164505\n",
      "trial: 1, iter: 3800, curr loss: 1.3866981267929077, avg loss: 1.386130734682083\n",
      "trial: 1, iter: 4000, curr loss: 1.383699655532837, avg loss: 1.3862223088741303\n",
      "trial: 1, iter: 4200, curr loss: 1.3865162134170532, avg loss: 1.386030929684639\n",
      "trial: 1, iter: 4400, curr loss: 1.3879094123840332, avg loss: 1.3861082047224045\n",
      "trial: 1, iter: 4600, curr loss: 1.3861701488494873, avg loss: 1.3858161121606827\n",
      "trial: 1, iter: 4800, curr loss: 1.3896710872650146, avg loss: 1.3855540359020233\n",
      "trial: 1, iter: 5000, curr loss: 1.3817466497421265, avg loss: 1.3853464990854263\n",
      "trial: 1, iter: 5200, curr loss: 1.3861833810806274, avg loss: 1.3848311334848404\n",
      "trial: 1, iter: 5400, curr loss: 1.376081943511963, avg loss: 1.3840310621261596\n",
      "trial: 1, iter: 5600, curr loss: 1.3877880573272705, avg loss: 1.3830659890174866\n",
      "trial: 1, iter: 5800, curr loss: 1.380807876586914, avg loss: 1.382798369526863\n",
      "trial: 1, iter: 6000, curr loss: 1.3834021091461182, avg loss: 1.381672866344452\n",
      "trial: 1, iter: 6200, curr loss: 1.3839037418365479, avg loss: 1.3804946345090867\n",
      "trial: 1, ldr: 0.0014222234021872282\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863226175308228, avg loss: 1.3870695918798446\n",
      "trial: 2, iter: 400, curr loss: 1.3870805501937866, avg loss: 1.3865710592269898\n",
      "trial: 2, iter: 600, curr loss: 1.3870517015457153, avg loss: 1.3867224311828614\n",
      "trial: 2, iter: 800, curr loss: 1.3866236209869385, avg loss: 1.3864415842294693\n",
      "trial: 2, iter: 1000, curr loss: 1.388190507888794, avg loss: 1.3864123618602753\n",
      "trial: 2, iter: 1200, curr loss: 1.3862184286117554, avg loss: 1.386400608420372\n",
      "trial: 2, iter: 1400, curr loss: 1.3868204355239868, avg loss: 1.3864929473400116\n",
      "trial: 2, iter: 1600, curr loss: 1.3868833780288696, avg loss: 1.3863773894309999\n",
      "trial: 2, iter: 1800, curr loss: 1.3863848447799683, avg loss: 1.386320361495018\n",
      "trial: 2, iter: 2000, curr loss: 1.3862929344177246, avg loss: 1.38635704100132\n",
      "trial: 2, iter: 2200, curr loss: 1.3851408958435059, avg loss: 1.3863528597354888\n",
      "trial: 2, iter: 2400, curr loss: 1.386667251586914, avg loss: 1.3863567799329757\n",
      "trial: 2, iter: 2600, curr loss: 1.3865333795547485, avg loss: 1.3863408213853836\n",
      "trial: 2, iter: 2800, curr loss: 1.3858169317245483, avg loss: 1.3863120919466019\n",
      "trial: 2, iter: 3000, curr loss: 1.3862260580062866, avg loss: 1.3863314044475556\n",
      "trial: 2, iter: 3200, curr loss: 1.387230634689331, avg loss: 1.3863591188192368\n",
      "trial: 2, iter: 3400, curr loss: 1.386500358581543, avg loss: 1.386312757730484\n",
      "trial: 2, iter: 3600, curr loss: 1.3863455057144165, avg loss: 1.3862859553098679\n",
      "trial: 2, iter: 3800, curr loss: 1.386617660522461, avg loss: 1.3862458735704422\n",
      "trial: 2, iter: 4000, curr loss: 1.3852519989013672, avg loss: 1.3861813002824783\n",
      "trial: 2, iter: 4200, curr loss: 1.3849104642868042, avg loss: 1.3862822765111924\n",
      "trial: 2, iter: 4400, curr loss: 1.3863343000411987, avg loss: 1.3861806082725525\n",
      "trial: 2, iter: 4600, curr loss: 1.3865892887115479, avg loss: 1.3862170457839966\n",
      "trial: 2, iter: 4800, curr loss: 1.3872356414794922, avg loss: 1.3860101425647735\n",
      "trial: 2, iter: 5000, curr loss: 1.3854410648345947, avg loss: 1.3859113800525664\n",
      "trial: 2, iter: 5200, curr loss: 1.3838527202606201, avg loss: 1.3859616601467133\n",
      "trial: 2, iter: 5400, curr loss: 1.3880884647369385, avg loss: 1.385376535654068\n",
      "trial: 2, iter: 5600, curr loss: 1.384738802909851, avg loss: 1.3848059922456741\n",
      "trial: 2, iter: 5800, curr loss: 1.3860869407653809, avg loss: 1.3843531250953673\n",
      "trial: 2, iter: 6000, curr loss: 1.3824008703231812, avg loss: 1.3836287307739257\n",
      "trial: 2, iter: 6200, curr loss: 1.3759818077087402, avg loss: 1.3822200626134873\n",
      "trial: 2, ldr: 0.0029694829136133194\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.385818362236023, avg loss: 1.387352238893509\n",
      "trial: 3, iter: 400, curr loss: 1.3836452960968018, avg loss: 1.386672362089157\n",
      "trial: 3, iter: 600, curr loss: 1.3857096433639526, avg loss: 1.3867595607042313\n",
      "trial: 3, iter: 800, curr loss: 1.3872888088226318, avg loss: 1.3865081942081452\n",
      "trial: 3, iter: 1000, curr loss: 1.385208010673523, avg loss: 1.3866265296936036\n",
      "trial: 3, iter: 1200, curr loss: 1.3851021528244019, avg loss: 1.3863556295633317\n",
      "trial: 3, iter: 1400, curr loss: 1.386829137802124, avg loss: 1.3864460867643356\n",
      "trial: 3, iter: 1600, curr loss: 1.3854707479476929, avg loss: 1.3864433705806731\n",
      "trial: 3, iter: 1800, curr loss: 1.3871479034423828, avg loss: 1.3863884675502778\n",
      "trial: 3, iter: 2000, curr loss: 1.3883849382400513, avg loss: 1.3862725394964217\n",
      "trial: 3, iter: 2200, curr loss: 1.3845634460449219, avg loss: 1.3863706374168396\n",
      "trial: 3, iter: 2400, curr loss: 1.3868944644927979, avg loss: 1.3864075469970703\n",
      "trial: 3, iter: 2600, curr loss: 1.3858191967010498, avg loss: 1.3862922644615174\n",
      "trial: 3, iter: 2800, curr loss: 1.3869200944900513, avg loss: 1.3863280099630355\n",
      "trial: 3, iter: 3000, curr loss: 1.38545560836792, avg loss: 1.3862757980823517\n",
      "trial: 3, iter: 3200, curr loss: 1.385503888130188, avg loss: 1.3862519770860673\n",
      "trial: 3, iter: 3400, curr loss: 1.3853123188018799, avg loss: 1.386189377307892\n",
      "trial: 3, iter: 3600, curr loss: 1.3839725255966187, avg loss: 1.3860692781209947\n",
      "trial: 3, iter: 3800, curr loss: 1.385317087173462, avg loss: 1.3858037400245666\n",
      "trial: 3, iter: 4000, curr loss: 1.3874588012695312, avg loss: 1.3858403998613358\n",
      "trial: 3, iter: 4200, curr loss: 1.3849438428878784, avg loss: 1.385416259765625\n",
      "trial: 3, iter: 4400, curr loss: 1.3877203464508057, avg loss: 1.3854135966300964\n",
      "trial: 3, iter: 4600, curr loss: 1.3841792345046997, avg loss: 1.3848456805944442\n",
      "trial: 3, iter: 4800, curr loss: 1.388169288635254, avg loss: 1.3843946158885956\n",
      "trial: 3, iter: 5000, curr loss: 1.3810250759124756, avg loss: 1.3837475389242173\n",
      "trial: 3, iter: 5200, curr loss: 1.3802664279937744, avg loss: 1.3829489827156067\n",
      "trial: 3, iter: 5400, curr loss: 1.3792444467544556, avg loss: 1.3818412744998931\n",
      "trial: 3, iter: 5600, curr loss: 1.3765535354614258, avg loss: 1.3805951803922654\n",
      "trial: 3, iter: 5800, curr loss: 1.3696792125701904, avg loss: 1.3790418773889541\n",
      "trial: 3, iter: 6000, curr loss: 1.3747400045394897, avg loss: 1.3776435083150864\n",
      "trial: 3, iter: 6200, curr loss: 1.3809322118759155, avg loss: 1.376529398560524\n",
      "trial: 3, ldr: -0.000785482581704855\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388315200805664, avg loss: 1.387081670165062\n",
      "trial: 4, iter: 400, curr loss: 1.384948492050171, avg loss: 1.3867136389017105\n",
      "trial: 4, iter: 600, curr loss: 1.3857643604278564, avg loss: 1.386528543829918\n",
      "trial: 4, iter: 800, curr loss: 1.3852932453155518, avg loss: 1.3866256886720658\n",
      "trial: 4, iter: 1000, curr loss: 1.38588285446167, avg loss: 1.3864675956964492\n",
      "trial: 4, iter: 1200, curr loss: 1.3865524530410767, avg loss: 1.3864748132228852\n",
      "trial: 4, iter: 1400, curr loss: 1.3853801488876343, avg loss: 1.3864216405153273\n",
      "trial: 4, iter: 1600, curr loss: 1.3866499662399292, avg loss: 1.3863009595870972\n",
      "trial: 4, iter: 1800, curr loss: 1.3869411945343018, avg loss: 1.3863181501626969\n",
      "trial: 4, iter: 2000, curr loss: 1.3869245052337646, avg loss: 1.3863027036190032\n",
      "trial: 4, iter: 2200, curr loss: 1.3866095542907715, avg loss: 1.386301316022873\n",
      "trial: 4, iter: 2400, curr loss: 1.3849587440490723, avg loss: 1.3863903182744979\n",
      "trial: 4, iter: 2600, curr loss: 1.386594533920288, avg loss: 1.3862406253814696\n",
      "trial: 4, iter: 2800, curr loss: 1.386735439300537, avg loss: 1.3861904966831207\n",
      "trial: 4, iter: 3000, curr loss: 1.3857961893081665, avg loss: 1.386158798933029\n",
      "trial: 4, iter: 3200, curr loss: 1.3850903511047363, avg loss: 1.38609603703022\n",
      "trial: 4, iter: 3400, curr loss: 1.3854912519454956, avg loss: 1.3858906370401383\n",
      "trial: 4, iter: 3600, curr loss: 1.384110450744629, avg loss: 1.3857599741220474\n",
      "trial: 4, iter: 3800, curr loss: 1.3863444328308105, avg loss: 1.3855974692106248\n",
      "trial: 4, iter: 4000, curr loss: 1.3858433961868286, avg loss: 1.3850913274288177\n",
      "trial: 4, iter: 4200, curr loss: 1.3860594034194946, avg loss: 1.3847381430864334\n",
      "trial: 4, iter: 4400, curr loss: 1.3839080333709717, avg loss: 1.3840907841920853\n",
      "trial: 4, iter: 4600, curr loss: 1.3830311298370361, avg loss: 1.383076434135437\n",
      "trial: 4, iter: 4800, curr loss: 1.3776577711105347, avg loss: 1.3821156871318818\n",
      "trial: 4, iter: 5000, curr loss: 1.3872478008270264, avg loss: 1.3806036698818207\n",
      "trial: 4, iter: 5200, curr loss: 1.3747413158416748, avg loss: 1.3793229055404663\n",
      "trial: 4, iter: 5400, curr loss: 1.3688451051712036, avg loss: 1.3771775263547896\n",
      "trial: 4, iter: 5600, curr loss: 1.3748750686645508, avg loss: 1.3752310800552368\n",
      "trial: 4, iter: 5800, curr loss: 1.3637210130691528, avg loss: 1.3728038638830184\n",
      "trial: 4, iter: 6000, curr loss: 1.3859772682189941, avg loss: 1.3715786105394363\n",
      "trial: 4, iter: 6200, curr loss: 1.3719191551208496, avg loss: 1.3689204913377762\n",
      "trial: 4, ldr: -0.004701556637883186\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385704755783081, avg loss: 1.3873262417316437\n",
      "trial: 5, iter: 400, curr loss: 1.3867465257644653, avg loss: 1.3868704146146775\n",
      "trial: 5, iter: 600, curr loss: 1.3866355419158936, avg loss: 1.3865004032850266\n",
      "trial: 5, iter: 800, curr loss: 1.3867785930633545, avg loss: 1.386599480509758\n",
      "trial: 5, iter: 1000, curr loss: 1.3845977783203125, avg loss: 1.3865147411823273\n",
      "trial: 5, iter: 1200, curr loss: 1.3852527141571045, avg loss: 1.3864039331674576\n",
      "trial: 5, iter: 1400, curr loss: 1.3866108655929565, avg loss: 1.3864243018627167\n",
      "trial: 5, iter: 1600, curr loss: 1.3862690925598145, avg loss: 1.3864118427038192\n",
      "trial: 5, iter: 1800, curr loss: 1.3867958784103394, avg loss: 1.3862973791360855\n",
      "trial: 5, iter: 2000, curr loss: 1.385913372039795, avg loss: 1.3864158004522324\n",
      "trial: 5, iter: 2200, curr loss: 1.3860875368118286, avg loss: 1.3864024204015732\n",
      "trial: 5, iter: 2400, curr loss: 1.385919451713562, avg loss: 1.3862790012359618\n",
      "trial: 5, iter: 2600, curr loss: 1.38593590259552, avg loss: 1.3863904517889023\n",
      "trial: 5, iter: 2800, curr loss: 1.3860106468200684, avg loss: 1.38624573469162\n",
      "trial: 5, iter: 3000, curr loss: 1.3869030475616455, avg loss: 1.3863796943426132\n",
      "trial: 5, iter: 3200, curr loss: 1.3857054710388184, avg loss: 1.3862954396009446\n",
      "trial: 5, iter: 3400, curr loss: 1.385633111000061, avg loss: 1.3863066446781158\n",
      "trial: 5, iter: 3600, curr loss: 1.3867402076721191, avg loss: 1.3862757086753845\n",
      "trial: 5, iter: 3800, curr loss: 1.3864187002182007, avg loss: 1.3863637322187423\n",
      "trial: 5, iter: 4000, curr loss: 1.3864326477050781, avg loss: 1.3863370484113693\n",
      "trial: 5, iter: 4200, curr loss: 1.38560152053833, avg loss: 1.3863153183460235\n",
      "trial: 5, iter: 4400, curr loss: 1.3866685628890991, avg loss: 1.3862186592817307\n",
      "trial: 5, iter: 4600, curr loss: 1.3856319189071655, avg loss: 1.3861546701192855\n",
      "trial: 5, iter: 4800, curr loss: 1.3848799467086792, avg loss: 1.386183544397354\n",
      "trial: 5, iter: 5000, curr loss: 1.3876837491989136, avg loss: 1.3860669898986817\n",
      "trial: 5, iter: 5200, curr loss: 1.3850390911102295, avg loss: 1.3860373187065125\n",
      "trial: 5, iter: 5400, curr loss: 1.3862310647964478, avg loss: 1.3858110457658768\n",
      "trial: 5, iter: 5600, curr loss: 1.3824712038040161, avg loss: 1.38579698741436\n",
      "trial: 5, iter: 5800, curr loss: 1.3858001232147217, avg loss: 1.3853279519081116\n",
      "trial: 5, iter: 6000, curr loss: 1.381331443786621, avg loss: 1.3849808502197265\n",
      "trial: 5, iter: 6200, curr loss: 1.3803741931915283, avg loss: 1.3842668372392655\n",
      "trial: 5, ldr: 0.0017512907506898046\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00013119156938046217\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3895890712738037, avg loss: 1.387351297736168\n",
      "trial: 1, iter: 400, curr loss: 1.3885942697525024, avg loss: 1.3869847482442856\n",
      "trial: 1, iter: 600, curr loss: 1.385830283164978, avg loss: 1.3867526072263718\n",
      "trial: 1, iter: 800, curr loss: 1.3865454196929932, avg loss: 1.3868069231510163\n",
      "trial: 1, iter: 1000, curr loss: 1.386569857597351, avg loss: 1.3866111785173416\n",
      "trial: 1, iter: 1200, curr loss: 1.3861292600631714, avg loss: 1.38658950984478\n",
      "trial: 1, iter: 1400, curr loss: 1.3885738849639893, avg loss: 1.3863876205682755\n",
      "trial: 1, iter: 1600, curr loss: 1.3859820365905762, avg loss: 1.3865610617399216\n",
      "trial: 1, iter: 1800, curr loss: 1.384651780128479, avg loss: 1.3863998091220855\n",
      "trial: 1, iter: 2000, curr loss: 1.3863117694854736, avg loss: 1.386291916370392\n",
      "trial: 1, iter: 2200, curr loss: 1.384677767753601, avg loss: 1.386316242814064\n",
      "trial: 1, iter: 2400, curr loss: 1.386973261833191, avg loss: 1.3861816906929016\n",
      "trial: 1, iter: 2600, curr loss: 1.3845024108886719, avg loss: 1.3862365233898162\n",
      "trial: 1, iter: 2800, curr loss: 1.385830044746399, avg loss: 1.3862780225276947\n",
      "trial: 1, iter: 3000, curr loss: 1.3848966360092163, avg loss: 1.3861644065380097\n",
      "trial: 1, iter: 3200, curr loss: 1.3868101835250854, avg loss: 1.386124941110611\n",
      "trial: 1, iter: 3400, curr loss: 1.385117769241333, avg loss: 1.386278475522995\n",
      "trial: 1, iter: 3600, curr loss: 1.3870121240615845, avg loss: 1.3860663121938706\n",
      "trial: 1, iter: 3800, curr loss: 1.3863111734390259, avg loss: 1.3860546386241912\n",
      "trial: 1, iter: 4000, curr loss: 1.3834874629974365, avg loss: 1.3858223783969879\n",
      "trial: 1, iter: 4200, curr loss: 1.384263277053833, avg loss: 1.3857751441001893\n",
      "trial: 1, iter: 4400, curr loss: 1.3830245733261108, avg loss: 1.385233244895935\n",
      "trial: 1, iter: 4600, curr loss: 1.3868906497955322, avg loss: 1.3848845219612123\n",
      "trial: 1, iter: 4800, curr loss: 1.3775817155838013, avg loss: 1.3845796889066697\n",
      "trial: 1, iter: 5000, curr loss: 1.3819825649261475, avg loss: 1.3835454344749452\n",
      "trial: 1, iter: 5200, curr loss: 1.3812761306762695, avg loss: 1.3830581933259964\n",
      "trial: 1, iter: 5400, curr loss: 1.3736333847045898, avg loss: 1.3803556507825852\n",
      "trial: 1, iter: 5600, curr loss: 1.3775094747543335, avg loss: 1.380151029229164\n",
      "trial: 1, iter: 5800, curr loss: 1.3734166622161865, avg loss: 1.378305766582489\n",
      "trial: 1, iter: 6000, curr loss: 1.3659552335739136, avg loss: 1.3769263571500778\n",
      "trial: 1, iter: 6200, curr loss: 1.3712279796600342, avg loss: 1.3745750987529755\n",
      "trial: 1, ldr: 0.006017363164573908\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387068271636963, avg loss: 1.3872590255737305\n",
      "trial: 2, iter: 400, curr loss: 1.382252812385559, avg loss: 1.386758013367653\n",
      "trial: 2, iter: 600, curr loss: 1.3843837976455688, avg loss: 1.3867646622657777\n",
      "trial: 2, iter: 800, curr loss: 1.3878822326660156, avg loss: 1.3867654359340669\n",
      "trial: 2, iter: 1000, curr loss: 1.3870577812194824, avg loss: 1.3865011751651763\n",
      "trial: 2, iter: 1200, curr loss: 1.3854275941848755, avg loss: 1.3864534950256349\n",
      "trial: 2, iter: 1400, curr loss: 1.3860315084457397, avg loss: 1.3864085072278975\n",
      "trial: 2, iter: 1600, curr loss: 1.38621187210083, avg loss: 1.3863938075304032\n",
      "trial: 2, iter: 1800, curr loss: 1.3861502408981323, avg loss: 1.3862817978858948\n",
      "trial: 2, iter: 2000, curr loss: 1.385876178741455, avg loss: 1.386399651169777\n",
      "trial: 2, iter: 2200, curr loss: 1.3858400583267212, avg loss: 1.3862346249818802\n",
      "trial: 2, iter: 2400, curr loss: 1.3871508836746216, avg loss: 1.3863589346408844\n",
      "trial: 2, iter: 2600, curr loss: 1.3862452507019043, avg loss: 1.3862915337085724\n",
      "trial: 2, iter: 2800, curr loss: 1.3874115943908691, avg loss: 1.3863207668066024\n",
      "trial: 2, iter: 3000, curr loss: 1.3854914903640747, avg loss: 1.3861685544252396\n",
      "trial: 2, iter: 3200, curr loss: 1.3879506587982178, avg loss: 1.3863368153572082\n",
      "trial: 2, iter: 3400, curr loss: 1.3872498273849487, avg loss: 1.3861476880311967\n",
      "trial: 2, iter: 3600, curr loss: 1.3853881359100342, avg loss: 1.3860214561223985\n",
      "trial: 2, iter: 3800, curr loss: 1.3858214616775513, avg loss: 1.3858715051412582\n",
      "trial: 2, iter: 4000, curr loss: 1.3866205215454102, avg loss: 1.3855568236112594\n",
      "trial: 2, iter: 4200, curr loss: 1.3871155977249146, avg loss: 1.3853210312128068\n",
      "trial: 2, iter: 4400, curr loss: 1.3847641944885254, avg loss: 1.3846617126464844\n",
      "trial: 2, iter: 4600, curr loss: 1.3835937976837158, avg loss: 1.384295049905777\n",
      "trial: 2, iter: 4800, curr loss: 1.379780888557434, avg loss: 1.383066024184227\n",
      "trial: 2, iter: 5000, curr loss: 1.3810256719589233, avg loss: 1.3817314583063125\n",
      "trial: 2, iter: 5200, curr loss: 1.3829668760299683, avg loss: 1.381145179271698\n",
      "trial: 2, iter: 5400, curr loss: 1.3623888492584229, avg loss: 1.378330832719803\n",
      "trial: 2, iter: 5600, curr loss: 1.37960684299469, avg loss: 1.3774079722166062\n",
      "trial: 2, iter: 5800, curr loss: 1.3679027557373047, avg loss: 1.3770496094226836\n",
      "trial: 2, iter: 6000, curr loss: 1.376068353652954, avg loss: 1.3741369146108626\n",
      "trial: 2, iter: 6200, curr loss: 1.3873741626739502, avg loss: 1.3745954626798629\n",
      "trial: 2, ldr: 0.0023366217501461506\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3922368288040161, avg loss: 1.3872578382492065\n",
      "trial: 3, iter: 400, curr loss: 1.3882410526275635, avg loss: 1.3867088550329207\n",
      "trial: 3, iter: 600, curr loss: 1.3865973949432373, avg loss: 1.3867494946718215\n",
      "trial: 3, iter: 800, curr loss: 1.3854516744613647, avg loss: 1.3865842950344085\n",
      "trial: 3, iter: 1000, curr loss: 1.3860580921173096, avg loss: 1.3865245324373245\n",
      "trial: 3, iter: 1200, curr loss: 1.385776400566101, avg loss: 1.3864370834827424\n",
      "trial: 3, iter: 1400, curr loss: 1.3877949714660645, avg loss: 1.3863921397924424\n",
      "trial: 3, iter: 1600, curr loss: 1.3856217861175537, avg loss: 1.3863582891225814\n",
      "trial: 3, iter: 1800, curr loss: 1.3849201202392578, avg loss: 1.3862952369451522\n",
      "trial: 3, iter: 2000, curr loss: 1.3874177932739258, avg loss: 1.3865085911750794\n",
      "trial: 3, iter: 2200, curr loss: 1.385682225227356, avg loss: 1.3863289171457291\n",
      "trial: 3, iter: 2400, curr loss: 1.387336254119873, avg loss: 1.3863463824987412\n",
      "trial: 3, iter: 2600, curr loss: 1.3875641822814941, avg loss: 1.3863498491048813\n",
      "trial: 3, iter: 2800, curr loss: 1.3859657049179077, avg loss: 1.3863580513000489\n",
      "trial: 3, iter: 3000, curr loss: 1.3856546878814697, avg loss: 1.3863121855258942\n",
      "trial: 3, iter: 3200, curr loss: 1.385042667388916, avg loss: 1.3862889850139617\n",
      "trial: 3, iter: 3400, curr loss: 1.386569619178772, avg loss: 1.3863740307092667\n",
      "trial: 3, iter: 3600, curr loss: 1.3862360715866089, avg loss: 1.386331987977028\n",
      "trial: 3, iter: 3800, curr loss: 1.38627028465271, avg loss: 1.3863533908128738\n",
      "trial: 3, iter: 4000, curr loss: 1.3860082626342773, avg loss: 1.3863522654771805\n",
      "trial: 3, iter: 4200, curr loss: 1.3848382234573364, avg loss: 1.3862255710363387\n",
      "trial: 3, iter: 4400, curr loss: 1.386122465133667, avg loss: 1.386392822265625\n",
      "trial: 3, iter: 4600, curr loss: 1.3863534927368164, avg loss: 1.3863370597362519\n",
      "trial: 3, iter: 4800, curr loss: 1.3863177299499512, avg loss: 1.3863076609373093\n",
      "trial: 3, iter: 5000, curr loss: 1.386528491973877, avg loss: 1.3863242077827453\n",
      "trial: 3, iter: 5200, curr loss: 1.3854658603668213, avg loss: 1.3862780129909515\n",
      "trial: 3, iter: 5400, curr loss: 1.3852829933166504, avg loss: 1.3862504678964616\n",
      "trial: 3, iter: 5600, curr loss: 1.3853634595870972, avg loss: 1.386290755867958\n",
      "trial: 3, iter: 5800, curr loss: 1.3862072229385376, avg loss: 1.3863814604282378\n",
      "trial: 3, iter: 6000, curr loss: 1.3856921195983887, avg loss: 1.386366394162178\n",
      "trial: 3, iter: 6200, curr loss: 1.3870290517807007, avg loss: 1.3862719935178758\n",
      "trial: 3, ldr: 0.002007592236623168\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3864655494689941, avg loss: 1.3872432643175125\n",
      "trial: 4, iter: 400, curr loss: 1.3842624425888062, avg loss: 1.3864022117853165\n",
      "trial: 4, iter: 600, curr loss: 1.3887187242507935, avg loss: 1.3867770516872406\n",
      "trial: 4, iter: 800, curr loss: 1.386562466621399, avg loss: 1.3864810287952423\n",
      "trial: 4, iter: 1000, curr loss: 1.387220025062561, avg loss: 1.3863736116886138\n",
      "trial: 4, iter: 1200, curr loss: 1.3880698680877686, avg loss: 1.3863823348283768\n",
      "trial: 4, iter: 1400, curr loss: 1.3864883184432983, avg loss: 1.386356150507927\n",
      "trial: 4, iter: 1600, curr loss: 1.38469398021698, avg loss: 1.3863913440704345\n",
      "trial: 4, iter: 1800, curr loss: 1.3863906860351562, avg loss: 1.3863396817445754\n",
      "trial: 4, iter: 2000, curr loss: 1.3852031230926514, avg loss: 1.386274866461754\n",
      "trial: 4, iter: 2200, curr loss: 1.385905146598816, avg loss: 1.3863575035333633\n",
      "trial: 4, iter: 2400, curr loss: 1.3855950832366943, avg loss: 1.386177680492401\n",
      "trial: 4, iter: 2600, curr loss: 1.3844255208969116, avg loss: 1.3862093245983125\n",
      "trial: 4, iter: 2800, curr loss: 1.3866426944732666, avg loss: 1.3862844240665435\n",
      "trial: 4, iter: 3000, curr loss: 1.3860379457473755, avg loss: 1.3861268317699433\n",
      "trial: 4, iter: 3200, curr loss: 1.3851090669631958, avg loss: 1.3859603840112686\n",
      "trial: 4, iter: 3400, curr loss: 1.3861100673675537, avg loss: 1.385900610089302\n",
      "trial: 4, iter: 3600, curr loss: 1.386620044708252, avg loss: 1.3855333697795869\n",
      "trial: 4, iter: 3800, curr loss: 1.3846807479858398, avg loss: 1.3852835243940353\n",
      "trial: 4, iter: 4000, curr loss: 1.38583505153656, avg loss: 1.384734051823616\n",
      "trial: 4, iter: 4200, curr loss: 1.3846001625061035, avg loss: 1.3842051273584366\n",
      "trial: 4, iter: 4400, curr loss: 1.3829559087753296, avg loss: 1.3834127628803252\n",
      "trial: 4, iter: 4600, curr loss: 1.3850899934768677, avg loss: 1.382270342707634\n",
      "trial: 4, iter: 4800, curr loss: 1.3809255361557007, avg loss: 1.3812237560749054\n",
      "trial: 4, iter: 5000, curr loss: 1.3841428756713867, avg loss: 1.3803249508142472\n",
      "trial: 4, iter: 5200, curr loss: 1.3638100624084473, avg loss: 1.3786126667261123\n",
      "trial: 4, iter: 5400, curr loss: 1.369771122932434, avg loss: 1.37832226395607\n",
      "trial: 4, iter: 5600, curr loss: 1.3759976625442505, avg loss: 1.3761489206552506\n",
      "trial: 4, iter: 5800, curr loss: 1.3770853281021118, avg loss: 1.3741207963228226\n",
      "trial: 4, iter: 6000, curr loss: 1.365297794342041, avg loss: 1.3729472213983536\n",
      "trial: 4, iter: 6200, curr loss: 1.3728479146957397, avg loss: 1.3722440773248672\n",
      "trial: 4, ldr: -0.0017392736626788974\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860727548599243, avg loss: 1.3874124193191528\n",
      "trial: 5, iter: 400, curr loss: 1.3858119249343872, avg loss: 1.3866592997312546\n",
      "trial: 5, iter: 600, curr loss: 1.3879286050796509, avg loss: 1.38677818775177\n",
      "trial: 5, iter: 800, curr loss: 1.3863426446914673, avg loss: 1.3865735447406768\n",
      "trial: 5, iter: 1000, curr loss: 1.3854678869247437, avg loss: 1.3863622015714645\n",
      "trial: 5, iter: 1200, curr loss: 1.386930227279663, avg loss: 1.3864274108409882\n",
      "trial: 5, iter: 1400, curr loss: 1.3843330144882202, avg loss: 1.3862094193696977\n",
      "trial: 5, iter: 1600, curr loss: 1.3865973949432373, avg loss: 1.3863533920049667\n",
      "trial: 5, iter: 1800, curr loss: 1.3846839666366577, avg loss: 1.3861827069520951\n",
      "trial: 5, iter: 2000, curr loss: 1.385906457901001, avg loss: 1.3863401591777802\n",
      "trial: 5, iter: 2200, curr loss: 1.3870550394058228, avg loss: 1.3861926341056823\n",
      "trial: 5, iter: 2400, curr loss: 1.3879802227020264, avg loss: 1.3862020671367645\n",
      "trial: 5, iter: 2600, curr loss: 1.3866441249847412, avg loss: 1.3861887598037719\n",
      "trial: 5, iter: 2800, curr loss: 1.386716365814209, avg loss: 1.3859822243452071\n",
      "trial: 5, iter: 3000, curr loss: 1.3838993310928345, avg loss: 1.3858028173446655\n",
      "trial: 5, iter: 3200, curr loss: 1.3863179683685303, avg loss: 1.3854636549949646\n",
      "trial: 5, iter: 3400, curr loss: 1.3845489025115967, avg loss: 1.3852588796615601\n",
      "trial: 5, iter: 3600, curr loss: 1.3838354349136353, avg loss: 1.3848344033956528\n",
      "trial: 5, iter: 3800, curr loss: 1.3841313123703003, avg loss: 1.3837203270196914\n",
      "trial: 5, iter: 4000, curr loss: 1.3813296556472778, avg loss: 1.3828524136543274\n",
      "trial: 5, iter: 4200, curr loss: 1.3751564025878906, avg loss: 1.3820378375053406\n",
      "trial: 5, iter: 4400, curr loss: 1.3741523027420044, avg loss: 1.3805546408891678\n",
      "trial: 5, iter: 4600, curr loss: 1.3669835329055786, avg loss: 1.37933602809906\n",
      "trial: 5, iter: 4800, curr loss: 1.380467414855957, avg loss: 1.3777756202220917\n",
      "trial: 5, iter: 5000, curr loss: 1.3831777572631836, avg loss: 1.3767681753635406\n",
      "trial: 5, iter: 5200, curr loss: 1.3750067949295044, avg loss: 1.375051280260086\n",
      "trial: 5, iter: 5400, curr loss: 1.3739060163497925, avg loss: 1.3733387553691865\n",
      "trial: 5, iter: 5600, curr loss: 1.3691527843475342, avg loss: 1.3710557502508163\n",
      "trial: 5, iter: 5800, curr loss: 1.3568042516708374, avg loss: 1.3685736501216887\n",
      "trial: 5, iter: 6000, curr loss: 1.3628146648406982, avg loss: 1.3674726897478104\n",
      "trial: 5, iter: 6200, curr loss: 1.365553617477417, avg loss: 1.365916662812233\n",
      "trial: 5, ldr: -0.005182018503546715\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0006880569970235228\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3863215446472168, avg loss: 1.3871974706649781\n",
      "trial: 1, iter: 400, curr loss: 1.3883918523788452, avg loss: 1.3870427149534226\n",
      "trial: 1, iter: 600, curr loss: 1.387244701385498, avg loss: 1.3867350101470948\n",
      "trial: 1, iter: 800, curr loss: 1.3863744735717773, avg loss: 1.3863990092277527\n",
      "trial: 1, iter: 1000, curr loss: 1.3900110721588135, avg loss: 1.38642893075943\n",
      "trial: 1, iter: 1200, curr loss: 1.387627363204956, avg loss: 1.386584193110466\n",
      "trial: 1, iter: 1400, curr loss: 1.3864027261734009, avg loss: 1.386383455991745\n",
      "trial: 1, iter: 1600, curr loss: 1.3874764442443848, avg loss: 1.3864279460906983\n",
      "trial: 1, iter: 1800, curr loss: 1.3884153366088867, avg loss: 1.3862875431776047\n",
      "trial: 1, iter: 2000, curr loss: 1.3864127397537231, avg loss: 1.3862371772527695\n",
      "trial: 1, iter: 2200, curr loss: 1.384486198425293, avg loss: 1.3863863861560821\n",
      "trial: 1, iter: 2400, curr loss: 1.38460111618042, avg loss: 1.3861978650093079\n",
      "trial: 1, iter: 2600, curr loss: 1.3865188360214233, avg loss: 1.3863852107524872\n",
      "trial: 1, iter: 2800, curr loss: 1.3867673873901367, avg loss: 1.3861853748559951\n",
      "trial: 1, iter: 3000, curr loss: 1.3849005699157715, avg loss: 1.3861328899860381\n",
      "trial: 1, iter: 3200, curr loss: 1.386414647102356, avg loss: 1.386019576191902\n",
      "trial: 1, iter: 3400, curr loss: 1.3833235502243042, avg loss: 1.3861699193716048\n",
      "trial: 1, iter: 3600, curr loss: 1.3827102184295654, avg loss: 1.3856887471675874\n",
      "trial: 1, iter: 3800, curr loss: 1.3863873481750488, avg loss: 1.385785745382309\n",
      "trial: 1, iter: 4000, curr loss: 1.3804086446762085, avg loss: 1.385401228070259\n",
      "trial: 1, iter: 4200, curr loss: 1.3857800960540771, avg loss: 1.3850128906965256\n",
      "trial: 1, iter: 4400, curr loss: 1.3807547092437744, avg loss: 1.3843538802862168\n",
      "trial: 1, iter: 4600, curr loss: 1.3804426193237305, avg loss: 1.3833850502967835\n",
      "trial: 1, iter: 4800, curr loss: 1.377515196800232, avg loss: 1.3822961896657944\n",
      "trial: 1, iter: 5000, curr loss: 1.3755466938018799, avg loss: 1.3810697138309478\n",
      "trial: 1, iter: 5200, curr loss: 1.3772392272949219, avg loss: 1.3795110136270523\n",
      "trial: 1, iter: 5400, curr loss: 1.364717960357666, avg loss: 1.3777577477693557\n",
      "trial: 1, iter: 5600, curr loss: 1.3709092140197754, avg loss: 1.3761310684680939\n",
      "trial: 1, iter: 5800, curr loss: 1.3587766885757446, avg loss: 1.3747848308086394\n",
      "trial: 1, iter: 6000, curr loss: 1.3712654113769531, avg loss: 1.3728477269411088\n",
      "trial: 1, iter: 6200, curr loss: 1.3654792308807373, avg loss: 1.3694250643253327\n",
      "trial: 1, ldr: -0.0030140553135424852\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3864079713821411, avg loss: 1.3871817409992218\n",
      "trial: 2, iter: 400, curr loss: 1.386233925819397, avg loss: 1.3865753787755966\n",
      "trial: 2, iter: 600, curr loss: 1.3897584676742554, avg loss: 1.386565763950348\n",
      "trial: 2, iter: 800, curr loss: 1.3859676122665405, avg loss: 1.3865010207891464\n",
      "trial: 2, iter: 1000, curr loss: 1.3855364322662354, avg loss: 1.3863918477296828\n",
      "trial: 2, iter: 1200, curr loss: 1.3870185613632202, avg loss: 1.386278904080391\n",
      "trial: 2, iter: 1400, curr loss: 1.3861093521118164, avg loss: 1.3863302552700043\n",
      "trial: 2, iter: 1600, curr loss: 1.3864442110061646, avg loss: 1.38627612054348\n",
      "trial: 2, iter: 1800, curr loss: 1.3850177526474, avg loss: 1.3863330370187759\n",
      "trial: 2, iter: 2000, curr loss: 1.3865079879760742, avg loss: 1.3863087821006774\n",
      "trial: 2, iter: 2200, curr loss: 1.3862576484680176, avg loss: 1.386165205836296\n",
      "trial: 2, iter: 2400, curr loss: 1.3868732452392578, avg loss: 1.386250513792038\n",
      "trial: 2, iter: 2600, curr loss: 1.385273814201355, avg loss: 1.3862596374750138\n",
      "trial: 2, iter: 2800, curr loss: 1.3867239952087402, avg loss: 1.386130450963974\n",
      "trial: 2, iter: 3000, curr loss: 1.389519214630127, avg loss: 1.3861094570159913\n",
      "trial: 2, iter: 3200, curr loss: 1.384774088859558, avg loss: 1.3860976672172547\n",
      "trial: 2, iter: 3400, curr loss: 1.3847548961639404, avg loss: 1.3859232085943223\n",
      "trial: 2, iter: 3600, curr loss: 1.385796308517456, avg loss: 1.3859532916545867\n",
      "trial: 2, iter: 3800, curr loss: 1.3877073526382446, avg loss: 1.385654559135437\n",
      "trial: 2, iter: 4000, curr loss: 1.3873546123504639, avg loss: 1.3852855545282363\n",
      "trial: 2, iter: 4200, curr loss: 1.387642502784729, avg loss: 1.3843611121177672\n",
      "trial: 2, iter: 4400, curr loss: 1.386983036994934, avg loss: 1.3837630367279052\n",
      "trial: 2, iter: 4600, curr loss: 1.3805676698684692, avg loss: 1.3828384292125702\n",
      "trial: 2, iter: 4800, curr loss: 1.3804234266281128, avg loss: 1.3811313462257386\n",
      "trial: 2, iter: 5000, curr loss: 1.3742440938949585, avg loss: 1.3799236154556274\n",
      "trial: 2, iter: 5200, curr loss: 1.3689042329788208, avg loss: 1.3787241351604462\n",
      "trial: 2, iter: 5400, curr loss: 1.3786813020706177, avg loss: 1.3751835745573044\n",
      "trial: 2, iter: 5600, curr loss: 1.365501046180725, avg loss: 1.3735208457708359\n",
      "trial: 2, iter: 5800, curr loss: 1.3661980628967285, avg loss: 1.3724658834934234\n",
      "trial: 2, iter: 6000, curr loss: 1.3602263927459717, avg loss: 1.369402651786804\n",
      "trial: 2, iter: 6200, curr loss: 1.3946328163146973, avg loss: 1.3683328729867936\n",
      "trial: 2, ldr: -0.0035328338854014874\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387128472328186, avg loss: 1.3869833832979201\n",
      "trial: 3, iter: 400, curr loss: 1.3883172273635864, avg loss: 1.3868363744020462\n",
      "trial: 3, iter: 600, curr loss: 1.3869203329086304, avg loss: 1.3865469455718995\n",
      "trial: 3, iter: 800, curr loss: 1.3869988918304443, avg loss: 1.3865224009752273\n",
      "trial: 3, iter: 1000, curr loss: 1.386589765548706, avg loss: 1.3865190517902375\n",
      "trial: 3, iter: 1200, curr loss: 1.3861037492752075, avg loss: 1.3864428752660751\n",
      "trial: 3, iter: 1400, curr loss: 1.387162446975708, avg loss: 1.3863482886552811\n",
      "trial: 3, iter: 1600, curr loss: 1.3853754997253418, avg loss: 1.3865077251195908\n",
      "trial: 3, iter: 1800, curr loss: 1.3870073556900024, avg loss: 1.386382588148117\n",
      "trial: 3, iter: 2000, curr loss: 1.3863983154296875, avg loss: 1.3862960630655288\n",
      "trial: 3, iter: 2200, curr loss: 1.3860340118408203, avg loss: 1.3864113348722458\n",
      "trial: 3, iter: 2400, curr loss: 1.3878687620162964, avg loss: 1.3862350392341614\n",
      "trial: 3, iter: 2600, curr loss: 1.3859294652938843, avg loss: 1.3863344025611877\n",
      "trial: 3, iter: 2800, curr loss: 1.3870052099227905, avg loss: 1.386327199935913\n",
      "trial: 3, iter: 3000, curr loss: 1.3873028755187988, avg loss: 1.3862839823961257\n",
      "trial: 3, iter: 3200, curr loss: 1.386125922203064, avg loss: 1.3862991452217102\n",
      "trial: 3, iter: 3400, curr loss: 1.3835043907165527, avg loss: 1.386245545744896\n",
      "trial: 3, iter: 3600, curr loss: 1.3862712383270264, avg loss: 1.3862752908468245\n",
      "trial: 3, iter: 3800, curr loss: 1.3857554197311401, avg loss: 1.3862158834934235\n",
      "trial: 3, iter: 4000, curr loss: 1.3864609003067017, avg loss: 1.386248123049736\n",
      "trial: 3, iter: 4200, curr loss: 1.3851770162582397, avg loss: 1.3861866891384125\n",
      "trial: 3, iter: 4400, curr loss: 1.388573169708252, avg loss: 1.3862178671360015\n",
      "trial: 3, iter: 4600, curr loss: 1.3867647647857666, avg loss: 1.3860767501592637\n",
      "trial: 3, iter: 4800, curr loss: 1.3852589130401611, avg loss: 1.3860010194778443\n",
      "trial: 3, iter: 5000, curr loss: 1.3862903118133545, avg loss: 1.385903137922287\n",
      "trial: 3, iter: 5200, curr loss: 1.3852659463882446, avg loss: 1.3857328826189041\n",
      "trial: 3, iter: 5400, curr loss: 1.3854461908340454, avg loss: 1.3853387004137039\n",
      "trial: 3, iter: 5600, curr loss: 1.3882098197937012, avg loss: 1.3847926872968674\n",
      "trial: 3, iter: 5800, curr loss: 1.386372685432434, avg loss: 1.3842519676685334\n",
      "trial: 3, iter: 6000, curr loss: 1.386660099029541, avg loss: 1.3833195984363555\n",
      "trial: 3, iter: 6200, curr loss: 1.3804396390914917, avg loss: 1.3817998254299164\n",
      "trial: 3, ldr: -0.008695807307958603\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.384422779083252, avg loss: 1.3873598766326904\n",
      "trial: 4, iter: 400, curr loss: 1.3869671821594238, avg loss: 1.3868080073595046\n",
      "trial: 4, iter: 600, curr loss: 1.3875380754470825, avg loss: 1.3866258537769318\n",
      "trial: 4, iter: 800, curr loss: 1.3858840465545654, avg loss: 1.3863839399814606\n",
      "trial: 4, iter: 1000, curr loss: 1.388388752937317, avg loss: 1.3863939511775971\n",
      "trial: 4, iter: 1200, curr loss: 1.3857778310775757, avg loss: 1.3865068447589874\n",
      "trial: 4, iter: 1400, curr loss: 1.3854821920394897, avg loss: 1.3863100463151932\n",
      "trial: 4, iter: 1600, curr loss: 1.3846075534820557, avg loss: 1.3864270150661469\n",
      "trial: 4, iter: 1800, curr loss: 1.3859899044036865, avg loss: 1.3864331656694413\n",
      "trial: 4, iter: 2000, curr loss: 1.3871312141418457, avg loss: 1.3864070373773574\n",
      "trial: 4, iter: 2200, curr loss: 1.3865171670913696, avg loss: 1.3863140988349913\n",
      "trial: 4, iter: 2400, curr loss: 1.385328769683838, avg loss: 1.3863864892721176\n",
      "trial: 4, iter: 2600, curr loss: 1.3861513137817383, avg loss: 1.3863199079036712\n",
      "trial: 4, iter: 2800, curr loss: 1.3858742713928223, avg loss: 1.3863717859983444\n",
      "trial: 4, iter: 3000, curr loss: 1.3857711553573608, avg loss: 1.3863527888059617\n",
      "trial: 4, iter: 3200, curr loss: 1.3863976001739502, avg loss: 1.3863415509462356\n",
      "trial: 4, iter: 3400, curr loss: 1.3856257200241089, avg loss: 1.38630888402462\n",
      "trial: 4, iter: 3600, curr loss: 1.3855555057525635, avg loss: 1.3863565576076509\n",
      "trial: 4, iter: 3800, curr loss: 1.386365532875061, avg loss: 1.3863531881570816\n",
      "trial: 4, iter: 4000, curr loss: 1.3860584497451782, avg loss: 1.3862916922569275\n",
      "trial: 4, iter: 4200, curr loss: 1.385486125946045, avg loss: 1.386308326125145\n",
      "trial: 4, iter: 4400, curr loss: 1.3865883350372314, avg loss: 1.3863308054208756\n",
      "trial: 4, iter: 4600, curr loss: 1.386346459388733, avg loss: 1.3863392901420593\n",
      "trial: 4, iter: 4800, curr loss: 1.3866093158721924, avg loss: 1.3862751460075378\n",
      "trial: 4, iter: 5000, curr loss: 1.3869578838348389, avg loss: 1.3863017946481704\n",
      "trial: 4, iter: 5200, curr loss: 1.3862031698226929, avg loss: 1.3863244533538819\n",
      "trial: 4, iter: 5400, curr loss: 1.386084794998169, avg loss: 1.3863128250837327\n",
      "trial: 4, iter: 5600, curr loss: 1.3864994049072266, avg loss: 1.3862980192899703\n",
      "trial: 4, iter: 5800, curr loss: 1.3860856294631958, avg loss: 1.3863178032636643\n",
      "trial: 4, iter: 6000, curr loss: 1.3860946893692017, avg loss: 1.3863043332099914\n",
      "trial: 4, iter: 6200, curr loss: 1.385463833808899, avg loss: 1.3863054209947585\n",
      "trial: 4, ldr: -7.158090738812461e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3885701894760132, avg loss: 1.3874427884817124\n",
      "trial: 5, iter: 400, curr loss: 1.3873004913330078, avg loss: 1.386791759133339\n",
      "trial: 5, iter: 600, curr loss: 1.389149785041809, avg loss: 1.3866782128810882\n",
      "trial: 5, iter: 800, curr loss: 1.3882074356079102, avg loss: 1.386543465256691\n",
      "trial: 5, iter: 1000, curr loss: 1.3864229917526245, avg loss: 1.386644719839096\n",
      "trial: 5, iter: 1200, curr loss: 1.3867419958114624, avg loss: 1.386440277695656\n",
      "trial: 5, iter: 1400, curr loss: 1.3855817317962646, avg loss: 1.3865403831005096\n",
      "trial: 5, iter: 1600, curr loss: 1.3866339921951294, avg loss: 1.3865317636728287\n",
      "trial: 5, iter: 1800, curr loss: 1.3863065242767334, avg loss: 1.3864247649908066\n",
      "trial: 5, iter: 2000, curr loss: 1.3848797082901, avg loss: 1.3863482093811035\n",
      "trial: 5, iter: 2200, curr loss: 1.3855186700820923, avg loss: 1.386364563703537\n",
      "trial: 5, iter: 2400, curr loss: 1.3859522342681885, avg loss: 1.3863926297426223\n",
      "trial: 5, iter: 2600, curr loss: 1.385451078414917, avg loss: 1.3863325363397598\n",
      "trial: 5, iter: 2800, curr loss: 1.3860704898834229, avg loss: 1.3863007366657256\n",
      "trial: 5, iter: 3000, curr loss: 1.3863611221313477, avg loss: 1.386344747543335\n",
      "trial: 5, iter: 3200, curr loss: 1.3867911100387573, avg loss: 1.3862963044643402\n",
      "trial: 5, iter: 3400, curr loss: 1.386700987815857, avg loss: 1.3863914787769318\n",
      "trial: 5, iter: 3600, curr loss: 1.385301947593689, avg loss: 1.386308404803276\n",
      "trial: 5, iter: 3800, curr loss: 1.3874861001968384, avg loss: 1.386309170126915\n",
      "trial: 5, iter: 4000, curr loss: 1.385770559310913, avg loss: 1.3862378233671189\n",
      "trial: 5, iter: 4200, curr loss: 1.3846347332000732, avg loss: 1.3862848407030106\n",
      "trial: 5, iter: 4400, curr loss: 1.385033130645752, avg loss: 1.3863163816928863\n",
      "trial: 5, iter: 4600, curr loss: 1.3860251903533936, avg loss: 1.3863475376367569\n",
      "trial: 5, iter: 4800, curr loss: 1.3859057426452637, avg loss: 1.3863020342588426\n",
      "trial: 5, iter: 5000, curr loss: 1.3854494094848633, avg loss: 1.3863340240716935\n",
      "trial: 5, iter: 5200, curr loss: 1.3871408700942993, avg loss: 1.3863117253780366\n",
      "trial: 5, iter: 5400, curr loss: 1.3853470087051392, avg loss: 1.3862207406759262\n",
      "trial: 5, iter: 5600, curr loss: 1.3868768215179443, avg loss: 1.3861969375610352\n",
      "trial: 5, iter: 5800, curr loss: 1.3864129781723022, avg loss: 1.3861825948953628\n",
      "trial: 5, iter: 6000, curr loss: 1.3872017860412598, avg loss: 1.3861316591501236\n",
      "trial: 5, iter: 6200, curr loss: 1.3858312368392944, avg loss: 1.3859799528121948\n",
      "trial: 5, ldr: 0.002795520471408963\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0025037513885763476\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3881832361221313, avg loss: 1.3874729406833648\n",
      "trial: 1, iter: 400, curr loss: 1.3851879835128784, avg loss: 1.3868315511941909\n",
      "trial: 1, iter: 600, curr loss: 1.3883514404296875, avg loss: 1.3867750644683838\n",
      "trial: 1, iter: 800, curr loss: 1.3878262042999268, avg loss: 1.3866550046205521\n",
      "trial: 1, iter: 1000, curr loss: 1.3826829195022583, avg loss: 1.3864922440052032\n",
      "trial: 1, iter: 1200, curr loss: 1.386320948600769, avg loss: 1.386503655910492\n",
      "trial: 1, iter: 1400, curr loss: 1.3877640962600708, avg loss: 1.3863384503126144\n",
      "trial: 1, iter: 1600, curr loss: 1.3854148387908936, avg loss: 1.3864224994182586\n",
      "trial: 1, iter: 1800, curr loss: 1.3881633281707764, avg loss: 1.3862836706638335\n",
      "trial: 1, iter: 2000, curr loss: 1.3865679502487183, avg loss: 1.3862453591823578\n",
      "trial: 1, iter: 2200, curr loss: 1.3852583169937134, avg loss: 1.386370045542717\n",
      "trial: 1, iter: 2400, curr loss: 1.387234091758728, avg loss: 1.3862735271453857\n",
      "trial: 1, iter: 2600, curr loss: 1.3881949186325073, avg loss: 1.386297715306282\n",
      "trial: 1, iter: 2800, curr loss: 1.3858156204223633, avg loss: 1.3861623388528823\n",
      "trial: 1, iter: 3000, curr loss: 1.384813904762268, avg loss: 1.386170396208763\n",
      "trial: 1, iter: 3200, curr loss: 1.386176347732544, avg loss: 1.3861047679185867\n",
      "trial: 1, iter: 3400, curr loss: 1.3863157033920288, avg loss: 1.3860106289386749\n",
      "trial: 1, iter: 3600, curr loss: 1.384822964668274, avg loss: 1.386093772649765\n",
      "trial: 1, iter: 3800, curr loss: 1.3865408897399902, avg loss: 1.3857694083452226\n",
      "trial: 1, iter: 4000, curr loss: 1.3841224908828735, avg loss: 1.3857534325122833\n",
      "trial: 1, iter: 4200, curr loss: 1.385814905166626, avg loss: 1.385286729335785\n",
      "trial: 1, iter: 4400, curr loss: 1.3823840618133545, avg loss: 1.385176987051964\n",
      "trial: 1, iter: 4600, curr loss: 1.3889449834823608, avg loss: 1.3848014014959336\n",
      "trial: 1, iter: 4800, curr loss: 1.3846559524536133, avg loss: 1.3838120520114898\n",
      "trial: 1, iter: 5000, curr loss: 1.3828349113464355, avg loss: 1.3829166913032531\n",
      "trial: 1, iter: 5200, curr loss: 1.3824999332427979, avg loss: 1.382153241634369\n",
      "trial: 1, iter: 5400, curr loss: 1.3746470212936401, avg loss: 1.3802982807159423\n",
      "trial: 1, iter: 5600, curr loss: 1.3753502368927002, avg loss: 1.3780404388904572\n",
      "trial: 1, iter: 5800, curr loss: 1.3781341314315796, avg loss: 1.3782645279169083\n",
      "trial: 1, iter: 6000, curr loss: 1.3731186389923096, avg loss: 1.3757987624406816\n",
      "trial: 1, iter: 6200, curr loss: 1.3747795820236206, avg loss: 1.3741887104511261\n",
      "trial: 1, ldr: -0.010390082374215126\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3898628950119019, avg loss: 1.3871375453472137\n",
      "trial: 2, iter: 400, curr loss: 1.3849260807037354, avg loss: 1.3868557125329972\n",
      "trial: 2, iter: 600, curr loss: 1.3877815008163452, avg loss: 1.3865908843278885\n",
      "trial: 2, iter: 800, curr loss: 1.3875043392181396, avg loss: 1.3864410072565079\n",
      "trial: 2, iter: 1000, curr loss: 1.3852112293243408, avg loss: 1.3864870631694795\n",
      "trial: 2, iter: 1200, curr loss: 1.3854609727859497, avg loss: 1.386424406170845\n",
      "trial: 2, iter: 1400, curr loss: 1.3860011100769043, avg loss: 1.3863050192594528\n",
      "trial: 2, iter: 1600, curr loss: 1.3867697715759277, avg loss: 1.3864089167118072\n",
      "trial: 2, iter: 1800, curr loss: 1.3856390714645386, avg loss: 1.3864173597097398\n",
      "trial: 2, iter: 2000, curr loss: 1.386573076248169, avg loss: 1.3863025498390198\n",
      "trial: 2, iter: 2200, curr loss: 1.386471152305603, avg loss: 1.3863147097826003\n",
      "trial: 2, iter: 2400, curr loss: 1.3864926099777222, avg loss: 1.386334903240204\n",
      "trial: 2, iter: 2600, curr loss: 1.3875970840454102, avg loss: 1.3864045149087907\n",
      "trial: 2, iter: 2800, curr loss: 1.3869341611862183, avg loss: 1.386311287879944\n",
      "trial: 2, iter: 3000, curr loss: 1.3827627897262573, avg loss: 1.3863086825609208\n",
      "trial: 2, iter: 3200, curr loss: 1.3861333131790161, avg loss: 1.3863616812229156\n",
      "trial: 2, iter: 3400, curr loss: 1.3860751390457153, avg loss: 1.3863593357801438\n",
      "trial: 2, iter: 3600, curr loss: 1.3873786926269531, avg loss: 1.386252498626709\n",
      "trial: 2, iter: 3800, curr loss: 1.3852782249450684, avg loss: 1.386203407049179\n",
      "trial: 2, iter: 4000, curr loss: 1.3854475021362305, avg loss: 1.3861323654651643\n",
      "trial: 2, iter: 4200, curr loss: 1.385534644126892, avg loss: 1.3861074542999268\n",
      "trial: 2, iter: 4400, curr loss: 1.3867840766906738, avg loss: 1.3859302181005477\n",
      "trial: 2, iter: 4600, curr loss: 1.3851646184921265, avg loss: 1.3859382438659669\n",
      "trial: 2, iter: 4800, curr loss: 1.3859007358551025, avg loss: 1.3857465368509292\n",
      "trial: 2, iter: 5000, curr loss: 1.3856291770935059, avg loss: 1.385252633690834\n",
      "trial: 2, iter: 5200, curr loss: 1.3840014934539795, avg loss: 1.3849547731876373\n",
      "trial: 2, iter: 5400, curr loss: 1.3804916143417358, avg loss: 1.3845400786399842\n",
      "trial: 2, iter: 5600, curr loss: 1.3811882734298706, avg loss: 1.3835636550188064\n",
      "trial: 2, iter: 5800, curr loss: 1.3781459331512451, avg loss: 1.3828928381204606\n",
      "trial: 2, iter: 6000, curr loss: 1.3798424005508423, avg loss: 1.3812138617038727\n",
      "trial: 2, iter: 6200, curr loss: 1.3825348615646362, avg loss: 1.3804702371358872\n",
      "trial: 2, ldr: -0.0009373045177198946\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3894115686416626, avg loss: 1.3872539240121842\n",
      "trial: 3, iter: 400, curr loss: 1.3860877752304077, avg loss: 1.386811997294426\n",
      "trial: 3, iter: 600, curr loss: 1.3862632513046265, avg loss: 1.386747595667839\n",
      "trial: 3, iter: 800, curr loss: 1.385849952697754, avg loss: 1.3865943306684494\n",
      "trial: 3, iter: 1000, curr loss: 1.3875892162322998, avg loss: 1.3866640144586564\n",
      "trial: 3, iter: 1200, curr loss: 1.3864411115646362, avg loss: 1.3864365333318711\n",
      "trial: 3, iter: 1400, curr loss: 1.3873772621154785, avg loss: 1.3863436782360077\n",
      "trial: 3, iter: 1600, curr loss: 1.3851666450500488, avg loss: 1.386419660449028\n",
      "trial: 3, iter: 1800, curr loss: 1.387454628944397, avg loss: 1.3864316815137863\n",
      "trial: 3, iter: 2000, curr loss: 1.386734127998352, avg loss: 1.3864112210273742\n",
      "trial: 3, iter: 2200, curr loss: 1.3852758407592773, avg loss: 1.3862675094604493\n",
      "trial: 3, iter: 2400, curr loss: 1.387772560119629, avg loss: 1.3863385510444641\n",
      "trial: 3, iter: 2600, curr loss: 1.3864381313323975, avg loss: 1.386331906914711\n",
      "trial: 3, iter: 2800, curr loss: 1.385512351989746, avg loss: 1.3862864714860916\n",
      "trial: 3, iter: 3000, curr loss: 1.3864049911499023, avg loss: 1.3862321132421493\n",
      "trial: 3, iter: 3200, curr loss: 1.387548804283142, avg loss: 1.3863185101747513\n",
      "trial: 3, iter: 3400, curr loss: 1.386044979095459, avg loss: 1.3862021893262864\n",
      "trial: 3, iter: 3600, curr loss: 1.3862823247909546, avg loss: 1.3861463183164597\n",
      "trial: 3, iter: 3800, curr loss: 1.3875638246536255, avg loss: 1.3861007189750671\n",
      "trial: 3, iter: 4000, curr loss: 1.3862136602401733, avg loss: 1.3859321808815002\n",
      "trial: 3, iter: 4200, curr loss: 1.3834850788116455, avg loss: 1.3859434139728546\n",
      "trial: 3, iter: 4400, curr loss: 1.3860875368118286, avg loss: 1.385539910197258\n",
      "trial: 3, iter: 4600, curr loss: 1.3914023637771606, avg loss: 1.3852756863832474\n",
      "trial: 3, iter: 4800, curr loss: 1.3842370510101318, avg loss: 1.384621250629425\n",
      "trial: 3, iter: 5000, curr loss: 1.3811166286468506, avg loss: 1.3838798892498017\n",
      "trial: 3, iter: 5200, curr loss: 1.384116530418396, avg loss: 1.3828561145067215\n",
      "trial: 3, iter: 5400, curr loss: 1.3819459676742554, avg loss: 1.381761958003044\n",
      "trial: 3, iter: 5600, curr loss: 1.3784925937652588, avg loss: 1.3801136004924774\n",
      "trial: 3, iter: 5800, curr loss: 1.384023666381836, avg loss: 1.3788654905557634\n",
      "trial: 3, iter: 6000, curr loss: 1.3729569911956787, avg loss: 1.3770248430967331\n",
      "trial: 3, iter: 6200, curr loss: 1.378838062286377, avg loss: 1.3749370753765107\n",
      "trial: 3, ldr: 0.018914008513092995\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.387436866760254, avg loss: 1.3873542320728303\n",
      "trial: 4, iter: 400, curr loss: 1.3882100582122803, avg loss: 1.3867458575963973\n",
      "trial: 4, iter: 600, curr loss: 1.3842391967773438, avg loss: 1.3866296869516372\n",
      "trial: 4, iter: 800, curr loss: 1.3880823850631714, avg loss: 1.3865023851394653\n",
      "trial: 4, iter: 1000, curr loss: 1.3865004777908325, avg loss: 1.3865014630556107\n",
      "trial: 4, iter: 1200, curr loss: 1.385890007019043, avg loss: 1.3865106534957885\n",
      "trial: 4, iter: 1400, curr loss: 1.3854137659072876, avg loss: 1.3864668661355972\n",
      "trial: 4, iter: 1600, curr loss: 1.3872158527374268, avg loss: 1.3863946187496186\n",
      "trial: 4, iter: 1800, curr loss: 1.3869718313217163, avg loss: 1.3864063149690629\n",
      "trial: 4, iter: 2000, curr loss: 1.3868234157562256, avg loss: 1.386284795999527\n",
      "trial: 4, iter: 2200, curr loss: 1.385811686515808, avg loss: 1.386346926689148\n",
      "trial: 4, iter: 2400, curr loss: 1.3859047889709473, avg loss: 1.3863504815101624\n",
      "trial: 4, iter: 2600, curr loss: 1.3868680000305176, avg loss: 1.3862250888347625\n",
      "trial: 4, iter: 2800, curr loss: 1.3860105276107788, avg loss: 1.386189604997635\n",
      "trial: 4, iter: 3000, curr loss: 1.3863937854766846, avg loss: 1.386041049361229\n",
      "trial: 4, iter: 3200, curr loss: 1.385780930519104, avg loss: 1.3861428171396255\n",
      "trial: 4, iter: 3400, curr loss: 1.3846412897109985, avg loss: 1.3860026931762695\n",
      "trial: 4, iter: 3600, curr loss: 1.3897372484207153, avg loss: 1.3858464795351029\n",
      "trial: 4, iter: 3800, curr loss: 1.3858330249786377, avg loss: 1.3854742109775544\n",
      "trial: 4, iter: 4000, curr loss: 1.3830105066299438, avg loss: 1.3851766961812972\n",
      "trial: 4, iter: 4200, curr loss: 1.386655330657959, avg loss: 1.3849880796670915\n",
      "trial: 4, iter: 4400, curr loss: 1.3864434957504272, avg loss: 1.383956687450409\n",
      "trial: 4, iter: 4600, curr loss: 1.3810744285583496, avg loss: 1.3833745563030242\n",
      "trial: 4, iter: 4800, curr loss: 1.375927209854126, avg loss: 1.381929263472557\n",
      "trial: 4, iter: 5000, curr loss: 1.375959038734436, avg loss: 1.3809619450569153\n",
      "trial: 4, iter: 5200, curr loss: 1.3727065324783325, avg loss: 1.3786311227083206\n",
      "trial: 4, iter: 5400, curr loss: 1.3818140029907227, avg loss: 1.3775267535448075\n",
      "trial: 4, iter: 5600, curr loss: 1.373642086982727, avg loss: 1.3756529688835144\n",
      "trial: 4, iter: 5800, curr loss: 1.369026780128479, avg loss: 1.3749761688709259\n",
      "trial: 4, iter: 6000, curr loss: 1.3746461868286133, avg loss: 1.3722328758239746\n",
      "trial: 4, iter: 6200, curr loss: 1.3671964406967163, avg loss: 1.37120765209198\n",
      "trial: 4, ldr: -0.0010941785294562578\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882404565811157, avg loss: 1.3874955314397812\n",
      "trial: 5, iter: 400, curr loss: 1.3875203132629395, avg loss: 1.3867636984586715\n",
      "trial: 5, iter: 600, curr loss: 1.3865506649017334, avg loss: 1.3865771782398224\n",
      "trial: 5, iter: 800, curr loss: 1.3863261938095093, avg loss: 1.3866317349672317\n",
      "trial: 5, iter: 1000, curr loss: 1.387245774269104, avg loss: 1.3863938218355178\n",
      "trial: 5, iter: 1200, curr loss: 1.3870903253555298, avg loss: 1.3864246410131456\n",
      "trial: 5, iter: 1400, curr loss: 1.3877966403961182, avg loss: 1.3863322204351425\n",
      "trial: 5, iter: 1600, curr loss: 1.3875082731246948, avg loss: 1.3864148223400117\n",
      "trial: 5, iter: 1800, curr loss: 1.386540412902832, avg loss: 1.386298548579216\n",
      "trial: 5, iter: 2000, curr loss: 1.3855667114257812, avg loss: 1.3863771057128906\n",
      "trial: 5, iter: 2200, curr loss: 1.3860697746276855, avg loss: 1.386363589167595\n",
      "trial: 5, iter: 2400, curr loss: 1.3872047662734985, avg loss: 1.3862987571954728\n",
      "trial: 5, iter: 2600, curr loss: 1.386716604232788, avg loss: 1.386358110308647\n",
      "trial: 5, iter: 2800, curr loss: 1.3867526054382324, avg loss: 1.3862547385692596\n",
      "trial: 5, iter: 3000, curr loss: 1.386168122291565, avg loss: 1.3862345200777053\n",
      "trial: 5, iter: 3200, curr loss: 1.3861720561981201, avg loss: 1.3861602979898453\n",
      "trial: 5, iter: 3400, curr loss: 1.3864578008651733, avg loss: 1.3860683923959731\n",
      "trial: 5, iter: 3600, curr loss: 1.3851721286773682, avg loss: 1.3859132218360901\n",
      "trial: 5, iter: 3800, curr loss: 1.3855843544006348, avg loss: 1.3856691169738768\n",
      "trial: 5, iter: 4000, curr loss: 1.3830723762512207, avg loss: 1.3854341721534729\n",
      "trial: 5, iter: 4200, curr loss: 1.378973364830017, avg loss: 1.3846272659301757\n",
      "trial: 5, iter: 4400, curr loss: 1.3825980424880981, avg loss: 1.3836638230085372\n",
      "trial: 5, iter: 4600, curr loss: 1.3822481632232666, avg loss: 1.3830492389202118\n",
      "trial: 5, iter: 4800, curr loss: 1.3781585693359375, avg loss: 1.3810467386245728\n",
      "trial: 5, iter: 5000, curr loss: 1.3860197067260742, avg loss: 1.3800192666053772\n",
      "trial: 5, iter: 5200, curr loss: 1.380755066871643, avg loss: 1.379463590979576\n",
      "trial: 5, iter: 5400, curr loss: 1.3812744617462158, avg loss: 1.3780170917510985\n",
      "trial: 5, iter: 5600, curr loss: 1.379410743713379, avg loss: 1.376595486998558\n",
      "trial: 5, iter: 5800, curr loss: 1.3632335662841797, avg loss: 1.3748108106851578\n",
      "trial: 5, iter: 6000, curr loss: 1.3749096393585205, avg loss: 1.3737273126840592\n",
      "trial: 5, iter: 6200, curr loss: 1.369327187538147, avg loss: 1.372013245820999\n",
      "trial: 5, ldr: -0.001161272986792028\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0010662340209819376\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862817287445068, avg loss: 1.387039394378662\n",
      "trial: 1, iter: 400, curr loss: 1.3886237144470215, avg loss: 1.386650212407112\n",
      "trial: 1, iter: 600, curr loss: 1.3877923488616943, avg loss: 1.3865076756477357\n",
      "trial: 1, iter: 800, curr loss: 1.3859827518463135, avg loss: 1.3865307939052582\n",
      "trial: 1, iter: 1000, curr loss: 1.3864562511444092, avg loss: 1.3865243351459504\n",
      "trial: 1, iter: 1200, curr loss: 1.3855305910110474, avg loss: 1.3864600253105164\n",
      "trial: 1, iter: 1400, curr loss: 1.3856902122497559, avg loss: 1.3864165782928466\n",
      "trial: 1, iter: 1600, curr loss: 1.3860851526260376, avg loss: 1.3863529378175736\n",
      "trial: 1, iter: 1800, curr loss: 1.3865896463394165, avg loss: 1.3863683480024338\n",
      "trial: 1, iter: 2000, curr loss: 1.3868907690048218, avg loss: 1.3862347906827928\n",
      "trial: 1, iter: 2200, curr loss: 1.3867967128753662, avg loss: 1.3863313072919845\n",
      "trial: 1, iter: 2400, curr loss: 1.3855825662612915, avg loss: 1.3861921638250352\n",
      "trial: 1, iter: 2600, curr loss: 1.3858834505081177, avg loss: 1.386240366101265\n",
      "trial: 1, iter: 2800, curr loss: 1.388329029083252, avg loss: 1.3861593717336655\n",
      "trial: 1, iter: 3000, curr loss: 1.3860037326812744, avg loss: 1.3860560929775239\n",
      "trial: 1, iter: 3200, curr loss: 1.3849329948425293, avg loss: 1.385762939453125\n",
      "trial: 1, iter: 3400, curr loss: 1.385164737701416, avg loss: 1.3855634236335754\n",
      "trial: 1, iter: 3600, curr loss: 1.3859717845916748, avg loss: 1.3856348812580108\n",
      "trial: 1, iter: 3800, curr loss: 1.3832281827926636, avg loss: 1.3845867800712586\n",
      "trial: 1, iter: 4000, curr loss: 1.382792353630066, avg loss: 1.3841368550062179\n",
      "trial: 1, iter: 4200, curr loss: 1.3847018480300903, avg loss: 1.3834397399425507\n",
      "trial: 1, iter: 4400, curr loss: 1.3765603303909302, avg loss: 1.3822115778923034\n",
      "trial: 1, iter: 4600, curr loss: 1.3846286535263062, avg loss: 1.381388214826584\n",
      "trial: 1, iter: 4800, curr loss: 1.3674076795578003, avg loss: 1.3799196362495423\n",
      "trial: 1, iter: 5000, curr loss: 1.382326364517212, avg loss: 1.3784470748901367\n",
      "trial: 1, iter: 5200, curr loss: 1.3679195642471313, avg loss: 1.3768950337171555\n",
      "trial: 1, iter: 5400, curr loss: 1.3760203123092651, avg loss: 1.3744384855031968\n",
      "trial: 1, iter: 5600, curr loss: 1.37847101688385, avg loss: 1.3714557403326035\n",
      "trial: 1, iter: 5800, curr loss: 1.3664668798446655, avg loss: 1.3701933670043944\n",
      "trial: 1, iter: 6000, curr loss: 1.3766615390777588, avg loss: 1.3677664393186568\n",
      "trial: 1, iter: 6200, curr loss: 1.3394699096679688, avg loss: 1.36493223965168\n",
      "trial: 1, ldr: 0.001500417711213231\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863327503204346, avg loss: 1.3872222471237183\n",
      "trial: 2, iter: 400, curr loss: 1.3845479488372803, avg loss: 1.3868282043933868\n",
      "trial: 2, iter: 600, curr loss: 1.3874258995056152, avg loss: 1.3864934766292571\n",
      "trial: 2, iter: 800, curr loss: 1.3870571851730347, avg loss: 1.3865194004774093\n",
      "trial: 2, iter: 1000, curr loss: 1.386613130569458, avg loss: 1.3864652037620544\n",
      "trial: 2, iter: 1200, curr loss: 1.3862698078155518, avg loss: 1.386310449242592\n",
      "trial: 2, iter: 1400, curr loss: 1.3864635229110718, avg loss: 1.3864008074998855\n",
      "trial: 2, iter: 1600, curr loss: 1.3871525526046753, avg loss: 1.386346659064293\n",
      "trial: 2, iter: 1800, curr loss: 1.3873025178909302, avg loss: 1.3863608986139297\n",
      "trial: 2, iter: 2000, curr loss: 1.3870668411254883, avg loss: 1.3864140683412551\n",
      "trial: 2, iter: 2200, curr loss: 1.3865082263946533, avg loss: 1.3863011354207992\n",
      "trial: 2, iter: 2400, curr loss: 1.384956955909729, avg loss: 1.3862899243831635\n",
      "trial: 2, iter: 2600, curr loss: 1.3867974281311035, avg loss: 1.3863235396146774\n",
      "trial: 2, iter: 2800, curr loss: 1.386081576347351, avg loss: 1.3863150078058242\n",
      "trial: 2, iter: 3000, curr loss: 1.3846220970153809, avg loss: 1.3863410449028015\n",
      "trial: 2, iter: 3200, curr loss: 1.385271430015564, avg loss: 1.3862750178575516\n",
      "trial: 2, iter: 3400, curr loss: 1.3861850500106812, avg loss: 1.3863839024305344\n",
      "trial: 2, iter: 3600, curr loss: 1.3854176998138428, avg loss: 1.3862541180849075\n",
      "trial: 2, iter: 3800, curr loss: 1.387292504310608, avg loss: 1.3863347560167312\n",
      "trial: 2, iter: 4000, curr loss: 1.3852211236953735, avg loss: 1.3861865550279617\n",
      "trial: 2, iter: 4200, curr loss: 1.3855454921722412, avg loss: 1.3862976729869843\n",
      "trial: 2, iter: 4400, curr loss: 1.3854713439941406, avg loss: 1.3863236433267594\n",
      "trial: 2, iter: 4600, curr loss: 1.3865550756454468, avg loss: 1.3862394666671753\n",
      "trial: 2, iter: 4800, curr loss: 1.3859050273895264, avg loss: 1.3861949491500853\n",
      "trial: 2, iter: 5000, curr loss: 1.3866208791732788, avg loss: 1.3862408941984177\n",
      "trial: 2, iter: 5200, curr loss: 1.3860877752304077, avg loss: 1.3861061680316924\n",
      "trial: 2, iter: 5400, curr loss: 1.3830586671829224, avg loss: 1.3860169386863708\n",
      "trial: 2, iter: 5600, curr loss: 1.3865892887115479, avg loss: 1.3858000117540359\n",
      "trial: 2, iter: 5800, curr loss: 1.3825827836990356, avg loss: 1.385579172372818\n",
      "trial: 2, iter: 6000, curr loss: 1.3865902423858643, avg loss: 1.3850885939598083\n",
      "trial: 2, iter: 6200, curr loss: 1.3840718269348145, avg loss: 1.3844014239311218\n",
      "trial: 2, ldr: -0.018816431984305382\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389525055885315, avg loss: 1.3873947203159331\n",
      "trial: 3, iter: 400, curr loss: 1.3858903646469116, avg loss: 1.3867124342918395\n",
      "trial: 3, iter: 600, curr loss: 1.3876444101333618, avg loss: 1.3865296232700348\n",
      "trial: 3, iter: 800, curr loss: 1.3876242637634277, avg loss: 1.3865865993499755\n",
      "trial: 3, iter: 1000, curr loss: 1.3878579139709473, avg loss: 1.3863434267044068\n",
      "trial: 3, iter: 1200, curr loss: 1.3862955570220947, avg loss: 1.386284938454628\n",
      "trial: 3, iter: 1400, curr loss: 1.3871983289718628, avg loss: 1.38645339012146\n",
      "trial: 3, iter: 1600, curr loss: 1.3858134746551514, avg loss: 1.3863311332464219\n",
      "trial: 3, iter: 1800, curr loss: 1.3857675790786743, avg loss: 1.3864011245965957\n",
      "trial: 3, iter: 2000, curr loss: 1.385836124420166, avg loss: 1.3863256943225861\n",
      "trial: 3, iter: 2200, curr loss: 1.3845816850662231, avg loss: 1.3862608361244202\n",
      "trial: 3, iter: 2400, curr loss: 1.3857871294021606, avg loss: 1.3864033913612366\n",
      "trial: 3, iter: 2600, curr loss: 1.3858834505081177, avg loss: 1.386241859793663\n",
      "trial: 3, iter: 2800, curr loss: 1.385418176651001, avg loss: 1.3862274366617202\n",
      "trial: 3, iter: 3000, curr loss: 1.3838802576065063, avg loss: 1.3863432395458222\n",
      "trial: 3, iter: 3200, curr loss: 1.3846668004989624, avg loss: 1.3862789154052735\n",
      "trial: 3, iter: 3400, curr loss: 1.386552095413208, avg loss: 1.386168577671051\n",
      "trial: 3, iter: 3600, curr loss: 1.385825276374817, avg loss: 1.3859764313697815\n",
      "trial: 3, iter: 3800, curr loss: 1.3838077783584595, avg loss: 1.3859579521417618\n",
      "trial: 3, iter: 4000, curr loss: 1.3853273391723633, avg loss: 1.385766687989235\n",
      "trial: 3, iter: 4200, curr loss: 1.3852003812789917, avg loss: 1.3855328840017318\n",
      "trial: 3, iter: 4400, curr loss: 1.3851494789123535, avg loss: 1.3852107864618302\n",
      "trial: 3, iter: 4600, curr loss: 1.38377845287323, avg loss: 1.3848415392637252\n",
      "trial: 3, iter: 4800, curr loss: 1.3852496147155762, avg loss: 1.3836882185935975\n",
      "trial: 3, iter: 5000, curr loss: 1.3759247064590454, avg loss: 1.3822979366779327\n",
      "trial: 3, iter: 5200, curr loss: 1.3775455951690674, avg loss: 1.3813573253154754\n",
      "trial: 3, iter: 5400, curr loss: 1.3861351013183594, avg loss: 1.3789085531234742\n",
      "trial: 3, iter: 5600, curr loss: 1.373969316482544, avg loss: 1.3786221170425415\n",
      "trial: 3, iter: 5800, curr loss: 1.3660653829574585, avg loss: 1.3761547261476517\n",
      "trial: 3, iter: 6000, curr loss: 1.36899995803833, avg loss: 1.3730754524469375\n",
      "trial: 3, iter: 6200, curr loss: 1.3762285709381104, avg loss: 1.3713511550426483\n",
      "trial: 3, ldr: 0.0037274311762303114\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3861656188964844, avg loss: 1.387118712067604\n",
      "trial: 4, iter: 400, curr loss: 1.3883253335952759, avg loss: 1.3868225979804993\n",
      "trial: 4, iter: 600, curr loss: 1.3872594833374023, avg loss: 1.3865207153558732\n",
      "trial: 4, iter: 800, curr loss: 1.3870903253555298, avg loss: 1.3864496070146561\n",
      "trial: 4, iter: 1000, curr loss: 1.386073112487793, avg loss: 1.3864437466859818\n",
      "trial: 4, iter: 1200, curr loss: 1.3856736421585083, avg loss: 1.3864238739013672\n",
      "trial: 4, iter: 1400, curr loss: 1.3856818675994873, avg loss: 1.3863687026500702\n",
      "trial: 4, iter: 1600, curr loss: 1.3848003149032593, avg loss: 1.3863417547941208\n",
      "trial: 4, iter: 1800, curr loss: 1.387358546257019, avg loss: 1.3864203900098802\n",
      "trial: 4, iter: 2000, curr loss: 1.3861849308013916, avg loss: 1.3863861775398254\n",
      "trial: 4, iter: 2200, curr loss: 1.3839573860168457, avg loss: 1.3862588125467301\n",
      "trial: 4, iter: 2400, curr loss: 1.3863525390625, avg loss: 1.3863970637321472\n",
      "trial: 4, iter: 2600, curr loss: 1.3867709636688232, avg loss: 1.386355727314949\n",
      "trial: 4, iter: 2800, curr loss: 1.3867056369781494, avg loss: 1.3863215500116348\n",
      "trial: 4, iter: 3000, curr loss: 1.3878220319747925, avg loss: 1.3862075114250183\n",
      "trial: 4, iter: 3200, curr loss: 1.3864779472351074, avg loss: 1.3863176929950713\n",
      "trial: 4, iter: 3400, curr loss: 1.3873533010482788, avg loss: 1.3863168472051621\n",
      "trial: 4, iter: 3600, curr loss: 1.3868770599365234, avg loss: 1.3861622893810273\n",
      "trial: 4, iter: 3800, curr loss: 1.3858437538146973, avg loss: 1.3862233191728592\n",
      "trial: 4, iter: 4000, curr loss: 1.3879339694976807, avg loss: 1.3861222034692764\n",
      "trial: 4, iter: 4200, curr loss: 1.3846746683120728, avg loss: 1.385930166244507\n",
      "trial: 4, iter: 4400, curr loss: 1.3868770599365234, avg loss: 1.385921516418457\n",
      "trial: 4, iter: 4600, curr loss: 1.3871309757232666, avg loss: 1.3856719899177552\n",
      "trial: 4, iter: 4800, curr loss: 1.3855161666870117, avg loss: 1.3852851289510726\n",
      "trial: 4, iter: 5000, curr loss: 1.387175440788269, avg loss: 1.3849486643075943\n",
      "trial: 4, iter: 5200, curr loss: 1.3839322328567505, avg loss: 1.38442755818367\n",
      "trial: 4, iter: 5400, curr loss: 1.3810514211654663, avg loss: 1.3834618949890136\n",
      "trial: 4, iter: 5600, curr loss: 1.3788217306137085, avg loss: 1.382613586783409\n",
      "trial: 4, iter: 5800, curr loss: 1.3861026763916016, avg loss: 1.381157094836235\n",
      "trial: 4, iter: 6000, curr loss: 1.382964849472046, avg loss: 1.3795920288562775\n",
      "trial: 4, iter: 6200, curr loss: 1.390280842781067, avg loss: 1.3776244187355042\n",
      "trial: 4, ldr: -0.006053376477211714\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3918606042861938, avg loss: 1.3878554147481919\n",
      "trial: 5, iter: 400, curr loss: 1.3873487710952759, avg loss: 1.3868528521060943\n",
      "trial: 5, iter: 600, curr loss: 1.3811225891113281, avg loss: 1.3867795640230178\n",
      "trial: 5, iter: 800, curr loss: 1.3877705335617065, avg loss: 1.3867154628038407\n",
      "trial: 5, iter: 1000, curr loss: 1.3839858770370483, avg loss: 1.3866038644313812\n",
      "trial: 5, iter: 1200, curr loss: 1.3875144720077515, avg loss: 1.3865722477436067\n",
      "trial: 5, iter: 1400, curr loss: 1.3867766857147217, avg loss: 1.3864531028270721\n",
      "trial: 5, iter: 1600, curr loss: 1.3852953910827637, avg loss: 1.38648994743824\n",
      "trial: 5, iter: 1800, curr loss: 1.388424277305603, avg loss: 1.3863722229003905\n",
      "trial: 5, iter: 2000, curr loss: 1.3878334760665894, avg loss: 1.3863642567396164\n",
      "trial: 5, iter: 2200, curr loss: 1.3887265920639038, avg loss: 1.3864370340108871\n",
      "trial: 5, iter: 2400, curr loss: 1.3862813711166382, avg loss: 1.3863093239068984\n",
      "trial: 5, iter: 2600, curr loss: 1.3859121799468994, avg loss: 1.38634148478508\n",
      "trial: 5, iter: 2800, curr loss: 1.3855867385864258, avg loss: 1.3863484573364258\n",
      "trial: 5, iter: 3000, curr loss: 1.3862125873565674, avg loss: 1.3863923126459121\n",
      "trial: 5, iter: 3200, curr loss: 1.3873918056488037, avg loss: 1.3862567716836929\n",
      "trial: 5, iter: 3400, curr loss: 1.3862464427947998, avg loss: 1.3862195497751235\n",
      "trial: 5, iter: 3600, curr loss: 1.3856446743011475, avg loss: 1.386362407207489\n",
      "trial: 5, iter: 3800, curr loss: 1.3874047994613647, avg loss: 1.3862933266162871\n",
      "trial: 5, iter: 4000, curr loss: 1.3867576122283936, avg loss: 1.3862350392341614\n",
      "trial: 5, iter: 4200, curr loss: 1.3844717741012573, avg loss: 1.3861723244190216\n",
      "trial: 5, iter: 4400, curr loss: 1.3865383863449097, avg loss: 1.3859784370660782\n",
      "trial: 5, iter: 4600, curr loss: 1.3863710165023804, avg loss: 1.3860079979896545\n",
      "trial: 5, iter: 4800, curr loss: 1.3863896131515503, avg loss: 1.3858774745464324\n",
      "trial: 5, iter: 5000, curr loss: 1.3869127035140991, avg loss: 1.3855224895477294\n",
      "trial: 5, iter: 5200, curr loss: 1.3835771083831787, avg loss: 1.3852232843637466\n",
      "trial: 5, iter: 5400, curr loss: 1.3822457790374756, avg loss: 1.3844185394048691\n",
      "trial: 5, iter: 5600, curr loss: 1.381990671157837, avg loss: 1.3839316952228546\n",
      "trial: 5, iter: 5800, curr loss: 1.3845572471618652, avg loss: 1.3831501603126526\n",
      "trial: 5, iter: 6000, curr loss: 1.378352403640747, avg loss: 1.3821738755702973\n",
      "trial: 5, iter: 6200, curr loss: 1.3867666721343994, avg loss: 1.3803974694013597\n",
      "trial: 5, ldr: 0.0006125847576186061\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0038058749632909894\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3834816217422485, avg loss: 1.387163401246071\n",
      "trial: 1, iter: 400, curr loss: 1.389145851135254, avg loss: 1.3867600607872008\n",
      "trial: 1, iter: 600, curr loss: 1.384376883506775, avg loss: 1.386803891658783\n",
      "trial: 1, iter: 800, curr loss: 1.3855115175247192, avg loss: 1.3864407563209533\n",
      "trial: 1, iter: 1000, curr loss: 1.3866236209869385, avg loss: 1.3866440153121948\n",
      "trial: 1, iter: 1200, curr loss: 1.3870389461517334, avg loss: 1.3864670765399933\n",
      "trial: 1, iter: 1400, curr loss: 1.38715398311615, avg loss: 1.3863672131299973\n",
      "trial: 1, iter: 1600, curr loss: 1.3861743211746216, avg loss: 1.3864372247457504\n",
      "trial: 1, iter: 1800, curr loss: 1.3891209363937378, avg loss: 1.3862979704141616\n",
      "trial: 1, iter: 2000, curr loss: 1.3848016262054443, avg loss: 1.3864034086465835\n",
      "trial: 1, iter: 2200, curr loss: 1.3854713439941406, avg loss: 1.3863824820518493\n",
      "trial: 1, iter: 2400, curr loss: 1.3870890140533447, avg loss: 1.3862346661090852\n",
      "trial: 1, iter: 2600, curr loss: 1.386691927909851, avg loss: 1.3862915939092637\n",
      "trial: 1, iter: 2800, curr loss: 1.3879584074020386, avg loss: 1.3863074684143066\n",
      "trial: 1, iter: 3000, curr loss: 1.3871421813964844, avg loss: 1.3861928749084473\n",
      "trial: 1, iter: 3200, curr loss: 1.3833661079406738, avg loss: 1.386166816353798\n",
      "trial: 1, iter: 3400, curr loss: 1.3867400884628296, avg loss: 1.3861680430173875\n",
      "trial: 1, iter: 3600, curr loss: 1.3859299421310425, avg loss: 1.3860273444652558\n",
      "trial: 1, iter: 3800, curr loss: 1.3876608610153198, avg loss: 1.3860545784235\n",
      "trial: 1, iter: 4000, curr loss: 1.3860613107681274, avg loss: 1.3859892463684083\n",
      "trial: 1, iter: 4200, curr loss: 1.3855262994766235, avg loss: 1.385889285802841\n",
      "trial: 1, iter: 4400, curr loss: 1.3817769289016724, avg loss: 1.3856489819288254\n",
      "trial: 1, iter: 4600, curr loss: 1.3855482339859009, avg loss: 1.3851621800661087\n",
      "trial: 1, iter: 4800, curr loss: 1.3844389915466309, avg loss: 1.38473035633564\n",
      "trial: 1, iter: 5000, curr loss: 1.3889726400375366, avg loss: 1.3838174796104432\n",
      "trial: 1, iter: 5200, curr loss: 1.3879867792129517, avg loss: 1.3833678245544434\n",
      "trial: 1, iter: 5400, curr loss: 1.3798648118972778, avg loss: 1.3815957254171372\n",
      "trial: 1, iter: 5600, curr loss: 1.3766247034072876, avg loss: 1.380742083787918\n",
      "trial: 1, iter: 5800, curr loss: 1.382819414138794, avg loss: 1.3797984302043915\n",
      "trial: 1, iter: 6000, curr loss: 1.3737285137176514, avg loss: 1.3787265974283218\n",
      "trial: 1, iter: 6200, curr loss: 1.3804001808166504, avg loss: 1.3777162092924118\n",
      "trial: 1, ldr: 0.005493959411978722\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.38925302028656, avg loss: 1.387130056619644\n",
      "trial: 2, iter: 400, curr loss: 1.3893115520477295, avg loss: 1.3868549197912217\n",
      "trial: 2, iter: 600, curr loss: 1.3867266178131104, avg loss: 1.386657389998436\n",
      "trial: 2, iter: 800, curr loss: 1.3870093822479248, avg loss: 1.3865172332525253\n",
      "trial: 2, iter: 1000, curr loss: 1.3865296840667725, avg loss: 1.386448959708214\n",
      "trial: 2, iter: 1200, curr loss: 1.3853920698165894, avg loss: 1.3864414221048356\n",
      "trial: 2, iter: 1400, curr loss: 1.3866888284683228, avg loss: 1.3863578289747238\n",
      "trial: 2, iter: 1600, curr loss: 1.3858723640441895, avg loss: 1.3862975060939788\n",
      "trial: 2, iter: 1800, curr loss: 1.3866382837295532, avg loss: 1.3863957077264786\n",
      "trial: 2, iter: 2000, curr loss: 1.385763168334961, avg loss: 1.386280171275139\n",
      "trial: 2, iter: 2200, curr loss: 1.3866196870803833, avg loss: 1.3863209813833237\n",
      "trial: 2, iter: 2400, curr loss: 1.3857170343399048, avg loss: 1.3863984000682832\n",
      "trial: 2, iter: 2600, curr loss: 1.3869097232818604, avg loss: 1.3863681113719941\n",
      "trial: 2, iter: 2800, curr loss: 1.386171579360962, avg loss: 1.3863020288944243\n",
      "trial: 2, iter: 3000, curr loss: 1.3860712051391602, avg loss: 1.3862877011299133\n",
      "trial: 2, iter: 3200, curr loss: 1.3870373964309692, avg loss: 1.3863474184274673\n",
      "trial: 2, iter: 3400, curr loss: 1.3861385583877563, avg loss: 1.3863661110401153\n",
      "trial: 2, iter: 3600, curr loss: 1.3859357833862305, avg loss: 1.3862999314069748\n",
      "trial: 2, iter: 3800, curr loss: 1.3852821588516235, avg loss: 1.3862464839220048\n",
      "trial: 2, iter: 4000, curr loss: 1.3863987922668457, avg loss: 1.3863714051246643\n",
      "trial: 2, iter: 4200, curr loss: 1.3863649368286133, avg loss: 1.3863066357374192\n",
      "trial: 2, iter: 4400, curr loss: 1.3860429525375366, avg loss: 1.3863114351034165\n",
      "trial: 2, iter: 4600, curr loss: 1.386246681213379, avg loss: 1.3863145089149476\n",
      "trial: 2, iter: 4800, curr loss: 1.3860652446746826, avg loss: 1.386318212747574\n",
      "trial: 2, iter: 5000, curr loss: 1.3862932920455933, avg loss: 1.3862078589200975\n",
      "trial: 2, iter: 5200, curr loss: 1.3862669467926025, avg loss: 1.3863796132802964\n",
      "trial: 2, iter: 5400, curr loss: 1.3863354921340942, avg loss: 1.3862877202033996\n",
      "trial: 2, iter: 5600, curr loss: 1.3869754076004028, avg loss: 1.3862495803833008\n",
      "trial: 2, iter: 5800, curr loss: 1.3859436511993408, avg loss: 1.3862776589393615\n",
      "trial: 2, iter: 6000, curr loss: 1.3865965604782104, avg loss: 1.3862235116958619\n",
      "trial: 2, iter: 6200, curr loss: 1.3862792253494263, avg loss: 1.3862182712554931\n",
      "trial: 2, ldr: -0.0012650175485759974\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387364149093628, avg loss: 1.387033788561821\n",
      "trial: 3, iter: 400, curr loss: 1.389067530632019, avg loss: 1.386651093363762\n",
      "trial: 3, iter: 600, curr loss: 1.383036494255066, avg loss: 1.3865099829435348\n",
      "trial: 3, iter: 800, curr loss: 1.3842843770980835, avg loss: 1.3866271960735321\n",
      "trial: 3, iter: 1000, curr loss: 1.388838768005371, avg loss: 1.3864025074243544\n",
      "trial: 3, iter: 1200, curr loss: 1.3835493326187134, avg loss: 1.3864591032266618\n",
      "trial: 3, iter: 1400, curr loss: 1.3840117454528809, avg loss: 1.3864322036504746\n",
      "trial: 3, iter: 1600, curr loss: 1.386688470840454, avg loss: 1.386368963122368\n",
      "trial: 3, iter: 1800, curr loss: 1.3861089944839478, avg loss: 1.386310976743698\n",
      "trial: 3, iter: 2000, curr loss: 1.3875595331192017, avg loss: 1.3863030415773392\n",
      "trial: 3, iter: 2200, curr loss: 1.3867706060409546, avg loss: 1.386425873041153\n",
      "trial: 3, iter: 2400, curr loss: 1.3868671655654907, avg loss: 1.3862750470638274\n",
      "trial: 3, iter: 2600, curr loss: 1.385499119758606, avg loss: 1.3863157635927201\n",
      "trial: 3, iter: 2800, curr loss: 1.3856743574142456, avg loss: 1.3863145822286607\n",
      "trial: 3, iter: 3000, curr loss: 1.3876991271972656, avg loss: 1.386299986243248\n",
      "trial: 3, iter: 3200, curr loss: 1.3852243423461914, avg loss: 1.3862966799736023\n",
      "trial: 3, iter: 3400, curr loss: 1.3867727518081665, avg loss: 1.3862799036502838\n",
      "trial: 3, iter: 3600, curr loss: 1.386817455291748, avg loss: 1.38617382645607\n",
      "trial: 3, iter: 3800, curr loss: 1.385330319404602, avg loss: 1.38611819088459\n",
      "trial: 3, iter: 4000, curr loss: 1.3846806287765503, avg loss: 1.3861537277698517\n",
      "trial: 3, iter: 4200, curr loss: 1.3845632076263428, avg loss: 1.3861611652374268\n",
      "trial: 3, iter: 4400, curr loss: 1.3878453969955444, avg loss: 1.3861213964223862\n",
      "trial: 3, iter: 4600, curr loss: 1.3857605457305908, avg loss: 1.3858570116758346\n",
      "trial: 3, iter: 4800, curr loss: 1.3824515342712402, avg loss: 1.3859644383192062\n",
      "trial: 3, iter: 5000, curr loss: 1.3886535167694092, avg loss: 1.3856069713830947\n",
      "trial: 3, iter: 5200, curr loss: 1.3841291666030884, avg loss: 1.3853953939676285\n",
      "trial: 3, iter: 5400, curr loss: 1.3795816898345947, avg loss: 1.3848977267742157\n",
      "trial: 3, iter: 5600, curr loss: 1.3838633298873901, avg loss: 1.3845761609077454\n",
      "trial: 3, iter: 5800, curr loss: 1.3821572065353394, avg loss: 1.3834732562303542\n",
      "trial: 3, iter: 6000, curr loss: 1.3680332899093628, avg loss: 1.3822015410661697\n",
      "trial: 3, iter: 6200, curr loss: 1.3792976140975952, avg loss: 1.3808670073747635\n",
      "trial: 3, ldr: -2.8221076718182303e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388145923614502, avg loss: 1.3873139780759811\n",
      "trial: 4, iter: 400, curr loss: 1.3879204988479614, avg loss: 1.3866434860229493\n",
      "trial: 4, iter: 600, curr loss: 1.3826924562454224, avg loss: 1.3866891992092132\n",
      "trial: 4, iter: 800, curr loss: 1.38907790184021, avg loss: 1.3864276951551437\n",
      "trial: 4, iter: 1000, curr loss: 1.384859323501587, avg loss: 1.3864114493131638\n",
      "trial: 4, iter: 1200, curr loss: 1.3887150287628174, avg loss: 1.3865052783489227\n",
      "trial: 4, iter: 1400, curr loss: 1.3865270614624023, avg loss: 1.386422369480133\n",
      "trial: 4, iter: 1600, curr loss: 1.3858160972595215, avg loss: 1.386364438533783\n",
      "trial: 4, iter: 1800, curr loss: 1.3871091604232788, avg loss: 1.3864736533164979\n",
      "trial: 4, iter: 2000, curr loss: 1.3869847059249878, avg loss: 1.3863227355480194\n",
      "trial: 4, iter: 2200, curr loss: 1.385764718055725, avg loss: 1.3863339322805404\n",
      "trial: 4, iter: 2400, curr loss: 1.3872876167297363, avg loss: 1.3862116450071336\n",
      "trial: 4, iter: 2600, curr loss: 1.3873553276062012, avg loss: 1.386399118900299\n",
      "trial: 4, iter: 2800, curr loss: 1.3858505487442017, avg loss: 1.3862730926275253\n",
      "trial: 4, iter: 3000, curr loss: 1.3860325813293457, avg loss: 1.3863007569313048\n",
      "trial: 4, iter: 3200, curr loss: 1.386339783668518, avg loss: 1.3863315898180009\n",
      "trial: 4, iter: 3400, curr loss: 1.386337399482727, avg loss: 1.3861864137649536\n",
      "trial: 4, iter: 3600, curr loss: 1.3844555616378784, avg loss: 1.3861642098426818\n",
      "trial: 4, iter: 3800, curr loss: 1.385861873626709, avg loss: 1.3859710454940797\n",
      "trial: 4, iter: 4000, curr loss: 1.386008620262146, avg loss: 1.385949553847313\n",
      "trial: 4, iter: 4200, curr loss: 1.385708212852478, avg loss: 1.3855286061763763\n",
      "trial: 4, iter: 4400, curr loss: 1.38805091381073, avg loss: 1.3852228212356568\n",
      "trial: 4, iter: 4600, curr loss: 1.3866298198699951, avg loss: 1.385070983171463\n",
      "trial: 4, iter: 4800, curr loss: 1.385920763015747, avg loss: 1.384785584807396\n",
      "trial: 4, iter: 5000, curr loss: 1.3813329935073853, avg loss: 1.3838345116376878\n",
      "trial: 4, iter: 5200, curr loss: 1.3834736347198486, avg loss: 1.3835733920335769\n",
      "trial: 4, iter: 5400, curr loss: 1.3746626377105713, avg loss: 1.3820697909593582\n",
      "trial: 4, iter: 5600, curr loss: 1.3843764066696167, avg loss: 1.3804625701904296\n",
      "trial: 4, iter: 5800, curr loss: 1.3733285665512085, avg loss: 1.3797668254375457\n",
      "trial: 4, iter: 6000, curr loss: 1.3733000755310059, avg loss: 1.3790529483556748\n",
      "trial: 4, iter: 6200, curr loss: 1.3834123611450195, avg loss: 1.3774028635025024\n",
      "trial: 4, ldr: 0.0010372736724093556\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3820569515228271, avg loss: 1.38730413377285\n",
      "trial: 5, iter: 400, curr loss: 1.3874073028564453, avg loss: 1.3868840885162355\n",
      "trial: 5, iter: 600, curr loss: 1.3865364789962769, avg loss: 1.38674973487854\n",
      "trial: 5, iter: 800, curr loss: 1.387412190437317, avg loss: 1.3865994256734848\n",
      "trial: 5, iter: 1000, curr loss: 1.3865175247192383, avg loss: 1.3864992666244507\n",
      "trial: 5, iter: 1200, curr loss: 1.3866883516311646, avg loss: 1.3864801460504532\n",
      "trial: 5, iter: 1400, curr loss: 1.3871151208877563, avg loss: 1.3864035242795945\n",
      "trial: 5, iter: 1600, curr loss: 1.3876603841781616, avg loss: 1.3863774567842484\n",
      "trial: 5, iter: 1800, curr loss: 1.3869318962097168, avg loss: 1.3864246731996537\n",
      "trial: 5, iter: 2000, curr loss: 1.3861024379730225, avg loss: 1.3863517481088639\n",
      "trial: 5, iter: 2200, curr loss: 1.3870664834976196, avg loss: 1.386384534239769\n",
      "trial: 5, iter: 2400, curr loss: 1.3854173421859741, avg loss: 1.386430195569992\n",
      "trial: 5, iter: 2600, curr loss: 1.3860609531402588, avg loss: 1.3863079315423965\n",
      "trial: 5, iter: 2800, curr loss: 1.3865361213684082, avg loss: 1.3862627971172332\n",
      "trial: 5, iter: 3000, curr loss: 1.3867186307907104, avg loss: 1.386337075829506\n",
      "trial: 5, iter: 3200, curr loss: 1.3875905275344849, avg loss: 1.3862514060735702\n",
      "trial: 5, iter: 3400, curr loss: 1.3888838291168213, avg loss: 1.3862473088502885\n",
      "trial: 5, iter: 3600, curr loss: 1.386903166770935, avg loss: 1.386318375468254\n",
      "trial: 5, iter: 3800, curr loss: 1.386034369468689, avg loss: 1.3862062722444535\n",
      "trial: 5, iter: 4000, curr loss: 1.384705901145935, avg loss: 1.38638836145401\n",
      "trial: 5, iter: 4200, curr loss: 1.3859374523162842, avg loss: 1.38633819937706\n",
      "trial: 5, iter: 4400, curr loss: 1.3855674266815186, avg loss: 1.3862151205539703\n",
      "trial: 5, iter: 4600, curr loss: 1.3865092992782593, avg loss: 1.3862138932943344\n",
      "trial: 5, iter: 4800, curr loss: 1.3861795663833618, avg loss: 1.3860949909687041\n",
      "trial: 5, iter: 5000, curr loss: 1.3855857849121094, avg loss: 1.3860401529073716\n",
      "trial: 5, iter: 5200, curr loss: 1.3848254680633545, avg loss: 1.3859054511785507\n",
      "trial: 5, iter: 5400, curr loss: 1.3861263990402222, avg loss: 1.385736591219902\n",
      "trial: 5, iter: 5600, curr loss: 1.3836473226547241, avg loss: 1.38553564786911\n",
      "trial: 5, iter: 5800, curr loss: 1.3849318027496338, avg loss: 1.3851546853780747\n",
      "trial: 5, iter: 6000, curr loss: 1.382001519203186, avg loss: 1.3843978589773178\n",
      "trial: 5, iter: 6200, curr loss: 1.3886938095092773, avg loss: 1.3838045984506606\n",
      "trial: 5, ldr: -0.0009852461516857147\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0008505496614816365\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3866716623306274, avg loss: 1.387068721652031\n",
      "trial: 1, iter: 400, curr loss: 1.3884708881378174, avg loss: 1.3866750967502595\n",
      "trial: 1, iter: 600, curr loss: 1.3861145973205566, avg loss: 1.3864839351177216\n",
      "trial: 1, iter: 800, curr loss: 1.3853157758712769, avg loss: 1.3865501230955124\n",
      "trial: 1, iter: 1000, curr loss: 1.3840034008026123, avg loss: 1.3863163989782334\n",
      "trial: 1, iter: 1200, curr loss: 1.3851115703582764, avg loss: 1.3864542329311371\n",
      "trial: 1, iter: 1400, curr loss: 1.3871806859970093, avg loss: 1.3863332659006118\n",
      "trial: 1, iter: 1600, curr loss: 1.385128378868103, avg loss: 1.3863795465230941\n",
      "trial: 1, iter: 1800, curr loss: 1.3866993188858032, avg loss: 1.386314954161644\n",
      "trial: 1, iter: 2000, curr loss: 1.386687159538269, avg loss: 1.3863272601366043\n",
      "trial: 1, iter: 2200, curr loss: 1.3861792087554932, avg loss: 1.3863393527269363\n",
      "trial: 1, iter: 2400, curr loss: 1.387284517288208, avg loss: 1.386318375468254\n",
      "trial: 1, iter: 2600, curr loss: 1.3863807916641235, avg loss: 1.3862697702646256\n",
      "trial: 1, iter: 2800, curr loss: 1.3862265348434448, avg loss: 1.3862587314844133\n",
      "trial: 1, iter: 3000, curr loss: 1.3863781690597534, avg loss: 1.386135379076004\n",
      "trial: 1, iter: 3200, curr loss: 1.3859559297561646, avg loss: 1.385991823077202\n",
      "trial: 1, iter: 3400, curr loss: 1.3821614980697632, avg loss: 1.3860133504867553\n",
      "trial: 1, iter: 3600, curr loss: 1.3863109350204468, avg loss: 1.3859460866451263\n",
      "trial: 1, iter: 3800, curr loss: 1.3868858814239502, avg loss: 1.385331757068634\n",
      "trial: 1, iter: 4000, curr loss: 1.388114333152771, avg loss: 1.3850991380214692\n",
      "trial: 1, iter: 4200, curr loss: 1.3815724849700928, avg loss: 1.3843946546316146\n",
      "trial: 1, iter: 4400, curr loss: 1.3868876695632935, avg loss: 1.383472135066986\n",
      "trial: 1, iter: 4600, curr loss: 1.3843977451324463, avg loss: 1.382125672698021\n",
      "trial: 1, iter: 4800, curr loss: 1.3853840827941895, avg loss: 1.381058810353279\n",
      "trial: 1, iter: 5000, curr loss: 1.3860583305358887, avg loss: 1.3787932413816453\n",
      "trial: 1, iter: 5200, curr loss: 1.3691191673278809, avg loss: 1.3778896927833557\n",
      "trial: 1, iter: 5400, curr loss: 1.368901014328003, avg loss: 1.3771179819107056\n",
      "trial: 1, iter: 5600, curr loss: 1.3567010164260864, avg loss: 1.3738972979784012\n",
      "trial: 1, iter: 5800, curr loss: 1.3596867322921753, avg loss: 1.3722645771503448\n",
      "trial: 1, iter: 6000, curr loss: 1.3747485876083374, avg loss: 1.3710330134630204\n",
      "trial: 1, iter: 6200, curr loss: 1.3553049564361572, avg loss: 1.369097888469696\n",
      "trial: 1, ldr: -0.012290663085877895\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3843696117401123, avg loss: 1.3874698400497436\n",
      "trial: 2, iter: 400, curr loss: 1.3860101699829102, avg loss: 1.3867160469293593\n",
      "trial: 2, iter: 600, curr loss: 1.387937068939209, avg loss: 1.3866489547491074\n",
      "trial: 2, iter: 800, curr loss: 1.386522889137268, avg loss: 1.3866646206378936\n",
      "trial: 2, iter: 1000, curr loss: 1.386249303817749, avg loss: 1.3865961158275604\n",
      "trial: 2, iter: 1200, curr loss: 1.3853185176849365, avg loss: 1.3863707441091537\n",
      "trial: 2, iter: 1400, curr loss: 1.3853284120559692, avg loss: 1.3863751477003097\n",
      "trial: 2, iter: 1600, curr loss: 1.3863810300827026, avg loss: 1.386362340450287\n",
      "trial: 2, iter: 1800, curr loss: 1.3881176710128784, avg loss: 1.3863069379329682\n",
      "trial: 2, iter: 2000, curr loss: 1.386628270149231, avg loss: 1.386365406513214\n",
      "trial: 2, iter: 2200, curr loss: 1.3880294561386108, avg loss: 1.3862769889831543\n",
      "trial: 2, iter: 2400, curr loss: 1.387355923652649, avg loss: 1.3864331638813019\n",
      "trial: 2, iter: 2600, curr loss: 1.3864049911499023, avg loss: 1.386307018995285\n",
      "trial: 2, iter: 2800, curr loss: 1.3866314888000488, avg loss: 1.3863091689348221\n",
      "trial: 2, iter: 3000, curr loss: 1.3858144283294678, avg loss: 1.3862673670053482\n",
      "trial: 2, iter: 3200, curr loss: 1.3861534595489502, avg loss: 1.3862539184093476\n",
      "trial: 2, iter: 3400, curr loss: 1.3848267793655396, avg loss: 1.3861780500411987\n",
      "trial: 2, iter: 3600, curr loss: 1.385516881942749, avg loss: 1.3862689852714538\n",
      "trial: 2, iter: 3800, curr loss: 1.386511206626892, avg loss: 1.3861370933055879\n",
      "trial: 2, iter: 4000, curr loss: 1.387062430381775, avg loss: 1.3861282086372375\n",
      "trial: 2, iter: 4200, curr loss: 1.3859684467315674, avg loss: 1.3860449981689453\n",
      "trial: 2, iter: 4400, curr loss: 1.3826491832733154, avg loss: 1.3856903725862504\n",
      "trial: 2, iter: 4600, curr loss: 1.3842443227767944, avg loss: 1.385694808959961\n",
      "trial: 2, iter: 4800, curr loss: 1.3828305006027222, avg loss: 1.3852441781759262\n",
      "trial: 2, iter: 5000, curr loss: 1.3863683938980103, avg loss: 1.3849099665880202\n",
      "trial: 2, iter: 5200, curr loss: 1.3851255178451538, avg loss: 1.3841713100671769\n",
      "trial: 2, iter: 5400, curr loss: 1.3786916732788086, avg loss: 1.3833895283937454\n",
      "trial: 2, iter: 5600, curr loss: 1.3752065896987915, avg loss: 1.3822679859399796\n",
      "trial: 2, iter: 5800, curr loss: 1.3842830657958984, avg loss: 1.3813512653112412\n",
      "trial: 2, iter: 6000, curr loss: 1.3768929243087769, avg loss: 1.3803518176078797\n",
      "trial: 2, iter: 6200, curr loss: 1.3722890615463257, avg loss: 1.3786539632081984\n",
      "trial: 2, ldr: 0.0027111037634313107\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.384856104850769, avg loss: 1.3871953040361404\n",
      "trial: 3, iter: 400, curr loss: 1.385716199874878, avg loss: 1.3866923105716706\n",
      "trial: 3, iter: 600, curr loss: 1.3849914073944092, avg loss: 1.3867195880413055\n",
      "trial: 3, iter: 800, curr loss: 1.3869460821151733, avg loss: 1.3866667836904525\n",
      "trial: 3, iter: 1000, curr loss: 1.3859975337982178, avg loss: 1.386456264257431\n",
      "trial: 3, iter: 1200, curr loss: 1.3839092254638672, avg loss: 1.3863467955589295\n",
      "trial: 3, iter: 1400, curr loss: 1.3857871294021606, avg loss: 1.3864496946334839\n",
      "trial: 3, iter: 1600, curr loss: 1.3864493370056152, avg loss: 1.3863767337799073\n",
      "trial: 3, iter: 1800, curr loss: 1.3867841958999634, avg loss: 1.3863448518514634\n",
      "trial: 3, iter: 2000, curr loss: 1.386468768119812, avg loss: 1.386390781402588\n",
      "trial: 3, iter: 2200, curr loss: 1.3867123126983643, avg loss: 1.386341986656189\n",
      "trial: 3, iter: 2400, curr loss: 1.385677695274353, avg loss: 1.386315626502037\n",
      "trial: 3, iter: 2600, curr loss: 1.3866089582443237, avg loss: 1.3863828772306441\n",
      "trial: 3, iter: 2800, curr loss: 1.3863773345947266, avg loss: 1.3863322412967682\n",
      "trial: 3, iter: 3000, curr loss: 1.3861684799194336, avg loss: 1.3863280886411666\n",
      "trial: 3, iter: 3200, curr loss: 1.3861807584762573, avg loss: 1.386337907910347\n",
      "trial: 3, iter: 3400, curr loss: 1.3856911659240723, avg loss: 1.3863376307487487\n",
      "trial: 3, iter: 3600, curr loss: 1.3855555057525635, avg loss: 1.3863190042972564\n",
      "trial: 3, iter: 3800, curr loss: 1.3866527080535889, avg loss: 1.3864298379421234\n",
      "trial: 3, iter: 4000, curr loss: 1.386231780052185, avg loss: 1.3863744044303894\n",
      "trial: 3, iter: 4200, curr loss: 1.3862872123718262, avg loss: 1.3862835383415222\n",
      "trial: 3, iter: 4400, curr loss: 1.386293888092041, avg loss: 1.3863504421710968\n",
      "trial: 3, iter: 4600, curr loss: 1.38601815700531, avg loss: 1.3863414859771728\n",
      "trial: 3, iter: 4800, curr loss: 1.3859905004501343, avg loss: 1.386328456401825\n",
      "trial: 3, iter: 5000, curr loss: 1.3864827156066895, avg loss: 1.3862777465581895\n",
      "trial: 3, iter: 5200, curr loss: 1.3860479593276978, avg loss: 1.38629114985466\n",
      "trial: 3, iter: 5400, curr loss: 1.386151909828186, avg loss: 1.3863678079843522\n",
      "trial: 3, iter: 5600, curr loss: 1.3864524364471436, avg loss: 1.3863199597597122\n",
      "trial: 3, iter: 5800, curr loss: 1.3860883712768555, avg loss: 1.3863464778661727\n",
      "trial: 3, iter: 6000, curr loss: 1.3869216442108154, avg loss: 1.38631980240345\n",
      "trial: 3, iter: 6200, curr loss: 1.3864338397979736, avg loss: 1.3863254994153977\n",
      "trial: 3, ldr: 0.0022331501822918653\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3872878551483154, avg loss: 1.3872904711961747\n",
      "trial: 4, iter: 400, curr loss: 1.3848803043365479, avg loss: 1.3867252558469771\n",
      "trial: 4, iter: 600, curr loss: 1.3860238790512085, avg loss: 1.3864823186397552\n",
      "trial: 4, iter: 800, curr loss: 1.384574294090271, avg loss: 1.3864039123058318\n",
      "trial: 4, iter: 1000, curr loss: 1.3874638080596924, avg loss: 1.3864003777503968\n",
      "trial: 4, iter: 1200, curr loss: 1.3863584995269775, avg loss: 1.3863978439569473\n",
      "trial: 4, iter: 1400, curr loss: 1.3855572938919067, avg loss: 1.386436089873314\n",
      "trial: 4, iter: 1600, curr loss: 1.3870978355407715, avg loss: 1.3863782167434693\n",
      "trial: 4, iter: 1800, curr loss: 1.3868248462677002, avg loss: 1.3863376134634018\n",
      "trial: 4, iter: 2000, curr loss: 1.3848737478256226, avg loss: 1.3863058823347092\n",
      "trial: 4, iter: 2200, curr loss: 1.3873151540756226, avg loss: 1.3862616693973542\n",
      "trial: 4, iter: 2400, curr loss: 1.3868749141693115, avg loss: 1.3864056491851806\n",
      "trial: 4, iter: 2600, curr loss: 1.387262225151062, avg loss: 1.3863556897640228\n",
      "trial: 4, iter: 2800, curr loss: 1.3864411115646362, avg loss: 1.386314572095871\n",
      "trial: 4, iter: 3000, curr loss: 1.386127233505249, avg loss: 1.3862378293275832\n",
      "trial: 4, iter: 3200, curr loss: 1.3862495422363281, avg loss: 1.386354261636734\n",
      "trial: 4, iter: 3400, curr loss: 1.386606216430664, avg loss: 1.386175315976143\n",
      "trial: 4, iter: 3600, curr loss: 1.385918378829956, avg loss: 1.3860751646757126\n",
      "trial: 4, iter: 3800, curr loss: 1.3904995918273926, avg loss: 1.385947409272194\n",
      "trial: 4, iter: 4000, curr loss: 1.3862545490264893, avg loss: 1.38592076420784\n",
      "trial: 4, iter: 4200, curr loss: 1.3881618976593018, avg loss: 1.3855203402042389\n",
      "trial: 4, iter: 4400, curr loss: 1.3836548328399658, avg loss: 1.385621018409729\n",
      "trial: 4, iter: 4600, curr loss: 1.3838657140731812, avg loss: 1.384933521747589\n",
      "trial: 4, iter: 4800, curr loss: 1.3852388858795166, avg loss: 1.3844166594743728\n",
      "trial: 4, iter: 5000, curr loss: 1.3800172805786133, avg loss: 1.3835356706380844\n",
      "trial: 4, iter: 5200, curr loss: 1.3839606046676636, avg loss: 1.3830462777614594\n",
      "trial: 4, iter: 5400, curr loss: 1.376792311668396, avg loss: 1.381888391971588\n",
      "trial: 4, iter: 5600, curr loss: 1.3793585300445557, avg loss: 1.3798381054401399\n",
      "trial: 4, iter: 5800, curr loss: 1.3795974254608154, avg loss: 1.3790458858013153\n",
      "trial: 4, iter: 6000, curr loss: 1.3863664865493774, avg loss: 1.3790193331241607\n",
      "trial: 4, iter: 6200, curr loss: 1.3807798624038696, avg loss: 1.3761766827106476\n",
      "trial: 4, ldr: -0.0003423214075155556\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3875797986984253, avg loss: 1.3876363265514373\n",
      "trial: 5, iter: 400, curr loss: 1.386282205581665, avg loss: 1.386668370962143\n",
      "trial: 5, iter: 600, curr loss: 1.3851244449615479, avg loss: 1.3868955069780349\n",
      "trial: 5, iter: 800, curr loss: 1.3876513242721558, avg loss: 1.3865303099155426\n",
      "trial: 5, iter: 1000, curr loss: 1.387370228767395, avg loss: 1.3866211080551147\n",
      "trial: 5, iter: 1200, curr loss: 1.3868935108184814, avg loss: 1.386578677892685\n",
      "trial: 5, iter: 1400, curr loss: 1.389700174331665, avg loss: 1.3863944172859193\n",
      "trial: 5, iter: 1600, curr loss: 1.38601815700531, avg loss: 1.3864043158292771\n",
      "trial: 5, iter: 1800, curr loss: 1.3854060173034668, avg loss: 1.3863315409421921\n",
      "trial: 5, iter: 2000, curr loss: 1.3860687017440796, avg loss: 1.3863781195878984\n",
      "trial: 5, iter: 2200, curr loss: 1.3851699829101562, avg loss: 1.3862642651796342\n",
      "trial: 5, iter: 2400, curr loss: 1.386557698249817, avg loss: 1.3863666886091233\n",
      "trial: 5, iter: 2600, curr loss: 1.3868228197097778, avg loss: 1.3863133043050766\n",
      "trial: 5, iter: 2800, curr loss: 1.387007474899292, avg loss: 1.3862978833913804\n",
      "trial: 5, iter: 3000, curr loss: 1.3865422010421753, avg loss: 1.386351026892662\n",
      "trial: 5, iter: 3200, curr loss: 1.3852779865264893, avg loss: 1.386223884820938\n",
      "trial: 5, iter: 3400, curr loss: 1.3866848945617676, avg loss: 1.386203482747078\n",
      "trial: 5, iter: 3600, curr loss: 1.3848769664764404, avg loss: 1.3862335979938507\n",
      "trial: 5, iter: 3800, curr loss: 1.3860942125320435, avg loss: 1.386045976281166\n",
      "trial: 5, iter: 4000, curr loss: 1.3869727849960327, avg loss: 1.3860470414161683\n",
      "trial: 5, iter: 4200, curr loss: 1.388535976409912, avg loss: 1.386019276380539\n",
      "trial: 5, iter: 4400, curr loss: 1.3833924531936646, avg loss: 1.3856291896104813\n",
      "trial: 5, iter: 4600, curr loss: 1.3867864608764648, avg loss: 1.3855692166090012\n",
      "trial: 5, iter: 4800, curr loss: 1.3858447074890137, avg loss: 1.384919788837433\n",
      "trial: 5, iter: 5000, curr loss: 1.3830002546310425, avg loss: 1.3840947896242142\n",
      "trial: 5, iter: 5200, curr loss: 1.3820511102676392, avg loss: 1.383471292257309\n",
      "trial: 5, iter: 5400, curr loss: 1.3773590326309204, avg loss: 1.3815311282873153\n",
      "trial: 5, iter: 5600, curr loss: 1.3838107585906982, avg loss: 1.3803098219633103\n",
      "trial: 5, iter: 5800, curr loss: 1.378178596496582, avg loss: 1.378540639281273\n",
      "trial: 5, iter: 6000, curr loss: 1.3669648170471191, avg loss: 1.3758685439825058\n",
      "trial: 5, iter: 6200, curr loss: 1.3672274351119995, avg loss: 1.3734676986932755\n",
      "trial: 5, ldr: 0.0054792119190096855\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0004419037257321179\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3880114555358887, avg loss: 1.3871617913246155\n",
      "trial: 1, iter: 400, curr loss: 1.3872381448745728, avg loss: 1.3867064303159713\n",
      "trial: 1, iter: 600, curr loss: 1.384010910987854, avg loss: 1.3867336237430572\n",
      "trial: 1, iter: 800, curr loss: 1.3843050003051758, avg loss: 1.3864842182397843\n",
      "trial: 1, iter: 1000, curr loss: 1.3866139650344849, avg loss: 1.386497830748558\n",
      "trial: 1, iter: 1200, curr loss: 1.386206030845642, avg loss: 1.3863079822063447\n",
      "trial: 1, iter: 1400, curr loss: 1.3884038925170898, avg loss: 1.3864554464817047\n",
      "trial: 1, iter: 1600, curr loss: 1.3859241008758545, avg loss: 1.3865119069814682\n",
      "trial: 1, iter: 1800, curr loss: 1.3868328332901, avg loss: 1.386354803442955\n",
      "trial: 1, iter: 2000, curr loss: 1.386250615119934, avg loss: 1.3863646811246872\n",
      "trial: 1, iter: 2200, curr loss: 1.3862178325653076, avg loss: 1.3862438839673996\n",
      "trial: 1, iter: 2400, curr loss: 1.3851804733276367, avg loss: 1.3862817829847336\n",
      "trial: 1, iter: 2600, curr loss: 1.3862483501434326, avg loss: 1.386326842904091\n",
      "trial: 1, iter: 2800, curr loss: 1.3861596584320068, avg loss: 1.3863073539733888\n",
      "trial: 1, iter: 3000, curr loss: 1.3865693807601929, avg loss: 1.386248859167099\n",
      "trial: 1, iter: 3200, curr loss: 1.3852205276489258, avg loss: 1.386273148059845\n",
      "trial: 1, iter: 3400, curr loss: 1.3851875066757202, avg loss: 1.386249725818634\n",
      "trial: 1, iter: 3600, curr loss: 1.3880729675292969, avg loss: 1.386110850572586\n",
      "trial: 1, iter: 3800, curr loss: 1.3864496946334839, avg loss: 1.3862516754865646\n",
      "trial: 1, iter: 4000, curr loss: 1.3847638368606567, avg loss: 1.3860882866382598\n",
      "trial: 1, iter: 4200, curr loss: 1.3875855207443237, avg loss: 1.385911638736725\n",
      "trial: 1, iter: 4400, curr loss: 1.3850656747817993, avg loss: 1.385758706331253\n",
      "trial: 1, iter: 4600, curr loss: 1.3860197067260742, avg loss: 1.3854323375225066\n",
      "trial: 1, iter: 4800, curr loss: 1.3875178098678589, avg loss: 1.3851821088790894\n",
      "trial: 1, iter: 5000, curr loss: 1.3855912685394287, avg loss: 1.3849265402555466\n",
      "trial: 1, iter: 5200, curr loss: 1.3807660341262817, avg loss: 1.3838016963005066\n",
      "trial: 1, iter: 5400, curr loss: 1.3793946504592896, avg loss: 1.3830446964502334\n",
      "trial: 1, iter: 5600, curr loss: 1.378872275352478, avg loss: 1.3819780838489533\n",
      "trial: 1, iter: 5800, curr loss: 1.3745369911193848, avg loss: 1.3801508224010468\n",
      "trial: 1, iter: 6000, curr loss: 1.3734724521636963, avg loss: 1.3789159017801285\n",
      "trial: 1, iter: 6200, curr loss: 1.3713085651397705, avg loss: 1.3767474633455277\n",
      "trial: 1, ldr: 0.006418853532522917\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3850857019424438, avg loss: 1.3869892007112503\n",
      "trial: 2, iter: 400, curr loss: 1.3868097066879272, avg loss: 1.3867065435647965\n",
      "trial: 2, iter: 600, curr loss: 1.3860491514205933, avg loss: 1.3865534257888794\n",
      "trial: 2, iter: 800, curr loss: 1.3883074522018433, avg loss: 1.3864718449115754\n",
      "trial: 2, iter: 1000, curr loss: 1.3872976303100586, avg loss: 1.3863114261627196\n",
      "trial: 2, iter: 1200, curr loss: 1.388477087020874, avg loss: 1.3863571506738663\n",
      "trial: 2, iter: 1400, curr loss: 1.3863699436187744, avg loss: 1.3864538723230362\n",
      "trial: 2, iter: 1600, curr loss: 1.3858755826950073, avg loss: 1.3863369834423065\n",
      "trial: 2, iter: 1800, curr loss: 1.3882006406784058, avg loss: 1.386269954442978\n",
      "trial: 2, iter: 2000, curr loss: 1.3871508836746216, avg loss: 1.386329353451729\n",
      "trial: 2, iter: 2200, curr loss: 1.3864184617996216, avg loss: 1.3863260620832443\n",
      "trial: 2, iter: 2400, curr loss: 1.3866418600082397, avg loss: 1.3863537752628325\n",
      "trial: 2, iter: 2600, curr loss: 1.3856143951416016, avg loss: 1.386282793879509\n",
      "trial: 2, iter: 2800, curr loss: 1.3866668939590454, avg loss: 1.3862769627571105\n",
      "trial: 2, iter: 3000, curr loss: 1.3874067068099976, avg loss: 1.3862803089618683\n",
      "trial: 2, iter: 3200, curr loss: 1.3860468864440918, avg loss: 1.3863360488414764\n",
      "trial: 2, iter: 3400, curr loss: 1.3868623971939087, avg loss: 1.3862742978334426\n",
      "trial: 2, iter: 3600, curr loss: 1.3857908248901367, avg loss: 1.3863468462228774\n",
      "trial: 2, iter: 3800, curr loss: 1.3863071203231812, avg loss: 1.386202850341797\n",
      "trial: 2, iter: 4000, curr loss: 1.3864893913269043, avg loss: 1.3861564856767654\n",
      "trial: 2, iter: 4200, curr loss: 1.3882843255996704, avg loss: 1.3861589699983596\n",
      "trial: 2, iter: 4400, curr loss: 1.3878268003463745, avg loss: 1.3862013059854508\n",
      "trial: 2, iter: 4600, curr loss: 1.3859411478042603, avg loss: 1.3858843958377838\n",
      "trial: 2, iter: 4800, curr loss: 1.3854053020477295, avg loss: 1.3859977900981904\n",
      "trial: 2, iter: 5000, curr loss: 1.385258436203003, avg loss: 1.3858916634321212\n",
      "trial: 2, iter: 5200, curr loss: 1.3868017196655273, avg loss: 1.385529505610466\n",
      "trial: 2, iter: 5400, curr loss: 1.385023832321167, avg loss: 1.385154908299446\n",
      "trial: 2, iter: 5600, curr loss: 1.3827760219573975, avg loss: 1.3846593171358108\n",
      "trial: 2, iter: 5800, curr loss: 1.386144757270813, avg loss: 1.3842558300495147\n",
      "trial: 2, iter: 6000, curr loss: 1.3793327808380127, avg loss: 1.38338472366333\n",
      "trial: 2, iter: 6200, curr loss: 1.380107045173645, avg loss: 1.3828852903842925\n",
      "trial: 2, ldr: 0.0033567589707672596\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3871046304702759, avg loss: 1.3872178506851196\n",
      "trial: 3, iter: 400, curr loss: 1.3862700462341309, avg loss: 1.3868932032585144\n",
      "trial: 3, iter: 600, curr loss: 1.3832464218139648, avg loss: 1.3866485852003096\n",
      "trial: 3, iter: 800, curr loss: 1.388400912284851, avg loss: 1.3864783143997192\n",
      "trial: 3, iter: 1000, curr loss: 1.3845417499542236, avg loss: 1.3864673888683319\n",
      "trial: 3, iter: 1200, curr loss: 1.3887649774551392, avg loss: 1.3864362221956252\n",
      "trial: 3, iter: 1400, curr loss: 1.3859587907791138, avg loss: 1.3864471274614334\n",
      "trial: 3, iter: 1600, curr loss: 1.3859047889709473, avg loss: 1.386404440999031\n",
      "trial: 3, iter: 1800, curr loss: 1.3870563507080078, avg loss: 1.3863564521074294\n",
      "trial: 3, iter: 2000, curr loss: 1.3870799541473389, avg loss: 1.3863506889343262\n",
      "trial: 3, iter: 2200, curr loss: 1.3860834836959839, avg loss: 1.3862939542531967\n",
      "trial: 3, iter: 2400, curr loss: 1.3868101835250854, avg loss: 1.3863292092084885\n",
      "trial: 3, iter: 2600, curr loss: 1.3860520124435425, avg loss: 1.3863100433349609\n",
      "trial: 3, iter: 2800, curr loss: 1.3865059614181519, avg loss: 1.3863113075494766\n",
      "trial: 3, iter: 3000, curr loss: 1.386733055114746, avg loss: 1.3862683469057082\n",
      "trial: 3, iter: 3200, curr loss: 1.3874417543411255, avg loss: 1.3863266402482985\n",
      "trial: 3, iter: 3400, curr loss: 1.3862640857696533, avg loss: 1.3863451081514357\n",
      "trial: 3, iter: 3600, curr loss: 1.3854565620422363, avg loss: 1.3863013011217118\n",
      "trial: 3, iter: 3800, curr loss: 1.3853559494018555, avg loss: 1.3862547439336776\n",
      "trial: 3, iter: 4000, curr loss: 1.3871573209762573, avg loss: 1.3862525504827499\n",
      "trial: 3, iter: 4200, curr loss: 1.386983871459961, avg loss: 1.3861331033706665\n",
      "trial: 3, iter: 4400, curr loss: 1.3876111507415771, avg loss: 1.3861424815654755\n",
      "trial: 3, iter: 4600, curr loss: 1.387818455696106, avg loss: 1.3861924159526824\n",
      "trial: 3, iter: 4800, curr loss: 1.386841058731079, avg loss: 1.3859125870466231\n",
      "trial: 3, iter: 5000, curr loss: 1.3869224786758423, avg loss: 1.386033644080162\n",
      "trial: 3, iter: 5200, curr loss: 1.382401704788208, avg loss: 1.3855563938617705\n",
      "trial: 3, iter: 5400, curr loss: 1.384177803993225, avg loss: 1.385262618660927\n",
      "trial: 3, iter: 5600, curr loss: 1.3847784996032715, avg loss: 1.384864889383316\n",
      "trial: 3, iter: 5800, curr loss: 1.3854132890701294, avg loss: 1.3840369600057603\n",
      "trial: 3, iter: 6000, curr loss: 1.3782039880752563, avg loss: 1.382990550994873\n",
      "trial: 3, iter: 6200, curr loss: 1.3691880702972412, avg loss: 1.3816270697116853\n",
      "trial: 3, ldr: 0.004828553181141615\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386892557144165, avg loss: 1.3872074180841445\n",
      "trial: 4, iter: 400, curr loss: 1.3893773555755615, avg loss: 1.3868005877733232\n",
      "trial: 4, iter: 600, curr loss: 1.38569176197052, avg loss: 1.386627618074417\n",
      "trial: 4, iter: 800, curr loss: 1.387060284614563, avg loss: 1.3866454589366912\n",
      "trial: 4, iter: 1000, curr loss: 1.3843120336532593, avg loss: 1.3864742588996888\n",
      "trial: 4, iter: 1200, curr loss: 1.3852654695510864, avg loss: 1.3865609860420227\n",
      "trial: 4, iter: 1400, curr loss: 1.3850550651550293, avg loss: 1.3863487237691878\n",
      "trial: 4, iter: 1600, curr loss: 1.3861957788467407, avg loss: 1.3863987743854522\n",
      "trial: 4, iter: 1800, curr loss: 1.3855310678482056, avg loss: 1.3863553142547607\n",
      "trial: 4, iter: 2000, curr loss: 1.385960340499878, avg loss: 1.3863270515203476\n",
      "trial: 4, iter: 2200, curr loss: 1.3858181238174438, avg loss: 1.3863846689462662\n",
      "trial: 4, iter: 2400, curr loss: 1.3859226703643799, avg loss: 1.3863899827003479\n",
      "trial: 4, iter: 2600, curr loss: 1.3868335485458374, avg loss: 1.386248353123665\n",
      "trial: 4, iter: 2800, curr loss: 1.3862890005111694, avg loss: 1.386291407942772\n",
      "trial: 4, iter: 3000, curr loss: 1.3858274221420288, avg loss: 1.3862546700239182\n",
      "trial: 4, iter: 3200, curr loss: 1.386491060256958, avg loss: 1.386406003832817\n",
      "trial: 4, iter: 3400, curr loss: 1.3874493837356567, avg loss: 1.3861561822891235\n",
      "trial: 4, iter: 3600, curr loss: 1.3843013048171997, avg loss: 1.386280786395073\n",
      "trial: 4, iter: 3800, curr loss: 1.3862515687942505, avg loss: 1.3862838488817215\n",
      "trial: 4, iter: 4000, curr loss: 1.388861060142517, avg loss: 1.3863464438915252\n",
      "trial: 4, iter: 4200, curr loss: 1.386009931564331, avg loss: 1.3861148607730867\n",
      "trial: 4, iter: 4400, curr loss: 1.384905457496643, avg loss: 1.386056625843048\n",
      "trial: 4, iter: 4600, curr loss: 1.3870348930358887, avg loss: 1.385892195701599\n",
      "trial: 4, iter: 4800, curr loss: 1.3832429647445679, avg loss: 1.3856099545955658\n",
      "trial: 4, iter: 5000, curr loss: 1.3841092586517334, avg loss: 1.3852500700950623\n",
      "trial: 4, iter: 5200, curr loss: 1.3838213682174683, avg loss: 1.384795081615448\n",
      "trial: 4, iter: 5400, curr loss: 1.3833216428756714, avg loss: 1.3840439754724503\n",
      "trial: 4, iter: 5600, curr loss: 1.3867336511611938, avg loss: 1.3837832897901534\n",
      "trial: 4, iter: 5800, curr loss: 1.3864668607711792, avg loss: 1.3820961487293244\n",
      "trial: 4, iter: 6000, curr loss: 1.3766545057296753, avg loss: 1.3813244491815566\n",
      "trial: 4, iter: 6200, curr loss: 1.3890962600708008, avg loss: 1.3796239292621613\n",
      "trial: 4, ldr: -0.0013456586748361588\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3826147317886353, avg loss: 1.3874463999271394\n",
      "trial: 5, iter: 400, curr loss: 1.386081576347351, avg loss: 1.3867594957351685\n",
      "trial: 5, iter: 600, curr loss: 1.3843721151351929, avg loss: 1.3866557604074479\n",
      "trial: 5, iter: 800, curr loss: 1.385980248451233, avg loss: 1.3864970368146896\n",
      "trial: 5, iter: 1000, curr loss: 1.3884831666946411, avg loss: 1.3864159876108169\n",
      "trial: 5, iter: 1200, curr loss: 1.3872663974761963, avg loss: 1.3864280450344086\n",
      "trial: 5, iter: 1400, curr loss: 1.3853793144226074, avg loss: 1.3864229440689086\n",
      "trial: 5, iter: 1600, curr loss: 1.3852334022521973, avg loss: 1.386246873140335\n",
      "trial: 5, iter: 1800, curr loss: 1.3859282732009888, avg loss: 1.386429426074028\n",
      "trial: 5, iter: 2000, curr loss: 1.3863364458084106, avg loss: 1.3863353258371354\n",
      "trial: 5, iter: 2200, curr loss: 1.3871833086013794, avg loss: 1.38635711312294\n",
      "trial: 5, iter: 2400, curr loss: 1.3860416412353516, avg loss: 1.3863464736938476\n",
      "trial: 5, iter: 2600, curr loss: 1.3861745595932007, avg loss: 1.3863060522079467\n",
      "trial: 5, iter: 2800, curr loss: 1.3859354257583618, avg loss: 1.38626708984375\n",
      "trial: 5, iter: 3000, curr loss: 1.386103868484497, avg loss: 1.386206448674202\n",
      "trial: 5, iter: 3200, curr loss: 1.3878008127212524, avg loss: 1.3861786979436874\n",
      "trial: 5, iter: 3400, curr loss: 1.385254144668579, avg loss: 1.386214570403099\n",
      "trial: 5, iter: 3600, curr loss: 1.3867971897125244, avg loss: 1.3861872869729996\n",
      "trial: 5, iter: 3800, curr loss: 1.387233018875122, avg loss: 1.3861032259464263\n",
      "trial: 5, iter: 4000, curr loss: 1.384380578994751, avg loss: 1.3859507703781129\n",
      "trial: 5, iter: 4200, curr loss: 1.3823226690292358, avg loss: 1.3856147623062134\n",
      "trial: 5, iter: 4400, curr loss: 1.3845884799957275, avg loss: 1.385538883805275\n",
      "trial: 5, iter: 4600, curr loss: 1.3872036933898926, avg loss: 1.3854836982488632\n",
      "trial: 5, iter: 4800, curr loss: 1.3844817876815796, avg loss: 1.3847036564350128\n",
      "trial: 5, iter: 5000, curr loss: 1.384727954864502, avg loss: 1.3841554617881775\n",
      "trial: 5, iter: 5200, curr loss: 1.3957046270370483, avg loss: 1.3830044788122178\n",
      "trial: 5, iter: 5400, curr loss: 1.385418176651001, avg loss: 1.382118243575096\n",
      "trial: 5, iter: 5600, curr loss: 1.3772910833358765, avg loss: 1.3810355991125107\n",
      "trial: 5, iter: 5800, curr loss: 1.3780897855758667, avg loss: 1.3795669323205948\n",
      "trial: 5, iter: 6000, curr loss: 1.3758631944656372, avg loss: 1.3780792945623397\n",
      "trial: 5, iter: 6200, curr loss: 1.3782343864440918, avg loss: 1.377514560818672\n",
      "trial: 5, ldr: 0.004963133484125137\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.003644328098744154\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3881844282150269, avg loss: 1.3868846809864044\n",
      "trial: 1, iter: 400, curr loss: 1.386705994606018, avg loss: 1.386787395477295\n",
      "trial: 1, iter: 600, curr loss: 1.3873261213302612, avg loss: 1.3865731316804886\n",
      "trial: 1, iter: 800, curr loss: 1.3844696283340454, avg loss: 1.3865116679668426\n",
      "trial: 1, iter: 1000, curr loss: 1.3863741159439087, avg loss: 1.3864983159303665\n",
      "trial: 1, iter: 1200, curr loss: 1.3847953081130981, avg loss: 1.3864024806022643\n",
      "trial: 1, iter: 1400, curr loss: 1.3875713348388672, avg loss: 1.3863940399885177\n",
      "trial: 1, iter: 1600, curr loss: 1.386628270149231, avg loss: 1.3863389742374421\n",
      "trial: 1, iter: 1800, curr loss: 1.386305332183838, avg loss: 1.3864599508047104\n",
      "trial: 1, iter: 2000, curr loss: 1.3859628438949585, avg loss: 1.3863508343696593\n",
      "trial: 1, iter: 2200, curr loss: 1.3877191543579102, avg loss: 1.386358083486557\n",
      "trial: 1, iter: 2400, curr loss: 1.3872430324554443, avg loss: 1.3863490611314773\n",
      "trial: 1, iter: 2600, curr loss: 1.3855661153793335, avg loss: 1.3862515825033188\n",
      "trial: 1, iter: 2800, curr loss: 1.3870010375976562, avg loss: 1.3863137245178223\n",
      "trial: 1, iter: 3000, curr loss: 1.3855658769607544, avg loss: 1.386223909854889\n",
      "trial: 1, iter: 3200, curr loss: 1.3863219022750854, avg loss: 1.38615343272686\n",
      "trial: 1, iter: 3400, curr loss: 1.3868873119354248, avg loss: 1.3861962085962296\n",
      "trial: 1, iter: 3600, curr loss: 1.3861783742904663, avg loss: 1.3861469757556915\n",
      "trial: 1, iter: 3800, curr loss: 1.3857110738754272, avg loss: 1.386048418879509\n",
      "trial: 1, iter: 4000, curr loss: 1.3877261877059937, avg loss: 1.385930370092392\n",
      "trial: 1, iter: 4200, curr loss: 1.3818113803863525, avg loss: 1.38565360724926\n",
      "trial: 1, iter: 4400, curr loss: 1.386953353881836, avg loss: 1.3853699731826783\n",
      "trial: 1, iter: 4600, curr loss: 1.3833473920822144, avg loss: 1.385106966495514\n",
      "trial: 1, iter: 4800, curr loss: 1.3849245309829712, avg loss: 1.3842012506723405\n",
      "trial: 1, iter: 5000, curr loss: 1.3772865533828735, avg loss: 1.3831584280729294\n",
      "trial: 1, iter: 5200, curr loss: 1.3836942911148071, avg loss: 1.3816111010313035\n",
      "trial: 1, iter: 5400, curr loss: 1.3812214136123657, avg loss: 1.3802420228719712\n",
      "trial: 1, iter: 5600, curr loss: 1.3807787895202637, avg loss: 1.378428481221199\n",
      "trial: 1, iter: 5800, curr loss: 1.3752176761627197, avg loss: 1.3772146666049958\n",
      "trial: 1, iter: 6000, curr loss: 1.3742419481277466, avg loss: 1.3766434651613235\n",
      "trial: 1, iter: 6200, curr loss: 1.3854258060455322, avg loss: 1.375588886141777\n",
      "trial: 1, ldr: 0.0013769243378192186\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3852863311767578, avg loss: 1.3870898950099946\n",
      "trial: 2, iter: 400, curr loss: 1.3851032257080078, avg loss: 1.386930189728737\n",
      "trial: 2, iter: 600, curr loss: 1.3880335092544556, avg loss: 1.3864133685827256\n",
      "trial: 2, iter: 800, curr loss: 1.3867712020874023, avg loss: 1.38661862552166\n",
      "trial: 2, iter: 1000, curr loss: 1.38328218460083, avg loss: 1.3864043152332306\n",
      "trial: 2, iter: 1200, curr loss: 1.3849836587905884, avg loss: 1.3864520543813705\n",
      "trial: 2, iter: 1400, curr loss: 1.3844075202941895, avg loss: 1.3864214968681337\n",
      "trial: 2, iter: 1600, curr loss: 1.3863465785980225, avg loss: 1.386432632803917\n",
      "trial: 2, iter: 1800, curr loss: 1.3859021663665771, avg loss: 1.3862655133008956\n",
      "trial: 2, iter: 2000, curr loss: 1.3863189220428467, avg loss: 1.3863777893781661\n",
      "trial: 2, iter: 2200, curr loss: 1.3876349925994873, avg loss: 1.3863268327713012\n",
      "trial: 2, iter: 2400, curr loss: 1.3882733583450317, avg loss: 1.3862544018030167\n",
      "trial: 2, iter: 2600, curr loss: 1.387662410736084, avg loss: 1.3863238060474397\n",
      "trial: 2, iter: 2800, curr loss: 1.385242223739624, avg loss: 1.3862595307826995\n",
      "trial: 2, iter: 3000, curr loss: 1.3852081298828125, avg loss: 1.3862742787599565\n",
      "trial: 2, iter: 3200, curr loss: 1.386659860610962, avg loss: 1.386087915301323\n",
      "trial: 2, iter: 3400, curr loss: 1.387019395828247, avg loss: 1.385950159430504\n",
      "trial: 2, iter: 3600, curr loss: 1.3863520622253418, avg loss: 1.385823476910591\n",
      "trial: 2, iter: 3800, curr loss: 1.3877904415130615, avg loss: 1.3854972535371781\n",
      "trial: 2, iter: 4000, curr loss: 1.3870021104812622, avg loss: 1.385102258324623\n",
      "trial: 2, iter: 4200, curr loss: 1.3851137161254883, avg loss: 1.3845398336648942\n",
      "trial: 2, iter: 4400, curr loss: 1.389441967010498, avg loss: 1.3836749571561813\n",
      "trial: 2, iter: 4600, curr loss: 1.3797366619110107, avg loss: 1.3827420383691789\n",
      "trial: 2, iter: 4800, curr loss: 1.3917638063430786, avg loss: 1.3817071557044982\n",
      "trial: 2, iter: 5000, curr loss: 1.379584789276123, avg loss: 1.3802946883440017\n",
      "trial: 2, iter: 5200, curr loss: 1.3713127374649048, avg loss: 1.3793150317668914\n",
      "trial: 2, iter: 5400, curr loss: 1.387851357460022, avg loss: 1.3777766913175582\n",
      "trial: 2, iter: 5600, curr loss: 1.368914008140564, avg loss: 1.3762186586856842\n",
      "trial: 2, iter: 5800, curr loss: 1.3845653533935547, avg loss: 1.375003418326378\n",
      "trial: 2, iter: 6000, curr loss: 1.3813964128494263, avg loss: 1.374435731768608\n",
      "trial: 2, iter: 6200, curr loss: 1.3681607246398926, avg loss: 1.3719946706295014\n",
      "trial: 2, ldr: -0.006231473758816719\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.383418321609497, avg loss: 1.3872558200359344\n",
      "trial: 3, iter: 400, curr loss: 1.3867093324661255, avg loss: 1.3866836100816726\n",
      "trial: 3, iter: 600, curr loss: 1.3861669301986694, avg loss: 1.3867034375667573\n",
      "trial: 3, iter: 800, curr loss: 1.384401798248291, avg loss: 1.3863668501377107\n",
      "trial: 3, iter: 1000, curr loss: 1.3858705759048462, avg loss: 1.3864821422100067\n",
      "trial: 3, iter: 1200, curr loss: 1.3856840133666992, avg loss: 1.38639201939106\n",
      "trial: 3, iter: 1400, curr loss: 1.3852190971374512, avg loss: 1.3863711988925933\n",
      "trial: 3, iter: 1600, curr loss: 1.3850096464157104, avg loss: 1.3864282196760178\n",
      "trial: 3, iter: 1800, curr loss: 1.3867772817611694, avg loss: 1.3863656097650527\n",
      "trial: 3, iter: 2000, curr loss: 1.3849197626113892, avg loss: 1.386255334019661\n",
      "trial: 3, iter: 2200, curr loss: 1.3857407569885254, avg loss: 1.3863180857896804\n",
      "trial: 3, iter: 2400, curr loss: 1.3873631954193115, avg loss: 1.3863270419836045\n",
      "trial: 3, iter: 2600, curr loss: 1.3860095739364624, avg loss: 1.3862789356708527\n",
      "trial: 3, iter: 2800, curr loss: 1.3863000869750977, avg loss: 1.386178076863289\n",
      "trial: 3, iter: 3000, curr loss: 1.3865288496017456, avg loss: 1.3861987501382829\n",
      "trial: 3, iter: 3200, curr loss: 1.385218620300293, avg loss: 1.3861251372098922\n",
      "trial: 3, iter: 3400, curr loss: 1.385651707649231, avg loss: 1.3859874814748765\n",
      "trial: 3, iter: 3600, curr loss: 1.384337306022644, avg loss: 1.385761974453926\n",
      "trial: 3, iter: 3800, curr loss: 1.3845810890197754, avg loss: 1.3856891107559204\n",
      "trial: 3, iter: 4000, curr loss: 1.3839569091796875, avg loss: 1.3851980590820312\n",
      "trial: 3, iter: 4200, curr loss: 1.3814268112182617, avg loss: 1.38462795317173\n",
      "trial: 3, iter: 4400, curr loss: 1.3856346607208252, avg loss: 1.3840938758850099\n",
      "trial: 3, iter: 4600, curr loss: 1.3857237100601196, avg loss: 1.3829779773950577\n",
      "trial: 3, iter: 4800, curr loss: 1.3770942687988281, avg loss: 1.3817713743448257\n",
      "trial: 3, iter: 5000, curr loss: 1.379477620124817, avg loss: 1.3804650723934173\n",
      "trial: 3, iter: 5200, curr loss: 1.379577875137329, avg loss: 1.3803783524036408\n",
      "trial: 3, iter: 5400, curr loss: 1.3925458192825317, avg loss: 1.3789328336715698\n",
      "trial: 3, iter: 5600, curr loss: 1.37021803855896, avg loss: 1.3775202840566636\n",
      "trial: 3, iter: 5800, curr loss: 1.382438063621521, avg loss: 1.3767676275968552\n",
      "trial: 3, iter: 6000, curr loss: 1.3739079236984253, avg loss: 1.3759549790620804\n",
      "trial: 3, iter: 6200, curr loss: 1.3723688125610352, avg loss: 1.3745076644420624\n",
      "trial: 3, ldr: 0.0013791148085147142\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3870868682861328, avg loss: 1.3870388382673264\n",
      "trial: 4, iter: 400, curr loss: 1.3838874101638794, avg loss: 1.3867334765195847\n",
      "trial: 4, iter: 600, curr loss: 1.3848025798797607, avg loss: 1.386602725982666\n",
      "trial: 4, iter: 800, curr loss: 1.386076807975769, avg loss: 1.386483986377716\n",
      "trial: 4, iter: 1000, curr loss: 1.3852601051330566, avg loss: 1.3864372223615646\n",
      "trial: 4, iter: 1200, curr loss: 1.3862344026565552, avg loss: 1.3864920657873154\n",
      "trial: 4, iter: 1400, curr loss: 1.386875033378601, avg loss: 1.386417020559311\n",
      "trial: 4, iter: 1600, curr loss: 1.3859905004501343, avg loss: 1.3864070415496825\n",
      "trial: 4, iter: 1800, curr loss: 1.3864563703536987, avg loss: 1.3863421839475631\n",
      "trial: 4, iter: 2000, curr loss: 1.3863096237182617, avg loss: 1.3863236922025681\n",
      "trial: 4, iter: 2200, curr loss: 1.3866180181503296, avg loss: 1.3863698089122771\n",
      "trial: 4, iter: 2400, curr loss: 1.3865891695022583, avg loss: 1.3862992030382157\n",
      "trial: 4, iter: 2600, curr loss: 1.3840441703796387, avg loss: 1.386256415247917\n",
      "trial: 4, iter: 2800, curr loss: 1.3878803253173828, avg loss: 1.386337358355522\n",
      "trial: 4, iter: 3000, curr loss: 1.3854718208312988, avg loss: 1.3863689768314362\n",
      "trial: 4, iter: 3200, curr loss: 1.3862769603729248, avg loss: 1.3862681019306182\n",
      "trial: 4, iter: 3400, curr loss: 1.3869259357452393, avg loss: 1.3862749654054642\n",
      "trial: 4, iter: 3600, curr loss: 1.3860993385314941, avg loss: 1.3861837393045426\n",
      "trial: 4, iter: 3800, curr loss: 1.3886862993240356, avg loss: 1.3862452298402785\n",
      "trial: 4, iter: 4000, curr loss: 1.3856624364852905, avg loss: 1.3861504298448564\n",
      "trial: 4, iter: 4200, curr loss: 1.3836824893951416, avg loss: 1.3860683488845824\n",
      "trial: 4, iter: 4400, curr loss: 1.3866115808486938, avg loss: 1.3859693813323974\n",
      "trial: 4, iter: 4600, curr loss: 1.3815433979034424, avg loss: 1.3856271636486053\n",
      "trial: 4, iter: 4800, curr loss: 1.3860516548156738, avg loss: 1.385382832288742\n",
      "trial: 4, iter: 5000, curr loss: 1.382920742034912, avg loss: 1.3847617346048355\n",
      "trial: 4, iter: 5200, curr loss: 1.3841114044189453, avg loss: 1.3838179290294648\n",
      "trial: 4, iter: 5400, curr loss: 1.3759404420852661, avg loss: 1.383421031832695\n",
      "trial: 4, iter: 5600, curr loss: 1.380013346672058, avg loss: 1.3816278219223022\n",
      "trial: 4, iter: 5800, curr loss: 1.3807278871536255, avg loss: 1.3809401088953017\n",
      "trial: 4, iter: 6000, curr loss: 1.3855564594268799, avg loss: 1.3792125189304352\n",
      "trial: 4, iter: 6200, curr loss: 1.3729703426361084, avg loss: 1.3779235565662384\n",
      "trial: 4, ldr: -0.008743898011744022\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3848228454589844, avg loss: 1.3872407138347627\n",
      "trial: 5, iter: 400, curr loss: 1.3860387802124023, avg loss: 1.3864563405513763\n",
      "trial: 5, iter: 600, curr loss: 1.3874843120574951, avg loss: 1.386580292582512\n",
      "trial: 5, iter: 800, curr loss: 1.3868705034255981, avg loss: 1.386551565527916\n",
      "trial: 5, iter: 1000, curr loss: 1.3875151872634888, avg loss: 1.3864049464464188\n",
      "trial: 5, iter: 1200, curr loss: 1.3867357969284058, avg loss: 1.386457638144493\n",
      "trial: 5, iter: 1400, curr loss: 1.387189269065857, avg loss: 1.3864048963785172\n",
      "trial: 5, iter: 1600, curr loss: 1.3845921754837036, avg loss: 1.3863261741399766\n",
      "trial: 5, iter: 1800, curr loss: 1.3861210346221924, avg loss: 1.3863376104831695\n",
      "trial: 5, iter: 2000, curr loss: 1.3853439092636108, avg loss: 1.3863250261545181\n",
      "trial: 5, iter: 2200, curr loss: 1.386677861213684, avg loss: 1.3863902699947357\n",
      "trial: 5, iter: 2400, curr loss: 1.387110710144043, avg loss: 1.386303099989891\n",
      "trial: 5, iter: 2600, curr loss: 1.384328842163086, avg loss: 1.3862520307302475\n",
      "trial: 5, iter: 2800, curr loss: 1.3856145143508911, avg loss: 1.3863214033842086\n",
      "trial: 5, iter: 3000, curr loss: 1.3875093460083008, avg loss: 1.3862016892433167\n",
      "trial: 5, iter: 3200, curr loss: 1.387495994567871, avg loss: 1.3862857788801193\n",
      "trial: 5, iter: 3400, curr loss: 1.3883798122406006, avg loss: 1.3861711841821671\n",
      "trial: 5, iter: 3600, curr loss: 1.384091854095459, avg loss: 1.3860109049081801\n",
      "trial: 5, iter: 3800, curr loss: 1.386515498161316, avg loss: 1.3860636478662491\n",
      "trial: 5, iter: 4000, curr loss: 1.3866273164749146, avg loss: 1.386159301996231\n",
      "trial: 5, iter: 4200, curr loss: 1.38456392288208, avg loss: 1.3859263426065445\n",
      "trial: 5, iter: 4400, curr loss: 1.3868889808654785, avg loss: 1.3857952058315277\n",
      "trial: 5, iter: 4600, curr loss: 1.3862740993499756, avg loss: 1.3857237666845321\n",
      "trial: 5, iter: 4800, curr loss: 1.3856900930404663, avg loss: 1.3850984644889832\n",
      "trial: 5, iter: 5000, curr loss: 1.3817996978759766, avg loss: 1.3851704436540604\n",
      "trial: 5, iter: 5200, curr loss: 1.3822225332260132, avg loss: 1.3842353385686874\n",
      "trial: 5, iter: 5400, curr loss: 1.3863489627838135, avg loss: 1.3832966327667235\n",
      "trial: 5, iter: 5600, curr loss: 1.3736339807510376, avg loss: 1.3823587274551392\n",
      "trial: 5, iter: 5800, curr loss: 1.3790791034698486, avg loss: 1.3813923060894013\n",
      "trial: 5, iter: 6000, curr loss: 1.3785940408706665, avg loss: 1.380165975689888\n",
      "trial: 5, iter: 6200, curr loss: 1.3743005990982056, avg loss: 1.3797874414920808\n",
      "trial: 5, ldr: 0.0020223488099873066\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0020393967628479005\n",
      "Experiment done with data path: ./data/catNon-lin-NI_3/data.20k.dz10.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_14/data.10k.dz100.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862762451171875, avg loss: 1.3881495690345764\n",
      "trial: 1, iter: 400, curr loss: 1.3853213787078857, avg loss: 1.3866491222381592\n",
      "trial: 1, iter: 600, curr loss: 1.3855689764022827, avg loss: 1.3865130883455277\n",
      "trial: 1, iter: 800, curr loss: 1.3864244222640991, avg loss: 1.386620655655861\n",
      "trial: 1, iter: 1000, curr loss: 1.3860968351364136, avg loss: 1.3863731211423873\n",
      "trial: 1, iter: 1200, curr loss: 1.386581540107727, avg loss: 1.3864927804470062\n",
      "trial: 1, iter: 1400, curr loss: 1.3868281841278076, avg loss: 1.3864997577667237\n",
      "trial: 1, iter: 1600, curr loss: 1.3865680694580078, avg loss: 1.38643445789814\n",
      "trial: 1, iter: 1800, curr loss: 1.3882802724838257, avg loss: 1.386426880955696\n",
      "trial: 1, iter: 2000, curr loss: 1.3862214088439941, avg loss: 1.386386497616768\n",
      "trial: 1, iter: 2200, curr loss: 1.386184573173523, avg loss: 1.3865241223573685\n",
      "trial: 1, iter: 2400, curr loss: 1.3859047889709473, avg loss: 1.3863950896263122\n",
      "trial: 1, iter: 2600, curr loss: 1.3863210678100586, avg loss: 1.38639888048172\n",
      "trial: 1, iter: 2800, curr loss: 1.387303113937378, avg loss: 1.3863074153661727\n",
      "trial: 1, iter: 3000, curr loss: 1.3862100839614868, avg loss: 1.3864573228359223\n",
      "trial: 1, ldr: -0.012366575188934803\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3858556747436523, avg loss: 1.3874649727344512\n",
      "trial: 2, iter: 400, curr loss: 1.3869483470916748, avg loss: 1.386817519068718\n",
      "trial: 2, iter: 600, curr loss: 1.3861989974975586, avg loss: 1.3865434616804122\n",
      "trial: 2, iter: 800, curr loss: 1.3858360052108765, avg loss: 1.3865511363744736\n",
      "trial: 2, iter: 1000, curr loss: 1.3860830068588257, avg loss: 1.38647775888443\n",
      "trial: 2, iter: 1200, curr loss: 1.386285662651062, avg loss: 1.3863663226366043\n",
      "trial: 2, iter: 1400, curr loss: 1.3853061199188232, avg loss: 1.3864455914497376\n",
      "trial: 2, iter: 1600, curr loss: 1.3875808715820312, avg loss: 1.3863765871524811\n",
      "trial: 2, iter: 1800, curr loss: 1.386130452156067, avg loss: 1.3863637030124665\n",
      "trial: 2, iter: 2000, curr loss: 1.3864814043045044, avg loss: 1.386357255578041\n",
      "trial: 2, iter: 2200, curr loss: 1.3859351873397827, avg loss: 1.3863035482168198\n",
      "trial: 2, iter: 2400, curr loss: 1.3852990865707397, avg loss: 1.3863178986310958\n",
      "trial: 2, iter: 2600, curr loss: 1.3866021633148193, avg loss: 1.3863488399982453\n",
      "trial: 2, iter: 2800, curr loss: 1.3864293098449707, avg loss: 1.3863917034864426\n",
      "trial: 2, iter: 3000, curr loss: 1.3860740661621094, avg loss: 1.3863868594169617\n",
      "trial: 2, ldr: -0.002982107223942876\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3836140632629395, avg loss: 1.3870898985862732\n",
      "trial: 3, iter: 400, curr loss: 1.3906837701797485, avg loss: 1.3866806435585022\n",
      "trial: 3, iter: 600, curr loss: 1.3888165950775146, avg loss: 1.386593029499054\n",
      "trial: 3, iter: 800, curr loss: 1.3888449668884277, avg loss: 1.3864535921812058\n",
      "trial: 3, iter: 1000, curr loss: 1.3854024410247803, avg loss: 1.386559225320816\n",
      "trial: 3, iter: 1200, curr loss: 1.3851146697998047, avg loss: 1.38647887468338\n",
      "trial: 3, iter: 1400, curr loss: 1.386570692062378, avg loss: 1.3864944916963577\n",
      "trial: 3, iter: 1600, curr loss: 1.385716199874878, avg loss: 1.3864226031303406\n",
      "trial: 3, iter: 1800, curr loss: 1.387383222579956, avg loss: 1.3863132309913635\n",
      "trial: 3, iter: 2000, curr loss: 1.3866932392120361, avg loss: 1.3864845043420793\n",
      "trial: 3, iter: 2200, curr loss: 1.3871992826461792, avg loss: 1.3864430016279221\n",
      "trial: 3, iter: 2400, curr loss: 1.386957049369812, avg loss: 1.3863705360889436\n",
      "trial: 3, iter: 2600, curr loss: 1.386635661125183, avg loss: 1.3863444530963898\n",
      "trial: 3, iter: 2800, curr loss: 1.3866416215896606, avg loss: 1.3863704216480255\n",
      "trial: 3, iter: 3000, curr loss: 1.3862806558609009, avg loss: 1.386359691619873\n",
      "trial: 3, ldr: -0.01043643243610859\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386888861656189, avg loss: 1.3875256568193435\n",
      "trial: 4, iter: 400, curr loss: 1.387296438217163, avg loss: 1.3866782248020173\n",
      "trial: 4, iter: 600, curr loss: 1.3849090337753296, avg loss: 1.3864813989400864\n",
      "trial: 4, iter: 800, curr loss: 1.3870359659194946, avg loss: 1.3864685678482056\n",
      "trial: 4, iter: 1000, curr loss: 1.387094259262085, avg loss: 1.3864752107858658\n",
      "trial: 4, iter: 1200, curr loss: 1.3874504566192627, avg loss: 1.3863374209403991\n",
      "trial: 4, iter: 1400, curr loss: 1.38593327999115, avg loss: 1.3863720828294754\n",
      "trial: 4, iter: 1600, curr loss: 1.3860281705856323, avg loss: 1.3864386969804763\n",
      "trial: 4, iter: 1800, curr loss: 1.385693907737732, avg loss: 1.3864549940824509\n",
      "trial: 4, iter: 2000, curr loss: 1.386525273323059, avg loss: 1.3863072949647903\n",
      "trial: 4, iter: 2200, curr loss: 1.3870837688446045, avg loss: 1.386370752453804\n",
      "trial: 4, iter: 2400, curr loss: 1.3841180801391602, avg loss: 1.3864306783676148\n",
      "trial: 4, iter: 2600, curr loss: 1.3870878219604492, avg loss: 1.3863935655355453\n",
      "trial: 4, iter: 2800, curr loss: 1.3882982730865479, avg loss: 1.386300802230835\n",
      "trial: 4, iter: 3000, curr loss: 1.3861560821533203, avg loss: 1.3864912247657777\n",
      "trial: 4, ldr: 0.01321343518793583\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.386648416519165, avg loss: 1.387161786556244\n",
      "trial: 5, iter: 400, curr loss: 1.3821873664855957, avg loss: 1.3866097283363343\n",
      "trial: 5, iter: 600, curr loss: 1.3827409744262695, avg loss: 1.3866385877132417\n",
      "trial: 5, iter: 800, curr loss: 1.3853778839111328, avg loss: 1.3865346693992615\n",
      "trial: 5, iter: 1000, curr loss: 1.383995771408081, avg loss: 1.386504665017128\n",
      "trial: 5, iter: 1200, curr loss: 1.3864738941192627, avg loss: 1.3864720541238784\n",
      "trial: 5, iter: 1400, curr loss: 1.3862072229385376, avg loss: 1.3864598566293715\n",
      "trial: 5, iter: 1600, curr loss: 1.3874672651290894, avg loss: 1.3863800913095474\n",
      "trial: 5, iter: 1800, curr loss: 1.3876653909683228, avg loss: 1.3863517093658446\n",
      "trial: 5, iter: 2000, curr loss: 1.3863096237182617, avg loss: 1.3863554358482362\n",
      "trial: 5, iter: 2200, curr loss: 1.3871036767959595, avg loss: 1.3864273607730866\n",
      "trial: 5, iter: 2400, curr loss: 1.3880865573883057, avg loss: 1.3863324493169784\n",
      "trial: 5, iter: 2600, curr loss: 1.3863056898117065, avg loss: 1.3864470630884171\n",
      "trial: 5, iter: 2800, curr loss: 1.3862475156784058, avg loss: 1.3863590723276138\n",
      "trial: 5, iter: 3000, curr loss: 1.3864428997039795, avg loss: 1.386372935771942\n",
      "trial: 5, ldr: -0.009599271230399609\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.00443419017829001\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3862327337265015, avg loss: 1.387281532883644\n",
      "trial: 1, iter: 400, curr loss: 1.386216640472412, avg loss: 1.3869836634397508\n",
      "trial: 1, iter: 600, curr loss: 1.3845306634902954, avg loss: 1.3865121245384215\n",
      "trial: 1, iter: 800, curr loss: 1.3865745067596436, avg loss: 1.3866259360313415\n",
      "trial: 1, iter: 1000, curr loss: 1.3866841793060303, avg loss: 1.386380667090416\n",
      "trial: 1, iter: 1200, curr loss: 1.3861985206604004, avg loss: 1.38644955098629\n",
      "trial: 1, iter: 1400, curr loss: 1.385079026222229, avg loss: 1.3864059728384017\n",
      "trial: 1, iter: 1600, curr loss: 1.3851313591003418, avg loss: 1.3863841539621353\n",
      "trial: 1, iter: 1800, curr loss: 1.3865936994552612, avg loss: 1.3863618242740632\n",
      "trial: 1, iter: 2000, curr loss: 1.3856334686279297, avg loss: 1.386452864408493\n",
      "trial: 1, iter: 2200, curr loss: 1.3853732347488403, avg loss: 1.3864552468061446\n",
      "trial: 1, iter: 2400, curr loss: 1.3861358165740967, avg loss: 1.3863751769065857\n",
      "trial: 1, iter: 2600, curr loss: 1.387224555015564, avg loss: 1.3864130991697312\n",
      "trial: 1, iter: 2800, curr loss: 1.3863294124603271, avg loss: 1.3863847655057908\n",
      "trial: 1, iter: 3000, curr loss: 1.385609745979309, avg loss: 1.3864024740457535\n",
      "trial: 1, ldr: 0.005266902502626181\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.385082721710205, avg loss: 1.3872309124469757\n",
      "trial: 2, iter: 400, curr loss: 1.385563850402832, avg loss: 1.38684009373188\n",
      "trial: 2, iter: 600, curr loss: 1.3848369121551514, avg loss: 1.3866545271873474\n",
      "trial: 2, iter: 800, curr loss: 1.3870844841003418, avg loss: 1.3864850747585296\n",
      "trial: 2, iter: 1000, curr loss: 1.385445237159729, avg loss: 1.3864557790756225\n",
      "trial: 2, iter: 1200, curr loss: 1.3891197443008423, avg loss: 1.386357238292694\n",
      "trial: 2, iter: 1400, curr loss: 1.386262059211731, avg loss: 1.3864120173454284\n",
      "trial: 2, iter: 1600, curr loss: 1.3858076333999634, avg loss: 1.3864640921354294\n",
      "trial: 2, iter: 1800, curr loss: 1.3858269453048706, avg loss: 1.3864294636249541\n",
      "trial: 2, iter: 2000, curr loss: 1.386324405670166, avg loss: 1.3863351440429688\n",
      "trial: 2, iter: 2200, curr loss: 1.3873041868209839, avg loss: 1.3863614350557327\n",
      "trial: 2, iter: 2400, curr loss: 1.3875433206558228, avg loss: 1.3863576966524125\n",
      "trial: 2, iter: 2600, curr loss: 1.386186122894287, avg loss: 1.386471379995346\n",
      "trial: 2, iter: 2800, curr loss: 1.38621985912323, avg loss: 1.3863188225030898\n",
      "trial: 2, iter: 3000, curr loss: 1.386047124862671, avg loss: 1.3863614511489868\n",
      "trial: 2, ldr: -0.0007402017363347113\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.385999083518982, avg loss: 1.3871835440397262\n",
      "trial: 3, iter: 400, curr loss: 1.3863943815231323, avg loss: 1.386782213449478\n",
      "trial: 3, iter: 600, curr loss: 1.387283444404602, avg loss: 1.3866833353042602\n",
      "trial: 3, iter: 800, curr loss: 1.3863157033920288, avg loss: 1.3864407414197921\n",
      "trial: 3, iter: 1000, curr loss: 1.3857866525650024, avg loss: 1.3864222627878189\n",
      "trial: 3, iter: 1200, curr loss: 1.3836851119995117, avg loss: 1.3864525043964386\n",
      "trial: 3, iter: 1400, curr loss: 1.3860018253326416, avg loss: 1.3864511227607728\n",
      "trial: 3, iter: 1600, curr loss: 1.3861416578292847, avg loss: 1.3864970183372498\n",
      "trial: 3, iter: 1800, curr loss: 1.386664628982544, avg loss: 1.3864057910442353\n",
      "trial: 3, iter: 2000, curr loss: 1.3869352340698242, avg loss: 1.386462932229042\n",
      "trial: 3, iter: 2200, curr loss: 1.3862271308898926, avg loss: 1.3864344215393067\n",
      "trial: 3, iter: 2400, curr loss: 1.3857446908950806, avg loss: 1.3864526617527009\n",
      "trial: 3, iter: 2600, curr loss: 1.385575294494629, avg loss: 1.3864415365457534\n",
      "trial: 3, iter: 2800, curr loss: 1.3866125345230103, avg loss: 1.3864778035879135\n",
      "trial: 3, iter: 3000, curr loss: 1.386636734008789, avg loss: 1.3864467245340348\n",
      "trial: 3, ldr: -0.006446049548685551\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3878557682037354, avg loss: 1.3874913090467453\n",
      "trial: 4, iter: 400, curr loss: 1.3845540285110474, avg loss: 1.386832708120346\n",
      "trial: 4, iter: 600, curr loss: 1.3882092237472534, avg loss: 1.3864696025848389\n",
      "trial: 4, iter: 800, curr loss: 1.3877582550048828, avg loss: 1.3866162818670273\n",
      "trial: 4, iter: 1000, curr loss: 1.3855575323104858, avg loss: 1.386466326713562\n",
      "trial: 4, iter: 1200, curr loss: 1.387134075164795, avg loss: 1.3864246165752412\n",
      "trial: 4, iter: 1400, curr loss: 1.3852708339691162, avg loss: 1.3864314305782317\n",
      "trial: 4, iter: 1600, curr loss: 1.3868389129638672, avg loss: 1.386367092728615\n",
      "trial: 4, iter: 1800, curr loss: 1.3866831064224243, avg loss: 1.386385428905487\n",
      "trial: 4, iter: 2000, curr loss: 1.3857636451721191, avg loss: 1.3863459825515747\n",
      "trial: 4, iter: 2200, curr loss: 1.3861372470855713, avg loss: 1.3863505512475967\n",
      "trial: 4, iter: 2400, curr loss: 1.386819839477539, avg loss: 1.386289363503456\n",
      "trial: 4, iter: 2600, curr loss: 1.3872214555740356, avg loss: 1.3863803946971893\n",
      "trial: 4, iter: 2800, curr loss: 1.3877718448638916, avg loss: 1.386379233598709\n",
      "trial: 4, iter: 3000, curr loss: 1.3864344358444214, avg loss: 1.3862785851955415\n",
      "trial: 4, ldr: -0.012843878008425236\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3880066871643066, avg loss: 1.3871762561798096\n",
      "trial: 5, iter: 400, curr loss: 1.3849828243255615, avg loss: 1.386584958434105\n",
      "trial: 5, iter: 600, curr loss: 1.3861037492752075, avg loss: 1.3865922230482102\n",
      "trial: 5, iter: 800, curr loss: 1.3871395587921143, avg loss: 1.386521635055542\n",
      "trial: 5, iter: 1000, curr loss: 1.386323094367981, avg loss: 1.3864132076501847\n",
      "trial: 5, iter: 1200, curr loss: 1.3870285749435425, avg loss: 1.3863824236392974\n",
      "trial: 5, iter: 1400, curr loss: 1.3857603073120117, avg loss: 1.3864912647008896\n",
      "trial: 5, iter: 1600, curr loss: 1.387612223625183, avg loss: 1.3864650112390517\n",
      "trial: 5, iter: 1800, curr loss: 1.3862934112548828, avg loss: 1.3863451528549193\n",
      "trial: 5, iter: 2000, curr loss: 1.3860441446304321, avg loss: 1.386269770860672\n",
      "trial: 5, iter: 2200, curr loss: 1.3858729600906372, avg loss: 1.386359353661537\n",
      "trial: 5, iter: 2400, curr loss: 1.3858669996261597, avg loss: 1.3863622784614562\n",
      "trial: 5, iter: 2600, curr loss: 1.3865333795547485, avg loss: 1.3863283944129945\n",
      "trial: 5, iter: 2800, curr loss: 1.386236310005188, avg loss: 1.3863922297954558\n",
      "trial: 5, iter: 3000, curr loss: 1.386259913444519, avg loss: 1.386221427321434\n",
      "trial: 5, ldr: 0.006311164237558842\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0016904125106520951\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.385219693183899, avg loss: 1.3874596285820007\n",
      "trial: 1, iter: 400, curr loss: 1.3873695135116577, avg loss: 1.3866191679239273\n",
      "trial: 1, iter: 600, curr loss: 1.3864754438400269, avg loss: 1.386705645918846\n",
      "trial: 1, iter: 800, curr loss: 1.3877078294754028, avg loss: 1.3865033507347106\n",
      "trial: 1, iter: 1000, curr loss: 1.386171817779541, avg loss: 1.3867064553499222\n",
      "trial: 1, iter: 1200, curr loss: 1.3861829042434692, avg loss: 1.3864230191707612\n",
      "trial: 1, iter: 1400, curr loss: 1.3865764141082764, avg loss: 1.3864784920215607\n",
      "trial: 1, iter: 1600, curr loss: 1.3866692781448364, avg loss: 1.3863594490289688\n",
      "trial: 1, iter: 1800, curr loss: 1.3845887184143066, avg loss: 1.386400974392891\n",
      "trial: 1, iter: 2000, curr loss: 1.386926531791687, avg loss: 1.3863631445169449\n",
      "trial: 1, iter: 2200, curr loss: 1.386399269104004, avg loss: 1.3863707065582276\n",
      "trial: 1, iter: 2400, curr loss: 1.386548638343811, avg loss: 1.386376321911812\n",
      "trial: 1, iter: 2600, curr loss: 1.3876588344573975, avg loss: 1.3863392657041549\n",
      "trial: 1, iter: 2800, curr loss: 1.38571298122406, avg loss: 1.3862919282913209\n",
      "trial: 1, iter: 3000, curr loss: 1.3858171701431274, avg loss: 1.3863839721679687\n",
      "trial: 1, ldr: 0.007308827247470617\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3893555402755737, avg loss: 1.3872235572338105\n",
      "trial: 2, iter: 400, curr loss: 1.3856929540634155, avg loss: 1.3866405701637268\n",
      "trial: 2, iter: 600, curr loss: 1.3849818706512451, avg loss: 1.3866028904914856\n",
      "trial: 2, iter: 800, curr loss: 1.3865711688995361, avg loss: 1.3865681964159011\n",
      "trial: 2, iter: 1000, curr loss: 1.3859338760375977, avg loss: 1.386584226489067\n",
      "trial: 2, iter: 1200, curr loss: 1.3865764141082764, avg loss: 1.3863886255025863\n",
      "trial: 2, iter: 1400, curr loss: 1.3855592012405396, avg loss: 1.3864707660675049\n",
      "trial: 2, iter: 1600, curr loss: 1.3869067430496216, avg loss: 1.3864821755886079\n",
      "trial: 2, iter: 1800, curr loss: 1.388104796409607, avg loss: 1.3864716827869414\n",
      "trial: 2, iter: 2000, curr loss: 1.386415958404541, avg loss: 1.3864381462335587\n",
      "trial: 2, iter: 2200, curr loss: 1.3859094381332397, avg loss: 1.3863667047023773\n",
      "trial: 2, iter: 2400, curr loss: 1.3859081268310547, avg loss: 1.3864529144763946\n",
      "trial: 2, iter: 2600, curr loss: 1.3860574960708618, avg loss: 1.3864017748832702\n",
      "trial: 2, iter: 2800, curr loss: 1.3866915702819824, avg loss: 1.3863431358337401\n",
      "trial: 2, iter: 3000, curr loss: 1.3866066932678223, avg loss: 1.3863905990123748\n",
      "trial: 2, ldr: 0.017779666930437088\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3880870342254639, avg loss: 1.387313838005066\n",
      "trial: 3, iter: 400, curr loss: 1.3870525360107422, avg loss: 1.3869390040636063\n",
      "trial: 3, iter: 600, curr loss: 1.3835479021072388, avg loss: 1.3865844106674194\n",
      "trial: 3, iter: 800, curr loss: 1.3845245838165283, avg loss: 1.3863892191648484\n",
      "trial: 3, iter: 1000, curr loss: 1.3859957456588745, avg loss: 1.3864748311042785\n",
      "trial: 3, iter: 1200, curr loss: 1.3857372999191284, avg loss: 1.3863505363464355\n",
      "trial: 3, iter: 1400, curr loss: 1.3860273361206055, avg loss: 1.3864744782447815\n",
      "trial: 3, iter: 1600, curr loss: 1.3854230642318726, avg loss: 1.3863800495862961\n",
      "trial: 3, iter: 1800, curr loss: 1.3862510919570923, avg loss: 1.3863728922605514\n",
      "trial: 3, iter: 2000, curr loss: 1.3863246440887451, avg loss: 1.3863986986875534\n",
      "trial: 3, iter: 2200, curr loss: 1.387252926826477, avg loss: 1.3863880264759063\n",
      "trial: 3, iter: 2400, curr loss: 1.385906457901001, avg loss: 1.3863821178674698\n",
      "trial: 3, iter: 2600, curr loss: 1.3856457471847534, avg loss: 1.3863779133558274\n",
      "trial: 3, iter: 2800, curr loss: 1.3868358135223389, avg loss: 1.3863626343011857\n",
      "trial: 3, iter: 3000, curr loss: 1.3862501382827759, avg loss: 1.3864114332199096\n",
      "trial: 3, ldr: 0.0134807163849473\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3881034851074219, avg loss: 1.387399171590805\n",
      "trial: 4, iter: 400, curr loss: 1.3889843225479126, avg loss: 1.3868155890703202\n",
      "trial: 4, iter: 600, curr loss: 1.3874835968017578, avg loss: 1.3867578703165053\n",
      "trial: 4, iter: 800, curr loss: 1.3865249156951904, avg loss: 1.3863680052757263\n",
      "trial: 4, iter: 1000, curr loss: 1.3875060081481934, avg loss: 1.386472383737564\n",
      "trial: 4, iter: 1200, curr loss: 1.3855931758880615, avg loss: 1.3864085966348647\n",
      "trial: 4, iter: 1400, curr loss: 1.3861122131347656, avg loss: 1.3863891702890396\n",
      "trial: 4, iter: 1600, curr loss: 1.3850164413452148, avg loss: 1.3863053333759308\n",
      "trial: 4, iter: 1800, curr loss: 1.386936068534851, avg loss: 1.3863827335834502\n",
      "trial: 4, iter: 2000, curr loss: 1.3859697580337524, avg loss: 1.3864042413234712\n",
      "trial: 4, iter: 2200, curr loss: 1.386310338973999, avg loss: 1.3863953948020935\n",
      "trial: 4, iter: 2400, curr loss: 1.3858044147491455, avg loss: 1.3863083028793335\n",
      "trial: 4, iter: 2600, curr loss: 1.3846909999847412, avg loss: 1.3863033717870712\n",
      "trial: 4, iter: 2800, curr loss: 1.3863836526870728, avg loss: 1.3864173674583435\n",
      "trial: 4, iter: 3000, curr loss: 1.3864803314208984, avg loss: 1.386330550312996\n",
      "trial: 4, ldr: -0.0075048645958304405\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3869147300720215, avg loss: 1.3872669380903244\n",
      "trial: 5, iter: 400, curr loss: 1.3882149457931519, avg loss: 1.3868575066328048\n",
      "trial: 5, iter: 600, curr loss: 1.3865333795547485, avg loss: 1.3865594452619552\n",
      "trial: 5, iter: 800, curr loss: 1.3888556957244873, avg loss: 1.386463199853897\n",
      "trial: 5, iter: 1000, curr loss: 1.38687264919281, avg loss: 1.3864284539222718\n",
      "trial: 5, iter: 1200, curr loss: 1.3859407901763916, avg loss: 1.3865077275037765\n",
      "trial: 5, iter: 1400, curr loss: 1.3880784511566162, avg loss: 1.3864324826002121\n",
      "trial: 5, iter: 1600, curr loss: 1.3858962059020996, avg loss: 1.386429918408394\n",
      "trial: 5, iter: 1800, curr loss: 1.3836623430252075, avg loss: 1.3863265377283096\n",
      "trial: 5, iter: 2000, curr loss: 1.3864655494689941, avg loss: 1.3864039582014085\n",
      "trial: 5, iter: 2200, curr loss: 1.3865954875946045, avg loss: 1.3863881021738051\n",
      "trial: 5, iter: 2400, curr loss: 1.3872756958007812, avg loss: 1.3863723272085189\n",
      "trial: 5, iter: 2600, curr loss: 1.3865923881530762, avg loss: 1.386333526968956\n",
      "trial: 5, iter: 2800, curr loss: 1.3877631425857544, avg loss: 1.3864001339673997\n",
      "trial: 5, iter: 3000, curr loss: 1.3861685991287231, avg loss: 1.3863746100664138\n",
      "trial: 5, ldr: 0.014287186786532402\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.009070306550711393\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3894509077072144, avg loss: 1.387296434044838\n",
      "trial: 1, iter: 400, curr loss: 1.3869473934173584, avg loss: 1.3867528712749482\n",
      "trial: 1, iter: 600, curr loss: 1.3874906301498413, avg loss: 1.3866478455066682\n",
      "trial: 1, iter: 800, curr loss: 1.3881862163543701, avg loss: 1.3864534413814544\n",
      "trial: 1, iter: 1000, curr loss: 1.3859636783599854, avg loss: 1.3863800567388536\n",
      "trial: 1, iter: 1200, curr loss: 1.3862262964248657, avg loss: 1.3865106934309006\n",
      "trial: 1, iter: 1400, curr loss: 1.3875226974487305, avg loss: 1.3863450127840042\n",
      "trial: 1, iter: 1600, curr loss: 1.3856691122055054, avg loss: 1.386373838186264\n",
      "trial: 1, iter: 1800, curr loss: 1.3877756595611572, avg loss: 1.386335659623146\n",
      "trial: 1, iter: 2000, curr loss: 1.3870898485183716, avg loss: 1.386449471116066\n",
      "trial: 1, iter: 2200, curr loss: 1.385511875152588, avg loss: 1.386387249827385\n",
      "trial: 1, iter: 2400, curr loss: 1.3865506649017334, avg loss: 1.386323093175888\n",
      "trial: 1, iter: 2600, curr loss: 1.3866175413131714, avg loss: 1.3863551640510559\n",
      "trial: 1, iter: 2800, curr loss: 1.385348916053772, avg loss: 1.3863543856143952\n",
      "trial: 1, iter: 3000, curr loss: 1.3860057592391968, avg loss: 1.3863064461946488\n",
      "trial: 1, ldr: 0.0024827534798532724\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3876514434814453, avg loss: 1.386985719203949\n",
      "trial: 2, iter: 400, curr loss: 1.3856828212738037, avg loss: 1.3867247432470322\n",
      "trial: 2, iter: 600, curr loss: 1.3864490985870361, avg loss: 1.3865571331977844\n",
      "trial: 2, iter: 800, curr loss: 1.3850212097167969, avg loss: 1.3863208055496217\n",
      "trial: 2, iter: 1000, curr loss: 1.3851017951965332, avg loss: 1.3865479415655135\n",
      "trial: 2, iter: 1200, curr loss: 1.3867861032485962, avg loss: 1.3862835985422135\n",
      "trial: 2, iter: 1400, curr loss: 1.386126160621643, avg loss: 1.3865207237005235\n",
      "trial: 2, iter: 1600, curr loss: 1.386984944343567, avg loss: 1.3863598376512527\n",
      "trial: 2, iter: 1800, curr loss: 1.3865004777908325, avg loss: 1.386388748884201\n",
      "trial: 2, iter: 2000, curr loss: 1.3856521844863892, avg loss: 1.3863760775327683\n",
      "trial: 2, iter: 2200, curr loss: 1.3859716653823853, avg loss: 1.3863753020763396\n",
      "trial: 2, iter: 2400, curr loss: 1.387068748474121, avg loss: 1.3863656258583068\n",
      "trial: 2, iter: 2600, curr loss: 1.3874157667160034, avg loss: 1.386389166712761\n",
      "trial: 2, iter: 2800, curr loss: 1.3853774070739746, avg loss: 1.3863474857807159\n",
      "trial: 2, iter: 3000, curr loss: 1.3866888284683228, avg loss: 1.3863603138923646\n",
      "trial: 2, ldr: -0.007864009588956833\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3875657320022583, avg loss: 1.387334840297699\n",
      "trial: 3, iter: 400, curr loss: 1.3886069059371948, avg loss: 1.386774789094925\n",
      "trial: 3, iter: 600, curr loss: 1.3843142986297607, avg loss: 1.3865873146057128\n",
      "trial: 3, iter: 800, curr loss: 1.3865169286727905, avg loss: 1.3865269154310227\n",
      "trial: 3, iter: 1000, curr loss: 1.3863580226898193, avg loss: 1.3865441167354584\n",
      "trial: 3, iter: 1200, curr loss: 1.3849411010742188, avg loss: 1.3864001500606538\n",
      "trial: 3, iter: 1400, curr loss: 1.3878587484359741, avg loss: 1.3863702565431595\n",
      "trial: 3, iter: 1600, curr loss: 1.3856920003890991, avg loss: 1.3862793761491776\n",
      "trial: 3, iter: 1800, curr loss: 1.385342001914978, avg loss: 1.386411657333374\n",
      "trial: 3, iter: 2000, curr loss: 1.3847001791000366, avg loss: 1.3863401836156846\n",
      "trial: 3, iter: 2200, curr loss: 1.3860505819320679, avg loss: 1.3863810300827026\n",
      "trial: 3, iter: 2400, curr loss: 1.3860090970993042, avg loss: 1.3863297182321548\n",
      "trial: 3, iter: 2600, curr loss: 1.3853180408477783, avg loss: 1.3863244324922561\n",
      "trial: 3, iter: 2800, curr loss: 1.385701060295105, avg loss: 1.3863069015741347\n",
      "trial: 3, iter: 3000, curr loss: 1.385441780090332, avg loss: 1.3863624823093414\n",
      "trial: 3, ldr: 0.0001976868079509586\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3877464532852173, avg loss: 1.387377579808235\n",
      "trial: 4, iter: 400, curr loss: 1.3871797323226929, avg loss: 1.386557247042656\n",
      "trial: 4, iter: 600, curr loss: 1.384423851966858, avg loss: 1.3866234678030014\n",
      "trial: 4, iter: 800, curr loss: 1.3858486413955688, avg loss: 1.386502707004547\n",
      "trial: 4, iter: 1000, curr loss: 1.3851451873779297, avg loss: 1.3864361119270325\n",
      "trial: 4, iter: 1200, curr loss: 1.3875322341918945, avg loss: 1.3862705314159394\n",
      "trial: 4, iter: 1400, curr loss: 1.386858582496643, avg loss: 1.3864646995067595\n",
      "trial: 4, iter: 1600, curr loss: 1.3866184949874878, avg loss: 1.3863915199041366\n",
      "trial: 4, iter: 1800, curr loss: 1.3857700824737549, avg loss: 1.3862979626655578\n",
      "trial: 4, iter: 2000, curr loss: 1.3852667808532715, avg loss: 1.386363024711609\n",
      "trial: 4, iter: 2200, curr loss: 1.3849319219589233, avg loss: 1.3864172512292863\n",
      "trial: 4, iter: 2400, curr loss: 1.3865278959274292, avg loss: 1.3863351905345918\n",
      "trial: 4, iter: 2600, curr loss: 1.387556791305542, avg loss: 1.386254141330719\n",
      "trial: 4, iter: 2800, curr loss: 1.3861637115478516, avg loss: 1.3864248067140579\n",
      "trial: 4, iter: 3000, curr loss: 1.3869539499282837, avg loss: 1.3863116264343263\n",
      "trial: 4, ldr: -0.005235247313976288\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3896055221557617, avg loss: 1.387226249575615\n",
      "trial: 5, iter: 400, curr loss: 1.3859448432922363, avg loss: 1.3867366683483124\n",
      "trial: 5, iter: 600, curr loss: 1.3863246440887451, avg loss: 1.3865323150157929\n",
      "trial: 5, iter: 800, curr loss: 1.3874094486236572, avg loss: 1.3865667933225632\n",
      "trial: 5, iter: 1000, curr loss: 1.384450912475586, avg loss: 1.3864321857690811\n",
      "trial: 5, iter: 1200, curr loss: 1.3869963884353638, avg loss: 1.3863947975635529\n",
      "trial: 5, iter: 1400, curr loss: 1.3853377103805542, avg loss: 1.3864160424470902\n",
      "trial: 5, iter: 1600, curr loss: 1.3865896463394165, avg loss: 1.3863474571704864\n",
      "trial: 5, iter: 1800, curr loss: 1.3865573406219482, avg loss: 1.386404306292534\n",
      "trial: 5, iter: 2000, curr loss: 1.3864424228668213, avg loss: 1.386392852663994\n",
      "trial: 5, iter: 2200, curr loss: 1.3865126371383667, avg loss: 1.3863669312000275\n",
      "trial: 5, iter: 2400, curr loss: 1.3866832256317139, avg loss: 1.3863347172737122\n",
      "trial: 5, iter: 2600, curr loss: 1.3869093656539917, avg loss: 1.3863107639551162\n",
      "trial: 5, iter: 2800, curr loss: 1.3860071897506714, avg loss: 1.3863978350162507\n",
      "trial: 5, iter: 3000, curr loss: 1.3863844871520996, avg loss: 1.386307310461998\n",
      "trial: 5, ldr: -0.004243600647896528\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0029324834526050837\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386928677558899, avg loss: 1.3871892005205155\n",
      "trial: 1, iter: 400, curr loss: 1.3851683139801025, avg loss: 1.3867939841747283\n",
      "trial: 1, iter: 600, curr loss: 1.3855464458465576, avg loss: 1.3866786962747575\n",
      "trial: 1, iter: 800, curr loss: 1.3860470056533813, avg loss: 1.3864802968502046\n",
      "trial: 1, iter: 1000, curr loss: 1.387489914894104, avg loss: 1.3863827401399613\n",
      "trial: 1, iter: 1200, curr loss: 1.3881456851959229, avg loss: 1.3863122689723968\n",
      "trial: 1, iter: 1400, curr loss: 1.3842661380767822, avg loss: 1.386354260444641\n",
      "trial: 1, iter: 1600, curr loss: 1.3853648900985718, avg loss: 1.3864116352796554\n",
      "trial: 1, iter: 1800, curr loss: 1.3858394622802734, avg loss: 1.3864081782102584\n",
      "trial: 1, iter: 2000, curr loss: 1.3864778280258179, avg loss: 1.386364597082138\n",
      "trial: 1, iter: 2200, curr loss: 1.3862597942352295, avg loss: 1.3863233828544617\n",
      "trial: 1, iter: 2400, curr loss: 1.386627197265625, avg loss: 1.3863258004188537\n",
      "trial: 1, iter: 2600, curr loss: 1.3861613273620605, avg loss: 1.386343048810959\n",
      "trial: 1, iter: 2800, curr loss: 1.3866435289382935, avg loss: 1.3863256019353867\n",
      "trial: 1, iter: 3000, curr loss: 1.3854576349258423, avg loss: 1.3863338834047318\n",
      "trial: 1, ldr: 0.009350460954010487\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866955041885376, avg loss: 1.3874149632453918\n",
      "trial: 2, iter: 400, curr loss: 1.3882404565811157, avg loss: 1.3868826180696487\n",
      "trial: 2, iter: 600, curr loss: 1.3865164518356323, avg loss: 1.3866118413209916\n",
      "trial: 2, iter: 800, curr loss: 1.3867883682250977, avg loss: 1.3864772713184357\n",
      "trial: 2, iter: 1000, curr loss: 1.3871033191680908, avg loss: 1.3866211867332459\n",
      "trial: 2, iter: 1200, curr loss: 1.387546420097351, avg loss: 1.386549590229988\n",
      "trial: 2, iter: 1400, curr loss: 1.3866379261016846, avg loss: 1.3864334988594056\n",
      "trial: 2, iter: 1600, curr loss: 1.3864352703094482, avg loss: 1.3865052354335785\n",
      "trial: 2, iter: 1800, curr loss: 1.3868820667266846, avg loss: 1.3863356816768646\n",
      "trial: 2, iter: 2000, curr loss: 1.385797381401062, avg loss: 1.3863481265306472\n",
      "trial: 2, iter: 2200, curr loss: 1.385871410369873, avg loss: 1.3864526295661925\n",
      "trial: 2, iter: 2400, curr loss: 1.3864471912384033, avg loss: 1.3863769888877868\n",
      "trial: 2, iter: 2600, curr loss: 1.38679039478302, avg loss: 1.386349492073059\n",
      "trial: 2, iter: 2800, curr loss: 1.3860125541687012, avg loss: 1.3863391160964966\n",
      "trial: 2, iter: 3000, curr loss: 1.386471152305603, avg loss: 1.3863089662790298\n",
      "trial: 2, ldr: -0.004943646490573883\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3848364353179932, avg loss: 1.3871876162290573\n",
      "trial: 3, iter: 400, curr loss: 1.3859225511550903, avg loss: 1.386670634150505\n",
      "trial: 3, iter: 600, curr loss: 1.3886282444000244, avg loss: 1.3864336401224135\n",
      "trial: 3, iter: 800, curr loss: 1.3862940073013306, avg loss: 1.3865368145704269\n",
      "trial: 3, iter: 1000, curr loss: 1.3868224620819092, avg loss: 1.386382839679718\n",
      "trial: 3, iter: 1200, curr loss: 1.3859657049179077, avg loss: 1.3864556384086608\n",
      "trial: 3, iter: 1400, curr loss: 1.384488582611084, avg loss: 1.3864684009552002\n",
      "trial: 3, iter: 1600, curr loss: 1.385850429534912, avg loss: 1.3863773828744888\n",
      "trial: 3, iter: 1800, curr loss: 1.3864785432815552, avg loss: 1.3864047861099242\n",
      "trial: 3, iter: 2000, curr loss: 1.386012315750122, avg loss: 1.3864587765932084\n",
      "trial: 3, iter: 2200, curr loss: 1.3871463537216187, avg loss: 1.386369137763977\n",
      "trial: 3, iter: 2400, curr loss: 1.386636734008789, avg loss: 1.3864031344652177\n",
      "trial: 3, iter: 2600, curr loss: 1.3873162269592285, avg loss: 1.3863492166996003\n",
      "trial: 3, iter: 2800, curr loss: 1.3866710662841797, avg loss: 1.3863583797216414\n",
      "trial: 3, iter: 3000, curr loss: 1.3863812685012817, avg loss: 1.3863368982076645\n",
      "trial: 3, ldr: -3.779648250201717e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3837761878967285, avg loss: 1.387140298485756\n",
      "trial: 4, iter: 400, curr loss: 1.387108564376831, avg loss: 1.38675832092762\n",
      "trial: 4, iter: 600, curr loss: 1.3852026462554932, avg loss: 1.3866232138872148\n",
      "trial: 4, iter: 800, curr loss: 1.3853906393051147, avg loss: 1.386503700017929\n",
      "trial: 4, iter: 1000, curr loss: 1.3863248825073242, avg loss: 1.3863698953390122\n",
      "trial: 4, iter: 1200, curr loss: 1.3855009078979492, avg loss: 1.386408159136772\n",
      "trial: 4, iter: 1400, curr loss: 1.3853490352630615, avg loss: 1.3865251976251602\n",
      "trial: 4, iter: 1600, curr loss: 1.3862028121948242, avg loss: 1.3864475828409195\n",
      "trial: 4, iter: 1800, curr loss: 1.3875219821929932, avg loss: 1.3863507628440856\n",
      "trial: 4, iter: 2000, curr loss: 1.3874030113220215, avg loss: 1.3862793779373168\n",
      "trial: 4, iter: 2200, curr loss: 1.3863646984100342, avg loss: 1.3863865077495574\n",
      "trial: 4, iter: 2400, curr loss: 1.3865032196044922, avg loss: 1.386387863755226\n",
      "trial: 4, iter: 2600, curr loss: 1.3859657049179077, avg loss: 1.3864072287082672\n",
      "trial: 4, iter: 2800, curr loss: 1.3855583667755127, avg loss: 1.3863934129476547\n",
      "trial: 4, iter: 3000, curr loss: 1.3870651721954346, avg loss: 1.3863300931453706\n",
      "trial: 4, ldr: -0.006099965889006853\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3883813619613647, avg loss: 1.3872438097000122\n",
      "trial: 5, iter: 400, curr loss: 1.3855992555618286, avg loss: 1.3865581202507018\n",
      "trial: 5, iter: 600, curr loss: 1.3853639364242554, avg loss: 1.386590742468834\n",
      "trial: 5, iter: 800, curr loss: 1.386205792427063, avg loss: 1.386491785645485\n",
      "trial: 5, iter: 1000, curr loss: 1.384100079536438, avg loss: 1.3864346742630005\n",
      "trial: 5, iter: 1200, curr loss: 1.3849698305130005, avg loss: 1.386425142288208\n",
      "trial: 5, iter: 1400, curr loss: 1.3874412775039673, avg loss: 1.3864208763837815\n",
      "trial: 5, iter: 1600, curr loss: 1.38565194606781, avg loss: 1.3863493716716766\n",
      "trial: 5, iter: 1800, curr loss: 1.386675477027893, avg loss: 1.3862940913438797\n",
      "trial: 5, iter: 2000, curr loss: 1.3866297006607056, avg loss: 1.3863320815563203\n",
      "trial: 5, iter: 2200, curr loss: 1.3865119218826294, avg loss: 1.386369097828865\n",
      "trial: 5, iter: 2400, curr loss: 1.387325644493103, avg loss: 1.3863197553157807\n",
      "trial: 5, iter: 2600, curr loss: 1.3861217498779297, avg loss: 1.3863680857419967\n",
      "trial: 5, iter: 2800, curr loss: 1.386857271194458, avg loss: 1.3863254547119142\n",
      "trial: 5, iter: 3000, curr loss: 1.3866431713104248, avg loss: 1.3863709354400635\n",
      "trial: 5, ldr: -0.012341463007032871\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0028144821830210277\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3832086324691772, avg loss: 1.3873057812452316\n",
      "trial: 1, iter: 400, curr loss: 1.3840901851654053, avg loss: 1.3868846660852432\n",
      "trial: 1, iter: 600, curr loss: 1.3890525102615356, avg loss: 1.3864838677644729\n",
      "trial: 1, iter: 800, curr loss: 1.3876020908355713, avg loss: 1.386641297340393\n",
      "trial: 1, iter: 1000, curr loss: 1.3860002756118774, avg loss: 1.3864661473035813\n",
      "trial: 1, iter: 1200, curr loss: 1.3876852989196777, avg loss: 1.3864773494005203\n",
      "trial: 1, iter: 1400, curr loss: 1.386586308479309, avg loss: 1.3864554303884506\n",
      "trial: 1, iter: 1600, curr loss: 1.3880764245986938, avg loss: 1.3864464098215104\n",
      "trial: 1, iter: 1800, curr loss: 1.3856897354125977, avg loss: 1.3863941115140914\n",
      "trial: 1, iter: 2000, curr loss: 1.38617742061615, avg loss: 1.3863972324132918\n",
      "trial: 1, iter: 2200, curr loss: 1.3862481117248535, avg loss: 1.386385636329651\n",
      "trial: 1, iter: 2400, curr loss: 1.3863486051559448, avg loss: 1.3864145374298096\n",
      "trial: 1, iter: 2600, curr loss: 1.38569176197052, avg loss: 1.3863230377435685\n",
      "trial: 1, iter: 2800, curr loss: 1.3863648176193237, avg loss: 1.3862682479619979\n",
      "trial: 1, iter: 3000, curr loss: 1.3863474130630493, avg loss: 1.3863499188423156\n",
      "trial: 1, ldr: -0.00290574599057436\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849828243255615, avg loss: 1.3873413211107255\n",
      "trial: 2, iter: 400, curr loss: 1.3879457712173462, avg loss: 1.3866883683204652\n",
      "trial: 2, iter: 600, curr loss: 1.3865931034088135, avg loss: 1.3865476644039154\n",
      "trial: 2, iter: 800, curr loss: 1.385282278060913, avg loss: 1.3864972692728044\n",
      "trial: 2, iter: 1000, curr loss: 1.3870151042938232, avg loss: 1.3864894944429398\n",
      "trial: 2, iter: 1200, curr loss: 1.3859375715255737, avg loss: 1.386450651884079\n",
      "trial: 2, iter: 1400, curr loss: 1.3862833976745605, avg loss: 1.3863958197832107\n",
      "trial: 2, iter: 1600, curr loss: 1.388024926185608, avg loss: 1.3863844162225722\n",
      "trial: 2, iter: 1800, curr loss: 1.386311650276184, avg loss: 1.386372933983803\n",
      "trial: 2, iter: 2000, curr loss: 1.385790228843689, avg loss: 1.386342785358429\n",
      "trial: 2, iter: 2200, curr loss: 1.3861161470413208, avg loss: 1.3863063204288482\n",
      "trial: 2, iter: 2400, curr loss: 1.3866910934448242, avg loss: 1.3863270097970963\n",
      "trial: 2, iter: 2600, curr loss: 1.3852672576904297, avg loss: 1.3863333284854888\n",
      "trial: 2, iter: 2800, curr loss: 1.386536955833435, avg loss: 1.3863255167007447\n",
      "trial: 2, iter: 3000, curr loss: 1.3863388299942017, avg loss: 1.3863670367002487\n",
      "trial: 2, ldr: -0.009581521153450012\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3847057819366455, avg loss: 1.3875199413299562\n",
      "trial: 3, iter: 400, curr loss: 1.3827779293060303, avg loss: 1.3865744787454606\n",
      "trial: 3, iter: 600, curr loss: 1.3865699768066406, avg loss: 1.3867577546834946\n",
      "trial: 3, iter: 800, curr loss: 1.386353611946106, avg loss: 1.386419182419777\n",
      "trial: 3, iter: 1000, curr loss: 1.3865249156951904, avg loss: 1.386497060060501\n",
      "trial: 3, iter: 1200, curr loss: 1.3875021934509277, avg loss: 1.3864523887634277\n",
      "trial: 3, iter: 1400, curr loss: 1.3857851028442383, avg loss: 1.3863684636354447\n",
      "trial: 3, iter: 1600, curr loss: 1.387305736541748, avg loss: 1.3863397246599198\n",
      "trial: 3, iter: 1800, curr loss: 1.386496901512146, avg loss: 1.386387267112732\n",
      "trial: 3, iter: 2000, curr loss: 1.3862926959991455, avg loss: 1.3863841450214387\n",
      "trial: 3, iter: 2200, curr loss: 1.386846661567688, avg loss: 1.3863806855678558\n",
      "trial: 3, iter: 2400, curr loss: 1.3864041566848755, avg loss: 1.3863154250383376\n",
      "trial: 3, iter: 2600, curr loss: 1.3870116472244263, avg loss: 1.3863075405359269\n",
      "trial: 3, iter: 2800, curr loss: 1.3854496479034424, avg loss: 1.3863245785236358\n",
      "trial: 3, iter: 3000, curr loss: 1.3861629962921143, avg loss: 1.3863746786117555\n",
      "trial: 3, ldr: 0.0033810085151344538\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3871073722839355, avg loss: 1.3873602533340454\n",
      "trial: 4, iter: 400, curr loss: 1.387850284576416, avg loss: 1.3869579356908799\n",
      "trial: 4, iter: 600, curr loss: 1.3875911235809326, avg loss: 1.3866058748960495\n",
      "trial: 4, iter: 800, curr loss: 1.387212872505188, avg loss: 1.3865207427740096\n",
      "trial: 4, iter: 1000, curr loss: 1.3867155313491821, avg loss: 1.3863943016529083\n",
      "trial: 4, iter: 1200, curr loss: 1.386720895767212, avg loss: 1.3864269715547561\n",
      "trial: 4, iter: 1400, curr loss: 1.3871186971664429, avg loss: 1.3863821309804916\n",
      "trial: 4, iter: 1600, curr loss: 1.3864227533340454, avg loss: 1.3864057123661042\n",
      "trial: 4, iter: 1800, curr loss: 1.3871710300445557, avg loss: 1.386326355934143\n",
      "trial: 4, iter: 2000, curr loss: 1.3868376016616821, avg loss: 1.386408236026764\n",
      "trial: 4, iter: 2200, curr loss: 1.3858232498168945, avg loss: 1.386319488286972\n",
      "trial: 4, iter: 2400, curr loss: 1.3861048221588135, avg loss: 1.3863754850625991\n",
      "trial: 4, iter: 2600, curr loss: 1.3852143287658691, avg loss: 1.3863084125518799\n",
      "trial: 4, iter: 2800, curr loss: 1.3854472637176514, avg loss: 1.3864147239923477\n",
      "trial: 4, iter: 3000, curr loss: 1.3864513635635376, avg loss: 1.386382492184639\n",
      "trial: 4, ldr: -0.02162308432161808\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3881069421768188, avg loss: 1.3874157685041428\n",
      "trial: 5, iter: 400, curr loss: 1.386634349822998, avg loss: 1.386806738972664\n",
      "trial: 5, iter: 600, curr loss: 1.3880531787872314, avg loss: 1.386496245265007\n",
      "trial: 5, iter: 800, curr loss: 1.3873810768127441, avg loss: 1.3865431672334672\n",
      "trial: 5, iter: 1000, curr loss: 1.3868898153305054, avg loss: 1.386692316532135\n",
      "trial: 5, iter: 1200, curr loss: 1.3858115673065186, avg loss: 1.3864537930488587\n",
      "trial: 5, iter: 1400, curr loss: 1.3856499195098877, avg loss: 1.3863727170228959\n",
      "trial: 5, iter: 1600, curr loss: 1.3862284421920776, avg loss: 1.3863739973306657\n",
      "trial: 5, iter: 1800, curr loss: 1.3866832256317139, avg loss: 1.386352156996727\n",
      "trial: 5, iter: 2000, curr loss: 1.3872829675674438, avg loss: 1.3863371247053147\n",
      "trial: 5, iter: 2200, curr loss: 1.3857651948928833, avg loss: 1.3864443308115006\n",
      "trial: 5, iter: 2400, curr loss: 1.3860597610473633, avg loss: 1.3863397067785264\n",
      "trial: 5, iter: 2600, curr loss: 1.3875950574874878, avg loss: 1.386331415772438\n",
      "trial: 5, iter: 2800, curr loss: 1.3863447904586792, avg loss: 1.386371960043907\n",
      "trial: 5, iter: 3000, curr loss: 1.383954405784607, avg loss: 1.3863815319538118\n",
      "trial: 5, ldr: 0.015880003571510315\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.002969867875799537\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3881423473358154, avg loss: 1.3872520220279694\n",
      "trial: 1, iter: 400, curr loss: 1.3863563537597656, avg loss: 1.3867754971981048\n",
      "trial: 1, iter: 600, curr loss: 1.3852416276931763, avg loss: 1.3865204513072968\n",
      "trial: 1, iter: 800, curr loss: 1.3865323066711426, avg loss: 1.3864933878183365\n",
      "trial: 1, iter: 1000, curr loss: 1.3839610815048218, avg loss: 1.3864403074979783\n",
      "trial: 1, iter: 1200, curr loss: 1.3861258029937744, avg loss: 1.3864368438720702\n",
      "trial: 1, iter: 1400, curr loss: 1.3882747888565063, avg loss: 1.3864203482866286\n",
      "trial: 1, iter: 1600, curr loss: 1.3851114511489868, avg loss: 1.3864702302217484\n",
      "trial: 1, iter: 1800, curr loss: 1.3880449533462524, avg loss: 1.3863700526952742\n",
      "trial: 1, iter: 2000, curr loss: 1.3866448402404785, avg loss: 1.386425542831421\n",
      "trial: 1, iter: 2200, curr loss: 1.3859267234802246, avg loss: 1.3863497924804689\n",
      "trial: 1, iter: 2400, curr loss: 1.3867180347442627, avg loss: 1.3863327062129975\n",
      "trial: 1, iter: 2600, curr loss: 1.3862990140914917, avg loss: 1.3863737154006959\n",
      "trial: 1, iter: 2800, curr loss: 1.3861148357391357, avg loss: 1.3863256591558457\n",
      "trial: 1, iter: 3000, curr loss: 1.3857502937316895, avg loss: 1.386336984038353\n",
      "trial: 1, ldr: -0.0018502123421058059\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3861925601959229, avg loss: 1.387199034690857\n",
      "trial: 2, iter: 400, curr loss: 1.3875261545181274, avg loss: 1.3866514080762864\n",
      "trial: 2, iter: 600, curr loss: 1.3870545625686646, avg loss: 1.3867103177309037\n",
      "trial: 2, iter: 800, curr loss: 1.3836350440979004, avg loss: 1.3863330656290054\n",
      "trial: 2, iter: 1000, curr loss: 1.3851990699768066, avg loss: 1.3865747714042664\n",
      "trial: 2, iter: 1200, curr loss: 1.3873878717422485, avg loss: 1.3863840311765672\n",
      "trial: 2, iter: 1400, curr loss: 1.386159062385559, avg loss: 1.3865619909763336\n",
      "trial: 2, iter: 1600, curr loss: 1.3862335681915283, avg loss: 1.3864799404144288\n",
      "trial: 2, iter: 1800, curr loss: 1.3869683742523193, avg loss: 1.3863189679384231\n",
      "trial: 2, iter: 2000, curr loss: 1.386049509048462, avg loss: 1.386387039422989\n",
      "trial: 2, iter: 2200, curr loss: 1.3855458498001099, avg loss: 1.386359320282936\n",
      "trial: 2, iter: 2400, curr loss: 1.3862110376358032, avg loss: 1.3863736897706986\n",
      "trial: 2, iter: 2600, curr loss: 1.3873635530471802, avg loss: 1.3863513642549514\n",
      "trial: 2, iter: 2800, curr loss: 1.3871346712112427, avg loss: 1.3863817822933198\n",
      "trial: 2, iter: 3000, curr loss: 1.3863892555236816, avg loss: 1.3863844698667527\n",
      "trial: 2, ldr: -0.0024404055438935757\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3849464654922485, avg loss: 1.3871759170293807\n",
      "trial: 3, iter: 400, curr loss: 1.385515570640564, avg loss: 1.3866253519058227\n",
      "trial: 3, iter: 600, curr loss: 1.386398196220398, avg loss: 1.386511544585228\n",
      "trial: 3, iter: 800, curr loss: 1.3878154754638672, avg loss: 1.3864948815107345\n",
      "trial: 3, iter: 1000, curr loss: 1.3851754665374756, avg loss: 1.3863722747564315\n",
      "trial: 3, iter: 1200, curr loss: 1.3870275020599365, avg loss: 1.3864274823665619\n",
      "trial: 3, iter: 1400, curr loss: 1.3858206272125244, avg loss: 1.386457883119583\n",
      "trial: 3, iter: 1600, curr loss: 1.3862308263778687, avg loss: 1.386385527253151\n",
      "trial: 3, iter: 1800, curr loss: 1.386056661605835, avg loss: 1.386339806318283\n",
      "trial: 3, iter: 2000, curr loss: 1.385985016822815, avg loss: 1.3863741898536681\n",
      "trial: 3, iter: 2200, curr loss: 1.3866167068481445, avg loss: 1.3864018499851227\n",
      "trial: 3, iter: 2400, curr loss: 1.387255311012268, avg loss: 1.3863327008485795\n",
      "trial: 3, iter: 2600, curr loss: 1.3863481283187866, avg loss: 1.3863510185480117\n",
      "trial: 3, iter: 2800, curr loss: 1.3836489915847778, avg loss: 1.386310863494873\n",
      "trial: 3, iter: 3000, curr loss: 1.3864825963974, avg loss: 1.3863703709840776\n",
      "trial: 3, ldr: -0.016906417906284332\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3851808309555054, avg loss: 1.3871356177330016\n",
      "trial: 4, iter: 400, curr loss: 1.383449912071228, avg loss: 1.3867522484064103\n",
      "trial: 4, iter: 600, curr loss: 1.38688325881958, avg loss: 1.386612114906311\n",
      "trial: 4, iter: 800, curr loss: 1.3872480392456055, avg loss: 1.3864951264858245\n",
      "trial: 4, iter: 1000, curr loss: 1.3866688013076782, avg loss: 1.3864382630586625\n",
      "trial: 4, iter: 1200, curr loss: 1.385794758796692, avg loss: 1.3862943083047867\n",
      "trial: 4, iter: 1400, curr loss: 1.3851920366287231, avg loss: 1.386372566819191\n",
      "trial: 4, iter: 1600, curr loss: 1.3868904113769531, avg loss: 1.3864617210626602\n",
      "trial: 4, iter: 1800, curr loss: 1.3855056762695312, avg loss: 1.3863656550645829\n",
      "trial: 4, iter: 2000, curr loss: 1.3857356309890747, avg loss: 1.386405708193779\n",
      "trial: 4, iter: 2200, curr loss: 1.3869889974594116, avg loss: 1.3863390237092972\n",
      "trial: 4, iter: 2400, curr loss: 1.387636423110962, avg loss: 1.3863859635591507\n",
      "trial: 4, iter: 2600, curr loss: 1.3863005638122559, avg loss: 1.3863566792011262\n",
      "trial: 4, iter: 2800, curr loss: 1.3864185810089111, avg loss: 1.38641000688076\n",
      "trial: 4, iter: 3000, curr loss: 1.3849941492080688, avg loss: 1.386352150440216\n",
      "trial: 4, ldr: -0.006612719036638737\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3859201669692993, avg loss: 1.387528933286667\n",
      "trial: 5, iter: 400, curr loss: 1.3870784044265747, avg loss: 1.3866787832975387\n",
      "trial: 5, iter: 600, curr loss: 1.386130452156067, avg loss: 1.3866694915294646\n",
      "trial: 5, iter: 800, curr loss: 1.387036919593811, avg loss: 1.3864707571268082\n",
      "trial: 5, iter: 1000, curr loss: 1.385616421699524, avg loss: 1.3864499253034592\n",
      "trial: 5, iter: 1200, curr loss: 1.388179063796997, avg loss: 1.386463925242424\n",
      "trial: 5, iter: 1400, curr loss: 1.3861416578292847, avg loss: 1.3863913196325302\n",
      "trial: 5, iter: 1600, curr loss: 1.386377215385437, avg loss: 1.3864101088047027\n",
      "trial: 5, iter: 1800, curr loss: 1.3867223262786865, avg loss: 1.3864146155118942\n",
      "trial: 5, iter: 2000, curr loss: 1.3869234323501587, avg loss: 1.3863050198554994\n",
      "trial: 5, iter: 2200, curr loss: 1.3860443830490112, avg loss: 1.386312740445137\n",
      "trial: 5, iter: 2400, curr loss: 1.3871618509292603, avg loss: 1.3863694316148758\n",
      "trial: 5, iter: 2600, curr loss: 1.3860875368118286, avg loss: 1.386395778656006\n",
      "trial: 5, iter: 2800, curr loss: 1.3856571912765503, avg loss: 1.3862870138883592\n",
      "trial: 5, iter: 3000, curr loss: 1.3854007720947266, avg loss: 1.3862994247674942\n",
      "trial: 5, ldr: 0.015148205682635307\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0025323098292574287\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3882944583892822, avg loss: 1.3872624450922013\n",
      "trial: 1, iter: 400, curr loss: 1.3893076181411743, avg loss: 1.3865312820672988\n",
      "trial: 1, iter: 600, curr loss: 1.3857862949371338, avg loss: 1.3866808038949967\n",
      "trial: 1, iter: 800, curr loss: 1.3877289295196533, avg loss: 1.3864485102891921\n",
      "trial: 1, iter: 1000, curr loss: 1.3844186067581177, avg loss: 1.3864075720310212\n",
      "trial: 1, iter: 1200, curr loss: 1.3884379863739014, avg loss: 1.3864371407032012\n",
      "trial: 1, iter: 1400, curr loss: 1.386154294013977, avg loss: 1.3865339297056198\n",
      "trial: 1, iter: 1600, curr loss: 1.3860151767730713, avg loss: 1.3864041042327881\n",
      "trial: 1, iter: 1800, curr loss: 1.3879523277282715, avg loss: 1.3864005094766616\n",
      "trial: 1, iter: 2000, curr loss: 1.3847264051437378, avg loss: 1.3864201533794402\n",
      "trial: 1, iter: 2200, curr loss: 1.3865156173706055, avg loss: 1.386466783285141\n",
      "trial: 1, iter: 2400, curr loss: 1.3851308822631836, avg loss: 1.38637351334095\n",
      "trial: 1, iter: 2600, curr loss: 1.386627435684204, avg loss: 1.3864078152179717\n",
      "trial: 1, iter: 2800, curr loss: 1.3883768320083618, avg loss: 1.3863281232118607\n",
      "trial: 1, iter: 3000, curr loss: 1.3868744373321533, avg loss: 1.3863820284605026\n",
      "trial: 1, ldr: 0.005354363936930895\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3869709968566895, avg loss: 1.387246527671814\n",
      "trial: 2, iter: 400, curr loss: 1.387589454650879, avg loss: 1.3867950826883315\n",
      "trial: 2, iter: 600, curr loss: 1.3880897760391235, avg loss: 1.3865024107694626\n",
      "trial: 2, iter: 800, curr loss: 1.3865009546279907, avg loss: 1.3864525508880616\n",
      "trial: 2, iter: 1000, curr loss: 1.3866357803344727, avg loss: 1.3864935541152954\n",
      "trial: 2, iter: 1200, curr loss: 1.3869149684906006, avg loss: 1.386442757844925\n",
      "trial: 2, iter: 1400, curr loss: 1.3853564262390137, avg loss: 1.3863856846094131\n",
      "trial: 2, iter: 1600, curr loss: 1.387629747390747, avg loss: 1.3863575452566146\n",
      "trial: 2, iter: 1800, curr loss: 1.3880162239074707, avg loss: 1.386356193423271\n",
      "trial: 2, iter: 2000, curr loss: 1.3866698741912842, avg loss: 1.3864337939023972\n",
      "trial: 2, iter: 2200, curr loss: 1.386033058166504, avg loss: 1.3863515222072602\n",
      "trial: 2, iter: 2400, curr loss: 1.3861298561096191, avg loss: 1.3863613665103913\n",
      "trial: 2, iter: 2600, curr loss: 1.3857927322387695, avg loss: 1.386412526369095\n",
      "trial: 2, iter: 2800, curr loss: 1.3861113786697388, avg loss: 1.3863352555036546\n",
      "trial: 2, iter: 3000, curr loss: 1.3857001066207886, avg loss: 1.38634905397892\n",
      "trial: 2, ldr: 0.0029261948075145483\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873142004013062, avg loss: 1.3871256744861602\n",
      "trial: 3, iter: 400, curr loss: 1.3850936889648438, avg loss: 1.3868126714229583\n",
      "trial: 3, iter: 600, curr loss: 1.3873323202133179, avg loss: 1.386661595106125\n",
      "trial: 3, iter: 800, curr loss: 1.3872891664505005, avg loss: 1.386437262892723\n",
      "trial: 3, iter: 1000, curr loss: 1.3860996961593628, avg loss: 1.3864899188280106\n",
      "trial: 3, iter: 1200, curr loss: 1.3867391347885132, avg loss: 1.3864044761657714\n",
      "trial: 3, iter: 1400, curr loss: 1.3871067762374878, avg loss: 1.3864011979103088\n",
      "trial: 3, iter: 1600, curr loss: 1.3863776922225952, avg loss: 1.3864113265275955\n",
      "trial: 3, iter: 1800, curr loss: 1.3870339393615723, avg loss: 1.3864090943336487\n",
      "trial: 3, iter: 2000, curr loss: 1.3871486186981201, avg loss: 1.3862686014175416\n",
      "trial: 3, iter: 2200, curr loss: 1.38493812084198, avg loss: 1.3863852351903916\n",
      "trial: 3, iter: 2400, curr loss: 1.386866807937622, avg loss: 1.3864128065109254\n",
      "trial: 3, iter: 2600, curr loss: 1.3867307901382446, avg loss: 1.3863771218061447\n",
      "trial: 3, iter: 2800, curr loss: 1.3868054151535034, avg loss: 1.386341701745987\n",
      "trial: 3, iter: 3000, curr loss: 1.3865503072738647, avg loss: 1.386355082988739\n",
      "trial: 3, ldr: -0.008325042203068733\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3856284618377686, avg loss: 1.3870485299825668\n",
      "trial: 4, iter: 400, curr loss: 1.3873560428619385, avg loss: 1.3865582460165025\n",
      "trial: 4, iter: 600, curr loss: 1.3853625059127808, avg loss: 1.3864592319726945\n",
      "trial: 4, iter: 800, curr loss: 1.3851354122161865, avg loss: 1.386403074860573\n",
      "trial: 4, iter: 1000, curr loss: 1.3867369890213013, avg loss: 1.3864848184585572\n",
      "trial: 4, iter: 1200, curr loss: 1.3879001140594482, avg loss: 1.3863511788845062\n",
      "trial: 4, iter: 1400, curr loss: 1.3851717710494995, avg loss: 1.386446380019188\n",
      "trial: 4, iter: 1600, curr loss: 1.386839747428894, avg loss: 1.3864442110061646\n",
      "trial: 4, iter: 1800, curr loss: 1.386331558227539, avg loss: 1.3863723081350328\n",
      "trial: 4, iter: 2000, curr loss: 1.3884254693984985, avg loss: 1.386438266634941\n",
      "trial: 4, iter: 2200, curr loss: 1.3860889673233032, avg loss: 1.3863560551404952\n",
      "trial: 4, iter: 2400, curr loss: 1.3875768184661865, avg loss: 1.3863511574268341\n",
      "trial: 4, iter: 2600, curr loss: 1.386690378189087, avg loss: 1.3864189159870148\n",
      "trial: 4, iter: 2800, curr loss: 1.3873746395111084, avg loss: 1.3863439291715622\n",
      "trial: 4, iter: 3000, curr loss: 1.3859775066375732, avg loss: 1.3864017552137375\n",
      "trial: 4, ldr: 0.0015611780108883977\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3893297910690308, avg loss: 1.387288095355034\n",
      "trial: 5, iter: 400, curr loss: 1.385072112083435, avg loss: 1.3867108315229415\n",
      "trial: 5, iter: 600, curr loss: 1.3862104415893555, avg loss: 1.3865263962745666\n",
      "trial: 5, iter: 800, curr loss: 1.385544776916504, avg loss: 1.386510916352272\n",
      "trial: 5, iter: 1000, curr loss: 1.3852665424346924, avg loss: 1.386480250954628\n",
      "trial: 5, iter: 1200, curr loss: 1.3884135484695435, avg loss: 1.3863185137510299\n",
      "trial: 5, iter: 1400, curr loss: 1.3872467279434204, avg loss: 1.386525028347969\n",
      "trial: 5, iter: 1600, curr loss: 1.3872343301773071, avg loss: 1.386373153924942\n",
      "trial: 5, iter: 1800, curr loss: 1.3865982294082642, avg loss: 1.3864355409145355\n",
      "trial: 5, iter: 2000, curr loss: 1.3869097232818604, avg loss: 1.3863227373361589\n",
      "trial: 5, iter: 2200, curr loss: 1.38677978515625, avg loss: 1.3864242219924927\n",
      "trial: 5, iter: 2400, curr loss: 1.3857814073562622, avg loss: 1.386382064819336\n",
      "trial: 5, iter: 2600, curr loss: 1.3872570991516113, avg loss: 1.3863665211200713\n",
      "trial: 5, iter: 2800, curr loss: 1.387428879737854, avg loss: 1.386411179304123\n",
      "trial: 5, iter: 3000, curr loss: 1.3860468864440918, avg loss: 1.3863734000921248\n",
      "trial: 5, ldr: 0.0030522742308676243\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0009137937566265463\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3858307600021362, avg loss: 1.3871291655302047\n",
      "trial: 1, iter: 400, curr loss: 1.3882167339324951, avg loss: 1.3868049812316894\n",
      "trial: 1, iter: 600, curr loss: 1.3869928121566772, avg loss: 1.3866820818185805\n",
      "trial: 1, iter: 800, curr loss: 1.3863736391067505, avg loss: 1.3864333832263946\n",
      "trial: 1, iter: 1000, curr loss: 1.3863252401351929, avg loss: 1.3863110774755478\n",
      "trial: 1, iter: 1200, curr loss: 1.3853774070739746, avg loss: 1.386392273902893\n",
      "trial: 1, iter: 1400, curr loss: 1.3853343725204468, avg loss: 1.3864558082818985\n",
      "trial: 1, iter: 1600, curr loss: 1.3860645294189453, avg loss: 1.3865887123346328\n",
      "trial: 1, iter: 1800, curr loss: 1.3869147300720215, avg loss: 1.3864428520202636\n",
      "trial: 1, iter: 2000, curr loss: 1.3855156898498535, avg loss: 1.3863771253824233\n",
      "trial: 1, iter: 2200, curr loss: 1.3853737115859985, avg loss: 1.3863863867521287\n",
      "trial: 1, iter: 2400, curr loss: 1.3859995603561401, avg loss: 1.3863763147592545\n",
      "trial: 1, iter: 2600, curr loss: 1.3861030340194702, avg loss: 1.3863168305158615\n",
      "trial: 1, iter: 2800, curr loss: 1.3866984844207764, avg loss: 1.3863396507501602\n",
      "trial: 1, iter: 3000, curr loss: 1.3871926069259644, avg loss: 1.386308718919754\n",
      "trial: 1, ldr: 0.02802695892751217\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3866289854049683, avg loss: 1.3873571825027466\n",
      "trial: 2, iter: 400, curr loss: 1.386279821395874, avg loss: 1.3868588119745255\n",
      "trial: 2, iter: 600, curr loss: 1.3856748342514038, avg loss: 1.3864902067184448\n",
      "trial: 2, iter: 800, curr loss: 1.3860801458358765, avg loss: 1.3864945095777512\n",
      "trial: 2, iter: 1000, curr loss: 1.3871204853057861, avg loss: 1.3865193486213685\n",
      "trial: 2, iter: 1200, curr loss: 1.387528657913208, avg loss: 1.3864293920993804\n",
      "trial: 2, iter: 1400, curr loss: 1.3864259719848633, avg loss: 1.386427747607231\n",
      "trial: 2, iter: 1600, curr loss: 1.386997103691101, avg loss: 1.3864243149757385\n",
      "trial: 2, iter: 1800, curr loss: 1.3859978914260864, avg loss: 1.386376110315323\n",
      "trial: 2, iter: 2000, curr loss: 1.3869175910949707, avg loss: 1.3863677817583084\n",
      "trial: 2, iter: 2200, curr loss: 1.387252688407898, avg loss: 1.386343343257904\n",
      "trial: 2, iter: 2400, curr loss: 1.3865208625793457, avg loss: 1.3863957220315932\n",
      "trial: 2, iter: 2600, curr loss: 1.3862276077270508, avg loss: 1.386350198984146\n",
      "trial: 2, iter: 2800, curr loss: 1.3863823413848877, avg loss: 1.386346310377121\n",
      "trial: 2, iter: 3000, curr loss: 1.3862687349319458, avg loss: 1.3864267563819885\n",
      "trial: 2, ldr: 0.004010537173599005\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3881210088729858, avg loss: 1.387222830057144\n",
      "trial: 3, iter: 400, curr loss: 1.3886423110961914, avg loss: 1.3867988240718843\n",
      "trial: 3, iter: 600, curr loss: 1.3868504762649536, avg loss: 1.3865793889760971\n",
      "trial: 3, iter: 800, curr loss: 1.3857407569885254, avg loss: 1.3864393109083175\n",
      "trial: 3, iter: 1000, curr loss: 1.3879534006118774, avg loss: 1.386431832909584\n",
      "trial: 3, iter: 1200, curr loss: 1.3862617015838623, avg loss: 1.3864373606443405\n",
      "trial: 3, iter: 1400, curr loss: 1.3866206407546997, avg loss: 1.3863399803638459\n",
      "trial: 3, iter: 1600, curr loss: 1.3870097398757935, avg loss: 1.3863744986057283\n",
      "trial: 3, iter: 1800, curr loss: 1.3853654861450195, avg loss: 1.3863826167583466\n",
      "trial: 3, iter: 2000, curr loss: 1.3867340087890625, avg loss: 1.3864965569972991\n",
      "trial: 3, iter: 2200, curr loss: 1.3867684602737427, avg loss: 1.386373943090439\n",
      "trial: 3, iter: 2400, curr loss: 1.3857380151748657, avg loss: 1.3863349968194962\n",
      "trial: 3, iter: 2600, curr loss: 1.3862404823303223, avg loss: 1.3863282352685928\n",
      "trial: 3, iter: 2800, curr loss: 1.386573314666748, avg loss: 1.3863457357883453\n",
      "trial: 3, iter: 3000, curr loss: 1.3850613832473755, avg loss: 1.3863259983062743\n",
      "trial: 3, ldr: -0.012274752371013165\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.384405493736267, avg loss: 1.3872431123256683\n",
      "trial: 4, iter: 400, curr loss: 1.3880432844161987, avg loss: 1.386946461200714\n",
      "trial: 4, iter: 600, curr loss: 1.3890233039855957, avg loss: 1.3866960299015045\n",
      "trial: 4, iter: 800, curr loss: 1.3866488933563232, avg loss: 1.3864294362068177\n",
      "trial: 4, iter: 1000, curr loss: 1.3863478899002075, avg loss: 1.3866262078285216\n",
      "trial: 4, iter: 1200, curr loss: 1.3863836526870728, avg loss: 1.3864991891384124\n",
      "trial: 4, iter: 1400, curr loss: 1.3856428861618042, avg loss: 1.3864409029483795\n",
      "trial: 4, iter: 1600, curr loss: 1.3865025043487549, avg loss: 1.386454387307167\n",
      "trial: 4, iter: 1800, curr loss: 1.3864377737045288, avg loss: 1.3863467580080033\n",
      "trial: 4, iter: 2000, curr loss: 1.3865694999694824, avg loss: 1.3863874751329421\n",
      "trial: 4, iter: 2200, curr loss: 1.3863050937652588, avg loss: 1.3863832807540895\n",
      "trial: 4, iter: 2400, curr loss: 1.386092185974121, avg loss: 1.3864116328954696\n",
      "trial: 4, iter: 2600, curr loss: 1.3865891695022583, avg loss: 1.3863611543178558\n",
      "trial: 4, iter: 2800, curr loss: 1.387253999710083, avg loss: 1.3863198411464692\n",
      "trial: 4, iter: 3000, curr loss: 1.385528564453125, avg loss: 1.3864151591062546\n",
      "trial: 4, ldr: 0.00611507473513484\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3879107236862183, avg loss: 1.3871426326036453\n",
      "trial: 5, iter: 400, curr loss: 1.3879072666168213, avg loss: 1.3867753618955612\n",
      "trial: 5, iter: 600, curr loss: 1.386609435081482, avg loss: 1.3864675801992417\n",
      "trial: 5, iter: 800, curr loss: 1.3871374130249023, avg loss: 1.38649917781353\n",
      "trial: 5, iter: 1000, curr loss: 1.3848764896392822, avg loss: 1.3865695685148238\n",
      "trial: 5, iter: 1200, curr loss: 1.387617826461792, avg loss: 1.3864601844549178\n",
      "trial: 5, iter: 1400, curr loss: 1.3858137130737305, avg loss: 1.3864713990688324\n",
      "trial: 5, iter: 1600, curr loss: 1.3864470720291138, avg loss: 1.3864957535266875\n",
      "trial: 5, iter: 1800, curr loss: 1.386507511138916, avg loss: 1.3864753985404967\n",
      "trial: 5, iter: 2000, curr loss: 1.3870108127593994, avg loss: 1.3863333040475845\n",
      "trial: 5, iter: 2200, curr loss: 1.3861380815505981, avg loss: 1.3864012449979781\n",
      "trial: 5, iter: 2400, curr loss: 1.3862321376800537, avg loss: 1.3863660430908202\n",
      "trial: 5, iter: 2600, curr loss: 1.3870843648910522, avg loss: 1.3863597679138184\n",
      "trial: 5, iter: 2800, curr loss: 1.3864855766296387, avg loss: 1.3863953018188477\n",
      "trial: 5, iter: 3000, curr loss: 1.385970950126648, avg loss: 1.3863501352071763\n",
      "trial: 5, ldr: -0.013092659413814545\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.002557031810283661\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3840850591659546, avg loss: 1.3874323391914367\n",
      "trial: 1, iter: 400, curr loss: 1.3916661739349365, avg loss: 1.3869508796930312\n",
      "trial: 1, iter: 600, curr loss: 1.3898494243621826, avg loss: 1.3864963507652284\n",
      "trial: 1, iter: 800, curr loss: 1.3873329162597656, avg loss: 1.38651116669178\n",
      "trial: 1, iter: 1000, curr loss: 1.3869962692260742, avg loss: 1.386482647061348\n",
      "trial: 1, iter: 1200, curr loss: 1.38573157787323, avg loss: 1.3864599347114563\n",
      "trial: 1, iter: 1400, curr loss: 1.3859069347381592, avg loss: 1.3864019173383713\n",
      "trial: 1, iter: 1600, curr loss: 1.3871870040893555, avg loss: 1.3864280676841736\n",
      "trial: 1, iter: 1800, curr loss: 1.3875997066497803, avg loss: 1.3863820242881775\n",
      "trial: 1, iter: 2000, curr loss: 1.3863791227340698, avg loss: 1.3862965989112854\n",
      "trial: 1, iter: 2200, curr loss: 1.3854707479476929, avg loss: 1.3863308918476105\n",
      "trial: 1, iter: 2400, curr loss: 1.3868534564971924, avg loss: 1.3863384783267976\n",
      "trial: 1, iter: 2600, curr loss: 1.3859299421310425, avg loss: 1.3863711172342301\n",
      "trial: 1, iter: 2800, curr loss: 1.3862404823303223, avg loss: 1.3863457340002059\n",
      "trial: 1, iter: 3000, curr loss: 1.3867554664611816, avg loss: 1.3863472884893417\n",
      "trial: 1, ldr: -0.0006670457660220563\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387858510017395, avg loss: 1.387730719447136\n",
      "trial: 2, iter: 400, curr loss: 1.3886090517044067, avg loss: 1.3866239362955093\n",
      "trial: 2, iter: 600, curr loss: 1.3858970403671265, avg loss: 1.3865961319208144\n",
      "trial: 2, iter: 800, curr loss: 1.384517788887024, avg loss: 1.3864559423923493\n",
      "trial: 2, iter: 1000, curr loss: 1.3866910934448242, avg loss: 1.3865255278348922\n",
      "trial: 2, iter: 1200, curr loss: 1.3871651887893677, avg loss: 1.3865003567934036\n",
      "trial: 2, iter: 1400, curr loss: 1.3867030143737793, avg loss: 1.3864376103878022\n",
      "trial: 2, iter: 1600, curr loss: 1.3855969905853271, avg loss: 1.3863477665185928\n",
      "trial: 2, iter: 1800, curr loss: 1.386209487915039, avg loss: 1.3863472145795823\n",
      "trial: 2, iter: 2000, curr loss: 1.385697364807129, avg loss: 1.3863144242763519\n",
      "trial: 2, iter: 2200, curr loss: 1.3873951435089111, avg loss: 1.3863278394937515\n",
      "trial: 2, iter: 2400, curr loss: 1.3861875534057617, avg loss: 1.3863379287719726\n",
      "trial: 2, iter: 2600, curr loss: 1.3863246440887451, avg loss: 1.3863488501310348\n",
      "trial: 2, iter: 2800, curr loss: 1.3865116834640503, avg loss: 1.3863470751047133\n",
      "trial: 2, iter: 3000, curr loss: 1.3862131834030151, avg loss: 1.3863518100976944\n",
      "trial: 2, ldr: 0.0056485640816390514\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3869130611419678, avg loss: 1.3872702926397324\n",
      "trial: 3, iter: 400, curr loss: 1.389567255973816, avg loss: 1.3868102377653122\n",
      "trial: 3, iter: 600, curr loss: 1.3858574628829956, avg loss: 1.3865239530801774\n",
      "trial: 3, iter: 800, curr loss: 1.3847615718841553, avg loss: 1.3866495096683502\n",
      "trial: 3, iter: 1000, curr loss: 1.3864165544509888, avg loss: 1.386503155231476\n",
      "trial: 3, iter: 1200, curr loss: 1.3880174160003662, avg loss: 1.3865311795473099\n",
      "trial: 3, iter: 1400, curr loss: 1.3888195753097534, avg loss: 1.3863736718893052\n",
      "trial: 3, iter: 1600, curr loss: 1.3859885931015015, avg loss: 1.3864534831047057\n",
      "trial: 3, iter: 1800, curr loss: 1.3875137567520142, avg loss: 1.3863788342475891\n",
      "trial: 3, iter: 2000, curr loss: 1.3856744766235352, avg loss: 1.3864034169912338\n",
      "trial: 3, iter: 2200, curr loss: 1.3866753578186035, avg loss: 1.3863698333501815\n",
      "trial: 3, iter: 2400, curr loss: 1.386173129081726, avg loss: 1.3863123387098313\n",
      "trial: 3, iter: 2600, curr loss: 1.386543869972229, avg loss: 1.3864185100793838\n",
      "trial: 3, iter: 2800, curr loss: 1.3871103525161743, avg loss: 1.3864107209444045\n",
      "trial: 3, iter: 3000, curr loss: 1.3859020471572876, avg loss: 1.386174269914627\n",
      "trial: 3, ldr: 0.0018043341115117073\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3896679878234863, avg loss: 1.3875848758220672\n",
      "trial: 4, iter: 400, curr loss: 1.3881940841674805, avg loss: 1.3867501246929168\n",
      "trial: 4, iter: 600, curr loss: 1.3836668729782104, avg loss: 1.3866445982456208\n",
      "trial: 4, iter: 800, curr loss: 1.3863292932510376, avg loss: 1.3864448881149292\n",
      "trial: 4, iter: 1000, curr loss: 1.3856523036956787, avg loss: 1.3864692431688308\n",
      "trial: 4, iter: 1200, curr loss: 1.3874303102493286, avg loss: 1.386388281583786\n",
      "trial: 4, iter: 1400, curr loss: 1.3872562646865845, avg loss: 1.3863413220643996\n",
      "trial: 4, iter: 1600, curr loss: 1.3869291543960571, avg loss: 1.386365697979927\n",
      "trial: 4, iter: 1800, curr loss: 1.3852566480636597, avg loss: 1.386400738954544\n",
      "trial: 4, iter: 2000, curr loss: 1.386852502822876, avg loss: 1.3864050674438477\n",
      "trial: 4, iter: 2200, curr loss: 1.3852320909500122, avg loss: 1.3864562261104583\n",
      "trial: 4, iter: 2400, curr loss: 1.3860551118850708, avg loss: 1.3864237785339355\n",
      "trial: 4, iter: 2600, curr loss: 1.3857501745224, avg loss: 1.3864320814609528\n",
      "trial: 4, iter: 2800, curr loss: 1.3862004280090332, avg loss: 1.386367719769478\n",
      "trial: 4, iter: 3000, curr loss: 1.3864558935165405, avg loss: 1.386420275568962\n",
      "trial: 4, ldr: -0.03310232236981392\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3848341703414917, avg loss: 1.387402476668358\n",
      "trial: 5, iter: 400, curr loss: 1.3865654468536377, avg loss: 1.3867361891269683\n",
      "trial: 5, iter: 600, curr loss: 1.3844298124313354, avg loss: 1.3865372490882875\n",
      "trial: 5, iter: 800, curr loss: 1.3881241083145142, avg loss: 1.386446225643158\n",
      "trial: 5, iter: 1000, curr loss: 1.3861796855926514, avg loss: 1.3864775210618974\n",
      "trial: 5, iter: 1200, curr loss: 1.3853846788406372, avg loss: 1.3865004152059555\n",
      "trial: 5, iter: 1400, curr loss: 1.3866950273513794, avg loss: 1.3864711284637452\n",
      "trial: 5, iter: 1600, curr loss: 1.3865392208099365, avg loss: 1.3863450825214385\n",
      "trial: 5, iter: 1800, curr loss: 1.3858534097671509, avg loss: 1.3863812220096587\n",
      "trial: 5, iter: 2000, curr loss: 1.3860743045806885, avg loss: 1.386469048857689\n",
      "trial: 5, iter: 2200, curr loss: 1.385910987854004, avg loss: 1.3863978332281113\n",
      "trial: 5, iter: 2400, curr loss: 1.386605143547058, avg loss: 1.386299444437027\n",
      "trial: 5, iter: 2600, curr loss: 1.3847720623016357, avg loss: 1.3862938320636748\n",
      "trial: 5, iter: 2800, curr loss: 1.3861193656921387, avg loss: 1.3864310526847838\n",
      "trial: 5, iter: 3000, curr loss: 1.385171890258789, avg loss: 1.386400955915451\n",
      "trial: 5, ldr: -0.006759769283235073\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.006615247845184058\n",
      "Experiment done with data path: ./data/catNon-lin-NI_14/data.10k.dz100.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_5/data.5k.dz20.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3874807357788086, avg loss: 1.3873532390594483\n",
      "trial: 1, iter: 400, curr loss: 1.3882228136062622, avg loss: 1.3868089777231216\n",
      "trial: 1, iter: 600, curr loss: 1.386033296585083, avg loss: 1.3860733169317245\n",
      "trial: 1, iter: 800, curr loss: 1.3778176307678223, avg loss: 1.3816110521554947\n",
      "trial: 1, iter: 1000, curr loss: 1.3445581197738647, avg loss: 1.3537704545259475\n",
      "trial: 1, iter: 1200, curr loss: 1.3408693075180054, avg loss: 1.3358657163381578\n",
      "trial: 1, iter: 1400, curr loss: 1.329958200454712, avg loss: 1.3282513809204102\n",
      "trial: 1, ldr: -0.0029625834431499243\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3894381523132324, avg loss: 1.3870054250955581\n",
      "trial: 2, iter: 400, curr loss: 1.3849681615829468, avg loss: 1.386005809903145\n",
      "trial: 2, iter: 600, curr loss: 1.3818737268447876, avg loss: 1.3811127936840057\n",
      "trial: 2, iter: 800, curr loss: 1.3460677862167358, avg loss: 1.3614507603645325\n",
      "trial: 2, iter: 1000, curr loss: 1.324013590812683, avg loss: 1.3393769752979279\n",
      "trial: 2, iter: 1200, curr loss: 1.3278841972351074, avg loss: 1.3299458295106887\n",
      "trial: 2, iter: 1400, curr loss: 1.342880129814148, avg loss: 1.322109666466713\n",
      "trial: 2, ldr: 0.029011309146881104\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3863441944122314, avg loss: 1.3872525161504745\n",
      "trial: 3, iter: 400, curr loss: 1.3871374130249023, avg loss: 1.3862716484069824\n",
      "trial: 3, iter: 600, curr loss: 1.3763024806976318, avg loss: 1.3826812213659287\n",
      "trial: 3, iter: 800, curr loss: 1.3491324186325073, avg loss: 1.363495517373085\n",
      "trial: 3, iter: 1000, curr loss: 1.3223018646240234, avg loss: 1.3425756138563156\n",
      "trial: 3, iter: 1200, curr loss: 1.3229589462280273, avg loss: 1.332945135831833\n",
      "trial: 3, iter: 1400, curr loss: 1.3335003852844238, avg loss: 1.325491955280304\n",
      "trial: 3, ldr: 0.05341489240527153\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3863176107406616, avg loss: 1.386842041015625\n",
      "trial: 4, iter: 400, curr loss: 1.386655569076538, avg loss: 1.3862599515914917\n",
      "trial: 4, iter: 600, curr loss: 1.3638097047805786, avg loss: 1.3814741218090056\n",
      "trial: 4, iter: 800, curr loss: 1.3550220727920532, avg loss: 1.3574575287103654\n",
      "trial: 4, iter: 1000, curr loss: 1.3192634582519531, avg loss: 1.3380482310056687\n",
      "trial: 4, iter: 1200, curr loss: 1.3142222166061401, avg loss: 1.3309182918071747\n",
      "trial: 4, iter: 1400, curr loss: 1.3047913312911987, avg loss: 1.3232782715559006\n",
      "trial: 4, ldr: 0.05611502751708031\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3833255767822266, avg loss: 1.3870023518800736\n",
      "trial: 5, iter: 400, curr loss: 1.3849858045578003, avg loss: 1.3866511809825897\n",
      "trial: 5, iter: 600, curr loss: 1.382799506187439, avg loss: 1.38494247674942\n",
      "trial: 5, iter: 800, curr loss: 1.3480947017669678, avg loss: 1.367586841583252\n",
      "trial: 5, iter: 1000, curr loss: 1.3421216011047363, avg loss: 1.3426178497076036\n",
      "trial: 5, iter: 1200, curr loss: 1.3274580240249634, avg loss: 1.3351588368415832\n",
      "trial: 5, iter: 1400, curr loss: 1.3286104202270508, avg loss: 1.324761270880699\n",
      "trial: 5, ldr: -0.002902955049648881\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.02653513811528683\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.387567400932312, avg loss: 1.3870194017887116\n",
      "trial: 1, iter: 400, curr loss: 1.3847967386245728, avg loss: 1.3865187287330627\n",
      "trial: 1, iter: 600, curr loss: 1.3839664459228516, avg loss: 1.3853835320472718\n",
      "trial: 1, iter: 800, curr loss: 1.3760464191436768, avg loss: 1.3810355919599533\n",
      "trial: 1, iter: 1000, curr loss: 1.353918194770813, avg loss: 1.3690826135873795\n",
      "trial: 1, iter: 1200, curr loss: 1.325378656387329, avg loss: 1.3455312108993531\n",
      "trial: 1, iter: 1400, curr loss: 1.330004096031189, avg loss: 1.3340478503704072\n",
      "trial: 1, ldr: 0.04753575101494789\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3891801834106445, avg loss: 1.3873373556137085\n",
      "trial: 2, iter: 400, curr loss: 1.3836514949798584, avg loss: 1.3864037418365478\n",
      "trial: 2, iter: 600, curr loss: 1.372990608215332, avg loss: 1.3837748867273332\n",
      "trial: 2, iter: 800, curr loss: 1.349311351776123, avg loss: 1.3646896862983704\n",
      "trial: 2, iter: 1000, curr loss: 1.3410274982452393, avg loss: 1.3424519217014312\n",
      "trial: 2, iter: 1200, curr loss: 1.3376327753067017, avg loss: 1.33016352891922\n",
      "trial: 2, iter: 1400, curr loss: 1.309922218322754, avg loss: 1.3258818608522416\n",
      "trial: 2, ldr: 0.03073730133473873\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.385724663734436, avg loss: 1.3869221180677413\n",
      "trial: 3, iter: 400, curr loss: 1.3869915008544922, avg loss: 1.386715612411499\n",
      "trial: 3, iter: 600, curr loss: 1.3852334022521973, avg loss: 1.3864673370122909\n",
      "trial: 3, iter: 800, curr loss: 1.3845807313919067, avg loss: 1.3861371964216231\n",
      "trial: 3, iter: 1000, curr loss: 1.3781625032424927, avg loss: 1.3839704936742783\n",
      "trial: 3, iter: 1200, curr loss: 1.348708152770996, avg loss: 1.3651708036661148\n",
      "trial: 3, iter: 1400, curr loss: 1.3313969373703003, avg loss: 1.34174345433712\n",
      "trial: 3, ldr: -0.0021142226178199053\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3874233961105347, avg loss: 1.387342032790184\n",
      "trial: 4, iter: 400, curr loss: 1.3877966403961182, avg loss: 1.386526809334755\n",
      "trial: 4, iter: 600, curr loss: 1.3810451030731201, avg loss: 1.3855882972478866\n",
      "trial: 4, iter: 800, curr loss: 1.3426461219787598, avg loss: 1.3743489694595337\n",
      "trial: 4, iter: 1000, curr loss: 1.360047459602356, avg loss: 1.3487085449695586\n",
      "trial: 4, iter: 1200, curr loss: 1.32652747631073, avg loss: 1.3360475039482116\n",
      "trial: 4, iter: 1400, curr loss: 1.32831871509552, avg loss: 1.3292746025323867\n",
      "trial: 4, ldr: 0.01719181425869465\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.386780023574829, avg loss: 1.3872952127456666\n",
      "trial: 5, iter: 400, curr loss: 1.386246681213379, avg loss: 1.386638661623001\n",
      "trial: 5, iter: 600, curr loss: 1.387030005455017, avg loss: 1.3859263372421264\n",
      "trial: 5, iter: 800, curr loss: 1.3744391202926636, avg loss: 1.3841093045473098\n",
      "trial: 5, iter: 1000, curr loss: 1.3425607681274414, avg loss: 1.3641665184497833\n",
      "trial: 5, iter: 1200, curr loss: 1.376198410987854, avg loss: 1.345583615899086\n",
      "trial: 5, iter: 1400, curr loss: 1.328203558921814, avg loss: 1.3349372905492782\n",
      "trial: 5, ldr: 0.027158526703715324\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.02410183413885534\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3874495029449463, avg loss: 1.3871488326787949\n",
      "trial: 1, iter: 400, curr loss: 1.3868426084518433, avg loss: 1.386287164092064\n",
      "trial: 1, iter: 600, curr loss: 1.381645679473877, avg loss: 1.3824149459600448\n",
      "trial: 1, iter: 800, curr loss: 1.3487647771835327, avg loss: 1.3591860026121139\n",
      "trial: 1, iter: 1000, curr loss: 1.318800449371338, avg loss: 1.3381214720010757\n",
      "trial: 1, iter: 1200, curr loss: 1.298386812210083, avg loss: 1.328709447979927\n",
      "trial: 1, iter: 1400, curr loss: 1.3068095445632935, avg loss: 1.3214036923646928\n",
      "trial: 1, ldr: 0.05463254824280739\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.383671522140503, avg loss: 1.3872120624780655\n",
      "trial: 2, iter: 400, curr loss: 1.3891429901123047, avg loss: 1.3868282747268676\n",
      "trial: 2, iter: 600, curr loss: 1.384791374206543, avg loss: 1.3863635855913161\n",
      "trial: 2, iter: 800, curr loss: 1.384246826171875, avg loss: 1.3852722960710526\n",
      "trial: 2, iter: 1000, curr loss: 1.3489683866500854, avg loss: 1.3658399951457978\n",
      "trial: 2, iter: 1200, curr loss: 1.348623514175415, avg loss: 1.3387450826168061\n",
      "trial: 2, iter: 1400, curr loss: 1.3404006958007812, avg loss: 1.328414590358734\n",
      "trial: 2, ldr: 0.08050302416086197\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.391422152519226, avg loss: 1.3875017166137695\n",
      "trial: 3, iter: 400, curr loss: 1.3856803178787231, avg loss: 1.3865069556236267\n",
      "trial: 3, iter: 600, curr loss: 1.3830729722976685, avg loss: 1.3859980422258378\n",
      "trial: 3, iter: 800, curr loss: 1.3769862651824951, avg loss: 1.381268607378006\n",
      "trial: 3, iter: 1000, curr loss: 1.3338268995285034, avg loss: 1.3569117081165314\n",
      "trial: 3, iter: 1200, curr loss: 1.336178183555603, avg loss: 1.3375167346000671\n",
      "trial: 3, iter: 1400, curr loss: 1.309219241142273, avg loss: 1.330015538930893\n",
      "trial: 3, ldr: 0.051621705293655396\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3861346244812012, avg loss: 1.38747780919075\n",
      "trial: 4, iter: 400, curr loss: 1.3876997232437134, avg loss: 1.3866004872322082\n",
      "trial: 4, iter: 600, curr loss: 1.386446475982666, avg loss: 1.3853641337156295\n",
      "trial: 4, iter: 800, curr loss: 1.3693439960479736, avg loss: 1.371303954720497\n",
      "trial: 4, iter: 1000, curr loss: 1.3360517024993896, avg loss: 1.346812637448311\n",
      "trial: 4, iter: 1200, curr loss: 1.3167109489440918, avg loss: 1.332820919752121\n",
      "trial: 4, iter: 1400, curr loss: 1.2936137914657593, avg loss: 1.32801333963871\n",
      "trial: 4, ldr: 0.0643993616104126\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3891066312789917, avg loss: 1.3869018876552581\n",
      "trial: 5, iter: 400, curr loss: 1.3873544931411743, avg loss: 1.3865427672863007\n",
      "trial: 5, iter: 600, curr loss: 1.3816430568695068, avg loss: 1.3856349807977677\n",
      "trial: 5, iter: 800, curr loss: 1.3813601732254028, avg loss: 1.3773364979028702\n",
      "trial: 5, iter: 1000, curr loss: 1.3293730020523071, avg loss: 1.3549198377132416\n",
      "trial: 5, iter: 1200, curr loss: 1.3061420917510986, avg loss: 1.3401445722579957\n",
      "trial: 5, iter: 1400, curr loss: 1.356095552444458, avg loss: 1.330545385479927\n",
      "trial: 5, ldr: 0.03749769553542137\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.05773086696863174\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3824131488800049, avg loss: 1.3872097754478454\n",
      "trial: 1, iter: 400, curr loss: 1.3858102560043335, avg loss: 1.3865885096788406\n",
      "trial: 1, iter: 600, curr loss: 1.3876162767410278, avg loss: 1.3858260136842728\n",
      "trial: 1, iter: 800, curr loss: 1.3777893781661987, avg loss: 1.3821473908424378\n",
      "trial: 1, iter: 1000, curr loss: 1.3314001560211182, avg loss: 1.3606516700983047\n",
      "trial: 1, iter: 1200, curr loss: 1.321641445159912, avg loss: 1.3420629072189332\n",
      "trial: 1, iter: 1400, curr loss: 1.3323771953582764, avg loss: 1.3349255669116973\n",
      "trial: 1, ldr: 0.039467599242925644\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3867794275283813, avg loss: 1.387471388578415\n",
      "trial: 2, iter: 400, curr loss: 1.388885259628296, avg loss: 1.3866324067115783\n",
      "trial: 2, iter: 600, curr loss: 1.3839362859725952, avg loss: 1.385542214512825\n",
      "trial: 2, iter: 800, curr loss: 1.3623019456863403, avg loss: 1.3773446482419969\n",
      "trial: 2, iter: 1000, curr loss: 1.3369961977005005, avg loss: 1.3517610210180282\n",
      "trial: 2, iter: 1200, curr loss: 1.3487056493759155, avg loss: 1.337336373925209\n",
      "trial: 2, iter: 1400, curr loss: 1.322473168373108, avg loss: 1.3298696333169937\n",
      "trial: 2, ldr: 0.020241927355527878\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3867236375808716, avg loss: 1.3871908086538314\n",
      "trial: 3, iter: 400, curr loss: 1.3863927125930786, avg loss: 1.386443287730217\n",
      "trial: 3, iter: 600, curr loss: 1.3834806680679321, avg loss: 1.384586715698242\n",
      "trial: 3, iter: 800, curr loss: 1.365999698638916, avg loss: 1.3672972351312638\n",
      "trial: 3, iter: 1000, curr loss: 1.340405821800232, avg loss: 1.3455258703231812\n",
      "trial: 3, iter: 1200, curr loss: 1.2866255044937134, avg loss: 1.3329379892349242\n",
      "trial: 3, iter: 1400, curr loss: 1.3215306997299194, avg loss: 1.3270092725753784\n",
      "trial: 3, ldr: 0.02306060865521431\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.382690191268921, avg loss: 1.386787367463112\n",
      "trial: 4, iter: 400, curr loss: 1.382944107055664, avg loss: 1.386534109711647\n",
      "trial: 4, iter: 600, curr loss: 1.3818275928497314, avg loss: 1.3862498021125793\n",
      "trial: 4, iter: 800, curr loss: 1.3815152645111084, avg loss: 1.385315079689026\n",
      "trial: 4, iter: 1000, curr loss: 1.354738712310791, avg loss: 1.3756226569414138\n",
      "trial: 4, iter: 1200, curr loss: 1.3460404872894287, avg loss: 1.351611503958702\n",
      "trial: 4, iter: 1400, curr loss: 1.3698759078979492, avg loss: 1.340535591840744\n",
      "trial: 4, ldr: 0.04268796741962433\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3905513286590576, avg loss: 1.3871666586399078\n",
      "trial: 5, iter: 400, curr loss: 1.3850479125976562, avg loss: 1.3865056627988814\n",
      "trial: 5, iter: 600, curr loss: 1.377960443496704, avg loss: 1.3845990872383118\n",
      "trial: 5, iter: 800, curr loss: 1.3472027778625488, avg loss: 1.3713059973716737\n",
      "trial: 5, iter: 1000, curr loss: 1.3483103513717651, avg loss: 1.3501908218860625\n",
      "trial: 5, iter: 1200, curr loss: 1.3409302234649658, avg loss: 1.3383206874132156\n",
      "trial: 5, iter: 1400, curr loss: 1.315160870552063, avg loss: 1.3294790035486221\n",
      "trial: 5, ldr: 0.03285935893654823\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.03166349232196808\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.388984203338623, avg loss: 1.3872329080104828\n",
      "trial: 1, iter: 400, curr loss: 1.383453369140625, avg loss: 1.3864752215147018\n",
      "trial: 1, iter: 600, curr loss: 1.3818581104278564, avg loss: 1.385396618247032\n",
      "trial: 1, iter: 800, curr loss: 1.3755890130996704, avg loss: 1.3813325929641724\n",
      "trial: 1, iter: 1000, curr loss: 1.3530752658843994, avg loss: 1.3733477222919463\n",
      "trial: 1, iter: 1200, curr loss: 1.3553340435028076, avg loss: 1.354062711596489\n",
      "trial: 1, iter: 1400, curr loss: 1.2990010976791382, avg loss: 1.3401637345552444\n",
      "trial: 1, ldr: 0.007283051498234272\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3841795921325684, avg loss: 1.3872492212057113\n",
      "trial: 2, iter: 400, curr loss: 1.3853851556777954, avg loss: 1.3860910642147064\n",
      "trial: 2, iter: 600, curr loss: 1.3672683238983154, avg loss: 1.3799035793542862\n",
      "trial: 2, iter: 800, curr loss: 1.340363621711731, avg loss: 1.3574478393793106\n",
      "trial: 2, iter: 1000, curr loss: 1.3388301134109497, avg loss: 1.3390480697154998\n",
      "trial: 2, iter: 1200, curr loss: 1.3567928075790405, avg loss: 1.3312833309173584\n",
      "trial: 2, iter: 1400, curr loss: 1.3447641134262085, avg loss: 1.3270313680171966\n",
      "trial: 2, ldr: 0.019576553255319595\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3884257078170776, avg loss: 1.3876022166013717\n",
      "trial: 3, iter: 400, curr loss: 1.383283257484436, avg loss: 1.3868787956237794\n",
      "trial: 3, iter: 600, curr loss: 1.3872758150100708, avg loss: 1.3853808289766312\n",
      "trial: 3, iter: 800, curr loss: 1.3717912435531616, avg loss: 1.3733507657051087\n",
      "trial: 3, iter: 1000, curr loss: 1.3372899293899536, avg loss: 1.3471856033802032\n",
      "trial: 3, iter: 1200, curr loss: 1.3502039909362793, avg loss: 1.3376566737890243\n",
      "trial: 3, iter: 1400, curr loss: 1.3479725122451782, avg loss: 1.3283804923295974\n",
      "trial: 3, ldr: 0.01615002006292343\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388763427734375, avg loss: 1.3874266707897187\n",
      "trial: 4, iter: 400, curr loss: 1.3873370885849, avg loss: 1.3865143209695816\n",
      "trial: 4, iter: 600, curr loss: 1.380056381225586, avg loss: 1.3839464092254639\n",
      "trial: 4, iter: 800, curr loss: 1.3466920852661133, avg loss: 1.3729717898368836\n",
      "trial: 4, iter: 1000, curr loss: 1.325135588645935, avg loss: 1.351941506266594\n",
      "trial: 4, iter: 1200, curr loss: 1.3467507362365723, avg loss: 1.3399818605184555\n",
      "trial: 4, iter: 1400, curr loss: 1.3262217044830322, avg loss: 1.3329407382011413\n",
      "trial: 4, ldr: -0.008320890367031097\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3869136571884155, avg loss: 1.3872653710842133\n",
      "trial: 5, iter: 400, curr loss: 1.3854948282241821, avg loss: 1.3865816062688827\n",
      "trial: 5, iter: 600, curr loss: 1.3881462812423706, avg loss: 1.3861256426572799\n",
      "trial: 5, iter: 800, curr loss: 1.3768616914749146, avg loss: 1.3827260148525238\n",
      "trial: 5, iter: 1000, curr loss: 1.3583393096923828, avg loss: 1.3600382840633392\n",
      "trial: 5, iter: 1200, curr loss: 1.3415393829345703, avg loss: 1.3403482711315156\n",
      "trial: 5, iter: 1400, curr loss: 1.3544633388519287, avg loss: 1.329483689069748\n",
      "trial: 5, ldr: -0.01865769736468792\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0032062074169516563\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3864802122116089, avg loss: 1.387414637207985\n",
      "trial: 1, iter: 400, curr loss: 1.3845415115356445, avg loss: 1.3865971273183824\n",
      "trial: 1, iter: 600, curr loss: 1.3812146186828613, avg loss: 1.385382512807846\n",
      "trial: 1, iter: 800, curr loss: 1.3605339527130127, avg loss: 1.3724115765094758\n",
      "trial: 1, iter: 1000, curr loss: 1.338056206703186, avg loss: 1.3448530572652817\n",
      "trial: 1, iter: 1200, curr loss: 1.3651273250579834, avg loss: 1.335314194560051\n",
      "trial: 1, iter: 1400, curr loss: 1.313128113746643, avg loss: 1.3256792920827865\n",
      "trial: 1, ldr: 0.04342690110206604\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3843729496002197, avg loss: 1.3875678062438965\n",
      "trial: 2, iter: 400, curr loss: 1.3872262239456177, avg loss: 1.3867478823661805\n",
      "trial: 2, iter: 600, curr loss: 1.3875961303710938, avg loss: 1.3862465667724608\n",
      "trial: 2, iter: 800, curr loss: 1.3743863105773926, avg loss: 1.3837016493082046\n",
      "trial: 2, iter: 1000, curr loss: 1.362106442451477, avg loss: 1.367747774720192\n",
      "trial: 2, iter: 1200, curr loss: 1.344970941543579, avg loss: 1.3462802439928054\n",
      "trial: 2, iter: 1400, curr loss: 1.3523085117340088, avg loss: 1.3330035853385924\n",
      "trial: 2, ldr: 0.040821436792612076\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3859933614730835, avg loss: 1.386837214231491\n",
      "trial: 3, iter: 400, curr loss: 1.3848614692687988, avg loss: 1.3861018627882005\n",
      "trial: 3, iter: 600, curr loss: 1.3803426027297974, avg loss: 1.384377955198288\n",
      "trial: 3, iter: 800, curr loss: 1.348829984664917, avg loss: 1.3704721289873123\n",
      "trial: 3, iter: 1000, curr loss: 1.3575575351715088, avg loss: 1.3456717324256897\n",
      "trial: 3, iter: 1200, curr loss: 1.3392478227615356, avg loss: 1.333721376657486\n",
      "trial: 3, iter: 1400, curr loss: 1.2943568229675293, avg loss: 1.3257610255479813\n",
      "trial: 3, ldr: 0.06765910983085632\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.384535551071167, avg loss: 1.3870939302444458\n",
      "trial: 4, iter: 400, curr loss: 1.387139916419983, avg loss: 1.3867098182439803\n",
      "trial: 4, iter: 600, curr loss: 1.3823294639587402, avg loss: 1.3861126762628555\n",
      "trial: 4, iter: 800, curr loss: 1.3898499011993408, avg loss: 1.3843690490722655\n",
      "trial: 4, iter: 1000, curr loss: 1.3642699718475342, avg loss: 1.3690195512771606\n",
      "trial: 4, iter: 1200, curr loss: 1.3218191862106323, avg loss: 1.3443956059217452\n",
      "trial: 4, iter: 1400, curr loss: 1.322130560874939, avg loss: 1.3323864126205445\n",
      "trial: 4, ldr: 0.0343717485666275\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3852571249008179, avg loss: 1.3869264596700668\n",
      "trial: 5, iter: 400, curr loss: 1.3819594383239746, avg loss: 1.38648666203022\n",
      "trial: 5, iter: 600, curr loss: 1.3863104581832886, avg loss: 1.3855447655916213\n",
      "trial: 5, iter: 800, curr loss: 1.3678648471832275, avg loss: 1.379188968539238\n",
      "trial: 5, iter: 1000, curr loss: 1.359477162361145, avg loss: 1.351928773522377\n",
      "trial: 5, iter: 1200, curr loss: 1.3412578105926514, avg loss: 1.3378610682487488\n",
      "trial: 5, iter: 1400, curr loss: 1.3553400039672852, avg loss: 1.3291422551870347\n",
      "trial: 5, ldr: 0.04864182695746422\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.04698420464992523\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386897087097168, avg loss: 1.3872104728221892\n",
      "trial: 1, iter: 400, curr loss: 1.3854546546936035, avg loss: 1.3859710067510604\n",
      "trial: 1, iter: 600, curr loss: 1.3782967329025269, avg loss: 1.3832712322473526\n",
      "trial: 1, iter: 800, curr loss: 1.366302728652954, avg loss: 1.3629028457403183\n",
      "trial: 1, iter: 1000, curr loss: 1.3308049440383911, avg loss: 1.340049551129341\n",
      "trial: 1, iter: 1200, curr loss: 1.3154577016830444, avg loss: 1.3257261896133423\n",
      "trial: 1, iter: 1400, curr loss: 1.3276708126068115, avg loss: 1.322801469564438\n",
      "trial: 1, ldr: 0.06387147307395935\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3906919956207275, avg loss: 1.3867035019397735\n",
      "trial: 2, iter: 400, curr loss: 1.3851269483566284, avg loss: 1.386060193181038\n",
      "trial: 2, iter: 600, curr loss: 1.3786782026290894, avg loss: 1.3837293469905854\n",
      "trial: 2, iter: 800, curr loss: 1.3536800146102905, avg loss: 1.3620243555307388\n",
      "trial: 2, iter: 1000, curr loss: 1.3505154848098755, avg loss: 1.3377257531881332\n",
      "trial: 2, iter: 1200, curr loss: 1.3060880899429321, avg loss: 1.3263096529245377\n",
      "trial: 2, iter: 1400, curr loss: 1.2931888103485107, avg loss: 1.3174267160892486\n",
      "trial: 2, ldr: 0.05167604982852936\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3839915990829468, avg loss: 1.3874237698316574\n",
      "trial: 3, iter: 400, curr loss: 1.389656662940979, avg loss: 1.3869878602027894\n",
      "trial: 3, iter: 600, curr loss: 1.3870970010757446, avg loss: 1.3862439370155335\n",
      "trial: 3, iter: 800, curr loss: 1.376703143119812, avg loss: 1.3823949658870698\n",
      "trial: 3, iter: 1000, curr loss: 1.3557913303375244, avg loss: 1.3590304678678513\n",
      "trial: 3, iter: 1200, curr loss: 1.3190349340438843, avg loss: 1.3383860397338867\n",
      "trial: 3, iter: 1400, curr loss: 1.3300095796585083, avg loss: 1.3290123075246811\n",
      "trial: 3, ldr: 0.01800617016851902\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3873953819274902, avg loss: 1.3869200551509857\n",
      "trial: 4, iter: 400, curr loss: 1.3887583017349243, avg loss: 1.38648564517498\n",
      "trial: 4, iter: 600, curr loss: 1.3850337266921997, avg loss: 1.3857799935340882\n",
      "trial: 4, iter: 800, curr loss: 1.3603410720825195, avg loss: 1.3754950439929963\n",
      "trial: 4, iter: 1000, curr loss: 1.3277039527893066, avg loss: 1.345957578420639\n",
      "trial: 4, iter: 1200, curr loss: 1.3244833946228027, avg loss: 1.3344169771671295\n",
      "trial: 4, iter: 1400, curr loss: 1.3023288249969482, avg loss: 1.3217869073152542\n",
      "trial: 4, ldr: 0.06645950675010681\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3857505321502686, avg loss: 1.3872578406333924\n",
      "trial: 5, iter: 400, curr loss: 1.38737952709198, avg loss: 1.3865844810009003\n",
      "trial: 5, iter: 600, curr loss: 1.3886719942092896, avg loss: 1.386340119242668\n",
      "trial: 5, iter: 800, curr loss: 1.3818966150283813, avg loss: 1.3857175505161285\n",
      "trial: 5, iter: 1000, curr loss: 1.3477222919464111, avg loss: 1.3726935017108917\n",
      "trial: 5, iter: 1200, curr loss: 1.3484338521957397, avg loss: 1.340316811800003\n",
      "trial: 5, iter: 1400, curr loss: 1.3278785943984985, avg loss: 1.3294991338253022\n",
      "trial: 5, ldr: 0.041748419404029846\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.048352323845028876\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3872493505477905, avg loss: 1.386984759569168\n",
      "trial: 1, iter: 400, curr loss: 1.384373426437378, avg loss: 1.386107081770897\n",
      "trial: 1, iter: 600, curr loss: 1.3787121772766113, avg loss: 1.3843100297451019\n",
      "trial: 1, iter: 800, curr loss: 1.3560075759887695, avg loss: 1.36644089281559\n",
      "trial: 1, iter: 1000, curr loss: 1.324912190437317, avg loss: 1.340218415260315\n",
      "trial: 1, iter: 1200, curr loss: 1.342132568359375, avg loss: 1.3300407499074935\n",
      "trial: 1, iter: 1400, curr loss: 1.3347296714782715, avg loss: 1.3204322135448456\n",
      "trial: 1, ldr: 0.04796072840690613\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3869750499725342, avg loss: 1.3870645010471343\n",
      "trial: 2, iter: 400, curr loss: 1.3876029253005981, avg loss: 1.386146064400673\n",
      "trial: 2, iter: 600, curr loss: 1.3739619255065918, avg loss: 1.3832143396139145\n",
      "trial: 2, iter: 800, curr loss: 1.3334176540374756, avg loss: 1.3648088216781615\n",
      "trial: 2, iter: 1000, curr loss: 1.313016653060913, avg loss: 1.3416598427295685\n",
      "trial: 2, iter: 1200, curr loss: 1.3343842029571533, avg loss: 1.3321405243873596\n",
      "trial: 2, iter: 1400, curr loss: 1.3422112464904785, avg loss: 1.3244922584295273\n",
      "trial: 2, ldr: -0.011995366774499416\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3808280229568481, avg loss: 1.3870721364021301\n",
      "trial: 3, iter: 400, curr loss: 1.3863250017166138, avg loss: 1.3858414113521575\n",
      "trial: 3, iter: 600, curr loss: 1.3757357597351074, avg loss: 1.3780598974227904\n",
      "trial: 3, iter: 800, curr loss: 1.3281846046447754, avg loss: 1.350187674164772\n",
      "trial: 3, iter: 1000, curr loss: 1.3359980583190918, avg loss: 1.3376033276319503\n",
      "trial: 3, iter: 1200, curr loss: 1.3001021146774292, avg loss: 1.3280806940793992\n",
      "trial: 3, iter: 1400, curr loss: 1.3077689409255981, avg loss: 1.3229899382591248\n",
      "trial: 3, ldr: 0.019802574068307877\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860416412353516, avg loss: 1.387128637433052\n",
      "trial: 4, iter: 400, curr loss: 1.3860071897506714, avg loss: 1.3863736230134964\n",
      "trial: 4, iter: 600, curr loss: 1.3854695558547974, avg loss: 1.3851536315679551\n",
      "trial: 4, iter: 800, curr loss: 1.3694263696670532, avg loss: 1.3750070893764497\n",
      "trial: 4, iter: 1000, curr loss: 1.3568066358566284, avg loss: 1.3500781881809234\n",
      "trial: 4, iter: 1200, curr loss: 1.3084684610366821, avg loss: 1.3340194934606553\n",
      "trial: 4, iter: 1400, curr loss: 1.3254308700561523, avg loss: 1.3250866669416428\n",
      "trial: 4, ldr: -0.013365435414016247\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882465362548828, avg loss: 1.3873305982351303\n",
      "trial: 5, iter: 400, curr loss: 1.3881828784942627, avg loss: 1.3863545340299606\n",
      "trial: 5, iter: 600, curr loss: 1.3837244510650635, avg loss: 1.384263335466385\n",
      "trial: 5, iter: 800, curr loss: 1.335042953491211, avg loss: 1.3643510288000107\n",
      "trial: 5, iter: 1000, curr loss: 1.334779143333435, avg loss: 1.338079292178154\n",
      "trial: 5, iter: 1200, curr loss: 1.3240864276885986, avg loss: 1.3298209661245346\n",
      "trial: 5, iter: 1400, curr loss: 1.3280994892120361, avg loss: 1.3260749059915542\n",
      "trial: 5, ldr: -0.010318516753613949\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0064167967066168785\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3861253261566162, avg loss: 1.3870289725065232\n",
      "trial: 1, iter: 400, curr loss: 1.384661078453064, avg loss: 1.3866949820518493\n",
      "trial: 1, iter: 600, curr loss: 1.3826404809951782, avg loss: 1.386147592663765\n",
      "trial: 1, iter: 800, curr loss: 1.364008903503418, avg loss: 1.382283905148506\n",
      "trial: 1, iter: 1000, curr loss: 1.3573393821716309, avg loss: 1.3557234054803848\n",
      "trial: 1, iter: 1200, curr loss: 1.348140835762024, avg loss: 1.3370572239160539\n",
      "trial: 1, iter: 1400, curr loss: 1.3212697505950928, avg loss: 1.3272232222557068\n",
      "trial: 1, ldr: 0.02328772284090519\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.388408899307251, avg loss: 1.387090903520584\n",
      "trial: 2, iter: 400, curr loss: 1.3831733465194702, avg loss: 1.3863833928108216\n",
      "trial: 2, iter: 600, curr loss: 1.3696082830429077, avg loss: 1.3824149733781814\n",
      "trial: 2, iter: 800, curr loss: 1.3534094095230103, avg loss: 1.3572701746225357\n",
      "trial: 2, iter: 1000, curr loss: 1.327934980392456, avg loss: 1.3376385897397995\n",
      "trial: 2, iter: 1200, curr loss: 1.3326942920684814, avg loss: 1.3280976104736328\n",
      "trial: 2, iter: 1400, curr loss: 1.3271558284759521, avg loss: 1.321443583369255\n",
      "trial: 2, ldr: 0.026416299864649773\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3870861530303955, avg loss: 1.3874032312631608\n",
      "trial: 3, iter: 400, curr loss: 1.3872820138931274, avg loss: 1.3864765053987502\n",
      "trial: 3, iter: 600, curr loss: 1.3860820531845093, avg loss: 1.385981666445732\n",
      "trial: 3, iter: 800, curr loss: 1.3731472492218018, avg loss: 1.3820885467529296\n",
      "trial: 3, iter: 1000, curr loss: 1.3581551313400269, avg loss: 1.3636670434474945\n",
      "trial: 3, iter: 1200, curr loss: 1.341353416442871, avg loss: 1.340049106478691\n",
      "trial: 3, iter: 1400, curr loss: 1.3450596332550049, avg loss: 1.3293326586484908\n",
      "trial: 3, ldr: 0.04647313430905342\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3888368606567383, avg loss: 1.3873262226581573\n",
      "trial: 4, iter: 400, curr loss: 1.3856942653656006, avg loss: 1.3863465613126755\n",
      "trial: 4, iter: 600, curr loss: 1.3810375928878784, avg loss: 1.384487726688385\n",
      "trial: 4, iter: 800, curr loss: 1.3378970623016357, avg loss: 1.3663656812906266\n",
      "trial: 4, iter: 1000, curr loss: 1.3371460437774658, avg loss: 1.3438932728767394\n",
      "trial: 4, iter: 1200, curr loss: 1.3241865634918213, avg loss: 1.3323198658227922\n",
      "trial: 4, iter: 1400, curr loss: 1.3152202367782593, avg loss: 1.3279116320610047\n",
      "trial: 4, ldr: 0.022058146074414253\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3864977359771729, avg loss: 1.3872962695360185\n",
      "trial: 5, iter: 400, curr loss: 1.3875083923339844, avg loss: 1.3865805608034134\n",
      "trial: 5, iter: 600, curr loss: 1.3844674825668335, avg loss: 1.3851250433921813\n",
      "trial: 5, iter: 800, curr loss: 1.364578127861023, avg loss: 1.3697585260868073\n",
      "trial: 5, iter: 1000, curr loss: 1.3425846099853516, avg loss: 1.3417570614814758\n",
      "trial: 5, iter: 1200, curr loss: 1.317611575126648, avg loss: 1.327449196577072\n",
      "trial: 5, iter: 1400, curr loss: 1.3004006147384644, avg loss: 1.3228581088781357\n",
      "trial: 5, ldr: 0.020570101216435432\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.027761080861091615\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.389679193496704, avg loss: 1.3872600388526917\n",
      "trial: 1, iter: 400, curr loss: 1.3805445432662964, avg loss: 1.3863236999511719\n",
      "trial: 1, iter: 600, curr loss: 1.3701292276382446, avg loss: 1.3809825456142426\n",
      "trial: 1, iter: 800, curr loss: 1.3574873208999634, avg loss: 1.3591986280679702\n",
      "trial: 1, iter: 1000, curr loss: 1.3457205295562744, avg loss: 1.3414209735393525\n",
      "trial: 1, iter: 1200, curr loss: 1.3288506269454956, avg loss: 1.3318493896722794\n",
      "trial: 1, iter: 1400, curr loss: 1.3052575588226318, avg loss: 1.3260145032405852\n",
      "trial: 1, ldr: 0.04486815258860588\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3876261711120605, avg loss: 1.387163006067276\n",
      "trial: 2, iter: 400, curr loss: 1.3846379518508911, avg loss: 1.386498622894287\n",
      "trial: 2, iter: 600, curr loss: 1.3851686716079712, avg loss: 1.3848693406581878\n",
      "trial: 2, iter: 800, curr loss: 1.3525142669677734, avg loss: 1.3753704988956452\n",
      "trial: 2, iter: 1000, curr loss: 1.324226975440979, avg loss: 1.3503763091564178\n",
      "trial: 2, iter: 1200, curr loss: 1.3165944814682007, avg loss: 1.3380596655607224\n",
      "trial: 2, iter: 1400, curr loss: 1.3317142724990845, avg loss: 1.327806189060211\n",
      "trial: 2, ldr: 0.07699037343263626\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389133334159851, avg loss: 1.3870683574676514\n",
      "trial: 3, iter: 400, curr loss: 1.3849035501480103, avg loss: 1.3864905953407287\n",
      "trial: 3, iter: 600, curr loss: 1.3839727640151978, avg loss: 1.385708031654358\n",
      "trial: 3, iter: 800, curr loss: 1.3565644025802612, avg loss: 1.3762126880884171\n",
      "trial: 3, iter: 1000, curr loss: 1.351503849029541, avg loss: 1.3496071070432663\n",
      "trial: 3, iter: 1200, curr loss: 1.362760305404663, avg loss: 1.3365871262550355\n",
      "trial: 3, iter: 1400, curr loss: 1.3422400951385498, avg loss: 1.3260747969150544\n",
      "trial: 3, ldr: 0.01776568964123726\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386309027671814, avg loss: 1.3871643596887588\n",
      "trial: 4, iter: 400, curr loss: 1.385242223739624, avg loss: 1.3867385041713716\n",
      "trial: 4, iter: 600, curr loss: 1.3849984407424927, avg loss: 1.3856549316644668\n",
      "trial: 4, iter: 800, curr loss: 1.360320806503296, avg loss: 1.3762093031406402\n",
      "trial: 4, iter: 1000, curr loss: 1.3257865905761719, avg loss: 1.345687028169632\n",
      "trial: 4, iter: 1200, curr loss: 1.3591912984848022, avg loss: 1.334722546339035\n",
      "trial: 4, iter: 1400, curr loss: 1.3280270099639893, avg loss: 1.3254604387283324\n",
      "trial: 4, ldr: 0.039605461061000824\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3874235153198242, avg loss: 1.3873052275180817\n",
      "trial: 5, iter: 400, curr loss: 1.3824740648269653, avg loss: 1.38675079703331\n",
      "trial: 5, iter: 600, curr loss: 1.3871229887008667, avg loss: 1.38514497756958\n",
      "trial: 5, iter: 800, curr loss: 1.3630952835083008, avg loss: 1.3702605378627777\n",
      "trial: 5, iter: 1000, curr loss: 1.336804747581482, avg loss: 1.3431495940685272\n",
      "trial: 5, iter: 1200, curr loss: 1.3091742992401123, avg loss: 1.3297815322875977\n",
      "trial: 5, iter: 1400, curr loss: 1.2827880382537842, avg loss: 1.324959111213684\n",
      "trial: 5, ldr: 0.03814070671796799\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.04347407668828964\n",
      "Experiment done with data path: ./data/catNon-lin-NI_5/data.5k.dz20.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_10/data.10k.dz50.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873950242996216, avg loss: 1.3872964143753053\n",
      "trial: 1, iter: 400, curr loss: 1.387048602104187, avg loss: 1.386493257880211\n",
      "trial: 1, iter: 600, curr loss: 1.3800002336502075, avg loss: 1.3844064086675645\n",
      "trial: 1, iter: 800, curr loss: 1.3612163066864014, avg loss: 1.3791690242290497\n",
      "trial: 1, iter: 1000, curr loss: 1.3710010051727295, avg loss: 1.3728619474172592\n",
      "trial: 1, iter: 1200, curr loss: 1.3460553884506226, avg loss: 1.3652216559648513\n",
      "trial: 1, iter: 1400, curr loss: 1.3621989488601685, avg loss: 1.360094473361969\n",
      "trial: 1, iter: 1600, curr loss: 1.3521853685379028, avg loss: 1.354653531908989\n",
      "trial: 1, iter: 1800, curr loss: 1.3489516973495483, avg loss: 1.3461810845136641\n",
      "trial: 1, iter: 2000, curr loss: 1.3120737075805664, avg loss: 1.3380138611793517\n",
      "trial: 1, iter: 2200, curr loss: 1.29635488986969, avg loss: 1.3295471626520157\n",
      "trial: 1, iter: 2400, curr loss: 1.3089954853057861, avg loss: 1.317684250473976\n",
      "trial: 1, iter: 2600, curr loss: 1.3176695108413696, avg loss: 1.3121213185787202\n",
      "trial: 1, iter: 2800, curr loss: 1.3203128576278687, avg loss: 1.306375834941864\n",
      "trial: 1, iter: 3000, curr loss: 1.3357070684432983, avg loss: 1.2988278859853744\n",
      "trial: 1, ldr: 0.17918425798416138\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3831684589385986, avg loss: 1.3871717631816864\n",
      "trial: 2, iter: 400, curr loss: 1.3871549367904663, avg loss: 1.3866283494234084\n",
      "trial: 2, iter: 600, curr loss: 1.3847603797912598, avg loss: 1.3862871980667115\n",
      "trial: 2, iter: 800, curr loss: 1.3692184686660767, avg loss: 1.3829430270195007\n",
      "trial: 2, iter: 1000, curr loss: 1.3541197776794434, avg loss: 1.372164506316185\n",
      "trial: 2, iter: 1200, curr loss: 1.3665175437927246, avg loss: 1.3659667319059372\n",
      "trial: 2, iter: 1400, curr loss: 1.3366163969039917, avg loss: 1.358427072763443\n",
      "trial: 2, iter: 1600, curr loss: 1.3544179201126099, avg loss: 1.3534265977144242\n",
      "trial: 2, iter: 1800, curr loss: 1.3208140134811401, avg loss: 1.3466693669557572\n",
      "trial: 2, iter: 2000, curr loss: 1.3249238729476929, avg loss: 1.3371802896261216\n",
      "trial: 2, iter: 2200, curr loss: 1.3182964324951172, avg loss: 1.3300194591283798\n",
      "trial: 2, iter: 2400, curr loss: 1.3408912420272827, avg loss: 1.3213117134571075\n",
      "trial: 2, iter: 2600, curr loss: 1.2971324920654297, avg loss: 1.3146640557050704\n",
      "trial: 2, iter: 2800, curr loss: 1.2643938064575195, avg loss: 1.308930782675743\n",
      "trial: 2, iter: 3000, curr loss: 1.3250244855880737, avg loss: 1.3041264736652374\n",
      "trial: 2, ldr: 0.1547844111919403\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3862171173095703, avg loss: 1.3873173826932907\n",
      "trial: 3, iter: 400, curr loss: 1.384957194328308, avg loss: 1.386483661532402\n",
      "trial: 3, iter: 600, curr loss: 1.3884167671203613, avg loss: 1.3861418235301972\n",
      "trial: 3, iter: 800, curr loss: 1.3788963556289673, avg loss: 1.3838959908485413\n",
      "trial: 3, iter: 1000, curr loss: 1.3583710193634033, avg loss: 1.37264468729496\n",
      "trial: 3, iter: 1200, curr loss: 1.350461483001709, avg loss: 1.363354316353798\n",
      "trial: 3, iter: 1400, curr loss: 1.3693828582763672, avg loss: 1.360219538807869\n",
      "trial: 3, iter: 1600, curr loss: 1.3468446731567383, avg loss: 1.351453146338463\n",
      "trial: 3, iter: 1800, curr loss: 1.3345037698745728, avg loss: 1.343926004767418\n",
      "trial: 3, iter: 2000, curr loss: 1.340472936630249, avg loss: 1.3352643239498139\n",
      "trial: 3, iter: 2200, curr loss: 1.3290420770645142, avg loss: 1.3236425828933716\n",
      "trial: 3, iter: 2400, curr loss: 1.2920162677764893, avg loss: 1.3194182819128037\n",
      "trial: 3, iter: 2600, curr loss: 1.2911772727966309, avg loss: 1.3114540606737137\n",
      "trial: 3, iter: 2800, curr loss: 1.2891055345535278, avg loss: 1.3063352739810943\n",
      "trial: 3, iter: 3000, curr loss: 1.3070878982543945, avg loss: 1.3045672112703324\n",
      "trial: 3, ldr: 0.27058160305023193\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865138292312622, avg loss: 1.3871463924646377\n",
      "trial: 4, iter: 400, curr loss: 1.3854093551635742, avg loss: 1.386388037800789\n",
      "trial: 4, iter: 600, curr loss: 1.3857641220092773, avg loss: 1.3860283386707306\n",
      "trial: 4, iter: 800, curr loss: 1.3698176145553589, avg loss: 1.3820876663923263\n",
      "trial: 4, iter: 1000, curr loss: 1.361480712890625, avg loss: 1.3698876261711121\n",
      "trial: 4, iter: 1200, curr loss: 1.3522357940673828, avg loss: 1.364524808526039\n",
      "trial: 4, iter: 1400, curr loss: 1.356467843055725, avg loss: 1.359504643678665\n",
      "trial: 4, iter: 1600, curr loss: 1.3531962633132935, avg loss: 1.3532414466142655\n",
      "trial: 4, iter: 1800, curr loss: 1.3366223573684692, avg loss: 1.3440213853120804\n",
      "trial: 4, iter: 2000, curr loss: 1.3226810693740845, avg loss: 1.3377501219511032\n",
      "trial: 4, iter: 2200, curr loss: 1.3570317029953003, avg loss: 1.329173713326454\n",
      "trial: 4, iter: 2400, curr loss: 1.2832928895950317, avg loss: 1.3196071124076842\n",
      "trial: 4, iter: 2600, curr loss: 1.3348158597946167, avg loss: 1.3131313353776932\n",
      "trial: 4, iter: 2800, curr loss: 1.2937273979187012, avg loss: 1.3096181929111481\n",
      "trial: 4, iter: 3000, curr loss: 1.3203365802764893, avg loss: 1.3065110820531844\n",
      "trial: 4, ldr: 0.2079499214887619\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3886816501617432, avg loss: 1.3873590451478959\n",
      "trial: 5, iter: 400, curr loss: 1.3858505487442017, avg loss: 1.386614909172058\n",
      "trial: 5, iter: 600, curr loss: 1.3884034156799316, avg loss: 1.3863455855846405\n",
      "trial: 5, iter: 800, curr loss: 1.3774069547653198, avg loss: 1.384713153243065\n",
      "trial: 5, iter: 1000, curr loss: 1.3843008279800415, avg loss: 1.380722886323929\n",
      "trial: 5, iter: 1200, curr loss: 1.364197015762329, avg loss: 1.3783713567256928\n",
      "trial: 5, iter: 1400, curr loss: 1.364745855331421, avg loss: 1.3715056186914445\n",
      "trial: 5, iter: 1600, curr loss: 1.3658416271209717, avg loss: 1.3637132519483566\n",
      "trial: 5, iter: 1800, curr loss: 1.3498411178588867, avg loss: 1.3581423717737198\n",
      "trial: 5, iter: 2000, curr loss: 1.3236242532730103, avg loss: 1.3562882494926454\n",
      "trial: 5, iter: 2200, curr loss: 1.3267604112625122, avg loss: 1.3466208148002625\n",
      "trial: 5, iter: 2400, curr loss: 1.3186705112457275, avg loss: 1.339351137280464\n",
      "trial: 5, iter: 2600, curr loss: 1.3196978569030762, avg loss: 1.3321733182668687\n",
      "trial: 5, iter: 2800, curr loss: 1.3281916379928589, avg loss: 1.3195827597379683\n",
      "trial: 5, iter: 3000, curr loss: 1.2976460456848145, avg loss: 1.3117371034622192\n",
      "trial: 5, ldr: 0.1970437616109848\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20190879106521606\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3840312957763672, avg loss: 1.3873228192329408\n",
      "trial: 1, iter: 400, curr loss: 1.3862762451171875, avg loss: 1.3864758962392807\n",
      "trial: 1, iter: 600, curr loss: 1.3846253156661987, avg loss: 1.385470359325409\n",
      "trial: 1, iter: 800, curr loss: 1.362287998199463, avg loss: 1.3783515036106109\n",
      "trial: 1, iter: 1000, curr loss: 1.3640118837356567, avg loss: 1.37177054643631\n",
      "trial: 1, iter: 1200, curr loss: 1.3643008470535278, avg loss: 1.367823303937912\n",
      "trial: 1, iter: 1400, curr loss: 1.354191780090332, avg loss: 1.362222012281418\n",
      "trial: 1, iter: 1600, curr loss: 1.3425883054733276, avg loss: 1.3552065885066986\n",
      "trial: 1, iter: 1800, curr loss: 1.3499889373779297, avg loss: 1.3487237191200256\n",
      "trial: 1, iter: 2000, curr loss: 1.3228371143341064, avg loss: 1.3428185367584229\n",
      "trial: 1, iter: 2200, curr loss: 1.3424357175827026, avg loss: 1.3338200843334198\n",
      "trial: 1, iter: 2400, curr loss: 1.352086067199707, avg loss: 1.3258759421110153\n",
      "trial: 1, iter: 2600, curr loss: 1.3232088088989258, avg loss: 1.3210335677862168\n",
      "trial: 1, iter: 2800, curr loss: 1.297485589981079, avg loss: 1.3160939598083496\n",
      "trial: 1, iter: 3000, curr loss: 1.278346300125122, avg loss: 1.3138002598285674\n",
      "trial: 1, ldr: 0.10927654802799225\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3860459327697754, avg loss: 1.3871252423524856\n",
      "trial: 2, iter: 400, curr loss: 1.3879579305648804, avg loss: 1.3866178995370866\n",
      "trial: 2, iter: 600, curr loss: 1.3876926898956299, avg loss: 1.386555431485176\n",
      "trial: 2, iter: 800, curr loss: 1.3868515491485596, avg loss: 1.3862215977907182\n",
      "trial: 2, iter: 1000, curr loss: 1.3844190835952759, avg loss: 1.3846550017595292\n",
      "trial: 2, iter: 1200, curr loss: 1.372320532798767, avg loss: 1.3752041751146316\n",
      "trial: 2, iter: 1400, curr loss: 1.3696175813674927, avg loss: 1.3696092802286148\n",
      "trial: 2, iter: 1600, curr loss: 1.373055338859558, avg loss: 1.3622477066516876\n",
      "trial: 2, iter: 1800, curr loss: 1.3780241012573242, avg loss: 1.355990858078003\n",
      "trial: 2, iter: 2000, curr loss: 1.353834629058838, avg loss: 1.352667362689972\n",
      "trial: 2, iter: 2200, curr loss: 1.3187947273254395, avg loss: 1.342333116531372\n",
      "trial: 2, iter: 2400, curr loss: 1.3302544355392456, avg loss: 1.33496273458004\n",
      "trial: 2, iter: 2600, curr loss: 1.3393489122390747, avg loss: 1.3289327239990234\n",
      "trial: 2, iter: 2800, curr loss: 1.3036493062973022, avg loss: 1.327481124997139\n",
      "trial: 2, iter: 3000, curr loss: 1.3201013803482056, avg loss: 1.3178772646188737\n",
      "trial: 2, ldr: 0.10205874592065811\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3878940343856812, avg loss: 1.3875322151184082\n",
      "trial: 3, iter: 400, curr loss: 1.388888955116272, avg loss: 1.3866886484622956\n",
      "trial: 3, iter: 600, curr loss: 1.3864891529083252, avg loss: 1.3865340757369995\n",
      "trial: 3, iter: 800, curr loss: 1.3864210844039917, avg loss: 1.38639435172081\n",
      "trial: 3, iter: 1000, curr loss: 1.3844523429870605, avg loss: 1.3864969003200531\n",
      "trial: 3, iter: 1200, curr loss: 1.380929946899414, avg loss: 1.3853015899658203\n",
      "trial: 3, iter: 1400, curr loss: 1.369936466217041, avg loss: 1.3779046583175658\n",
      "trial: 3, iter: 1600, curr loss: 1.384997844696045, avg loss: 1.3683609473705292\n",
      "trial: 3, iter: 1800, curr loss: 1.3551793098449707, avg loss: 1.3640470600128174\n",
      "trial: 3, iter: 2000, curr loss: 1.3583916425704956, avg loss: 1.3563537669181824\n",
      "trial: 3, iter: 2200, curr loss: 1.3438550233840942, avg loss: 1.3508118867874146\n",
      "trial: 3, iter: 2400, curr loss: 1.3284493684768677, avg loss: 1.3409508007764817\n",
      "trial: 3, iter: 2600, curr loss: 1.3404333591461182, avg loss: 1.3334616059064865\n",
      "trial: 3, iter: 2800, curr loss: 1.324722170829773, avg loss: 1.326078966856003\n",
      "trial: 3, iter: 3000, curr loss: 1.3025130033493042, avg loss: 1.3195107132196426\n",
      "trial: 3, ldr: 0.1668478548526764\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3885098695755005, avg loss: 1.3873431086540222\n",
      "trial: 4, iter: 400, curr loss: 1.3864715099334717, avg loss: 1.3868052065372467\n",
      "trial: 4, iter: 600, curr loss: 1.3859796524047852, avg loss: 1.38656621158123\n",
      "trial: 4, iter: 800, curr loss: 1.3872742652893066, avg loss: 1.3864808225631713\n",
      "trial: 4, iter: 1000, curr loss: 1.3845349550247192, avg loss: 1.386094070672989\n",
      "trial: 4, iter: 1200, curr loss: 1.3809149265289307, avg loss: 1.3836469537019729\n",
      "trial: 4, iter: 1400, curr loss: 1.3919059038162231, avg loss: 1.3723441290855407\n",
      "trial: 4, iter: 1600, curr loss: 1.3709068298339844, avg loss: 1.3657614552974702\n",
      "trial: 4, iter: 1800, curr loss: 1.3388044834136963, avg loss: 1.3599968206882478\n",
      "trial: 4, iter: 2000, curr loss: 1.3362466096878052, avg loss: 1.354761655330658\n",
      "trial: 4, iter: 2200, curr loss: 1.3204420804977417, avg loss: 1.3459105694293976\n",
      "trial: 4, iter: 2400, curr loss: 1.3203643560409546, avg loss: 1.3372395598888398\n",
      "trial: 4, iter: 2600, curr loss: 1.3015284538269043, avg loss: 1.3305700981616975\n",
      "trial: 4, iter: 2800, curr loss: 1.3654861450195312, avg loss: 1.3235508328676224\n",
      "trial: 4, iter: 3000, curr loss: 1.305644154548645, avg loss: 1.3169952595233918\n",
      "trial: 4, ldr: 0.13108181953430176\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3903075456619263, avg loss: 1.3874088793992996\n",
      "trial: 5, iter: 400, curr loss: 1.3806499242782593, avg loss: 1.3865702414512635\n",
      "trial: 5, iter: 600, curr loss: 1.3855082988739014, avg loss: 1.3863490533828735\n",
      "trial: 5, iter: 800, curr loss: 1.3830437660217285, avg loss: 1.385687780380249\n",
      "trial: 5, iter: 1000, curr loss: 1.3867268562316895, avg loss: 1.382488389611244\n",
      "trial: 5, iter: 1200, curr loss: 1.371514081954956, avg loss: 1.3719083607196807\n",
      "trial: 5, iter: 1400, curr loss: 1.3644909858703613, avg loss: 1.3659181034564971\n",
      "trial: 5, iter: 1600, curr loss: 1.3526095151901245, avg loss: 1.3614855885505677\n",
      "trial: 5, iter: 1800, curr loss: 1.3620352745056152, avg loss: 1.356582426428795\n",
      "trial: 5, iter: 2000, curr loss: 1.3385486602783203, avg loss: 1.3510677993297577\n",
      "trial: 5, iter: 2200, curr loss: 1.3313331604003906, avg loss: 1.3439503479003907\n",
      "trial: 5, iter: 2400, curr loss: 1.3401249647140503, avg loss: 1.3355803990364075\n",
      "trial: 5, iter: 2600, curr loss: 1.3332856893539429, avg loss: 1.3265527129173278\n",
      "trial: 5, iter: 2800, curr loss: 1.3020919561386108, avg loss: 1.3197493207454682\n",
      "trial: 5, iter: 3000, curr loss: 1.3241561651229858, avg loss: 1.3132965081930161\n",
      "trial: 5, ldr: 0.15218673646450043\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1322903409600258\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873704671859741, avg loss: 1.387356117963791\n",
      "trial: 1, iter: 400, curr loss: 1.3849412202835083, avg loss: 1.3867456114292145\n",
      "trial: 1, iter: 600, curr loss: 1.3876018524169922, avg loss: 1.3864928656816482\n",
      "trial: 1, iter: 800, curr loss: 1.3844873905181885, avg loss: 1.386236862540245\n",
      "trial: 1, iter: 1000, curr loss: 1.3777542114257812, avg loss: 1.3826794087886811\n",
      "trial: 1, iter: 1200, curr loss: 1.3715156316757202, avg loss: 1.373966736793518\n",
      "trial: 1, iter: 1400, curr loss: 1.3934961557388306, avg loss: 1.368389055132866\n",
      "trial: 1, iter: 1600, curr loss: 1.3698406219482422, avg loss: 1.3625472331047057\n",
      "trial: 1, iter: 1800, curr loss: 1.3471195697784424, avg loss: 1.356603342294693\n",
      "trial: 1, iter: 2000, curr loss: 1.329196572303772, avg loss: 1.3499502164125443\n",
      "trial: 1, iter: 2200, curr loss: 1.342030644416809, avg loss: 1.3407999932765962\n",
      "trial: 1, iter: 2400, curr loss: 1.3143812417984009, avg loss: 1.3346391838788987\n",
      "trial: 1, iter: 2600, curr loss: 1.3147404193878174, avg loss: 1.3251485860347747\n",
      "trial: 1, iter: 2800, curr loss: 1.3112431764602661, avg loss: 1.3202205991744995\n",
      "trial: 1, iter: 3000, curr loss: 1.2937461137771606, avg loss: 1.3106163150072099\n",
      "trial: 1, ldr: 0.2749975025653839\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3851735591888428, avg loss: 1.3872341984510421\n",
      "trial: 2, iter: 400, curr loss: 1.3876947164535522, avg loss: 1.386422935128212\n",
      "trial: 2, iter: 600, curr loss: 1.3890935182571411, avg loss: 1.3860070782899856\n",
      "trial: 2, iter: 800, curr loss: 1.3870632648468018, avg loss: 1.385343866944313\n",
      "trial: 2, iter: 1000, curr loss: 1.3709107637405396, avg loss: 1.3785832041502\n",
      "trial: 2, iter: 1200, curr loss: 1.3718044757843018, avg loss: 1.367398829460144\n",
      "trial: 2, iter: 1400, curr loss: 1.3601847887039185, avg loss: 1.3636628860235214\n",
      "trial: 2, iter: 1600, curr loss: 1.3600058555603027, avg loss: 1.3578334659337998\n",
      "trial: 2, iter: 1800, curr loss: 1.340245246887207, avg loss: 1.3518431210517883\n",
      "trial: 2, iter: 2000, curr loss: 1.3218148946762085, avg loss: 1.3399712342023848\n",
      "trial: 2, iter: 2200, curr loss: 1.3102972507476807, avg loss: 1.3311295968294143\n",
      "trial: 2, iter: 2400, curr loss: 1.2967849969863892, avg loss: 1.3214751768112183\n",
      "trial: 2, iter: 2600, curr loss: 1.3278791904449463, avg loss: 1.3128400057554246\n",
      "trial: 2, iter: 2800, curr loss: 1.3240199089050293, avg loss: 1.3095983457565308\n",
      "trial: 2, iter: 3000, curr loss: 1.282719373703003, avg loss: 1.3035526406764983\n",
      "trial: 2, ldr: 0.18337909877300262\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3883850574493408, avg loss: 1.3873904329538345\n",
      "trial: 3, iter: 400, curr loss: 1.382957100868225, avg loss: 1.3868532174825667\n",
      "trial: 3, iter: 600, curr loss: 1.3891019821166992, avg loss: 1.38656503200531\n",
      "trial: 3, iter: 800, curr loss: 1.381766676902771, avg loss: 1.3861297261714935\n",
      "trial: 3, iter: 1000, curr loss: 1.3831895589828491, avg loss: 1.3844599479436874\n",
      "trial: 3, iter: 1200, curr loss: 1.3693875074386597, avg loss: 1.3765914326906203\n",
      "trial: 3, iter: 1400, curr loss: 1.3746763467788696, avg loss: 1.3700197863578796\n",
      "trial: 3, iter: 1600, curr loss: 1.370386004447937, avg loss: 1.3636694526672364\n",
      "trial: 3, iter: 1800, curr loss: 1.349465012550354, avg loss: 1.3575319892168045\n",
      "trial: 3, iter: 2000, curr loss: 1.363464593887329, avg loss: 1.3480436152219772\n",
      "trial: 3, iter: 2200, curr loss: 1.3404757976531982, avg loss: 1.3408535194396973\n",
      "trial: 3, iter: 2400, curr loss: 1.334204912185669, avg loss: 1.3334897768497467\n",
      "trial: 3, iter: 2600, curr loss: 1.3212445974349976, avg loss: 1.3257608753442764\n",
      "trial: 3, iter: 2800, curr loss: 1.3027515411376953, avg loss: 1.320162279009819\n",
      "trial: 3, iter: 3000, curr loss: 1.3115599155426025, avg loss: 1.314706745147705\n",
      "trial: 3, ldr: 0.2407938539981842\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.383626937866211, avg loss: 1.3873883801698685\n",
      "trial: 4, iter: 400, curr loss: 1.3864210844039917, avg loss: 1.3864125764369966\n",
      "trial: 4, iter: 600, curr loss: 1.3851736783981323, avg loss: 1.3862549275159837\n",
      "trial: 4, iter: 800, curr loss: 1.377882719039917, avg loss: 1.3827216136455536\n",
      "trial: 4, iter: 1000, curr loss: 1.3603965044021606, avg loss: 1.3732458299398422\n",
      "trial: 4, iter: 1200, curr loss: 1.3550078868865967, avg loss: 1.3668622171878815\n",
      "trial: 4, iter: 1400, curr loss: 1.3437083959579468, avg loss: 1.3605983942747115\n",
      "trial: 4, iter: 1600, curr loss: 1.3324387073516846, avg loss: 1.3547245103120804\n",
      "trial: 4, iter: 1800, curr loss: 1.3324300050735474, avg loss: 1.3439635747671128\n",
      "trial: 4, iter: 2000, curr loss: 1.3183051347732544, avg loss: 1.337203141450882\n",
      "trial: 4, iter: 2200, curr loss: 1.3342382907867432, avg loss: 1.3312588971853256\n",
      "trial: 4, iter: 2400, curr loss: 1.3220762014389038, avg loss: 1.3277440083026886\n",
      "trial: 4, iter: 2600, curr loss: 1.3019709587097168, avg loss: 1.315295078754425\n",
      "trial: 4, iter: 2800, curr loss: 1.3060965538024902, avg loss: 1.3126050919294356\n",
      "trial: 4, iter: 3000, curr loss: 1.3001184463500977, avg loss: 1.3081924134492875\n",
      "trial: 4, ldr: 0.1957334727048874\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3869956731796265, avg loss: 1.3873221725225449\n",
      "trial: 5, iter: 400, curr loss: 1.3854734897613525, avg loss: 1.3866497051715851\n",
      "trial: 5, iter: 600, curr loss: 1.3883227109909058, avg loss: 1.3863558870553971\n",
      "trial: 5, iter: 800, curr loss: 1.3818470239639282, avg loss: 1.3838657855987548\n",
      "trial: 5, iter: 1000, curr loss: 1.3710899353027344, avg loss: 1.3797103756666182\n",
      "trial: 5, iter: 1200, curr loss: 1.3674086332321167, avg loss: 1.3728434067964554\n",
      "trial: 5, iter: 1400, curr loss: 1.3640365600585938, avg loss: 1.3651728862524033\n",
      "trial: 5, iter: 1600, curr loss: 1.339423418045044, avg loss: 1.3608026397228241\n",
      "trial: 5, iter: 1800, curr loss: 1.339591145515442, avg loss: 1.3543807941675186\n",
      "trial: 5, iter: 2000, curr loss: 1.323980689048767, avg loss: 1.3449506932497024\n",
      "trial: 5, iter: 2200, curr loss: 1.3529011011123657, avg loss: 1.3350782442092894\n",
      "trial: 5, iter: 2400, curr loss: 1.2972052097320557, avg loss: 1.3271812337636948\n",
      "trial: 5, iter: 2600, curr loss: 1.3113610744476318, avg loss: 1.3207515597343444\n",
      "trial: 5, iter: 2800, curr loss: 1.3078480958938599, avg loss: 1.3125538569688797\n",
      "trial: 5, iter: 3000, curr loss: 1.2663931846618652, avg loss: 1.308346912264824\n",
      "trial: 5, ldr: 0.20995087921619415\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.22097096145153045\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3928561210632324, avg loss: 1.3873179799318314\n",
      "trial: 1, iter: 400, curr loss: 1.3885539770126343, avg loss: 1.3866247892379762\n",
      "trial: 1, iter: 600, curr loss: 1.3835391998291016, avg loss: 1.386262477040291\n",
      "trial: 1, iter: 800, curr loss: 1.3686467409133911, avg loss: 1.3805345982313155\n",
      "trial: 1, iter: 1000, curr loss: 1.3644276857376099, avg loss: 1.3708001273870467\n",
      "trial: 1, iter: 1200, curr loss: 1.3753552436828613, avg loss: 1.3659179353713988\n",
      "trial: 1, iter: 1400, curr loss: 1.3631082773208618, avg loss: 1.3604438722133636\n",
      "trial: 1, iter: 1600, curr loss: 1.3517781496047974, avg loss: 1.3545894294977188\n",
      "trial: 1, iter: 1800, curr loss: 1.3298929929733276, avg loss: 1.3457398080825806\n",
      "trial: 1, iter: 2000, curr loss: 1.3092695474624634, avg loss: 1.3368468099832536\n",
      "trial: 1, iter: 2200, curr loss: 1.3482980728149414, avg loss: 1.3326485973596573\n",
      "trial: 1, iter: 2400, curr loss: 1.3105661869049072, avg loss: 1.3257939571142197\n",
      "trial: 1, iter: 2600, curr loss: 1.3090145587921143, avg loss: 1.3212792485952378\n",
      "trial: 1, iter: 2800, curr loss: 1.2736481428146362, avg loss: 1.3164818799495697\n",
      "trial: 1, iter: 3000, curr loss: 1.3114070892333984, avg loss: 1.3110004729032516\n",
      "trial: 1, ldr: 0.19768193364143372\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3862347602844238, avg loss: 1.3870216524600982\n",
      "trial: 2, iter: 400, curr loss: 1.3864198923110962, avg loss: 1.3867287230491638\n",
      "trial: 2, iter: 600, curr loss: 1.3855273723602295, avg loss: 1.386279945373535\n",
      "trial: 2, iter: 800, curr loss: 1.370606541633606, avg loss: 1.3830061620473861\n",
      "trial: 2, iter: 1000, curr loss: 1.3634122610092163, avg loss: 1.3713511264324187\n",
      "trial: 2, iter: 1200, curr loss: 1.3629837036132812, avg loss: 1.365429121851921\n",
      "trial: 2, iter: 1400, curr loss: 1.3749570846557617, avg loss: 1.3594222342967988\n",
      "trial: 2, iter: 1600, curr loss: 1.357047438621521, avg loss: 1.3560946434736252\n",
      "trial: 2, iter: 1800, curr loss: 1.3735121488571167, avg loss: 1.346520450115204\n",
      "trial: 2, iter: 2000, curr loss: 1.349815011024475, avg loss: 1.3400651556253433\n",
      "trial: 2, iter: 2200, curr loss: 1.2857800722122192, avg loss: 1.328963775038719\n",
      "trial: 2, iter: 2400, curr loss: 1.343356966972351, avg loss: 1.3255666768550873\n",
      "trial: 2, iter: 2600, curr loss: 1.3506563901901245, avg loss: 1.3196849089860916\n",
      "trial: 2, iter: 2800, curr loss: 1.3061162233352661, avg loss: 1.3098574966192245\n",
      "trial: 2, iter: 3000, curr loss: 1.305465579032898, avg loss: 1.304941109418869\n",
      "trial: 2, ldr: 0.15908057987689972\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.388507604598999, avg loss: 1.3871720606088638\n",
      "trial: 3, iter: 400, curr loss: 1.3857613801956177, avg loss: 1.3867531979084016\n",
      "trial: 3, iter: 600, curr loss: 1.3837838172912598, avg loss: 1.386377026438713\n",
      "trial: 3, iter: 800, curr loss: 1.3842675685882568, avg loss: 1.3855367255210878\n",
      "trial: 3, iter: 1000, curr loss: 1.3782179355621338, avg loss: 1.3766644221544266\n",
      "trial: 3, iter: 1200, curr loss: 1.3643783330917358, avg loss: 1.3681448179483413\n",
      "trial: 3, iter: 1400, curr loss: 1.3808138370513916, avg loss: 1.3623175102472305\n",
      "trial: 3, iter: 1600, curr loss: 1.3684539794921875, avg loss: 1.3573140680789948\n",
      "trial: 3, iter: 1800, curr loss: 1.3452050685882568, avg loss: 1.3501895993947983\n",
      "trial: 3, iter: 2000, curr loss: 1.3312478065490723, avg loss: 1.3394402450323104\n",
      "trial: 3, iter: 2200, curr loss: 1.3201541900634766, avg loss: 1.3307244658470154\n",
      "trial: 3, iter: 2400, curr loss: 1.3330862522125244, avg loss: 1.3268015885353088\n",
      "trial: 3, iter: 2600, curr loss: 1.3181313276290894, avg loss: 1.3184047305583955\n",
      "trial: 3, iter: 2800, curr loss: 1.292480230331421, avg loss: 1.3131726562976838\n",
      "trial: 3, iter: 3000, curr loss: 1.301820158958435, avg loss: 1.3099559235572815\n",
      "trial: 3, ldr: 0.10817523300647736\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388254165649414, avg loss: 1.387128180861473\n",
      "trial: 4, iter: 400, curr loss: 1.3857553005218506, avg loss: 1.3865305578708649\n",
      "trial: 4, iter: 600, curr loss: 1.3862026929855347, avg loss: 1.3866572284698486\n",
      "trial: 4, iter: 800, curr loss: 1.3780394792556763, avg loss: 1.3851194339990616\n",
      "trial: 4, iter: 1000, curr loss: 1.3724218606948853, avg loss: 1.3771006190776824\n",
      "trial: 4, iter: 1200, curr loss: 1.3508296012878418, avg loss: 1.3695775985717773\n",
      "trial: 4, iter: 1400, curr loss: 1.3380141258239746, avg loss: 1.3638223862648011\n",
      "trial: 4, iter: 1600, curr loss: 1.3585652112960815, avg loss: 1.3560136246681214\n",
      "trial: 4, iter: 1800, curr loss: 1.3286067247390747, avg loss: 1.3537053751945496\n",
      "trial: 4, iter: 2000, curr loss: 1.3441816568374634, avg loss: 1.3419142615795137\n",
      "trial: 4, iter: 2200, curr loss: 1.3119796514511108, avg loss: 1.3342946940660476\n",
      "trial: 4, iter: 2400, curr loss: 1.3302026987075806, avg loss: 1.325621204972267\n",
      "trial: 4, iter: 2600, curr loss: 1.318528413772583, avg loss: 1.3187079894542695\n",
      "trial: 4, iter: 2800, curr loss: 1.3183870315551758, avg loss: 1.311707016825676\n",
      "trial: 4, iter: 3000, curr loss: 1.2939817905426025, avg loss: 1.3038382238149644\n",
      "trial: 4, ldr: 0.14007794857025146\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3854235410690308, avg loss: 1.3870560079813004\n",
      "trial: 5, iter: 400, curr loss: 1.386863350868225, avg loss: 1.386472873687744\n",
      "trial: 5, iter: 600, curr loss: 1.386206865310669, avg loss: 1.3860761630535126\n",
      "trial: 5, iter: 800, curr loss: 1.3958680629730225, avg loss: 1.3839276146888733\n",
      "trial: 5, iter: 1000, curr loss: 1.3604549169540405, avg loss: 1.3748284351825715\n",
      "trial: 5, iter: 1200, curr loss: 1.3903824090957642, avg loss: 1.3682770812511444\n",
      "trial: 5, iter: 1400, curr loss: 1.3469524383544922, avg loss: 1.362667158842087\n",
      "trial: 5, iter: 1600, curr loss: 1.357923150062561, avg loss: 1.3592743593454362\n",
      "trial: 5, iter: 1800, curr loss: 1.3521357774734497, avg loss: 1.352885770201683\n",
      "trial: 5, iter: 2000, curr loss: 1.3262280225753784, avg loss: 1.3461163932085036\n",
      "trial: 5, iter: 2200, curr loss: 1.350256085395813, avg loss: 1.3356457394361496\n",
      "trial: 5, iter: 2400, curr loss: 1.315757393836975, avg loss: 1.3291964823007583\n",
      "trial: 5, iter: 2600, curr loss: 1.3475474119186401, avg loss: 1.3213342946767808\n",
      "trial: 5, iter: 2800, curr loss: 1.3243741989135742, avg loss: 1.3129072231054306\n",
      "trial: 5, iter: 3000, curr loss: 1.311955213546753, avg loss: 1.3073241555690764\n",
      "trial: 5, ldr: 0.1806403398513794\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.15713120698928834\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386155605316162, avg loss: 1.3873365676403047\n",
      "trial: 1, iter: 400, curr loss: 1.386362910270691, avg loss: 1.3862806594371795\n",
      "trial: 1, iter: 600, curr loss: 1.3823776245117188, avg loss: 1.385493113398552\n",
      "trial: 1, iter: 800, curr loss: 1.3628106117248535, avg loss: 1.379882190823555\n",
      "trial: 1, iter: 1000, curr loss: 1.385148286819458, avg loss: 1.368919643163681\n",
      "trial: 1, iter: 1200, curr loss: 1.3601683378219604, avg loss: 1.3629438602924346\n",
      "trial: 1, iter: 1400, curr loss: 1.3612661361694336, avg loss: 1.3553859639167785\n",
      "trial: 1, iter: 1600, curr loss: 1.3455746173858643, avg loss: 1.352923634648323\n",
      "trial: 1, iter: 1800, curr loss: 1.3337920904159546, avg loss: 1.343723286986351\n",
      "trial: 1, iter: 2000, curr loss: 1.3267451524734497, avg loss: 1.335939230322838\n",
      "trial: 1, iter: 2200, curr loss: 1.347701907157898, avg loss: 1.3294252330064773\n",
      "trial: 1, iter: 2400, curr loss: 1.3205385208129883, avg loss: 1.3214782589673997\n",
      "trial: 1, iter: 2600, curr loss: 1.3116662502288818, avg loss: 1.3124422895908356\n",
      "trial: 1, iter: 2800, curr loss: 1.2794781923294067, avg loss: 1.3093068075180054\n",
      "trial: 1, iter: 3000, curr loss: 1.2948410511016846, avg loss: 1.3064197570085525\n",
      "trial: 1, ldr: 0.1157136932015419\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849539756774902, avg loss: 1.3874827122688294\n",
      "trial: 2, iter: 400, curr loss: 1.388849139213562, avg loss: 1.3865630024671554\n",
      "trial: 2, iter: 600, curr loss: 1.3894269466400146, avg loss: 1.3866011369228364\n",
      "trial: 2, iter: 800, curr loss: 1.3831754922866821, avg loss: 1.386129810810089\n",
      "trial: 2, iter: 1000, curr loss: 1.3801546096801758, avg loss: 1.3843346744775773\n",
      "trial: 2, iter: 1200, curr loss: 1.3646540641784668, avg loss: 1.3777176105976106\n",
      "trial: 2, iter: 1400, curr loss: 1.3722259998321533, avg loss: 1.368304681777954\n",
      "trial: 2, iter: 1600, curr loss: 1.3822033405303955, avg loss: 1.3628127509355545\n",
      "trial: 2, iter: 1800, curr loss: 1.3728653192520142, avg loss: 1.356216425895691\n",
      "trial: 2, iter: 2000, curr loss: 1.3456295728683472, avg loss: 1.3526005625724793\n",
      "trial: 2, iter: 2200, curr loss: 1.3178187608718872, avg loss: 1.3435111039876937\n",
      "trial: 2, iter: 2400, curr loss: 1.3483850955963135, avg loss: 1.3369797044992446\n",
      "trial: 2, iter: 2600, curr loss: 1.3472228050231934, avg loss: 1.3283592092990875\n",
      "trial: 2, iter: 2800, curr loss: 1.3283454179763794, avg loss: 1.325086480975151\n",
      "trial: 2, iter: 3000, curr loss: 1.341812252998352, avg loss: 1.3144846147298812\n",
      "trial: 2, ldr: 0.12784843146800995\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3877629041671753, avg loss: 1.3870196861028672\n",
      "trial: 3, iter: 400, curr loss: 1.3855781555175781, avg loss: 1.38675883769989\n",
      "trial: 3, iter: 600, curr loss: 1.3882331848144531, avg loss: 1.3864604330062866\n",
      "trial: 3, iter: 800, curr loss: 1.3878382444381714, avg loss: 1.386284413933754\n",
      "trial: 3, iter: 1000, curr loss: 1.376703143119812, avg loss: 1.3827324652671813\n",
      "trial: 3, iter: 1200, curr loss: 1.3786276578903198, avg loss: 1.3720670068264007\n",
      "trial: 3, iter: 1400, curr loss: 1.371497631072998, avg loss: 1.3654604715108871\n",
      "trial: 3, iter: 1600, curr loss: 1.3246798515319824, avg loss: 1.3592030704021454\n",
      "trial: 3, iter: 1800, curr loss: 1.3262661695480347, avg loss: 1.352158476114273\n",
      "trial: 3, iter: 2000, curr loss: 1.3324165344238281, avg loss: 1.344564654827118\n",
      "trial: 3, iter: 2200, curr loss: 1.3560587167739868, avg loss: 1.3357054907083512\n",
      "trial: 3, iter: 2400, curr loss: 1.32514488697052, avg loss: 1.3258953040838242\n",
      "trial: 3, iter: 2600, curr loss: 1.3073036670684814, avg loss: 1.3202939546108245\n",
      "trial: 3, iter: 2800, curr loss: 1.3704885244369507, avg loss: 1.317185128927231\n",
      "trial: 3, iter: 3000, curr loss: 1.3330756425857544, avg loss: 1.3113695341348648\n",
      "trial: 3, ldr: 0.18246370553970337\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838810920715332, avg loss: 1.3872703582048416\n",
      "trial: 4, iter: 400, curr loss: 1.3858634233474731, avg loss: 1.3865570867061614\n",
      "trial: 4, iter: 600, curr loss: 1.3901258707046509, avg loss: 1.3862105375528335\n",
      "trial: 4, iter: 800, curr loss: 1.3752095699310303, avg loss: 1.382481237053871\n",
      "trial: 4, iter: 1000, curr loss: 1.3735880851745605, avg loss: 1.3717494332790374\n",
      "trial: 4, iter: 1200, curr loss: 1.3538062572479248, avg loss: 1.3666823703050612\n",
      "trial: 4, iter: 1400, curr loss: 1.3503721952438354, avg loss: 1.3604347360134126\n",
      "trial: 4, iter: 1600, curr loss: 1.339883804321289, avg loss: 1.3593494147062302\n",
      "trial: 4, iter: 1800, curr loss: 1.3470948934555054, avg loss: 1.349575411081314\n",
      "trial: 4, iter: 2000, curr loss: 1.320259690284729, avg loss: 1.3444835233688355\n",
      "trial: 4, iter: 2200, curr loss: 1.328515887260437, avg loss: 1.333388530611992\n",
      "trial: 4, iter: 2400, curr loss: 1.3358780145645142, avg loss: 1.3283235692977906\n",
      "trial: 4, iter: 2600, curr loss: 1.3331983089447021, avg loss: 1.3214140504598617\n",
      "trial: 4, iter: 2800, curr loss: 1.3344292640686035, avg loss: 1.315600608587265\n",
      "trial: 4, iter: 3000, curr loss: 1.3200455904006958, avg loss: 1.3073405915498733\n",
      "trial: 4, ldr: 0.24261431396007538\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3872538805007935, avg loss: 1.387641875743866\n",
      "trial: 5, iter: 400, curr loss: 1.387516736984253, avg loss: 1.3865088814496993\n",
      "trial: 5, iter: 600, curr loss: 1.3840267658233643, avg loss: 1.386156205534935\n",
      "trial: 5, iter: 800, curr loss: 1.3822977542877197, avg loss: 1.3845214265584946\n",
      "trial: 5, iter: 1000, curr loss: 1.3607797622680664, avg loss: 1.373443191051483\n",
      "trial: 5, iter: 1200, curr loss: 1.3418047428131104, avg loss: 1.3668515783548356\n",
      "trial: 5, iter: 1400, curr loss: 1.3624422550201416, avg loss: 1.3624223107099533\n",
      "trial: 5, iter: 1600, curr loss: 1.3582713603973389, avg loss: 1.3569085907936096\n",
      "trial: 5, iter: 1800, curr loss: 1.3168922662734985, avg loss: 1.3525911277532578\n",
      "trial: 5, iter: 2000, curr loss: 1.366583228111267, avg loss: 1.345101387500763\n",
      "trial: 5, iter: 2200, curr loss: 1.314983606338501, avg loss: 1.3366155499219894\n",
      "trial: 5, iter: 2400, curr loss: 1.3079051971435547, avg loss: 1.328633794784546\n",
      "trial: 5, iter: 2600, curr loss: 1.3436497449874878, avg loss: 1.3223089861869812\n",
      "trial: 5, iter: 2800, curr loss: 1.3099772930145264, avg loss: 1.3165555077791213\n",
      "trial: 5, iter: 3000, curr loss: 1.3064748048782349, avg loss: 1.314306446313858\n",
      "trial: 5, ldr: 0.19895192980766296\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.1735184147953987\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3873990774154663, avg loss: 1.387323908805847\n",
      "trial: 1, iter: 400, curr loss: 1.385727882385254, avg loss: 1.3864310157299042\n",
      "trial: 1, iter: 600, curr loss: 1.3794796466827393, avg loss: 1.3834544092416763\n",
      "trial: 1, iter: 800, curr loss: 1.3765493631362915, avg loss: 1.37331447660923\n",
      "trial: 1, iter: 1000, curr loss: 1.3599869012832642, avg loss: 1.3657528537511825\n",
      "trial: 1, iter: 1200, curr loss: 1.362304925918579, avg loss: 1.3621216928958892\n",
      "trial: 1, iter: 1400, curr loss: 1.3414759635925293, avg loss: 1.3552793735265731\n",
      "trial: 1, iter: 1600, curr loss: 1.3239333629608154, avg loss: 1.3471455979347229\n",
      "trial: 1, iter: 1800, curr loss: 1.3250354528427124, avg loss: 1.3385111796855926\n",
      "trial: 1, iter: 2000, curr loss: 1.330771803855896, avg loss: 1.332957148551941\n",
      "trial: 1, iter: 2200, curr loss: 1.3247284889221191, avg loss: 1.3257339149713516\n",
      "trial: 1, iter: 2400, curr loss: 1.3226780891418457, avg loss: 1.3178959947824478\n",
      "trial: 1, iter: 2600, curr loss: 1.3046379089355469, avg loss: 1.3122878682613373\n",
      "trial: 1, iter: 2800, curr loss: 1.3226968050003052, avg loss: 1.3103074330091475\n",
      "trial: 1, iter: 3000, curr loss: 1.3081796169281006, avg loss: 1.306989438533783\n",
      "trial: 1, ldr: 0.1604551076889038\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3847788572311401, avg loss: 1.3874095457792281\n",
      "trial: 2, iter: 400, curr loss: 1.3875960111618042, avg loss: 1.386612566113472\n",
      "trial: 2, iter: 600, curr loss: 1.3859989643096924, avg loss: 1.386498260498047\n",
      "trial: 2, iter: 800, curr loss: 1.3833510875701904, avg loss: 1.3851120108366013\n",
      "trial: 2, iter: 1000, curr loss: 1.376035213470459, avg loss: 1.379743099808693\n",
      "trial: 2, iter: 1200, curr loss: 1.3629436492919922, avg loss: 1.371133013367653\n",
      "trial: 2, iter: 1400, curr loss: 1.3812751770019531, avg loss: 1.3658530849218369\n",
      "trial: 2, iter: 1600, curr loss: 1.3580749034881592, avg loss: 1.3601723837852477\n",
      "trial: 2, iter: 1800, curr loss: 1.3358397483825684, avg loss: 1.3541710245609284\n",
      "trial: 2, iter: 2000, curr loss: 1.352049708366394, avg loss: 1.3462280815839767\n",
      "trial: 2, iter: 2200, curr loss: 1.3036807775497437, avg loss: 1.3377839612960816\n",
      "trial: 2, iter: 2400, curr loss: 1.3377577066421509, avg loss: 1.3321001464128495\n",
      "trial: 2, iter: 2600, curr loss: 1.2954339981079102, avg loss: 1.3243568116426467\n",
      "trial: 2, iter: 2800, curr loss: 1.2982662916183472, avg loss: 1.3193247073888779\n",
      "trial: 2, iter: 3000, curr loss: 1.2771549224853516, avg loss: 1.3130501091480256\n",
      "trial: 2, ldr: 0.17005309462547302\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3886172771453857, avg loss: 1.3873675620555879\n",
      "trial: 3, iter: 400, curr loss: 1.386204481124878, avg loss: 1.3868694311380387\n",
      "trial: 3, iter: 600, curr loss: 1.3874605894088745, avg loss: 1.3860892468690873\n",
      "trial: 3, iter: 800, curr loss: 1.3786214590072632, avg loss: 1.383321326971054\n",
      "trial: 3, iter: 1000, curr loss: 1.3676949739456177, avg loss: 1.3785866546630858\n",
      "trial: 3, iter: 1200, curr loss: 1.347144365310669, avg loss: 1.3723674762248992\n",
      "trial: 3, iter: 1400, curr loss: 1.3376953601837158, avg loss: 1.366075018644333\n",
      "trial: 3, iter: 1600, curr loss: 1.376842975616455, avg loss: 1.3590311485528945\n",
      "trial: 3, iter: 1800, curr loss: 1.3589911460876465, avg loss: 1.3551362496614456\n",
      "trial: 3, iter: 2000, curr loss: 1.34260094165802, avg loss: 1.34548204600811\n",
      "trial: 3, iter: 2200, curr loss: 1.3631446361541748, avg loss: 1.3361696422100067\n",
      "trial: 3, iter: 2400, curr loss: 1.3123767375946045, avg loss: 1.3305933767557143\n",
      "trial: 3, iter: 2600, curr loss: 1.3209028244018555, avg loss: 1.3218402296304703\n",
      "trial: 3, iter: 2800, curr loss: 1.339639663696289, avg loss: 1.3177562159299852\n",
      "trial: 3, iter: 3000, curr loss: 1.2864736318588257, avg loss: 1.3109504193067552\n",
      "trial: 3, ldr: 0.2612408995628357\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3853377103805542, avg loss: 1.38731791973114\n",
      "trial: 4, iter: 400, curr loss: 1.3879897594451904, avg loss: 1.3867316466569901\n",
      "trial: 4, iter: 600, curr loss: 1.3899441957473755, avg loss: 1.3857776147127152\n",
      "trial: 4, iter: 800, curr loss: 1.3793044090270996, avg loss: 1.3821951597929\n",
      "trial: 4, iter: 1000, curr loss: 1.3658967018127441, avg loss: 1.3762449914216994\n",
      "trial: 4, iter: 1200, curr loss: 1.385282039642334, avg loss: 1.368927265405655\n",
      "trial: 4, iter: 1400, curr loss: 1.3494035005569458, avg loss: 1.364236872792244\n",
      "trial: 4, iter: 1600, curr loss: 1.371000051498413, avg loss: 1.359942499399185\n",
      "trial: 4, iter: 1800, curr loss: 1.351479172706604, avg loss: 1.3550606960058211\n",
      "trial: 4, iter: 2000, curr loss: 1.3229519128799438, avg loss: 1.3489049142599105\n",
      "trial: 4, iter: 2200, curr loss: 1.3241404294967651, avg loss: 1.3390827107429504\n",
      "trial: 4, iter: 2400, curr loss: 1.3206485509872437, avg loss: 1.3329518610239028\n",
      "trial: 4, iter: 2600, curr loss: 1.3196388483047485, avg loss: 1.3263710474967956\n",
      "trial: 4, iter: 2800, curr loss: 1.322698950767517, avg loss: 1.3192186522483826\n",
      "trial: 4, iter: 3000, curr loss: 1.3234621286392212, avg loss: 1.3147738009691239\n",
      "trial: 4, ldr: 0.17224401235580444\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385892391204834, avg loss: 1.387684282064438\n",
      "trial: 5, iter: 400, curr loss: 1.3893609046936035, avg loss: 1.3866759949922562\n",
      "trial: 5, iter: 600, curr loss: 1.3866947889328003, avg loss: 1.386387096643448\n",
      "trial: 5, iter: 800, curr loss: 1.3850698471069336, avg loss: 1.3852807521820067\n",
      "trial: 5, iter: 1000, curr loss: 1.386784553527832, avg loss: 1.3802332127094268\n",
      "trial: 5, iter: 1200, curr loss: 1.3842401504516602, avg loss: 1.3707534807920456\n",
      "trial: 5, iter: 1400, curr loss: 1.3674254417419434, avg loss: 1.3652270305156708\n",
      "trial: 5, iter: 1600, curr loss: 1.3550642728805542, avg loss: 1.3610463190078734\n",
      "trial: 5, iter: 1800, curr loss: 1.378578543663025, avg loss: 1.356277659535408\n",
      "trial: 5, iter: 2000, curr loss: 1.3454771041870117, avg loss: 1.34796816945076\n",
      "trial: 5, iter: 2200, curr loss: 1.3177707195281982, avg loss: 1.336074543595314\n",
      "trial: 5, iter: 2400, curr loss: 1.3035786151885986, avg loss: 1.3274102419614793\n",
      "trial: 5, iter: 2600, curr loss: 1.2916890382766724, avg loss: 1.3215715134143828\n",
      "trial: 5, iter: 2800, curr loss: 1.2968671321868896, avg loss: 1.3118426817655564\n",
      "trial: 5, iter: 3000, curr loss: 1.3304224014282227, avg loss: 1.307384003996849\n",
      "trial: 5, ldr: 0.25667688250541687\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20413399934768678\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3871126174926758, avg loss: 1.3875569319725036\n",
      "trial: 1, iter: 400, curr loss: 1.387760043144226, avg loss: 1.3868827491998672\n",
      "trial: 1, iter: 600, curr loss: 1.3832504749298096, avg loss: 1.386376114487648\n",
      "trial: 1, iter: 800, curr loss: 1.382466197013855, avg loss: 1.384213040471077\n",
      "trial: 1, iter: 1000, curr loss: 1.3602064847946167, avg loss: 1.3725388151407243\n",
      "trial: 1, iter: 1200, curr loss: 1.3593026399612427, avg loss: 1.3648046749830245\n",
      "trial: 1, iter: 1400, curr loss: 1.355747938156128, avg loss: 1.3613099151849746\n",
      "trial: 1, iter: 1600, curr loss: 1.356420636177063, avg loss: 1.3561454898118972\n",
      "trial: 1, iter: 1800, curr loss: 1.3528554439544678, avg loss: 1.3483443748950958\n",
      "trial: 1, iter: 2000, curr loss: 1.3518067598342896, avg loss: 1.3404859298467635\n",
      "trial: 1, iter: 2200, curr loss: 1.3240264654159546, avg loss: 1.3334035825729371\n",
      "trial: 1, iter: 2400, curr loss: 1.324038028717041, avg loss: 1.3230757755041123\n",
      "trial: 1, iter: 2600, curr loss: 1.2818676233291626, avg loss: 1.3195512986183167\n",
      "trial: 1, iter: 2800, curr loss: 1.2807639837265015, avg loss: 1.30783442735672\n",
      "trial: 1, iter: 3000, curr loss: 1.3198379278182983, avg loss: 1.3051493281126023\n",
      "trial: 1, ldr: 0.1946123242378235\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3845956325531006, avg loss: 1.3871267414093018\n",
      "trial: 2, iter: 400, curr loss: 1.3904738426208496, avg loss: 1.3865496158599853\n",
      "trial: 2, iter: 600, curr loss: 1.3885173797607422, avg loss: 1.386116310954094\n",
      "trial: 2, iter: 800, curr loss: 1.3775912523269653, avg loss: 1.382925016283989\n",
      "trial: 2, iter: 1000, curr loss: 1.364607572555542, avg loss: 1.375119430422783\n",
      "trial: 2, iter: 1200, curr loss: 1.3307117223739624, avg loss: 1.3657415509223938\n",
      "trial: 2, iter: 1400, curr loss: 1.3602230548858643, avg loss: 1.361237832903862\n",
      "trial: 2, iter: 1600, curr loss: 1.3584964275360107, avg loss: 1.3566076052188873\n",
      "trial: 2, iter: 1800, curr loss: 1.3441028594970703, avg loss: 1.3514456796646117\n",
      "trial: 2, iter: 2000, curr loss: 1.3533371686935425, avg loss: 1.3420142805576325\n",
      "trial: 2, iter: 2200, curr loss: 1.3213143348693848, avg loss: 1.3354603731632233\n",
      "trial: 2, iter: 2400, curr loss: 1.3246809244155884, avg loss: 1.3262394607067107\n",
      "trial: 2, iter: 2600, curr loss: 1.3185324668884277, avg loss: 1.3188884776830674\n",
      "trial: 2, iter: 2800, curr loss: 1.277258038520813, avg loss: 1.3137126898765563\n",
      "trial: 2, iter: 3000, curr loss: 1.2866572141647339, avg loss: 1.3086789280176163\n",
      "trial: 2, ldr: 0.18998658657073975\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.386055588722229, avg loss: 1.3873023319244384\n",
      "trial: 3, iter: 400, curr loss: 1.3850752115249634, avg loss: 1.3865509986877442\n",
      "trial: 3, iter: 600, curr loss: 1.3885836601257324, avg loss: 1.386514048576355\n",
      "trial: 3, iter: 800, curr loss: 1.3861557245254517, avg loss: 1.3858730137348174\n",
      "trial: 3, iter: 1000, curr loss: 1.3815001249313354, avg loss: 1.3832953602075577\n",
      "trial: 3, iter: 1200, curr loss: 1.3757280111312866, avg loss: 1.3769769096374511\n",
      "trial: 3, iter: 1400, curr loss: 1.3684101104736328, avg loss: 1.3676394110918044\n",
      "trial: 3, iter: 1600, curr loss: 1.3683053255081177, avg loss: 1.3619781547784806\n",
      "trial: 3, iter: 1800, curr loss: 1.34617280960083, avg loss: 1.3557826203107834\n",
      "trial: 3, iter: 2000, curr loss: 1.3254196643829346, avg loss: 1.3515465092658996\n",
      "trial: 3, iter: 2200, curr loss: 1.2994567155838013, avg loss: 1.3423088216781616\n",
      "trial: 3, iter: 2400, curr loss: 1.3201242685317993, avg loss: 1.3330098968744277\n",
      "trial: 3, iter: 2600, curr loss: 1.3020328283309937, avg loss: 1.3249749165773392\n",
      "trial: 3, iter: 2800, curr loss: 1.3278071880340576, avg loss: 1.3190304166078568\n",
      "trial: 3, iter: 3000, curr loss: 1.3210499286651611, avg loss: 1.3125094884634019\n",
      "trial: 3, ldr: 0.1613026112318039\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865729570388794, avg loss: 1.3873289585113526\n",
      "trial: 4, iter: 400, curr loss: 1.3866493701934814, avg loss: 1.3866662335395814\n",
      "trial: 4, iter: 600, curr loss: 1.385464072227478, avg loss: 1.3862303692102431\n",
      "trial: 4, iter: 800, curr loss: 1.3868192434310913, avg loss: 1.3860088074207306\n",
      "trial: 4, iter: 1000, curr loss: 1.3725037574768066, avg loss: 1.3824982279539109\n",
      "trial: 4, iter: 1200, curr loss: 1.3683830499649048, avg loss: 1.3724818170070647\n",
      "trial: 4, iter: 1400, curr loss: 1.360305905342102, avg loss: 1.3656607747077942\n",
      "trial: 4, iter: 1600, curr loss: 1.3382856845855713, avg loss: 1.3586620539426804\n",
      "trial: 4, iter: 1800, curr loss: 1.3668771982192993, avg loss: 1.3536058920621872\n",
      "trial: 4, iter: 2000, curr loss: 1.3205260038375854, avg loss: 1.344810237288475\n",
      "trial: 4, iter: 2200, curr loss: 1.3384718894958496, avg loss: 1.33974387049675\n",
      "trial: 4, iter: 2400, curr loss: 1.304772138595581, avg loss: 1.3296940219402313\n",
      "trial: 4, iter: 2600, curr loss: 1.3204259872436523, avg loss: 1.32269749045372\n",
      "trial: 4, iter: 2800, curr loss: 1.301095724105835, avg loss: 1.3174039345979691\n",
      "trial: 4, iter: 3000, curr loss: 1.2610247135162354, avg loss: 1.3096776384115218\n",
      "trial: 4, ldr: 0.18823972344398499\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.384006381034851, avg loss: 1.3873381000757217\n",
      "trial: 5, iter: 400, curr loss: 1.386810064315796, avg loss: 1.3864383256435395\n",
      "trial: 5, iter: 600, curr loss: 1.388622760772705, avg loss: 1.3863961148262023\n",
      "trial: 5, iter: 800, curr loss: 1.3884334564208984, avg loss: 1.3861885726451875\n",
      "trial: 5, iter: 1000, curr loss: 1.3839784860610962, avg loss: 1.385046555995941\n",
      "trial: 5, iter: 1200, curr loss: 1.3745790719985962, avg loss: 1.3763295435905456\n",
      "trial: 5, iter: 1400, curr loss: 1.377304196357727, avg loss: 1.3681894820928573\n",
      "trial: 5, iter: 1600, curr loss: 1.3603917360305786, avg loss: 1.3639694154262543\n",
      "trial: 5, iter: 1800, curr loss: 1.3386772871017456, avg loss: 1.357413838505745\n",
      "trial: 5, iter: 2000, curr loss: 1.345937967300415, avg loss: 1.3531642347574233\n",
      "trial: 5, iter: 2200, curr loss: 1.3441848754882812, avg loss: 1.34385588824749\n",
      "trial: 5, iter: 2400, curr loss: 1.32523512840271, avg loss: 1.3336772119998932\n",
      "trial: 5, iter: 2600, curr loss: 1.3234654664993286, avg loss: 1.3288325870037079\n",
      "trial: 5, iter: 2800, curr loss: 1.3307960033416748, avg loss: 1.3200911486148834\n",
      "trial: 5, iter: 3000, curr loss: 1.317537546157837, avg loss: 1.3163517075777054\n",
      "trial: 5, ldr: 0.19747626781463623\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.18632350265979766\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.383040428161621, avg loss: 1.3873860400915146\n",
      "trial: 1, iter: 400, curr loss: 1.3879649639129639, avg loss: 1.3867008709907531\n",
      "trial: 1, iter: 600, curr loss: 1.3847832679748535, avg loss: 1.3863723486661912\n",
      "trial: 1, iter: 800, curr loss: 1.387855887413025, avg loss: 1.385936449766159\n",
      "trial: 1, iter: 1000, curr loss: 1.3865586519241333, avg loss: 1.3847565072774888\n",
      "trial: 1, iter: 1200, curr loss: 1.3731639385223389, avg loss: 1.381374695301056\n",
      "trial: 1, iter: 1400, curr loss: 1.3831616640090942, avg loss: 1.378403615951538\n",
      "trial: 1, iter: 1600, curr loss: 1.382136344909668, avg loss: 1.376473376750946\n",
      "trial: 1, iter: 1800, curr loss: 1.3543217182159424, avg loss: 1.3709375923871994\n",
      "trial: 1, iter: 2000, curr loss: 1.3414307832717896, avg loss: 1.3634115499258042\n",
      "trial: 1, iter: 2200, curr loss: 1.3518803119659424, avg loss: 1.357054191827774\n",
      "trial: 1, iter: 2400, curr loss: 1.3327456712722778, avg loss: 1.3490596705675124\n",
      "trial: 1, iter: 2600, curr loss: 1.3533810377120972, avg loss: 1.343027821779251\n",
      "trial: 1, iter: 2800, curr loss: 1.3443678617477417, avg loss: 1.3321113240718843\n",
      "trial: 1, iter: 3000, curr loss: 1.3382872343063354, avg loss: 1.322389132976532\n",
      "trial: 1, ldr: 0.18265937268733978\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3889678716659546, avg loss: 1.387101098895073\n",
      "trial: 2, iter: 400, curr loss: 1.3880373239517212, avg loss: 1.3867207658290863\n",
      "trial: 2, iter: 600, curr loss: 1.383962631225586, avg loss: 1.3864149767160416\n",
      "trial: 2, iter: 800, curr loss: 1.3876423835754395, avg loss: 1.3862315285205842\n",
      "trial: 2, iter: 1000, curr loss: 1.3855092525482178, avg loss: 1.3849154222011566\n",
      "trial: 2, iter: 1200, curr loss: 1.382394790649414, avg loss: 1.3796228063106537\n",
      "trial: 2, iter: 1400, curr loss: 1.3491393327713013, avg loss: 1.3705269336700439\n",
      "trial: 2, iter: 1600, curr loss: 1.362722635269165, avg loss: 1.3651673835515976\n",
      "trial: 2, iter: 1800, curr loss: 1.3581926822662354, avg loss: 1.3585597115755081\n",
      "trial: 2, iter: 2000, curr loss: 1.3650354146957397, avg loss: 1.3501384526491165\n",
      "trial: 2, iter: 2200, curr loss: 1.3222099542617798, avg loss: 1.340909194946289\n",
      "trial: 2, iter: 2400, curr loss: 1.349198341369629, avg loss: 1.3301010429859161\n",
      "trial: 2, iter: 2600, curr loss: 1.3003921508789062, avg loss: 1.32321515917778\n",
      "trial: 2, iter: 2800, curr loss: 1.3266247510910034, avg loss: 1.3173092412948608\n",
      "trial: 2, iter: 3000, curr loss: 1.2893708944320679, avg loss: 1.311098240017891\n",
      "trial: 2, ldr: 0.20580044388771057\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387203335762024, avg loss: 1.3872580283880234\n",
      "trial: 3, iter: 400, curr loss: 1.3863345384597778, avg loss: 1.3867434668540954\n",
      "trial: 3, iter: 600, curr loss: 1.385274052619934, avg loss: 1.3863439929485322\n",
      "trial: 3, iter: 800, curr loss: 1.3854306936264038, avg loss: 1.3863480234146117\n",
      "trial: 3, iter: 1000, curr loss: 1.385259985923767, avg loss: 1.3860488295555116\n",
      "trial: 3, iter: 1200, curr loss: 1.378739595413208, avg loss: 1.38440096616745\n",
      "trial: 3, iter: 1400, curr loss: 1.3833359479904175, avg loss: 1.3770220792293548\n",
      "trial: 3, iter: 1600, curr loss: 1.3899708986282349, avg loss: 1.3688572555780412\n",
      "trial: 3, iter: 1800, curr loss: 1.3929756879806519, avg loss: 1.364866895675659\n",
      "trial: 3, iter: 2000, curr loss: 1.3419678211212158, avg loss: 1.361440630555153\n",
      "trial: 3, iter: 2200, curr loss: 1.3680669069290161, avg loss: 1.359337187409401\n",
      "trial: 3, iter: 2400, curr loss: 1.3555958271026611, avg loss: 1.3557051062583922\n",
      "trial: 3, iter: 2600, curr loss: 1.3350551128387451, avg loss: 1.3472647792100907\n",
      "trial: 3, iter: 2800, curr loss: 1.3513141870498657, avg loss: 1.3397741830348968\n",
      "trial: 3, iter: 3000, curr loss: 1.334507942199707, avg loss: 1.3328181153535843\n",
      "trial: 3, ldr: 0.09915608167648315\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.387195110321045, avg loss: 1.387323541045189\n",
      "trial: 4, iter: 400, curr loss: 1.3868463039398193, avg loss: 1.3865820693969726\n",
      "trial: 4, iter: 600, curr loss: 1.3883569240570068, avg loss: 1.386560508608818\n",
      "trial: 4, iter: 800, curr loss: 1.3818106651306152, avg loss: 1.3856847709417344\n",
      "trial: 4, iter: 1000, curr loss: 1.3893036842346191, avg loss: 1.383865283727646\n",
      "trial: 4, iter: 1200, curr loss: 1.364733099937439, avg loss: 1.3760810083150863\n",
      "trial: 4, iter: 1400, curr loss: 1.3669090270996094, avg loss: 1.3694062060117722\n",
      "trial: 4, iter: 1600, curr loss: 1.358619213104248, avg loss: 1.3638335889577866\n",
      "trial: 4, iter: 1800, curr loss: 1.3517378568649292, avg loss: 1.3614088368415833\n",
      "trial: 4, iter: 2000, curr loss: 1.3667107820510864, avg loss: 1.3560580384731293\n",
      "trial: 4, iter: 2200, curr loss: 1.3500131368637085, avg loss: 1.3474102401733399\n",
      "trial: 4, iter: 2400, curr loss: 1.3353570699691772, avg loss: 1.33907876431942\n",
      "trial: 4, iter: 2600, curr loss: 1.3337764739990234, avg loss: 1.3308447229862213\n",
      "trial: 4, iter: 2800, curr loss: 1.323702335357666, avg loss: 1.324364019036293\n",
      "trial: 4, iter: 3000, curr loss: 1.3275842666625977, avg loss: 1.314545070528984\n",
      "trial: 4, ldr: 0.18315823376178741\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.382591962814331, avg loss: 1.3875102978944778\n",
      "trial: 5, iter: 400, curr loss: 1.3881540298461914, avg loss: 1.386671022772789\n",
      "trial: 5, iter: 600, curr loss: 1.3851462602615356, avg loss: 1.3864007824659348\n",
      "trial: 5, iter: 800, curr loss: 1.386208415031433, avg loss: 1.385894200205803\n",
      "trial: 5, iter: 1000, curr loss: 1.3823599815368652, avg loss: 1.3830510461330414\n",
      "trial: 5, iter: 1200, curr loss: 1.3668218851089478, avg loss: 1.3772472369670867\n",
      "trial: 5, iter: 1400, curr loss: 1.367329478263855, avg loss: 1.3679150086641312\n",
      "trial: 5, iter: 1600, curr loss: 1.3695595264434814, avg loss: 1.3625092828273773\n",
      "trial: 5, iter: 1800, curr loss: 1.379579782485962, avg loss: 1.3547559159994125\n",
      "trial: 5, iter: 2000, curr loss: 1.3297337293624878, avg loss: 1.3480649745464326\n",
      "trial: 5, iter: 2200, curr loss: 1.328966498374939, avg loss: 1.3384245449304581\n",
      "trial: 5, iter: 2400, curr loss: 1.3044846057891846, avg loss: 1.32964662194252\n",
      "trial: 5, iter: 2600, curr loss: 1.304456114768982, avg loss: 1.3226426064968109\n",
      "trial: 5, iter: 2800, curr loss: 1.3037099838256836, avg loss: 1.3159641790390015\n",
      "trial: 5, iter: 3000, curr loss: 1.310497522354126, avg loss: 1.3113481414318084\n",
      "trial: 5, ldr: 0.13851416110992432\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.16185765862464904\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3852075338363647, avg loss: 1.3869234108924866\n",
      "trial: 1, iter: 400, curr loss: 1.3894128799438477, avg loss: 1.386607819199562\n",
      "trial: 1, iter: 600, curr loss: 1.3842514753341675, avg loss: 1.3862876445055008\n",
      "trial: 1, iter: 800, curr loss: 1.3849854469299316, avg loss: 1.3821701043844223\n",
      "trial: 1, iter: 1000, curr loss: 1.3771060705184937, avg loss: 1.3735835659503937\n",
      "trial: 1, iter: 1200, curr loss: 1.3725777864456177, avg loss: 1.3655212479829788\n",
      "trial: 1, iter: 1400, curr loss: 1.3412679433822632, avg loss: 1.3583718472719193\n",
      "trial: 1, iter: 1600, curr loss: 1.3490763902664185, avg loss: 1.3509733122587204\n",
      "trial: 1, iter: 1800, curr loss: 1.32317316532135, avg loss: 1.338949379324913\n",
      "trial: 1, iter: 2000, curr loss: 1.328440546989441, avg loss: 1.3336329865455627\n",
      "trial: 1, iter: 2200, curr loss: 1.3105088472366333, avg loss: 1.32477093398571\n",
      "trial: 1, iter: 2400, curr loss: 1.3169119358062744, avg loss: 1.3188482451438903\n",
      "trial: 1, iter: 2600, curr loss: 1.2959805727005005, avg loss: 1.3135943740606308\n",
      "trial: 1, iter: 2800, curr loss: 1.2946748733520508, avg loss: 1.3081330341100692\n",
      "trial: 1, iter: 3000, curr loss: 1.2799659967422485, avg loss: 1.3013059562444687\n",
      "trial: 1, ldr: 0.1877400428056717\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3879306316375732, avg loss: 1.3872651010751724\n",
      "trial: 2, iter: 400, curr loss: 1.3849080801010132, avg loss: 1.3867374765872955\n",
      "trial: 2, iter: 600, curr loss: 1.3836771249771118, avg loss: 1.3863099437952042\n",
      "trial: 2, iter: 800, curr loss: 1.3790178298950195, avg loss: 1.3836687433719634\n",
      "trial: 2, iter: 1000, curr loss: 1.3636023998260498, avg loss: 1.375306248664856\n",
      "trial: 2, iter: 1200, curr loss: 1.3557507991790771, avg loss: 1.3675247085094453\n",
      "trial: 2, iter: 1400, curr loss: 1.351585865020752, avg loss: 1.3620717716217041\n",
      "trial: 2, iter: 1600, curr loss: 1.344313621520996, avg loss: 1.3549687230587006\n",
      "trial: 2, iter: 1800, curr loss: 1.3453351259231567, avg loss: 1.3468692940473557\n",
      "trial: 2, iter: 2000, curr loss: 1.3289235830307007, avg loss: 1.3415710175037383\n",
      "trial: 2, iter: 2200, curr loss: 1.3464081287384033, avg loss: 1.3336584126949311\n",
      "trial: 2, iter: 2400, curr loss: 1.2949916124343872, avg loss: 1.3277960854768753\n",
      "trial: 2, iter: 2600, curr loss: 1.3192744255065918, avg loss: 1.3214960670471192\n",
      "trial: 2, iter: 2800, curr loss: 1.3412944078445435, avg loss: 1.3171721535921097\n",
      "trial: 2, iter: 3000, curr loss: 1.2849280834197998, avg loss: 1.307759484052658\n",
      "trial: 2, ldr: 0.19082728028297424\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3881266117095947, avg loss: 1.3869578284025192\n",
      "trial: 3, iter: 400, curr loss: 1.3861764669418335, avg loss: 1.386719849705696\n",
      "trial: 3, iter: 600, curr loss: 1.3857221603393555, avg loss: 1.3861231541633605\n",
      "trial: 3, iter: 800, curr loss: 1.372648000717163, avg loss: 1.3804558259248734\n",
      "trial: 3, iter: 1000, curr loss: 1.354272484779358, avg loss: 1.370339354276657\n",
      "trial: 3, iter: 1200, curr loss: 1.3680537939071655, avg loss: 1.3652846014499664\n",
      "trial: 3, iter: 1400, curr loss: 1.3583160638809204, avg loss: 1.3604999858140945\n",
      "trial: 3, iter: 1600, curr loss: 1.3500256538391113, avg loss: 1.3538218712806702\n",
      "trial: 3, iter: 1800, curr loss: 1.3499956130981445, avg loss: 1.3440705722570419\n",
      "trial: 3, iter: 2000, curr loss: 1.3259696960449219, avg loss: 1.3380663865804672\n",
      "trial: 3, iter: 2200, curr loss: 1.332541823387146, avg loss: 1.328896737098694\n",
      "trial: 3, iter: 2400, curr loss: 1.3142329454421997, avg loss: 1.3253933191299438\n",
      "trial: 3, iter: 2600, curr loss: 1.3336212635040283, avg loss: 1.318595650792122\n",
      "trial: 3, iter: 2800, curr loss: 1.3100038766860962, avg loss: 1.3156116151809691\n",
      "trial: 3, iter: 3000, curr loss: 1.3264570236206055, avg loss: 1.3103467810153961\n",
      "trial: 3, ldr: 0.16115275025367737\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3814058303833008, avg loss: 1.387362093925476\n",
      "trial: 4, iter: 400, curr loss: 1.386956810951233, avg loss: 1.386634224653244\n",
      "trial: 4, iter: 600, curr loss: 1.3877902030944824, avg loss: 1.3861517745256424\n",
      "trial: 4, iter: 800, curr loss: 1.389859676361084, avg loss: 1.3814079749584198\n",
      "trial: 4, iter: 1000, curr loss: 1.371909737586975, avg loss: 1.3697765862941742\n",
      "trial: 4, iter: 1200, curr loss: 1.35350501537323, avg loss: 1.3635018688440323\n",
      "trial: 4, iter: 1400, curr loss: 1.347260594367981, avg loss: 1.3569715243577958\n",
      "trial: 4, iter: 1600, curr loss: 1.3323546648025513, avg loss: 1.3500518119335174\n",
      "trial: 4, iter: 1800, curr loss: 1.323428750038147, avg loss: 1.3414391177892684\n",
      "trial: 4, iter: 2000, curr loss: 1.3090790510177612, avg loss: 1.3314992666244507\n",
      "trial: 4, iter: 2200, curr loss: 1.3400163650512695, avg loss: 1.3271938771009446\n",
      "trial: 4, iter: 2400, curr loss: 1.306409239768982, avg loss: 1.3211617559194564\n",
      "trial: 4, iter: 2600, curr loss: 1.3183432817459106, avg loss: 1.315423931479454\n",
      "trial: 4, iter: 2800, curr loss: 1.2936898469924927, avg loss: 1.3092399424314498\n",
      "trial: 4, iter: 3000, curr loss: 1.3210504055023193, avg loss: 1.3043847352266311\n",
      "trial: 4, ldr: 0.21976147592067719\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385671854019165, avg loss: 1.3874783515930176\n",
      "trial: 5, iter: 400, curr loss: 1.383371114730835, avg loss: 1.386426637172699\n",
      "trial: 5, iter: 600, curr loss: 1.3779593706130981, avg loss: 1.385726084113121\n",
      "trial: 5, iter: 800, curr loss: 1.3738571405410767, avg loss: 1.382520417571068\n",
      "trial: 5, iter: 1000, curr loss: 1.3777456283569336, avg loss: 1.3754803961515427\n",
      "trial: 5, iter: 1200, curr loss: 1.3584991693496704, avg loss: 1.3713366597890855\n",
      "trial: 5, iter: 1400, curr loss: 1.3719377517700195, avg loss: 1.3662741255760193\n",
      "trial: 5, iter: 1600, curr loss: 1.3574090003967285, avg loss: 1.3616712492704393\n",
      "trial: 5, iter: 1800, curr loss: 1.370676040649414, avg loss: 1.355926885008812\n",
      "trial: 5, iter: 2000, curr loss: 1.3307390213012695, avg loss: 1.3485721850395203\n",
      "trial: 5, iter: 2200, curr loss: 1.3366349935531616, avg loss: 1.343604730963707\n",
      "trial: 5, iter: 2400, curr loss: 1.337967038154602, avg loss: 1.3359284681081771\n",
      "trial: 5, iter: 2600, curr loss: 1.327355980873108, avg loss: 1.3293924587965011\n",
      "trial: 5, iter: 2800, curr loss: 1.2890819311141968, avg loss: 1.323399630188942\n",
      "trial: 5, iter: 3000, curr loss: 1.3495392799377441, avg loss: 1.3173090994358063\n",
      "trial: 5, ldr: 0.15317289531230927\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.18253088891506195\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3842506408691406, avg loss: 1.387347245812416\n",
      "trial: 1, iter: 400, curr loss: 1.38736093044281, avg loss: 1.3864652413129805\n",
      "trial: 1, iter: 600, curr loss: 1.3761485815048218, avg loss: 1.3837212681770326\n",
      "trial: 1, iter: 800, curr loss: 1.392675757408142, avg loss: 1.369599216580391\n",
      "trial: 1, iter: 1000, curr loss: 1.3735498189926147, avg loss: 1.3625782167911529\n",
      "trial: 1, iter: 1200, curr loss: 1.3512532711029053, avg loss: 1.3604791021347047\n",
      "trial: 1, iter: 1400, curr loss: 1.3787227869033813, avg loss: 1.3534367913007737\n",
      "trial: 1, iter: 1600, curr loss: 1.3610339164733887, avg loss: 1.345926126241684\n",
      "trial: 1, iter: 1800, curr loss: 1.3375219106674194, avg loss: 1.3396139842271806\n",
      "trial: 1, iter: 2000, curr loss: 1.3011939525604248, avg loss: 1.3324574655294419\n",
      "trial: 1, iter: 2200, curr loss: 1.3272241353988647, avg loss: 1.323710747361183\n",
      "trial: 1, iter: 2400, curr loss: 1.3030422925949097, avg loss: 1.317342409491539\n",
      "trial: 1, iter: 2600, curr loss: 1.2850946187973022, avg loss: 1.3145784741640092\n",
      "trial: 1, iter: 2800, curr loss: 1.2842707633972168, avg loss: 1.309032810330391\n",
      "trial: 1, iter: 3000, curr loss: 1.3221920728683472, avg loss: 1.3002783131599427\n",
      "trial: 1, ldr: 0.2672747075557709\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3909245729446411, avg loss: 1.3874952208995819\n",
      "trial: 2, iter: 400, curr loss: 1.3888068199157715, avg loss: 1.3867012041807174\n",
      "trial: 2, iter: 600, curr loss: 1.3882886171340942, avg loss: 1.386386696100235\n",
      "trial: 2, iter: 800, curr loss: 1.3859654664993286, avg loss: 1.3862871831655503\n",
      "trial: 2, iter: 1000, curr loss: 1.3773765563964844, avg loss: 1.3836645913124084\n",
      "trial: 2, iter: 1200, curr loss: 1.3505747318267822, avg loss: 1.3712754654884338\n",
      "trial: 2, iter: 1400, curr loss: 1.3781085014343262, avg loss: 1.3623599624633789\n",
      "trial: 2, iter: 1600, curr loss: 1.3569375276565552, avg loss: 1.3584035074710845\n",
      "trial: 2, iter: 1800, curr loss: 1.3176625967025757, avg loss: 1.3532011038064957\n",
      "trial: 2, iter: 2000, curr loss: 1.3579078912734985, avg loss: 1.341675009727478\n",
      "trial: 2, iter: 2200, curr loss: 1.347258448600769, avg loss: 1.3325852143764496\n",
      "trial: 2, iter: 2400, curr loss: 1.3200068473815918, avg loss: 1.3243510049581528\n",
      "trial: 2, iter: 2600, curr loss: 1.2988078594207764, avg loss: 1.3162649738788605\n",
      "trial: 2, iter: 2800, curr loss: 1.3139551877975464, avg loss: 1.3074772125482559\n",
      "trial: 2, iter: 3000, curr loss: 1.3344767093658447, avg loss: 1.3048709201812745\n",
      "trial: 2, ldr: 0.20008161664009094\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3875536918640137, avg loss: 1.38790888607502\n",
      "trial: 3, iter: 400, curr loss: 1.3866968154907227, avg loss: 1.3867292380332947\n",
      "trial: 3, iter: 600, curr loss: 1.3888640403747559, avg loss: 1.3867851120233536\n",
      "trial: 3, iter: 800, curr loss: 1.3846120834350586, avg loss: 1.3859649676084518\n",
      "trial: 3, iter: 1000, curr loss: 1.3827073574066162, avg loss: 1.3827889442443848\n",
      "trial: 3, iter: 1200, curr loss: 1.3827157020568848, avg loss: 1.3736755567789078\n",
      "trial: 3, iter: 1400, curr loss: 1.3721059560775757, avg loss: 1.3684750938415526\n",
      "trial: 3, iter: 1600, curr loss: 1.3624913692474365, avg loss: 1.3660808795690536\n",
      "trial: 3, iter: 1800, curr loss: 1.3714245557785034, avg loss: 1.3610954415798187\n",
      "trial: 3, iter: 2000, curr loss: 1.3601282835006714, avg loss: 1.3539420533180238\n",
      "trial: 3, iter: 2200, curr loss: 1.356659173965454, avg loss: 1.3451963984966278\n",
      "trial: 3, iter: 2400, curr loss: 1.3522714376449585, avg loss: 1.3349745070934296\n",
      "trial: 3, iter: 2600, curr loss: 1.3223117589950562, avg loss: 1.326911209821701\n",
      "trial: 3, iter: 2800, curr loss: 1.3152114152908325, avg loss: 1.3169118803739548\n",
      "trial: 3, iter: 3000, curr loss: 1.291267991065979, avg loss: 1.3096443974971772\n",
      "trial: 3, ldr: 0.15470340847969055\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3857181072235107, avg loss: 1.3878622871637345\n",
      "trial: 4, iter: 400, curr loss: 1.3897711038589478, avg loss: 1.3866338312625885\n",
      "trial: 4, iter: 600, curr loss: 1.385043978691101, avg loss: 1.386122033596039\n",
      "trial: 4, iter: 800, curr loss: 1.3809128999710083, avg loss: 1.3826250714063644\n",
      "trial: 4, iter: 1000, curr loss: 1.3732311725616455, avg loss: 1.3701329243183136\n",
      "trial: 4, iter: 1200, curr loss: 1.3610613346099854, avg loss: 1.3627057790756225\n",
      "trial: 4, iter: 1400, curr loss: 1.3582743406295776, avg loss: 1.357928426861763\n",
      "trial: 4, iter: 1600, curr loss: 1.331998348236084, avg loss: 1.3530947291851043\n",
      "trial: 4, iter: 1800, curr loss: 1.3562639951705933, avg loss: 1.3449826103448868\n",
      "trial: 4, iter: 2000, curr loss: 1.3223676681518555, avg loss: 1.3374260258674622\n",
      "trial: 4, iter: 2200, curr loss: 1.3072917461395264, avg loss: 1.3291193503141403\n",
      "trial: 4, iter: 2400, curr loss: 1.3008824586868286, avg loss: 1.318221029639244\n",
      "trial: 4, iter: 2600, curr loss: 1.328514814376831, avg loss: 1.3120844489336014\n",
      "trial: 4, iter: 2800, curr loss: 1.3132452964782715, avg loss: 1.3087673646211624\n",
      "trial: 4, iter: 3000, curr loss: 1.310861587524414, avg loss: 1.3048537635803223\n",
      "trial: 4, ldr: 0.2111739218235016\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3882871866226196, avg loss: 1.3871421861648559\n",
      "trial: 5, iter: 400, curr loss: 1.3868612051010132, avg loss: 1.3865766763687133\n",
      "trial: 5, iter: 600, curr loss: 1.388850212097168, avg loss: 1.38610899746418\n",
      "trial: 5, iter: 800, curr loss: 1.3808887004852295, avg loss: 1.383796635866165\n",
      "trial: 5, iter: 1000, curr loss: 1.3780763149261475, avg loss: 1.3777755111455918\n",
      "trial: 5, iter: 1200, curr loss: 1.3367962837219238, avg loss: 1.370341956615448\n",
      "trial: 5, iter: 1400, curr loss: 1.3643794059753418, avg loss: 1.3634713858366012\n",
      "trial: 5, iter: 1600, curr loss: 1.3718186616897583, avg loss: 1.3586372476816178\n",
      "trial: 5, iter: 1800, curr loss: 1.3432835340499878, avg loss: 1.354990583062172\n",
      "trial: 5, iter: 2000, curr loss: 1.3431105613708496, avg loss: 1.3462077587842942\n",
      "trial: 5, iter: 2200, curr loss: 1.3627761602401733, avg loss: 1.3387209063768386\n",
      "trial: 5, iter: 2400, curr loss: 1.3248045444488525, avg loss: 1.329559664130211\n",
      "trial: 5, iter: 2600, curr loss: 1.2980685234069824, avg loss: 1.3235257703065872\n",
      "trial: 5, iter: 2800, curr loss: 1.2982078790664673, avg loss: 1.3150645571947097\n",
      "trial: 5, iter: 3000, curr loss: 1.3125503063201904, avg loss: 1.3080486363172532\n",
      "trial: 5, ldr: 0.17052976787090302\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2007526844739914\n",
      "Experiment done with data path: ./data/catNon-lin-NI_10/data.10k.dz50.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_17/data.5k.dz200.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3849681615829468, avg loss: 1.3873020136356353\n",
      "trial: 1, iter: 400, curr loss: 1.3864516019821167, avg loss: 1.3868153470754623\n",
      "trial: 1, iter: 600, curr loss: 1.3858537673950195, avg loss: 1.3865988701581955\n",
      "trial: 1, iter: 800, curr loss: 1.387043833732605, avg loss: 1.3865455102920532\n",
      "trial: 1, iter: 1000, curr loss: 1.3859232664108276, avg loss: 1.386502931714058\n",
      "trial: 1, iter: 1200, curr loss: 1.3869181871414185, avg loss: 1.3864974784851074\n",
      "trial: 1, iter: 1400, curr loss: 1.3859779834747314, avg loss: 1.3863778918981553\n",
      "trial: 1, ldr: 0.0029678044375032187\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.38650381565094, avg loss: 1.387320224046707\n",
      "trial: 2, iter: 400, curr loss: 1.387977123260498, avg loss: 1.3865698349475861\n",
      "trial: 2, iter: 600, curr loss: 1.3853164911270142, avg loss: 1.3867293709516526\n",
      "trial: 2, iter: 800, curr loss: 1.384954810142517, avg loss: 1.3865274411439896\n",
      "trial: 2, iter: 1000, curr loss: 1.3864949941635132, avg loss: 1.386405593752861\n",
      "trial: 2, iter: 1200, curr loss: 1.3857609033584595, avg loss: 1.3865109103918076\n",
      "trial: 2, iter: 1400, curr loss: 1.3858340978622437, avg loss: 1.3863955324888229\n",
      "trial: 2, ldr: -0.004710246808826923\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.38722825050354, avg loss: 1.3875197690725327\n",
      "trial: 3, iter: 400, curr loss: 1.3849992752075195, avg loss: 1.3865712481737136\n",
      "trial: 3, iter: 600, curr loss: 1.3843075037002563, avg loss: 1.3864065998792647\n",
      "trial: 3, iter: 800, curr loss: 1.3857954740524292, avg loss: 1.3864718264341354\n",
      "trial: 3, iter: 1000, curr loss: 1.3853533267974854, avg loss: 1.38632603764534\n",
      "trial: 3, iter: 1200, curr loss: 1.3851162195205688, avg loss: 1.3864053499698639\n",
      "trial: 3, iter: 1400, curr loss: 1.3864613771438599, avg loss: 1.3863733148574828\n",
      "trial: 3, ldr: -0.002406842540949583\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.388006329536438, avg loss: 1.387387502193451\n",
      "trial: 4, iter: 400, curr loss: 1.3879709243774414, avg loss: 1.3866205829381943\n",
      "trial: 4, iter: 600, curr loss: 1.3859888315200806, avg loss: 1.3865579825639724\n",
      "trial: 4, iter: 800, curr loss: 1.3857203722000122, avg loss: 1.3864646124839783\n",
      "trial: 4, iter: 1000, curr loss: 1.3870476484298706, avg loss: 1.3865915948152543\n",
      "trial: 4, iter: 1200, curr loss: 1.3858381509780884, avg loss: 1.3864843291044235\n",
      "trial: 4, iter: 1400, curr loss: 1.3862472772598267, avg loss: 1.3863436883687974\n",
      "trial: 4, ldr: 0.01295956689864397\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3848360776901245, avg loss: 1.3870143347978592\n",
      "trial: 5, iter: 400, curr loss: 1.3852710723876953, avg loss: 1.3866753834486008\n",
      "trial: 5, iter: 600, curr loss: 1.3856604099273682, avg loss: 1.3865409821271897\n",
      "trial: 5, iter: 800, curr loss: 1.385691523551941, avg loss: 1.38642227768898\n",
      "trial: 5, iter: 1000, curr loss: 1.3864467144012451, avg loss: 1.3865452128648759\n",
      "trial: 5, iter: 1200, curr loss: 1.3854252099990845, avg loss: 1.386436504125595\n",
      "trial: 5, iter: 1400, curr loss: 1.3869425058364868, avg loss: 1.3863783925771713\n",
      "trial: 5, ldr: 0.009218146093189716\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.00360568561591208\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38723886013031, avg loss: 1.3870782667398454\n",
      "trial: 1, iter: 400, curr loss: 1.387987494468689, avg loss: 1.3866674613952636\n",
      "trial: 1, iter: 600, curr loss: 1.3869129419326782, avg loss: 1.3865163511037826\n",
      "trial: 1, iter: 800, curr loss: 1.3869813680648804, avg loss: 1.38642451941967\n",
      "trial: 1, iter: 1000, curr loss: 1.3865653276443481, avg loss: 1.386468272805214\n",
      "trial: 1, iter: 1200, curr loss: 1.3865090608596802, avg loss: 1.3863867872953415\n",
      "trial: 1, iter: 1400, curr loss: 1.3857289552688599, avg loss: 1.3863653630018233\n",
      "trial: 1, ldr: -0.0005721749039366841\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3860327005386353, avg loss: 1.3872415393590927\n",
      "trial: 2, iter: 400, curr loss: 1.3877688646316528, avg loss: 1.386532569527626\n",
      "trial: 2, iter: 600, curr loss: 1.3876253366470337, avg loss: 1.3866594970226287\n",
      "trial: 2, iter: 800, curr loss: 1.3872929811477661, avg loss: 1.3864566564559937\n",
      "trial: 2, iter: 1000, curr loss: 1.3865116834640503, avg loss: 1.3864080864191055\n",
      "trial: 2, iter: 1200, curr loss: 1.3867676258087158, avg loss: 1.3863729506731033\n",
      "trial: 2, iter: 1400, curr loss: 1.386348843574524, avg loss: 1.3863506644964219\n",
      "trial: 2, ldr: 0.008651570416986942\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3855937719345093, avg loss: 1.3870823574066162\n",
      "trial: 3, iter: 400, curr loss: 1.3871784210205078, avg loss: 1.3865740877389907\n",
      "trial: 3, iter: 600, curr loss: 1.3865529298782349, avg loss: 1.3865747082233428\n",
      "trial: 3, iter: 800, curr loss: 1.3865665197372437, avg loss: 1.3865011942386627\n",
      "trial: 3, iter: 1000, curr loss: 1.3869215250015259, avg loss: 1.386450593471527\n",
      "trial: 3, iter: 1200, curr loss: 1.3859190940856934, avg loss: 1.3864236891269683\n",
      "trial: 3, iter: 1400, curr loss: 1.3866424560546875, avg loss: 1.3864034539461136\n",
      "trial: 3, ldr: 0.0073675736784935\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3866115808486938, avg loss: 1.387353109717369\n",
      "trial: 4, iter: 400, curr loss: 1.3883581161499023, avg loss: 1.3865896463394165\n",
      "trial: 4, iter: 600, curr loss: 1.387065052986145, avg loss: 1.3864993679523467\n",
      "trial: 4, iter: 800, curr loss: 1.3842326402664185, avg loss: 1.3866196471452712\n",
      "trial: 4, iter: 1000, curr loss: 1.3847782611846924, avg loss: 1.3865498518943786\n",
      "trial: 4, iter: 1200, curr loss: 1.3861846923828125, avg loss: 1.3865526562929154\n",
      "trial: 4, iter: 1400, curr loss: 1.3856620788574219, avg loss: 1.386429604291916\n",
      "trial: 4, ldr: -0.04131753742694855\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3887299299240112, avg loss: 1.3872832083702087\n",
      "trial: 5, iter: 400, curr loss: 1.3820596933364868, avg loss: 1.3866212582588195\n",
      "trial: 5, iter: 600, curr loss: 1.3863810300827026, avg loss: 1.3865112364292145\n",
      "trial: 5, iter: 800, curr loss: 1.3862175941467285, avg loss: 1.386399958729744\n",
      "trial: 5, iter: 1000, curr loss: 1.386686086654663, avg loss: 1.3864655250310898\n",
      "trial: 5, iter: 1200, curr loss: 1.3869601488113403, avg loss: 1.3864063781499862\n",
      "trial: 5, iter: 1400, curr loss: 1.3859734535217285, avg loss: 1.3865524864196777\n",
      "trial: 5, ldr: -0.01274101622402668\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.007722316891886294\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3868215084075928, avg loss: 1.3872113901376724\n",
      "trial: 1, iter: 400, curr loss: 1.3849561214447021, avg loss: 1.3867913866043091\n",
      "trial: 1, iter: 600, curr loss: 1.3863986730575562, avg loss: 1.3865036904811858\n",
      "trial: 1, iter: 800, curr loss: 1.3863418102264404, avg loss: 1.3865097266435624\n",
      "trial: 1, iter: 1000, curr loss: 1.386061668395996, avg loss: 1.3865326792001724\n",
      "trial: 1, iter: 1200, curr loss: 1.3855987787246704, avg loss: 1.3862984848022462\n",
      "trial: 1, iter: 1400, curr loss: 1.384698510169983, avg loss: 1.3864309173822402\n",
      "trial: 1, ldr: -0.002273766091093421\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3882733583450317, avg loss: 1.3876544308662415\n",
      "trial: 2, iter: 400, curr loss: 1.3859301805496216, avg loss: 1.3866675257682801\n",
      "trial: 2, iter: 600, curr loss: 1.3881611824035645, avg loss: 1.3865707695484162\n",
      "trial: 2, iter: 800, curr loss: 1.3875095844268799, avg loss: 1.3867347204685212\n",
      "trial: 2, iter: 1000, curr loss: 1.387692928314209, avg loss: 1.3865373998880386\n",
      "trial: 2, iter: 1200, curr loss: 1.3864320516586304, avg loss: 1.3865307229757309\n",
      "trial: 2, iter: 1400, curr loss: 1.3861088752746582, avg loss: 1.3864046931266785\n",
      "trial: 2, ldr: -0.016273848712444305\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.389151692390442, avg loss: 1.387220913171768\n",
      "trial: 3, iter: 400, curr loss: 1.3854037523269653, avg loss: 1.3866672283411026\n",
      "trial: 3, iter: 600, curr loss: 1.3856637477874756, avg loss: 1.386596541404724\n",
      "trial: 3, iter: 800, curr loss: 1.3851717710494995, avg loss: 1.3866899394989014\n",
      "trial: 3, iter: 1000, curr loss: 1.3844012022018433, avg loss: 1.3866021132469177\n",
      "trial: 3, iter: 1200, curr loss: 1.3859697580337524, avg loss: 1.3865226912498474\n",
      "trial: 3, iter: 1400, curr loss: 1.386165976524353, avg loss: 1.3865008062124253\n",
      "trial: 3, ldr: 0.013275758363306522\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3845884799957275, avg loss: 1.3872263795137405\n",
      "trial: 4, iter: 400, curr loss: 1.3875696659088135, avg loss: 1.3864876008033753\n",
      "trial: 4, iter: 600, curr loss: 1.3865690231323242, avg loss: 1.386492793560028\n",
      "trial: 4, iter: 800, curr loss: 1.3867213726043701, avg loss: 1.3864539813995362\n",
      "trial: 4, iter: 1000, curr loss: 1.3864041566848755, avg loss: 1.3862920278310775\n",
      "trial: 4, iter: 1200, curr loss: 1.3866955041885376, avg loss: 1.386469955444336\n",
      "trial: 4, iter: 1400, curr loss: 1.3866970539093018, avg loss: 1.386408019065857\n",
      "trial: 4, ldr: 0.0013707836624234915\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3861844539642334, avg loss: 1.3871437817811967\n",
      "trial: 5, iter: 400, curr loss: 1.3861924409866333, avg loss: 1.3867788642644883\n",
      "trial: 5, iter: 600, curr loss: 1.387891173362732, avg loss: 1.3865557342767716\n",
      "trial: 5, iter: 800, curr loss: 1.386979103088379, avg loss: 1.386571210026741\n",
      "trial: 5, iter: 1000, curr loss: 1.3881498575210571, avg loss: 1.3864386761188507\n",
      "trial: 5, iter: 1200, curr loss: 1.3876969814300537, avg loss: 1.386496941447258\n",
      "trial: 5, iter: 1400, curr loss: 1.385162115097046, avg loss: 1.386454793214798\n",
      "trial: 5, ldr: -0.003976544365286827\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0015755234286189078\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3868831396102905, avg loss: 1.387543905377388\n",
      "trial: 1, iter: 400, curr loss: 1.3905880451202393, avg loss: 1.3868435889482498\n",
      "trial: 1, iter: 600, curr loss: 1.3858507871627808, avg loss: 1.3867181771993637\n",
      "trial: 1, iter: 800, curr loss: 1.3865468502044678, avg loss: 1.3865155655145645\n",
      "trial: 1, iter: 1000, curr loss: 1.3879306316375732, avg loss: 1.386610771417618\n",
      "trial: 1, iter: 1200, curr loss: 1.385044813156128, avg loss: 1.3863764435052872\n",
      "trial: 1, iter: 1400, curr loss: 1.3862123489379883, avg loss: 1.3864671456813813\n",
      "trial: 1, ldr: -0.003241640515625477\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3876361846923828, avg loss: 1.3874011147022247\n",
      "trial: 2, iter: 400, curr loss: 1.3869346380233765, avg loss: 1.386757047176361\n",
      "trial: 2, iter: 600, curr loss: 1.3869481086730957, avg loss: 1.3864899754524231\n",
      "trial: 2, iter: 800, curr loss: 1.3871045112609863, avg loss: 1.3864724165201188\n",
      "trial: 2, iter: 1000, curr loss: 1.3871132135391235, avg loss: 1.3865584075450896\n",
      "trial: 2, iter: 1200, curr loss: 1.38828444480896, avg loss: 1.3864706349372864\n",
      "trial: 2, iter: 1400, curr loss: 1.3872249126434326, avg loss: 1.3864698779582978\n",
      "trial: 2, ldr: -0.0028288073372095823\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3831757307052612, avg loss: 1.3869946867227554\n",
      "trial: 3, iter: 400, curr loss: 1.3861719369888306, avg loss: 1.3865888130664825\n",
      "trial: 3, iter: 600, curr loss: 1.3860437870025635, avg loss: 1.3865337246656417\n",
      "trial: 3, iter: 800, curr loss: 1.3848233222961426, avg loss: 1.386430190205574\n",
      "trial: 3, iter: 1000, curr loss: 1.3835200071334839, avg loss: 1.38642140686512\n",
      "trial: 3, iter: 1200, curr loss: 1.3849159479141235, avg loss: 1.3864698266983033\n",
      "trial: 3, iter: 1400, curr loss: 1.3866543769836426, avg loss: 1.386438325047493\n",
      "trial: 3, ldr: -0.004090900998562574\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.385217547416687, avg loss: 1.3871802818775176\n",
      "trial: 4, iter: 400, curr loss: 1.3860739469528198, avg loss: 1.3867383396625519\n",
      "trial: 4, iter: 600, curr loss: 1.385958194732666, avg loss: 1.386522007584572\n",
      "trial: 4, iter: 800, curr loss: 1.3863675594329834, avg loss: 1.3864266937971115\n",
      "trial: 4, iter: 1000, curr loss: 1.3858113288879395, avg loss: 1.3863475614786147\n",
      "trial: 4, iter: 1200, curr loss: 1.3869898319244385, avg loss: 1.386414789557457\n",
      "trial: 4, iter: 1400, curr loss: 1.3857673406600952, avg loss: 1.3863562631607056\n",
      "trial: 4, ldr: -0.006098664831370115\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3859031200408936, avg loss: 1.3873790681362153\n",
      "trial: 5, iter: 400, curr loss: 1.3869693279266357, avg loss: 1.3865667647123336\n",
      "trial: 5, iter: 600, curr loss: 1.3866980075836182, avg loss: 1.3865089064836502\n",
      "trial: 5, iter: 800, curr loss: 1.3872201442718506, avg loss: 1.3866117680072785\n",
      "trial: 5, iter: 1000, curr loss: 1.388663411140442, avg loss: 1.386554133296013\n",
      "trial: 5, iter: 1200, curr loss: 1.3885376453399658, avg loss: 1.3865477246046067\n",
      "trial: 5, iter: 1400, curr loss: 1.3848819732666016, avg loss: 1.3865411776304244\n",
      "trial: 5, ldr: -0.006035543978214264\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.004459111532196402\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3867685794830322, avg loss: 1.3872568029165269\n",
      "trial: 1, iter: 400, curr loss: 1.38605797290802, avg loss: 1.386761724948883\n",
      "trial: 1, iter: 600, curr loss: 1.3877815008163452, avg loss: 1.3866271644830703\n",
      "trial: 1, iter: 800, curr loss: 1.3824899196624756, avg loss: 1.3865375244617462\n",
      "trial: 1, iter: 1000, curr loss: 1.3863157033920288, avg loss: 1.3864479041099549\n",
      "trial: 1, iter: 1200, curr loss: 1.3845311403274536, avg loss: 1.3864641106128692\n",
      "trial: 1, iter: 1400, curr loss: 1.3865675926208496, avg loss: 1.3864373248815536\n",
      "trial: 1, ldr: 0.007617211900651455\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3854275941848755, avg loss: 1.3872500795125962\n",
      "trial: 2, iter: 400, curr loss: 1.3854961395263672, avg loss: 1.3867728561162949\n",
      "trial: 2, iter: 600, curr loss: 1.3867114782333374, avg loss: 1.3865965133905411\n",
      "trial: 2, iter: 800, curr loss: 1.3868502378463745, avg loss: 1.386423454284668\n",
      "trial: 2, iter: 1000, curr loss: 1.3868930339813232, avg loss: 1.3864969307184218\n",
      "trial: 2, iter: 1200, curr loss: 1.3869843482971191, avg loss: 1.3864062911272048\n",
      "trial: 2, iter: 1400, curr loss: 1.3873895406723022, avg loss: 1.386401913166046\n",
      "trial: 2, ldr: -0.008270244114100933\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3865443468093872, avg loss: 1.3870487815141679\n",
      "trial: 3, iter: 400, curr loss: 1.3878055810928345, avg loss: 1.3866439163684845\n",
      "trial: 3, iter: 600, curr loss: 1.3857871294021606, avg loss: 1.3864240109920503\n",
      "trial: 3, iter: 800, curr loss: 1.3874435424804688, avg loss: 1.3863767623901366\n",
      "trial: 3, iter: 1000, curr loss: 1.3854165077209473, avg loss: 1.3864344388246537\n",
      "trial: 3, iter: 1200, curr loss: 1.3866523504257202, avg loss: 1.3864296436309815\n",
      "trial: 3, iter: 1400, curr loss: 1.3853970766067505, avg loss: 1.386342681646347\n",
      "trial: 3, ldr: 0.010408232919871807\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3891912698745728, avg loss: 1.3871220874786376\n",
      "trial: 4, iter: 400, curr loss: 1.388173222541809, avg loss: 1.386595494747162\n",
      "trial: 4, iter: 600, curr loss: 1.3869543075561523, avg loss: 1.386579255461693\n",
      "trial: 4, iter: 800, curr loss: 1.387440800666809, avg loss: 1.3864441120624542\n",
      "trial: 4, iter: 1000, curr loss: 1.387267827987671, avg loss: 1.386436671614647\n",
      "trial: 4, iter: 1200, curr loss: 1.3871749639511108, avg loss: 1.3863657093048096\n",
      "trial: 4, iter: 1400, curr loss: 1.3870034217834473, avg loss: 1.3863566720485687\n",
      "trial: 4, ldr: 0.023523354902863503\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3876296281814575, avg loss: 1.3871538770198821\n",
      "trial: 5, iter: 400, curr loss: 1.3860068321228027, avg loss: 1.3868194794654847\n",
      "trial: 5, iter: 600, curr loss: 1.3866908550262451, avg loss: 1.3866935962438582\n",
      "trial: 5, iter: 800, curr loss: 1.3880515098571777, avg loss: 1.3865557062625884\n",
      "trial: 5, iter: 1000, curr loss: 1.3859179019927979, avg loss: 1.3863775932788849\n",
      "trial: 5, iter: 1200, curr loss: 1.3864853382110596, avg loss: 1.3865045326948167\n",
      "trial: 5, iter: 1400, curr loss: 1.385222315788269, avg loss: 1.386413568854332\n",
      "trial: 5, ldr: -0.006678280420601368\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.005320055037736892\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3874763250350952, avg loss: 1.3874921768903732\n",
      "trial: 1, iter: 400, curr loss: 1.3863211870193481, avg loss: 1.386656062602997\n",
      "trial: 1, iter: 600, curr loss: 1.3851737976074219, avg loss: 1.3864215040206909\n",
      "trial: 1, iter: 800, curr loss: 1.3857403993606567, avg loss: 1.3865572732686997\n",
      "trial: 1, iter: 1000, curr loss: 1.387994408607483, avg loss: 1.3864624333381652\n",
      "trial: 1, iter: 1200, curr loss: 1.3850421905517578, avg loss: 1.3863864421844483\n",
      "trial: 1, iter: 1400, curr loss: 1.3857526779174805, avg loss: 1.386510627269745\n",
      "trial: 1, ldr: 0.009504021145403385\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.388083577156067, avg loss: 1.3873569321632386\n",
      "trial: 2, iter: 400, curr loss: 1.3848419189453125, avg loss: 1.3867006903886796\n",
      "trial: 2, iter: 600, curr loss: 1.3867599964141846, avg loss: 1.3865919303894043\n",
      "trial: 2, iter: 800, curr loss: 1.386417269706726, avg loss: 1.3864054417610168\n",
      "trial: 2, iter: 1000, curr loss: 1.3864305019378662, avg loss: 1.3867405533790589\n",
      "trial: 2, iter: 1200, curr loss: 1.3866204023361206, avg loss: 1.3865745663642883\n",
      "trial: 2, iter: 1400, curr loss: 1.3859448432922363, avg loss: 1.3864995127916335\n",
      "trial: 2, ldr: -0.0012014793464913964\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.38895845413208, avg loss: 1.387237961292267\n",
      "trial: 3, iter: 400, curr loss: 1.3855006694793701, avg loss: 1.3867201006412506\n",
      "trial: 3, iter: 600, curr loss: 1.3850167989730835, avg loss: 1.386597284078598\n",
      "trial: 3, iter: 800, curr loss: 1.3843278884887695, avg loss: 1.3866159945726395\n",
      "trial: 3, iter: 1000, curr loss: 1.3860996961593628, avg loss: 1.3865189516544343\n",
      "trial: 3, iter: 1200, curr loss: 1.3864686489105225, avg loss: 1.3865052133798599\n",
      "trial: 3, iter: 1400, curr loss: 1.3859541416168213, avg loss: 1.3862159007787704\n",
      "trial: 3, ldr: -0.015422118827700615\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3885375261306763, avg loss: 1.387188059091568\n",
      "trial: 4, iter: 400, curr loss: 1.3864421844482422, avg loss: 1.386654236316681\n",
      "trial: 4, iter: 600, curr loss: 1.386153221130371, avg loss: 1.38657255589962\n",
      "trial: 4, iter: 800, curr loss: 1.3850657939910889, avg loss: 1.3864678364992142\n",
      "trial: 4, iter: 1000, curr loss: 1.3858692646026611, avg loss: 1.386490241289139\n",
      "trial: 4, iter: 1200, curr loss: 1.385265827178955, avg loss: 1.3863173657655716\n",
      "trial: 4, iter: 1400, curr loss: 1.3869136571884155, avg loss: 1.3863633519411087\n",
      "trial: 4, ldr: -0.011282525025308132\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3855317831039429, avg loss: 1.3875015425682067\n",
      "trial: 5, iter: 400, curr loss: 1.3880631923675537, avg loss: 1.3867600357532501\n",
      "trial: 5, iter: 600, curr loss: 1.3874980211257935, avg loss: 1.3865903753042221\n",
      "trial: 5, iter: 800, curr loss: 1.3843427896499634, avg loss: 1.3865267926454543\n",
      "trial: 5, iter: 1000, curr loss: 1.3858304023742676, avg loss: 1.3864943182468414\n",
      "trial: 5, iter: 1200, curr loss: 1.3866369724273682, avg loss: 1.3863777661323546\n",
      "trial: 5, iter: 1400, curr loss: 1.3886158466339111, avg loss: 1.3864019471406936\n",
      "trial: 5, ldr: -0.015931235626339912\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.006866667536087334\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3878971338272095, avg loss: 1.3871247208118438\n",
      "trial: 1, iter: 400, curr loss: 1.3872506618499756, avg loss: 1.3867587542533875\n",
      "trial: 1, iter: 600, curr loss: 1.3844013214111328, avg loss: 1.3866197967529297\n",
      "trial: 1, iter: 800, curr loss: 1.3889802694320679, avg loss: 1.3865466940402984\n",
      "trial: 1, iter: 1000, curr loss: 1.3854448795318604, avg loss: 1.3864035677909852\n",
      "trial: 1, iter: 1200, curr loss: 1.3876228332519531, avg loss: 1.3865449953079223\n",
      "trial: 1, iter: 1400, curr loss: 1.3864319324493408, avg loss: 1.3864308154582978\n",
      "trial: 1, ldr: -0.022815823554992676\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849153518676758, avg loss: 1.3874370139837264\n",
      "trial: 2, iter: 400, curr loss: 1.3878886699676514, avg loss: 1.3868564689159393\n",
      "trial: 2, iter: 600, curr loss: 1.3845200538635254, avg loss: 1.3866426837444306\n",
      "trial: 2, iter: 800, curr loss: 1.3870937824249268, avg loss: 1.3864729231595994\n",
      "trial: 2, iter: 1000, curr loss: 1.3849679231643677, avg loss: 1.3864638125896454\n",
      "trial: 2, iter: 1200, curr loss: 1.3873724937438965, avg loss: 1.386425393819809\n",
      "trial: 2, iter: 1400, curr loss: 1.3878480195999146, avg loss: 1.3864634537696838\n",
      "trial: 2, ldr: 0.004349734168499708\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3884646892547607, avg loss: 1.387272334098816\n",
      "trial: 3, iter: 400, curr loss: 1.385955572128296, avg loss: 1.3867922669649124\n",
      "trial: 3, iter: 600, curr loss: 1.387306571006775, avg loss: 1.3867277330160142\n",
      "trial: 3, iter: 800, curr loss: 1.3855938911437988, avg loss: 1.3863852906227112\n",
      "trial: 3, iter: 1000, curr loss: 1.3862583637237549, avg loss: 1.3865458846092225\n",
      "trial: 3, iter: 1200, curr loss: 1.386152744293213, avg loss: 1.3863947767019271\n",
      "trial: 3, iter: 1400, curr loss: 1.3874893188476562, avg loss: 1.386403683423996\n",
      "trial: 3, ldr: -0.021710146218538284\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3883684873580933, avg loss: 1.387469668984413\n",
      "trial: 4, iter: 400, curr loss: 1.3870571851730347, avg loss: 1.3867897140979766\n",
      "trial: 4, iter: 600, curr loss: 1.386115550994873, avg loss: 1.3865648376941682\n",
      "trial: 4, iter: 800, curr loss: 1.3865132331848145, avg loss: 1.38649021089077\n",
      "trial: 4, iter: 1000, curr loss: 1.384305715560913, avg loss: 1.3864323073625564\n",
      "trial: 4, iter: 1200, curr loss: 1.3868340253829956, avg loss: 1.3863388657569886\n",
      "trial: 4, iter: 1400, curr loss: 1.385965347290039, avg loss: 1.3865362358093263\n",
      "trial: 4, ldr: -0.0072096651419997215\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3875099420547485, avg loss: 1.3876147669553758\n",
      "trial: 5, iter: 400, curr loss: 1.3855910301208496, avg loss: 1.3866716200113296\n",
      "trial: 5, iter: 600, curr loss: 1.3869084119796753, avg loss: 1.3865760868787766\n",
      "trial: 5, iter: 800, curr loss: 1.3852523565292358, avg loss: 1.386585270166397\n",
      "trial: 5, iter: 1000, curr loss: 1.3858778476715088, avg loss: 1.3865115416049958\n",
      "trial: 5, iter: 1200, curr loss: 1.3879245519638062, avg loss: 1.3864414066076278\n",
      "trial: 5, iter: 1400, curr loss: 1.3865110874176025, avg loss: 1.3864676016569137\n",
      "trial: 5, ldr: 0.00268276734277606\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.008940626680850983\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3879364728927612, avg loss: 1.3872446042299271\n",
      "trial: 1, iter: 400, curr loss: 1.3873369693756104, avg loss: 1.3868439775705337\n",
      "trial: 1, iter: 600, curr loss: 1.3861899375915527, avg loss: 1.3866087347269058\n",
      "trial: 1, iter: 800, curr loss: 1.3874303102493286, avg loss: 1.3865460723638534\n",
      "trial: 1, iter: 1000, curr loss: 1.3879740238189697, avg loss: 1.3867699241638183\n",
      "trial: 1, iter: 1200, curr loss: 1.3851934671401978, avg loss: 1.3864458924531937\n",
      "trial: 1, iter: 1400, curr loss: 1.3854868412017822, avg loss: 1.3864170056581497\n",
      "trial: 1, ldr: -0.016886454075574875\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3877041339874268, avg loss: 1.3870622247457505\n",
      "trial: 2, iter: 400, curr loss: 1.3859573602676392, avg loss: 1.3866701978445053\n",
      "trial: 2, iter: 600, curr loss: 1.384723424911499, avg loss: 1.3864747595787048\n",
      "trial: 2, iter: 800, curr loss: 1.38816499710083, avg loss: 1.386470957994461\n",
      "trial: 2, iter: 1000, curr loss: 1.386438250541687, avg loss: 1.386397111415863\n",
      "trial: 2, iter: 1200, curr loss: 1.3870742321014404, avg loss: 1.3863869047164916\n",
      "trial: 2, iter: 1400, curr loss: 1.3866194486618042, avg loss: 1.386427640914917\n",
      "trial: 2, ldr: 0.0014068909222260118\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3832042217254639, avg loss: 1.3873901927471162\n",
      "trial: 3, iter: 400, curr loss: 1.3844834566116333, avg loss: 1.3865980744361877\n",
      "trial: 3, iter: 600, curr loss: 1.3858989477157593, avg loss: 1.3866097116470337\n",
      "trial: 3, iter: 800, curr loss: 1.38694167137146, avg loss: 1.3864555436372756\n",
      "trial: 3, iter: 1000, curr loss: 1.386284351348877, avg loss: 1.3865318977832795\n",
      "trial: 3, iter: 1200, curr loss: 1.386345624923706, avg loss: 1.3863925588130952\n",
      "trial: 3, iter: 1400, curr loss: 1.3863111734390259, avg loss: 1.3864492505788804\n",
      "trial: 3, ldr: -0.009586665779352188\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3838474750518799, avg loss: 1.3872786837816238\n",
      "trial: 4, iter: 400, curr loss: 1.384708046913147, avg loss: 1.3866442155838012\n",
      "trial: 4, iter: 600, curr loss: 1.385725736618042, avg loss: 1.38650393307209\n",
      "trial: 4, iter: 800, curr loss: 1.3875354528427124, avg loss: 1.3866046148538589\n",
      "trial: 4, iter: 1000, curr loss: 1.38518488407135, avg loss: 1.3864321166276932\n",
      "trial: 4, iter: 1200, curr loss: 1.3880492448806763, avg loss: 1.3864171761274338\n",
      "trial: 4, iter: 1400, curr loss: 1.3857334852218628, avg loss: 1.3863993632793425\n",
      "trial: 4, ldr: 0.0039031272754073143\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.386015772819519, avg loss: 1.3872514057159424\n",
      "trial: 5, iter: 400, curr loss: 1.3868485689163208, avg loss: 1.3867395001649856\n",
      "trial: 5, iter: 600, curr loss: 1.3873463869094849, avg loss: 1.3865284526348114\n",
      "trial: 5, iter: 800, curr loss: 1.3868204355239868, avg loss: 1.3866129755973815\n",
      "trial: 5, iter: 1000, curr loss: 1.3848260641098022, avg loss: 1.3865082663297654\n",
      "trial: 5, iter: 1200, curr loss: 1.3879916667938232, avg loss: 1.3863992202281952\n",
      "trial: 5, iter: 1400, curr loss: 1.3859378099441528, avg loss: 1.3863477897644043\n",
      "trial: 5, ldr: -0.0056723253801465034\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.005367085407488048\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3867876529693604, avg loss: 1.3871758663654328\n",
      "trial: 1, iter: 400, curr loss: 1.386897325515747, avg loss: 1.3864972710609436\n",
      "trial: 1, iter: 600, curr loss: 1.3862183094024658, avg loss: 1.386629537343979\n",
      "trial: 1, iter: 800, curr loss: 1.386279821395874, avg loss: 1.38641053378582\n",
      "trial: 1, iter: 1000, curr loss: 1.3876286745071411, avg loss: 1.3864144831895828\n",
      "trial: 1, iter: 1200, curr loss: 1.3860092163085938, avg loss: 1.386464131474495\n",
      "trial: 1, iter: 1400, curr loss: 1.3867919445037842, avg loss: 1.3864391952753068\n",
      "trial: 1, ldr: -0.009023627266287804\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3899425268173218, avg loss: 1.3873619693517685\n",
      "trial: 2, iter: 400, curr loss: 1.3849161863327026, avg loss: 1.3864166647195817\n",
      "trial: 2, iter: 600, curr loss: 1.3852430582046509, avg loss: 1.3866835862398148\n",
      "trial: 2, iter: 800, curr loss: 1.3897669315338135, avg loss: 1.3863284766674042\n",
      "trial: 2, iter: 1000, curr loss: 1.385701298713684, avg loss: 1.3865483605861664\n",
      "trial: 2, iter: 1200, curr loss: 1.3881065845489502, avg loss: 1.3865284132957458\n",
      "trial: 2, iter: 1400, curr loss: 1.386894941329956, avg loss: 1.3864461809396744\n",
      "trial: 2, ldr: 0.004042485263198614\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3850045204162598, avg loss: 1.3871192276477813\n",
      "trial: 3, iter: 400, curr loss: 1.3872133493423462, avg loss: 1.386735552549362\n",
      "trial: 3, iter: 600, curr loss: 1.3852550983428955, avg loss: 1.3865407729148864\n",
      "trial: 3, iter: 800, curr loss: 1.3876428604125977, avg loss: 1.3864413553476334\n",
      "trial: 3, iter: 1000, curr loss: 1.3866212368011475, avg loss: 1.3864707338809967\n",
      "trial: 3, iter: 1200, curr loss: 1.385270357131958, avg loss: 1.3864501720666886\n",
      "trial: 3, iter: 1400, curr loss: 1.3863706588745117, avg loss: 1.3865103048086167\n",
      "trial: 3, ldr: 0.0029213919769972563\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3860186338424683, avg loss: 1.3872971314191818\n",
      "trial: 4, iter: 400, curr loss: 1.3860474824905396, avg loss: 1.386672895550728\n",
      "trial: 4, iter: 600, curr loss: 1.3858140707015991, avg loss: 1.3865247052907943\n",
      "trial: 4, iter: 800, curr loss: 1.3889784812927246, avg loss: 1.386690701842308\n",
      "trial: 4, iter: 1000, curr loss: 1.3854987621307373, avg loss: 1.386545278429985\n",
      "trial: 4, iter: 1200, curr loss: 1.3856334686279297, avg loss: 1.3865132570266723\n",
      "trial: 4, iter: 1400, curr loss: 1.386737585067749, avg loss: 1.3864675641059876\n",
      "trial: 4, ldr: -0.00811211857944727\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.384105920791626, avg loss: 1.3874494433403015\n",
      "trial: 5, iter: 400, curr loss: 1.3846409320831299, avg loss: 1.3866657650470733\n",
      "trial: 5, iter: 600, curr loss: 1.389874815940857, avg loss: 1.3866389566659927\n",
      "trial: 5, iter: 800, curr loss: 1.3873801231384277, avg loss: 1.3865175580978393\n",
      "trial: 5, iter: 1000, curr loss: 1.3874900341033936, avg loss: 1.386571785211563\n",
      "trial: 5, iter: 1200, curr loss: 1.385907769203186, avg loss: 1.3864285087585448\n",
      "trial: 5, iter: 1400, curr loss: 1.385511875152588, avg loss: 1.3864813709259034\n",
      "trial: 5, ldr: -0.032732002437114716\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.008580774208530784\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3852638006210327, avg loss: 1.3875151896476745\n",
      "trial: 1, iter: 400, curr loss: 1.387005090713501, avg loss: 1.3866474401950837\n",
      "trial: 1, iter: 600, curr loss: 1.3875385522842407, avg loss: 1.3864692497253417\n",
      "trial: 1, iter: 800, curr loss: 1.38718581199646, avg loss: 1.3864728283882142\n",
      "trial: 1, iter: 1000, curr loss: 1.3868438005447388, avg loss: 1.3864602279663085\n",
      "trial: 1, iter: 1200, curr loss: 1.38725745677948, avg loss: 1.386355203986168\n",
      "trial: 1, iter: 1400, curr loss: 1.385618805885315, avg loss: 1.3863849228620528\n",
      "trial: 1, ldr: -0.030533649027347565\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3898332118988037, avg loss: 1.3872081631422042\n",
      "trial: 2, iter: 400, curr loss: 1.3874696493148804, avg loss: 1.386749963760376\n",
      "trial: 2, iter: 600, curr loss: 1.3862265348434448, avg loss: 1.386485538482666\n",
      "trial: 2, iter: 800, curr loss: 1.3878852128982544, avg loss: 1.386538941860199\n",
      "trial: 2, iter: 1000, curr loss: 1.3853399753570557, avg loss: 1.3864741426706315\n",
      "trial: 2, iter: 1200, curr loss: 1.3863601684570312, avg loss: 1.386439870595932\n",
      "trial: 2, iter: 1400, curr loss: 1.3869965076446533, avg loss: 1.3864768534898757\n",
      "trial: 2, ldr: -0.002639359561726451\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387365460395813, avg loss: 1.387421463727951\n",
      "trial: 3, iter: 400, curr loss: 1.3883821964263916, avg loss: 1.3867353415489196\n",
      "trial: 3, iter: 600, curr loss: 1.3858768939971924, avg loss: 1.38659055352211\n",
      "trial: 3, iter: 800, curr loss: 1.3861932754516602, avg loss: 1.3864787977933883\n",
      "trial: 3, iter: 1000, curr loss: 1.387122392654419, avg loss: 1.3864167040586473\n",
      "trial: 3, iter: 1200, curr loss: 1.3868929147720337, avg loss: 1.3864817583560944\n",
      "trial: 3, iter: 1400, curr loss: 1.3853542804718018, avg loss: 1.3864376336336135\n",
      "trial: 3, ldr: -0.003573065623641014\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3850229978561401, avg loss: 1.3873568445444107\n",
      "trial: 4, iter: 400, curr loss: 1.3862184286117554, avg loss: 1.3866630733013152\n",
      "trial: 4, iter: 600, curr loss: 1.3856568336486816, avg loss: 1.3864469105005264\n",
      "trial: 4, iter: 800, curr loss: 1.3860890865325928, avg loss: 1.3863848584890366\n",
      "trial: 4, iter: 1000, curr loss: 1.3858095407485962, avg loss: 1.386588965654373\n",
      "trial: 4, iter: 1200, curr loss: 1.3886473178863525, avg loss: 1.386420842409134\n",
      "trial: 4, iter: 1400, curr loss: 1.3873533010482788, avg loss: 1.38643243432045\n",
      "trial: 4, ldr: -0.0035894534084945917\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3870248794555664, avg loss: 1.3873551952838898\n",
      "trial: 5, iter: 400, curr loss: 1.389159917831421, avg loss: 1.386663549542427\n",
      "trial: 5, iter: 600, curr loss: 1.386207938194275, avg loss: 1.3866187012195588\n",
      "trial: 5, iter: 800, curr loss: 1.3855483531951904, avg loss: 1.3865420073270798\n",
      "trial: 5, iter: 1000, curr loss: 1.3873162269592285, avg loss: 1.3864733916521073\n",
      "trial: 5, iter: 1200, curr loss: 1.3843179941177368, avg loss: 1.3863357627391815\n",
      "trial: 5, iter: 1400, curr loss: 1.386751413345337, avg loss: 1.3865255016088485\n",
      "trial: 5, ldr: -0.011011334136128426\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.010269372351467609\n",
      "Experiment done with data path: ./data/catNon-lin-NI_17/data.5k.dz200.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_19/data.20k.dz200.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3821015357971191, avg loss: 1.3872975045442582\n",
      "trial: 1, iter: 400, curr loss: 1.3850687742233276, avg loss: 1.3866438961029053\n",
      "trial: 1, iter: 600, curr loss: 1.3853098154067993, avg loss: 1.3866151601076127\n",
      "trial: 1, iter: 800, curr loss: 1.3882051706314087, avg loss: 1.386600257754326\n",
      "trial: 1, iter: 1000, curr loss: 1.3880598545074463, avg loss: 1.3864129519462585\n",
      "trial: 1, iter: 1200, curr loss: 1.3857295513153076, avg loss: 1.38654680788517\n",
      "trial: 1, iter: 1400, curr loss: 1.3885722160339355, avg loss: 1.3864070028066635\n",
      "trial: 1, iter: 1600, curr loss: 1.386782169342041, avg loss: 1.386527223587036\n",
      "trial: 1, iter: 1800, curr loss: 1.3854702711105347, avg loss: 1.3863869524002075\n",
      "trial: 1, iter: 2000, curr loss: 1.3851869106292725, avg loss: 1.3864311271905898\n",
      "trial: 1, iter: 2200, curr loss: 1.3858877420425415, avg loss: 1.3864046549797058\n",
      "trial: 1, iter: 2400, curr loss: 1.3869541883468628, avg loss: 1.3864202219247819\n",
      "trial: 1, iter: 2600, curr loss: 1.3866767883300781, avg loss: 1.3863550943136216\n",
      "trial: 1, iter: 2800, curr loss: 1.3865611553192139, avg loss: 1.386334039568901\n",
      "trial: 1, iter: 3000, curr loss: 1.3862899541854858, avg loss: 1.3863566279411317\n",
      "trial: 1, iter: 3200, curr loss: 1.3874552249908447, avg loss: 1.386493330001831\n",
      "trial: 1, iter: 3400, curr loss: 1.3873997926712036, avg loss: 1.3863809114694596\n",
      "trial: 1, iter: 3600, curr loss: 1.3857355117797852, avg loss: 1.386392310857773\n",
      "trial: 1, iter: 3800, curr loss: 1.3860200643539429, avg loss: 1.3863382494449616\n",
      "trial: 1, iter: 4000, curr loss: 1.3863605260849, avg loss: 1.386338860988617\n",
      "trial: 1, iter: 4200, curr loss: 1.3855592012405396, avg loss: 1.3863334631919861\n",
      "trial: 1, iter: 4400, curr loss: 1.3862111568450928, avg loss: 1.386323014497757\n",
      "trial: 1, iter: 4600, curr loss: 1.386717438697815, avg loss: 1.3863317793607712\n",
      "trial: 1, iter: 4800, curr loss: 1.3873834609985352, avg loss: 1.386326796412468\n",
      "trial: 1, iter: 5000, curr loss: 1.3863441944122314, avg loss: 1.3863643723726273\n",
      "trial: 1, iter: 5200, curr loss: 1.3881107568740845, avg loss: 1.3863222467899323\n",
      "trial: 1, iter: 5400, curr loss: 1.386186122894287, avg loss: 1.3863679873943329\n",
      "trial: 1, iter: 5600, curr loss: 1.3856693506240845, avg loss: 1.3862881433963776\n",
      "trial: 1, iter: 5800, curr loss: 1.386527419090271, avg loss: 1.386376093029976\n",
      "trial: 1, iter: 6000, curr loss: 1.3858692646026611, avg loss: 1.386327576637268\n",
      "trial: 1, iter: 6200, curr loss: 1.386522650718689, avg loss: 1.3863371533155442\n",
      "trial: 1, ldr: 0.01155872829258442\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387787103652954, avg loss: 1.3875778579711915\n",
      "trial: 2, iter: 400, curr loss: 1.384848713874817, avg loss: 1.3866481983661652\n",
      "trial: 2, iter: 600, curr loss: 1.3873313665390015, avg loss: 1.3866321378946305\n",
      "trial: 2, iter: 800, curr loss: 1.3854560852050781, avg loss: 1.3864531791210175\n",
      "trial: 2, iter: 1000, curr loss: 1.3875995874404907, avg loss: 1.3863065093755722\n",
      "trial: 2, iter: 1200, curr loss: 1.3843154907226562, avg loss: 1.3865919983386994\n",
      "trial: 2, iter: 1400, curr loss: 1.3851722478866577, avg loss: 1.3864852315187455\n",
      "trial: 2, iter: 1600, curr loss: 1.386389136314392, avg loss: 1.3863975042104721\n",
      "trial: 2, iter: 1800, curr loss: 1.3868436813354492, avg loss: 1.3864027571678161\n",
      "trial: 2, iter: 2000, curr loss: 1.3861645460128784, avg loss: 1.386395987868309\n",
      "trial: 2, iter: 2200, curr loss: 1.3865712881088257, avg loss: 1.3863534504175186\n",
      "trial: 2, iter: 2400, curr loss: 1.38450026512146, avg loss: 1.3863913249969482\n",
      "trial: 2, iter: 2600, curr loss: 1.3876852989196777, avg loss: 1.386456651687622\n",
      "trial: 2, iter: 2800, curr loss: 1.3867264986038208, avg loss: 1.3863765794038772\n",
      "trial: 2, iter: 3000, curr loss: 1.3865950107574463, avg loss: 1.3863523715734483\n",
      "trial: 2, iter: 3200, curr loss: 1.3859652280807495, avg loss: 1.386360833644867\n",
      "trial: 2, iter: 3400, curr loss: 1.3865505456924438, avg loss: 1.386323517560959\n",
      "trial: 2, iter: 3600, curr loss: 1.385437250137329, avg loss: 1.3863436126708983\n",
      "trial: 2, iter: 3800, curr loss: 1.3861340284347534, avg loss: 1.3863570994138719\n",
      "trial: 2, iter: 4000, curr loss: 1.3860050439834595, avg loss: 1.3863125520944595\n",
      "trial: 2, iter: 4200, curr loss: 1.386452555656433, avg loss: 1.3863575249910354\n",
      "trial: 2, iter: 4400, curr loss: 1.3861674070358276, avg loss: 1.3863341814279557\n",
      "trial: 2, iter: 4600, curr loss: 1.3864039182662964, avg loss: 1.3863025504350661\n",
      "trial: 2, iter: 4800, curr loss: 1.386225938796997, avg loss: 1.386328477859497\n",
      "trial: 2, iter: 5000, curr loss: 1.3859056234359741, avg loss: 1.3863179332017899\n",
      "trial: 2, iter: 5200, curr loss: 1.3862007856369019, avg loss: 1.3863190984725953\n",
      "trial: 2, iter: 5400, curr loss: 1.3861606121063232, avg loss: 1.386322734951973\n",
      "trial: 2, iter: 5600, curr loss: 1.3863826990127563, avg loss: 1.3862934219837189\n",
      "trial: 2, iter: 5800, curr loss: 1.3867133855819702, avg loss: 1.386293226480484\n",
      "trial: 2, iter: 6000, curr loss: 1.3860136270523071, avg loss: 1.3863759976625443\n",
      "trial: 2, iter: 6200, curr loss: 1.3862124681472778, avg loss: 1.3863130986690522\n",
      "trial: 2, ldr: -0.008043495006859303\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3859446048736572, avg loss: 1.3870811593532562\n",
      "trial: 3, iter: 400, curr loss: 1.3830190896987915, avg loss: 1.386732321381569\n",
      "trial: 3, iter: 600, curr loss: 1.387252926826477, avg loss: 1.3865127927064895\n",
      "trial: 3, iter: 800, curr loss: 1.3870697021484375, avg loss: 1.3865846818685532\n",
      "trial: 3, iter: 1000, curr loss: 1.384125828742981, avg loss: 1.3864956486225128\n",
      "trial: 3, iter: 1200, curr loss: 1.3866392374038696, avg loss: 1.386492099761963\n",
      "trial: 3, iter: 1400, curr loss: 1.3856052160263062, avg loss: 1.3863508003950118\n",
      "trial: 3, iter: 1600, curr loss: 1.386513352394104, avg loss: 1.3863930773735047\n",
      "trial: 3, iter: 1800, curr loss: 1.3862406015396118, avg loss: 1.3863960659503938\n",
      "trial: 3, iter: 2000, curr loss: 1.386892318725586, avg loss: 1.3864313846826553\n",
      "trial: 3, iter: 2200, curr loss: 1.385069727897644, avg loss: 1.3864829635620117\n",
      "trial: 3, iter: 2400, curr loss: 1.3871486186981201, avg loss: 1.3864815247058868\n",
      "trial: 3, iter: 2600, curr loss: 1.3858586549758911, avg loss: 1.3863219976425172\n",
      "trial: 3, iter: 2800, curr loss: 1.3869738578796387, avg loss: 1.3864070224761962\n",
      "trial: 3, iter: 3000, curr loss: 1.3873541355133057, avg loss: 1.3863186252117157\n",
      "trial: 3, iter: 3200, curr loss: 1.3865677118301392, avg loss: 1.3863627725839616\n",
      "trial: 3, iter: 3400, curr loss: 1.3870160579681396, avg loss: 1.3863949805498124\n",
      "trial: 3, iter: 3600, curr loss: 1.3865281343460083, avg loss: 1.3864053064584732\n",
      "trial: 3, iter: 3800, curr loss: 1.3870580196380615, avg loss: 1.3863314789533616\n",
      "trial: 3, iter: 4000, curr loss: 1.3862272500991821, avg loss: 1.3863431817293168\n",
      "trial: 3, iter: 4200, curr loss: 1.3866915702819824, avg loss: 1.3863277101516724\n",
      "trial: 3, iter: 4400, curr loss: 1.386813998222351, avg loss: 1.386338882446289\n",
      "trial: 3, iter: 4600, curr loss: 1.3861134052276611, avg loss: 1.3863293904066085\n",
      "trial: 3, iter: 4800, curr loss: 1.386242389678955, avg loss: 1.386316592693329\n",
      "trial: 3, iter: 5000, curr loss: 1.3865383863449097, avg loss: 1.3862845885753632\n",
      "trial: 3, iter: 5200, curr loss: 1.3857272863388062, avg loss: 1.3863467061519623\n",
      "trial: 3, iter: 5400, curr loss: 1.3868730068206787, avg loss: 1.3863351649045945\n",
      "trial: 3, iter: 5600, curr loss: 1.3860163688659668, avg loss: 1.3863469368219377\n",
      "trial: 3, iter: 5800, curr loss: 1.386048674583435, avg loss: 1.3863143831491471\n",
      "trial: 3, iter: 6000, curr loss: 1.3867390155792236, avg loss: 1.3863219475746156\n",
      "trial: 3, iter: 6200, curr loss: 1.3861141204833984, avg loss: 1.3863464123010636\n",
      "trial: 3, ldr: -0.001171492855064571\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3879129886627197, avg loss: 1.3873423057794572\n",
      "trial: 4, iter: 400, curr loss: 1.3868199586868286, avg loss: 1.3868620437383652\n",
      "trial: 4, iter: 600, curr loss: 1.3874984979629517, avg loss: 1.3866304218769074\n",
      "trial: 4, iter: 800, curr loss: 1.3873637914657593, avg loss: 1.3865592169761658\n",
      "trial: 4, iter: 1000, curr loss: 1.3880932331085205, avg loss: 1.386513044834137\n",
      "trial: 4, iter: 1200, curr loss: 1.3862323760986328, avg loss: 1.3864904481172562\n",
      "trial: 4, iter: 1400, curr loss: 1.3870697021484375, avg loss: 1.3864216744899749\n",
      "trial: 4, iter: 1600, curr loss: 1.385095238685608, avg loss: 1.3863389945030213\n",
      "trial: 4, iter: 1800, curr loss: 1.3879635334014893, avg loss: 1.3863679033517837\n",
      "trial: 4, iter: 2000, curr loss: 1.3865694999694824, avg loss: 1.38647119641304\n",
      "trial: 4, iter: 2200, curr loss: 1.3854460716247559, avg loss: 1.3863545286655425\n",
      "trial: 4, iter: 2400, curr loss: 1.3864295482635498, avg loss: 1.3863552623987199\n",
      "trial: 4, iter: 2600, curr loss: 1.3854713439941406, avg loss: 1.386364042162895\n",
      "trial: 4, iter: 2800, curr loss: 1.385977864265442, avg loss: 1.3863935565948486\n",
      "trial: 4, iter: 3000, curr loss: 1.3859891891479492, avg loss: 1.386584113240242\n",
      "trial: 4, iter: 3200, curr loss: 1.3856019973754883, avg loss: 1.3864009577035903\n",
      "trial: 4, iter: 3400, curr loss: 1.3844501972198486, avg loss: 1.3862850290536881\n",
      "trial: 4, iter: 3600, curr loss: 1.3858619928359985, avg loss: 1.3865066856145858\n",
      "trial: 4, iter: 3800, curr loss: 1.3869439363479614, avg loss: 1.3863396787643432\n",
      "trial: 4, iter: 4000, curr loss: 1.3859299421310425, avg loss: 1.3863776689767837\n",
      "trial: 4, iter: 4200, curr loss: 1.3852680921554565, avg loss: 1.3863254088163375\n",
      "trial: 4, iter: 4400, curr loss: 1.3859773874282837, avg loss: 1.3863367640972137\n",
      "trial: 4, iter: 4600, curr loss: 1.3863904476165771, avg loss: 1.3863245898485184\n",
      "trial: 4, iter: 4800, curr loss: 1.3860417604446411, avg loss: 1.3863262301683426\n",
      "trial: 4, iter: 5000, curr loss: 1.3861051797866821, avg loss: 1.386339077949524\n",
      "trial: 4, iter: 5200, curr loss: 1.3874552249908447, avg loss: 1.3863272762298584\n",
      "trial: 4, iter: 5400, curr loss: 1.3861838579177856, avg loss: 1.3862874245643615\n",
      "trial: 4, iter: 5600, curr loss: 1.3858623504638672, avg loss: 1.38626042842865\n",
      "trial: 4, iter: 5800, curr loss: 1.3863681554794312, avg loss: 1.3863466167449952\n",
      "trial: 4, iter: 6000, curr loss: 1.386324405670166, avg loss: 1.3863327312469482\n",
      "trial: 4, iter: 6200, curr loss: 1.3862922191619873, avg loss: 1.3864056771993638\n",
      "trial: 4, ldr: 0.00034115739981643856\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3877027034759521, avg loss: 1.387180922627449\n",
      "trial: 5, iter: 400, curr loss: 1.38693106174469, avg loss: 1.386626135110855\n",
      "trial: 5, iter: 600, curr loss: 1.386502742767334, avg loss: 1.3865697836875917\n",
      "trial: 5, iter: 800, curr loss: 1.387510061264038, avg loss: 1.3864673817157744\n",
      "trial: 5, iter: 1000, curr loss: 1.3851920366287231, avg loss: 1.3865186941623688\n",
      "trial: 5, iter: 1200, curr loss: 1.3859955072402954, avg loss: 1.386465911269188\n",
      "trial: 5, iter: 1400, curr loss: 1.3861401081085205, avg loss: 1.3864853936433792\n",
      "trial: 5, iter: 1600, curr loss: 1.3865420818328857, avg loss: 1.386329367160797\n",
      "trial: 5, iter: 1800, curr loss: 1.3860583305358887, avg loss: 1.3864179682731628\n",
      "trial: 5, iter: 2000, curr loss: 1.3843169212341309, avg loss: 1.3863957023620606\n",
      "trial: 5, iter: 2200, curr loss: 1.3862416744232178, avg loss: 1.3864171528816223\n",
      "trial: 5, iter: 2400, curr loss: 1.3863873481750488, avg loss: 1.3864591115713119\n",
      "trial: 5, iter: 2600, curr loss: 1.3860394954681396, avg loss: 1.386393342614174\n",
      "trial: 5, iter: 2800, curr loss: 1.3865485191345215, avg loss: 1.3864232516288757\n",
      "trial: 5, iter: 3000, curr loss: 1.3852626085281372, avg loss: 1.3863572353124618\n",
      "trial: 5, iter: 3200, curr loss: 1.385787844657898, avg loss: 1.3864162921905518\n",
      "trial: 5, iter: 3400, curr loss: 1.386224627494812, avg loss: 1.386391350030899\n",
      "trial: 5, iter: 3600, curr loss: 1.3875247240066528, avg loss: 1.3863853114843367\n",
      "trial: 5, iter: 3800, curr loss: 1.3860899209976196, avg loss: 1.3863641041517258\n",
      "trial: 5, iter: 4000, curr loss: 1.3862617015838623, avg loss: 1.386356721520424\n",
      "trial: 5, iter: 4200, curr loss: 1.3865854740142822, avg loss: 1.3864357525110245\n",
      "trial: 5, iter: 4400, curr loss: 1.38605535030365, avg loss: 1.3863286256790162\n",
      "trial: 5, iter: 4600, curr loss: 1.3863556385040283, avg loss: 1.386338951587677\n",
      "trial: 5, iter: 4800, curr loss: 1.3858563899993896, avg loss: 1.386349681019783\n",
      "trial: 5, iter: 5000, curr loss: 1.3868852853775024, avg loss: 1.386315723657608\n",
      "trial: 5, iter: 5200, curr loss: 1.386598825454712, avg loss: 1.3863411808013917\n",
      "trial: 5, iter: 5400, curr loss: 1.3863486051559448, avg loss: 1.3862936449050904\n",
      "trial: 5, iter: 5600, curr loss: 1.386452317237854, avg loss: 1.3863389080762862\n",
      "trial: 5, iter: 5800, curr loss: 1.3861125707626343, avg loss: 1.3863098508119582\n",
      "trial: 5, iter: 6000, curr loss: 1.3857684135437012, avg loss: 1.3862957191467284\n",
      "trial: 5, iter: 6200, curr loss: 1.388155460357666, avg loss: 1.386255728006363\n",
      "trial: 5, ldr: 0.02534150891005993\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0056052813481073825\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38444185256958, avg loss: 1.3870276069641114\n",
      "trial: 1, iter: 400, curr loss: 1.3868142366409302, avg loss: 1.3866406953334809\n",
      "trial: 1, iter: 600, curr loss: 1.384539008140564, avg loss: 1.3866724473237992\n",
      "trial: 1, iter: 800, curr loss: 1.3866971731185913, avg loss: 1.386511258482933\n",
      "trial: 1, iter: 1000, curr loss: 1.3873400688171387, avg loss: 1.3865351420640946\n",
      "trial: 1, iter: 1200, curr loss: 1.3873844146728516, avg loss: 1.38641508102417\n",
      "trial: 1, iter: 1400, curr loss: 1.3862206935882568, avg loss: 1.3864883691072465\n",
      "trial: 1, iter: 1600, curr loss: 1.3873273134231567, avg loss: 1.386359738111496\n",
      "trial: 1, iter: 1800, curr loss: 1.3865723609924316, avg loss: 1.3864608466625215\n",
      "trial: 1, iter: 2000, curr loss: 1.3862773180007935, avg loss: 1.3863917297124864\n",
      "trial: 1, iter: 2200, curr loss: 1.3860198259353638, avg loss: 1.3863404899835587\n",
      "trial: 1, iter: 2400, curr loss: 1.3864209651947021, avg loss: 1.3863569921255112\n",
      "trial: 1, iter: 2600, curr loss: 1.38571035861969, avg loss: 1.3863590413331985\n",
      "trial: 1, iter: 2800, curr loss: 1.3885836601257324, avg loss: 1.3863405168056488\n",
      "trial: 1, iter: 3000, curr loss: 1.38601815700531, avg loss: 1.3863483363389968\n",
      "trial: 1, iter: 3200, curr loss: 1.3857059478759766, avg loss: 1.386426880955696\n",
      "trial: 1, iter: 3400, curr loss: 1.3857057094573975, avg loss: 1.3862814581394196\n",
      "trial: 1, iter: 3600, curr loss: 1.3864641189575195, avg loss: 1.3863675343990325\n",
      "trial: 1, iter: 3800, curr loss: 1.387077808380127, avg loss: 1.3863651937246322\n",
      "trial: 1, iter: 4000, curr loss: 1.3857566118240356, avg loss: 1.3863612258434295\n",
      "trial: 1, iter: 4200, curr loss: 1.385980248451233, avg loss: 1.3863890600204467\n",
      "trial: 1, iter: 4400, curr loss: 1.3860243558883667, avg loss: 1.3863213968276977\n",
      "trial: 1, iter: 4600, curr loss: 1.3869950771331787, avg loss: 1.3863462388515473\n",
      "trial: 1, iter: 4800, curr loss: 1.386232852935791, avg loss: 1.3863178825378417\n",
      "trial: 1, iter: 5000, curr loss: 1.386322259902954, avg loss: 1.3863190710544586\n",
      "trial: 1, iter: 5200, curr loss: 1.38631010055542, avg loss: 1.3863028931617736\n",
      "trial: 1, iter: 5400, curr loss: 1.3864498138427734, avg loss: 1.3863001400232315\n",
      "trial: 1, iter: 5600, curr loss: 1.3872672319412231, avg loss: 1.386328262090683\n",
      "trial: 1, iter: 5800, curr loss: 1.3895491361618042, avg loss: 1.386326664686203\n",
      "trial: 1, iter: 6000, curr loss: 1.387220025062561, avg loss: 1.3864336282014846\n",
      "trial: 1, iter: 6200, curr loss: 1.3865605592727661, avg loss: 1.3863105726242066\n",
      "trial: 1, ldr: -0.003759524552151561\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3876558542251587, avg loss: 1.3874000293016433\n",
      "trial: 2, iter: 400, curr loss: 1.3824195861816406, avg loss: 1.3867381823062896\n",
      "trial: 2, iter: 600, curr loss: 1.3867155313491821, avg loss: 1.3865985822677613\n",
      "trial: 2, iter: 800, curr loss: 1.3855011463165283, avg loss: 1.3865900325775147\n",
      "trial: 2, iter: 1000, curr loss: 1.3861578702926636, avg loss: 1.3864370238780976\n",
      "trial: 2, iter: 1200, curr loss: 1.38670814037323, avg loss: 1.3864210271835327\n",
      "trial: 2, iter: 1400, curr loss: 1.386452317237854, avg loss: 1.3863390654325485\n",
      "trial: 2, iter: 1600, curr loss: 1.387495994567871, avg loss: 1.3863445687294007\n",
      "trial: 2, iter: 1800, curr loss: 1.383693814277649, avg loss: 1.3864359670877457\n",
      "trial: 2, iter: 2000, curr loss: 1.3861544132232666, avg loss: 1.386426609158516\n",
      "trial: 2, iter: 2200, curr loss: 1.3855596780776978, avg loss: 1.3863097304105758\n",
      "trial: 2, iter: 2400, curr loss: 1.3865971565246582, avg loss: 1.3864138042926788\n",
      "trial: 2, iter: 2600, curr loss: 1.3867720365524292, avg loss: 1.3863472282886504\n",
      "trial: 2, iter: 2800, curr loss: 1.3864468336105347, avg loss: 1.3863775604963302\n",
      "trial: 2, iter: 3000, curr loss: 1.3863770961761475, avg loss: 1.3863665330410004\n",
      "trial: 2, iter: 3200, curr loss: 1.3862602710723877, avg loss: 1.38635488986969\n",
      "trial: 2, iter: 3400, curr loss: 1.3869982957839966, avg loss: 1.3863325029611588\n",
      "trial: 2, iter: 3600, curr loss: 1.3872787952423096, avg loss: 1.3864242243766784\n",
      "trial: 2, iter: 3800, curr loss: 1.3864988088607788, avg loss: 1.3863788282871246\n",
      "trial: 2, iter: 4000, curr loss: 1.386458158493042, avg loss: 1.3863998115062715\n",
      "trial: 2, iter: 4200, curr loss: 1.386204481124878, avg loss: 1.3863491982221603\n",
      "trial: 2, iter: 4400, curr loss: 1.3853707313537598, avg loss: 1.3863285660743714\n",
      "trial: 2, iter: 4600, curr loss: 1.3865054845809937, avg loss: 1.3864374643564223\n",
      "trial: 2, iter: 4800, curr loss: 1.3859007358551025, avg loss: 1.3863129848241806\n",
      "trial: 2, iter: 5000, curr loss: 1.3867117166519165, avg loss: 1.3863590717315675\n",
      "trial: 2, iter: 5200, curr loss: 1.3866809606552124, avg loss: 1.3863436961174012\n",
      "trial: 2, iter: 5400, curr loss: 1.3863455057144165, avg loss: 1.3863661414384842\n",
      "trial: 2, iter: 5600, curr loss: 1.3860265016555786, avg loss: 1.386297383904457\n",
      "trial: 2, iter: 5800, curr loss: 1.3860368728637695, avg loss: 1.3863017696142197\n",
      "trial: 2, iter: 6000, curr loss: 1.3865801095962524, avg loss: 1.386276832818985\n",
      "trial: 2, iter: 6200, curr loss: 1.3864505290985107, avg loss: 1.3863703900575637\n",
      "trial: 2, ldr: 0.007938980124890804\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3851548433303833, avg loss: 1.3875074017047881\n",
      "trial: 3, iter: 400, curr loss: 1.3870686292648315, avg loss: 1.3868219542503357\n",
      "trial: 3, iter: 600, curr loss: 1.3842003345489502, avg loss: 1.3865271174907685\n",
      "trial: 3, iter: 800, curr loss: 1.3879890441894531, avg loss: 1.386500554084778\n",
      "trial: 3, iter: 1000, curr loss: 1.386955976486206, avg loss: 1.3865960037708283\n",
      "trial: 3, iter: 1200, curr loss: 1.3876172304153442, avg loss: 1.3864761471748352\n",
      "trial: 3, iter: 1400, curr loss: 1.3853839635849, avg loss: 1.3864601093530655\n",
      "trial: 3, iter: 1600, curr loss: 1.385773777961731, avg loss: 1.3864059609174728\n",
      "trial: 3, iter: 1800, curr loss: 1.38650643825531, avg loss: 1.3863471913337708\n",
      "trial: 3, iter: 2000, curr loss: 1.3857086896896362, avg loss: 1.386354119181633\n",
      "trial: 3, iter: 2200, curr loss: 1.3870701789855957, avg loss: 1.3864088702201842\n",
      "trial: 3, iter: 2400, curr loss: 1.3864870071411133, avg loss: 1.3862961685657502\n",
      "trial: 3, iter: 2600, curr loss: 1.3869413137435913, avg loss: 1.3863658899068831\n",
      "trial: 3, iter: 2800, curr loss: 1.3868234157562256, avg loss: 1.3863183951377869\n",
      "trial: 3, iter: 3000, curr loss: 1.3866602182388306, avg loss: 1.3863102811574937\n",
      "trial: 3, iter: 3200, curr loss: 1.386106014251709, avg loss: 1.3863421565294265\n",
      "trial: 3, iter: 3400, curr loss: 1.3864407539367676, avg loss: 1.3862274158000947\n",
      "trial: 3, iter: 3600, curr loss: 1.3864119052886963, avg loss: 1.386391162276268\n",
      "trial: 3, iter: 3800, curr loss: 1.3861174583435059, avg loss: 1.3863486462831498\n",
      "trial: 3, iter: 4000, curr loss: 1.3861491680145264, avg loss: 1.3863348841667176\n",
      "trial: 3, iter: 4200, curr loss: 1.3861004114151, avg loss: 1.3863316529989242\n",
      "trial: 3, iter: 4400, curr loss: 1.386099100112915, avg loss: 1.3863663458824158\n",
      "trial: 3, iter: 4600, curr loss: 1.3860224485397339, avg loss: 1.3863281053304672\n",
      "trial: 3, iter: 4800, curr loss: 1.3859174251556396, avg loss: 1.3862904262542726\n",
      "trial: 3, iter: 5000, curr loss: 1.3864251375198364, avg loss: 1.3863475298881531\n",
      "trial: 3, iter: 5200, curr loss: 1.3869200944900513, avg loss: 1.3863238525390624\n",
      "trial: 3, iter: 5400, curr loss: 1.3864363431930542, avg loss: 1.3863193809986114\n",
      "trial: 3, iter: 5600, curr loss: 1.3862926959991455, avg loss: 1.3862931001186372\n",
      "trial: 3, iter: 5800, curr loss: 1.386415958404541, avg loss: 1.3863047832250595\n",
      "trial: 3, iter: 6000, curr loss: 1.3861867189407349, avg loss: 1.3862871152162553\n",
      "trial: 3, iter: 6200, curr loss: 1.3864902257919312, avg loss: 1.3862995833158493\n",
      "trial: 3, ldr: 0.0013670087791979313\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3834164142608643, avg loss: 1.3870713609457015\n",
      "trial: 4, iter: 400, curr loss: 1.387091040611267, avg loss: 1.386713011264801\n",
      "trial: 4, iter: 600, curr loss: 1.3887686729431152, avg loss: 1.3864297080039978\n",
      "trial: 4, iter: 800, curr loss: 1.3881568908691406, avg loss: 1.3864805489778518\n",
      "trial: 4, iter: 1000, curr loss: 1.385891079902649, avg loss: 1.386428307890892\n",
      "trial: 4, iter: 1200, curr loss: 1.3850535154342651, avg loss: 1.386414332985878\n",
      "trial: 4, iter: 1400, curr loss: 1.3853631019592285, avg loss: 1.3864767050743103\n",
      "trial: 4, iter: 1600, curr loss: 1.3861020803451538, avg loss: 1.3863650554418563\n",
      "trial: 4, iter: 1800, curr loss: 1.3853864669799805, avg loss: 1.3864316123723983\n",
      "trial: 4, iter: 2000, curr loss: 1.3860161304473877, avg loss: 1.386441149711609\n",
      "trial: 4, iter: 2200, curr loss: 1.3860007524490356, avg loss: 1.3863747602701186\n",
      "trial: 4, iter: 2400, curr loss: 1.3859392404556274, avg loss: 1.3863593351840973\n",
      "trial: 4, iter: 2600, curr loss: 1.385606288909912, avg loss: 1.3863886964321137\n",
      "trial: 4, iter: 2800, curr loss: 1.3865398168563843, avg loss: 1.3864200192689895\n",
      "trial: 4, iter: 3000, curr loss: 1.3858858346939087, avg loss: 1.3863587337732315\n",
      "trial: 4, iter: 3200, curr loss: 1.386486530303955, avg loss: 1.3864007741212845\n",
      "trial: 4, iter: 3400, curr loss: 1.3866047859191895, avg loss: 1.3864258104562759\n",
      "trial: 4, iter: 3600, curr loss: 1.3865243196487427, avg loss: 1.3863649970293046\n",
      "trial: 4, iter: 3800, curr loss: 1.3859413862228394, avg loss: 1.3863484609127044\n",
      "trial: 4, iter: 4000, curr loss: 1.3866268396377563, avg loss: 1.3863548177480698\n",
      "trial: 4, iter: 4200, curr loss: 1.38698410987854, avg loss: 1.386292878985405\n",
      "trial: 4, iter: 4400, curr loss: 1.386791706085205, avg loss: 1.3863653099536897\n",
      "trial: 4, iter: 4600, curr loss: 1.3862340450286865, avg loss: 1.3863239163160324\n",
      "trial: 4, iter: 4800, curr loss: 1.3856807947158813, avg loss: 1.3863234621286393\n",
      "trial: 4, iter: 5000, curr loss: 1.3866430521011353, avg loss: 1.3862956845760346\n",
      "trial: 4, iter: 5200, curr loss: 1.385718584060669, avg loss: 1.3862689214944839\n",
      "trial: 4, iter: 5400, curr loss: 1.3864368200302124, avg loss: 1.3863195472955703\n",
      "trial: 4, iter: 5600, curr loss: 1.3862847089767456, avg loss: 1.3863379395008086\n",
      "trial: 4, iter: 5800, curr loss: 1.386643886566162, avg loss: 1.3862882775068284\n",
      "trial: 4, iter: 6000, curr loss: 1.3861583471298218, avg loss: 1.3863055646419524\n",
      "trial: 4, iter: 6200, curr loss: 1.3867778778076172, avg loss: 1.3862953662872315\n",
      "trial: 4, ldr: -0.005314357113093138\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3867558240890503, avg loss: 1.3875342911481858\n",
      "trial: 5, iter: 400, curr loss: 1.3870316743850708, avg loss: 1.3866563057899475\n",
      "trial: 5, iter: 600, curr loss: 1.3858134746551514, avg loss: 1.3867399817705155\n",
      "trial: 5, iter: 800, curr loss: 1.387290120124817, avg loss: 1.3866655826568604\n",
      "trial: 5, iter: 1000, curr loss: 1.3849198818206787, avg loss: 1.3865265476703643\n",
      "trial: 5, iter: 1200, curr loss: 1.3873459100723267, avg loss: 1.38650459587574\n",
      "trial: 5, iter: 1400, curr loss: 1.3873389959335327, avg loss: 1.3864831179380417\n",
      "trial: 5, iter: 1600, curr loss: 1.3864158391952515, avg loss: 1.3864664232730866\n",
      "trial: 5, iter: 1800, curr loss: 1.386884331703186, avg loss: 1.3865542846918106\n",
      "trial: 5, iter: 2000, curr loss: 1.3875535726547241, avg loss: 1.3864903056621551\n",
      "trial: 5, iter: 2200, curr loss: 1.3866617679595947, avg loss: 1.3864931416511537\n",
      "trial: 5, iter: 2400, curr loss: 1.385413646697998, avg loss: 1.3864275634288787\n",
      "trial: 5, iter: 2600, curr loss: 1.3858988285064697, avg loss: 1.3862731903791428\n",
      "trial: 5, iter: 2800, curr loss: 1.3874629735946655, avg loss: 1.3864226651191711\n",
      "trial: 5, iter: 3000, curr loss: 1.3861548900604248, avg loss: 1.3863900965452194\n",
      "trial: 5, iter: 3200, curr loss: 1.38639235496521, avg loss: 1.3863432121276855\n",
      "trial: 5, iter: 3400, curr loss: 1.386118769645691, avg loss: 1.3863407397270202\n",
      "trial: 5, iter: 3600, curr loss: 1.3856858015060425, avg loss: 1.386312016248703\n",
      "trial: 5, iter: 3800, curr loss: 1.3862910270690918, avg loss: 1.3863345903158188\n",
      "trial: 5, iter: 4000, curr loss: 1.3862502574920654, avg loss: 1.3863220226764679\n",
      "trial: 5, iter: 4200, curr loss: 1.3866324424743652, avg loss: 1.3862957048416138\n",
      "trial: 5, iter: 4400, curr loss: 1.3862226009368896, avg loss: 1.3863259488344193\n",
      "trial: 5, iter: 4600, curr loss: 1.3864569664001465, avg loss: 1.3862938404083252\n",
      "trial: 5, iter: 4800, curr loss: 1.387123703956604, avg loss: 1.386341797709465\n",
      "trial: 5, iter: 5000, curr loss: 1.3862733840942383, avg loss: 1.38634790122509\n",
      "trial: 5, iter: 5200, curr loss: 1.3862239122390747, avg loss: 1.3863125669956207\n",
      "trial: 5, iter: 5400, curr loss: 1.3864870071411133, avg loss: 1.3862809491157533\n",
      "trial: 5, iter: 5600, curr loss: 1.386727213859558, avg loss: 1.3863149785995483\n",
      "trial: 5, iter: 5800, curr loss: 1.3867489099502563, avg loss: 1.3863149052858352\n",
      "trial: 5, iter: 6000, curr loss: 1.3864938020706177, avg loss: 1.3863293099403382\n",
      "trial: 5, iter: 6200, curr loss: 1.386388897895813, avg loss: 1.3863146287202834\n",
      "trial: 5, ldr: -0.0026322565972805023\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0004800298716872931\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3853297233581543, avg loss: 1.3871264296770096\n",
      "trial: 1, iter: 400, curr loss: 1.3900552988052368, avg loss: 1.3867583125829697\n",
      "trial: 1, iter: 600, curr loss: 1.3868743181228638, avg loss: 1.386637977361679\n",
      "trial: 1, iter: 800, curr loss: 1.3859927654266357, avg loss: 1.3865133887529373\n",
      "trial: 1, iter: 1000, curr loss: 1.3875946998596191, avg loss: 1.3865028190612794\n",
      "trial: 1, iter: 1200, curr loss: 1.384931206703186, avg loss: 1.3864093154668808\n",
      "trial: 1, iter: 1400, curr loss: 1.3870726823806763, avg loss: 1.3864620780944825\n",
      "trial: 1, iter: 1600, curr loss: 1.3861782550811768, avg loss: 1.3863546365499497\n",
      "trial: 1, iter: 1800, curr loss: 1.3856374025344849, avg loss: 1.3863979828357698\n",
      "trial: 1, iter: 2000, curr loss: 1.3864223957061768, avg loss: 1.3864288765192032\n",
      "trial: 1, iter: 2200, curr loss: 1.3867466449737549, avg loss: 1.3863648849725723\n",
      "trial: 1, iter: 2400, curr loss: 1.3873546123504639, avg loss: 1.386325752735138\n",
      "trial: 1, iter: 2600, curr loss: 1.3864859342575073, avg loss: 1.3862825798988343\n",
      "trial: 1, iter: 2800, curr loss: 1.3878943920135498, avg loss: 1.3863717353343963\n",
      "trial: 1, iter: 3000, curr loss: 1.3876965045928955, avg loss: 1.3863015186786651\n",
      "trial: 1, iter: 3200, curr loss: 1.386666178703308, avg loss: 1.3863553881645203\n",
      "trial: 1, iter: 3400, curr loss: 1.386768102645874, avg loss: 1.3864268881082535\n",
      "trial: 1, iter: 3600, curr loss: 1.3856080770492554, avg loss: 1.3863466370105744\n",
      "trial: 1, iter: 3800, curr loss: 1.385725736618042, avg loss: 1.3863360315561295\n",
      "trial: 1, iter: 4000, curr loss: 1.386333703994751, avg loss: 1.3863817709684372\n",
      "trial: 1, iter: 4200, curr loss: 1.385891318321228, avg loss: 1.386340501308441\n",
      "trial: 1, iter: 4400, curr loss: 1.3859336376190186, avg loss: 1.3863115960359573\n",
      "trial: 1, iter: 4600, curr loss: 1.3863645792007446, avg loss: 1.38633385181427\n",
      "trial: 1, iter: 4800, curr loss: 1.3869714736938477, avg loss: 1.386333263516426\n",
      "trial: 1, iter: 5000, curr loss: 1.3854817152023315, avg loss: 1.3863066112995148\n",
      "trial: 1, iter: 5200, curr loss: 1.3864659070968628, avg loss: 1.386414692401886\n",
      "trial: 1, iter: 5400, curr loss: 1.3864774703979492, avg loss: 1.3863436740636825\n",
      "trial: 1, iter: 5600, curr loss: 1.3862563371658325, avg loss: 1.3863118249177933\n",
      "trial: 1, iter: 5800, curr loss: 1.3870484828948975, avg loss: 1.3863058286905288\n",
      "trial: 1, iter: 6000, curr loss: 1.3868348598480225, avg loss: 1.3863310617208482\n",
      "trial: 1, iter: 6200, curr loss: 1.3865721225738525, avg loss: 1.3862769097089767\n",
      "trial: 1, ldr: 0.0051609124056994915\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3888294696807861, avg loss: 1.387458393573761\n",
      "trial: 2, iter: 400, curr loss: 1.3849564790725708, avg loss: 1.38662233710289\n",
      "trial: 2, iter: 600, curr loss: 1.3857043981552124, avg loss: 1.3865078353881837\n",
      "trial: 2, iter: 800, curr loss: 1.3852250576019287, avg loss: 1.3865876364707947\n",
      "trial: 2, iter: 1000, curr loss: 1.3863712549209595, avg loss: 1.3865801906585693\n",
      "trial: 2, iter: 1200, curr loss: 1.3862417936325073, avg loss: 1.3864081990718842\n",
      "trial: 2, iter: 1400, curr loss: 1.3863027095794678, avg loss: 1.3864926773309707\n",
      "trial: 2, iter: 1600, curr loss: 1.3845843076705933, avg loss: 1.3863540387153626\n",
      "trial: 2, iter: 1800, curr loss: 1.388409972190857, avg loss: 1.3865091323852539\n",
      "trial: 2, iter: 2000, curr loss: 1.3864388465881348, avg loss: 1.3864799922704696\n",
      "trial: 2, iter: 2200, curr loss: 1.385817050933838, avg loss: 1.3863940954208374\n",
      "trial: 2, iter: 2400, curr loss: 1.3849666118621826, avg loss: 1.3863977003097534\n",
      "trial: 2, iter: 2600, curr loss: 1.3860023021697998, avg loss: 1.3863821363449096\n",
      "trial: 2, iter: 2800, curr loss: 1.3854641914367676, avg loss: 1.3863703411817552\n",
      "trial: 2, iter: 3000, curr loss: 1.3866221904754639, avg loss: 1.3863265722990037\n",
      "trial: 2, iter: 3200, curr loss: 1.3863061666488647, avg loss: 1.3863973832130432\n",
      "trial: 2, iter: 3400, curr loss: 1.3868162631988525, avg loss: 1.3863834893703462\n",
      "trial: 2, iter: 3600, curr loss: 1.3864457607269287, avg loss: 1.3863751304149627\n",
      "trial: 2, iter: 3800, curr loss: 1.3857120275497437, avg loss: 1.3863726711273194\n",
      "trial: 2, iter: 4000, curr loss: 1.3868153095245361, avg loss: 1.3863444298505783\n",
      "trial: 2, iter: 4200, curr loss: 1.3883856534957886, avg loss: 1.3862933647632598\n",
      "trial: 2, iter: 4400, curr loss: 1.3872896432876587, avg loss: 1.3863126063346862\n",
      "trial: 2, iter: 4600, curr loss: 1.386487603187561, avg loss: 1.3863542819023131\n",
      "trial: 2, iter: 4800, curr loss: 1.3853055238723755, avg loss: 1.3862764942646026\n",
      "trial: 2, iter: 5000, curr loss: 1.3856347799301147, avg loss: 1.3863496214151383\n",
      "trial: 2, iter: 5200, curr loss: 1.3859678506851196, avg loss: 1.3862849819660186\n",
      "trial: 2, iter: 5400, curr loss: 1.386868953704834, avg loss: 1.3862817019224167\n",
      "trial: 2, iter: 5600, curr loss: 1.3863838911056519, avg loss: 1.3864006400108337\n",
      "trial: 2, iter: 5800, curr loss: 1.3868842124938965, avg loss: 1.3863454055786133\n",
      "trial: 2, iter: 6000, curr loss: 1.3864295482635498, avg loss: 1.3863193839788437\n",
      "trial: 2, iter: 6200, curr loss: 1.3865762948989868, avg loss: 1.3863275319337844\n",
      "trial: 2, ldr: 0.0023742064367979765\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3888362646102905, avg loss: 1.387747950553894\n",
      "trial: 3, iter: 400, curr loss: 1.3865376710891724, avg loss: 1.3867589712142945\n",
      "trial: 3, iter: 600, curr loss: 1.3835101127624512, avg loss: 1.3866602420806884\n",
      "trial: 3, iter: 800, curr loss: 1.3869491815567017, avg loss: 1.3865990030765534\n",
      "trial: 3, iter: 1000, curr loss: 1.3880258798599243, avg loss: 1.3864607805013656\n",
      "trial: 3, iter: 1200, curr loss: 1.386755108833313, avg loss: 1.3864534229040146\n",
      "trial: 3, iter: 1400, curr loss: 1.3834712505340576, avg loss: 1.3863890433311463\n",
      "trial: 3, iter: 1600, curr loss: 1.386305809020996, avg loss: 1.3864289551973343\n",
      "trial: 3, iter: 1800, curr loss: 1.3842941522598267, avg loss: 1.386431803703308\n",
      "trial: 3, iter: 2000, curr loss: 1.3855791091918945, avg loss: 1.3863965433835983\n",
      "trial: 3, iter: 2200, curr loss: 1.386096715927124, avg loss: 1.386373409628868\n",
      "trial: 3, iter: 2400, curr loss: 1.3856616020202637, avg loss: 1.386364358663559\n",
      "trial: 3, iter: 2600, curr loss: 1.3881765604019165, avg loss: 1.3864317148923875\n",
      "trial: 3, iter: 2800, curr loss: 1.3864418268203735, avg loss: 1.3863791608810425\n",
      "trial: 3, iter: 3000, curr loss: 1.3880034685134888, avg loss: 1.3864055556058883\n",
      "trial: 3, iter: 3200, curr loss: 1.3867309093475342, avg loss: 1.386372299194336\n",
      "trial: 3, iter: 3400, curr loss: 1.3873240947723389, avg loss: 1.386389409303665\n",
      "trial: 3, iter: 3600, curr loss: 1.3872120380401611, avg loss: 1.386350740790367\n",
      "trial: 3, iter: 3800, curr loss: 1.385751724243164, avg loss: 1.3864026725292207\n",
      "trial: 3, iter: 4000, curr loss: 1.3859524726867676, avg loss: 1.3863418895006179\n",
      "trial: 3, iter: 4200, curr loss: 1.386915683746338, avg loss: 1.3864013642072677\n",
      "trial: 3, iter: 4400, curr loss: 1.3866552114486694, avg loss: 1.3863067483901979\n",
      "trial: 3, iter: 4600, curr loss: 1.3861947059631348, avg loss: 1.386343210339546\n",
      "trial: 3, iter: 4800, curr loss: 1.386785864830017, avg loss: 1.3863125318288803\n",
      "trial: 3, iter: 5000, curr loss: 1.3865907192230225, avg loss: 1.3863565498590469\n",
      "trial: 3, iter: 5200, curr loss: 1.386399507522583, avg loss: 1.3863408851623535\n",
      "trial: 3, iter: 5400, curr loss: 1.385326862335205, avg loss: 1.3862671774625779\n",
      "trial: 3, iter: 5600, curr loss: 1.3868838548660278, avg loss: 1.3863636875152587\n",
      "trial: 3, iter: 5800, curr loss: 1.3860373497009277, avg loss: 1.3863250654935837\n",
      "trial: 3, iter: 6000, curr loss: 1.3869267702102661, avg loss: 1.3862909138202668\n",
      "trial: 3, iter: 6200, curr loss: 1.3871272802352905, avg loss: 1.3862534773349762\n",
      "trial: 3, ldr: -0.005077631678432226\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3889321088790894, avg loss: 1.387353503704071\n",
      "trial: 4, iter: 400, curr loss: 1.386691689491272, avg loss: 1.3866702538728715\n",
      "trial: 4, iter: 600, curr loss: 1.3900635242462158, avg loss: 1.3865852665901184\n",
      "trial: 4, iter: 800, curr loss: 1.3875905275344849, avg loss: 1.3865948367118834\n",
      "trial: 4, iter: 1000, curr loss: 1.3852295875549316, avg loss: 1.3864409416913985\n",
      "trial: 4, iter: 1200, curr loss: 1.3865920305252075, avg loss: 1.3863567966222763\n",
      "trial: 4, iter: 1400, curr loss: 1.3861970901489258, avg loss: 1.3864911341667174\n",
      "trial: 4, iter: 1600, curr loss: 1.3857675790786743, avg loss: 1.38633074760437\n",
      "trial: 4, iter: 1800, curr loss: 1.3853565454483032, avg loss: 1.3863091546297073\n",
      "trial: 4, iter: 2000, curr loss: 1.3870640993118286, avg loss: 1.3864432495832444\n",
      "trial: 4, iter: 2200, curr loss: 1.3861607313156128, avg loss: 1.3863830268383026\n",
      "trial: 4, iter: 2400, curr loss: 1.3868707418441772, avg loss: 1.3863377314805985\n",
      "trial: 4, iter: 2600, curr loss: 1.3876197338104248, avg loss: 1.3863833624124526\n",
      "trial: 4, iter: 2800, curr loss: 1.385858178138733, avg loss: 1.3863622677326202\n",
      "trial: 4, iter: 3000, curr loss: 1.387058138847351, avg loss: 1.3864014786481857\n",
      "trial: 4, iter: 3200, curr loss: 1.3858562707901, avg loss: 1.386370570063591\n",
      "trial: 4, iter: 3400, curr loss: 1.3861515522003174, avg loss: 1.3863121902942657\n",
      "trial: 4, iter: 3600, curr loss: 1.3864057064056396, avg loss: 1.3863489949703216\n",
      "trial: 4, iter: 3800, curr loss: 1.3862296342849731, avg loss: 1.3863314270973206\n",
      "trial: 4, iter: 4000, curr loss: 1.3862460851669312, avg loss: 1.3863630616664886\n",
      "trial: 4, iter: 4200, curr loss: 1.3860011100769043, avg loss: 1.3863494712114335\n",
      "trial: 4, iter: 4400, curr loss: 1.386400818824768, avg loss: 1.3863564890623092\n",
      "trial: 4, iter: 4600, curr loss: 1.3861196041107178, avg loss: 1.3863391721248626\n",
      "trial: 4, iter: 4800, curr loss: 1.3860942125320435, avg loss: 1.3863465487957\n",
      "trial: 4, iter: 5000, curr loss: 1.386168122291565, avg loss: 1.3863012707233429\n",
      "trial: 4, iter: 5200, curr loss: 1.3868427276611328, avg loss: 1.3862425810098649\n",
      "trial: 4, iter: 5400, curr loss: 1.385784387588501, avg loss: 1.3862700790166855\n",
      "trial: 4, iter: 5600, curr loss: 1.3858915567398071, avg loss: 1.386335582137108\n",
      "trial: 4, iter: 5800, curr loss: 1.3868823051452637, avg loss: 1.3863555461168289\n",
      "trial: 4, iter: 6000, curr loss: 1.3864004611968994, avg loss: 1.3863234877586366\n",
      "trial: 4, iter: 6200, curr loss: 1.386834979057312, avg loss: 1.3863056576251984\n",
      "trial: 4, ldr: 0.0002699962060432881\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3849717378616333, avg loss: 1.387221617102623\n",
      "trial: 5, iter: 400, curr loss: 1.3835960626602173, avg loss: 1.3866490358114243\n",
      "trial: 5, iter: 600, curr loss: 1.3882173299789429, avg loss: 1.386729258298874\n",
      "trial: 5, iter: 800, curr loss: 1.385433554649353, avg loss: 1.3864549499750138\n",
      "trial: 5, iter: 1000, curr loss: 1.3847683668136597, avg loss: 1.3865801912546158\n",
      "trial: 5, iter: 1200, curr loss: 1.38592529296875, avg loss: 1.386530573964119\n",
      "trial: 5, iter: 1400, curr loss: 1.3870190382003784, avg loss: 1.3864380842447281\n",
      "trial: 5, iter: 1600, curr loss: 1.3854820728302002, avg loss: 1.3864575976133346\n",
      "trial: 5, iter: 1800, curr loss: 1.3862521648406982, avg loss: 1.3864051407575608\n",
      "trial: 5, iter: 2000, curr loss: 1.385938048362732, avg loss: 1.3863553893566132\n",
      "trial: 5, iter: 2200, curr loss: 1.386271595954895, avg loss: 1.3864378249645233\n",
      "trial: 5, iter: 2400, curr loss: 1.3882311582565308, avg loss: 1.3862977313995362\n",
      "trial: 5, iter: 2600, curr loss: 1.3866662979125977, avg loss: 1.3864333593845368\n",
      "trial: 5, iter: 2800, curr loss: 1.3851017951965332, avg loss: 1.38637551009655\n",
      "trial: 5, iter: 3000, curr loss: 1.386713981628418, avg loss: 1.3863513201475144\n",
      "trial: 5, iter: 3200, curr loss: 1.3859256505966187, avg loss: 1.3863801503181457\n",
      "trial: 5, iter: 3400, curr loss: 1.3864790201187134, avg loss: 1.3863436317443847\n",
      "trial: 5, iter: 3600, curr loss: 1.3870623111724854, avg loss: 1.3863687855005264\n",
      "trial: 5, iter: 3800, curr loss: 1.386460304260254, avg loss: 1.3863795685768128\n",
      "trial: 5, iter: 4000, curr loss: 1.3863930702209473, avg loss: 1.3863537156581878\n",
      "trial: 5, iter: 4200, curr loss: 1.3863040208816528, avg loss: 1.386317129135132\n",
      "trial: 5, iter: 4400, curr loss: 1.3866236209869385, avg loss: 1.3863524663448334\n",
      "trial: 5, iter: 4600, curr loss: 1.3866753578186035, avg loss: 1.3863218247890472\n",
      "trial: 5, iter: 4800, curr loss: 1.385957956314087, avg loss: 1.386321081519127\n",
      "trial: 5, iter: 5000, curr loss: 1.3860529661178589, avg loss: 1.386305421590805\n",
      "trial: 5, iter: 5200, curr loss: 1.386444091796875, avg loss: 1.3863394182920457\n",
      "trial: 5, iter: 5400, curr loss: 1.3863029479980469, avg loss: 1.3863239604234696\n",
      "trial: 5, iter: 5600, curr loss: 1.386481761932373, avg loss: 1.386336013674736\n",
      "trial: 5, iter: 5800, curr loss: 1.3860996961593628, avg loss: 1.386303700208664\n",
      "trial: 5, iter: 6000, curr loss: 1.3858193159103394, avg loss: 1.3863093584775925\n",
      "trial: 5, iter: 6200, curr loss: 1.3858778476715088, avg loss: 1.3863277125358582\n",
      "trial: 5, ldr: -0.0017206491902470589\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0002013668359722942\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3859343528747559, avg loss: 1.38706130027771\n",
      "trial: 1, iter: 400, curr loss: 1.3848140239715576, avg loss: 1.3865835613012314\n",
      "trial: 1, iter: 600, curr loss: 1.386756181716919, avg loss: 1.386647292971611\n",
      "trial: 1, iter: 800, curr loss: 1.3868805170059204, avg loss: 1.386419767141342\n",
      "trial: 1, iter: 1000, curr loss: 1.3860511779785156, avg loss: 1.3863679212331772\n",
      "trial: 1, iter: 1200, curr loss: 1.3859444856643677, avg loss: 1.386403849720955\n",
      "trial: 1, iter: 1400, curr loss: 1.385489821434021, avg loss: 1.3863706678152083\n",
      "trial: 1, iter: 1600, curr loss: 1.3872065544128418, avg loss: 1.3864476031064987\n",
      "trial: 1, iter: 1800, curr loss: 1.3860596418380737, avg loss: 1.386347468495369\n",
      "trial: 1, iter: 2000, curr loss: 1.3862236738204956, avg loss: 1.3863772344589234\n",
      "trial: 1, iter: 2200, curr loss: 1.3861716985702515, avg loss: 1.3863422852754592\n",
      "trial: 1, iter: 2400, curr loss: 1.3855606317520142, avg loss: 1.3862716180086136\n",
      "trial: 1, iter: 2600, curr loss: 1.3870065212249756, avg loss: 1.3864581733942032\n",
      "trial: 1, iter: 2800, curr loss: 1.3871991634368896, avg loss: 1.3863238221406937\n",
      "trial: 1, iter: 3000, curr loss: 1.3874949216842651, avg loss: 1.3863631498813629\n",
      "trial: 1, iter: 3200, curr loss: 1.3865469694137573, avg loss: 1.3863565999269485\n",
      "trial: 1, iter: 3400, curr loss: 1.386527180671692, avg loss: 1.3863701593875886\n",
      "trial: 1, iter: 3600, curr loss: 1.3860622644424438, avg loss: 1.3863339638710022\n",
      "trial: 1, iter: 3800, curr loss: 1.3851145505905151, avg loss: 1.3863753855228425\n",
      "trial: 1, iter: 4000, curr loss: 1.386682391166687, avg loss: 1.3863569682836532\n",
      "trial: 1, iter: 4200, curr loss: 1.3867926597595215, avg loss: 1.3863646382093429\n",
      "trial: 1, iter: 4400, curr loss: 1.3861286640167236, avg loss: 1.3863178086280823\n",
      "trial: 1, iter: 4600, curr loss: 1.3869128227233887, avg loss: 1.386352898478508\n",
      "trial: 1, iter: 4800, curr loss: 1.3864527940750122, avg loss: 1.3864279633760452\n",
      "trial: 1, iter: 5000, curr loss: 1.3857873678207397, avg loss: 1.386426603794098\n",
      "trial: 1, iter: 5200, curr loss: 1.385927438735962, avg loss: 1.3863672149181365\n",
      "trial: 1, iter: 5400, curr loss: 1.3868061304092407, avg loss: 1.3863577216863632\n",
      "trial: 1, iter: 5600, curr loss: 1.3865797519683838, avg loss: 1.386332728266716\n",
      "trial: 1, iter: 5800, curr loss: 1.3861825466156006, avg loss: 1.3863264954090118\n",
      "trial: 1, iter: 6000, curr loss: 1.3867650032043457, avg loss: 1.3863109600543977\n",
      "trial: 1, iter: 6200, curr loss: 1.3860949277877808, avg loss: 1.3862791138887405\n",
      "trial: 1, ldr: -0.002847318071871996\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3876982927322388, avg loss: 1.3872275453805925\n",
      "trial: 2, iter: 400, curr loss: 1.3891493082046509, avg loss: 1.386760449409485\n",
      "trial: 2, iter: 600, curr loss: 1.386143684387207, avg loss: 1.3865120089054108\n",
      "trial: 2, iter: 800, curr loss: 1.385576844215393, avg loss: 1.3865829396247864\n",
      "trial: 2, iter: 1000, curr loss: 1.3875842094421387, avg loss: 1.3863669013977051\n",
      "trial: 2, iter: 1200, curr loss: 1.3868893384933472, avg loss: 1.3864234632253647\n",
      "trial: 2, iter: 1400, curr loss: 1.3851653337478638, avg loss: 1.3863928949832915\n",
      "trial: 2, iter: 1600, curr loss: 1.3852620124816895, avg loss: 1.3864129424095153\n",
      "trial: 2, iter: 1800, curr loss: 1.386352777481079, avg loss: 1.3863766437768936\n",
      "trial: 2, iter: 2000, curr loss: 1.3860453367233276, avg loss: 1.3864491599798203\n",
      "trial: 2, iter: 2200, curr loss: 1.3856924772262573, avg loss: 1.3864613825082779\n",
      "trial: 2, iter: 2400, curr loss: 1.3849372863769531, avg loss: 1.3864584612846373\n",
      "trial: 2, iter: 2600, curr loss: 1.3863794803619385, avg loss: 1.3864590907096863\n",
      "trial: 2, iter: 2800, curr loss: 1.3862546682357788, avg loss: 1.3863790786266328\n",
      "trial: 2, iter: 3000, curr loss: 1.386314868927002, avg loss: 1.3863916623592376\n",
      "trial: 2, iter: 3200, curr loss: 1.3876163959503174, avg loss: 1.3862878942489625\n",
      "trial: 2, iter: 3400, curr loss: 1.3860055208206177, avg loss: 1.386400330066681\n",
      "trial: 2, iter: 3600, curr loss: 1.3862237930297852, avg loss: 1.3863404148817062\n",
      "trial: 2, iter: 3800, curr loss: 1.3861554861068726, avg loss: 1.3863688051700591\n",
      "trial: 2, iter: 4000, curr loss: 1.3862236738204956, avg loss: 1.3862904918193817\n",
      "trial: 2, iter: 4200, curr loss: 1.386818289756775, avg loss: 1.3863725990056992\n",
      "trial: 2, iter: 4400, curr loss: 1.386279821395874, avg loss: 1.3863380551338196\n",
      "trial: 2, iter: 4600, curr loss: 1.3865423202514648, avg loss: 1.386297622323036\n",
      "trial: 2, iter: 4800, curr loss: 1.3868653774261475, avg loss: 1.3863386237621307\n",
      "trial: 2, iter: 5000, curr loss: 1.3864985704421997, avg loss: 1.386342794895172\n",
      "trial: 2, iter: 5200, curr loss: 1.3863070011138916, avg loss: 1.3862865257263184\n",
      "trial: 2, iter: 5400, curr loss: 1.3854107856750488, avg loss: 1.3863275063037872\n",
      "trial: 2, iter: 5600, curr loss: 1.3871376514434814, avg loss: 1.3863719069957734\n",
      "trial: 2, iter: 5800, curr loss: 1.3863112926483154, avg loss: 1.3863601619005204\n",
      "trial: 2, iter: 6000, curr loss: 1.386841893196106, avg loss: 1.3863229691982268\n",
      "trial: 2, iter: 6200, curr loss: 1.3864585161209106, avg loss: 1.3863115179538728\n",
      "trial: 2, ldr: 0.013732124119997025\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873645067214966, avg loss: 1.3872744405269624\n",
      "trial: 3, iter: 400, curr loss: 1.3851007223129272, avg loss: 1.386689835190773\n",
      "trial: 3, iter: 600, curr loss: 1.3870362043380737, avg loss: 1.3866586732864379\n",
      "trial: 3, iter: 800, curr loss: 1.386897087097168, avg loss: 1.386586702466011\n",
      "trial: 3, iter: 1000, curr loss: 1.3867218494415283, avg loss: 1.386509571671486\n",
      "trial: 3, iter: 1200, curr loss: 1.3843692541122437, avg loss: 1.386570183634758\n",
      "trial: 3, iter: 1400, curr loss: 1.386176347732544, avg loss: 1.3864462232589723\n",
      "trial: 3, iter: 1600, curr loss: 1.3872734308242798, avg loss: 1.3864406764507293\n",
      "trial: 3, iter: 1800, curr loss: 1.3874253034591675, avg loss: 1.3863412994146347\n",
      "trial: 3, iter: 2000, curr loss: 1.3862230777740479, avg loss: 1.3864160370826721\n",
      "trial: 3, iter: 2200, curr loss: 1.3856722116470337, avg loss: 1.3864062464237212\n",
      "trial: 3, iter: 2400, curr loss: 1.3858020305633545, avg loss: 1.3864519077539443\n",
      "trial: 3, iter: 2600, curr loss: 1.385764241218567, avg loss: 1.386374751329422\n",
      "trial: 3, iter: 2800, curr loss: 1.3874956369400024, avg loss: 1.3863754445314407\n",
      "trial: 3, iter: 3000, curr loss: 1.386117696762085, avg loss: 1.386418007016182\n",
      "trial: 3, iter: 3200, curr loss: 1.3857439756393433, avg loss: 1.3863955003023147\n",
      "trial: 3, iter: 3400, curr loss: 1.3863635063171387, avg loss: 1.3863680797815323\n",
      "trial: 3, iter: 3600, curr loss: 1.3862156867980957, avg loss: 1.3863990551233292\n",
      "trial: 3, iter: 3800, curr loss: 1.38616943359375, avg loss: 1.3863296401500702\n",
      "trial: 3, iter: 4000, curr loss: 1.3863476514816284, avg loss: 1.3863957846164703\n",
      "trial: 3, iter: 4200, curr loss: 1.3863003253936768, avg loss: 1.386300237774849\n",
      "trial: 3, iter: 4400, curr loss: 1.3859410285949707, avg loss: 1.3863013982772827\n",
      "trial: 3, iter: 4600, curr loss: 1.3865292072296143, avg loss: 1.3863184183835984\n",
      "trial: 3, iter: 4800, curr loss: 1.3859314918518066, avg loss: 1.3863104856014252\n",
      "trial: 3, iter: 5000, curr loss: 1.3866370916366577, avg loss: 1.3863303881883622\n",
      "trial: 3, iter: 5200, curr loss: 1.38660728931427, avg loss: 1.386326749920845\n",
      "trial: 3, iter: 5400, curr loss: 1.3863945007324219, avg loss: 1.3863085806369781\n",
      "trial: 3, iter: 5600, curr loss: 1.3859549760818481, avg loss: 1.3863027358055116\n",
      "trial: 3, iter: 5800, curr loss: 1.3862402439117432, avg loss: 1.386312934756279\n",
      "trial: 3, iter: 6000, curr loss: 1.3862916231155396, avg loss: 1.3863033616542817\n",
      "trial: 3, iter: 6200, curr loss: 1.3864850997924805, avg loss: 1.3863034272193908\n",
      "trial: 3, ldr: 0.0017339024925604463\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.385771632194519, avg loss: 1.3873261922597886\n",
      "trial: 4, iter: 400, curr loss: 1.3867658376693726, avg loss: 1.3866314816474914\n",
      "trial: 4, iter: 600, curr loss: 1.3867106437683105, avg loss: 1.3867152947187424\n",
      "trial: 4, iter: 800, curr loss: 1.3876969814300537, avg loss: 1.3864822870492934\n",
      "trial: 4, iter: 1000, curr loss: 1.385099172592163, avg loss: 1.3863906806707382\n",
      "trial: 4, iter: 1200, curr loss: 1.3865234851837158, avg loss: 1.386461929678917\n",
      "trial: 4, iter: 1400, curr loss: 1.3865472078323364, avg loss: 1.3864767456054687\n",
      "trial: 4, iter: 1600, curr loss: 1.3870923519134521, avg loss: 1.3863232302665711\n",
      "trial: 4, iter: 1800, curr loss: 1.385196566581726, avg loss: 1.3863550174236297\n",
      "trial: 4, iter: 2000, curr loss: 1.3870747089385986, avg loss: 1.3863393813371658\n",
      "trial: 4, iter: 2200, curr loss: 1.3864631652832031, avg loss: 1.3864044815301895\n",
      "trial: 4, iter: 2400, curr loss: 1.384509801864624, avg loss: 1.3862882912158967\n",
      "trial: 4, iter: 2600, curr loss: 1.3859684467315674, avg loss: 1.386351627111435\n",
      "trial: 4, iter: 2800, curr loss: 1.386401891708374, avg loss: 1.386449174284935\n",
      "trial: 4, iter: 3000, curr loss: 1.3854620456695557, avg loss: 1.3863607758283616\n",
      "trial: 4, iter: 3200, curr loss: 1.386688470840454, avg loss: 1.3863834071159362\n",
      "trial: 4, iter: 3400, curr loss: 1.3866342306137085, avg loss: 1.3863558727502823\n",
      "trial: 4, iter: 3600, curr loss: 1.3855403661727905, avg loss: 1.3863411432504653\n",
      "trial: 4, iter: 3800, curr loss: 1.3861199617385864, avg loss: 1.3863637870550156\n",
      "trial: 4, iter: 4000, curr loss: 1.3863269090652466, avg loss: 1.3863263815641402\n",
      "trial: 4, iter: 4200, curr loss: 1.387418508529663, avg loss: 1.3863120299577714\n",
      "trial: 4, iter: 4400, curr loss: 1.3867183923721313, avg loss: 1.3863572615385056\n",
      "trial: 4, iter: 4600, curr loss: 1.3861091136932373, avg loss: 1.3863399040699005\n",
      "trial: 4, iter: 4800, curr loss: 1.386343240737915, avg loss: 1.3863030803203582\n",
      "trial: 4, iter: 5000, curr loss: 1.385416865348816, avg loss: 1.3863084882497787\n",
      "trial: 4, iter: 5200, curr loss: 1.3869575262069702, avg loss: 1.3862769240140915\n",
      "trial: 4, iter: 5400, curr loss: 1.386590838432312, avg loss: 1.3863677352666854\n",
      "trial: 4, iter: 5600, curr loss: 1.3859902620315552, avg loss: 1.3863781785964966\n",
      "trial: 4, iter: 5800, curr loss: 1.3862605094909668, avg loss: 1.3863057255744935\n",
      "trial: 4, iter: 6000, curr loss: 1.3865889310836792, avg loss: 1.3863097715377808\n",
      "trial: 4, iter: 6200, curr loss: 1.3867377042770386, avg loss: 1.3864042639732361\n",
      "trial: 4, ldr: -0.0015845984453335404\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3871835470199585, avg loss: 1.387261769771576\n",
      "trial: 5, iter: 400, curr loss: 1.3859509229660034, avg loss: 1.386524465084076\n",
      "trial: 5, iter: 600, curr loss: 1.3857783079147339, avg loss: 1.3865098118782044\n",
      "trial: 5, iter: 800, curr loss: 1.3866912126541138, avg loss: 1.3864639735221862\n",
      "trial: 5, iter: 1000, curr loss: 1.386255145072937, avg loss: 1.3864098489284515\n",
      "trial: 5, iter: 1200, curr loss: 1.3869374990463257, avg loss: 1.3864380633831024\n",
      "trial: 5, iter: 1400, curr loss: 1.3870153427124023, avg loss: 1.3864805912971496\n",
      "trial: 5, iter: 1600, curr loss: 1.3859381675720215, avg loss: 1.3864669322967529\n",
      "trial: 5, iter: 1800, curr loss: 1.3862489461898804, avg loss: 1.3864394223690033\n",
      "trial: 5, iter: 2000, curr loss: 1.3867847919464111, avg loss: 1.386402269601822\n",
      "trial: 5, iter: 2200, curr loss: 1.3866902589797974, avg loss: 1.3864260774850845\n",
      "trial: 5, iter: 2400, curr loss: 1.3857229948043823, avg loss: 1.38634319961071\n",
      "trial: 5, iter: 2600, curr loss: 1.385392665863037, avg loss: 1.386363297700882\n",
      "trial: 5, iter: 2800, curr loss: 1.3866344690322876, avg loss: 1.386372182369232\n",
      "trial: 5, iter: 3000, curr loss: 1.38566255569458, avg loss: 1.3863346272706984\n",
      "trial: 5, iter: 3200, curr loss: 1.3872770071029663, avg loss: 1.3863233458995818\n",
      "trial: 5, iter: 3400, curr loss: 1.3862098455429077, avg loss: 1.386351382136345\n",
      "trial: 5, iter: 3600, curr loss: 1.3857605457305908, avg loss: 1.3862717264890672\n",
      "trial: 5, iter: 3800, curr loss: 1.3864561319351196, avg loss: 1.3863479667901992\n",
      "trial: 5, iter: 4000, curr loss: 1.3864843845367432, avg loss: 1.3863050776720047\n",
      "trial: 5, iter: 4200, curr loss: 1.3860245943069458, avg loss: 1.3863341420888902\n",
      "trial: 5, iter: 4400, curr loss: 1.3863276243209839, avg loss: 1.3863108992576598\n",
      "trial: 5, iter: 4600, curr loss: 1.3863866329193115, avg loss: 1.3863155514001846\n",
      "trial: 5, iter: 4800, curr loss: 1.3861420154571533, avg loss: 1.38630342066288\n",
      "trial: 5, iter: 5000, curr loss: 1.3861585855484009, avg loss: 1.3863433426618577\n",
      "trial: 5, iter: 5200, curr loss: 1.3862899541854858, avg loss: 1.3862989407777786\n",
      "trial: 5, iter: 5400, curr loss: 1.3863775730133057, avg loss: 1.386302016377449\n",
      "trial: 5, iter: 5600, curr loss: 1.3866199254989624, avg loss: 1.3863178443908692\n",
      "trial: 5, iter: 5800, curr loss: 1.3866199254989624, avg loss: 1.3863046634197236\n",
      "trial: 5, iter: 6000, curr loss: 1.3862966299057007, avg loss: 1.3862981063127517\n",
      "trial: 5, iter: 6200, curr loss: 1.3862167596817017, avg loss: 1.386307727098465\n",
      "trial: 5, ldr: -0.0031508731190115213\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0015766473952680826\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3878967761993408, avg loss: 1.3873333042860032\n",
      "trial: 1, iter: 400, curr loss: 1.3869067430496216, avg loss: 1.3866554474830628\n",
      "trial: 1, iter: 600, curr loss: 1.3870564699172974, avg loss: 1.386979369521141\n",
      "trial: 1, iter: 800, curr loss: 1.3865467309951782, avg loss: 1.3864873087406158\n",
      "trial: 1, iter: 1000, curr loss: 1.3867584466934204, avg loss: 1.3865314084291458\n",
      "trial: 1, iter: 1200, curr loss: 1.3861879110336304, avg loss: 1.3864087533950806\n",
      "trial: 1, iter: 1400, curr loss: 1.3852291107177734, avg loss: 1.386427121758461\n",
      "trial: 1, iter: 1600, curr loss: 1.3863070011138916, avg loss: 1.3864624339342118\n",
      "trial: 1, iter: 1800, curr loss: 1.385711669921875, avg loss: 1.386358426809311\n",
      "trial: 1, iter: 2000, curr loss: 1.3864672183990479, avg loss: 1.3863555628061295\n",
      "trial: 1, iter: 2200, curr loss: 1.3861920833587646, avg loss: 1.3862894654273987\n",
      "trial: 1, iter: 2400, curr loss: 1.386288046836853, avg loss: 1.3864158046245576\n",
      "trial: 1, iter: 2600, curr loss: 1.3865938186645508, avg loss: 1.3863783818483353\n",
      "trial: 1, iter: 2800, curr loss: 1.386439561843872, avg loss: 1.3863531178236008\n",
      "trial: 1, iter: 3000, curr loss: 1.385357141494751, avg loss: 1.3863858157396316\n",
      "trial: 1, iter: 3200, curr loss: 1.3867013454437256, avg loss: 1.386380853652954\n",
      "trial: 1, iter: 3400, curr loss: 1.3866325616836548, avg loss: 1.386437799334526\n",
      "trial: 1, iter: 3600, curr loss: 1.385963797569275, avg loss: 1.3863679027557374\n",
      "trial: 1, iter: 3800, curr loss: 1.3864527940750122, avg loss: 1.386340959072113\n",
      "trial: 1, iter: 4000, curr loss: 1.3870642185211182, avg loss: 1.3863328284025191\n",
      "trial: 1, iter: 4200, curr loss: 1.3885736465454102, avg loss: 1.3863026869297028\n",
      "trial: 1, iter: 4400, curr loss: 1.3877280950546265, avg loss: 1.3863419336080551\n",
      "trial: 1, iter: 4600, curr loss: 1.3859612941741943, avg loss: 1.3863908368349076\n",
      "trial: 1, iter: 4800, curr loss: 1.3864136934280396, avg loss: 1.3863385730981828\n",
      "trial: 1, iter: 5000, curr loss: 1.3858896493911743, avg loss: 1.3862599372863769\n",
      "trial: 1, iter: 5200, curr loss: 1.3863379955291748, avg loss: 1.3863694030046463\n",
      "trial: 1, iter: 5400, curr loss: 1.3862601518630981, avg loss: 1.3863290393352508\n",
      "trial: 1, iter: 5600, curr loss: 1.38567054271698, avg loss: 1.386304976940155\n",
      "trial: 1, iter: 5800, curr loss: 1.386548638343811, avg loss: 1.3863044881820679\n",
      "trial: 1, iter: 6000, curr loss: 1.3862332105636597, avg loss: 1.3863439285755157\n",
      "trial: 1, iter: 6200, curr loss: 1.3864519596099854, avg loss: 1.3863457977771758\n",
      "trial: 1, ldr: -0.002790455473586917\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3885167837142944, avg loss: 1.3873584848642349\n",
      "trial: 2, iter: 400, curr loss: 1.3837661743164062, avg loss: 1.3866625589132309\n",
      "trial: 2, iter: 600, curr loss: 1.3861445188522339, avg loss: 1.3865587824583054\n",
      "trial: 2, iter: 800, curr loss: 1.3848917484283447, avg loss: 1.3865524756908416\n",
      "trial: 2, iter: 1000, curr loss: 1.387276291847229, avg loss: 1.3863207536935807\n",
      "trial: 2, iter: 1200, curr loss: 1.38508939743042, avg loss: 1.386432136297226\n",
      "trial: 2, iter: 1400, curr loss: 1.3863470554351807, avg loss: 1.3865186166763306\n",
      "trial: 2, iter: 1600, curr loss: 1.3851388692855835, avg loss: 1.3863795071840286\n",
      "trial: 2, iter: 1800, curr loss: 1.3891680240631104, avg loss: 1.3864849609136582\n",
      "trial: 2, iter: 2000, curr loss: 1.3843663930892944, avg loss: 1.386491140127182\n",
      "trial: 2, iter: 2200, curr loss: 1.3844658136367798, avg loss: 1.3864881217479705\n",
      "trial: 2, iter: 2400, curr loss: 1.385741949081421, avg loss: 1.3864246368408204\n",
      "trial: 2, iter: 2600, curr loss: 1.3869835138320923, avg loss: 1.3864217537641526\n",
      "trial: 2, iter: 2800, curr loss: 1.3862251043319702, avg loss: 1.386409468650818\n",
      "trial: 2, iter: 3000, curr loss: 1.3872451782226562, avg loss: 1.3863093250989913\n",
      "trial: 2, iter: 3200, curr loss: 1.386318564414978, avg loss: 1.3863720464706422\n",
      "trial: 2, iter: 3400, curr loss: 1.3867486715316772, avg loss: 1.3863381510972976\n",
      "trial: 2, iter: 3600, curr loss: 1.3860089778900146, avg loss: 1.3863614785671234\n",
      "trial: 2, iter: 3800, curr loss: 1.3875668048858643, avg loss: 1.3863024765253067\n",
      "trial: 2, iter: 4000, curr loss: 1.385764479637146, avg loss: 1.3862906563282014\n",
      "trial: 2, iter: 4200, curr loss: 1.3843852281570435, avg loss: 1.3862964111566543\n",
      "trial: 2, iter: 4400, curr loss: 1.386579155921936, avg loss: 1.3863984215259553\n",
      "trial: 2, iter: 4600, curr loss: 1.3865362405776978, avg loss: 1.3863265919685364\n",
      "trial: 2, iter: 4800, curr loss: 1.3852078914642334, avg loss: 1.3863090240955354\n",
      "trial: 2, iter: 5000, curr loss: 1.3857102394104004, avg loss: 1.3863728582859038\n",
      "trial: 2, iter: 5200, curr loss: 1.3854715824127197, avg loss: 1.3863686114549636\n",
      "trial: 2, iter: 5400, curr loss: 1.386096477508545, avg loss: 1.3863853067159653\n",
      "trial: 2, iter: 5600, curr loss: 1.385886788368225, avg loss: 1.3863551354408263\n",
      "trial: 2, iter: 5800, curr loss: 1.3862073421478271, avg loss: 1.3863434904813767\n",
      "trial: 2, iter: 6000, curr loss: 1.3861819505691528, avg loss: 1.3862963700294495\n",
      "trial: 2, iter: 6200, curr loss: 1.38664972782135, avg loss: 1.386370285153389\n",
      "trial: 2, ldr: -0.0009224560926668346\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3851374387741089, avg loss: 1.3878750318288804\n",
      "trial: 3, iter: 400, curr loss: 1.386183261871338, avg loss: 1.3867476093769073\n",
      "trial: 3, iter: 600, curr loss: 1.3864378929138184, avg loss: 1.3865899389982224\n",
      "trial: 3, iter: 800, curr loss: 1.388932704925537, avg loss: 1.3865186005830765\n",
      "trial: 3, iter: 1000, curr loss: 1.3871917724609375, avg loss: 1.3864305764436722\n",
      "trial: 3, iter: 1200, curr loss: 1.386839509010315, avg loss: 1.386569812297821\n",
      "trial: 3, iter: 1400, curr loss: 1.3870404958724976, avg loss: 1.3864531314373016\n",
      "trial: 3, iter: 1600, curr loss: 1.384560227394104, avg loss: 1.3863848090171813\n",
      "trial: 3, iter: 1800, curr loss: 1.3868086338043213, avg loss: 1.3863944989442825\n",
      "trial: 3, iter: 2000, curr loss: 1.3870896100997925, avg loss: 1.3863914996385573\n",
      "trial: 3, iter: 2200, curr loss: 1.386911153793335, avg loss: 1.386372999548912\n",
      "trial: 3, iter: 2400, curr loss: 1.3866320848464966, avg loss: 1.3863841950893403\n",
      "trial: 3, iter: 2600, curr loss: 1.3869229555130005, avg loss: 1.3863721078634261\n",
      "trial: 3, iter: 2800, curr loss: 1.388034462928772, avg loss: 1.3863151335716248\n",
      "trial: 3, iter: 3000, curr loss: 1.385144829750061, avg loss: 1.3863888174295425\n",
      "trial: 3, iter: 3200, curr loss: 1.3861485719680786, avg loss: 1.3863835090398788\n",
      "trial: 3, iter: 3400, curr loss: 1.3866653442382812, avg loss: 1.3863190925121307\n",
      "trial: 3, iter: 3600, curr loss: 1.3864437341690063, avg loss: 1.3864254915714265\n",
      "trial: 3, iter: 3800, curr loss: 1.3861582279205322, avg loss: 1.3863225013017655\n",
      "trial: 3, iter: 4000, curr loss: 1.386497974395752, avg loss: 1.3863041889667511\n",
      "trial: 3, iter: 4200, curr loss: 1.3866106271743774, avg loss: 1.3863716322183608\n",
      "trial: 3, iter: 4400, curr loss: 1.3859851360321045, avg loss: 1.3863562744855882\n",
      "trial: 3, iter: 4600, curr loss: 1.3864480257034302, avg loss: 1.3863633996248246\n",
      "trial: 3, iter: 4800, curr loss: 1.3868659734725952, avg loss: 1.386297864317894\n",
      "trial: 3, iter: 5000, curr loss: 1.386033535003662, avg loss: 1.3863284581899642\n",
      "trial: 3, iter: 5200, curr loss: 1.3862088918685913, avg loss: 1.3863053637742997\n",
      "trial: 3, iter: 5400, curr loss: 1.385652780532837, avg loss: 1.38627947807312\n",
      "trial: 3, iter: 5600, curr loss: 1.3857030868530273, avg loss: 1.3863198667764665\n",
      "trial: 3, iter: 5800, curr loss: 1.386370301246643, avg loss: 1.3862888944149017\n",
      "trial: 3, iter: 6000, curr loss: 1.3858379125595093, avg loss: 1.386338313817978\n",
      "trial: 3, iter: 6200, curr loss: 1.386715054512024, avg loss: 1.3864437967538834\n",
      "trial: 3, ldr: 0.0026126825250685215\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3877235651016235, avg loss: 1.3870664185285568\n",
      "trial: 4, iter: 400, curr loss: 1.3871073722839355, avg loss: 1.3866356700658797\n",
      "trial: 4, iter: 600, curr loss: 1.3877644538879395, avg loss: 1.386556996703148\n",
      "trial: 4, iter: 800, curr loss: 1.386364459991455, avg loss: 1.3864999932050706\n",
      "trial: 4, iter: 1000, curr loss: 1.3860150575637817, avg loss: 1.3865110009908677\n",
      "trial: 4, iter: 1200, curr loss: 1.3864996433258057, avg loss: 1.3865368419885635\n",
      "trial: 4, iter: 1400, curr loss: 1.3859838247299194, avg loss: 1.3863454926013947\n",
      "trial: 4, iter: 1600, curr loss: 1.3863025903701782, avg loss: 1.3864561587572097\n",
      "trial: 4, iter: 1800, curr loss: 1.3868656158447266, avg loss: 1.386445516347885\n",
      "trial: 4, iter: 2000, curr loss: 1.3865160942077637, avg loss: 1.3864243745803833\n",
      "trial: 4, iter: 2200, curr loss: 1.385601282119751, avg loss: 1.3863509327173233\n",
      "trial: 4, iter: 2400, curr loss: 1.3866485357284546, avg loss: 1.3863847136497498\n",
      "trial: 4, iter: 2600, curr loss: 1.3864622116088867, avg loss: 1.3863791453838348\n",
      "trial: 4, iter: 2800, curr loss: 1.3861311674118042, avg loss: 1.3863390344381332\n",
      "trial: 4, iter: 3000, curr loss: 1.3869163990020752, avg loss: 1.3863905262947083\n",
      "trial: 4, iter: 3200, curr loss: 1.3853511810302734, avg loss: 1.3863344657421113\n",
      "trial: 4, iter: 3400, curr loss: 1.3860111236572266, avg loss: 1.386387002468109\n",
      "trial: 4, iter: 3600, curr loss: 1.3867868185043335, avg loss: 1.3863844239711762\n",
      "trial: 4, iter: 3800, curr loss: 1.3854186534881592, avg loss: 1.3863719898462294\n",
      "trial: 4, iter: 4000, curr loss: 1.3873767852783203, avg loss: 1.3863385558128356\n",
      "trial: 4, iter: 4200, curr loss: 1.3862590789794922, avg loss: 1.3863406640291214\n",
      "trial: 4, iter: 4400, curr loss: 1.3857214450836182, avg loss: 1.3864029353857041\n",
      "trial: 4, iter: 4600, curr loss: 1.3860398530960083, avg loss: 1.3864081531763077\n",
      "trial: 4, iter: 4800, curr loss: 1.3862735033035278, avg loss: 1.3862446159124375\n",
      "trial: 4, iter: 5000, curr loss: 1.3864431381225586, avg loss: 1.3863444298505783\n",
      "trial: 4, iter: 5200, curr loss: 1.3870450258255005, avg loss: 1.3863795793056488\n",
      "trial: 4, iter: 5400, curr loss: 1.385998249053955, avg loss: 1.386389620900154\n",
      "trial: 4, iter: 5600, curr loss: 1.3863462209701538, avg loss: 1.3864071035385133\n",
      "trial: 4, iter: 5800, curr loss: 1.3860266208648682, avg loss: 1.3863588577508927\n",
      "trial: 4, iter: 6000, curr loss: 1.386142373085022, avg loss: 1.3863447284698487\n",
      "trial: 4, iter: 6200, curr loss: 1.386326551437378, avg loss: 1.3863801437616348\n",
      "trial: 4, ldr: -0.00059549231082201\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387633204460144, avg loss: 1.3873704129457474\n",
      "trial: 5, iter: 400, curr loss: 1.3866939544677734, avg loss: 1.386588596701622\n",
      "trial: 5, iter: 600, curr loss: 1.3859572410583496, avg loss: 1.3865845280885696\n",
      "trial: 5, iter: 800, curr loss: 1.3852828741073608, avg loss: 1.3865382128953934\n",
      "trial: 5, iter: 1000, curr loss: 1.386447548866272, avg loss: 1.3865703344345093\n",
      "trial: 5, iter: 1200, curr loss: 1.3852719068527222, avg loss: 1.3865457201004028\n",
      "trial: 5, iter: 1400, curr loss: 1.387998104095459, avg loss: 1.3864498430490493\n",
      "trial: 5, iter: 1600, curr loss: 1.3868138790130615, avg loss: 1.3864249312877654\n",
      "trial: 5, iter: 1800, curr loss: 1.3873600959777832, avg loss: 1.3864359456300734\n",
      "trial: 5, iter: 2000, curr loss: 1.387508749961853, avg loss: 1.3864357340335847\n",
      "trial: 5, iter: 2200, curr loss: 1.3871780633926392, avg loss: 1.3863594925403595\n",
      "trial: 5, iter: 2400, curr loss: 1.3865050077438354, avg loss: 1.3863734006881714\n",
      "trial: 5, iter: 2600, curr loss: 1.3862783908843994, avg loss: 1.3863751244544984\n",
      "trial: 5, iter: 2800, curr loss: 1.3875248432159424, avg loss: 1.3863056463003158\n",
      "trial: 5, iter: 3000, curr loss: 1.3854507207870483, avg loss: 1.386298965215683\n",
      "trial: 5, iter: 3200, curr loss: 1.3865362405776978, avg loss: 1.386353730559349\n",
      "trial: 5, iter: 3400, curr loss: 1.3861663341522217, avg loss: 1.3863747107982636\n",
      "trial: 5, iter: 3600, curr loss: 1.3864246606826782, avg loss: 1.386319677233696\n",
      "trial: 5, iter: 3800, curr loss: 1.3870500326156616, avg loss: 1.3863213521242141\n",
      "trial: 5, iter: 4000, curr loss: 1.3867045640945435, avg loss: 1.3863548755645752\n",
      "trial: 5, iter: 4200, curr loss: 1.385626196861267, avg loss: 1.3863598716259002\n",
      "trial: 5, iter: 4400, curr loss: 1.3858591318130493, avg loss: 1.3862704104185104\n",
      "trial: 5, iter: 4600, curr loss: 1.3859511613845825, avg loss: 1.386352654695511\n",
      "trial: 5, iter: 4800, curr loss: 1.3873798847198486, avg loss: 1.3863073420524596\n",
      "trial: 5, iter: 5000, curr loss: 1.3863978385925293, avg loss: 1.3863434422016143\n",
      "trial: 5, iter: 5200, curr loss: 1.3863351345062256, avg loss: 1.386329243183136\n",
      "trial: 5, iter: 5400, curr loss: 1.386277675628662, avg loss: 1.3863260900974275\n",
      "trial: 5, iter: 5600, curr loss: 1.3862450122833252, avg loss: 1.3863206213712693\n",
      "trial: 5, iter: 5800, curr loss: 1.3864696025848389, avg loss: 1.386324167251587\n",
      "trial: 5, iter: 6000, curr loss: 1.3864035606384277, avg loss: 1.3863274186849595\n",
      "trial: 5, iter: 6200, curr loss: 1.3878949880599976, avg loss: 1.3863080030679702\n",
      "trial: 5, ldr: -0.006876971572637558\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0017145385849289597\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.384037971496582, avg loss: 1.3869916307926178\n",
      "trial: 1, iter: 400, curr loss: 1.3872511386871338, avg loss: 1.3867503005266189\n",
      "trial: 1, iter: 600, curr loss: 1.3885588645935059, avg loss: 1.386472731232643\n",
      "trial: 1, iter: 800, curr loss: 1.3850226402282715, avg loss: 1.3864417535066604\n",
      "trial: 1, iter: 1000, curr loss: 1.3872581720352173, avg loss: 1.3864587014913559\n",
      "trial: 1, iter: 1200, curr loss: 1.3853012323379517, avg loss: 1.3864363408088685\n",
      "trial: 1, iter: 1400, curr loss: 1.386487364768982, avg loss: 1.3863787138462067\n",
      "trial: 1, iter: 1600, curr loss: 1.3873504400253296, avg loss: 1.3864849799871444\n",
      "trial: 1, iter: 1800, curr loss: 1.3854169845581055, avg loss: 1.3864025068283081\n",
      "trial: 1, iter: 2000, curr loss: 1.38766348361969, avg loss: 1.3863444387912751\n",
      "trial: 1, iter: 2200, curr loss: 1.3865265846252441, avg loss: 1.3864599466323853\n",
      "trial: 1, iter: 2400, curr loss: 1.3873082399368286, avg loss: 1.386412513256073\n",
      "trial: 1, iter: 2600, curr loss: 1.3860440254211426, avg loss: 1.3863565587997437\n",
      "trial: 1, iter: 2800, curr loss: 1.3865808248519897, avg loss: 1.386325700879097\n",
      "trial: 1, iter: 3000, curr loss: 1.3868496417999268, avg loss: 1.3863505905866622\n",
      "trial: 1, iter: 3200, curr loss: 1.3854132890701294, avg loss: 1.3862889796495437\n",
      "trial: 1, iter: 3400, curr loss: 1.3864773511886597, avg loss: 1.3863993227481841\n",
      "trial: 1, iter: 3600, curr loss: 1.3867452144622803, avg loss: 1.386374028325081\n",
      "trial: 1, iter: 3800, curr loss: 1.3863757848739624, avg loss: 1.3863774567842484\n",
      "trial: 1, iter: 4000, curr loss: 1.3869023323059082, avg loss: 1.3862896555662154\n",
      "trial: 1, iter: 4200, curr loss: 1.386212706565857, avg loss: 1.3863991105556488\n",
      "trial: 1, iter: 4400, curr loss: 1.3865599632263184, avg loss: 1.386350675225258\n",
      "trial: 1, iter: 4600, curr loss: 1.3854573965072632, avg loss: 1.3862964844703674\n",
      "trial: 1, iter: 4800, curr loss: 1.386458396911621, avg loss: 1.3863531064987182\n",
      "trial: 1, iter: 5000, curr loss: 1.3851035833358765, avg loss: 1.3862975615262985\n",
      "trial: 1, iter: 5200, curr loss: 1.3863097429275513, avg loss: 1.386375868320465\n",
      "trial: 1, iter: 5400, curr loss: 1.3869552612304688, avg loss: 1.3863660860061646\n",
      "trial: 1, iter: 5600, curr loss: 1.385967493057251, avg loss: 1.386337468624115\n",
      "trial: 1, iter: 5800, curr loss: 1.3862911462783813, avg loss: 1.3863513994216918\n",
      "trial: 1, iter: 6000, curr loss: 1.386291742324829, avg loss: 1.386315729022026\n",
      "trial: 1, iter: 6200, curr loss: 1.386307954788208, avg loss: 1.3862965381145478\n",
      "trial: 1, ldr: -0.00038732081884518266\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.384920358657837, avg loss: 1.3870407730340957\n",
      "trial: 2, iter: 400, curr loss: 1.3858908414840698, avg loss: 1.3867483425140381\n",
      "trial: 2, iter: 600, curr loss: 1.3868050575256348, avg loss: 1.3864829224348068\n",
      "trial: 2, iter: 800, curr loss: 1.3875842094421387, avg loss: 1.386568848490715\n",
      "trial: 2, iter: 1000, curr loss: 1.387377142906189, avg loss: 1.3865038079023362\n",
      "trial: 2, iter: 1200, curr loss: 1.3860344886779785, avg loss: 1.3864441472291946\n",
      "trial: 2, iter: 1400, curr loss: 1.385880947113037, avg loss: 1.3864397931098937\n",
      "trial: 2, iter: 1600, curr loss: 1.3870322704315186, avg loss: 1.38641956448555\n",
      "trial: 2, iter: 1800, curr loss: 1.3851925134658813, avg loss: 1.38639062166214\n",
      "trial: 2, iter: 2000, curr loss: 1.3847808837890625, avg loss: 1.3863056588172913\n",
      "trial: 2, iter: 2200, curr loss: 1.386222243309021, avg loss: 1.3863625013828278\n",
      "trial: 2, iter: 2400, curr loss: 1.3858696222305298, avg loss: 1.3863927406072616\n",
      "trial: 2, iter: 2600, curr loss: 1.385518193244934, avg loss: 1.3864057832956314\n",
      "trial: 2, iter: 2800, curr loss: 1.3861709833145142, avg loss: 1.3863938271999359\n",
      "trial: 2, iter: 3000, curr loss: 1.3865352869033813, avg loss: 1.3863466656208039\n",
      "trial: 2, iter: 3200, curr loss: 1.386294960975647, avg loss: 1.386398742198944\n",
      "trial: 2, iter: 3400, curr loss: 1.3874011039733887, avg loss: 1.3863072955608369\n",
      "trial: 2, iter: 3600, curr loss: 1.3870972394943237, avg loss: 1.3863657385110855\n",
      "trial: 2, iter: 3800, curr loss: 1.3859288692474365, avg loss: 1.3863682848215104\n",
      "trial: 2, iter: 4000, curr loss: 1.3860853910446167, avg loss: 1.3863120573759078\n",
      "trial: 2, iter: 4200, curr loss: 1.3868719339370728, avg loss: 1.3862958973646164\n",
      "trial: 2, iter: 4400, curr loss: 1.3860021829605103, avg loss: 1.3863478434085845\n",
      "trial: 2, iter: 4600, curr loss: 1.3861780166625977, avg loss: 1.3863449889421462\n",
      "trial: 2, iter: 4800, curr loss: 1.3862545490264893, avg loss: 1.3862810987234115\n",
      "trial: 2, iter: 5000, curr loss: 1.3856137990951538, avg loss: 1.386316705942154\n",
      "trial: 2, iter: 5200, curr loss: 1.3862159252166748, avg loss: 1.3863606399297714\n",
      "trial: 2, iter: 5400, curr loss: 1.3863518238067627, avg loss: 1.3862793534994124\n",
      "trial: 2, iter: 5600, curr loss: 1.3858590126037598, avg loss: 1.3863431793451308\n",
      "trial: 2, iter: 5800, curr loss: 1.3868496417999268, avg loss: 1.386382179260254\n",
      "trial: 2, iter: 6000, curr loss: 1.3869441747665405, avg loss: 1.3863362628221512\n",
      "trial: 2, iter: 6200, curr loss: 1.3857502937316895, avg loss: 1.3863224172592163\n",
      "trial: 2, ldr: -4.5285181840881705e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3886733055114746, avg loss: 1.3869733488559723\n",
      "trial: 3, iter: 400, curr loss: 1.385156273841858, avg loss: 1.3867237597703934\n",
      "trial: 3, iter: 600, curr loss: 1.3855681419372559, avg loss: 1.3867183774709702\n",
      "trial: 3, iter: 800, curr loss: 1.3884096145629883, avg loss: 1.386387102007866\n",
      "trial: 3, iter: 1000, curr loss: 1.3865536451339722, avg loss: 1.3865204566717149\n",
      "trial: 3, iter: 1200, curr loss: 1.3873363733291626, avg loss: 1.3864567184448242\n",
      "trial: 3, iter: 1400, curr loss: 1.3887839317321777, avg loss: 1.3865199434757232\n",
      "trial: 3, iter: 1600, curr loss: 1.386786699295044, avg loss: 1.386479754447937\n",
      "trial: 3, iter: 1800, curr loss: 1.385029673576355, avg loss: 1.386382052898407\n",
      "trial: 3, iter: 2000, curr loss: 1.387672781944275, avg loss: 1.3863981330394746\n",
      "trial: 3, iter: 2200, curr loss: 1.386051058769226, avg loss: 1.3864118772745133\n",
      "trial: 3, iter: 2400, curr loss: 1.3858946561813354, avg loss: 1.3863583838939666\n",
      "trial: 3, iter: 2600, curr loss: 1.3853037357330322, avg loss: 1.3863963890075683\n",
      "trial: 3, iter: 2800, curr loss: 1.385580062866211, avg loss: 1.3863522642850876\n",
      "trial: 3, iter: 3000, curr loss: 1.387236475944519, avg loss: 1.3863645315170288\n",
      "trial: 3, iter: 3200, curr loss: 1.3865783214569092, avg loss: 1.386326823234558\n",
      "trial: 3, iter: 3400, curr loss: 1.3859364986419678, avg loss: 1.3863394498825072\n",
      "trial: 3, iter: 3600, curr loss: 1.38626229763031, avg loss: 1.38642853975296\n",
      "trial: 3, iter: 3800, curr loss: 1.3857638835906982, avg loss: 1.3863382655382157\n",
      "trial: 3, iter: 4000, curr loss: 1.386270523071289, avg loss: 1.3863532841205597\n",
      "trial: 3, iter: 4200, curr loss: 1.3855537176132202, avg loss: 1.3863719552755356\n",
      "trial: 3, iter: 4400, curr loss: 1.3858842849731445, avg loss: 1.3863627368211746\n",
      "trial: 3, iter: 4600, curr loss: 1.3863816261291504, avg loss: 1.386310754418373\n",
      "trial: 3, iter: 4800, curr loss: 1.3869909048080444, avg loss: 1.386339208483696\n",
      "trial: 3, iter: 5000, curr loss: 1.3864670991897583, avg loss: 1.386327287554741\n",
      "trial: 3, iter: 5200, curr loss: 1.3858919143676758, avg loss: 1.386303842663765\n",
      "trial: 3, iter: 5400, curr loss: 1.3861573934555054, avg loss: 1.3863141709566116\n",
      "trial: 3, iter: 5600, curr loss: 1.3860520124435425, avg loss: 1.3863362550735474\n",
      "trial: 3, iter: 5800, curr loss: 1.3865667581558228, avg loss: 1.3863494980335236\n",
      "trial: 3, iter: 6000, curr loss: 1.3858379125595093, avg loss: 1.3862981247901915\n",
      "trial: 3, iter: 6200, curr loss: 1.3860770463943481, avg loss: 1.386329870223999\n",
      "trial: 3, ldr: -0.01021586637943983\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3918802738189697, avg loss: 1.387084020972252\n",
      "trial: 4, iter: 400, curr loss: 1.3861912488937378, avg loss: 1.3869242036342622\n",
      "trial: 4, iter: 600, curr loss: 1.3878213167190552, avg loss: 1.3864025551080703\n",
      "trial: 4, iter: 800, curr loss: 1.3859174251556396, avg loss: 1.3865746802091599\n",
      "trial: 4, iter: 1000, curr loss: 1.3866878747940063, avg loss: 1.3865311735868453\n",
      "trial: 4, iter: 1200, curr loss: 1.3849520683288574, avg loss: 1.386324320435524\n",
      "trial: 4, iter: 1400, curr loss: 1.3868874311447144, avg loss: 1.386580879688263\n",
      "trial: 4, iter: 1600, curr loss: 1.3868625164031982, avg loss: 1.386420242190361\n",
      "trial: 4, iter: 1800, curr loss: 1.3860585689544678, avg loss: 1.3863924437761306\n",
      "trial: 4, iter: 2000, curr loss: 1.3885273933410645, avg loss: 1.3863447350263596\n",
      "trial: 4, iter: 2200, curr loss: 1.3862072229385376, avg loss: 1.3864431411027909\n",
      "trial: 4, iter: 2400, curr loss: 1.3854151964187622, avg loss: 1.3864832746982574\n",
      "trial: 4, iter: 2600, curr loss: 1.3869737386703491, avg loss: 1.386436207294464\n",
      "trial: 4, iter: 2800, curr loss: 1.386020302772522, avg loss: 1.3864132589101792\n",
      "trial: 4, iter: 3000, curr loss: 1.3858026266098022, avg loss: 1.3863829332590103\n",
      "trial: 4, iter: 3200, curr loss: 1.3867000341415405, avg loss: 1.386440155506134\n",
      "trial: 4, iter: 3400, curr loss: 1.387478232383728, avg loss: 1.386311051249504\n",
      "trial: 4, iter: 3600, curr loss: 1.3867331743240356, avg loss: 1.3863631093502045\n",
      "trial: 4, iter: 3800, curr loss: 1.3859139680862427, avg loss: 1.3863116097450257\n",
      "trial: 4, iter: 4000, curr loss: 1.3861618041992188, avg loss: 1.3863793784379959\n",
      "trial: 4, iter: 4200, curr loss: 1.386712908744812, avg loss: 1.3863163298368455\n",
      "trial: 4, iter: 4400, curr loss: 1.3865275382995605, avg loss: 1.3863556230068206\n",
      "trial: 4, iter: 4600, curr loss: 1.3868122100830078, avg loss: 1.3863168913125992\n",
      "trial: 4, iter: 4800, curr loss: 1.386488914489746, avg loss: 1.3863173747062683\n",
      "trial: 4, iter: 5000, curr loss: 1.386518955230713, avg loss: 1.3862922143936158\n",
      "trial: 4, iter: 5200, curr loss: 1.386100172996521, avg loss: 1.386283165216446\n",
      "trial: 4, iter: 5400, curr loss: 1.3868536949157715, avg loss: 1.386397923231125\n",
      "trial: 4, iter: 5600, curr loss: 1.3862677812576294, avg loss: 1.3863838225603105\n",
      "trial: 4, iter: 5800, curr loss: 1.3857440948486328, avg loss: 1.3863017934560775\n",
      "trial: 4, iter: 6000, curr loss: 1.386256217956543, avg loss: 1.3863189268112182\n",
      "trial: 4, iter: 6200, curr loss: 1.3863037824630737, avg loss: 1.3863362544775009\n",
      "trial: 4, ldr: -0.00034236974897794425\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385068655014038, avg loss: 1.3871200877428054\n",
      "trial: 5, iter: 400, curr loss: 1.387109637260437, avg loss: 1.386493397951126\n",
      "trial: 5, iter: 600, curr loss: 1.3871238231658936, avg loss: 1.3864659065008162\n",
      "trial: 5, iter: 800, curr loss: 1.3852548599243164, avg loss: 1.3864569926261903\n",
      "trial: 5, iter: 1000, curr loss: 1.386291742324829, avg loss: 1.3864248031377793\n",
      "trial: 5, iter: 1200, curr loss: 1.3863791227340698, avg loss: 1.3864343643188477\n",
      "trial: 5, iter: 1400, curr loss: 1.3869037628173828, avg loss: 1.3864000618457795\n",
      "trial: 5, iter: 1600, curr loss: 1.385979175567627, avg loss: 1.3863608223199844\n",
      "trial: 5, iter: 1800, curr loss: 1.385847568511963, avg loss: 1.38634248316288\n",
      "trial: 5, iter: 2000, curr loss: 1.3873800039291382, avg loss: 1.3863241928815841\n",
      "trial: 5, iter: 2200, curr loss: 1.386573314666748, avg loss: 1.3864036041498184\n",
      "trial: 5, iter: 2400, curr loss: 1.3862948417663574, avg loss: 1.386351599097252\n",
      "trial: 5, iter: 2600, curr loss: 1.3858433961868286, avg loss: 1.3863513249158859\n",
      "trial: 5, iter: 2800, curr loss: 1.3855130672454834, avg loss: 1.386326748728752\n",
      "trial: 5, iter: 3000, curr loss: 1.3871440887451172, avg loss: 1.386408154964447\n",
      "trial: 5, iter: 3200, curr loss: 1.3861926794052124, avg loss: 1.3863340669870376\n",
      "trial: 5, iter: 3400, curr loss: 1.3873704671859741, avg loss: 1.3863407957553864\n",
      "trial: 5, iter: 3600, curr loss: 1.3867378234863281, avg loss: 1.3863531136512757\n",
      "trial: 5, iter: 3800, curr loss: 1.3858798742294312, avg loss: 1.3863321608304977\n",
      "trial: 5, iter: 4000, curr loss: 1.3862690925598145, avg loss: 1.3863206368684768\n",
      "trial: 5, iter: 4200, curr loss: 1.3869655132293701, avg loss: 1.3863623011112214\n",
      "trial: 5, iter: 4400, curr loss: 1.3863861560821533, avg loss: 1.3863431572914124\n",
      "trial: 5, iter: 4600, curr loss: 1.3859866857528687, avg loss: 1.386329923272133\n",
      "trial: 5, iter: 4800, curr loss: 1.3859975337982178, avg loss: 1.3863350188732146\n",
      "trial: 5, iter: 5000, curr loss: 1.3861931562423706, avg loss: 1.3863140404224397\n",
      "trial: 5, iter: 5200, curr loss: 1.3862496614456177, avg loss: 1.3863273549079895\n",
      "trial: 5, iter: 5400, curr loss: 1.3861172199249268, avg loss: 1.3863189494609833\n",
      "trial: 5, iter: 5600, curr loss: 1.386009693145752, avg loss: 1.3863080900907516\n",
      "trial: 5, iter: 5800, curr loss: 1.3857336044311523, avg loss: 1.3863361501693725\n",
      "trial: 5, iter: 6000, curr loss: 1.3865320682525635, avg loss: 1.3863088524341582\n",
      "trial: 5, iter: 6200, curr loss: 1.3862531185150146, avg loss: 1.386332380771637\n",
      "trial: 5, ldr: 0.008690170012414455\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0004601344233378768\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.389557957649231, avg loss: 1.3875258260965346\n",
      "trial: 1, iter: 400, curr loss: 1.3878270387649536, avg loss: 1.3866993170976638\n",
      "trial: 1, iter: 600, curr loss: 1.386026382446289, avg loss: 1.3864941316843034\n",
      "trial: 1, iter: 800, curr loss: 1.3860552310943604, avg loss: 1.3867227464914322\n",
      "trial: 1, iter: 1000, curr loss: 1.3867629766464233, avg loss: 1.386458895802498\n",
      "trial: 1, iter: 1200, curr loss: 1.3841829299926758, avg loss: 1.3865554231405257\n",
      "trial: 1, iter: 1400, curr loss: 1.3858522176742554, avg loss: 1.3865093678236007\n",
      "trial: 1, iter: 1600, curr loss: 1.3865183591842651, avg loss: 1.3864116978645324\n",
      "trial: 1, iter: 1800, curr loss: 1.3855994939804077, avg loss: 1.3864361852407456\n",
      "trial: 1, iter: 2000, curr loss: 1.386576771736145, avg loss: 1.3863822245597839\n",
      "trial: 1, iter: 2200, curr loss: 1.3858755826950073, avg loss: 1.3863643258810043\n",
      "trial: 1, iter: 2400, curr loss: 1.3866580724716187, avg loss: 1.386437937617302\n",
      "trial: 1, iter: 2600, curr loss: 1.3860204219818115, avg loss: 1.3863630056381226\n",
      "trial: 1, iter: 2800, curr loss: 1.3867614269256592, avg loss: 1.386348661184311\n",
      "trial: 1, iter: 3000, curr loss: 1.3858304023742676, avg loss: 1.3863017141819\n",
      "trial: 1, iter: 3200, curr loss: 1.3874222040176392, avg loss: 1.3862732005119325\n",
      "trial: 1, iter: 3400, curr loss: 1.3854445219039917, avg loss: 1.3863343960046768\n",
      "trial: 1, iter: 3600, curr loss: 1.3870879411697388, avg loss: 1.3863585275411605\n",
      "trial: 1, iter: 3800, curr loss: 1.3869881629943848, avg loss: 1.3863708436489106\n",
      "trial: 1, iter: 4000, curr loss: 1.3863497972488403, avg loss: 1.3863323765993119\n",
      "trial: 1, iter: 4200, curr loss: 1.3861733675003052, avg loss: 1.3863479763269424\n",
      "trial: 1, iter: 4400, curr loss: 1.3861639499664307, avg loss: 1.3862994128465653\n",
      "trial: 1, iter: 4600, curr loss: 1.3871607780456543, avg loss: 1.3863658571243287\n",
      "trial: 1, iter: 4800, curr loss: 1.3861562013626099, avg loss: 1.3863350754976274\n",
      "trial: 1, iter: 5000, curr loss: 1.3864084482192993, avg loss: 1.386319494843483\n",
      "trial: 1, iter: 5200, curr loss: 1.3866177797317505, avg loss: 1.3863252955675125\n",
      "trial: 1, iter: 5400, curr loss: 1.3860822916030884, avg loss: 1.3863182383775712\n",
      "trial: 1, iter: 5600, curr loss: 1.3862888813018799, avg loss: 1.3863250190019607\n",
      "trial: 1, iter: 5800, curr loss: 1.385772943496704, avg loss: 1.3862951344251633\n",
      "trial: 1, iter: 6000, curr loss: 1.386138916015625, avg loss: 1.3863395053148269\n",
      "trial: 1, iter: 6200, curr loss: 1.3866729736328125, avg loss: 1.3863081246614457\n",
      "trial: 1, ldr: -0.012600520625710487\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386465072631836, avg loss: 1.3873384940624236\n",
      "trial: 2, iter: 400, curr loss: 1.3889720439910889, avg loss: 1.3866656631231309\n",
      "trial: 2, iter: 600, curr loss: 1.3863316774368286, avg loss: 1.3866407644748688\n",
      "trial: 2, iter: 800, curr loss: 1.3850106000900269, avg loss: 1.3865939056873322\n",
      "trial: 2, iter: 1000, curr loss: 1.3893545866012573, avg loss: 1.386678723692894\n",
      "trial: 2, iter: 1200, curr loss: 1.3865636587142944, avg loss: 1.3865282666683196\n",
      "trial: 2, iter: 1400, curr loss: 1.3885962963104248, avg loss: 1.3864580351114273\n",
      "trial: 2, iter: 1600, curr loss: 1.3856403827667236, avg loss: 1.386483747959137\n",
      "trial: 2, iter: 1800, curr loss: 1.3875596523284912, avg loss: 1.3864744555950166\n",
      "trial: 2, iter: 2000, curr loss: 1.3862125873565674, avg loss: 1.3864664924144745\n",
      "trial: 2, iter: 2200, curr loss: 1.387678861618042, avg loss: 1.3864158433675766\n",
      "trial: 2, iter: 2400, curr loss: 1.3871030807495117, avg loss: 1.3863469344377517\n",
      "trial: 2, iter: 2600, curr loss: 1.3851832151412964, avg loss: 1.386461084485054\n",
      "trial: 2, iter: 2800, curr loss: 1.3880078792572021, avg loss: 1.3864298766851426\n",
      "trial: 2, iter: 3000, curr loss: 1.3866111040115356, avg loss: 1.3863999021053315\n",
      "trial: 2, iter: 3200, curr loss: 1.3875229358673096, avg loss: 1.3863975006341933\n",
      "trial: 2, iter: 3400, curr loss: 1.3853294849395752, avg loss: 1.3864046412706375\n",
      "trial: 2, iter: 3600, curr loss: 1.3875014781951904, avg loss: 1.3863456535339356\n",
      "trial: 2, iter: 3800, curr loss: 1.3868552446365356, avg loss: 1.386412305831909\n",
      "trial: 2, iter: 4000, curr loss: 1.3861896991729736, avg loss: 1.3863526421785355\n",
      "trial: 2, iter: 4200, curr loss: 1.3857765197753906, avg loss: 1.3863224333524704\n",
      "trial: 2, iter: 4400, curr loss: 1.386395812034607, avg loss: 1.3863133496046067\n",
      "trial: 2, iter: 4600, curr loss: 1.3861032724380493, avg loss: 1.3863409370183946\n",
      "trial: 2, iter: 4800, curr loss: 1.3863961696624756, avg loss: 1.3863339084386825\n",
      "trial: 2, iter: 5000, curr loss: 1.3860580921173096, avg loss: 1.3863191121816636\n",
      "trial: 2, iter: 5200, curr loss: 1.3860485553741455, avg loss: 1.3864075082540512\n",
      "trial: 2, iter: 5400, curr loss: 1.3861438035964966, avg loss: 1.3863515222072602\n",
      "trial: 2, iter: 5600, curr loss: 1.3862563371658325, avg loss: 1.386322588324547\n",
      "trial: 2, iter: 5800, curr loss: 1.3862934112548828, avg loss: 1.3863225001096726\n",
      "trial: 2, iter: 6000, curr loss: 1.3861931562423706, avg loss: 1.3863380110263825\n",
      "trial: 2, iter: 6200, curr loss: 1.3866463899612427, avg loss: 1.386351038813591\n",
      "trial: 2, ldr: -0.009088672697544098\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.386182188987732, avg loss: 1.3871987074613572\n",
      "trial: 3, iter: 400, curr loss: 1.3879997730255127, avg loss: 1.386660987138748\n",
      "trial: 3, iter: 600, curr loss: 1.3888059854507446, avg loss: 1.3865601605176925\n",
      "trial: 3, iter: 800, curr loss: 1.3868719339370728, avg loss: 1.386661673784256\n",
      "trial: 3, iter: 1000, curr loss: 1.3870913982391357, avg loss: 1.3865639525651932\n",
      "trial: 3, iter: 1200, curr loss: 1.3868324756622314, avg loss: 1.3864845341444016\n",
      "trial: 3, iter: 1400, curr loss: 1.3876036405563354, avg loss: 1.3863244104385375\n",
      "trial: 3, iter: 1600, curr loss: 1.386586308479309, avg loss: 1.38642103433609\n",
      "trial: 3, iter: 1800, curr loss: 1.3871053457260132, avg loss: 1.3864159822463988\n",
      "trial: 3, iter: 2000, curr loss: 1.386575698852539, avg loss: 1.3863569462299348\n",
      "trial: 3, iter: 2200, curr loss: 1.3867664337158203, avg loss: 1.3863870680332184\n",
      "trial: 3, iter: 2400, curr loss: 1.3863075971603394, avg loss: 1.3863993787765503\n",
      "trial: 3, iter: 2600, curr loss: 1.385116457939148, avg loss: 1.3863387817144395\n",
      "trial: 3, iter: 2800, curr loss: 1.386383056640625, avg loss: 1.386372265815735\n",
      "trial: 3, iter: 3000, curr loss: 1.3863394260406494, avg loss: 1.3863741546869277\n",
      "trial: 3, iter: 3200, curr loss: 1.3859421014785767, avg loss: 1.3863767033815384\n",
      "trial: 3, iter: 3400, curr loss: 1.3862100839614868, avg loss: 1.3863770645856857\n",
      "trial: 3, iter: 3600, curr loss: 1.3866117000579834, avg loss: 1.3863380628824233\n",
      "trial: 3, iter: 3800, curr loss: 1.387420415878296, avg loss: 1.3862828475236892\n",
      "trial: 3, iter: 4000, curr loss: 1.3865185976028442, avg loss: 1.386342094540596\n",
      "trial: 3, iter: 4200, curr loss: 1.3862236738204956, avg loss: 1.386389901638031\n",
      "trial: 3, iter: 4400, curr loss: 1.388350248336792, avg loss: 1.3863355469703675\n",
      "trial: 3, iter: 4600, curr loss: 1.3859364986419678, avg loss: 1.3864138627052307\n",
      "trial: 3, iter: 4800, curr loss: 1.385817289352417, avg loss: 1.3863635957241058\n",
      "trial: 3, iter: 5000, curr loss: 1.3866688013076782, avg loss: 1.3863457292318344\n",
      "trial: 3, iter: 5200, curr loss: 1.3865278959274292, avg loss: 1.3863667380809783\n",
      "trial: 3, iter: 5400, curr loss: 1.386346459388733, avg loss: 1.3863972288370132\n",
      "trial: 3, iter: 5600, curr loss: 1.3863928318023682, avg loss: 1.3862919747829436\n",
      "trial: 3, iter: 5800, curr loss: 1.3872958421707153, avg loss: 1.3863284283876418\n",
      "trial: 3, iter: 6000, curr loss: 1.3865207433700562, avg loss: 1.3863473725318909\n",
      "trial: 3, iter: 6200, curr loss: 1.3860480785369873, avg loss: 1.3863093334436416\n",
      "trial: 3, ldr: -0.002246701391413808\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3888521194458008, avg loss: 1.3874239206314087\n",
      "trial: 4, iter: 400, curr loss: 1.385837197303772, avg loss: 1.3868022912740707\n",
      "trial: 4, iter: 600, curr loss: 1.385488510131836, avg loss: 1.3863942605257034\n",
      "trial: 4, iter: 800, curr loss: 1.3865041732788086, avg loss: 1.3865148556232452\n",
      "trial: 4, iter: 1000, curr loss: 1.386439561843872, avg loss: 1.386521721482277\n",
      "trial: 4, iter: 1200, curr loss: 1.386436104774475, avg loss: 1.3863572651147842\n",
      "trial: 4, iter: 1400, curr loss: 1.3872498273849487, avg loss: 1.38644786298275\n",
      "trial: 4, iter: 1600, curr loss: 1.3861758708953857, avg loss: 1.3864560401439667\n",
      "trial: 4, iter: 1800, curr loss: 1.3855515718460083, avg loss: 1.3863397300243379\n",
      "trial: 4, iter: 2000, curr loss: 1.3860750198364258, avg loss: 1.3864016902446747\n",
      "trial: 4, iter: 2200, curr loss: 1.3870924711227417, avg loss: 1.386381259560585\n",
      "trial: 4, iter: 2400, curr loss: 1.3869349956512451, avg loss: 1.3863668978214263\n",
      "trial: 4, iter: 2600, curr loss: 1.3868566751480103, avg loss: 1.3864269173145294\n",
      "trial: 4, iter: 2800, curr loss: 1.386681079864502, avg loss: 1.386352653503418\n",
      "trial: 4, iter: 3000, curr loss: 1.386010766029358, avg loss: 1.3863582330942155\n",
      "trial: 4, iter: 3200, curr loss: 1.3854618072509766, avg loss: 1.3862886184453964\n",
      "trial: 4, iter: 3400, curr loss: 1.385623812675476, avg loss: 1.3863542783260345\n",
      "trial: 4, iter: 3600, curr loss: 1.3864020109176636, avg loss: 1.3863680291175842\n",
      "trial: 4, iter: 3800, curr loss: 1.385673999786377, avg loss: 1.3863560289144516\n",
      "trial: 4, iter: 4000, curr loss: 1.386301875114441, avg loss: 1.386291937828064\n",
      "trial: 4, iter: 4200, curr loss: 1.386468529701233, avg loss: 1.3863706803321838\n",
      "trial: 4, iter: 4400, curr loss: 1.3867993354797363, avg loss: 1.386355345249176\n",
      "trial: 4, iter: 4600, curr loss: 1.386266827583313, avg loss: 1.3863269579410553\n",
      "trial: 4, iter: 4800, curr loss: 1.3867003917694092, avg loss: 1.3863228261470795\n",
      "trial: 4, iter: 5000, curr loss: 1.3856521844863892, avg loss: 1.386285858154297\n",
      "trial: 4, iter: 5200, curr loss: 1.3859213590621948, avg loss: 1.3863459169864654\n",
      "trial: 4, iter: 5400, curr loss: 1.386593222618103, avg loss: 1.3863316076993941\n",
      "trial: 4, iter: 5600, curr loss: 1.3853389024734497, avg loss: 1.3862786799669267\n",
      "trial: 4, iter: 5800, curr loss: 1.3860294818878174, avg loss: 1.3863348364830017\n",
      "trial: 4, iter: 6000, curr loss: 1.3857001066207886, avg loss: 1.386353257894516\n",
      "trial: 4, iter: 6200, curr loss: 1.3864600658416748, avg loss: 1.3863494688272475\n",
      "trial: 4, ldr: -0.004152138717472553\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3856520652770996, avg loss: 1.387260650396347\n",
      "trial: 5, iter: 400, curr loss: 1.3864877223968506, avg loss: 1.3866869109869002\n",
      "trial: 5, iter: 600, curr loss: 1.3866395950317383, avg loss: 1.3866191041469573\n",
      "trial: 5, iter: 800, curr loss: 1.386622428894043, avg loss: 1.386459487080574\n",
      "trial: 5, iter: 1000, curr loss: 1.3859682083129883, avg loss: 1.3864345771074296\n",
      "trial: 5, iter: 1200, curr loss: 1.3860671520233154, avg loss: 1.3865134817361833\n",
      "trial: 5, iter: 1400, curr loss: 1.3870084285736084, avg loss: 1.3863883233070373\n",
      "trial: 5, iter: 1600, curr loss: 1.386124849319458, avg loss: 1.3864917713403702\n",
      "trial: 5, iter: 1800, curr loss: 1.3859127759933472, avg loss: 1.3863812881708144\n",
      "trial: 5, iter: 2000, curr loss: 1.3870012760162354, avg loss: 1.3863893246650696\n",
      "trial: 5, iter: 2200, curr loss: 1.3865910768508911, avg loss: 1.386425267457962\n",
      "trial: 5, iter: 2400, curr loss: 1.3858332633972168, avg loss: 1.38634733915329\n",
      "trial: 5, iter: 2600, curr loss: 1.387206792831421, avg loss: 1.3864091050624847\n",
      "trial: 5, iter: 2800, curr loss: 1.386595368385315, avg loss: 1.386404917240143\n",
      "trial: 5, iter: 3000, curr loss: 1.3863098621368408, avg loss: 1.386351089477539\n",
      "trial: 5, iter: 3200, curr loss: 1.3861689567565918, avg loss: 1.3863629108667375\n",
      "trial: 5, iter: 3400, curr loss: 1.3864011764526367, avg loss: 1.3862933337688446\n",
      "trial: 5, iter: 3600, curr loss: 1.3860278129577637, avg loss: 1.3863202291727066\n",
      "trial: 5, iter: 3800, curr loss: 1.387966513633728, avg loss: 1.3862882107496262\n",
      "trial: 5, iter: 4000, curr loss: 1.3874742984771729, avg loss: 1.3864221775531769\n",
      "trial: 5, iter: 4200, curr loss: 1.3857227563858032, avg loss: 1.3863483476638794\n",
      "trial: 5, iter: 4400, curr loss: 1.3863744735717773, avg loss: 1.3863422495126725\n",
      "trial: 5, iter: 4600, curr loss: 1.3866304159164429, avg loss: 1.3863207131624222\n",
      "trial: 5, iter: 4800, curr loss: 1.3869190216064453, avg loss: 1.386360238790512\n",
      "trial: 5, iter: 5000, curr loss: 1.3873279094696045, avg loss: 1.386299552321434\n",
      "trial: 5, iter: 5200, curr loss: 1.3866896629333496, avg loss: 1.3863573133945466\n",
      "trial: 5, iter: 5400, curr loss: 1.3865923881530762, avg loss: 1.3863210552930831\n",
      "trial: 5, iter: 5600, curr loss: 1.386685848236084, avg loss: 1.3863226276636125\n",
      "trial: 5, iter: 5800, curr loss: 1.3864222764968872, avg loss: 1.386297492980957\n",
      "trial: 5, iter: 6000, curr loss: 1.3862755298614502, avg loss: 1.3862977522611617\n",
      "trial: 5, iter: 6200, curr loss: 1.3867015838623047, avg loss: 1.3863195246458053\n",
      "trial: 5, ldr: -0.004404309671372175\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.006498468620702624\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3867738246917725, avg loss: 1.3872583270072938\n",
      "trial: 1, iter: 400, curr loss: 1.3856964111328125, avg loss: 1.3866703188419343\n",
      "trial: 1, iter: 600, curr loss: 1.386386752128601, avg loss: 1.3864858770370483\n",
      "trial: 1, iter: 800, curr loss: 1.3857027292251587, avg loss: 1.386633722782135\n",
      "trial: 1, iter: 1000, curr loss: 1.3860610723495483, avg loss: 1.386486948132515\n",
      "trial: 1, iter: 1200, curr loss: 1.3851215839385986, avg loss: 1.3863807040452958\n",
      "trial: 1, iter: 1400, curr loss: 1.3872147798538208, avg loss: 1.3863563215732575\n",
      "trial: 1, iter: 1600, curr loss: 1.3891198635101318, avg loss: 1.3863976043462753\n",
      "trial: 1, iter: 1800, curr loss: 1.3869904279708862, avg loss: 1.3865993636846543\n",
      "trial: 1, iter: 2000, curr loss: 1.3883793354034424, avg loss: 1.3864602535963058\n",
      "trial: 1, iter: 2200, curr loss: 1.3886548280715942, avg loss: 1.3863897067308426\n",
      "trial: 1, iter: 2400, curr loss: 1.3887139558792114, avg loss: 1.386544741988182\n",
      "trial: 1, iter: 2600, curr loss: 1.38668692111969, avg loss: 1.3864666092395783\n",
      "trial: 1, iter: 2800, curr loss: 1.3887107372283936, avg loss: 1.3863932502269745\n",
      "trial: 1, iter: 3000, curr loss: 1.386711835861206, avg loss: 1.3864201843738555\n",
      "trial: 1, iter: 3200, curr loss: 1.3860245943069458, avg loss: 1.3863373446464538\n",
      "trial: 1, iter: 3400, curr loss: 1.3860749006271362, avg loss: 1.3863857245445252\n",
      "trial: 1, iter: 3600, curr loss: 1.3877670764923096, avg loss: 1.3864862948656083\n",
      "trial: 1, iter: 3800, curr loss: 1.3862391710281372, avg loss: 1.386450364589691\n",
      "trial: 1, iter: 4000, curr loss: 1.3860809803009033, avg loss: 1.3864419603347777\n",
      "trial: 1, iter: 4200, curr loss: 1.386622667312622, avg loss: 1.386420212984085\n",
      "trial: 1, iter: 4400, curr loss: 1.3864065408706665, avg loss: 1.3863360422849655\n",
      "trial: 1, iter: 4600, curr loss: 1.3867415189743042, avg loss: 1.3863227063417434\n",
      "trial: 1, iter: 4800, curr loss: 1.386389136314392, avg loss: 1.386306384205818\n",
      "trial: 1, iter: 5000, curr loss: 1.3861593008041382, avg loss: 1.3863670307397842\n",
      "trial: 1, iter: 5200, curr loss: 1.3863259553909302, avg loss: 1.386295879483223\n",
      "trial: 1, iter: 5400, curr loss: 1.3871568441390991, avg loss: 1.386328604221344\n",
      "trial: 1, iter: 5600, curr loss: 1.3865044116973877, avg loss: 1.3862981176376343\n",
      "trial: 1, iter: 5800, curr loss: 1.3863173723220825, avg loss: 1.3862975591421127\n",
      "trial: 1, iter: 6000, curr loss: 1.3862509727478027, avg loss: 1.3863252025842667\n",
      "trial: 1, iter: 6200, curr loss: 1.3861925601959229, avg loss: 1.3862931555509568\n",
      "trial: 1, ldr: 0.007003025151789188\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3860210180282593, avg loss: 1.3874134701490402\n",
      "trial: 2, iter: 400, curr loss: 1.3871184587478638, avg loss: 1.3866597253084183\n",
      "trial: 2, iter: 600, curr loss: 1.387403964996338, avg loss: 1.3863821184635163\n",
      "trial: 2, iter: 800, curr loss: 1.3854366540908813, avg loss: 1.3865085911750794\n",
      "trial: 2, iter: 1000, curr loss: 1.3854684829711914, avg loss: 1.38646970808506\n",
      "trial: 2, iter: 1200, curr loss: 1.3861899375915527, avg loss: 1.3864716809988022\n",
      "trial: 2, iter: 1400, curr loss: 1.3872160911560059, avg loss: 1.3864535504579545\n",
      "trial: 2, iter: 1600, curr loss: 1.3848122358322144, avg loss: 1.3864057117700577\n",
      "trial: 2, iter: 1800, curr loss: 1.386272668838501, avg loss: 1.3865178138017655\n",
      "trial: 2, iter: 2000, curr loss: 1.3872178792953491, avg loss: 1.3864903742074965\n",
      "trial: 2, iter: 2200, curr loss: 1.3859885931015015, avg loss: 1.3865079337358475\n",
      "trial: 2, iter: 2400, curr loss: 1.3859491348266602, avg loss: 1.386389165520668\n",
      "trial: 2, iter: 2600, curr loss: 1.3864809274673462, avg loss: 1.386451297402382\n",
      "trial: 2, iter: 2800, curr loss: 1.3863866329193115, avg loss: 1.3863480108976365\n",
      "trial: 2, iter: 3000, curr loss: 1.386938214302063, avg loss: 1.3863317269086837\n",
      "trial: 2, iter: 3200, curr loss: 1.3878744840621948, avg loss: 1.3862954467535018\n",
      "trial: 2, iter: 3400, curr loss: 1.3869725465774536, avg loss: 1.3864574760198594\n",
      "trial: 2, iter: 3600, curr loss: 1.3871452808380127, avg loss: 1.3863273638486862\n",
      "trial: 2, iter: 3800, curr loss: 1.384963035583496, avg loss: 1.3863126122951508\n",
      "trial: 2, iter: 4000, curr loss: 1.385480523109436, avg loss: 1.3863361567258834\n",
      "trial: 2, iter: 4200, curr loss: 1.3865330219268799, avg loss: 1.38636964738369\n",
      "trial: 2, iter: 4400, curr loss: 1.3864452838897705, avg loss: 1.3863660085201264\n",
      "trial: 2, iter: 4600, curr loss: 1.3863420486450195, avg loss: 1.3862921243906021\n",
      "trial: 2, iter: 4800, curr loss: 1.3869142532348633, avg loss: 1.3863669031858443\n",
      "trial: 2, iter: 5000, curr loss: 1.3850454092025757, avg loss: 1.3862703281641007\n",
      "trial: 2, iter: 5200, curr loss: 1.3868975639343262, avg loss: 1.3863454586267472\n",
      "trial: 2, iter: 5400, curr loss: 1.38689124584198, avg loss: 1.3863307237625122\n",
      "trial: 2, iter: 5600, curr loss: 1.3869625329971313, avg loss: 1.386316908597946\n",
      "trial: 2, iter: 5800, curr loss: 1.3862439393997192, avg loss: 1.3863045465946198\n",
      "trial: 2, iter: 6000, curr loss: 1.3852638006210327, avg loss: 1.3862188154458999\n",
      "trial: 2, iter: 6200, curr loss: 1.3865944147109985, avg loss: 1.38641222178936\n",
      "trial: 2, ldr: 0.0030016209930181503\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3904025554656982, avg loss: 1.387250611782074\n",
      "trial: 3, iter: 400, curr loss: 1.3868201971054077, avg loss: 1.3867085433006288\n",
      "trial: 3, iter: 600, curr loss: 1.3872761726379395, avg loss: 1.3863903468847274\n",
      "trial: 3, iter: 800, curr loss: 1.386958122253418, avg loss: 1.3866235148906707\n",
      "trial: 3, iter: 1000, curr loss: 1.3868165016174316, avg loss: 1.386393243074417\n",
      "trial: 3, iter: 1200, curr loss: 1.3867889642715454, avg loss: 1.3864028936624526\n",
      "trial: 3, iter: 1400, curr loss: 1.3844730854034424, avg loss: 1.38642149746418\n",
      "trial: 3, iter: 1600, curr loss: 1.3871426582336426, avg loss: 1.3864306843280791\n",
      "trial: 3, iter: 1800, curr loss: 1.387957215309143, avg loss: 1.3864496213197708\n",
      "trial: 3, iter: 2000, curr loss: 1.3862457275390625, avg loss: 1.3865891921520233\n",
      "trial: 3, iter: 2200, curr loss: 1.385741114616394, avg loss: 1.386428666114807\n",
      "trial: 3, iter: 2400, curr loss: 1.3867048025131226, avg loss: 1.38643920481205\n",
      "trial: 3, iter: 2600, curr loss: 1.3861796855926514, avg loss: 1.386311172246933\n",
      "trial: 3, iter: 2800, curr loss: 1.3849300146102905, avg loss: 1.386363748908043\n",
      "trial: 3, iter: 3000, curr loss: 1.3861644268035889, avg loss: 1.3863946384191512\n",
      "trial: 3, iter: 3200, curr loss: 1.386005163192749, avg loss: 1.3863835787773133\n",
      "trial: 3, iter: 3400, curr loss: 1.3867195844650269, avg loss: 1.3863212794065476\n",
      "trial: 3, iter: 3600, curr loss: 1.386683702468872, avg loss: 1.3863796806335449\n",
      "trial: 3, iter: 3800, curr loss: 1.3860807418823242, avg loss: 1.3863274133205414\n",
      "trial: 3, iter: 4000, curr loss: 1.3863246440887451, avg loss: 1.3863553792238235\n",
      "trial: 3, iter: 4200, curr loss: 1.386068344116211, avg loss: 1.3863398468494414\n",
      "trial: 3, iter: 4400, curr loss: 1.3863120079040527, avg loss: 1.3862654399871825\n",
      "trial: 3, iter: 4600, curr loss: 1.3857311010360718, avg loss: 1.3863369280099869\n",
      "trial: 3, iter: 4800, curr loss: 1.3869684934616089, avg loss: 1.3863916659355164\n",
      "trial: 3, iter: 5000, curr loss: 1.3865538835525513, avg loss: 1.3863039553165435\n",
      "trial: 3, iter: 5200, curr loss: 1.3866389989852905, avg loss: 1.3863128119707107\n",
      "trial: 3, iter: 5400, curr loss: 1.3859083652496338, avg loss: 1.386295320391655\n",
      "trial: 3, iter: 5600, curr loss: 1.3863862752914429, avg loss: 1.3863127905130386\n",
      "trial: 3, iter: 5800, curr loss: 1.3863424062728882, avg loss: 1.3862611883878708\n",
      "trial: 3, iter: 6000, curr loss: 1.3863649368286133, avg loss: 1.3863538962602615\n",
      "trial: 3, iter: 6200, curr loss: 1.3866081237792969, avg loss: 1.3863188004493714\n",
      "trial: 3, ldr: -0.016201723366975784\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3875336647033691, avg loss: 1.3873313558101654\n",
      "trial: 4, iter: 400, curr loss: 1.384865403175354, avg loss: 1.386634630560875\n",
      "trial: 4, iter: 600, curr loss: 1.3863158226013184, avg loss: 1.386629176735878\n",
      "trial: 4, iter: 800, curr loss: 1.38582444190979, avg loss: 1.386354478597641\n",
      "trial: 4, iter: 1000, curr loss: 1.386317491531372, avg loss: 1.386534602046013\n",
      "trial: 4, iter: 1200, curr loss: 1.3862428665161133, avg loss: 1.3864026325941086\n",
      "trial: 4, iter: 1400, curr loss: 1.385814905166626, avg loss: 1.3864863044023514\n",
      "trial: 4, iter: 1600, curr loss: 1.3868093490600586, avg loss: 1.3863864022493362\n",
      "trial: 4, iter: 1800, curr loss: 1.385569453239441, avg loss: 1.3865028876066208\n",
      "trial: 4, iter: 2000, curr loss: 1.3870614767074585, avg loss: 1.386381340622902\n",
      "trial: 4, iter: 2200, curr loss: 1.3860771656036377, avg loss: 1.3863497072458266\n",
      "trial: 4, iter: 2400, curr loss: 1.3860853910446167, avg loss: 1.3863040161132814\n",
      "trial: 4, iter: 2600, curr loss: 1.3853760957717896, avg loss: 1.386397390961647\n",
      "trial: 4, iter: 2800, curr loss: 1.3857803344726562, avg loss: 1.3862678444385528\n",
      "trial: 4, iter: 3000, curr loss: 1.3861572742462158, avg loss: 1.3863864630460738\n",
      "trial: 4, iter: 3200, curr loss: 1.386202096939087, avg loss: 1.3863258790969848\n",
      "trial: 4, iter: 3400, curr loss: 1.3870131969451904, avg loss: 1.3863334131240845\n",
      "trial: 4, iter: 3600, curr loss: 1.3863964080810547, avg loss: 1.386366487145424\n",
      "trial: 4, iter: 3800, curr loss: 1.3862415552139282, avg loss: 1.3863495779037476\n",
      "trial: 4, iter: 4000, curr loss: 1.3865033388137817, avg loss: 1.386316993832588\n",
      "trial: 4, iter: 4200, curr loss: 1.3861030340194702, avg loss: 1.386339019536972\n",
      "trial: 4, iter: 4400, curr loss: 1.386216163635254, avg loss: 1.3863486951589585\n",
      "trial: 4, iter: 4600, curr loss: 1.3860535621643066, avg loss: 1.386317885518074\n",
      "trial: 4, iter: 4800, curr loss: 1.3864296674728394, avg loss: 1.386341912150383\n",
      "trial: 4, iter: 5000, curr loss: 1.3861147165298462, avg loss: 1.3863230627775192\n",
      "trial: 4, iter: 5200, curr loss: 1.3863945007324219, avg loss: 1.3863106590509415\n",
      "trial: 4, iter: 5400, curr loss: 1.3862379789352417, avg loss: 1.386276248693466\n",
      "trial: 4, iter: 5600, curr loss: 1.3849140405654907, avg loss: 1.3862802517414092\n",
      "trial: 4, iter: 5800, curr loss: 1.3862746953964233, avg loss: 1.386347907781601\n",
      "trial: 4, iter: 6000, curr loss: 1.3864203691482544, avg loss: 1.3863013792037964\n",
      "trial: 4, iter: 6200, curr loss: 1.3859654664993286, avg loss: 1.386308029294014\n",
      "trial: 4, ldr: -0.00420294888317585\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3852739334106445, avg loss: 1.3873448020219803\n",
      "trial: 5, iter: 400, curr loss: 1.3860362768173218, avg loss: 1.3868528306484222\n",
      "trial: 5, iter: 600, curr loss: 1.3871660232543945, avg loss: 1.3866943228244781\n",
      "trial: 5, iter: 800, curr loss: 1.384864330291748, avg loss: 1.3866077148914338\n",
      "trial: 5, iter: 1000, curr loss: 1.3861103057861328, avg loss: 1.3865039092302323\n",
      "trial: 5, iter: 1200, curr loss: 1.3862428665161133, avg loss: 1.3866129451990128\n",
      "trial: 5, iter: 1400, curr loss: 1.387512445449829, avg loss: 1.386535919904709\n",
      "trial: 5, iter: 1600, curr loss: 1.3859610557556152, avg loss: 1.3863886708021165\n",
      "trial: 5, iter: 1800, curr loss: 1.3873202800750732, avg loss: 1.3864116722345352\n",
      "trial: 5, iter: 2000, curr loss: 1.385376214981079, avg loss: 1.386378788948059\n",
      "trial: 5, iter: 2200, curr loss: 1.3860374689102173, avg loss: 1.3863951951265334\n",
      "trial: 5, iter: 2400, curr loss: 1.3859148025512695, avg loss: 1.3863902360200882\n",
      "trial: 5, iter: 2600, curr loss: 1.3852936029434204, avg loss: 1.3863883966207504\n",
      "trial: 5, iter: 2800, curr loss: 1.3865677118301392, avg loss: 1.3864563477039338\n",
      "trial: 5, iter: 3000, curr loss: 1.3865149021148682, avg loss: 1.3864841622114181\n",
      "trial: 5, iter: 3200, curr loss: 1.38851797580719, avg loss: 1.3863771957159043\n",
      "trial: 5, iter: 3400, curr loss: 1.3867859840393066, avg loss: 1.3864403015375137\n",
      "trial: 5, iter: 3600, curr loss: 1.3854726552963257, avg loss: 1.3863449823856353\n",
      "trial: 5, iter: 3800, curr loss: 1.3866474628448486, avg loss: 1.386383328437805\n",
      "trial: 5, iter: 4000, curr loss: 1.3862911462783813, avg loss: 1.3863450813293456\n",
      "trial: 5, iter: 4200, curr loss: 1.3862873315811157, avg loss: 1.3863797718286515\n",
      "trial: 5, iter: 4400, curr loss: 1.386225938796997, avg loss: 1.3862937021255493\n",
      "trial: 5, iter: 4600, curr loss: 1.3860950469970703, avg loss: 1.3864359563589097\n",
      "trial: 5, iter: 4800, curr loss: 1.3858228921890259, avg loss: 1.3863654190301895\n",
      "trial: 5, iter: 5000, curr loss: 1.385905146598816, avg loss: 1.3863357764482498\n",
      "trial: 5, iter: 5200, curr loss: 1.3872348070144653, avg loss: 1.3863180035352707\n",
      "trial: 5, iter: 5400, curr loss: 1.3862937688827515, avg loss: 1.3863791280984878\n",
      "trial: 5, iter: 5600, curr loss: 1.3869072198867798, avg loss: 1.386335763335228\n",
      "trial: 5, iter: 5800, curr loss: 1.3865087032318115, avg loss: 1.38629973590374\n",
      "trial: 5, iter: 6000, curr loss: 1.3861693143844604, avg loss: 1.3863406455516816\n",
      "trial: 5, iter: 6200, curr loss: 1.3864129781723022, avg loss: 1.3863729071617126\n",
      "trial: 5, ldr: 0.005565650761127472\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0009668750688433647\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3881958723068237, avg loss: 1.3873520284891128\n",
      "trial: 1, iter: 400, curr loss: 1.3882319927215576, avg loss: 1.386720540523529\n",
      "trial: 1, iter: 600, curr loss: 1.3870563507080078, avg loss: 1.3866401660442351\n",
      "trial: 1, iter: 800, curr loss: 1.3856698274612427, avg loss: 1.3865468829870224\n",
      "trial: 1, iter: 1000, curr loss: 1.385604977607727, avg loss: 1.386587329506874\n",
      "trial: 1, iter: 1200, curr loss: 1.3863505125045776, avg loss: 1.3865280330181122\n",
      "trial: 1, iter: 1400, curr loss: 1.388528823852539, avg loss: 1.386400122642517\n",
      "trial: 1, iter: 1600, curr loss: 1.3853777647018433, avg loss: 1.3864579713344574\n",
      "trial: 1, iter: 1800, curr loss: 1.3853939771652222, avg loss: 1.386538446545601\n",
      "trial: 1, iter: 2000, curr loss: 1.384522557258606, avg loss: 1.3865081244707107\n",
      "trial: 1, iter: 2200, curr loss: 1.387317419052124, avg loss: 1.3863756716251374\n",
      "trial: 1, iter: 2400, curr loss: 1.3870251178741455, avg loss: 1.386418389081955\n",
      "trial: 1, iter: 2600, curr loss: 1.3864145278930664, avg loss: 1.386369281411171\n",
      "trial: 1, iter: 2800, curr loss: 1.3856468200683594, avg loss: 1.3863558727502823\n",
      "trial: 1, iter: 3000, curr loss: 1.387308120727539, avg loss: 1.3863886243104935\n",
      "trial: 1, iter: 3200, curr loss: 1.3859297037124634, avg loss: 1.386326720714569\n",
      "trial: 1, iter: 3400, curr loss: 1.3859772682189941, avg loss: 1.3863398998975753\n",
      "trial: 1, iter: 3600, curr loss: 1.3865787982940674, avg loss: 1.3863138896226883\n",
      "trial: 1, iter: 3800, curr loss: 1.386404037475586, avg loss: 1.386342938542366\n",
      "trial: 1, iter: 4000, curr loss: 1.3872343301773071, avg loss: 1.3863015973567963\n",
      "trial: 1, iter: 4200, curr loss: 1.3861786127090454, avg loss: 1.386325675845146\n",
      "trial: 1, iter: 4400, curr loss: 1.386191725730896, avg loss: 1.3863122510910033\n",
      "trial: 1, iter: 4600, curr loss: 1.3859734535217285, avg loss: 1.386300903558731\n",
      "trial: 1, iter: 4800, curr loss: 1.3862864971160889, avg loss: 1.386326374411583\n",
      "trial: 1, iter: 5000, curr loss: 1.3863056898117065, avg loss: 1.3862824219465255\n",
      "trial: 1, iter: 5200, curr loss: 1.386374831199646, avg loss: 1.3863422113656998\n",
      "trial: 1, iter: 5400, curr loss: 1.386439561843872, avg loss: 1.38631146132946\n",
      "trial: 1, iter: 5600, curr loss: 1.3867337703704834, avg loss: 1.386293687224388\n",
      "trial: 1, iter: 5800, curr loss: 1.3863205909729004, avg loss: 1.386262629032135\n",
      "trial: 1, iter: 6000, curr loss: 1.385056495666504, avg loss: 1.38619932949543\n",
      "trial: 1, iter: 6200, curr loss: 1.386398196220398, avg loss: 1.3864411288499832\n",
      "trial: 1, ldr: 0.0021000951528549194\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.387823224067688, avg loss: 1.387543653845787\n",
      "trial: 2, iter: 400, curr loss: 1.3883113861083984, avg loss: 1.3868290239572525\n",
      "trial: 2, iter: 600, curr loss: 1.3860396146774292, avg loss: 1.38661678314209\n",
      "trial: 2, iter: 800, curr loss: 1.3864631652832031, avg loss: 1.3864076161384582\n",
      "trial: 2, iter: 1000, curr loss: 1.3861210346221924, avg loss: 1.3865079736709596\n",
      "trial: 2, iter: 1200, curr loss: 1.386508584022522, avg loss: 1.3865290862321853\n",
      "trial: 2, iter: 1400, curr loss: 1.3841832876205444, avg loss: 1.3865214639902115\n",
      "trial: 2, iter: 1600, curr loss: 1.384898066520691, avg loss: 1.386459560394287\n",
      "trial: 2, iter: 1800, curr loss: 1.3876336812973022, avg loss: 1.3863174158334732\n",
      "trial: 2, iter: 2000, curr loss: 1.3873400688171387, avg loss: 1.3864508140087128\n",
      "trial: 2, iter: 2200, curr loss: 1.3861267566680908, avg loss: 1.3864208418130874\n",
      "trial: 2, iter: 2400, curr loss: 1.3860796689987183, avg loss: 1.386465864777565\n",
      "trial: 2, iter: 2600, curr loss: 1.3861089944839478, avg loss: 1.3864121240377427\n",
      "trial: 2, iter: 2800, curr loss: 1.387977123260498, avg loss: 1.3863294464349747\n",
      "trial: 2, iter: 3000, curr loss: 1.3863189220428467, avg loss: 1.386359092593193\n",
      "trial: 2, iter: 3200, curr loss: 1.3876268863677979, avg loss: 1.3863564044237138\n",
      "trial: 2, iter: 3400, curr loss: 1.385774850845337, avg loss: 1.3863871026039123\n",
      "trial: 2, iter: 3600, curr loss: 1.3855812549591064, avg loss: 1.3863413941860199\n",
      "trial: 2, iter: 3800, curr loss: 1.3862704038619995, avg loss: 1.3863435345888138\n",
      "trial: 2, iter: 4000, curr loss: 1.3863660097122192, avg loss: 1.3863149178028107\n",
      "trial: 2, iter: 4200, curr loss: 1.3871980905532837, avg loss: 1.386324194073677\n",
      "trial: 2, iter: 4400, curr loss: 1.386281967163086, avg loss: 1.3863135522603989\n",
      "trial: 2, iter: 4600, curr loss: 1.3860875368118286, avg loss: 1.3862828332185746\n",
      "trial: 2, iter: 4800, curr loss: 1.3864001035690308, avg loss: 1.3863454008102416\n",
      "trial: 2, iter: 5000, curr loss: 1.3862395286560059, avg loss: 1.3863259303569793\n",
      "trial: 2, iter: 5200, curr loss: 1.3862543106079102, avg loss: 1.3863279658555985\n",
      "trial: 2, iter: 5400, curr loss: 1.385697603225708, avg loss: 1.3863059395551682\n",
      "trial: 2, iter: 5600, curr loss: 1.3864140510559082, avg loss: 1.3863272607326507\n",
      "trial: 2, iter: 5800, curr loss: 1.3860737085342407, avg loss: 1.3863156867027282\n",
      "trial: 2, iter: 6000, curr loss: 1.385783076286316, avg loss: 1.3862647759914397\n",
      "trial: 2, iter: 6200, curr loss: 1.386385440826416, avg loss: 1.3863165587186814\n",
      "trial: 2, ldr: 0.000629322836175561\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3826395273208618, avg loss: 1.3871696537733078\n",
      "trial: 3, iter: 400, curr loss: 1.3844962120056152, avg loss: 1.3867226040363312\n",
      "trial: 3, iter: 600, curr loss: 1.3866117000579834, avg loss: 1.3864863514900208\n",
      "trial: 3, iter: 800, curr loss: 1.3860944509506226, avg loss: 1.3865363383293152\n",
      "trial: 3, iter: 1000, curr loss: 1.3852065801620483, avg loss: 1.3863901787996291\n",
      "trial: 3, iter: 1200, curr loss: 1.3868966102600098, avg loss: 1.3865900862216949\n",
      "trial: 3, iter: 1400, curr loss: 1.3875551223754883, avg loss: 1.3864253067970276\n",
      "trial: 3, iter: 1600, curr loss: 1.386865496635437, avg loss: 1.386365576982498\n",
      "trial: 3, iter: 1800, curr loss: 1.3870729207992554, avg loss: 1.3864311575889587\n",
      "trial: 3, iter: 2000, curr loss: 1.385040283203125, avg loss: 1.3863446187973023\n",
      "trial: 3, iter: 2200, curr loss: 1.3857442140579224, avg loss: 1.386376051902771\n",
      "trial: 3, iter: 2400, curr loss: 1.3863765001296997, avg loss: 1.386409375667572\n",
      "trial: 3, iter: 2600, curr loss: 1.3862583637237549, avg loss: 1.3863694715499877\n",
      "trial: 3, iter: 2800, curr loss: 1.3859515190124512, avg loss: 1.3863683754205705\n",
      "trial: 3, iter: 3000, curr loss: 1.3864644765853882, avg loss: 1.386371950507164\n",
      "trial: 3, iter: 3200, curr loss: 1.3854409456253052, avg loss: 1.3863776922225952\n",
      "trial: 3, iter: 3400, curr loss: 1.3865442276000977, avg loss: 1.3862990760803222\n",
      "trial: 3, iter: 3600, curr loss: 1.386746883392334, avg loss: 1.3863811331987381\n",
      "trial: 3, iter: 3800, curr loss: 1.3867559432983398, avg loss: 1.386388236284256\n",
      "trial: 3, iter: 4000, curr loss: 1.3863074779510498, avg loss: 1.3863408267498016\n",
      "trial: 3, iter: 4200, curr loss: 1.3858071565628052, avg loss: 1.3862737381458283\n",
      "trial: 3, iter: 4400, curr loss: 1.386336088180542, avg loss: 1.3863621550798415\n",
      "trial: 3, iter: 4600, curr loss: 1.3866573572158813, avg loss: 1.3863602709770202\n",
      "trial: 3, iter: 4800, curr loss: 1.3859301805496216, avg loss: 1.3863074666261672\n",
      "trial: 3, iter: 5000, curr loss: 1.3866221904754639, avg loss: 1.3862867099046707\n",
      "trial: 3, iter: 5200, curr loss: 1.3867353200912476, avg loss: 1.3863871455192567\n",
      "trial: 3, iter: 5400, curr loss: 1.3863446712493896, avg loss: 1.3863468050956727\n",
      "trial: 3, iter: 5600, curr loss: 1.386290192604065, avg loss: 1.386311012506485\n",
      "trial: 3, iter: 5800, curr loss: 1.38587486743927, avg loss: 1.3863018953800201\n",
      "trial: 3, iter: 6000, curr loss: 1.3867378234863281, avg loss: 1.3863415813446045\n",
      "trial: 3, iter: 6200, curr loss: 1.3858473300933838, avg loss: 1.38654199719429\n",
      "trial: 3, ldr: -0.004715068731456995\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3858435153961182, avg loss: 1.3873021578788758\n",
      "trial: 4, iter: 400, curr loss: 1.3876875638961792, avg loss: 1.386610088944435\n",
      "trial: 4, iter: 600, curr loss: 1.3863393068313599, avg loss: 1.3865269088745118\n",
      "trial: 4, iter: 800, curr loss: 1.3848406076431274, avg loss: 1.3864240020513534\n",
      "trial: 4, iter: 1000, curr loss: 1.38746178150177, avg loss: 1.3865320312976837\n",
      "trial: 4, iter: 1200, curr loss: 1.3852657079696655, avg loss: 1.3864162158966065\n",
      "trial: 4, iter: 1400, curr loss: 1.3865710496902466, avg loss: 1.3864691883325577\n",
      "trial: 4, iter: 1600, curr loss: 1.385568380355835, avg loss: 1.386470414996147\n",
      "trial: 4, iter: 1800, curr loss: 1.3861500024795532, avg loss: 1.3863758808374405\n",
      "trial: 4, iter: 2000, curr loss: 1.3860254287719727, avg loss: 1.3863407754898072\n",
      "trial: 4, iter: 2200, curr loss: 1.3860363960266113, avg loss: 1.386421115398407\n",
      "trial: 4, iter: 2400, curr loss: 1.3871333599090576, avg loss: 1.386389552950859\n",
      "trial: 4, iter: 2600, curr loss: 1.3861099481582642, avg loss: 1.3863650822639466\n",
      "trial: 4, iter: 2800, curr loss: 1.3865611553192139, avg loss: 1.3864151263237\n",
      "trial: 4, iter: 3000, curr loss: 1.3869638442993164, avg loss: 1.3864190101623535\n",
      "trial: 4, iter: 3200, curr loss: 1.3869240283966064, avg loss: 1.3863571190834045\n",
      "trial: 4, iter: 3400, curr loss: 1.3862168788909912, avg loss: 1.3864300537109375\n",
      "trial: 4, iter: 3600, curr loss: 1.3863046169281006, avg loss: 1.3863840591907501\n",
      "trial: 4, iter: 3800, curr loss: 1.3864867687225342, avg loss: 1.3863176012039184\n",
      "trial: 4, iter: 4000, curr loss: 1.3861433267593384, avg loss: 1.386357929110527\n",
      "trial: 4, iter: 4200, curr loss: 1.386172890663147, avg loss: 1.3863271653652192\n",
      "trial: 4, iter: 4400, curr loss: 1.3862473964691162, avg loss: 1.3863741701841354\n",
      "trial: 4, iter: 4600, curr loss: 1.3865571022033691, avg loss: 1.3863438618183137\n",
      "trial: 4, iter: 4800, curr loss: 1.386531949043274, avg loss: 1.3863372200727462\n",
      "trial: 4, iter: 5000, curr loss: 1.3861361742019653, avg loss: 1.3863599663972854\n",
      "trial: 4, iter: 5200, curr loss: 1.385992407798767, avg loss: 1.3863301599025726\n",
      "trial: 4, iter: 5400, curr loss: 1.3860207796096802, avg loss: 1.3862979513406755\n",
      "trial: 4, iter: 5600, curr loss: 1.386404275894165, avg loss: 1.386375122666359\n",
      "trial: 4, iter: 5800, curr loss: 1.38631010055542, avg loss: 1.3862914055585862\n",
      "trial: 4, iter: 6000, curr loss: 1.3862407207489014, avg loss: 1.3863415265083312\n",
      "trial: 4, iter: 6200, curr loss: 1.3863624334335327, avg loss: 1.386322753429413\n",
      "trial: 4, ldr: 0.001093090744689107\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3836530447006226, avg loss: 1.3872815424203873\n",
      "trial: 5, iter: 400, curr loss: 1.3863763809204102, avg loss: 1.3866698223352432\n",
      "trial: 5, iter: 600, curr loss: 1.3869588375091553, avg loss: 1.3866047310829162\n",
      "trial: 5, iter: 800, curr loss: 1.3866932392120361, avg loss: 1.3865281242132186\n",
      "trial: 5, iter: 1000, curr loss: 1.385855793952942, avg loss: 1.3865253603458405\n",
      "trial: 5, iter: 1200, curr loss: 1.3841551542282104, avg loss: 1.3863931518793107\n",
      "trial: 5, iter: 1400, curr loss: 1.387511968612671, avg loss: 1.3863752478361129\n",
      "trial: 5, iter: 1600, curr loss: 1.3866790533065796, avg loss: 1.3864383959770203\n",
      "trial: 5, iter: 1800, curr loss: 1.387829303741455, avg loss: 1.3863447946310044\n",
      "trial: 5, iter: 2000, curr loss: 1.3873791694641113, avg loss: 1.3864252173900604\n",
      "trial: 5, iter: 2200, curr loss: 1.385939359664917, avg loss: 1.3863561940193176\n",
      "trial: 5, iter: 2400, curr loss: 1.3855071067810059, avg loss: 1.3863997262716294\n",
      "trial: 5, iter: 2600, curr loss: 1.3874777555465698, avg loss: 1.386357865333557\n",
      "trial: 5, iter: 2800, curr loss: 1.3868881464004517, avg loss: 1.3864038252830506\n",
      "trial: 5, iter: 3000, curr loss: 1.386601209640503, avg loss: 1.3864256197214126\n",
      "trial: 5, iter: 3200, curr loss: 1.3867125511169434, avg loss: 1.386347251534462\n",
      "trial: 5, iter: 3400, curr loss: 1.3858323097229004, avg loss: 1.3863327944278716\n",
      "trial: 5, iter: 3600, curr loss: 1.386082410812378, avg loss: 1.3863653421401978\n",
      "trial: 5, iter: 3800, curr loss: 1.386183261871338, avg loss: 1.3863332563638686\n",
      "trial: 5, iter: 4000, curr loss: 1.3860580921173096, avg loss: 1.3863207346200943\n",
      "trial: 5, iter: 4200, curr loss: 1.3863450288772583, avg loss: 1.3863438618183137\n",
      "trial: 5, iter: 4400, curr loss: 1.3863327503204346, avg loss: 1.3863372522592545\n",
      "trial: 5, iter: 4600, curr loss: 1.3862080574035645, avg loss: 1.3863144940137864\n",
      "trial: 5, iter: 4800, curr loss: 1.386048674583435, avg loss: 1.3863138097524643\n",
      "trial: 5, iter: 5000, curr loss: 1.3869160413742065, avg loss: 1.3863322275877\n",
      "trial: 5, iter: 5200, curr loss: 1.3861017227172852, avg loss: 1.386288805603981\n",
      "trial: 5, iter: 5400, curr loss: 1.3866363763809204, avg loss: 1.386335278749466\n",
      "trial: 5, iter: 5600, curr loss: 1.386618733406067, avg loss: 1.3863153451681136\n",
      "trial: 5, iter: 5800, curr loss: 1.3862961530685425, avg loss: 1.386317327618599\n",
      "trial: 5, iter: 6000, curr loss: 1.3865972757339478, avg loss: 1.3862952357530594\n",
      "trial: 5, iter: 6200, curr loss: 1.3862546682357788, avg loss: 1.386303243637085\n",
      "trial: 5, ldr: -0.0007323106401599944\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.0003249741275794804\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.384087324142456, avg loss: 1.3873545360565185\n",
      "trial: 1, iter: 400, curr loss: 1.3848084211349487, avg loss: 1.3866028982400893\n",
      "trial: 1, iter: 600, curr loss: 1.3862472772598267, avg loss: 1.386633648276329\n",
      "trial: 1, iter: 800, curr loss: 1.38787841796875, avg loss: 1.3864577168226242\n",
      "trial: 1, iter: 1000, curr loss: 1.3875352144241333, avg loss: 1.3864807510375976\n",
      "trial: 1, iter: 1200, curr loss: 1.3872665166854858, avg loss: 1.3864413207769395\n",
      "trial: 1, iter: 1400, curr loss: 1.3859304189682007, avg loss: 1.3864554619789125\n",
      "trial: 1, iter: 1600, curr loss: 1.3860031366348267, avg loss: 1.3864569979906083\n",
      "trial: 1, iter: 1800, curr loss: 1.3869699239730835, avg loss: 1.3864137583971023\n",
      "trial: 1, iter: 2000, curr loss: 1.3870357275009155, avg loss: 1.3863684612512588\n",
      "trial: 1, iter: 2200, curr loss: 1.386061191558838, avg loss: 1.3864492470026015\n",
      "trial: 1, iter: 2400, curr loss: 1.386006236076355, avg loss: 1.3864321517944336\n",
      "trial: 1, iter: 2600, curr loss: 1.3861716985702515, avg loss: 1.3864656341075898\n",
      "trial: 1, iter: 2800, curr loss: 1.386525273323059, avg loss: 1.3863438946008682\n",
      "trial: 1, iter: 3000, curr loss: 1.3863401412963867, avg loss: 1.3863810765743256\n",
      "trial: 1, iter: 3200, curr loss: 1.3861340284347534, avg loss: 1.3863497364521027\n",
      "trial: 1, iter: 3400, curr loss: 1.3870223760604858, avg loss: 1.3863468688726426\n",
      "trial: 1, iter: 3600, curr loss: 1.3862825632095337, avg loss: 1.3863592422008515\n",
      "trial: 1, iter: 3800, curr loss: 1.3858479261398315, avg loss: 1.3863215363025665\n",
      "trial: 1, iter: 4000, curr loss: 1.3862671852111816, avg loss: 1.3863844692707061\n",
      "trial: 1, iter: 4200, curr loss: 1.3873674869537354, avg loss: 1.3863595855236053\n",
      "trial: 1, iter: 4400, curr loss: 1.3861888647079468, avg loss: 1.3863772946596145\n",
      "trial: 1, iter: 4600, curr loss: 1.3858369588851929, avg loss: 1.386293026804924\n",
      "trial: 1, iter: 4800, curr loss: 1.3861318826675415, avg loss: 1.3863437682390214\n",
      "trial: 1, iter: 5000, curr loss: 1.3849599361419678, avg loss: 1.3862594616413118\n",
      "trial: 1, iter: 5200, curr loss: 1.3854386806488037, avg loss: 1.3863475447893143\n",
      "trial: 1, iter: 5400, curr loss: 1.386765718460083, avg loss: 1.386322323679924\n",
      "trial: 1, iter: 5600, curr loss: 1.3857618570327759, avg loss: 1.3863556051254273\n",
      "trial: 1, iter: 5800, curr loss: 1.3857777118682861, avg loss: 1.3862898683547973\n",
      "trial: 1, iter: 6000, curr loss: 1.3861678838729858, avg loss: 1.3863409703969956\n",
      "trial: 1, iter: 6200, curr loss: 1.3863126039505005, avg loss: 1.3863163924217223\n",
      "trial: 1, ldr: 0.0008049797033891082\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3893516063690186, avg loss: 1.3872243404388427\n",
      "trial: 2, iter: 400, curr loss: 1.3881080150604248, avg loss: 1.3866914051771164\n",
      "trial: 2, iter: 600, curr loss: 1.3860903978347778, avg loss: 1.3866128396987916\n",
      "trial: 2, iter: 800, curr loss: 1.3861088752746582, avg loss: 1.386480433344841\n",
      "trial: 2, iter: 1000, curr loss: 1.3871192932128906, avg loss: 1.3865674620866775\n",
      "trial: 2, iter: 1200, curr loss: 1.3861435651779175, avg loss: 1.3864034140110015\n",
      "trial: 2, iter: 1400, curr loss: 1.3862055540084839, avg loss: 1.3864158415794372\n",
      "trial: 2, iter: 1600, curr loss: 1.3870022296905518, avg loss: 1.3865793359279632\n",
      "trial: 2, iter: 1800, curr loss: 1.3874125480651855, avg loss: 1.3864300900697708\n",
      "trial: 2, iter: 2000, curr loss: 1.3873921632766724, avg loss: 1.386406443119049\n",
      "trial: 2, iter: 2200, curr loss: 1.3868252038955688, avg loss: 1.3863894212245942\n",
      "trial: 2, iter: 2400, curr loss: 1.3867416381835938, avg loss: 1.386407117843628\n",
      "trial: 2, iter: 2600, curr loss: 1.3858460187911987, avg loss: 1.3863798707723618\n",
      "trial: 2, iter: 2800, curr loss: 1.3859920501708984, avg loss: 1.3863388109207153\n",
      "trial: 2, iter: 3000, curr loss: 1.3859260082244873, avg loss: 1.3864150178432464\n",
      "trial: 2, iter: 3200, curr loss: 1.3869487047195435, avg loss: 1.3863562113046646\n",
      "trial: 2, iter: 3400, curr loss: 1.386431097984314, avg loss: 1.3863602185249329\n",
      "trial: 2, iter: 3600, curr loss: 1.38557767868042, avg loss: 1.3863253128528594\n",
      "trial: 2, iter: 3800, curr loss: 1.3873475790023804, avg loss: 1.3863822221755981\n",
      "trial: 2, iter: 4000, curr loss: 1.3863316774368286, avg loss: 1.386363418698311\n",
      "trial: 2, iter: 4200, curr loss: 1.3871005773544312, avg loss: 1.3863247096538545\n",
      "trial: 2, iter: 4400, curr loss: 1.3863164186477661, avg loss: 1.3863671547174454\n",
      "trial: 2, iter: 4600, curr loss: 1.3864701986312866, avg loss: 1.386343429684639\n",
      "trial: 2, iter: 4800, curr loss: 1.3859375715255737, avg loss: 1.3863071328401566\n",
      "trial: 2, iter: 5000, curr loss: 1.3861916065216064, avg loss: 1.3863407582044602\n",
      "trial: 2, iter: 5200, curr loss: 1.3864643573760986, avg loss: 1.3863004040718079\n",
      "trial: 2, iter: 5400, curr loss: 1.386396050453186, avg loss: 1.386306538581848\n",
      "trial: 2, iter: 5600, curr loss: 1.387005090713501, avg loss: 1.3863036137819291\n",
      "trial: 2, iter: 5800, curr loss: 1.3862125873565674, avg loss: 1.3863762021064758\n",
      "trial: 2, iter: 6000, curr loss: 1.3869868516921997, avg loss: 1.3863271802663804\n",
      "trial: 2, iter: 6200, curr loss: 1.3859353065490723, avg loss: 1.3863062697649002\n",
      "trial: 2, ldr: 0.003667164593935013\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3886263370513916, avg loss: 1.3872801125049592\n",
      "trial: 3, iter: 400, curr loss: 1.3853191137313843, avg loss: 1.3866237580776215\n",
      "trial: 3, iter: 600, curr loss: 1.3878353834152222, avg loss: 1.3865950524806976\n",
      "trial: 3, iter: 800, curr loss: 1.3870363235473633, avg loss: 1.386600524187088\n",
      "trial: 3, iter: 1000, curr loss: 1.3865694999694824, avg loss: 1.386465003490448\n",
      "trial: 3, iter: 1200, curr loss: 1.3855929374694824, avg loss: 1.3863906013965606\n",
      "trial: 3, iter: 1400, curr loss: 1.3852547407150269, avg loss: 1.3864136964082718\n",
      "trial: 3, iter: 1600, curr loss: 1.38723623752594, avg loss: 1.386341786980629\n",
      "trial: 3, iter: 1800, curr loss: 1.3869448900222778, avg loss: 1.3864700347185135\n",
      "trial: 3, iter: 2000, curr loss: 1.3876245021820068, avg loss: 1.386396336555481\n",
      "trial: 3, iter: 2200, curr loss: 1.3862704038619995, avg loss: 1.386408724784851\n",
      "trial: 3, iter: 2400, curr loss: 1.3868945837020874, avg loss: 1.3864862298965455\n",
      "trial: 3, iter: 2600, curr loss: 1.3851560354232788, avg loss: 1.386368417739868\n",
      "trial: 3, iter: 2800, curr loss: 1.3862916231155396, avg loss: 1.3863760578632354\n",
      "trial: 3, iter: 3000, curr loss: 1.3851230144500732, avg loss: 1.3863374251127243\n",
      "trial: 3, iter: 3200, curr loss: 1.3866671323776245, avg loss: 1.386358739733696\n",
      "trial: 3, iter: 3400, curr loss: 1.3863905668258667, avg loss: 1.386357483267784\n",
      "trial: 3, iter: 3600, curr loss: 1.386277437210083, avg loss: 1.3863158184289932\n",
      "trial: 3, iter: 3800, curr loss: 1.3861572742462158, avg loss: 1.3863234382867813\n",
      "trial: 3, iter: 4000, curr loss: 1.386384129524231, avg loss: 1.38634159386158\n",
      "trial: 3, iter: 4200, curr loss: 1.3874435424804688, avg loss: 1.386310413479805\n",
      "trial: 3, iter: 4400, curr loss: 1.3858931064605713, avg loss: 1.3863925963640213\n",
      "trial: 3, iter: 4600, curr loss: 1.3869887590408325, avg loss: 1.3863460808992385\n",
      "trial: 3, iter: 4800, curr loss: 1.3864860534667969, avg loss: 1.3863473325967788\n",
      "trial: 3, iter: 5000, curr loss: 1.3862876892089844, avg loss: 1.3863653481006621\n",
      "trial: 3, iter: 5200, curr loss: 1.3855652809143066, avg loss: 1.3863238829374314\n",
      "trial: 3, iter: 5400, curr loss: 1.3863234519958496, avg loss: 1.3863204163312912\n",
      "trial: 3, iter: 5600, curr loss: 1.3865159749984741, avg loss: 1.3863000786304474\n",
      "trial: 3, iter: 5800, curr loss: 1.3860024213790894, avg loss: 1.3863167369365692\n",
      "trial: 3, iter: 6000, curr loss: 1.385535478591919, avg loss: 1.3862843316793443\n",
      "trial: 3, iter: 6200, curr loss: 1.3859484195709229, avg loss: 1.3863335239887238\n",
      "trial: 3, ldr: -7.185149297583848e-05\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.386572003364563, avg loss: 1.3874315226078033\n",
      "trial: 4, iter: 400, curr loss: 1.3902164697647095, avg loss: 1.386826742887497\n",
      "trial: 4, iter: 600, curr loss: 1.3855372667312622, avg loss: 1.3863817286491393\n",
      "trial: 4, iter: 800, curr loss: 1.3877311944961548, avg loss: 1.3865216338634492\n",
      "trial: 4, iter: 1000, curr loss: 1.3862155675888062, avg loss: 1.3865552979707718\n",
      "trial: 4, iter: 1200, curr loss: 1.3870035409927368, avg loss: 1.3865974992513657\n",
      "trial: 4, iter: 1400, curr loss: 1.3875468969345093, avg loss: 1.386426168680191\n",
      "trial: 4, iter: 1600, curr loss: 1.3862781524658203, avg loss: 1.3864422172307969\n",
      "trial: 4, iter: 1800, curr loss: 1.3870950937271118, avg loss: 1.3863881069421768\n",
      "trial: 4, iter: 2000, curr loss: 1.3869651556015015, avg loss: 1.3863537907600403\n",
      "trial: 4, iter: 2200, curr loss: 1.3861286640167236, avg loss: 1.386377856731415\n",
      "trial: 4, iter: 2400, curr loss: 1.386621356010437, avg loss: 1.3864017307758332\n",
      "trial: 4, iter: 2600, curr loss: 1.385887622833252, avg loss: 1.3863345962762832\n",
      "trial: 4, iter: 2800, curr loss: 1.386183500289917, avg loss: 1.386345539689064\n",
      "trial: 4, iter: 3000, curr loss: 1.3878828287124634, avg loss: 1.386398622393608\n",
      "trial: 4, iter: 3200, curr loss: 1.3855594396591187, avg loss: 1.386403158903122\n",
      "trial: 4, iter: 3400, curr loss: 1.3852418661117554, avg loss: 1.3864258903264999\n",
      "trial: 4, iter: 3600, curr loss: 1.386319875717163, avg loss: 1.386405907869339\n",
      "trial: 4, iter: 3800, curr loss: 1.3862920999526978, avg loss: 1.386384255886078\n",
      "trial: 4, iter: 4000, curr loss: 1.3861364126205444, avg loss: 1.38634925365448\n",
      "trial: 4, iter: 4200, curr loss: 1.3868377208709717, avg loss: 1.3863050359487534\n",
      "trial: 4, iter: 4400, curr loss: 1.3861271142959595, avg loss: 1.3863958007097243\n",
      "trial: 4, iter: 4600, curr loss: 1.386565923690796, avg loss: 1.386315912604332\n",
      "trial: 4, iter: 4800, curr loss: 1.3864696025848389, avg loss: 1.3863284558057785\n",
      "trial: 4, iter: 5000, curr loss: 1.3861230611801147, avg loss: 1.386311458349228\n",
      "trial: 4, iter: 5200, curr loss: 1.3862954378128052, avg loss: 1.3863250362873076\n",
      "trial: 4, iter: 5400, curr loss: 1.3858699798583984, avg loss: 1.3862815660238266\n",
      "trial: 4, iter: 5600, curr loss: 1.3861279487609863, avg loss: 1.386326726078987\n",
      "trial: 4, iter: 5800, curr loss: 1.3862515687942505, avg loss: 1.3863023644685746\n",
      "trial: 4, iter: 6000, curr loss: 1.386397123336792, avg loss: 1.38631680727005\n",
      "trial: 4, iter: 6200, curr loss: 1.3864063024520874, avg loss: 1.386301177740097\n",
      "trial: 4, ldr: 0.00031162184313870966\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3860985040664673, avg loss: 1.3871292161941529\n",
      "trial: 5, iter: 400, curr loss: 1.3881925344467163, avg loss: 1.3865304780006409\n",
      "trial: 5, iter: 600, curr loss: 1.3834768533706665, avg loss: 1.3864937454462052\n",
      "trial: 5, iter: 800, curr loss: 1.386655330657959, avg loss: 1.3864818197488784\n",
      "trial: 5, iter: 1000, curr loss: 1.3871190547943115, avg loss: 1.3864775002002716\n",
      "trial: 5, iter: 1200, curr loss: 1.3872603178024292, avg loss: 1.3863377064466476\n",
      "trial: 5, iter: 1400, curr loss: 1.3858163356781006, avg loss: 1.3865009897947311\n",
      "trial: 5, iter: 1600, curr loss: 1.387284278869629, avg loss: 1.3863420689105987\n",
      "trial: 5, iter: 1800, curr loss: 1.386978268623352, avg loss: 1.3864372372627258\n",
      "trial: 5, iter: 2000, curr loss: 1.3871958255767822, avg loss: 1.3862991720438003\n",
      "trial: 5, iter: 2200, curr loss: 1.3858625888824463, avg loss: 1.3863032424449921\n",
      "trial: 5, iter: 2400, curr loss: 1.3867613077163696, avg loss: 1.386482179760933\n",
      "trial: 5, iter: 2600, curr loss: 1.3861820697784424, avg loss: 1.386387060880661\n",
      "trial: 5, iter: 2800, curr loss: 1.3861663341522217, avg loss: 1.3863506132364274\n",
      "trial: 5, iter: 3000, curr loss: 1.3863401412963867, avg loss: 1.386399169564247\n",
      "trial: 5, iter: 3200, curr loss: 1.3861042261123657, avg loss: 1.3863933902978898\n",
      "trial: 5, iter: 3400, curr loss: 1.387325406074524, avg loss: 1.3863621157407762\n",
      "trial: 5, iter: 3600, curr loss: 1.3865700960159302, avg loss: 1.3863771486282348\n",
      "trial: 5, iter: 3800, curr loss: 1.3869277238845825, avg loss: 1.386378139257431\n",
      "trial: 5, iter: 4000, curr loss: 1.3874456882476807, avg loss: 1.3863872104883195\n",
      "trial: 5, iter: 4200, curr loss: 1.3869925737380981, avg loss: 1.3863532799482345\n",
      "trial: 5, iter: 4400, curr loss: 1.3862859010696411, avg loss: 1.386353070139885\n",
      "trial: 5, iter: 4600, curr loss: 1.386252999305725, avg loss: 1.3863582825660705\n",
      "trial: 5, iter: 4800, curr loss: 1.3863272666931152, avg loss: 1.3863423728942872\n",
      "trial: 5, iter: 5000, curr loss: 1.3867335319519043, avg loss: 1.3863404047489167\n",
      "trial: 5, iter: 5200, curr loss: 1.3868824243545532, avg loss: 1.3863935315608977\n",
      "trial: 5, iter: 5400, curr loss: 1.3867859840393066, avg loss: 1.3863992166519166\n",
      "trial: 5, iter: 5600, curr loss: 1.3872073888778687, avg loss: 1.386384260058403\n",
      "trial: 5, iter: 5800, curr loss: 1.3868328332901, avg loss: 1.3863565391302108\n",
      "trial: 5, iter: 6000, curr loss: 1.3860217332839966, avg loss: 1.3863347578048706\n",
      "trial: 5, iter: 6200, curr loss: 1.3863914012908936, avg loss: 1.3863202494382858\n",
      "trial: 5, ldr: -0.00023254039115272462\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.0008958748512668535\n",
      "Experiment done with data path: ./data/catNon-lin-NI_19/data.20k.dz200.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_2/data.10k.dz10.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3857285976409912, avg loss: 1.3858922386169434\n",
      "trial: 1, iter: 400, curr loss: 1.3180114030838013, avg loss: 1.3641052973270416\n",
      "trial: 1, iter: 600, curr loss: 1.288122534751892, avg loss: 1.315277813076973\n",
      "trial: 1, iter: 800, curr loss: 1.2617511749267578, avg loss: 1.2956677049398422\n",
      "trial: 1, iter: 1000, curr loss: 1.260299563407898, avg loss: 1.2868655109405518\n",
      "trial: 1, iter: 1200, curr loss: 1.263317584991455, avg loss: 1.2822959631681443\n",
      "trial: 1, iter: 1400, curr loss: 1.2989068031311035, avg loss: 1.2805386137962342\n",
      "trial: 1, iter: 1600, curr loss: 1.297217845916748, avg loss: 1.2772203266620636\n",
      "trial: 1, iter: 1800, curr loss: 1.2784810066223145, avg loss: 1.2757141417264939\n",
      "trial: 1, iter: 2000, curr loss: 1.231154203414917, avg loss: 1.271774162054062\n",
      "trial: 1, iter: 2200, curr loss: 1.2621630430221558, avg loss: 1.270997193455696\n",
      "trial: 1, iter: 2400, curr loss: 1.2542952299118042, avg loss: 1.267373153567314\n",
      "trial: 1, iter: 2600, curr loss: 1.2551240921020508, avg loss: 1.2663503128290177\n",
      "trial: 1, iter: 2800, curr loss: 1.2576053142547607, avg loss: 1.263689860701561\n",
      "trial: 1, iter: 3000, curr loss: 1.2518916130065918, avg loss: 1.2626102828979493\n",
      "trial: 1, ldr: 0.1520642191171646\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3771090507507324, avg loss: 1.3855749821662904\n",
      "trial: 2, iter: 400, curr loss: 1.3182175159454346, avg loss: 1.3628352111577988\n",
      "trial: 2, iter: 600, curr loss: 1.2806451320648193, avg loss: 1.318092251420021\n",
      "trial: 2, iter: 800, curr loss: 1.3045263290405273, avg loss: 1.2977274876832963\n",
      "trial: 2, iter: 1000, curr loss: 1.2381051778793335, avg loss: 1.2869219160079957\n",
      "trial: 2, iter: 1200, curr loss: 1.2929984331130981, avg loss: 1.2869947856664659\n",
      "trial: 2, iter: 1400, curr loss: 1.2490679025650024, avg loss: 1.2803728038072586\n",
      "trial: 2, iter: 1600, curr loss: 1.23058021068573, avg loss: 1.2785906767845154\n",
      "trial: 2, iter: 1800, curr loss: 1.2584731578826904, avg loss: 1.2722990167140962\n",
      "trial: 2, iter: 2000, curr loss: 1.2845547199249268, avg loss: 1.271396985054016\n",
      "trial: 2, iter: 2200, curr loss: 1.247950792312622, avg loss: 1.2723822140693664\n",
      "trial: 2, iter: 2400, curr loss: 1.2481130361557007, avg loss: 1.267993032336235\n",
      "trial: 2, iter: 2600, curr loss: 1.2590699195861816, avg loss: 1.2664040398597718\n",
      "trial: 2, iter: 2800, curr loss: 1.2222700119018555, avg loss: 1.2643677973747254\n",
      "trial: 2, iter: 3000, curr loss: 1.2736613750457764, avg loss: 1.2595022237300872\n",
      "trial: 2, ldr: 0.15597710013389587\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3820457458496094, avg loss: 1.3855276560783387\n",
      "trial: 3, iter: 400, curr loss: 1.3671009540557861, avg loss: 1.3671286261081697\n",
      "trial: 3, iter: 600, curr loss: 1.3148133754730225, avg loss: 1.3306741136312485\n",
      "trial: 3, iter: 800, curr loss: 1.2719208002090454, avg loss: 1.3058577305078507\n",
      "trial: 3, iter: 1000, curr loss: 1.3051307201385498, avg loss: 1.2957603496313095\n",
      "trial: 3, iter: 1200, curr loss: 1.2711910009384155, avg loss: 1.291123589873314\n",
      "trial: 3, iter: 1400, curr loss: 1.2648885250091553, avg loss: 1.2859302055835724\n",
      "trial: 3, iter: 1600, curr loss: 1.2007722854614258, avg loss: 1.2774936217069626\n",
      "trial: 3, iter: 1800, curr loss: 1.2793622016906738, avg loss: 1.2784337294101715\n",
      "trial: 3, iter: 2000, curr loss: 1.2769025564193726, avg loss: 1.2756362247467041\n",
      "trial: 3, iter: 2200, curr loss: 1.2699694633483887, avg loss: 1.2728765910863877\n",
      "trial: 3, iter: 2400, curr loss: 1.260565161705017, avg loss: 1.2696599155664443\n",
      "trial: 3, iter: 2600, curr loss: 1.2300972938537598, avg loss: 1.2706175929307937\n",
      "trial: 3, iter: 2800, curr loss: 1.2558749914169312, avg loss: 1.2658806711435318\n",
      "trial: 3, iter: 3000, curr loss: 1.3075470924377441, avg loss: 1.2617612689733506\n",
      "trial: 3, ldr: 0.15271097421646118\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3796290159225464, avg loss: 1.3846463012695311\n",
      "trial: 4, iter: 400, curr loss: 1.3196320533752441, avg loss: 1.351287905573845\n",
      "trial: 4, iter: 600, curr loss: 1.3476601839065552, avg loss: 1.3096767175197601\n",
      "trial: 4, iter: 800, curr loss: 1.2883777618408203, avg loss: 1.2963392853736877\n",
      "trial: 4, iter: 1000, curr loss: 1.2970798015594482, avg loss: 1.2845787572860718\n",
      "trial: 4, iter: 1200, curr loss: 1.2165149450302124, avg loss: 1.281611018180847\n",
      "trial: 4, iter: 1400, curr loss: 1.2420742511749268, avg loss: 1.280327627658844\n",
      "trial: 4, iter: 1600, curr loss: 1.2684499025344849, avg loss: 1.27441547870636\n",
      "trial: 4, iter: 1800, curr loss: 1.268344759941101, avg loss: 1.2752970623970032\n",
      "trial: 4, iter: 2000, curr loss: 1.2559128999710083, avg loss: 1.2713551485538483\n",
      "trial: 4, iter: 2200, curr loss: 1.3354328870773315, avg loss: 1.2706430071592332\n",
      "trial: 4, iter: 2400, curr loss: 1.2583317756652832, avg loss: 1.265747356414795\n",
      "trial: 4, iter: 2600, curr loss: 1.2190592288970947, avg loss: 1.2637924814224244\n",
      "trial: 4, iter: 2800, curr loss: 1.2612732648849487, avg loss: 1.263565679192543\n",
      "trial: 4, iter: 3000, curr loss: 1.268633246421814, avg loss: 1.26169253885746\n",
      "trial: 4, ldr: 0.18085329234600067\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3820217847824097, avg loss: 1.385571613907814\n",
      "trial: 5, iter: 400, curr loss: 1.3683689832687378, avg loss: 1.3693682485818863\n",
      "trial: 5, iter: 600, curr loss: 1.3307133913040161, avg loss: 1.3299172508716584\n",
      "trial: 5, iter: 800, curr loss: 1.297513723373413, avg loss: 1.3047910511493683\n",
      "trial: 5, iter: 1000, curr loss: 1.3267874717712402, avg loss: 1.2928043115139007\n",
      "trial: 5, iter: 1200, curr loss: 1.265681505203247, avg loss: 1.2904029619693755\n",
      "trial: 5, iter: 1400, curr loss: 1.2577033042907715, avg loss: 1.2855083400011063\n",
      "trial: 5, iter: 1600, curr loss: 1.266021490097046, avg loss: 1.2807708436250687\n",
      "trial: 5, iter: 1800, curr loss: 1.295238733291626, avg loss: 1.2795391923189163\n",
      "trial: 5, iter: 2000, curr loss: 1.243524193763733, avg loss: 1.2751327699422836\n",
      "trial: 5, iter: 2200, curr loss: 1.2878224849700928, avg loss: 1.2737545257806777\n",
      "trial: 5, iter: 2400, curr loss: 1.2316272258758545, avg loss: 1.2738695913553237\n",
      "trial: 5, iter: 2600, curr loss: 1.299384593963623, avg loss: 1.2692239248752595\n",
      "trial: 5, iter: 2800, curr loss: 1.242502212524414, avg loss: 1.2686157429218292\n",
      "trial: 5, iter: 3000, curr loss: 1.2339677810668945, avg loss: 1.2680565971136093\n",
      "trial: 5, ldr: 0.1725989133119583\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.16284089982509614\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3803807497024536, avg loss: 1.3847278720140457\n",
      "trial: 1, iter: 400, curr loss: 1.3350977897644043, avg loss: 1.3560968047380448\n",
      "trial: 1, iter: 600, curr loss: 1.3030903339385986, avg loss: 1.3131180441379546\n",
      "trial: 1, iter: 800, curr loss: 1.284336805343628, avg loss: 1.2937153470516205\n",
      "trial: 1, iter: 1000, curr loss: 1.3159306049346924, avg loss: 1.285537495613098\n",
      "trial: 1, iter: 1200, curr loss: 1.2363483905792236, avg loss: 1.279256820678711\n",
      "trial: 1, iter: 1400, curr loss: 1.2967965602874756, avg loss: 1.279358503818512\n",
      "trial: 1, iter: 1600, curr loss: 1.2633644342422485, avg loss: 1.2726928901672363\n",
      "trial: 1, iter: 1800, curr loss: 1.291638970375061, avg loss: 1.2692682653665543\n",
      "trial: 1, iter: 2000, curr loss: 1.2518547773361206, avg loss: 1.267830126285553\n",
      "trial: 1, iter: 2200, curr loss: 1.269071340560913, avg loss: 1.268579113483429\n",
      "trial: 1, iter: 2400, curr loss: 1.2696914672851562, avg loss: 1.262356168627739\n",
      "trial: 1, iter: 2600, curr loss: 1.2562850713729858, avg loss: 1.2628505527973175\n",
      "trial: 1, iter: 2800, curr loss: 1.264683723449707, avg loss: 1.2591617357730867\n",
      "trial: 1, iter: 3000, curr loss: 1.324669361114502, avg loss: 1.2564298075437546\n",
      "trial: 1, ldr: 0.16033262014389038\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3830032348632812, avg loss: 1.3856302815675736\n",
      "trial: 2, iter: 400, curr loss: 1.3537222146987915, avg loss: 1.3626458930969239\n",
      "trial: 2, iter: 600, curr loss: 1.3042526245117188, avg loss: 1.3174606907367705\n",
      "trial: 2, iter: 800, curr loss: 1.302812933921814, avg loss: 1.297891190648079\n",
      "trial: 2, iter: 1000, curr loss: 1.2867138385772705, avg loss: 1.2906777435541152\n",
      "trial: 2, iter: 1200, curr loss: 1.309871792793274, avg loss: 1.2778109353780747\n",
      "trial: 2, iter: 1400, curr loss: 1.241552472114563, avg loss: 1.276929423213005\n",
      "trial: 2, iter: 1600, curr loss: 1.2598204612731934, avg loss: 1.27498517036438\n",
      "trial: 2, iter: 1800, curr loss: 1.2824124097824097, avg loss: 1.2736501038074493\n",
      "trial: 2, iter: 2000, curr loss: 1.302154302597046, avg loss: 1.2723319965600968\n",
      "trial: 2, iter: 2200, curr loss: 1.2475277185440063, avg loss: 1.2664236450195312\n",
      "trial: 2, iter: 2400, curr loss: 1.266555905342102, avg loss: 1.2634356957674027\n",
      "trial: 2, iter: 2600, curr loss: 1.2498316764831543, avg loss: 1.263046656847\n",
      "trial: 2, iter: 2800, curr loss: 1.3112350702285767, avg loss: 1.261395297050476\n",
      "trial: 2, iter: 3000, curr loss: 1.2120094299316406, avg loss: 1.261128644347191\n",
      "trial: 2, ldr: 0.24824343621730804\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3747364282608032, avg loss: 1.3842746365070342\n",
      "trial: 3, iter: 400, curr loss: 1.3327221870422363, avg loss: 1.3550345140695572\n",
      "trial: 3, iter: 600, curr loss: 1.2923221588134766, avg loss: 1.3185202264785767\n",
      "trial: 3, iter: 800, curr loss: 1.2569724321365356, avg loss: 1.297254621386528\n",
      "trial: 3, iter: 1000, curr loss: 1.2932809591293335, avg loss: 1.2910873532295226\n",
      "trial: 3, iter: 1200, curr loss: 1.248619556427002, avg loss: 1.2788243544101716\n",
      "trial: 3, iter: 1400, curr loss: 1.2631937265396118, avg loss: 1.278628563284874\n",
      "trial: 3, iter: 1600, curr loss: 1.2651740312576294, avg loss: 1.2710467708110809\n",
      "trial: 3, iter: 1800, curr loss: 1.2563568353652954, avg loss: 1.2714670568704605\n",
      "trial: 3, iter: 2000, curr loss: 1.2422538995742798, avg loss: 1.270130796432495\n",
      "trial: 3, iter: 2200, curr loss: 1.290271520614624, avg loss: 1.2634637230634689\n",
      "trial: 3, iter: 2400, curr loss: 1.2528077363967896, avg loss: 1.2611053484678267\n",
      "trial: 3, iter: 2600, curr loss: 1.257605791091919, avg loss: 1.2577748221158982\n",
      "trial: 3, iter: 2800, curr loss: 1.2198766469955444, avg loss: 1.25713423371315\n",
      "trial: 3, iter: 3000, curr loss: 1.2607756853103638, avg loss: 1.2554337084293365\n",
      "trial: 3, ldr: 0.18723039329051971\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3804060220718384, avg loss: 1.3854148018360137\n",
      "trial: 4, iter: 400, curr loss: 1.3346222639083862, avg loss: 1.3593617057800294\n",
      "trial: 4, iter: 600, curr loss: 1.3184212446212769, avg loss: 1.3093169540166856\n",
      "trial: 4, iter: 800, curr loss: 1.2848474979400635, avg loss: 1.2940308958292008\n",
      "trial: 4, iter: 1000, curr loss: 1.2400760650634766, avg loss: 1.2875906652212143\n",
      "trial: 4, iter: 1200, curr loss: 1.2713494300842285, avg loss: 1.2790372729301454\n",
      "trial: 4, iter: 1400, curr loss: 1.2932265996932983, avg loss: 1.2755183672904968\n",
      "trial: 4, iter: 1600, curr loss: 1.270102858543396, avg loss: 1.274791906476021\n",
      "trial: 4, iter: 1800, curr loss: 1.3166334629058838, avg loss: 1.269518228173256\n",
      "trial: 4, iter: 2000, curr loss: 1.2432665824890137, avg loss: 1.2695634794235229\n",
      "trial: 4, iter: 2200, curr loss: 1.287717342376709, avg loss: 1.2666195172071457\n",
      "trial: 4, iter: 2400, curr loss: 1.2727930545806885, avg loss: 1.260857959985733\n",
      "trial: 4, iter: 2600, curr loss: 1.2518008947372437, avg loss: 1.2580456411838532\n",
      "trial: 4, iter: 2800, curr loss: 1.2490850687026978, avg loss: 1.25648139834404\n",
      "trial: 4, iter: 3000, curr loss: 1.2611297369003296, avg loss: 1.2552788770198822\n",
      "trial: 4, ldr: 0.23160630464553833\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.380703091621399, avg loss: 1.3857852172851564\n",
      "trial: 5, iter: 400, curr loss: 1.3459980487823486, avg loss: 1.3643922728300095\n",
      "trial: 5, iter: 600, curr loss: 1.321223497390747, avg loss: 1.315439140200615\n",
      "trial: 5, iter: 800, curr loss: 1.300948977470398, avg loss: 1.293976555466652\n",
      "trial: 5, iter: 1000, curr loss: 1.3096024990081787, avg loss: 1.288483117222786\n",
      "trial: 5, iter: 1200, curr loss: 1.2867133617401123, avg loss: 1.282432075738907\n",
      "trial: 5, iter: 1400, curr loss: 1.269113540649414, avg loss: 1.2791224968433381\n",
      "trial: 5, iter: 1600, curr loss: 1.2754713296890259, avg loss: 1.2729638755321502\n",
      "trial: 5, iter: 1800, curr loss: 1.2575405836105347, avg loss: 1.2696359646320343\n",
      "trial: 5, iter: 2000, curr loss: 1.2439298629760742, avg loss: 1.2632153898477554\n",
      "trial: 5, iter: 2200, curr loss: 1.2613654136657715, avg loss: 1.2694482123851776\n",
      "trial: 5, iter: 2400, curr loss: 1.2770557403564453, avg loss: 1.2610296374559402\n",
      "trial: 5, iter: 2600, curr loss: 1.2644898891448975, avg loss: 1.261625583767891\n",
      "trial: 5, iter: 2800, curr loss: 1.2407721281051636, avg loss: 1.2585135048627853\n",
      "trial: 5, iter: 3000, curr loss: 1.3160654306411743, avg loss: 1.2552229142189026\n",
      "trial: 5, ldr: 0.06643449515104294\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.17876944988965987\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3806923627853394, avg loss: 1.3856108742952347\n",
      "trial: 1, iter: 400, curr loss: 1.3377610445022583, avg loss: 1.3589124131202697\n",
      "trial: 1, iter: 600, curr loss: 1.2942991256713867, avg loss: 1.309719933271408\n",
      "trial: 1, iter: 800, curr loss: 1.313694715499878, avg loss: 1.295630049109459\n",
      "trial: 1, iter: 1000, curr loss: 1.2594285011291504, avg loss: 1.289487026333809\n",
      "trial: 1, iter: 1200, curr loss: 1.251959204673767, avg loss: 1.2822456449270248\n",
      "trial: 1, iter: 1400, curr loss: 1.3082960844039917, avg loss: 1.2793278408050537\n",
      "trial: 1, iter: 1600, curr loss: 1.2650699615478516, avg loss: 1.274657478928566\n",
      "trial: 1, iter: 1800, curr loss: 1.3247219324111938, avg loss: 1.2716128712892532\n",
      "trial: 1, iter: 2000, curr loss: 1.2469364404678345, avg loss: 1.266916303038597\n",
      "trial: 1, iter: 2200, curr loss: 1.260768175125122, avg loss: 1.2659935909509659\n",
      "trial: 1, iter: 2400, curr loss: 1.2460942268371582, avg loss: 1.2605427211523057\n",
      "trial: 1, iter: 2600, curr loss: 1.2490273714065552, avg loss: 1.2606377226114274\n",
      "trial: 1, iter: 2800, curr loss: 1.2699096202850342, avg loss: 1.2632988822460174\n",
      "trial: 1, iter: 3000, curr loss: 1.2613929510116577, avg loss: 1.2577400648593902\n",
      "trial: 1, ldr: 0.23146095871925354\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3821097612380981, avg loss: 1.3860662168264388\n",
      "trial: 2, iter: 400, curr loss: 1.3620810508728027, avg loss: 1.3738306337594985\n",
      "trial: 2, iter: 600, curr loss: 1.3080476522445679, avg loss: 1.329696324467659\n",
      "trial: 2, iter: 800, curr loss: 1.2674293518066406, avg loss: 1.3016461104154586\n",
      "trial: 2, iter: 1000, curr loss: 1.2735061645507812, avg loss: 1.29342256963253\n",
      "trial: 2, iter: 1200, curr loss: 1.2673540115356445, avg loss: 1.2888707256317138\n",
      "trial: 2, iter: 1400, curr loss: 1.2694308757781982, avg loss: 1.281658512353897\n",
      "trial: 2, iter: 1600, curr loss: 1.2531648874282837, avg loss: 1.2786065983772277\n",
      "trial: 2, iter: 1800, curr loss: 1.2495341300964355, avg loss: 1.2779047089815139\n",
      "trial: 2, iter: 2000, curr loss: 1.2710309028625488, avg loss: 1.2703102344274522\n",
      "trial: 2, iter: 2200, curr loss: 1.2624473571777344, avg loss: 1.2682739007472992\n",
      "trial: 2, iter: 2400, curr loss: 1.2564994096755981, avg loss: 1.2694658505916596\n",
      "trial: 2, iter: 2600, curr loss: 1.275126576423645, avg loss: 1.265785934329033\n",
      "trial: 2, iter: 2800, curr loss: 1.2557481527328491, avg loss: 1.2590535724163054\n",
      "trial: 2, iter: 3000, curr loss: 1.26352858543396, avg loss: 1.2607208108901977\n",
      "trial: 2, ldr: 0.19812420010566711\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3778589963912964, avg loss: 1.3856830602884294\n",
      "trial: 3, iter: 400, curr loss: 1.356620192527771, avg loss: 1.3661156272888184\n",
      "trial: 3, iter: 600, curr loss: 1.2601314783096313, avg loss: 1.3161700403690337\n",
      "trial: 3, iter: 800, curr loss: 1.3092198371887207, avg loss: 1.299402928352356\n",
      "trial: 3, iter: 1000, curr loss: 1.2501981258392334, avg loss: 1.2878293681144715\n",
      "trial: 3, iter: 1200, curr loss: 1.2997395992279053, avg loss: 1.284415798187256\n",
      "trial: 3, iter: 1400, curr loss: 1.2621766328811646, avg loss: 1.2797962355613708\n",
      "trial: 3, iter: 1600, curr loss: 1.3034809827804565, avg loss: 1.277603994011879\n",
      "trial: 3, iter: 1800, curr loss: 1.2831485271453857, avg loss: 1.276516497731209\n",
      "trial: 3, iter: 2000, curr loss: 1.2703986167907715, avg loss: 1.2706553721427918\n",
      "trial: 3, iter: 2200, curr loss: 1.2489690780639648, avg loss: 1.27417010307312\n",
      "trial: 3, iter: 2400, curr loss: 1.2671031951904297, avg loss: 1.2671784114837648\n",
      "trial: 3, iter: 2600, curr loss: 1.2512943744659424, avg loss: 1.2686368817090987\n",
      "trial: 3, iter: 2800, curr loss: 1.2898647785186768, avg loss: 1.2673349565267562\n",
      "trial: 3, iter: 3000, curr loss: 1.2786548137664795, avg loss: 1.2645301270484923\n",
      "trial: 3, ldr: 0.12039345502853394\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3787436485290527, avg loss: 1.3863079410791397\n",
      "trial: 4, iter: 400, curr loss: 1.338210940361023, avg loss: 1.3605240184068679\n",
      "trial: 4, iter: 600, curr loss: 1.321488857269287, avg loss: 1.308497125506401\n",
      "trial: 4, iter: 800, curr loss: 1.330106258392334, avg loss: 1.294628186225891\n",
      "trial: 4, iter: 1000, curr loss: 1.3165968656539917, avg loss: 1.286626415848732\n",
      "trial: 4, iter: 1200, curr loss: 1.2746583223342896, avg loss: 1.282627009153366\n",
      "trial: 4, iter: 1400, curr loss: 1.2236974239349365, avg loss: 1.2767373251914977\n",
      "trial: 4, iter: 1600, curr loss: 1.2660682201385498, avg loss: 1.275801187157631\n",
      "trial: 4, iter: 1800, curr loss: 1.2979601621627808, avg loss: 1.2718032538890838\n",
      "trial: 4, iter: 2000, curr loss: 1.25687575340271, avg loss: 1.2667430633306502\n",
      "trial: 4, iter: 2200, curr loss: 1.2936451435089111, avg loss: 1.2651076370477676\n",
      "trial: 4, iter: 2400, curr loss: 1.2210958003997803, avg loss: 1.2625603073835372\n",
      "trial: 4, iter: 2600, curr loss: 1.2110011577606201, avg loss: 1.2639173007011413\n",
      "trial: 4, iter: 2800, curr loss: 1.2630789279937744, avg loss: 1.2603771990537644\n",
      "trial: 4, iter: 3000, curr loss: 1.219372272491455, avg loss: 1.2597126042842866\n",
      "trial: 4, ldr: 0.25394207239151\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3809963464736938, avg loss: 1.384814824461937\n",
      "trial: 5, iter: 400, curr loss: 1.3195050954818726, avg loss: 1.3539722818136215\n",
      "trial: 5, iter: 600, curr loss: 1.2996752262115479, avg loss: 1.310690551996231\n",
      "trial: 5, iter: 800, curr loss: 1.3098033666610718, avg loss: 1.2926753240823745\n",
      "trial: 5, iter: 1000, curr loss: 1.282004714012146, avg loss: 1.2856694447994232\n",
      "trial: 5, iter: 1200, curr loss: 1.2851362228393555, avg loss: 1.2812788903713226\n",
      "trial: 5, iter: 1400, curr loss: 1.285470962524414, avg loss: 1.2777236479520797\n",
      "trial: 5, iter: 1600, curr loss: 1.245255470275879, avg loss: 1.2740993309020996\n",
      "trial: 5, iter: 1800, curr loss: 1.2271220684051514, avg loss: 1.2714982491731643\n",
      "trial: 5, iter: 2000, curr loss: 1.2492153644561768, avg loss: 1.2707199680805206\n",
      "trial: 5, iter: 2200, curr loss: 1.2592803239822388, avg loss: 1.2647913736104965\n",
      "trial: 5, iter: 2400, curr loss: 1.2471973896026611, avg loss: 1.266916806101799\n",
      "trial: 5, iter: 2600, curr loss: 1.2673685550689697, avg loss: 1.262022030353546\n",
      "trial: 5, iter: 2800, curr loss: 1.2759137153625488, avg loss: 1.2619342446327209\n",
      "trial: 5, iter: 3000, curr loss: 1.300379753112793, avg loss: 1.2560549926757814\n",
      "trial: 5, ldr: 0.21992698311805725\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20476953387260438\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3845349550247192, avg loss: 1.385487648844719\n",
      "trial: 1, iter: 400, curr loss: 1.3359529972076416, avg loss: 1.3597472262382508\n",
      "trial: 1, iter: 600, curr loss: 1.3106507062911987, avg loss: 1.314936084151268\n",
      "trial: 1, iter: 800, curr loss: 1.2791285514831543, avg loss: 1.2993280488252639\n",
      "trial: 1, iter: 1000, curr loss: 1.288478970527649, avg loss: 1.2907493704557418\n",
      "trial: 1, iter: 1200, curr loss: 1.2852582931518555, avg loss: 1.2860411179065705\n",
      "trial: 1, iter: 1400, curr loss: 1.2540357112884521, avg loss: 1.2771681463718414\n",
      "trial: 1, iter: 1600, curr loss: 1.2898563146591187, avg loss: 1.2770360642671585\n",
      "trial: 1, iter: 1800, curr loss: 1.256460428237915, avg loss: 1.2749358493089675\n",
      "trial: 1, iter: 2000, curr loss: 1.2627211809158325, avg loss: 1.2713775002956391\n",
      "trial: 1, iter: 2200, curr loss: 1.2707105875015259, avg loss: 1.2640411782264709\n",
      "trial: 1, iter: 2400, curr loss: 1.2734243869781494, avg loss: 1.2677160769701004\n",
      "trial: 1, iter: 2600, curr loss: 1.2551162242889404, avg loss: 1.2661039680242538\n",
      "trial: 1, iter: 2800, curr loss: 1.2905712127685547, avg loss: 1.2598269492387772\n",
      "trial: 1, iter: 3000, curr loss: 1.2380964756011963, avg loss: 1.2604833632707595\n",
      "trial: 1, ldr: 0.21152134239673615\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.382712483406067, avg loss: 1.3855751818418502\n",
      "trial: 2, iter: 400, curr loss: 1.3518164157867432, avg loss: 1.3646065545082093\n",
      "trial: 2, iter: 600, curr loss: 1.3081260919570923, avg loss: 1.3205538219213486\n",
      "trial: 2, iter: 800, curr loss: 1.3449698686599731, avg loss: 1.3011611706018449\n",
      "trial: 2, iter: 1000, curr loss: 1.3353687524795532, avg loss: 1.2931992202997207\n",
      "trial: 2, iter: 1200, curr loss: 1.2977855205535889, avg loss: 1.286458842754364\n",
      "trial: 2, iter: 1400, curr loss: 1.2920761108398438, avg loss: 1.2809321975708008\n",
      "trial: 2, iter: 1600, curr loss: 1.294298768043518, avg loss: 1.2773801910877227\n",
      "trial: 2, iter: 1800, curr loss: 1.2367490530014038, avg loss: 1.2775015860795975\n",
      "trial: 2, iter: 2000, curr loss: 1.2551021575927734, avg loss: 1.2704309421777724\n",
      "trial: 2, iter: 2200, curr loss: 1.2844363451004028, avg loss: 1.2704197293519974\n",
      "trial: 2, iter: 2400, curr loss: 1.2118382453918457, avg loss: 1.2685725665092469\n",
      "trial: 2, iter: 2600, curr loss: 1.279911994934082, avg loss: 1.2650467032194137\n",
      "trial: 2, iter: 2800, curr loss: 1.2400710582733154, avg loss: 1.2655913811922073\n",
      "trial: 2, iter: 3000, curr loss: 1.2428683042526245, avg loss: 1.267111361026764\n",
      "trial: 2, ldr: 0.1354445219039917\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3803746700286865, avg loss: 1.385576968193054\n",
      "trial: 3, iter: 400, curr loss: 1.3300102949142456, avg loss: 1.3577741116285325\n",
      "trial: 3, iter: 600, curr loss: 1.3202534914016724, avg loss: 1.3104351443052291\n",
      "trial: 3, iter: 800, curr loss: 1.2873656749725342, avg loss: 1.297192952632904\n",
      "trial: 3, iter: 1000, curr loss: 1.2935786247253418, avg loss: 1.2864756578207015\n",
      "trial: 3, iter: 1200, curr loss: 1.2847305536270142, avg loss: 1.2823549401760101\n",
      "trial: 3, iter: 1400, curr loss: 1.3160532712936401, avg loss: 1.2784299093484879\n",
      "trial: 3, iter: 1600, curr loss: 1.2285758256912231, avg loss: 1.2740384614467621\n",
      "trial: 3, iter: 1800, curr loss: 1.2753764390945435, avg loss: 1.269862259030342\n",
      "trial: 3, iter: 2000, curr loss: 1.2548458576202393, avg loss: 1.2713469702005387\n",
      "trial: 3, iter: 2200, curr loss: 1.247497797012329, avg loss: 1.2667939680814744\n",
      "trial: 3, iter: 2400, curr loss: 1.2860685586929321, avg loss: 1.2642919367551804\n",
      "trial: 3, iter: 2600, curr loss: 1.26793372631073, avg loss: 1.2603561520576476\n",
      "trial: 3, iter: 2800, curr loss: 1.2447816133499146, avg loss: 1.2592299127578734\n",
      "trial: 3, iter: 3000, curr loss: 1.2669743299484253, avg loss: 1.25743577003479\n",
      "trial: 3, ldr: 0.1604730635881424\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3792229890823364, avg loss: 1.3862800770998\n",
      "trial: 4, iter: 400, curr loss: 1.3226804733276367, avg loss: 1.3658665007352828\n",
      "trial: 4, iter: 600, curr loss: 1.3276844024658203, avg loss: 1.3143584388494491\n",
      "trial: 4, iter: 800, curr loss: 1.3158780336380005, avg loss: 1.2964776718616486\n",
      "trial: 4, iter: 1000, curr loss: 1.2676082849502563, avg loss: 1.2876749449968339\n",
      "trial: 4, iter: 1200, curr loss: 1.2995505332946777, avg loss: 1.2797403293848038\n",
      "trial: 4, iter: 1400, curr loss: 1.278584599494934, avg loss: 1.27725977063179\n",
      "trial: 4, iter: 1600, curr loss: 1.2945924997329712, avg loss: 1.2735594874620437\n",
      "trial: 4, iter: 1800, curr loss: 1.2306300401687622, avg loss: 1.2714025342464448\n",
      "trial: 4, iter: 2000, curr loss: 1.2959874868392944, avg loss: 1.2714520037174224\n",
      "trial: 4, iter: 2200, curr loss: 1.252928376197815, avg loss: 1.2655658745765686\n",
      "trial: 4, iter: 2400, curr loss: 1.2610619068145752, avg loss: 1.2623622703552246\n",
      "trial: 4, iter: 2600, curr loss: 1.2625359296798706, avg loss: 1.2636249178647996\n",
      "trial: 4, iter: 2800, curr loss: 1.2360680103302002, avg loss: 1.2573999094963073\n",
      "trial: 4, iter: 3000, curr loss: 1.271756887435913, avg loss: 1.2589361613988876\n",
      "trial: 4, ldr: 0.26079267263412476\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3798890113830566, avg loss: 1.3856643098592758\n",
      "trial: 5, iter: 400, curr loss: 1.3069571256637573, avg loss: 1.3617994701862335\n",
      "trial: 5, iter: 600, curr loss: 1.275370717048645, avg loss: 1.314489212036133\n",
      "trial: 5, iter: 800, curr loss: 1.2915546894073486, avg loss: 1.29566463470459\n",
      "trial: 5, iter: 1000, curr loss: 1.274340271949768, avg loss: 1.2907654410600662\n",
      "trial: 5, iter: 1200, curr loss: 1.2858084440231323, avg loss: 1.2837883675098418\n",
      "trial: 5, iter: 1400, curr loss: 1.2724987268447876, avg loss: 1.2820992428064346\n",
      "trial: 5, iter: 1600, curr loss: 1.279354214668274, avg loss: 1.2777413350343705\n",
      "trial: 5, iter: 1800, curr loss: 1.2909783124923706, avg loss: 1.2730928081274033\n",
      "trial: 5, iter: 2000, curr loss: 1.2572020292282104, avg loss: 1.27226565182209\n",
      "trial: 5, iter: 2200, curr loss: 1.2652593851089478, avg loss: 1.2702967303991317\n",
      "trial: 5, iter: 2400, curr loss: 1.2542009353637695, avg loss: 1.2675706273317338\n",
      "trial: 5, iter: 2600, curr loss: 1.2402727603912354, avg loss: 1.261164898276329\n",
      "trial: 5, iter: 2800, curr loss: 1.2701313495635986, avg loss: 1.2619462424516679\n",
      "trial: 5, iter: 3000, curr loss: 1.2529306411743164, avg loss: 1.2609911847114563\n",
      "trial: 5, ldr: 0.2005622833967209\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.19375877678394318\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3740028142929077, avg loss: 1.384645630121231\n",
      "trial: 1, iter: 400, curr loss: 1.3117283582687378, avg loss: 1.3483443784713744\n",
      "trial: 1, iter: 600, curr loss: 1.280312418937683, avg loss: 1.3053690087795258\n",
      "trial: 1, iter: 800, curr loss: 1.2945576906204224, avg loss: 1.291374735236168\n",
      "trial: 1, iter: 1000, curr loss: 1.3050882816314697, avg loss: 1.2833931279182433\n",
      "trial: 1, iter: 1200, curr loss: 1.3038115501403809, avg loss: 1.280423074364662\n",
      "trial: 1, iter: 1400, curr loss: 1.2743500471115112, avg loss: 1.275874798297882\n",
      "trial: 1, iter: 1600, curr loss: 1.3100073337554932, avg loss: 1.2751429051160812\n",
      "trial: 1, iter: 1800, curr loss: 1.2208870649337769, avg loss: 1.2663126575946808\n",
      "trial: 1, iter: 2000, curr loss: 1.2788965702056885, avg loss: 1.2681188100576402\n",
      "trial: 1, iter: 2200, curr loss: 1.2385367155075073, avg loss: 1.2623874992132187\n",
      "trial: 1, iter: 2400, curr loss: 1.2576043605804443, avg loss: 1.263009859919548\n",
      "trial: 1, iter: 2600, curr loss: 1.26041579246521, avg loss: 1.2608424192667007\n",
      "trial: 1, iter: 2800, curr loss: 1.2723095417022705, avg loss: 1.2561345613002777\n",
      "trial: 1, iter: 3000, curr loss: 1.2744377851486206, avg loss: 1.252943686246872\n",
      "trial: 1, ldr: 0.2318311482667923\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3849126100540161, avg loss: 1.3858958208560943\n",
      "trial: 2, iter: 400, curr loss: 1.3249391317367554, avg loss: 1.360230877995491\n",
      "trial: 2, iter: 600, curr loss: 1.3192342519760132, avg loss: 1.312854009270668\n",
      "trial: 2, iter: 800, curr loss: 1.2785180807113647, avg loss: 1.2954792511463165\n",
      "trial: 2, iter: 1000, curr loss: 1.2832123041152954, avg loss: 1.2881969636678696\n",
      "trial: 2, iter: 1200, curr loss: 1.2835406064987183, avg loss: 1.2811945676803589\n",
      "trial: 2, iter: 1400, curr loss: 1.240924596786499, avg loss: 1.2757619768381119\n",
      "trial: 2, iter: 1600, curr loss: 1.2936506271362305, avg loss: 1.2749087089300155\n",
      "trial: 2, iter: 1800, curr loss: 1.2376378774642944, avg loss: 1.2693803697824477\n",
      "trial: 2, iter: 2000, curr loss: 1.3213019371032715, avg loss: 1.2638261288404464\n",
      "trial: 2, iter: 2200, curr loss: 1.2085239887237549, avg loss: 1.2593762224912644\n",
      "trial: 2, iter: 2400, curr loss: 1.2599753141403198, avg loss: 1.262809088230133\n",
      "trial: 2, iter: 2600, curr loss: 1.2609472274780273, avg loss: 1.2607253926992417\n",
      "trial: 2, iter: 2800, curr loss: 1.2366620302200317, avg loss: 1.2569942289590836\n",
      "trial: 2, iter: 3000, curr loss: 1.265960931777954, avg loss: 1.2545969051122665\n",
      "trial: 2, ldr: 0.23720751702785492\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3818548917770386, avg loss: 1.3855054873228072\n",
      "trial: 3, iter: 400, curr loss: 1.3421717882156372, avg loss: 1.3603041100502014\n",
      "trial: 3, iter: 600, curr loss: 1.30812668800354, avg loss: 1.313102514743805\n",
      "trial: 3, iter: 800, curr loss: 1.2823846340179443, avg loss: 1.2924604523181915\n",
      "trial: 3, iter: 1000, curr loss: 1.2881020307540894, avg loss: 1.286697779893875\n",
      "trial: 3, iter: 1200, curr loss: 1.2481603622436523, avg loss: 1.2796777361631393\n",
      "trial: 3, iter: 1400, curr loss: 1.2683522701263428, avg loss: 1.2764458173513413\n",
      "trial: 3, iter: 1600, curr loss: 1.3303524255752563, avg loss: 1.2731302452087403\n",
      "trial: 3, iter: 1800, curr loss: 1.2837313413619995, avg loss: 1.2709541010856629\n",
      "trial: 3, iter: 2000, curr loss: 1.2503643035888672, avg loss: 1.2693155682086945\n",
      "trial: 3, iter: 2200, curr loss: 1.2533211708068848, avg loss: 1.2654863178730011\n",
      "trial: 3, iter: 2400, curr loss: 1.2934949398040771, avg loss: 1.2658695101737976\n",
      "trial: 3, iter: 2600, curr loss: 1.2683000564575195, avg loss: 1.259876613020897\n",
      "trial: 3, iter: 2800, curr loss: 1.241777777671814, avg loss: 1.2599006330966949\n",
      "trial: 3, iter: 3000, curr loss: 1.2312636375427246, avg loss: 1.2587322717905045\n",
      "trial: 3, ldr: 0.14560185372829437\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3754651546478271, avg loss: 1.3852728366851808\n",
      "trial: 4, iter: 400, curr loss: 1.319899559020996, avg loss: 1.3503430777788161\n",
      "trial: 4, iter: 600, curr loss: 1.2941919565200806, avg loss: 1.304928904771805\n",
      "trial: 4, iter: 800, curr loss: 1.2687267065048218, avg loss: 1.2893395948410034\n",
      "trial: 4, iter: 1000, curr loss: 1.2929450273513794, avg loss: 1.287200517654419\n",
      "trial: 4, iter: 1200, curr loss: 1.3011140823364258, avg loss: 1.2773381835222244\n",
      "trial: 4, iter: 1400, curr loss: 1.2447234392166138, avg loss: 1.2760642957687378\n",
      "trial: 4, iter: 1600, curr loss: 1.2797958850860596, avg loss: 1.2738924407958985\n",
      "trial: 4, iter: 1800, curr loss: 1.254536747932434, avg loss: 1.2693279606103898\n",
      "trial: 4, iter: 2000, curr loss: 1.2427669763565063, avg loss: 1.2666365844011307\n",
      "trial: 4, iter: 2200, curr loss: 1.2595926523208618, avg loss: 1.2653578215837478\n",
      "trial: 4, iter: 2400, curr loss: 1.2837837934494019, avg loss: 1.2622343772649764\n",
      "trial: 4, iter: 2600, curr loss: 1.2967469692230225, avg loss: 1.2629858934879303\n",
      "trial: 4, iter: 2800, curr loss: 1.234625220298767, avg loss: 1.2562866288423538\n",
      "trial: 4, iter: 3000, curr loss: 1.2350198030471802, avg loss: 1.2550099873542786\n",
      "trial: 4, ldr: 0.19009366631507874\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.38192880153656, avg loss: 1.3856423532962798\n",
      "trial: 5, iter: 400, curr loss: 1.3234766721725464, avg loss: 1.3587785309553146\n",
      "trial: 5, iter: 600, curr loss: 1.3401846885681152, avg loss: 1.3099891370534897\n",
      "trial: 5, iter: 800, curr loss: 1.2900222539901733, avg loss: 1.2952997237443924\n",
      "trial: 5, iter: 1000, curr loss: 1.299580454826355, avg loss: 1.2878446489572526\n",
      "trial: 5, iter: 1200, curr loss: 1.279463768005371, avg loss: 1.28349107503891\n",
      "trial: 5, iter: 1400, curr loss: 1.2966996431350708, avg loss: 1.278252666592598\n",
      "trial: 5, iter: 1600, curr loss: 1.2784690856933594, avg loss: 1.2759021568298339\n",
      "trial: 5, iter: 1800, curr loss: 1.2353698015213013, avg loss: 1.274962124824524\n",
      "trial: 5, iter: 2000, curr loss: 1.2869088649749756, avg loss: 1.2696378439664842\n",
      "trial: 5, iter: 2200, curr loss: 1.2783589363098145, avg loss: 1.2695942795276642\n",
      "trial: 5, iter: 2400, curr loss: 1.2359627485275269, avg loss: 1.2643304163217544\n",
      "trial: 5, iter: 2600, curr loss: 1.234763741493225, avg loss: 1.264526010155678\n",
      "trial: 5, iter: 2800, curr loss: 1.2043449878692627, avg loss: 1.2572659373283386\n",
      "trial: 5, iter: 3000, curr loss: 1.2569408416748047, avg loss: 1.2605480533838271\n",
      "trial: 5, ldr: 0.3011815547943115\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.22118314802646638\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3809367418289185, avg loss: 1.384604611992836\n",
      "trial: 1, iter: 400, curr loss: 1.3171977996826172, avg loss: 1.357224002480507\n",
      "trial: 1, iter: 600, curr loss: 1.2926476001739502, avg loss: 1.3100521540641785\n",
      "trial: 1, iter: 800, curr loss: 1.3182191848754883, avg loss: 1.2970006823539735\n",
      "trial: 1, iter: 1000, curr loss: 1.270137071609497, avg loss: 1.2869477725028993\n",
      "trial: 1, iter: 1200, curr loss: 1.2688196897506714, avg loss: 1.2800151467323304\n",
      "trial: 1, iter: 1400, curr loss: 1.3239299058914185, avg loss: 1.2769591474533082\n",
      "trial: 1, iter: 1600, curr loss: 1.2636361122131348, avg loss: 1.2729681223630904\n",
      "trial: 1, iter: 1800, curr loss: 1.265811800956726, avg loss: 1.273803813457489\n",
      "trial: 1, iter: 2000, curr loss: 1.2533094882965088, avg loss: 1.2723028802871703\n",
      "trial: 1, iter: 2200, curr loss: 1.2554019689559937, avg loss: 1.268029762506485\n",
      "trial: 1, iter: 2400, curr loss: 1.2636096477508545, avg loss: 1.2660126954317092\n",
      "trial: 1, iter: 2600, curr loss: 1.2484490871429443, avg loss: 1.2631646919250488\n",
      "trial: 1, iter: 2800, curr loss: 1.2994509935379028, avg loss: 1.2629093307256698\n",
      "trial: 1, iter: 3000, curr loss: 1.2691744565963745, avg loss: 1.2599791210889817\n",
      "trial: 1, ldr: 0.1794428676366806\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.386504888534546, avg loss: 1.3849125027656555\n",
      "trial: 2, iter: 400, curr loss: 1.315498948097229, avg loss: 1.3616915917396546\n",
      "trial: 2, iter: 600, curr loss: 1.3139910697937012, avg loss: 1.3166744846105576\n",
      "trial: 2, iter: 800, curr loss: 1.279253363609314, avg loss: 1.2956300866603851\n",
      "trial: 2, iter: 1000, curr loss: 1.2762428522109985, avg loss: 1.2839456236362456\n",
      "trial: 2, iter: 1200, curr loss: 1.2757152318954468, avg loss: 1.280976068377495\n",
      "trial: 2, iter: 1400, curr loss: 1.262534260749817, avg loss: 1.2753498363494873\n",
      "trial: 2, iter: 1600, curr loss: 1.227443814277649, avg loss: 1.271848509311676\n",
      "trial: 2, iter: 1800, curr loss: 1.2658292055130005, avg loss: 1.2699620997905732\n",
      "trial: 2, iter: 2000, curr loss: 1.2613295316696167, avg loss: 1.270803781747818\n",
      "trial: 2, iter: 2200, curr loss: 1.291107177734375, avg loss: 1.2669130384922027\n",
      "trial: 2, iter: 2400, curr loss: 1.2464520931243896, avg loss: 1.265021751523018\n",
      "trial: 2, iter: 2600, curr loss: 1.2827332019805908, avg loss: 1.2603282088041305\n",
      "trial: 2, iter: 2800, curr loss: 1.2704850435256958, avg loss: 1.258266681432724\n",
      "trial: 2, iter: 3000, curr loss: 1.2774658203125, avg loss: 1.2574717777967452\n",
      "trial: 2, ldr: 0.21530309319496155\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3834551572799683, avg loss: 1.3857760316133498\n",
      "trial: 3, iter: 400, curr loss: 1.3557707071304321, avg loss: 1.3611151671409607\n",
      "trial: 3, iter: 600, curr loss: 1.3088734149932861, avg loss: 1.3121968472003938\n",
      "trial: 3, iter: 800, curr loss: 1.305019736289978, avg loss: 1.2947664296627044\n",
      "trial: 3, iter: 1000, curr loss: 1.2699397802352905, avg loss: 1.2858606207370757\n",
      "trial: 3, iter: 1200, curr loss: 1.2971508502960205, avg loss: 1.277192172408104\n",
      "trial: 3, iter: 1400, curr loss: 1.2709113359451294, avg loss: 1.2765286594629288\n",
      "trial: 3, iter: 1600, curr loss: 1.2488739490509033, avg loss: 1.2697365683317186\n",
      "trial: 3, iter: 1800, curr loss: 1.2648930549621582, avg loss: 1.2663665366172792\n",
      "trial: 3, iter: 2000, curr loss: 1.2576533555984497, avg loss: 1.2635218834877013\n",
      "trial: 3, iter: 2200, curr loss: 1.2990885972976685, avg loss: 1.2590461593866349\n",
      "trial: 3, iter: 2400, curr loss: 1.2493624687194824, avg loss: 1.2602615612745285\n",
      "trial: 3, iter: 2600, curr loss: 1.2993491888046265, avg loss: 1.2549590998888016\n",
      "trial: 3, iter: 2800, curr loss: 1.2894684076309204, avg loss: 1.2524057322740554\n",
      "trial: 3, iter: 3000, curr loss: 1.2617971897125244, avg loss: 1.252596178650856\n",
      "trial: 3, ldr: 0.22600041329860687\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3844826221466064, avg loss: 1.3844210779666901\n",
      "trial: 4, iter: 400, curr loss: 1.3335459232330322, avg loss: 1.3536360305547714\n",
      "trial: 4, iter: 600, curr loss: 1.2960312366485596, avg loss: 1.3106892257928848\n",
      "trial: 4, iter: 800, curr loss: 1.2887815237045288, avg loss: 1.2969759094715119\n",
      "trial: 4, iter: 1000, curr loss: 1.2695369720458984, avg loss: 1.2905091124773025\n",
      "trial: 4, iter: 1200, curr loss: 1.2912544012069702, avg loss: 1.2830925339460373\n",
      "trial: 4, iter: 1400, curr loss: 1.3357492685317993, avg loss: 1.2799704492092132\n",
      "trial: 4, iter: 1600, curr loss: 1.28865385055542, avg loss: 1.2746416133642198\n",
      "trial: 4, iter: 1800, curr loss: 1.2505433559417725, avg loss: 1.2703724002838135\n",
      "trial: 4, iter: 2000, curr loss: 1.2477054595947266, avg loss: 1.2687018567323685\n",
      "trial: 4, iter: 2200, curr loss: 1.2526851892471313, avg loss: 1.2659286665916443\n",
      "trial: 4, iter: 2400, curr loss: 1.2707575559616089, avg loss: 1.2651067489385606\n",
      "trial: 4, iter: 2600, curr loss: 1.2635868787765503, avg loss: 1.2617972230911254\n",
      "trial: 4, iter: 2800, curr loss: 1.266471266746521, avg loss: 1.2579524141550065\n",
      "trial: 4, iter: 3000, curr loss: 1.2810555696487427, avg loss: 1.2585615336894989\n",
      "trial: 4, ldr: 0.20100730657577515\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3839054107666016, avg loss: 1.3854673552513121\n",
      "trial: 5, iter: 400, curr loss: 1.3400275707244873, avg loss: 1.3694387608766556\n",
      "trial: 5, iter: 600, curr loss: 1.315946102142334, avg loss: 1.3251798713207246\n",
      "trial: 5, iter: 800, curr loss: 1.2830760478973389, avg loss: 1.2989008808135987\n",
      "trial: 5, iter: 1000, curr loss: 1.2728960514068604, avg loss: 1.291027939915657\n",
      "trial: 5, iter: 1200, curr loss: 1.2906616926193237, avg loss: 1.2848754811286927\n",
      "trial: 5, iter: 1400, curr loss: 1.2700761556625366, avg loss: 1.2804615330696105\n",
      "trial: 5, iter: 1600, curr loss: 1.2899986505508423, avg loss: 1.2754391676187515\n",
      "trial: 5, iter: 1800, curr loss: 1.223446011543274, avg loss: 1.2740585386753083\n",
      "trial: 5, iter: 2000, curr loss: 1.342441439628601, avg loss: 1.268089135289192\n",
      "trial: 5, iter: 2200, curr loss: 1.280776023864746, avg loss: 1.2691548585891723\n",
      "trial: 5, iter: 2400, curr loss: 1.2729904651641846, avg loss: 1.2620901107788085\n",
      "trial: 5, iter: 2600, curr loss: 1.256271481513977, avg loss: 1.260717459321022\n",
      "trial: 5, iter: 2800, curr loss: 1.272247314453125, avg loss: 1.2616200369596482\n",
      "trial: 5, iter: 3000, curr loss: 1.2705655097961426, avg loss: 1.2553655856847763\n",
      "trial: 5, ldr: 0.2094336450099945\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20623746514320374\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3908060789108276, avg loss: 1.3860853451490402\n",
      "trial: 1, iter: 400, curr loss: 1.3578979969024658, avg loss: 1.3691941583156586\n",
      "trial: 1, iter: 600, curr loss: 1.3159220218658447, avg loss: 1.3232608485221862\n",
      "trial: 1, iter: 800, curr loss: 1.2825028896331787, avg loss: 1.299326446056366\n",
      "trial: 1, iter: 1000, curr loss: 1.3011115789413452, avg loss: 1.290940454006195\n",
      "trial: 1, iter: 1200, curr loss: 1.3037190437316895, avg loss: 1.2876143914461136\n",
      "trial: 1, iter: 1400, curr loss: 1.2614775896072388, avg loss: 1.2821018731594085\n",
      "trial: 1, iter: 1600, curr loss: 1.2623573541641235, avg loss: 1.2759299516677856\n",
      "trial: 1, iter: 1800, curr loss: 1.2470422983169556, avg loss: 1.2757840913534164\n",
      "trial: 1, iter: 2000, curr loss: 1.292142391204834, avg loss: 1.270286239385605\n",
      "trial: 1, iter: 2200, curr loss: 1.2500650882720947, avg loss: 1.2692159932851792\n",
      "trial: 1, iter: 2400, curr loss: 1.2657831907272339, avg loss: 1.2698546952009202\n",
      "trial: 1, iter: 2600, curr loss: 1.271160364151001, avg loss: 1.2662774920463562\n",
      "trial: 1, iter: 2800, curr loss: 1.2986716032028198, avg loss: 1.2661151772737502\n",
      "trial: 1, iter: 3000, curr loss: 1.2955046892166138, avg loss: 1.2628921926021577\n",
      "trial: 1, ldr: 0.18351636826992035\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3782559633255005, avg loss: 1.3851362764835358\n",
      "trial: 2, iter: 400, curr loss: 1.3342336416244507, avg loss: 1.3665340155363084\n",
      "trial: 2, iter: 600, curr loss: 1.3119926452636719, avg loss: 1.322499351501465\n",
      "trial: 2, iter: 800, curr loss: 1.2640838623046875, avg loss: 1.2998238587379456\n",
      "trial: 2, iter: 1000, curr loss: 1.2852423191070557, avg loss: 1.2910211777687073\n",
      "trial: 2, iter: 1200, curr loss: 1.2905274629592896, avg loss: 1.2849433350563049\n",
      "trial: 2, iter: 1400, curr loss: 1.2579171657562256, avg loss: 1.2775284999608993\n",
      "trial: 2, iter: 1600, curr loss: 1.2705879211425781, avg loss: 1.2751595360040664\n",
      "trial: 2, iter: 1800, curr loss: 1.265773892402649, avg loss: 1.272740688920021\n",
      "trial: 2, iter: 2000, curr loss: 1.299239993095398, avg loss: 1.2671414995193482\n",
      "trial: 2, iter: 2200, curr loss: 1.252480149269104, avg loss: 1.2684270203113557\n",
      "trial: 2, iter: 2400, curr loss: 1.286057710647583, avg loss: 1.2651027417182923\n",
      "trial: 2, iter: 2600, curr loss: 1.2748159170150757, avg loss: 1.2611852097511291\n",
      "trial: 2, iter: 2800, curr loss: 1.2361949682235718, avg loss: 1.2581170511245727\n",
      "trial: 2, iter: 3000, curr loss: 1.2813719511032104, avg loss: 1.2594997191429138\n",
      "trial: 2, ldr: 0.15949177742004395\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3840901851654053, avg loss: 1.3851993292570115\n",
      "trial: 3, iter: 400, curr loss: 1.3584026098251343, avg loss: 1.3715244716405868\n",
      "trial: 3, iter: 600, curr loss: 1.3160455226898193, avg loss: 1.333432104587555\n",
      "trial: 3, iter: 800, curr loss: 1.3119902610778809, avg loss: 1.306809471845627\n",
      "trial: 3, iter: 1000, curr loss: 1.311859130859375, avg loss: 1.2920564800500869\n",
      "trial: 3, iter: 1200, curr loss: 1.3170939683914185, avg loss: 1.2853207433223723\n",
      "trial: 3, iter: 1400, curr loss: 1.2766194343566895, avg loss: 1.2828238141536712\n",
      "trial: 3, iter: 1600, curr loss: 1.2586729526519775, avg loss: 1.272750004529953\n",
      "trial: 3, iter: 1800, curr loss: 1.2651673555374146, avg loss: 1.27453289270401\n",
      "trial: 3, iter: 2000, curr loss: 1.262538194656372, avg loss: 1.2713130867481233\n",
      "trial: 3, iter: 2200, curr loss: 1.242627501487732, avg loss: 1.2676000773906708\n",
      "trial: 3, iter: 2400, curr loss: 1.2711365222930908, avg loss: 1.2668618285655975\n",
      "trial: 3, iter: 2600, curr loss: 1.2442361116409302, avg loss: 1.264402151107788\n",
      "trial: 3, iter: 2800, curr loss: 1.282204270362854, avg loss: 1.2641448521614074\n",
      "trial: 3, iter: 3000, curr loss: 1.2686657905578613, avg loss: 1.2604801559448242\n",
      "trial: 3, ldr: 0.20191149413585663\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3784537315368652, avg loss: 1.385136747956276\n",
      "trial: 4, iter: 400, curr loss: 1.3421545028686523, avg loss: 1.3597649127244948\n",
      "trial: 4, iter: 600, curr loss: 1.275863528251648, avg loss: 1.3168705236911773\n",
      "trial: 4, iter: 800, curr loss: 1.2819596529006958, avg loss: 1.2994489187002183\n",
      "trial: 4, iter: 1000, curr loss: 1.2977129220962524, avg loss: 1.2929763853549958\n",
      "trial: 4, iter: 1200, curr loss: 1.311525583267212, avg loss: 1.2883112162351609\n",
      "trial: 4, iter: 1400, curr loss: 1.2996563911437988, avg loss: 1.2806630086898805\n",
      "trial: 4, iter: 1600, curr loss: 1.268092155456543, avg loss: 1.2765357154607773\n",
      "trial: 4, iter: 1800, curr loss: 1.2559535503387451, avg loss: 1.2768351835012437\n",
      "trial: 4, iter: 2000, curr loss: 1.2580382823944092, avg loss: 1.2721311086416245\n",
      "trial: 4, iter: 2200, curr loss: 1.3401942253112793, avg loss: 1.2697662967443466\n",
      "trial: 4, iter: 2400, curr loss: 1.2822779417037964, avg loss: 1.2717393654584885\n",
      "trial: 4, iter: 2600, curr loss: 1.2906445264816284, avg loss: 1.2678865712881089\n",
      "trial: 4, iter: 2800, curr loss: 1.2969512939453125, avg loss: 1.261586571931839\n",
      "trial: 4, iter: 3000, curr loss: 1.217617392539978, avg loss: 1.2612995833158493\n",
      "trial: 4, ldr: 0.20060886442661285\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3866839408874512, avg loss: 1.3861572968959808\n",
      "trial: 5, iter: 400, curr loss: 1.3469454050064087, avg loss: 1.3752175104618072\n",
      "trial: 5, iter: 600, curr loss: 1.3407758474349976, avg loss: 1.338275859951973\n",
      "trial: 5, iter: 800, curr loss: 1.297930359840393, avg loss: 1.3063888430595398\n",
      "trial: 5, iter: 1000, curr loss: 1.2671127319335938, avg loss: 1.2928767275810242\n",
      "trial: 5, iter: 1200, curr loss: 1.2554337978363037, avg loss: 1.2862302988767624\n",
      "trial: 5, iter: 1400, curr loss: 1.2868496179580688, avg loss: 1.2789892828464509\n",
      "trial: 5, iter: 1600, curr loss: 1.2842004299163818, avg loss: 1.276159982085228\n",
      "trial: 5, iter: 1800, curr loss: 1.3117663860321045, avg loss: 1.2755525135993957\n",
      "trial: 5, iter: 2000, curr loss: 1.2912049293518066, avg loss: 1.2733997946977615\n",
      "trial: 5, iter: 2200, curr loss: 1.2958014011383057, avg loss: 1.2681967580318452\n",
      "trial: 5, iter: 2400, curr loss: 1.2931880950927734, avg loss: 1.2677539110183715\n",
      "trial: 5, iter: 2600, curr loss: 1.2233378887176514, avg loss: 1.2642506569623948\n",
      "trial: 5, iter: 2800, curr loss: 1.2753450870513916, avg loss: 1.262429228425026\n",
      "trial: 5, iter: 3000, curr loss: 1.2548269033432007, avg loss: 1.2604472064971923\n",
      "trial: 5, ldr: 0.29666218161582947\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.20843813717365264\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.381964921951294, avg loss: 1.3860151374340057\n",
      "trial: 1, iter: 400, curr loss: 1.3506380319595337, avg loss: 1.3693625986576081\n",
      "trial: 1, iter: 600, curr loss: 1.298754096031189, avg loss: 1.3154813641309737\n",
      "trial: 1, iter: 800, curr loss: 1.3356508016586304, avg loss: 1.2989036929607392\n",
      "trial: 1, iter: 1000, curr loss: 1.2710905075073242, avg loss: 1.2904263162612915\n",
      "trial: 1, iter: 1200, curr loss: 1.2933698892593384, avg loss: 1.2845405668020249\n",
      "trial: 1, iter: 1400, curr loss: 1.2767785787582397, avg loss: 1.2809401434659957\n",
      "trial: 1, iter: 1600, curr loss: 1.2708649635314941, avg loss: 1.2801620864868164\n",
      "trial: 1, iter: 1800, curr loss: 1.2608275413513184, avg loss: 1.2729214906692505\n",
      "trial: 1, iter: 2000, curr loss: 1.276887059211731, avg loss: 1.273764575123787\n",
      "trial: 1, iter: 2200, curr loss: 1.2693443298339844, avg loss: 1.26882846057415\n",
      "trial: 1, iter: 2400, curr loss: 1.2508295774459839, avg loss: 1.2648475486040116\n",
      "trial: 1, iter: 2600, curr loss: 1.252484679222107, avg loss: 1.2657333290576935\n",
      "trial: 1, iter: 2800, curr loss: 1.244897723197937, avg loss: 1.2608678913116456\n",
      "trial: 1, iter: 3000, curr loss: 1.233712911605835, avg loss: 1.2587789952754975\n",
      "trial: 1, ldr: 0.17460119724273682\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.389628291130066, avg loss: 1.3868191754817962\n",
      "trial: 2, iter: 400, curr loss: 1.3626534938812256, avg loss: 1.3775140947103501\n",
      "trial: 2, iter: 600, curr loss: 1.3149975538253784, avg loss: 1.3339265447854995\n",
      "trial: 2, iter: 800, curr loss: 1.2649788856506348, avg loss: 1.3054321283102035\n",
      "trial: 2, iter: 1000, curr loss: 1.2757140398025513, avg loss: 1.295128864645958\n",
      "trial: 2, iter: 1200, curr loss: 1.2597551345825195, avg loss: 1.2868632555007935\n",
      "trial: 2, iter: 1400, curr loss: 1.295727014541626, avg loss: 1.2837756723165512\n",
      "trial: 2, iter: 1600, curr loss: 1.3398942947387695, avg loss: 1.2796427369117738\n",
      "trial: 2, iter: 1800, curr loss: 1.2577143907546997, avg loss: 1.275349156856537\n",
      "trial: 2, iter: 2000, curr loss: 1.2251569032669067, avg loss: 1.2722924345731734\n",
      "trial: 2, iter: 2200, curr loss: 1.2906907796859741, avg loss: 1.2715945386886596\n",
      "trial: 2, iter: 2400, curr loss: 1.2793419361114502, avg loss: 1.2661418670415878\n",
      "trial: 2, iter: 2600, curr loss: 1.2584844827651978, avg loss: 1.2627077507972717\n",
      "trial: 2, iter: 2800, curr loss: 1.2879403829574585, avg loss: 1.263168283700943\n",
      "trial: 2, iter: 3000, curr loss: 1.2855960130691528, avg loss: 1.2622072076797486\n",
      "trial: 2, ldr: 0.21960647404193878\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3880432844161987, avg loss: 1.3868966162204743\n",
      "trial: 3, iter: 400, curr loss: 1.3703818321228027, avg loss: 1.3784561163187028\n",
      "trial: 3, iter: 600, curr loss: 1.3378044366836548, avg loss: 1.3470641088485718\n",
      "trial: 3, iter: 800, curr loss: 1.3267416954040527, avg loss: 1.3128571766614914\n",
      "trial: 3, iter: 1000, curr loss: 1.285157561302185, avg loss: 1.3001615530252457\n",
      "trial: 3, iter: 1200, curr loss: 1.2722525596618652, avg loss: 1.2920081043243408\n",
      "trial: 3, iter: 1400, curr loss: 1.2937002182006836, avg loss: 1.2899752181768418\n",
      "trial: 3, iter: 1600, curr loss: 1.303607702255249, avg loss: 1.2811177307367325\n",
      "trial: 3, iter: 1800, curr loss: 1.2980858087539673, avg loss: 1.2784310030937194\n",
      "trial: 3, iter: 2000, curr loss: 1.2362120151519775, avg loss: 1.2778488302230835\n",
      "trial: 3, iter: 2200, curr loss: 1.2613474130630493, avg loss: 1.2754925256967544\n",
      "trial: 3, iter: 2400, curr loss: 1.2506258487701416, avg loss: 1.2714080476760865\n",
      "trial: 3, iter: 2600, curr loss: 1.2445728778839111, avg loss: 1.2680766135454178\n",
      "trial: 3, iter: 2800, curr loss: 1.2867881059646606, avg loss: 1.2707219016551972\n",
      "trial: 3, iter: 3000, curr loss: 1.28299880027771, avg loss: 1.2661079132556916\n",
      "trial: 3, ldr: 0.09303761273622513\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3785107135772705, avg loss: 1.3861245501041413\n",
      "trial: 4, iter: 400, curr loss: 1.2946025133132935, avg loss: 1.355755376815796\n",
      "trial: 4, iter: 600, curr loss: 1.3062169551849365, avg loss: 1.3088424170017243\n",
      "trial: 4, iter: 800, curr loss: 1.332263708114624, avg loss: 1.2979984438419343\n",
      "trial: 4, iter: 1000, curr loss: 1.2721202373504639, avg loss: 1.2881202858686447\n",
      "trial: 4, iter: 1200, curr loss: 1.2529566287994385, avg loss: 1.284038828611374\n",
      "trial: 4, iter: 1400, curr loss: 1.2849572896957397, avg loss: 1.276281179189682\n",
      "trial: 4, iter: 1600, curr loss: 1.2677745819091797, avg loss: 1.2785305595397949\n",
      "trial: 4, iter: 1800, curr loss: 1.2648638486862183, avg loss: 1.2742643135786056\n",
      "trial: 4, iter: 2000, curr loss: 1.276852011680603, avg loss: 1.271986026763916\n",
      "trial: 4, iter: 2200, curr loss: 1.2597041130065918, avg loss: 1.2708174431324004\n",
      "trial: 4, iter: 2400, curr loss: 1.2788300514221191, avg loss: 1.2695815187692643\n",
      "trial: 4, iter: 2600, curr loss: 1.2592365741729736, avg loss: 1.2670051795244217\n",
      "trial: 4, iter: 2800, curr loss: 1.2567555904388428, avg loss: 1.26313201546669\n",
      "trial: 4, iter: 3000, curr loss: 1.2450239658355713, avg loss: 1.2610893642902374\n",
      "trial: 4, ldr: 0.06579834222793579\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3844208717346191, avg loss: 1.3859794622659682\n",
      "trial: 5, iter: 400, curr loss: 1.3741751909255981, avg loss: 1.3766605454683303\n",
      "trial: 5, iter: 600, curr loss: 1.3021329641342163, avg loss: 1.3426051145792008\n",
      "trial: 5, iter: 800, curr loss: 1.2772712707519531, avg loss: 1.3120051604509353\n",
      "trial: 5, iter: 1000, curr loss: 1.3082759380340576, avg loss: 1.2977709233760835\n",
      "trial: 5, iter: 1200, curr loss: 1.2863863706588745, avg loss: 1.2915967804193498\n",
      "trial: 5, iter: 1400, curr loss: 1.3052730560302734, avg loss: 1.2852195608615875\n",
      "trial: 5, iter: 1600, curr loss: 1.2797410488128662, avg loss: 1.2812925285100938\n",
      "trial: 5, iter: 1800, curr loss: 1.2797869443893433, avg loss: 1.2777078592777251\n",
      "trial: 5, iter: 2000, curr loss: 1.2489126920700073, avg loss: 1.27208447098732\n",
      "trial: 5, iter: 2200, curr loss: 1.3058514595031738, avg loss: 1.2733047962188722\n",
      "trial: 5, iter: 2400, curr loss: 1.269095540046692, avg loss: 1.2675054824352265\n",
      "trial: 5, iter: 2600, curr loss: 1.2346686124801636, avg loss: 1.2679351681470872\n",
      "trial: 5, iter: 2800, curr loss: 1.3089616298675537, avg loss: 1.2659951412677766\n",
      "trial: 5, iter: 3000, curr loss: 1.2683968544006348, avg loss: 1.2664692628383636\n",
      "trial: 5, ldr: 0.13574565947055817\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.13775785714387895\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3814202547073364, avg loss: 1.384768135547638\n",
      "trial: 1, iter: 400, curr loss: 1.3521465063095093, avg loss: 1.3516405886411667\n",
      "trial: 1, iter: 600, curr loss: 1.2708690166473389, avg loss: 1.3102770787477493\n",
      "trial: 1, iter: 800, curr loss: 1.3002318143844604, avg loss: 1.296405953168869\n",
      "trial: 1, iter: 1000, curr loss: 1.312300205230713, avg loss: 1.2900132381916045\n",
      "trial: 1, iter: 1200, curr loss: 1.249992847442627, avg loss: 1.2822653752565385\n",
      "trial: 1, iter: 1400, curr loss: 1.2866482734680176, avg loss: 1.2784198606014252\n",
      "trial: 1, iter: 1600, curr loss: 1.2828409671783447, avg loss: 1.2745293205976487\n",
      "trial: 1, iter: 1800, curr loss: 1.2863796949386597, avg loss: 1.2708358424901962\n",
      "trial: 1, iter: 2000, curr loss: 1.2494159936904907, avg loss: 1.2684311962127686\n",
      "trial: 1, iter: 2200, curr loss: 1.249186396598816, avg loss: 1.2675778043270112\n",
      "trial: 1, iter: 2400, curr loss: 1.2896684408187866, avg loss: 1.2661804056167603\n",
      "trial: 1, iter: 2600, curr loss: 1.221215844154358, avg loss: 1.2632520931959152\n",
      "trial: 1, iter: 2800, curr loss: 1.2647125720977783, avg loss: 1.2608883845806123\n",
      "trial: 1, iter: 3000, curr loss: 1.2534106969833374, avg loss: 1.2626006627082824\n",
      "trial: 1, ldr: 0.1870882511138916\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3798857927322388, avg loss: 1.386631526350975\n",
      "trial: 2, iter: 400, curr loss: 1.3766463994979858, avg loss: 1.3748016083240509\n",
      "trial: 2, iter: 600, curr loss: 1.3319233655929565, avg loss: 1.331606742143631\n",
      "trial: 2, iter: 800, curr loss: 1.3182123899459839, avg loss: 1.3057509380578995\n",
      "trial: 2, iter: 1000, curr loss: 1.2879141569137573, avg loss: 1.2953562235832214\n",
      "trial: 2, iter: 1200, curr loss: 1.2823269367218018, avg loss: 1.2918184155225754\n",
      "trial: 2, iter: 1400, curr loss: 1.2755389213562012, avg loss: 1.2827624982595445\n",
      "trial: 2, iter: 1600, curr loss: 1.261535406112671, avg loss: 1.2795742571353912\n",
      "trial: 2, iter: 1800, curr loss: 1.2804895639419556, avg loss: 1.2767741942405701\n",
      "trial: 2, iter: 2000, curr loss: 1.2702715396881104, avg loss: 1.2716461384296418\n",
      "trial: 2, iter: 2200, curr loss: 1.26137113571167, avg loss: 1.2709492915868759\n",
      "trial: 2, iter: 2400, curr loss: 1.2271668910980225, avg loss: 1.268635264635086\n",
      "trial: 2, iter: 2600, curr loss: 1.2559382915496826, avg loss: 1.2644080704450607\n",
      "trial: 2, iter: 2800, curr loss: 1.2227510213851929, avg loss: 1.2590249061584473\n",
      "trial: 2, iter: 3000, curr loss: 1.3109428882598877, avg loss: 1.2601644718647003\n",
      "trial: 2, ldr: 0.12185225635766983\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3822575807571411, avg loss: 1.3857276743650437\n",
      "trial: 3, iter: 400, curr loss: 1.3506470918655396, avg loss: 1.3611920171976089\n",
      "trial: 3, iter: 600, curr loss: 1.3089048862457275, avg loss: 1.313929174542427\n",
      "trial: 3, iter: 800, curr loss: 1.2781143188476562, avg loss: 1.2972454506158828\n",
      "trial: 3, iter: 1000, curr loss: 1.2525140047073364, avg loss: 1.2903582394123077\n",
      "trial: 3, iter: 1200, curr loss: 1.2895127534866333, avg loss: 1.2831581878662108\n",
      "trial: 3, iter: 1400, curr loss: 1.2495603561401367, avg loss: 1.278708671927452\n",
      "trial: 3, iter: 1600, curr loss: 1.2677000761032104, avg loss: 1.275895231962204\n",
      "trial: 3, iter: 1800, curr loss: 1.284676432609558, avg loss: 1.273068130016327\n",
      "trial: 3, iter: 2000, curr loss: 1.274851679801941, avg loss: 1.272302953004837\n",
      "trial: 3, iter: 2200, curr loss: 1.2859694957733154, avg loss: 1.2672178119421005\n",
      "trial: 3, iter: 2400, curr loss: 1.3055297136306763, avg loss: 1.265919764637947\n",
      "trial: 3, iter: 2600, curr loss: 1.2365398406982422, avg loss: 1.2619975417852403\n",
      "trial: 3, iter: 2800, curr loss: 1.2891541719436646, avg loss: 1.2610368567705155\n",
      "trial: 3, iter: 3000, curr loss: 1.2580751180648804, avg loss: 1.2585510849952697\n",
      "trial: 3, ldr: 0.22764426469802856\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.381780982017517, avg loss: 1.3844867545366286\n",
      "trial: 4, iter: 400, curr loss: 1.3362492322921753, avg loss: 1.3579879665374757\n",
      "trial: 4, iter: 600, curr loss: 1.2926596403121948, avg loss: 1.3188556230068207\n",
      "trial: 4, iter: 800, curr loss: 1.288856863975525, avg loss: 1.2981446754932404\n",
      "trial: 4, iter: 1000, curr loss: 1.2996093034744263, avg loss: 1.2905059272050858\n",
      "trial: 4, iter: 1200, curr loss: 1.2648130655288696, avg loss: 1.2865580689907075\n",
      "trial: 4, iter: 1400, curr loss: 1.2466686964035034, avg loss: 1.282703579068184\n",
      "trial: 4, iter: 1600, curr loss: 1.2885609865188599, avg loss: 1.279213124513626\n",
      "trial: 4, iter: 1800, curr loss: 1.3234705924987793, avg loss: 1.2773380994796752\n",
      "trial: 4, iter: 2000, curr loss: 1.2810146808624268, avg loss: 1.2716712439060212\n",
      "trial: 4, iter: 2200, curr loss: 1.25748610496521, avg loss: 1.2708032149076463\n",
      "trial: 4, iter: 2400, curr loss: 1.2714271545410156, avg loss: 1.2673699164390564\n",
      "trial: 4, iter: 2600, curr loss: 1.276996374130249, avg loss: 1.2667933547496795\n",
      "trial: 4, iter: 2800, curr loss: 1.2303205728530884, avg loss: 1.2657115870714188\n",
      "trial: 4, iter: 3000, curr loss: 1.2389442920684814, avg loss: 1.2622803562879563\n",
      "trial: 4, ldr: 0.29234185814857483\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3793573379516602, avg loss: 1.3847846627235412\n",
      "trial: 5, iter: 400, curr loss: 1.3192591667175293, avg loss: 1.3540712767839431\n",
      "trial: 5, iter: 600, curr loss: 1.3424476385116577, avg loss: 1.311166620850563\n",
      "trial: 5, iter: 800, curr loss: 1.2801170349121094, avg loss: 1.2966521900892258\n",
      "trial: 5, iter: 1000, curr loss: 1.287063717842102, avg loss: 1.2888906008005143\n",
      "trial: 5, iter: 1200, curr loss: 1.2976642847061157, avg loss: 1.2835078412294387\n",
      "trial: 5, iter: 1400, curr loss: 1.3094182014465332, avg loss: 1.2806615042686462\n",
      "trial: 5, iter: 1600, curr loss: 1.2619376182556152, avg loss: 1.2781861585378647\n",
      "trial: 5, iter: 1800, curr loss: 1.2888987064361572, avg loss: 1.2744105905294418\n",
      "trial: 5, iter: 2000, curr loss: 1.2818266153335571, avg loss: 1.2741750705242156\n",
      "trial: 5, iter: 2200, curr loss: 1.2673673629760742, avg loss: 1.2692438971996307\n",
      "trial: 5, iter: 2400, curr loss: 1.2554231882095337, avg loss: 1.2667942893505098\n",
      "trial: 5, iter: 2600, curr loss: 1.2840628623962402, avg loss: 1.2666023498773575\n",
      "trial: 5, iter: 2800, curr loss: 1.276018738746643, avg loss: 1.2604743254184723\n",
      "trial: 5, iter: 3000, curr loss: 1.2715463638305664, avg loss: 1.2601322388648988\n",
      "trial: 5, ldr: 0.2916397452354431\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.2241132751107216\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.386171817779541, avg loss: 1.3864276432991027\n",
      "trial: 1, iter: 400, curr loss: 1.3612754344940186, avg loss: 1.3768784254789352\n",
      "trial: 1, iter: 600, curr loss: 1.332565188407898, avg loss: 1.3358902472257614\n",
      "trial: 1, iter: 800, curr loss: 1.3314249515533447, avg loss: 1.307120127081871\n",
      "trial: 1, iter: 1000, curr loss: 1.2892873287200928, avg loss: 1.2970582139492035\n",
      "trial: 1, iter: 1200, curr loss: 1.3097971677780151, avg loss: 1.2867101967334746\n",
      "trial: 1, iter: 1400, curr loss: 1.2932716608047485, avg loss: 1.2833461153507233\n",
      "trial: 1, iter: 1600, curr loss: 1.2648943662643433, avg loss: 1.276770640015602\n",
      "trial: 1, iter: 1800, curr loss: 1.258025050163269, avg loss: 1.2777838814258575\n",
      "trial: 1, iter: 2000, curr loss: 1.2899969816207886, avg loss: 1.2667224633693694\n",
      "trial: 1, iter: 2200, curr loss: 1.2794935703277588, avg loss: 1.2696239095926285\n",
      "trial: 1, iter: 2400, curr loss: 1.2865039110183716, avg loss: 1.2618099850416185\n",
      "trial: 1, iter: 2600, curr loss: 1.2100449800491333, avg loss: 1.261492955684662\n",
      "trial: 1, iter: 2800, curr loss: 1.2296944856643677, avg loss: 1.2671345722675325\n",
      "trial: 1, iter: 3000, curr loss: 1.2187222242355347, avg loss: 1.2601545977592468\n",
      "trial: 1, ldr: 0.21623603999614716\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3875612020492554, avg loss: 1.3865716224908828\n",
      "trial: 2, iter: 400, curr loss: 1.3689777851104736, avg loss: 1.3796413511037826\n",
      "trial: 2, iter: 600, curr loss: 1.3124390840530396, avg loss: 1.3377836787700652\n",
      "trial: 2, iter: 800, curr loss: 1.300843358039856, avg loss: 1.3063331872224808\n",
      "trial: 2, iter: 1000, curr loss: 1.2670753002166748, avg loss: 1.2993448978662492\n",
      "trial: 2, iter: 1200, curr loss: 1.2789885997772217, avg loss: 1.290116584300995\n",
      "trial: 2, iter: 1400, curr loss: 1.3168201446533203, avg loss: 1.2829243195056916\n",
      "trial: 2, iter: 1600, curr loss: 1.294695258140564, avg loss: 1.2788520157337189\n",
      "trial: 2, iter: 1800, curr loss: 1.2840559482574463, avg loss: 1.275358824133873\n",
      "trial: 2, iter: 2000, curr loss: 1.3069318532943726, avg loss: 1.271090105175972\n",
      "trial: 2, iter: 2200, curr loss: 1.3114044666290283, avg loss: 1.2674045753479004\n",
      "trial: 2, iter: 2400, curr loss: 1.238152027130127, avg loss: 1.2672914892435074\n",
      "trial: 2, iter: 2600, curr loss: 1.2709981203079224, avg loss: 1.2605222594738006\n",
      "trial: 2, iter: 2800, curr loss: 1.2823406457901, avg loss: 1.2599733293056488\n",
      "trial: 2, iter: 3000, curr loss: 1.2435492277145386, avg loss: 1.2586522233486175\n",
      "trial: 2, ldr: 0.21137812733650208\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3794045448303223, avg loss: 1.3855808252096176\n",
      "trial: 3, iter: 400, curr loss: 1.3390717506408691, avg loss: 1.3631000906229018\n",
      "trial: 3, iter: 600, curr loss: 1.3285365104675293, avg loss: 1.3161148083209993\n",
      "trial: 3, iter: 800, curr loss: 1.2874175310134888, avg loss: 1.2980266004800796\n",
      "trial: 3, iter: 1000, curr loss: 1.265369176864624, avg loss: 1.2910316514968871\n",
      "trial: 3, iter: 1200, curr loss: 1.25935959815979, avg loss: 1.2812546741962434\n",
      "trial: 3, iter: 1400, curr loss: 1.2908813953399658, avg loss: 1.2775287944078446\n",
      "trial: 3, iter: 1600, curr loss: 1.2794374227523804, avg loss: 1.2754894983768463\n",
      "trial: 3, iter: 1800, curr loss: 1.2918169498443604, avg loss: 1.2778079825639725\n",
      "trial: 3, iter: 2000, curr loss: 1.2674061059951782, avg loss: 1.2716607177257537\n",
      "trial: 3, iter: 2200, curr loss: 1.2973613739013672, avg loss: 1.2667959731817247\n",
      "trial: 3, iter: 2400, curr loss: 1.3025273084640503, avg loss: 1.266568056344986\n",
      "trial: 3, iter: 2600, curr loss: 1.2628899812698364, avg loss: 1.2634047359228133\n",
      "trial: 3, iter: 2800, curr loss: 1.279801607131958, avg loss: 1.2621425682306289\n",
      "trial: 3, iter: 3000, curr loss: 1.2416716814041138, avg loss: 1.2605500274896622\n",
      "trial: 3, ldr: 0.20722904801368713\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.382411003112793, avg loss: 1.385658238530159\n",
      "trial: 4, iter: 400, curr loss: 1.3323736190795898, avg loss: 1.3580273967981338\n",
      "trial: 4, iter: 600, curr loss: 1.3073031902313232, avg loss: 1.311792271733284\n",
      "trial: 4, iter: 800, curr loss: 1.2637051343917847, avg loss: 1.3008381015062331\n",
      "trial: 4, iter: 1000, curr loss: 1.328049898147583, avg loss: 1.2948089945316315\n",
      "trial: 4, iter: 1200, curr loss: 1.2845120429992676, avg loss: 1.2867476320266724\n",
      "trial: 4, iter: 1400, curr loss: 1.2426433563232422, avg loss: 1.2808892989158631\n",
      "trial: 4, iter: 1600, curr loss: 1.2686376571655273, avg loss: 1.278168552517891\n",
      "trial: 4, iter: 1800, curr loss: 1.2430754899978638, avg loss: 1.2729762870073318\n",
      "trial: 4, iter: 2000, curr loss: 1.2176222801208496, avg loss: 1.27214197576046\n",
      "trial: 4, iter: 2200, curr loss: 1.2679812908172607, avg loss: 1.2708868336677552\n",
      "trial: 4, iter: 2400, curr loss: 1.264722466468811, avg loss: 1.2641775423288346\n",
      "trial: 4, iter: 2600, curr loss: 1.2676938772201538, avg loss: 1.2660803884267806\n",
      "trial: 4, iter: 2800, curr loss: 1.2929487228393555, avg loss: 1.2651016730070115\n",
      "trial: 4, iter: 3000, curr loss: 1.258612871170044, avg loss: 1.2613908940553664\n",
      "trial: 4, ldr: 0.24071918427944183\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.375709056854248, avg loss: 1.38463865339756\n",
      "trial: 5, iter: 400, curr loss: 1.319871425628662, avg loss: 1.3550863379240037\n",
      "trial: 5, iter: 600, curr loss: 1.2951359748840332, avg loss: 1.3150764411687852\n",
      "trial: 5, iter: 800, curr loss: 1.3098819255828857, avg loss: 1.2988968962430953\n",
      "trial: 5, iter: 1000, curr loss: 1.3170007467269897, avg loss: 1.2923434942960739\n",
      "trial: 5, iter: 1200, curr loss: 1.2781915664672852, avg loss: 1.287421504855156\n",
      "trial: 5, iter: 1400, curr loss: 1.3441073894500732, avg loss: 1.2819713562726975\n",
      "trial: 5, iter: 1600, curr loss: 1.2774810791015625, avg loss: 1.2786645942926407\n",
      "trial: 5, iter: 1800, curr loss: 1.284095048904419, avg loss: 1.2740448039770127\n",
      "trial: 5, iter: 2000, curr loss: 1.274444580078125, avg loss: 1.2764524567127227\n",
      "trial: 5, iter: 2200, curr loss: 1.2554818391799927, avg loss: 1.2693480616807937\n",
      "trial: 5, iter: 2400, curr loss: 1.2558784484863281, avg loss: 1.2683990997076036\n",
      "trial: 5, iter: 2600, curr loss: 1.2209479808807373, avg loss: 1.2644307160377501\n",
      "trial: 5, iter: 2800, curr loss: 1.287654161453247, avg loss: 1.261139761209488\n",
      "trial: 5, iter: 3000, curr loss: 1.2598415613174438, avg loss: 1.259258890748024\n",
      "trial: 5, ldr: 0.23564927279949188\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.222242334485054\n",
      "Experiment done with data path: ./data/catNon-lin-NI_2/data.10k.dz10.seed0.npy\n",
      "Experiment start with data path: ./data/catNon-lin-NI_1/data.5k.dz10.seed0.npy\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3853830099105835, avg loss: 1.3871078985929488\n",
      "trial: 1, iter: 400, curr loss: 1.3784892559051514, avg loss: 1.3840530353784561\n",
      "trial: 1, iter: 600, curr loss: 1.3372458219528198, avg loss: 1.354870423078537\n",
      "trial: 1, iter: 800, curr loss: 1.3009798526763916, avg loss: 1.3165066832304\n",
      "trial: 1, iter: 1000, curr loss: 1.267930507659912, avg loss: 1.3079385876655578\n",
      "trial: 1, iter: 1200, curr loss: 1.2860772609710693, avg loss: 1.3018929195404052\n",
      "trial: 1, iter: 1400, curr loss: 1.2557039260864258, avg loss: 1.2946639293432236\n",
      "trial: 1, ldr: -0.004434212576597929\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3850488662719727, avg loss: 1.3864219707250596\n",
      "trial: 2, iter: 400, curr loss: 1.370357871055603, avg loss: 1.380588297843933\n",
      "trial: 2, iter: 600, curr loss: 1.3170980215072632, avg loss: 1.3468460255861283\n",
      "trial: 2, iter: 800, curr loss: 1.279097318649292, avg loss: 1.3185762017965317\n",
      "trial: 2, iter: 1000, curr loss: 1.3111765384674072, avg loss: 1.3071722865104676\n",
      "trial: 2, iter: 1200, curr loss: 1.297415852546692, avg loss: 1.3007993185520172\n",
      "trial: 2, iter: 1400, curr loss: 1.2642335891723633, avg loss: 1.2932018786668777\n",
      "trial: 2, ldr: 0.037163738161325455\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873798847198486, avg loss: 1.386855925321579\n",
      "trial: 3, iter: 400, curr loss: 1.3713752031326294, avg loss: 1.3813075548410416\n",
      "trial: 3, iter: 600, curr loss: 1.331180453300476, avg loss: 1.3550796860456467\n",
      "trial: 3, iter: 800, curr loss: 1.303436517715454, avg loss: 1.3203378075361252\n",
      "trial: 3, iter: 1000, curr loss: 1.269750714302063, avg loss: 1.304727800488472\n",
      "trial: 3, iter: 1200, curr loss: 1.3159306049346924, avg loss: 1.2992993664741517\n",
      "trial: 3, iter: 1400, curr loss: 1.2494677305221558, avg loss: 1.2951791977882385\n",
      "trial: 3, ldr: 0.011093140579760075\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3880689144134521, avg loss: 1.3871192407608033\n",
      "trial: 4, iter: 400, curr loss: 1.379583477973938, avg loss: 1.3830475705862044\n",
      "trial: 4, iter: 600, curr loss: 1.3347907066345215, avg loss: 1.3473136389255524\n",
      "trial: 4, iter: 800, curr loss: 1.2967168092727661, avg loss: 1.316056364774704\n",
      "trial: 4, iter: 1000, curr loss: 1.3349870443344116, avg loss: 1.304961212873459\n",
      "trial: 4, iter: 1200, curr loss: 1.3033314943313599, avg loss: 1.2962513154745101\n",
      "trial: 4, iter: 1400, curr loss: 1.3231855630874634, avg loss: 1.2937486165761947\n",
      "trial: 4, ldr: 0.01318287942558527\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3828867673873901, avg loss: 1.3864673852920533\n",
      "trial: 5, iter: 400, curr loss: 1.3665153980255127, avg loss: 1.3803865402936935\n",
      "trial: 5, iter: 600, curr loss: 1.322903037071228, avg loss: 1.3361978042125702\n",
      "trial: 5, iter: 800, curr loss: 1.300225853919983, avg loss: 1.3104637205600738\n",
      "trial: 5, iter: 1000, curr loss: 1.3104463815689087, avg loss: 1.3016275876760484\n",
      "trial: 5, iter: 1200, curr loss: 1.2796131372451782, avg loss: 1.29568703353405\n",
      "trial: 5, iter: 1400, curr loss: 1.256293773651123, avg loss: 1.2912324726581574\n",
      "trial: 5, ldr: 0.0117012495175004\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.013741359021514655\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3815499544143677, avg loss: 1.3867660653591156\n",
      "trial: 1, iter: 400, curr loss: 1.377709150314331, avg loss: 1.3818228471279144\n",
      "trial: 1, iter: 600, curr loss: 1.3036789894104004, avg loss: 1.348061804175377\n",
      "trial: 1, iter: 800, curr loss: 1.307725429534912, avg loss: 1.3198560661077499\n",
      "trial: 1, iter: 1000, curr loss: 1.3175452947616577, avg loss: 1.3055467468500137\n",
      "trial: 1, iter: 1200, curr loss: 1.2868432998657227, avg loss: 1.296754879951477\n",
      "trial: 1, iter: 1400, curr loss: 1.3002207279205322, avg loss: 1.2899802398681641\n",
      "trial: 1, ldr: 0.05646253004670143\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3889284133911133, avg loss: 1.3868339574337005\n",
      "trial: 2, iter: 400, curr loss: 1.3766289949417114, avg loss: 1.3834748536348342\n",
      "trial: 2, iter: 600, curr loss: 1.3468014001846313, avg loss: 1.3589641612768173\n",
      "trial: 2, iter: 800, curr loss: 1.2921117544174194, avg loss: 1.3226932340860367\n",
      "trial: 2, iter: 1000, curr loss: 1.2867650985717773, avg loss: 1.3131719595193863\n",
      "trial: 2, iter: 1200, curr loss: 1.2897744178771973, avg loss: 1.3037440580129624\n",
      "trial: 2, iter: 1400, curr loss: 1.276924729347229, avg loss: 1.2954423761367797\n",
      "trial: 2, ldr: 0.026056461036205292\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3825737237930298, avg loss: 1.3866690188646316\n",
      "trial: 3, iter: 400, curr loss: 1.3640336990356445, avg loss: 1.382028289437294\n",
      "trial: 3, iter: 600, curr loss: 1.336669683456421, avg loss: 1.3519593781232835\n",
      "trial: 3, iter: 800, curr loss: 1.2986540794372559, avg loss: 1.3197028934955597\n",
      "trial: 3, iter: 1000, curr loss: 1.2909513711929321, avg loss: 1.3063944047689438\n",
      "trial: 3, iter: 1200, curr loss: 1.2648974657058716, avg loss: 1.2991251260042191\n",
      "trial: 3, iter: 1400, curr loss: 1.2878451347351074, avg loss: 1.2888694375753402\n",
      "trial: 3, ldr: 0.037632543593645096\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3878754377365112, avg loss: 1.386711797118187\n",
      "trial: 4, iter: 400, curr loss: 1.358319878578186, avg loss: 1.3791954571008682\n",
      "trial: 4, iter: 600, curr loss: 1.323734164237976, avg loss: 1.3462204438447953\n",
      "trial: 4, iter: 800, curr loss: 1.3295278549194336, avg loss: 1.3186159926652907\n",
      "trial: 4, iter: 1000, curr loss: 1.3300961256027222, avg loss: 1.3094500714540482\n",
      "trial: 4, iter: 1200, curr loss: 1.3345179557800293, avg loss: 1.3030313950777055\n",
      "trial: 4, iter: 1400, curr loss: 1.2920739650726318, avg loss: 1.2967241042852402\n",
      "trial: 4, ldr: 0.05761697515845299\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.387642502784729, avg loss: 1.3870739990472793\n",
      "trial: 5, iter: 400, curr loss: 1.3766632080078125, avg loss: 1.3846452617645264\n",
      "trial: 5, iter: 600, curr loss: 1.3382185697555542, avg loss: 1.3647468149662019\n",
      "trial: 5, iter: 800, curr loss: 1.340589165687561, avg loss: 1.326636997461319\n",
      "trial: 5, iter: 1000, curr loss: 1.2952532768249512, avg loss: 1.3099880927801133\n",
      "trial: 5, iter: 1200, curr loss: 1.2796915769577026, avg loss: 1.3001962441205979\n",
      "trial: 5, iter: 1400, curr loss: 1.324600100517273, avg loss: 1.2929653573036193\n",
      "trial: 5, ldr: 0.06742500513792038\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.049038702994585036\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.384477972984314, avg loss: 1.3867472738027573\n",
      "trial: 1, iter: 400, curr loss: 1.3827388286590576, avg loss: 1.3837663906812667\n",
      "trial: 1, iter: 600, curr loss: 1.337039589881897, avg loss: 1.3601845866441726\n",
      "trial: 1, iter: 800, curr loss: 1.3173032999038696, avg loss: 1.3210723453760147\n",
      "trial: 1, iter: 1000, curr loss: 1.2966980934143066, avg loss: 1.3065686464309691\n",
      "trial: 1, iter: 1200, curr loss: 1.284571886062622, avg loss: 1.299986938238144\n",
      "trial: 1, iter: 1400, curr loss: 1.2722469568252563, avg loss: 1.2944218975305557\n",
      "trial: 1, ldr: 0.010695799253880978\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3878921270370483, avg loss: 1.3872681605815886\n",
      "trial: 2, iter: 400, curr loss: 1.3742791414260864, avg loss: 1.3842393583059311\n",
      "trial: 2, iter: 600, curr loss: 1.3566498756408691, avg loss: 1.363172333240509\n",
      "trial: 2, iter: 800, curr loss: 1.3062033653259277, avg loss: 1.325673176050186\n",
      "trial: 2, iter: 1000, curr loss: 1.2724508047103882, avg loss: 1.3056994897127152\n",
      "trial: 2, iter: 1200, curr loss: 1.3256700038909912, avg loss: 1.2980328756570816\n",
      "trial: 2, iter: 1400, curr loss: 1.303596019744873, avg loss: 1.2934798818826676\n",
      "trial: 2, ldr: 0.07356295734643936\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3873685598373413, avg loss: 1.387239660024643\n",
      "trial: 3, iter: 400, curr loss: 1.3855741024017334, avg loss: 1.3854668658971787\n",
      "trial: 3, iter: 600, curr loss: 1.3621505498886108, avg loss: 1.37637233376503\n",
      "trial: 3, iter: 800, curr loss: 1.32584810256958, avg loss: 1.3482038605213165\n",
      "trial: 3, iter: 1000, curr loss: 1.3464336395263672, avg loss: 1.3219088000059127\n",
      "trial: 3, iter: 1200, curr loss: 1.3472620248794556, avg loss: 1.3093427318334578\n",
      "trial: 3, iter: 1400, curr loss: 1.3010129928588867, avg loss: 1.301721128821373\n",
      "trial: 3, ldr: 0.05903230607509613\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3865541219711304, avg loss: 1.387232510447502\n",
      "trial: 4, iter: 400, curr loss: 1.3873430490493774, avg loss: 1.3859484845399856\n",
      "trial: 4, iter: 600, curr loss: 1.3478680849075317, avg loss: 1.375077673792839\n",
      "trial: 4, iter: 800, curr loss: 1.3305304050445557, avg loss: 1.3350710767507552\n",
      "trial: 4, iter: 1000, curr loss: 1.2840956449508667, avg loss: 1.3151597833633424\n",
      "trial: 4, iter: 1200, curr loss: 1.3146215677261353, avg loss: 1.304156221151352\n",
      "trial: 4, iter: 1400, curr loss: 1.3125157356262207, avg loss: 1.2994337272644043\n",
      "trial: 4, ldr: 0.02466105856001377\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.385349988937378, avg loss: 1.386937347650528\n",
      "trial: 5, iter: 400, curr loss: 1.378869891166687, avg loss: 1.3830911058187485\n",
      "trial: 5, iter: 600, curr loss: 1.3205496072769165, avg loss: 1.3570192766189575\n",
      "trial: 5, iter: 800, curr loss: 1.3312065601348877, avg loss: 1.3235226833820344\n",
      "trial: 5, iter: 1000, curr loss: 1.3183926343917847, avg loss: 1.3095882546901703\n",
      "trial: 5, iter: 1200, curr loss: 1.2780357599258423, avg loss: 1.3015088772773742\n",
      "trial: 5, iter: 1400, curr loss: 1.2953002452850342, avg loss: 1.2946662300825118\n",
      "trial: 5, ldr: 0.03429766371846199\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.04044995699077845\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3868792057037354, avg loss: 1.3867540508508682\n",
      "trial: 1, iter: 400, curr loss: 1.3703927993774414, avg loss: 1.3820085805654525\n",
      "trial: 1, iter: 600, curr loss: 1.3337833881378174, avg loss: 1.3468817418813706\n",
      "trial: 1, iter: 800, curr loss: 1.2920303344726562, avg loss: 1.3165691077709198\n",
      "trial: 1, iter: 1000, curr loss: 1.323486566543579, avg loss: 1.3061706292629243\n",
      "trial: 1, iter: 1200, curr loss: 1.2859309911727905, avg loss: 1.2985432314872742\n",
      "trial: 1, iter: 1400, curr loss: 1.2940696477890015, avg loss: 1.2945726442337036\n",
      "trial: 1, ldr: 0.08952755481004715\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3843613862991333, avg loss: 1.3869619429111482\n",
      "trial: 2, iter: 400, curr loss: 1.3729815483093262, avg loss: 1.381983128786087\n",
      "trial: 2, iter: 600, curr loss: 1.3242404460906982, avg loss: 1.3439898759126663\n",
      "trial: 2, iter: 800, curr loss: 1.2993927001953125, avg loss: 1.3170651006698608\n",
      "trial: 2, iter: 1000, curr loss: 1.2652020454406738, avg loss: 1.3054211884737015\n",
      "trial: 2, iter: 1200, curr loss: 1.3234610557556152, avg loss: 1.3014437121152878\n",
      "trial: 2, iter: 1400, curr loss: 1.2765772342681885, avg loss: 1.2934748351573944\n",
      "trial: 2, ldr: 0.052907392382621765\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3874467611312866, avg loss: 1.386965612769127\n",
      "trial: 3, iter: 400, curr loss: 1.3862576484680176, avg loss: 1.3849432587623596\n",
      "trial: 3, iter: 600, curr loss: 1.351488709449768, avg loss: 1.3676119846105577\n",
      "trial: 3, iter: 800, curr loss: 1.3225367069244385, avg loss: 1.3229454952478408\n",
      "trial: 3, iter: 1000, curr loss: 1.3196446895599365, avg loss: 1.3055104088783265\n",
      "trial: 3, iter: 1200, curr loss: 1.278227686882019, avg loss: 1.2965029793977738\n",
      "trial: 3, iter: 1400, curr loss: 1.2954894304275513, avg loss: 1.2875206983089447\n",
      "trial: 3, ldr: 0.07917612046003342\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3893043994903564, avg loss: 1.3867380338907243\n",
      "trial: 4, iter: 400, curr loss: 1.3660080432891846, avg loss: 1.3813375061750413\n",
      "trial: 4, iter: 600, curr loss: 1.3251228332519531, avg loss: 1.3413872665166855\n",
      "trial: 4, iter: 800, curr loss: 1.3027889728546143, avg loss: 1.3149143415689468\n",
      "trial: 4, iter: 1000, curr loss: 1.2909654378890991, avg loss: 1.306350125670433\n",
      "trial: 4, iter: 1200, curr loss: 1.3062329292297363, avg loss: 1.2976310187578202\n",
      "trial: 4, iter: 1400, curr loss: 1.281087875366211, avg loss: 1.2942239135503768\n",
      "trial: 4, ldr: 0.0464547835290432\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.383554458618164, avg loss: 1.3869096541404724\n",
      "trial: 5, iter: 400, curr loss: 1.382699966430664, avg loss: 1.3828086894750595\n",
      "trial: 5, iter: 600, curr loss: 1.3160251379013062, avg loss: 1.3500877517461776\n",
      "trial: 5, iter: 800, curr loss: 1.3105438947677612, avg loss: 1.3163797610998154\n",
      "trial: 5, iter: 1000, curr loss: 1.3072314262390137, avg loss: 1.308846383690834\n",
      "trial: 5, iter: 1200, curr loss: 1.3363182544708252, avg loss: 1.2996063774824143\n",
      "trial: 5, iter: 1400, curr loss: 1.3059359788894653, avg loss: 1.2939236116409303\n",
      "trial: 5, ldr: 0.02126508206129074\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.05786618664860725\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3858941793441772, avg loss: 1.3865495562553405\n",
      "trial: 1, iter: 400, curr loss: 1.3703453540802002, avg loss: 1.3808667314052583\n",
      "trial: 1, iter: 600, curr loss: 1.3147820234298706, avg loss: 1.3438130098581313\n",
      "trial: 1, iter: 800, curr loss: 1.3045134544372559, avg loss: 1.3168139511346817\n",
      "trial: 1, iter: 1000, curr loss: 1.2807971239089966, avg loss: 1.3045809221267701\n",
      "trial: 1, iter: 1200, curr loss: 1.306379795074463, avg loss: 1.2987867665290833\n",
      "trial: 1, iter: 1400, curr loss: 1.2984291315078735, avg loss: 1.2940592825412751\n",
      "trial: 1, ldr: 0.10448680073022842\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.389891266822815, avg loss: 1.3870075011253358\n",
      "trial: 2, iter: 400, curr loss: 1.3827152252197266, avg loss: 1.3847369503974916\n",
      "trial: 2, iter: 600, curr loss: 1.3070168495178223, avg loss: 1.3612400048971176\n",
      "trial: 2, iter: 800, curr loss: 1.3213386535644531, avg loss: 1.3173427599668504\n",
      "trial: 2, iter: 1000, curr loss: 1.2922163009643555, avg loss: 1.306395219564438\n",
      "trial: 2, iter: 1200, curr loss: 1.2809038162231445, avg loss: 1.2969678223133088\n",
      "trial: 2, iter: 1400, curr loss: 1.2826077938079834, avg loss: 1.289505478143692\n",
      "trial: 2, ldr: 0.09633956849575043\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.387883186340332, avg loss: 1.3869020694494247\n",
      "trial: 3, iter: 400, curr loss: 1.382468581199646, avg loss: 1.3843656086921692\n",
      "trial: 3, iter: 600, curr loss: 1.3591476678848267, avg loss: 1.3642740279436112\n",
      "trial: 3, iter: 800, curr loss: 1.273832082748413, avg loss: 1.3245880532264709\n",
      "trial: 3, iter: 1000, curr loss: 1.2792072296142578, avg loss: 1.3089269924163818\n",
      "trial: 3, iter: 1200, curr loss: 1.309033751487732, avg loss: 1.301661216020584\n",
      "trial: 3, iter: 1400, curr loss: 1.3207964897155762, avg loss: 1.2934942334890365\n",
      "trial: 3, ldr: 0.05262245982885361\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3877484798431396, avg loss: 1.387206469774246\n",
      "trial: 4, iter: 400, curr loss: 1.3809529542922974, avg loss: 1.3850975865125656\n",
      "trial: 4, iter: 600, curr loss: 1.348649501800537, avg loss: 1.3698860496282577\n",
      "trial: 4, iter: 800, curr loss: 1.3042654991149902, avg loss: 1.3329148000478745\n",
      "trial: 4, iter: 1000, curr loss: 1.2994122505187988, avg loss: 1.315168000459671\n",
      "trial: 4, iter: 1200, curr loss: 1.3171286582946777, avg loss: 1.3087319058179856\n",
      "trial: 4, iter: 1400, curr loss: 1.3040127754211426, avg loss: 1.2973294705152512\n",
      "trial: 4, ldr: 0.051464326679706573\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.381490707397461, avg loss: 1.3872115105390548\n",
      "trial: 5, iter: 400, curr loss: 1.373928427696228, avg loss: 1.383738459944725\n",
      "trial: 5, iter: 600, curr loss: 1.323790192604065, avg loss: 1.3585730648040772\n",
      "trial: 5, iter: 800, curr loss: 1.3267979621887207, avg loss: 1.324495639204979\n",
      "trial: 5, iter: 1000, curr loss: 1.3111746311187744, avg loss: 1.3081908982992172\n",
      "trial: 5, iter: 1200, curr loss: 1.3002147674560547, avg loss: 1.3007017743587495\n",
      "trial: 5, iter: 1400, curr loss: 1.2421330213546753, avg loss: 1.2904344379901886\n",
      "trial: 5, ldr: 0.08537620306015015\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.07805787175893783\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3836814165115356, avg loss: 1.3863873052597047\n",
      "trial: 1, iter: 400, curr loss: 1.3738315105438232, avg loss: 1.381133009791374\n",
      "trial: 1, iter: 600, curr loss: 1.3486781120300293, avg loss: 1.3502626401185989\n",
      "trial: 1, iter: 800, curr loss: 1.3320082426071167, avg loss: 1.321399592757225\n",
      "trial: 1, iter: 1000, curr loss: 1.2862682342529297, avg loss: 1.3058024764060974\n",
      "trial: 1, iter: 1200, curr loss: 1.3249378204345703, avg loss: 1.3030496096611024\n",
      "trial: 1, iter: 1400, curr loss: 1.3221746683120728, avg loss: 1.2919571501016618\n",
      "trial: 1, ldr: -0.03474852815270424\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3888307809829712, avg loss: 1.3872953057289124\n",
      "trial: 2, iter: 400, curr loss: 1.3857800960540771, avg loss: 1.3864842474460601\n",
      "trial: 2, iter: 600, curr loss: 1.3784668445587158, avg loss: 1.3835760354995728\n",
      "trial: 2, iter: 800, curr loss: 1.3106515407562256, avg loss: 1.353345317840576\n",
      "trial: 2, iter: 1000, curr loss: 1.314624547958374, avg loss: 1.3203274875879287\n",
      "trial: 2, iter: 1200, curr loss: 1.2982659339904785, avg loss: 1.3089643728733062\n",
      "trial: 2, iter: 1400, curr loss: 1.2806459665298462, avg loss: 1.3007874363660812\n",
      "trial: 2, ldr: 0.029033832252025604\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3882092237472534, avg loss: 1.3869395130872726\n",
      "trial: 3, iter: 400, curr loss: 1.379614233970642, avg loss: 1.3847238969802858\n",
      "trial: 3, iter: 600, curr loss: 1.3704291582107544, avg loss: 1.370168981552124\n",
      "trial: 3, iter: 800, curr loss: 1.300206184387207, avg loss: 1.3344481176137923\n",
      "trial: 3, iter: 1000, curr loss: 1.2994712591171265, avg loss: 1.313890699148178\n",
      "trial: 3, iter: 1200, curr loss: 1.3083659410476685, avg loss: 1.3052574825286865\n",
      "trial: 3, iter: 1400, curr loss: 1.2741020917892456, avg loss: 1.2958433765172959\n",
      "trial: 3, ldr: 0.014617458917200565\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.382809042930603, avg loss: 1.3868944823741913\n",
      "trial: 4, iter: 400, curr loss: 1.3573671579360962, avg loss: 1.3795403134822846\n",
      "trial: 4, iter: 600, curr loss: 1.3426650762557983, avg loss: 1.3376213032007218\n",
      "trial: 4, iter: 800, curr loss: 1.2842118740081787, avg loss: 1.3145484459400176\n",
      "trial: 4, iter: 1000, curr loss: 1.3092498779296875, avg loss: 1.3065940713882447\n",
      "trial: 4, iter: 1200, curr loss: 1.315751314163208, avg loss: 1.2983426833152771\n",
      "trial: 4, iter: 1400, curr loss: 1.2692152261734009, avg loss: 1.294213554263115\n",
      "trial: 4, ldr: 0.05335518717765808\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3843103647232056, avg loss: 1.3862771677970886\n",
      "trial: 5, iter: 400, curr loss: 1.3734068870544434, avg loss: 1.3793648952245712\n",
      "trial: 5, iter: 600, curr loss: 1.3137812614440918, avg loss: 1.3451803755760192\n",
      "trial: 5, iter: 800, curr loss: 1.3143752813339233, avg loss: 1.3183927321434021\n",
      "trial: 5, iter: 1000, curr loss: 1.3334823846817017, avg loss: 1.3067586886882783\n",
      "trial: 5, iter: 1200, curr loss: 1.2795255184173584, avg loss: 1.2985251009464265\n",
      "trial: 5, iter: 1400, curr loss: 1.2826052904129028, avg loss: 1.294751832485199\n",
      "trial: 5, ldr: 0.1305982619524002\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.03857124242931605\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3922641277313232, avg loss: 1.3868503069877625\n",
      "trial: 1, iter: 400, curr loss: 1.385129690170288, avg loss: 1.3854820072650909\n",
      "trial: 1, iter: 600, curr loss: 1.3467662334442139, avg loss: 1.3735178482532502\n",
      "trial: 1, iter: 800, curr loss: 1.3096970319747925, avg loss: 1.330047422647476\n",
      "trial: 1, iter: 1000, curr loss: 1.3186719417572021, avg loss: 1.3120131224393845\n",
      "trial: 1, iter: 1200, curr loss: 1.284237265586853, avg loss: 1.3028818571567535\n",
      "trial: 1, iter: 1400, curr loss: 1.2986783981323242, avg loss: 1.2957303988933564\n",
      "trial: 1, ldr: -0.03520440682768822\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3888028860092163, avg loss: 1.3875270986557007\n",
      "trial: 2, iter: 400, curr loss: 1.3824881315231323, avg loss: 1.3854435127973557\n",
      "trial: 2, iter: 600, curr loss: 1.328344464302063, avg loss: 1.3721801042556763\n",
      "trial: 2, iter: 800, curr loss: 1.310286045074463, avg loss: 1.3323374003171922\n",
      "trial: 2, iter: 1000, curr loss: 1.3126420974731445, avg loss: 1.3119498825073241\n",
      "trial: 2, iter: 1200, curr loss: 1.344969630241394, avg loss: 1.305459298491478\n",
      "trial: 2, iter: 1400, curr loss: 1.3442391157150269, avg loss: 1.3008640450239182\n",
      "trial: 2, ldr: -0.009273495525121689\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3847219944000244, avg loss: 1.3870447647571564\n",
      "trial: 3, iter: 400, curr loss: 1.3762290477752686, avg loss: 1.3842304980754851\n",
      "trial: 3, iter: 600, curr loss: 1.3451101779937744, avg loss: 1.3605089884996415\n",
      "trial: 3, iter: 800, curr loss: 1.3166756629943848, avg loss: 1.3229673552513121\n",
      "trial: 3, iter: 1000, curr loss: 1.2937254905700684, avg loss: 1.313060110807419\n",
      "trial: 3, iter: 1200, curr loss: 1.3139716386795044, avg loss: 1.3029908537864685\n",
      "trial: 3, iter: 1400, curr loss: 1.3051005601882935, avg loss: 1.298190997838974\n",
      "trial: 3, ldr: -0.004553261678665876\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3879085779190063, avg loss: 1.3871460849046706\n",
      "trial: 4, iter: 400, curr loss: 1.3832470178604126, avg loss: 1.3846397745609282\n",
      "trial: 4, iter: 600, curr loss: 1.3491690158843994, avg loss: 1.361354233622551\n",
      "trial: 4, iter: 800, curr loss: 1.2997243404388428, avg loss: 1.3235317832231521\n",
      "trial: 4, iter: 1000, curr loss: 1.3179652690887451, avg loss: 1.3141359776258468\n",
      "trial: 4, iter: 1200, curr loss: 1.292634129524231, avg loss: 1.3037615340948105\n",
      "trial: 4, iter: 1400, curr loss: 1.3071858882904053, avg loss: 1.2992551404237747\n",
      "trial: 4, ldr: -0.0020614394452422857\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3892323970794678, avg loss: 1.386578465104103\n",
      "trial: 5, iter: 400, curr loss: 1.3787466287612915, avg loss: 1.3825601261854172\n",
      "trial: 5, iter: 600, curr loss: 1.3315836191177368, avg loss: 1.3522574305534363\n",
      "trial: 5, iter: 800, curr loss: 1.3224815130233765, avg loss: 1.3191817283630372\n",
      "trial: 5, iter: 1000, curr loss: 1.292787790298462, avg loss: 1.3122608536481857\n",
      "trial: 5, iter: 1200, curr loss: 1.3380815982818604, avg loss: 1.3016537553071976\n",
      "trial: 5, iter: 1400, curr loss: 1.279061198234558, avg loss: 1.2933572536706925\n",
      "trial: 5, ldr: 0.014412138611078262\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: -0.007336092973127961\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.3864634037017822, avg loss: 1.3869584411382676\n",
      "trial: 1, iter: 400, curr loss: 1.3696218729019165, avg loss: 1.382618910074234\n",
      "trial: 1, iter: 600, curr loss: 1.3143153190612793, avg loss: 1.3492786884307861\n",
      "trial: 1, iter: 800, curr loss: 1.3195120096206665, avg loss: 1.3188925820589066\n",
      "trial: 1, iter: 1000, curr loss: 1.268099308013916, avg loss: 1.3065116256475449\n",
      "trial: 1, iter: 1200, curr loss: 1.339630365371704, avg loss: 1.3012144207954406\n",
      "trial: 1, iter: 1400, curr loss: 1.3037430047988892, avg loss: 1.292620455622673\n",
      "trial: 1, ldr: 0.04449757561087608\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.389167308807373, avg loss: 1.3869207924604416\n",
      "trial: 2, iter: 400, curr loss: 1.3802834749221802, avg loss: 1.3848477309942246\n",
      "trial: 2, iter: 600, curr loss: 1.3488723039627075, avg loss: 1.368238976597786\n",
      "trial: 2, iter: 800, curr loss: 1.329197883605957, avg loss: 1.3334022969007493\n",
      "trial: 2, iter: 1000, curr loss: 1.2962040901184082, avg loss: 1.3159451377391815\n",
      "trial: 2, iter: 1200, curr loss: 1.313950777053833, avg loss: 1.3087225061655046\n",
      "trial: 2, iter: 1400, curr loss: 1.2895894050598145, avg loss: 1.3020040768384933\n",
      "trial: 2, ldr: 0.048347022384405136\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3869514465332031, avg loss: 1.3870122933387756\n",
      "trial: 3, iter: 400, curr loss: 1.3840240240097046, avg loss: 1.3855684131383896\n",
      "trial: 3, iter: 600, curr loss: 1.3590410947799683, avg loss: 1.3703103077411651\n",
      "trial: 3, iter: 800, curr loss: 1.3124996423721313, avg loss: 1.3327546620368957\n",
      "trial: 3, iter: 1000, curr loss: 1.338828206062317, avg loss: 1.3137783211469651\n",
      "trial: 3, iter: 1200, curr loss: 1.3278162479400635, avg loss: 1.3096622949838639\n",
      "trial: 3, iter: 1400, curr loss: 1.279551386833191, avg loss: 1.2988505226373672\n",
      "trial: 3, ldr: 0.059485796838998795\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3811920881271362, avg loss: 1.386820461153984\n",
      "trial: 4, iter: 400, curr loss: 1.3770610094070435, avg loss: 1.3837679439783097\n",
      "trial: 4, iter: 600, curr loss: 1.3755824565887451, avg loss: 1.3548319745063782\n",
      "trial: 4, iter: 800, curr loss: 1.3309926986694336, avg loss: 1.3216777473688126\n",
      "trial: 4, iter: 1000, curr loss: 1.2831839323043823, avg loss: 1.3107975792884827\n",
      "trial: 4, iter: 1200, curr loss: 1.297505497932434, avg loss: 1.3031584239006042\n",
      "trial: 4, iter: 1400, curr loss: 1.27657151222229, avg loss: 1.293438674211502\n",
      "trial: 4, ldr: 0.07511549443006516\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3908506631851196, avg loss: 1.3860601830482482\n",
      "trial: 5, iter: 400, curr loss: 1.3628345727920532, avg loss: 1.3771335691213609\n",
      "trial: 5, iter: 600, curr loss: 1.2860411405563354, avg loss: 1.3353167551755905\n",
      "trial: 5, iter: 800, curr loss: 1.3448811769485474, avg loss: 1.3123684978485108\n",
      "trial: 5, iter: 1000, curr loss: 1.3220293521881104, avg loss: 1.3052344316244124\n",
      "trial: 5, iter: 1200, curr loss: 1.2895768880844116, avg loss: 1.2970621490478516\n",
      "trial: 5, iter: 1400, curr loss: 1.2790679931640625, avg loss: 1.2879909509420395\n",
      "trial: 5, ldr: 0.06870125979185104\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.05922942981123924\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.38901948928833, avg loss: 1.3868730157613753\n",
      "trial: 1, iter: 400, curr loss: 1.3852607011795044, avg loss: 1.3845049041509627\n",
      "trial: 1, iter: 600, curr loss: 1.3423810005187988, avg loss: 1.3657038414478302\n",
      "trial: 1, iter: 800, curr loss: 1.3207135200500488, avg loss: 1.3298149937391281\n",
      "trial: 1, iter: 1000, curr loss: 1.3202427625656128, avg loss: 1.313711154460907\n",
      "trial: 1, iter: 1200, curr loss: 1.2868841886520386, avg loss: 1.3085720127820968\n",
      "trial: 1, iter: 1400, curr loss: 1.3336918354034424, avg loss: 1.2971200829744338\n",
      "trial: 1, ldr: 0.03713540360331535\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3863216638565063, avg loss: 1.386779881119728\n",
      "trial: 2, iter: 400, curr loss: 1.3693498373031616, avg loss: 1.3827792119979858\n",
      "trial: 2, iter: 600, curr loss: 1.3364301919937134, avg loss: 1.3530539959669112\n",
      "trial: 2, iter: 800, curr loss: 1.3308520317077637, avg loss: 1.3203845930099487\n",
      "trial: 2, iter: 1000, curr loss: 1.3466182947158813, avg loss: 1.3126067352294921\n",
      "trial: 2, iter: 1200, curr loss: 1.3067831993103027, avg loss: 1.300397143959999\n",
      "trial: 2, iter: 1400, curr loss: 1.2592073678970337, avg loss: 1.2960845118761062\n",
      "trial: 2, ldr: 0.07096385210752487\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3843480348587036, avg loss: 1.387456933259964\n",
      "trial: 3, iter: 400, curr loss: 1.3851579427719116, avg loss: 1.386127478480339\n",
      "trial: 3, iter: 600, curr loss: 1.3520900011062622, avg loss: 1.3770914298295975\n",
      "trial: 3, iter: 800, curr loss: 1.3155741691589355, avg loss: 1.3326306986808776\n",
      "trial: 3, iter: 1000, curr loss: 1.311854362487793, avg loss: 1.3133710098266602\n",
      "trial: 3, iter: 1200, curr loss: 1.324574589729309, avg loss: 1.3045603942871093\n",
      "trial: 3, iter: 1400, curr loss: 1.3031121492385864, avg loss: 1.298871540427208\n",
      "trial: 3, ldr: 0.029598282650113106\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3804800510406494, avg loss: 1.387155687212944\n",
      "trial: 4, iter: 400, curr loss: 1.3804019689559937, avg loss: 1.383363134264946\n",
      "trial: 4, iter: 600, curr loss: 1.342061161994934, avg loss: 1.3553616642951964\n",
      "trial: 4, iter: 800, curr loss: 1.3149807453155518, avg loss: 1.3221610760688782\n",
      "trial: 4, iter: 1000, curr loss: 1.305668830871582, avg loss: 1.3056613945960998\n",
      "trial: 4, iter: 1200, curr loss: 1.303435206413269, avg loss: 1.2992221707105636\n",
      "trial: 4, iter: 1400, curr loss: 1.2951745986938477, avg loss: 1.2967127084732055\n",
      "trial: 4, ldr: 0.03731396049261093\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3826425075531006, avg loss: 1.3868066298961639\n",
      "trial: 5, iter: 400, curr loss: 1.3774036169052124, avg loss: 1.3830070406198502\n",
      "trial: 5, iter: 600, curr loss: 1.3440759181976318, avg loss: 1.3549366694688798\n",
      "trial: 5, iter: 800, curr loss: 1.273228645324707, avg loss: 1.3234000945091247\n",
      "trial: 5, iter: 1000, curr loss: 1.304629921913147, avg loss: 1.308327066898346\n",
      "trial: 5, iter: 1200, curr loss: 1.3111785650253296, avg loss: 1.2986444395780563\n",
      "trial: 5, iter: 1400, curr loss: 1.3061693906784058, avg loss: 1.293331738114357\n",
      "trial: 5, ldr: 0.05592355877161026\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.046187011525034904\n",
      "################################################################\n",
      "trial: 1, iter: 200, curr loss: 1.383535385131836, avg loss: 1.3869417065382004\n",
      "trial: 1, iter: 400, curr loss: 1.3828248977661133, avg loss: 1.3839251619577408\n",
      "trial: 1, iter: 600, curr loss: 1.325002908706665, avg loss: 1.3577445489168167\n",
      "trial: 1, iter: 800, curr loss: 1.278075098991394, avg loss: 1.3210189604759217\n",
      "trial: 1, iter: 1000, curr loss: 1.307800054550171, avg loss: 1.306131703853607\n",
      "trial: 1, iter: 1200, curr loss: 1.2938287258148193, avg loss: 1.2990713405609131\n",
      "trial: 1, iter: 1400, curr loss: 1.3065754175186157, avg loss: 1.2926262229681016\n",
      "trial: 1, ldr: 0.003420815337449312\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 200, curr loss: 1.3855314254760742, avg loss: 1.3875313538312912\n",
      "trial: 2, iter: 400, curr loss: 1.3795443773269653, avg loss: 1.384552876353264\n",
      "trial: 2, iter: 600, curr loss: 1.3450778722763062, avg loss: 1.3649965703487397\n",
      "trial: 2, iter: 800, curr loss: 1.3346105813980103, avg loss: 1.325088678598404\n",
      "trial: 2, iter: 1000, curr loss: 1.3475422859191895, avg loss: 1.3073006683588029\n",
      "trial: 2, iter: 1200, curr loss: 1.2966241836547852, avg loss: 1.2978586512804031\n",
      "trial: 2, iter: 1400, curr loss: 1.3327581882476807, avg loss: 1.2928002029657364\n",
      "trial: 2, ldr: 0.04546394571661949\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 200, curr loss: 1.3860034942626953, avg loss: 1.3862140262126923\n",
      "trial: 3, iter: 400, curr loss: 1.3539237976074219, avg loss: 1.3764063042402268\n",
      "trial: 3, iter: 600, curr loss: 1.347398281097412, avg loss: 1.338763148188591\n",
      "trial: 3, iter: 800, curr loss: 1.3390926122665405, avg loss: 1.3159667557477952\n",
      "trial: 3, iter: 1000, curr loss: 1.3312640190124512, avg loss: 1.3068887972831726\n",
      "trial: 3, iter: 1200, curr loss: 1.3251296281814575, avg loss: 1.3025362122058868\n",
      "trial: 3, iter: 1400, curr loss: 1.294107437133789, avg loss: 1.2965928548574448\n",
      "trial: 3, ldr: 0.03192409873008728\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 200, curr loss: 1.3873590230941772, avg loss: 1.3869144463539123\n",
      "trial: 4, iter: 400, curr loss: 1.3776739835739136, avg loss: 1.3834813636541368\n",
      "trial: 4, iter: 600, curr loss: 1.348753571510315, avg loss: 1.3581637102365494\n",
      "trial: 4, iter: 800, curr loss: 1.3313030004501343, avg loss: 1.3249061477184296\n",
      "trial: 4, iter: 1000, curr loss: 1.3235220909118652, avg loss: 1.3102375763654708\n",
      "trial: 4, iter: 1200, curr loss: 1.301498532295227, avg loss: 1.3018518406152726\n",
      "trial: 4, iter: 1400, curr loss: 1.315473198890686, avg loss: 1.292675598859787\n",
      "trial: 4, ldr: 0.07760743051767349\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 200, curr loss: 1.3877553939819336, avg loss: 1.3860680878162384\n",
      "trial: 5, iter: 400, curr loss: 1.364834189414978, avg loss: 1.378810505270958\n",
      "trial: 5, iter: 600, curr loss: 1.2952288389205933, avg loss: 1.3413159328699111\n",
      "trial: 5, iter: 800, curr loss: 1.3051952123641968, avg loss: 1.3116973918676376\n",
      "trial: 5, iter: 1000, curr loss: 1.3111321926116943, avg loss: 1.297307444214821\n",
      "trial: 5, iter: 1200, curr loss: 1.2923078536987305, avg loss: 1.2947544449567794\n",
      "trial: 5, iter: 1400, curr loss: 1.27943754196167, avg loss: 1.2887734335660934\n",
      "trial: 5, ldr: 0.06798206269741058\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.04527967059984803\n",
      "Experiment done with data path: ./data/catNon-lin-NI_1/data.5k.dz10.seed0.npy\n"
     ]
    }
   ],
   "source": [
    "# final arrays\n",
    "ldr_final = []\n",
    "data_path = []\n",
    "for in_dir in os.listdir('./data'):\n",
    "    curr_path = os.path.join('./data', in_dir)\n",
    "    if os.path.isdir(curr_path) and 'catNon' in in_dir:\n",
    "        for in_in_dir in os.listdir(curr_path):\n",
    "            if 'data' in in_in_dir:\n",
    "                print('Experiment start with data path: {}'.format(os.path.join(curr_path, in_in_dir)))\n",
    "                split = in_in_dir.split('.')\n",
    "                num_of_samples = int(split[1][:-1]) * 1000\n",
    "                z_dim = int(split[2][2:])\n",
    "                x_idx, y_idx, z_idx = [0], [1], list(range(2, z_dim + 2))\n",
    "                num_of_inner_iteration = int(20 * num_of_samples / batch_size)\n",
    "                ldr_arr = []\n",
    "                dv_arr = []\n",
    "                nwj_arr = []\n",
    "                for i in range(num_of_outer_iteration):\n",
    "                    ldr = multiclass_probabilistic_classifier_experiment(prime, data_range, num_of_samples, weight, feature_size, beta_arr, alpha_arr, para_param, priv_param, x_idx, y_idx, z_idx, hidden_size_arr, lr, num_of_mid_iteration, num_of_inner_iteration, batch_size, load_data=os.path.join(curr_path, in_in_dir), save_avg=200)\n",
    "                    ldr_arr.append(ldr)\n",
    "                ldr_mean = np.mean(np.asarray(ldr_arr))\n",
    "                ldr_final.append(ldr_mean)\n",
    "                data_path.append(os.path.join(curr_path, in_in_dir))\n",
    "                print('Experiment done with data path: {}'.format(os.path.join(curr_path, in_in_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5fc20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0011987021303502842,\n",
       " -0.001168770823132945,\n",
       " 0.26203800141811373,\n",
       " 0.25875690251588823,\n",
       " 0.012462627839995546,\n",
       " -0.0001273348770286731,\n",
       " -0.0006374029666378078,\n",
       " -0.0007525013432314153,\n",
       " 0.3185618199990131,\n",
       " 2.104283874033245e-05,\n",
       " 0.00016991513781249517,\n",
       " 0.15360785111784936,\n",
       " -0.0003700729634510935,\n",
       " -0.0011447861757187638,\n",
       " 0.03162260217126459,\n",
       " 0.18214184492826463,\n",
       " -0.0044855737383477385,\n",
       " -0.00021658502664649877,\n",
       " 0.19601108774542808,\n",
       " 0.04210853388067335]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldr_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
