{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:07:54.618247141Z",
     "start_time": "2023-12-12T22:07:53.577899277Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from probabilistic_classifier.experiment import ccmi_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "prime = None\n",
    "data_range = None\n",
    "num_of_samples = 20000\n",
    "\n",
    "hidden_size_arr = [64, 64]\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "num_of_outer_iteration = 10\n",
    "num_of_mid_iteration = 5\n",
    "num_of_inner_iteration = int(20 * num_of_samples / batch_size)\n",
    "\n",
    "para_param, priv_param = None, None\n",
    "beta_arr, alpha_arr = None, None\n",
    "\n",
    "feature_size = None\n",
    "weight = None\n",
    "z_dim = 50\n",
    "x_idx, y_idx, z_idx = [0], [1], list(range(2, z_dim + 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:09:44.633001741Z",
     "start_time": "2023-12-12T23:09:44.628233173Z"
    }
   },
   "id": "b8bb10f2344d44d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.1977669894695282, avg loss: 0.3436892538368702\n",
      "trial: 1, iter: 1000, curr loss: 0.21104758977890015, avg loss: 0.20742782159149648\n",
      "trial: 1, iter: 1500, curr loss: 0.2036542147397995, avg loss: 0.193592479839921\n",
      "trial: 1, iter: 2000, curr loss: 0.15413270890712738, avg loss: 0.19058800095319747\n",
      "trial: 1, iter: 2500, curr loss: 0.21894589066505432, avg loss: 0.1820121622979641\n",
      "trial: 1, iter: 3000, curr loss: 0.1460089087486267, avg loss: 0.17608827936649324\n",
      "trial: 1, iter: 3500, curr loss: 0.27165138721466064, avg loss: 0.17337381079792977\n",
      "trial: 1, iter: 4000, curr loss: 0.09141450375318527, avg loss: 0.16886015543341637\n",
      "trial: 1, iter: 4500, curr loss: 0.207227423787117, avg loss: 0.166479110583663\n",
      "trial: 1, iter: 5000, curr loss: 0.19797495007514954, avg loss: 0.16218541103601455\n",
      "trial: 1, iter: 5500, curr loss: 0.11248311400413513, avg loss: 0.15765915641188621\n",
      "trial: 1, iter: 6000, curr loss: 0.21895095705986023, avg loss: 0.15345025825500488\n",
      "trial: 1, ldr: 2.62629771232605, dv: 1.4787647724151611, nwj: 0.47588658332824707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.2031620293855667, avg loss: 0.35636401042342186\n",
      "trial: 2, iter: 1000, curr loss: 0.21174059808254242, avg loss: 0.20222983433306216\n",
      "trial: 2, iter: 1500, curr loss: 0.21911343932151794, avg loss: 0.19980819901823998\n",
      "trial: 2, iter: 2000, curr loss: 0.11578530073165894, avg loss: 0.1889731367379427\n",
      "trial: 2, iter: 2500, curr loss: 0.16563613712787628, avg loss: 0.1869407553523779\n",
      "trial: 2, iter: 3000, curr loss: 0.1453123390674591, avg loss: 0.1806665224134922\n",
      "trial: 2, iter: 3500, curr loss: 0.21747826039791107, avg loss: 0.18317517796158791\n",
      "trial: 2, iter: 4000, curr loss: 0.12521691620349884, avg loss: 0.1736164892911911\n",
      "trial: 2, iter: 4500, curr loss: 0.09329389035701752, avg loss: 0.16715535510331392\n",
      "trial: 2, iter: 5000, curr loss: 0.13471852242946625, avg loss: 0.16534090036153792\n",
      "trial: 2, iter: 5500, curr loss: 0.12741699814796448, avg loss: 0.15690097199380398\n",
      "trial: 2, iter: 6000, curr loss: 0.11410124599933624, avg loss: 0.16183198153972625\n",
      "trial: 2, ldr: 3.084460735321045, dv: 1.623115062713623, nwj: -0.22729730606079102\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.13158364593982697, avg loss: 0.3577294257879257\n",
      "trial: 3, iter: 1000, curr loss: 0.18796512484550476, avg loss: 0.20564431163668634\n",
      "trial: 3, iter: 1500, curr loss: 0.13980364799499512, avg loss: 0.19501117154955863\n",
      "trial: 3, iter: 2000, curr loss: 0.1811276078224182, avg loss: 0.19117972464859487\n",
      "trial: 3, iter: 2500, curr loss: 0.17321820557117462, avg loss: 0.18579335868358612\n",
      "trial: 3, iter: 3000, curr loss: 0.17197220027446747, avg loss: 0.18246538172662258\n",
      "trial: 3, iter: 3500, curr loss: 0.11431381106376648, avg loss: 0.17712483164668083\n",
      "trial: 3, iter: 4000, curr loss: 0.12751546502113342, avg loss: 0.17165448953211307\n",
      "trial: 3, iter: 4500, curr loss: 0.12184665352106094, avg loss: 0.16749295000731945\n",
      "trial: 3, iter: 5000, curr loss: 0.17474403977394104, avg loss: 0.1706108123213053\n",
      "trial: 3, iter: 5500, curr loss: 0.21777808666229248, avg loss: 0.16060108426213265\n",
      "trial: 3, iter: 6000, curr loss: 0.15931689739227295, avg loss: 0.15963000528514384\n",
      "trial: 3, ldr: 2.9177281856536865, dv: 1.296694278717041, nwj: -1.1405889987945557\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.2755769193172455, avg loss: 0.358255166977644\n",
      "trial: 4, iter: 1000, curr loss: 0.2247156798839569, avg loss: 0.2081226909160614\n",
      "trial: 4, iter: 1500, curr loss: 0.1247483640909195, avg loss: 0.19686540041863917\n",
      "trial: 4, iter: 2000, curr loss: 0.23005922138690948, avg loss: 0.18754281155765057\n",
      "trial: 4, iter: 2500, curr loss: 0.1328248232603073, avg loss: 0.18356863681972027\n",
      "trial: 4, iter: 3000, curr loss: 0.16005855798721313, avg loss: 0.17984295684099197\n",
      "trial: 4, iter: 3500, curr loss: 0.1406201273202896, avg loss: 0.17637581458687782\n",
      "trial: 4, iter: 4000, curr loss: 0.11452406644821167, avg loss: 0.17394448298215867\n",
      "trial: 4, iter: 4500, curr loss: 0.11781357228755951, avg loss: 0.17133573147654532\n",
      "trial: 4, iter: 5000, curr loss: 0.19020000100135803, avg loss: 0.1664594221264124\n",
      "trial: 4, iter: 5500, curr loss: 0.1880941540002823, avg loss: 0.1587337598875165\n",
      "trial: 4, iter: 6000, curr loss: 0.18106037378311157, avg loss: 0.16175128264725208\n",
      "trial: 4, ldr: 2.8472421169281006, dv: 1.5020502805709839, nwj: 0.00831913948059082\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.23485317826271057, avg loss: 0.36033966244757176\n",
      "trial: 5, iter: 1000, curr loss: 0.169891357421875, avg loss: 0.20861009126901628\n",
      "trial: 5, iter: 1500, curr loss: 0.17613360285758972, avg loss: 0.19999902965128422\n",
      "trial: 5, iter: 2000, curr loss: 0.15999525785446167, avg loss: 0.19224903294444085\n",
      "trial: 5, iter: 2500, curr loss: 0.1090461015701294, avg loss: 0.1851281256377697\n",
      "trial: 5, iter: 3000, curr loss: 0.21067583560943604, avg loss: 0.1754064754396677\n",
      "trial: 5, iter: 3500, curr loss: 0.20527684688568115, avg loss: 0.17162147942185402\n",
      "trial: 5, iter: 4000, curr loss: 0.2217346727848053, avg loss: 0.16898425452411175\n",
      "trial: 5, iter: 4500, curr loss: 0.148367777466774, avg loss: 0.1662784433364868\n",
      "trial: 5, iter: 5000, curr loss: 0.1184997707605362, avg loss: 0.1635022953003645\n",
      "trial: 5, iter: 5500, curr loss: 0.25080299377441406, avg loss: 0.15929189748317002\n",
      "trial: 5, iter: 6000, curr loss: 0.1266031414270401, avg loss: 0.15879144591093064\n",
      "trial: 5, ldr: 2.8033103942871094, dv: 1.5233107805252075, nwj: 0.20667219161987305\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.855807828903198\n",
      "\tdv: 1.4847870349884034\n",
      "\tnwj: -0.13540167808532716\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6924344897270203, avg loss: 0.6928119888305664\n",
      "trial: 1, iter: 1000, curr loss: 0.6932719945907593, avg loss: 0.690350994348526\n",
      "trial: 1, iter: 1500, curr loss: 0.6877895593643188, avg loss: 0.6870404477119446\n",
      "trial: 1, iter: 2000, curr loss: 0.6736692190170288, avg loss: 0.6819435653686523\n",
      "trial: 1, iter: 2500, curr loss: 0.6630716323852539, avg loss: 0.6762578048706055\n",
      "trial: 1, iter: 3000, curr loss: 0.6579877138137817, avg loss: 0.6695507644414902\n",
      "trial: 1, iter: 3500, curr loss: 0.6801878213882446, avg loss: 0.6630897151231766\n",
      "trial: 1, iter: 4000, curr loss: 0.6166402101516724, avg loss: 0.6553890409469605\n",
      "trial: 1, iter: 4500, curr loss: 0.6138478517532349, avg loss: 0.6497423750162125\n",
      "trial: 1, iter: 5000, curr loss: 0.6853612661361694, avg loss: 0.6440835053920746\n",
      "trial: 1, iter: 5500, curr loss: 0.617702841758728, avg loss: 0.6379260882139206\n",
      "trial: 1, iter: 6000, curr loss: 0.6544959545135498, avg loss: 0.6327815557718277\n",
      "trial: 1, ldr: -0.17764858901500702, dv: -0.49276202917099, nwj: -0.5480632781982422\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6914236545562744, avg loss: 0.6927094433307648\n",
      "trial: 2, iter: 1000, curr loss: 0.6896610260009766, avg loss: 0.6910271818637848\n",
      "trial: 2, iter: 1500, curr loss: 0.6764365434646606, avg loss: 0.6859743715524673\n",
      "trial: 2, iter: 2000, curr loss: 0.6520918607711792, avg loss: 0.6794786978960037\n",
      "trial: 2, iter: 2500, curr loss: 0.6757887601852417, avg loss: 0.6731047332286835\n",
      "trial: 2, iter: 3000, curr loss: 0.6672859191894531, avg loss: 0.6658480516672134\n",
      "trial: 2, iter: 3500, curr loss: 0.6450754404067993, avg loss: 0.6572188512086868\n",
      "trial: 2, iter: 4000, curr loss: 0.6562705039978027, avg loss: 0.6520900844335557\n",
      "trial: 2, iter: 4500, curr loss: 0.6369650363922119, avg loss: 0.6455982567071915\n",
      "trial: 2, iter: 5000, curr loss: 0.6351169943809509, avg loss: 0.6406554259061813\n",
      "trial: 2, iter: 5500, curr loss: 0.61137455701828, avg loss: 0.6345522869825363\n",
      "trial: 2, iter: 6000, curr loss: 0.6304527521133423, avg loss: 0.6301924011707306\n",
      "trial: 2, ldr: -0.10174441337585449, dv: -0.5581899285316467, nwj: -0.6801978349685669\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6930732727050781, avg loss: 0.6925645867586135\n",
      "trial: 3, iter: 1000, curr loss: 0.688086748123169, avg loss: 0.6911718071699142\n",
      "trial: 3, iter: 1500, curr loss: 0.6797469258308411, avg loss: 0.6881319668292999\n",
      "trial: 3, iter: 2000, curr loss: 0.6757868528366089, avg loss: 0.6840975707769394\n",
      "trial: 3, iter: 2500, curr loss: 0.6694038510322571, avg loss: 0.6769550415277481\n",
      "trial: 3, iter: 3000, curr loss: 0.6799194812774658, avg loss: 0.6720823312997818\n",
      "trial: 3, iter: 3500, curr loss: 0.6877894997596741, avg loss: 0.6657615203857422\n",
      "trial: 3, iter: 4000, curr loss: 0.6718157529830933, avg loss: 0.6597149105072021\n",
      "trial: 3, iter: 4500, curr loss: 0.6363974809646606, avg loss: 0.6525847525596619\n",
      "trial: 3, iter: 5000, curr loss: 0.659923255443573, avg loss: 0.6466474488973618\n",
      "trial: 3, iter: 5500, curr loss: 0.6205328702926636, avg loss: 0.6404225066900253\n",
      "trial: 3, iter: 6000, curr loss: 0.6286665201187134, avg loss: 0.6338955034017563\n",
      "trial: 3, ldr: -0.13847142457962036, dv: -0.49422430992126465, nwj: -0.5657262802124023\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6907253861427307, avg loss: 0.6924420696496963\n",
      "trial: 4, iter: 1000, curr loss: 0.6967195272445679, avg loss: 0.6909011961221695\n",
      "trial: 4, iter: 1500, curr loss: 0.6818505525588989, avg loss: 0.6872478125095367\n",
      "trial: 4, iter: 2000, curr loss: 0.6868573427200317, avg loss: 0.6814141844511032\n",
      "trial: 4, iter: 2500, curr loss: 0.6944910287857056, avg loss: 0.6747271699905395\n",
      "trial: 4, iter: 3000, curr loss: 0.6818097829818726, avg loss: 0.6673148407936096\n",
      "trial: 4, iter: 3500, curr loss: 0.6991463899612427, avg loss: 0.6606698921918869\n",
      "trial: 4, iter: 4000, curr loss: 0.6282839179039001, avg loss: 0.6536747331619263\n",
      "trial: 4, iter: 4500, curr loss: 0.6323400735855103, avg loss: 0.6489649149179458\n",
      "trial: 4, iter: 5000, curr loss: 0.6312751770019531, avg loss: 0.6430393221378327\n",
      "trial: 4, iter: 5500, curr loss: 0.6354418396949768, avg loss: 0.6376541831493377\n",
      "trial: 4, iter: 6000, curr loss: 0.6540620923042297, avg loss: 0.6317677503824234\n",
      "trial: 4, ldr: -0.06653311848640442, dv: -0.49525055289268494, nwj: -0.6018202304840088\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6924976110458374, avg loss: 0.6928536009788513\n",
      "trial: 5, iter: 1000, curr loss: 0.6894323229789734, avg loss: 0.6911815230846405\n",
      "trial: 5, iter: 1500, curr loss: 0.684661865234375, avg loss: 0.6884748672246933\n",
      "trial: 5, iter: 2000, curr loss: 0.6677735447883606, avg loss: 0.68390383207798\n",
      "trial: 5, iter: 2500, curr loss: 0.6980616450309753, avg loss: 0.678135132431984\n",
      "trial: 5, iter: 3000, curr loss: 0.6632210612297058, avg loss: 0.67053666472435\n",
      "trial: 5, iter: 3500, curr loss: 0.669480562210083, avg loss: 0.6646014785766602\n",
      "trial: 5, iter: 4000, curr loss: 0.6844756603240967, avg loss: 0.657650265455246\n",
      "trial: 5, iter: 4500, curr loss: 0.650222659111023, avg loss: 0.6517879166603089\n",
      "trial: 5, iter: 5000, curr loss: 0.6459146738052368, avg loss: 0.6454740898609161\n",
      "trial: 5, iter: 5500, curr loss: 0.6577352285385132, avg loss: 0.6392602121829987\n",
      "trial: 5, iter: 6000, curr loss: 0.6515225172042847, avg loss: 0.6354507156610489\n",
      "trial: 5, ldr: -0.12783779203891754, dv: -0.4894428849220276, nwj: -0.563469648361206\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.12244706749916076\n",
      "\tdv: -0.5059739410877228\n",
      "\tnwj: -0.5918554544448853\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.2091720998287201, avg loss: 0.3498349215388298\n",
      "trial: 1, iter: 1000, curr loss: 0.17569273710250854, avg loss: 0.2069165771305561\n",
      "trial: 1, iter: 1500, curr loss: 0.13481217622756958, avg loss: 0.19928421248495579\n",
      "trial: 1, iter: 2000, curr loss: 0.1681334674358368, avg loss: 0.19130368004739284\n",
      "trial: 1, iter: 2500, curr loss: 0.19038048386573792, avg loss: 0.187237145408988\n",
      "trial: 1, iter: 3000, curr loss: 0.22395890951156616, avg loss: 0.18601091594994068\n",
      "trial: 1, iter: 3500, curr loss: 0.15678671002388, avg loss: 0.1825100798457861\n",
      "trial: 1, iter: 4000, curr loss: 0.17392855882644653, avg loss: 0.17479379917681218\n",
      "trial: 1, iter: 4500, curr loss: 0.1785845011472702, avg loss: 0.16916596941649914\n",
      "trial: 1, iter: 5000, curr loss: 0.23248057067394257, avg loss: 0.16392195720970631\n",
      "trial: 1, iter: 5500, curr loss: 0.17832347750663757, avg loss: 0.1620144745260477\n",
      "trial: 1, iter: 6000, curr loss: 0.1484992504119873, avg loss: 0.15821397264301776\n",
      "trial: 1, ldr: 2.8554282188415527, dv: 1.4009981155395508, nwj: -0.42661428451538086\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.21722356975078583, avg loss: 0.35350527480244637\n",
      "trial: 2, iter: 1000, curr loss: 0.15359747409820557, avg loss: 0.2083533083796501\n",
      "trial: 2, iter: 1500, curr loss: 0.2079218626022339, avg loss: 0.20273149286210537\n",
      "trial: 2, iter: 2000, curr loss: 0.20188221335411072, avg loss: 0.1921182852089405\n",
      "trial: 2, iter: 2500, curr loss: 0.2251974195241928, avg loss: 0.18833623524010182\n",
      "trial: 2, iter: 3000, curr loss: 0.21368516981601715, avg loss: 0.18113699251413345\n",
      "trial: 2, iter: 3500, curr loss: 0.1425156593322754, avg loss: 0.18058465775847435\n",
      "trial: 2, iter: 4000, curr loss: 0.18221968412399292, avg loss: 0.1702554410919547\n",
      "trial: 2, iter: 4500, curr loss: 0.16681715846061707, avg loss: 0.16706817109882832\n",
      "trial: 2, iter: 5000, curr loss: 0.20174351334571838, avg loss: 0.16728867986798288\n",
      "trial: 2, iter: 5500, curr loss: 0.12334132939577103, avg loss: 0.1600181372240186\n",
      "trial: 2, iter: 6000, curr loss: 0.18172955513000488, avg loss: 0.15806375794112681\n",
      "trial: 2, ldr: 2.8590304851531982, dv: 1.3577260971069336, nwj: -0.6285083293914795\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.21612736582756042, avg loss: 0.35471807673573497\n",
      "trial: 3, iter: 1000, curr loss: 0.192769393324852, avg loss: 0.20606172500550746\n",
      "trial: 3, iter: 1500, curr loss: 0.15758103132247925, avg loss: 0.19668519288301467\n",
      "trial: 3, iter: 2000, curr loss: 0.2335343211889267, avg loss: 0.19356476390361785\n",
      "trial: 3, iter: 2500, curr loss: 0.24513472616672516, avg loss: 0.18382442869246007\n",
      "trial: 3, iter: 3000, curr loss: 0.19099938869476318, avg loss: 0.18091728703677654\n",
      "trial: 3, iter: 3500, curr loss: 0.18579018115997314, avg loss: 0.17564015284180642\n",
      "trial: 3, iter: 4000, curr loss: 0.12555626034736633, avg loss: 0.17593049016594886\n",
      "trial: 3, iter: 4500, curr loss: 0.12481121718883514, avg loss: 0.16858750012516976\n",
      "trial: 3, iter: 5000, curr loss: 0.16574174165725708, avg loss: 0.16390396781265737\n",
      "trial: 3, iter: 5500, curr loss: 0.14827674627304077, avg loss: 0.15884123431146144\n",
      "trial: 3, iter: 6000, curr loss: 0.18897411227226257, avg loss: 0.15471780145913364\n",
      "trial: 3, ldr: 3.0437228679656982, dv: 1.2838468551635742, nwj: -1.767993688583374\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.20734737813472748, avg loss: 0.3499570307135582\n",
      "trial: 4, iter: 1000, curr loss: 0.11008427292108536, avg loss: 0.20964798794686795\n",
      "trial: 4, iter: 1500, curr loss: 0.19885259866714478, avg loss: 0.1969598424732685\n",
      "trial: 4, iter: 2000, curr loss: 0.14116789400577545, avg loss: 0.18982555368542672\n",
      "trial: 4, iter: 2500, curr loss: 0.18301644921302795, avg loss: 0.186450186252594\n",
      "trial: 4, iter: 3000, curr loss: 0.15259121358394623, avg loss: 0.17639486715197564\n",
      "trial: 4, iter: 3500, curr loss: 0.12940514087677002, avg loss: 0.1760303667485714\n",
      "trial: 4, iter: 4000, curr loss: 0.10755351185798645, avg loss: 0.17083543939888476\n",
      "trial: 4, iter: 4500, curr loss: 0.21263709664344788, avg loss: 0.16688414561748505\n",
      "trial: 4, iter: 5000, curr loss: 0.0985715240240097, avg loss: 0.1666249165982008\n",
      "trial: 4, iter: 5500, curr loss: 0.11195501685142517, avg loss: 0.1644518781453371\n",
      "trial: 4, iter: 6000, curr loss: 0.12495815753936768, avg loss: 0.15476290265470743\n",
      "trial: 4, ldr: 2.855226516723633, dv: 1.519187092781067, nwj: 0.05127882957458496\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.2979664206504822, avg loss: 0.3521026784181595\n",
      "trial: 5, iter: 1000, curr loss: 0.19188901782035828, avg loss: 0.20766137009859084\n",
      "trial: 5, iter: 1500, curr loss: 0.21084898710250854, avg loss: 0.1961350177824497\n",
      "trial: 5, iter: 2000, curr loss: 0.17734262347221375, avg loss: 0.1923067636191845\n",
      "trial: 5, iter: 2500, curr loss: 0.18903103470802307, avg loss: 0.18635654336214066\n",
      "trial: 5, iter: 3000, curr loss: 0.2007097601890564, avg loss: 0.17877888089418412\n",
      "trial: 5, iter: 3500, curr loss: 0.21403418481349945, avg loss: 0.1808227887004614\n",
      "trial: 5, iter: 4000, curr loss: 0.19003835320472717, avg loss: 0.1731663590222597\n",
      "trial: 5, iter: 4500, curr loss: 0.13518822193145752, avg loss: 0.16780243119597435\n",
      "trial: 5, iter: 5000, curr loss: 0.15293683111667633, avg loss: 0.16596123720705508\n",
      "trial: 5, iter: 5500, curr loss: 0.16490882635116577, avg loss: 0.15973467434942723\n",
      "trial: 5, iter: 6000, curr loss: 0.1460486799478531, avg loss: 0.15642828778922557\n",
      "trial: 5, ldr: 2.8184447288513184, dv: 1.1854479312896729, nwj: -1.3007478713989258\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.88637056350708\n",
      "\tdv: 1.3494412183761597\n",
      "\tnwj: -0.8145170688629151\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6901299953460693, avg loss: 0.6929511505365372\n",
      "trial: 1, iter: 1000, curr loss: 0.6869363784790039, avg loss: 0.6915259039402009\n",
      "trial: 1, iter: 1500, curr loss: 0.6752481460571289, avg loss: 0.6874576004743576\n",
      "trial: 1, iter: 2000, curr loss: 0.6771431565284729, avg loss: 0.6822087463140488\n",
      "trial: 1, iter: 2500, curr loss: 0.6656702756881714, avg loss: 0.6755638018846511\n",
      "trial: 1, iter: 3000, curr loss: 0.673900842666626, avg loss: 0.6686870416402817\n",
      "trial: 1, iter: 3500, curr loss: 0.6197224855422974, avg loss: 0.6594830647706985\n",
      "trial: 1, iter: 4000, curr loss: 0.6468754410743713, avg loss: 0.6545869251489639\n",
      "trial: 1, iter: 4500, curr loss: 0.6260350942611694, avg loss: 0.6475381314754486\n",
      "trial: 1, iter: 5000, curr loss: 0.627068281173706, avg loss: 0.6420578142404556\n",
      "trial: 1, iter: 5500, curr loss: 0.6749190092086792, avg loss: 0.6351514898538589\n",
      "trial: 1, iter: 6000, curr loss: 0.6588680744171143, avg loss: 0.6305610624551773\n",
      "trial: 1, ldr: -0.12604811787605286, dv: -0.48284006118774414, nwj: -0.5547866821289062\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6894458532333374, avg loss: 0.692822098493576\n",
      "trial: 2, iter: 1000, curr loss: 0.6962195634841919, avg loss: 0.6907622385025024\n",
      "trial: 2, iter: 1500, curr loss: 0.7114529013633728, avg loss: 0.6868673157691956\n",
      "trial: 2, iter: 2000, curr loss: 0.6536592245101929, avg loss: 0.6818295686244965\n",
      "trial: 2, iter: 2500, curr loss: 0.6989867687225342, avg loss: 0.6744889261722564\n",
      "trial: 2, iter: 3000, curr loss: 0.6449130773544312, avg loss: 0.6674096205234528\n",
      "trial: 2, iter: 3500, curr loss: 0.6573032140731812, avg loss: 0.660273215174675\n",
      "trial: 2, iter: 4000, curr loss: 0.6418097615242004, avg loss: 0.6528760392665863\n",
      "trial: 2, iter: 4500, curr loss: 0.6668834686279297, avg loss: 0.646186811208725\n",
      "trial: 2, iter: 5000, curr loss: 0.6475900411605835, avg loss: 0.6417832355499268\n",
      "trial: 2, iter: 5500, curr loss: 0.6606460809707642, avg loss: 0.634130774140358\n",
      "trial: 2, iter: 6000, curr loss: 0.6601669192314148, avg loss: 0.6291142059564591\n",
      "trial: 2, ldr: -0.03451661765575409, dv: -0.505034327507019, nwj: -0.6353392601013184\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6924383640289307, avg loss: 0.692944057226181\n",
      "trial: 3, iter: 1000, curr loss: 0.6855477690696716, avg loss: 0.6915457832813263\n",
      "trial: 3, iter: 1500, curr loss: 0.7028248310089111, avg loss: 0.6885723589658738\n",
      "trial: 3, iter: 2000, curr loss: 0.6811930537223816, avg loss: 0.6836602735519409\n",
      "trial: 3, iter: 2500, curr loss: 0.6558191776275635, avg loss: 0.6761929832696915\n",
      "trial: 3, iter: 3000, curr loss: 0.6862918138504028, avg loss: 0.6702685970067978\n",
      "trial: 3, iter: 3500, curr loss: 0.6447682976722717, avg loss: 0.6611583162546157\n",
      "trial: 3, iter: 4000, curr loss: 0.6627641916275024, avg loss: 0.6542942844629288\n",
      "trial: 3, iter: 4500, curr loss: 0.6113265752792358, avg loss: 0.6481670325994492\n",
      "trial: 3, iter: 5000, curr loss: 0.6223737001419067, avg loss: 0.6417834776639938\n",
      "trial: 3, iter: 5500, curr loss: 0.6499587297439575, avg loss: 0.6364540028572082\n",
      "trial: 3, iter: 6000, curr loss: 0.5889556407928467, avg loss: 0.6293332285881043\n",
      "trial: 3, ldr: -0.11475866287946701, dv: -0.4866851568222046, nwj: -0.5652849674224854\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6934390664100647, avg loss: 0.6928087626695633\n",
      "trial: 4, iter: 1000, curr loss: 0.6864707469940186, avg loss: 0.6916114566326141\n",
      "trial: 4, iter: 1500, curr loss: 0.6853514909744263, avg loss: 0.6888198480606079\n",
      "trial: 4, iter: 2000, curr loss: 0.6740423440933228, avg loss: 0.6826792588233948\n",
      "trial: 4, iter: 2500, curr loss: 0.679235577583313, avg loss: 0.677174168229103\n",
      "trial: 4, iter: 3000, curr loss: 0.6755367517471313, avg loss: 0.670781455874443\n",
      "trial: 4, iter: 3500, curr loss: 0.6510552763938904, avg loss: 0.6642402511835098\n",
      "trial: 4, iter: 4000, curr loss: 0.680139422416687, avg loss: 0.6563810812234878\n",
      "trial: 4, iter: 4500, curr loss: 0.6692252159118652, avg loss: 0.6507645285129547\n",
      "trial: 4, iter: 5000, curr loss: 0.6363536715507507, avg loss: 0.6440929111242294\n",
      "trial: 4, iter: 5500, curr loss: 0.6234248876571655, avg loss: 0.6386621601581574\n",
      "trial: 4, iter: 6000, curr loss: 0.6432161331176758, avg loss: 0.6329417593479156\n",
      "trial: 4, ldr: -0.055946677923202515, dv: -0.4950375258922577, nwj: -0.6072429418563843\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.691642165184021, avg loss: 0.6927034715414048\n",
      "trial: 5, iter: 1000, curr loss: 0.6947748064994812, avg loss: 0.6911903960704804\n",
      "trial: 5, iter: 1500, curr loss: 0.6850489974021912, avg loss: 0.6865164573192597\n",
      "trial: 5, iter: 2000, curr loss: 0.6767396330833435, avg loss: 0.6817438659667969\n",
      "trial: 5, iter: 2500, curr loss: 0.7078831195831299, avg loss: 0.6757725205421448\n",
      "trial: 5, iter: 3000, curr loss: 0.6518473625183105, avg loss: 0.670305500984192\n",
      "trial: 5, iter: 3500, curr loss: 0.6766335964202881, avg loss: 0.661670023560524\n",
      "trial: 5, iter: 4000, curr loss: 0.6481269598007202, avg loss: 0.6553198608160019\n",
      "trial: 5, iter: 4500, curr loss: 0.611952006816864, avg loss: 0.6486604670286179\n",
      "trial: 5, iter: 5000, curr loss: 0.6158071756362915, avg loss: 0.6429690345525741\n",
      "trial: 5, iter: 5500, curr loss: 0.6642239689826965, avg loss: 0.6366003514528275\n",
      "trial: 5, iter: 6000, curr loss: 0.6536385416984558, avg loss: 0.6336560019254684\n",
      "trial: 5, ldr: -0.06664296239614487, dv: -0.49279549717903137, nwj: -0.5979973077774048\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.07958260774612427\n",
      "\tdv: -0.4924785137176514\n",
      "\tnwj: -0.5921302318572998\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.21363553404808044, avg loss: 0.3447197133004665\n",
      "trial: 1, iter: 1000, curr loss: 0.29705387353897095, avg loss: 0.20297914658486843\n",
      "trial: 1, iter: 1500, curr loss: 0.18780282139778137, avg loss: 0.19558465142548084\n",
      "trial: 1, iter: 2000, curr loss: 0.24347743391990662, avg loss: 0.18813454337418078\n",
      "trial: 1, iter: 2500, curr loss: 0.20362919569015503, avg loss: 0.1797780453711748\n",
      "trial: 1, iter: 3000, curr loss: 0.2149893045425415, avg loss: 0.17863116815686225\n",
      "trial: 1, iter: 3500, curr loss: 0.16492748260498047, avg loss: 0.17381733863800763\n",
      "trial: 1, iter: 4000, curr loss: 0.18529199063777924, avg loss: 0.16934148624539375\n",
      "trial: 1, iter: 4500, curr loss: 0.13536202907562256, avg loss: 0.16394049188494683\n",
      "trial: 1, iter: 5000, curr loss: 0.15702849626541138, avg loss: 0.1619240526854992\n",
      "trial: 1, iter: 5500, curr loss: 0.14365461468696594, avg loss: 0.15951745429635047\n",
      "trial: 1, iter: 6000, curr loss: 0.26251745223999023, avg loss: 0.15656526277959346\n",
      "trial: 1, ldr: 2.6379926204681396, dv: 1.3817812204360962, nwj: 0.12590241432189941\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.19390636682510376, avg loss: 0.35190534448623656\n",
      "trial: 2, iter: 1000, curr loss: 0.26970985531806946, avg loss: 0.20631254553794862\n",
      "trial: 2, iter: 1500, curr loss: 0.18068331480026245, avg loss: 0.19283903366327285\n",
      "trial: 2, iter: 2000, curr loss: 0.23293159902095795, avg loss: 0.18914700421690941\n",
      "trial: 2, iter: 2500, curr loss: 0.20646414160728455, avg loss: 0.1829385262131691\n",
      "trial: 2, iter: 3000, curr loss: 0.21632534265518188, avg loss: 0.18082689212262631\n",
      "trial: 2, iter: 3500, curr loss: 0.10393093526363373, avg loss: 0.17710465875267983\n",
      "trial: 2, iter: 4000, curr loss: 0.2105381041765213, avg loss: 0.1751352332085371\n",
      "trial: 2, iter: 4500, curr loss: 0.2085573971271515, avg loss: 0.17036354607343673\n",
      "trial: 2, iter: 5000, curr loss: 0.12631751596927643, avg loss: 0.16113162083923815\n",
      "trial: 2, iter: 5500, curr loss: 0.17772668600082397, avg loss: 0.16266669751703738\n",
      "trial: 2, iter: 6000, curr loss: 0.18473270535469055, avg loss: 0.1603232540041208\n",
      "trial: 2, ldr: 2.8937485218048096, dv: 1.3192766904830933, nwj: -0.9344422817230225\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.2704616189002991, avg loss: 0.35411280554533003\n",
      "trial: 3, iter: 1000, curr loss: 0.1803187131881714, avg loss: 0.20378622648119926\n",
      "trial: 3, iter: 1500, curr loss: 0.16168266534805298, avg loss: 0.19251684029400348\n",
      "trial: 3, iter: 2000, curr loss: 0.2146441638469696, avg loss: 0.1894656558036804\n",
      "trial: 3, iter: 2500, curr loss: 0.1902771145105362, avg loss: 0.18235104024410248\n",
      "trial: 3, iter: 3000, curr loss: 0.15500620007514954, avg loss: 0.1809437303841114\n",
      "trial: 3, iter: 3500, curr loss: 0.1971518099308014, avg loss: 0.17498457941412926\n",
      "trial: 3, iter: 4000, curr loss: 0.12790074944496155, avg loss: 0.17187492184340955\n",
      "trial: 3, iter: 4500, curr loss: 0.2017829567193985, avg loss: 0.16420070374011994\n",
      "trial: 3, iter: 5000, curr loss: 0.17325471341609955, avg loss: 0.16125284330546855\n",
      "trial: 3, iter: 5500, curr loss: 0.13260534405708313, avg loss: 0.15607165105640888\n",
      "trial: 3, iter: 6000, curr loss: 0.24555976688861847, avg loss: 0.1563748936727643\n",
      "trial: 3, ldr: 2.40185284614563, dv: 1.5441207885742188, nwj: 1.0440456867218018\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.25498145818710327, avg loss: 0.34787040719389917\n",
      "trial: 4, iter: 1000, curr loss: 0.2813112139701843, avg loss: 0.2062531595379114\n",
      "trial: 4, iter: 1500, curr loss: 0.18859773874282837, avg loss: 0.1925527551025152\n",
      "trial: 4, iter: 2000, curr loss: 0.1973571479320526, avg loss: 0.19159935292601585\n",
      "trial: 4, iter: 2500, curr loss: 0.20873774588108063, avg loss: 0.18129728415608407\n",
      "trial: 4, iter: 3000, curr loss: 0.24693132936954498, avg loss: 0.17753054995834827\n",
      "trial: 4, iter: 3500, curr loss: 0.17757561802864075, avg loss: 0.1753015371412039\n",
      "trial: 4, iter: 4000, curr loss: 0.18746821582317352, avg loss: 0.16898806096613408\n",
      "trial: 4, iter: 4500, curr loss: 0.17853806912899017, avg loss: 0.1640401650071144\n",
      "trial: 4, iter: 5000, curr loss: 0.22666282951831818, avg loss: 0.16395697122812272\n",
      "trial: 4, iter: 5500, curr loss: 0.1965334415435791, avg loss: 0.15873024712502956\n",
      "trial: 4, iter: 6000, curr loss: 0.12711235880851746, avg loss: 0.15574360252916813\n",
      "trial: 4, ldr: 2.88417649269104, dv: 1.2668263912200928, nwj: -1.1555416584014893\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.2347097396850586, avg loss: 0.3656634529232979\n",
      "trial: 5, iter: 1000, curr loss: 0.13912881910800934, avg loss: 0.20846263986825944\n",
      "trial: 5, iter: 1500, curr loss: 0.24360080063343048, avg loss: 0.19519181008636952\n",
      "trial: 5, iter: 2000, curr loss: 0.20334197580814362, avg loss: 0.18929710321128368\n",
      "trial: 5, iter: 2500, curr loss: 0.15707246959209442, avg loss: 0.18562582302093505\n",
      "trial: 5, iter: 3000, curr loss: 0.13662520051002502, avg loss: 0.1790332172960043\n",
      "trial: 5, iter: 3500, curr loss: 0.15326306223869324, avg loss: 0.1763121704608202\n",
      "trial: 5, iter: 4000, curr loss: 0.09874977171421051, avg loss: 0.16780472028255464\n",
      "trial: 5, iter: 4500, curr loss: 0.17353108525276184, avg loss: 0.16708740667998792\n",
      "trial: 5, iter: 5000, curr loss: 0.23500032722949982, avg loss: 0.1612670649215579\n",
      "trial: 5, iter: 5500, curr loss: 0.14993783831596375, avg loss: 0.15746696488559245\n",
      "trial: 5, iter: 6000, curr loss: 0.22322502732276917, avg loss: 0.15344735968112946\n",
      "trial: 5, ldr: 2.868866205215454, dv: 1.3090636730194092, nwj: -0.8890154361724854\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.7373273372650146\n",
      "\tdv: 1.364213752746582\n",
      "\tnwj: -0.36181025505065917\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6940027475357056, avg loss: 0.6926600307226181\n",
      "trial: 1, iter: 1000, curr loss: 0.6947413682937622, avg loss: 0.691604097366333\n",
      "trial: 1, iter: 1500, curr loss: 0.6903866529464722, avg loss: 0.6885306376218796\n",
      "trial: 1, iter: 2000, curr loss: 0.6765952110290527, avg loss: 0.6835301160812378\n",
      "trial: 1, iter: 2500, curr loss: 0.6748976707458496, avg loss: 0.6787003268003464\n",
      "trial: 1, iter: 3000, curr loss: 0.6469889879226685, avg loss: 0.6727861543893814\n",
      "trial: 1, iter: 3500, curr loss: 0.6642086505889893, avg loss: 0.6668711047172546\n",
      "trial: 1, iter: 4000, curr loss: 0.6595325469970703, avg loss: 0.6606339054107666\n",
      "trial: 1, iter: 4500, curr loss: 0.647250771522522, avg loss: 0.6554914687871933\n",
      "trial: 1, iter: 5000, curr loss: 0.6879925727844238, avg loss: 0.6480590481758117\n",
      "trial: 1, iter: 5500, curr loss: 0.6624303460121155, avg loss: 0.641713210940361\n",
      "trial: 1, iter: 6000, curr loss: 0.5963611006736755, avg loss: 0.6355959634780883\n",
      "trial: 1, ldr: -0.08695661276578903, dv: -0.42059481143951416, nwj: -0.48299455642700195\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6901001334190369, avg loss: 0.6926610653400421\n",
      "trial: 2, iter: 1000, curr loss: 0.6892695426940918, avg loss: 0.6909983484745026\n",
      "trial: 2, iter: 1500, curr loss: 0.6873706579208374, avg loss: 0.6877531996965408\n",
      "trial: 2, iter: 2000, curr loss: 0.6849751472473145, avg loss: 0.6823522845506668\n",
      "trial: 2, iter: 2500, curr loss: 0.6528503894805908, avg loss: 0.6773883899450303\n",
      "trial: 2, iter: 3000, curr loss: 0.6733913421630859, avg loss: 0.6703245598077774\n",
      "trial: 2, iter: 3500, curr loss: 0.6653752326965332, avg loss: 0.6628379385471344\n",
      "trial: 2, iter: 4000, curr loss: 0.6819862127304077, avg loss: 0.6563369599580765\n",
      "trial: 2, iter: 4500, curr loss: 0.6364006996154785, avg loss: 0.6474168111085892\n",
      "trial: 2, iter: 5000, curr loss: 0.6222686171531677, avg loss: 0.643120948433876\n",
      "trial: 2, iter: 5500, curr loss: 0.6186914443969727, avg loss: 0.6372576010227203\n",
      "trial: 2, iter: 6000, curr loss: 0.621056318283081, avg loss: 0.6324820712804794\n",
      "trial: 2, ldr: -0.12747564911842346, dv: -0.456870973110199, nwj: -0.5176029205322266\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6935743093490601, avg loss: 0.6929204412698746\n",
      "trial: 3, iter: 1000, curr loss: 0.6883578300476074, avg loss: 0.691415090084076\n",
      "trial: 3, iter: 1500, curr loss: 0.6809772253036499, avg loss: 0.6880327670574188\n",
      "trial: 3, iter: 2000, curr loss: 0.6854941844940186, avg loss: 0.6846819820404053\n",
      "trial: 3, iter: 2500, curr loss: 0.6676450371742249, avg loss: 0.6792814601659775\n",
      "trial: 3, iter: 3000, curr loss: 0.6773569583892822, avg loss: 0.671948230624199\n",
      "trial: 3, iter: 3500, curr loss: 0.6744526624679565, avg loss: 0.6668559603691101\n",
      "trial: 3, iter: 4000, curr loss: 0.6372016072273254, avg loss: 0.6586621215343476\n",
      "trial: 3, iter: 4500, curr loss: 0.6375194787979126, avg loss: 0.6532529606819153\n",
      "trial: 3, iter: 5000, curr loss: 0.6176475882530212, avg loss: 0.6457909096479416\n",
      "trial: 3, iter: 5500, curr loss: 0.6122767925262451, avg loss: 0.6398594939708709\n",
      "trial: 3, iter: 6000, curr loss: 0.5985709428787231, avg loss: 0.6360176998376846\n",
      "trial: 3, ldr: -0.0779981017112732, dv: -0.4653189480304718, nwj: -0.5510270595550537\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6936697959899902, avg loss: 0.6927084593772889\n",
      "trial: 4, iter: 1000, curr loss: 0.6912470459938049, avg loss: 0.6913530713319779\n",
      "trial: 4, iter: 1500, curr loss: 0.6871706247329712, avg loss: 0.6876921122074127\n",
      "trial: 4, iter: 2000, curr loss: 0.6802607178688049, avg loss: 0.6830106250047684\n",
      "trial: 4, iter: 2500, curr loss: 0.6496814489364624, avg loss: 0.676394516825676\n",
      "trial: 4, iter: 3000, curr loss: 0.6963274478912354, avg loss: 0.6692686008214951\n",
      "trial: 4, iter: 3500, curr loss: 0.6604341268539429, avg loss: 0.6627519211769104\n",
      "trial: 4, iter: 4000, curr loss: 0.6363365054130554, avg loss: 0.6546387953758239\n",
      "trial: 4, iter: 4500, curr loss: 0.6161555051803589, avg loss: 0.6489328633546829\n",
      "trial: 4, iter: 5000, curr loss: 0.6532440781593323, avg loss: 0.6441797523498535\n",
      "trial: 4, iter: 5500, curr loss: 0.624792218208313, avg loss: 0.6364286346435547\n",
      "trial: 4, iter: 6000, curr loss: 0.6412250995635986, avg loss: 0.6299610987901688\n",
      "trial: 4, ldr: -0.12379130721092224, dv: -0.5418676733970642, nwj: -0.6428279876708984\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6987206339836121, avg loss: 0.6925087504386902\n",
      "trial: 5, iter: 1000, curr loss: 0.6916860342025757, avg loss: 0.6909603064060211\n",
      "trial: 5, iter: 1500, curr loss: 0.6921639442443848, avg loss: 0.6875187140703202\n",
      "trial: 5, iter: 2000, curr loss: 0.682293176651001, avg loss: 0.6824587776660919\n",
      "trial: 5, iter: 2500, curr loss: 0.6560591459274292, avg loss: 0.6768332600593567\n",
      "trial: 5, iter: 3000, curr loss: 0.6662900447845459, avg loss: 0.6703458812236786\n",
      "trial: 5, iter: 3500, curr loss: 0.6334686279296875, avg loss: 0.663928321480751\n",
      "trial: 5, iter: 4000, curr loss: 0.6652923822402954, avg loss: 0.6554874867200852\n",
      "trial: 5, iter: 4500, curr loss: 0.6568021774291992, avg loss: 0.6495658408403396\n",
      "trial: 5, iter: 5000, curr loss: 0.6185320615768433, avg loss: 0.6439719531536102\n",
      "trial: 5, iter: 5500, curr loss: 0.6641923189163208, avg loss: 0.6394965187311172\n",
      "trial: 5, iter: 6000, curr loss: 0.6210888624191284, avg loss: 0.6340862940549851\n",
      "trial: 5, ldr: -0.10331552475690842, dv: -0.48712074756622314, nwj: -0.5711749792098999\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.10390743911266327\n",
      "\tdv: -0.47435463070869444\n",
      "\tnwj: -0.5531255006790161\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.2176496535539627, avg loss: 0.351302590072155\n",
      "trial: 1, iter: 1000, curr loss: 0.2698200047016144, avg loss: 0.2020096684396267\n",
      "trial: 1, iter: 1500, curr loss: 0.1622241735458374, avg loss: 0.19245088279247283\n",
      "trial: 1, iter: 2000, curr loss: 0.19958923757076263, avg loss: 0.18693772271275522\n",
      "trial: 1, iter: 2500, curr loss: 0.25775423645973206, avg loss: 0.1833322524726391\n",
      "trial: 1, iter: 3000, curr loss: 0.19270816445350647, avg loss: 0.17807598714530468\n",
      "trial: 1, iter: 3500, curr loss: 0.3484828472137451, avg loss: 0.17281385540962219\n",
      "trial: 1, iter: 4000, curr loss: 0.2578129470348358, avg loss: 0.16997134689986707\n",
      "trial: 1, iter: 4500, curr loss: 0.14854642748832703, avg loss: 0.16484283290803434\n",
      "trial: 1, iter: 5000, curr loss: 0.15303869545459747, avg loss: 0.16163235008716584\n",
      "trial: 1, iter: 5500, curr loss: 0.14842164516448975, avg loss: 0.1597658991217613\n",
      "trial: 1, iter: 6000, curr loss: 0.1488538682460785, avg loss: 0.1549301205724478\n",
      "trial: 1, ldr: 3.077108383178711, dv: 1.3390153646469116, nwj: -1.6093807220458984\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.19552280008792877, avg loss: 0.34458660370111466\n",
      "trial: 2, iter: 1000, curr loss: 0.16948729753494263, avg loss: 0.20103037263453008\n",
      "trial: 2, iter: 1500, curr loss: 0.1483609676361084, avg loss: 0.1934092059135437\n",
      "trial: 2, iter: 2000, curr loss: 0.1327686607837677, avg loss: 0.18092182478308677\n",
      "trial: 2, iter: 2500, curr loss: 0.2136193960905075, avg loss: 0.17701365247368814\n",
      "trial: 2, iter: 3000, curr loss: 0.2139814794063568, avg loss: 0.17561229931563138\n",
      "trial: 2, iter: 3500, curr loss: 0.22317259013652802, avg loss: 0.1687662463635206\n",
      "trial: 2, iter: 4000, curr loss: 0.10442766547203064, avg loss: 0.1610127241909504\n",
      "trial: 2, iter: 4500, curr loss: 0.2568953335285187, avg loss: 0.16167472454160453\n",
      "trial: 2, iter: 5000, curr loss: 0.24480842053890228, avg loss: 0.15967312329262495\n",
      "trial: 2, iter: 5500, curr loss: 0.10681210458278656, avg loss: 0.15373439040780068\n",
      "trial: 2, iter: 6000, curr loss: 0.1828334629535675, avg loss: 0.15191903130710124\n",
      "trial: 2, ldr: 2.9620413780212402, dv: 1.165664553642273, nwj: -2.0657267570495605\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.20323395729064941, avg loss: 0.34313429974019527\n",
      "trial: 3, iter: 1000, curr loss: 0.25231748819351196, avg loss: 0.19987402880191804\n",
      "trial: 3, iter: 1500, curr loss: 0.16852545738220215, avg loss: 0.1943236049860716\n",
      "trial: 3, iter: 2000, curr loss: 0.1772649884223938, avg loss: 0.18532960402965545\n",
      "trial: 3, iter: 2500, curr loss: 0.1887480914592743, avg loss: 0.17955282557010652\n",
      "trial: 3, iter: 3000, curr loss: 0.1266719251871109, avg loss: 0.17139020398259164\n",
      "trial: 3, iter: 3500, curr loss: 0.16049274802207947, avg loss: 0.17335884706676005\n",
      "trial: 3, iter: 4000, curr loss: 0.198321133852005, avg loss: 0.16185389010608195\n",
      "trial: 3, iter: 4500, curr loss: 0.1171153336763382, avg loss: 0.16166529005765914\n",
      "trial: 3, iter: 5000, curr loss: 0.16631099581718445, avg loss: 0.15860083577036857\n",
      "trial: 3, iter: 5500, curr loss: 0.23865383863449097, avg loss: 0.15374020782113076\n",
      "trial: 3, iter: 6000, curr loss: 0.15412360429763794, avg loss: 0.15011348039656877\n",
      "trial: 3, ldr: 2.7145822048187256, dv: 1.4782629013061523, nwj: 0.2716646194458008\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.2150585651397705, avg loss: 0.36577157562971113\n",
      "trial: 4, iter: 1000, curr loss: 0.19747813045978546, avg loss: 0.20521299681067467\n",
      "trial: 4, iter: 1500, curr loss: 0.1931624859571457, avg loss: 0.19027618710696698\n",
      "trial: 4, iter: 2000, curr loss: 0.18481992185115814, avg loss: 0.18305150589346886\n",
      "trial: 4, iter: 2500, curr loss: 0.14527413249015808, avg loss: 0.17786169667541982\n",
      "trial: 4, iter: 3000, curr loss: 0.20128867030143738, avg loss: 0.17243882422149182\n",
      "trial: 4, iter: 3500, curr loss: 0.12929631769657135, avg loss: 0.1721971620619297\n",
      "trial: 4, iter: 4000, curr loss: 0.1307743787765503, avg loss: 0.1634447980672121\n",
      "trial: 4, iter: 4500, curr loss: 0.13562211394309998, avg loss: 0.16282138480246067\n",
      "trial: 4, iter: 5000, curr loss: 0.1246698722243309, avg loss: 0.16005223017930983\n",
      "trial: 4, iter: 5500, curr loss: 0.2088223695755005, avg loss: 0.15681136120855807\n",
      "trial: 4, iter: 6000, curr loss: 0.11934906989336014, avg loss: 0.15298229284584522\n",
      "trial: 4, ldr: 2.8754842281341553, dv: 1.126927137374878, nwj: -1.870821237564087\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.2497377097606659, avg loss: 0.3539424819648266\n",
      "trial: 5, iter: 1000, curr loss: 0.21590428054332733, avg loss: 0.2018231852799654\n",
      "trial: 5, iter: 1500, curr loss: 0.14641237258911133, avg loss: 0.19445151318609716\n",
      "trial: 5, iter: 2000, curr loss: 0.2516871392726898, avg loss: 0.18562494081258774\n",
      "trial: 5, iter: 2500, curr loss: 0.2550532817840576, avg loss: 0.18429698979854583\n",
      "trial: 5, iter: 3000, curr loss: 0.19046150147914886, avg loss: 0.1776882514208555\n",
      "trial: 5, iter: 3500, curr loss: 0.1712602823972702, avg loss: 0.17123604591190816\n",
      "trial: 5, iter: 4000, curr loss: 0.1310817003250122, avg loss: 0.1628449591100216\n",
      "trial: 5, iter: 4500, curr loss: 0.22145648300647736, avg loss: 0.16271238710731267\n",
      "trial: 5, iter: 5000, curr loss: 0.24234886467456818, avg loss: 0.15890815776586534\n",
      "trial: 5, iter: 5500, curr loss: 0.16963207721710205, avg loss: 0.15489701124280691\n",
      "trial: 5, iter: 6000, curr loss: 0.23482275009155273, avg loss: 0.15013112412393093\n",
      "trial: 5, ldr: 3.0022177696228027, dv: 1.3768303394317627, nwj: -1.078169345855713\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.926286792755127\n",
      "\tdv: 1.2973400592803954\n",
      "\tnwj: -1.2704866886138917\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6898255944252014, avg loss: 0.6926566685438156\n",
      "trial: 1, iter: 1000, curr loss: 0.7054427862167358, avg loss: 0.6913979613780975\n",
      "trial: 1, iter: 1500, curr loss: 0.6797130107879639, avg loss: 0.6883894118070603\n",
      "trial: 1, iter: 2000, curr loss: 0.6759997606277466, avg loss: 0.6832872489690781\n",
      "trial: 1, iter: 2500, curr loss: 0.6674525737762451, avg loss: 0.6772943351268769\n",
      "trial: 1, iter: 3000, curr loss: 0.6525408029556274, avg loss: 0.6683857984542847\n",
      "trial: 1, iter: 3500, curr loss: 0.6443679332733154, avg loss: 0.662620949268341\n",
      "trial: 1, iter: 4000, curr loss: 0.6314477324485779, avg loss: 0.6564660456180572\n",
      "trial: 1, iter: 4500, curr loss: 0.6794286966323853, avg loss: 0.6507646003961564\n",
      "trial: 1, iter: 5000, curr loss: 0.6312770843505859, avg loss: 0.6450626931190491\n",
      "trial: 1, iter: 5500, curr loss: 0.6390938758850098, avg loss: 0.6393393919467926\n",
      "trial: 1, iter: 6000, curr loss: 0.6191367506980896, avg loss: 0.635997729897499\n",
      "trial: 1, ldr: -0.014683048240840435, dv: -0.4516870677471161, nwj: -0.5627453327178955\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6891977787017822, avg loss: 0.6925744122266769\n",
      "trial: 2, iter: 1000, curr loss: 0.6860191822052002, avg loss: 0.6908099564313889\n",
      "trial: 2, iter: 1500, curr loss: 0.6918769478797913, avg loss: 0.687457977771759\n",
      "trial: 2, iter: 2000, curr loss: 0.685478150844574, avg loss: 0.6825412344932557\n",
      "trial: 2, iter: 2500, curr loss: 0.6867161989212036, avg loss: 0.6773040215969086\n",
      "trial: 2, iter: 3000, curr loss: 0.6504491567611694, avg loss: 0.6684689537286759\n",
      "trial: 2, iter: 3500, curr loss: 0.6388460993766785, avg loss: 0.6609288580417633\n",
      "trial: 2, iter: 4000, curr loss: 0.648025631904602, avg loss: 0.6548600535392761\n",
      "trial: 2, iter: 4500, curr loss: 0.6374324560165405, avg loss: 0.6480884513854981\n",
      "trial: 2, iter: 5000, curr loss: 0.6559780240058899, avg loss: 0.641156501531601\n",
      "trial: 2, iter: 5500, curr loss: 0.6383013725280762, avg loss: 0.6371026179790497\n",
      "trial: 2, iter: 6000, curr loss: 0.5998998284339905, avg loss: 0.6306608860492706\n",
      "trial: 2, ldr: -0.07637017965316772, dv: -0.47488096356391907, nwj: -0.5659749507904053\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6914644837379456, avg loss: 0.6928080028295517\n",
      "trial: 3, iter: 1000, curr loss: 0.6742468476295471, avg loss: 0.6910076909065247\n",
      "trial: 3, iter: 1500, curr loss: 0.6812637448310852, avg loss: 0.6876485335826874\n",
      "trial: 3, iter: 2000, curr loss: 0.6847105026245117, avg loss: 0.6811203957796097\n",
      "trial: 3, iter: 2500, curr loss: 0.6387825012207031, avg loss: 0.6747207057476043\n",
      "trial: 3, iter: 3000, curr loss: 0.625065803527832, avg loss: 0.666808039188385\n",
      "trial: 3, iter: 3500, curr loss: 0.62671959400177, avg loss: 0.6582922284603119\n",
      "trial: 3, iter: 4000, curr loss: 0.6404924392700195, avg loss: 0.6516472960710525\n",
      "trial: 3, iter: 4500, curr loss: 0.6723434925079346, avg loss: 0.6442474139928818\n",
      "trial: 3, iter: 5000, curr loss: 0.5916990041732788, avg loss: 0.6403380379676819\n",
      "trial: 3, iter: 5500, curr loss: 0.6295938491821289, avg loss: 0.6349451096057892\n",
      "trial: 3, iter: 6000, curr loss: 0.5553687214851379, avg loss: 0.6310246367454528\n",
      "trial: 3, ldr: -0.13291755318641663, dv: -0.509070634841919, nwj: -0.5895875692367554\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6906692981719971, avg loss: 0.6927227458953857\n",
      "trial: 4, iter: 1000, curr loss: 0.6875893473625183, avg loss: 0.6907195883989334\n",
      "trial: 4, iter: 1500, curr loss: 0.6746535301208496, avg loss: 0.6870129830837249\n",
      "trial: 4, iter: 2000, curr loss: 0.6735352277755737, avg loss: 0.6828287168741226\n",
      "trial: 4, iter: 2500, curr loss: 0.6766664981842041, avg loss: 0.6754013926982879\n",
      "trial: 4, iter: 3000, curr loss: 0.6878196001052856, avg loss: 0.6693744317293168\n",
      "trial: 4, iter: 3500, curr loss: 0.6185939908027649, avg loss: 0.6617924456596375\n",
      "trial: 4, iter: 4000, curr loss: 0.6311960220336914, avg loss: 0.6556134667396546\n",
      "trial: 4, iter: 4500, curr loss: 0.6524965763092041, avg loss: 0.6481817109584809\n",
      "trial: 4, iter: 5000, curr loss: 0.6173394918441772, avg loss: 0.6425950464010238\n",
      "trial: 4, iter: 5500, curr loss: 0.5919166803359985, avg loss: 0.6352316122055054\n",
      "trial: 4, iter: 6000, curr loss: 0.6394718885421753, avg loss: 0.6311286497116089\n",
      "trial: 4, ldr: -0.17968715727329254, dv: -0.5263813734054565, nwj: -0.5940712690353394\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6918110251426697, avg loss: 0.6925739942789078\n",
      "trial: 5, iter: 1000, curr loss: 0.6991892457008362, avg loss: 0.6907026071548462\n",
      "trial: 5, iter: 1500, curr loss: 0.6666103005409241, avg loss: 0.6872728573083877\n",
      "trial: 5, iter: 2000, curr loss: 0.6656928062438965, avg loss: 0.6816395424604416\n",
      "trial: 5, iter: 2500, curr loss: 0.6680310964584351, avg loss: 0.6743322676420211\n",
      "trial: 5, iter: 3000, curr loss: 0.6520197987556458, avg loss: 0.66541597032547\n",
      "trial: 5, iter: 3500, curr loss: 0.6486510038375854, avg loss: 0.6594641253948211\n",
      "trial: 5, iter: 4000, curr loss: 0.639893651008606, avg loss: 0.6520606688261033\n",
      "trial: 5, iter: 4500, curr loss: 0.6736793518066406, avg loss: 0.6456653467416763\n",
      "trial: 5, iter: 5000, curr loss: 0.6158390045166016, avg loss: 0.6409040430784225\n",
      "trial: 5, iter: 5500, curr loss: 0.6424809694290161, avg loss: 0.6348067461252213\n",
      "trial: 5, iter: 6000, curr loss: 0.5963307619094849, avg loss: 0.6312626659870147\n",
      "trial: 5, ldr: -0.07311738282442093, dv: -0.4887900650501251, nwj: -0.5885071754455566\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.09535506423562765\n",
      "\tdv: -0.49016202092170713\n",
      "\tnwj: -0.5801772594451904\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.1921314001083374, avg loss: 0.36099974639713767\n",
      "trial: 1, iter: 1000, curr loss: 0.19502902030944824, avg loss: 0.20485069218277932\n",
      "trial: 1, iter: 1500, curr loss: 0.17790070176124573, avg loss: 0.20027467961609363\n",
      "trial: 1, iter: 2000, curr loss: 0.11305709183216095, avg loss: 0.19384724202752113\n",
      "trial: 1, iter: 2500, curr loss: 0.2033780813217163, avg loss: 0.18669112080335618\n",
      "trial: 1, iter: 3000, curr loss: 0.15085607767105103, avg loss: 0.18747707869112493\n",
      "trial: 1, iter: 3500, curr loss: 0.20846211910247803, avg loss: 0.1791380660533905\n",
      "trial: 1, iter: 4000, curr loss: 0.16465553641319275, avg loss: 0.17647666540741921\n",
      "trial: 1, iter: 4500, curr loss: 0.18241018056869507, avg loss: 0.16694089813530444\n",
      "trial: 1, iter: 5000, curr loss: 0.14043620228767395, avg loss: 0.16617786392569542\n",
      "trial: 1, iter: 5500, curr loss: 0.1456487476825714, avg loss: 0.16422140286117792\n",
      "trial: 1, iter: 6000, curr loss: 0.1416928917169571, avg loss: 0.16167191025614738\n",
      "trial: 1, ldr: 3.054598331451416, dv: 1.498830795288086, nwj: -0.6841239929199219\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.2636772692203522, avg loss: 0.35574940833449364\n",
      "trial: 2, iter: 1000, curr loss: 0.1907539665699005, avg loss: 0.21164430105686188\n",
      "trial: 2, iter: 1500, curr loss: 0.2226293683052063, avg loss: 0.19902113802731036\n",
      "trial: 2, iter: 2000, curr loss: 0.2811495363712311, avg loss: 0.19538763241469861\n",
      "trial: 2, iter: 2500, curr loss: 0.22222530841827393, avg loss: 0.19045269860327244\n",
      "trial: 2, iter: 3000, curr loss: 0.1732582449913025, avg loss: 0.18441201928257941\n",
      "trial: 2, iter: 3500, curr loss: 0.12897732853889465, avg loss: 0.18137486423552035\n",
      "trial: 2, iter: 4000, curr loss: 0.13301369547843933, avg loss: 0.17511574299633503\n",
      "trial: 2, iter: 4500, curr loss: 0.1520894169807434, avg loss: 0.1720938931554556\n",
      "trial: 2, iter: 5000, curr loss: 0.2009551227092743, avg loss: 0.16532569880783557\n",
      "trial: 2, iter: 5500, curr loss: 0.1288960576057434, avg loss: 0.16325589787960051\n",
      "trial: 2, iter: 6000, curr loss: 0.1713918149471283, avg loss: 0.15908643792569638\n",
      "trial: 2, ldr: 2.7999088764190674, dv: 1.6949243545532227, nwj: 0.7807309627532959\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.21718008816242218, avg loss: 0.3480811219215393\n",
      "trial: 3, iter: 1000, curr loss: 0.17851600050926208, avg loss: 0.20380754265189172\n",
      "trial: 3, iter: 1500, curr loss: 0.21663358807563782, avg loss: 0.19669029611349106\n",
      "trial: 3, iter: 2000, curr loss: 0.13347838819026947, avg loss: 0.19286414362490178\n",
      "trial: 3, iter: 2500, curr loss: 0.15930621325969696, avg loss: 0.1863554308116436\n",
      "trial: 3, iter: 3000, curr loss: 0.13487349450588226, avg loss: 0.1804034142792225\n",
      "trial: 3, iter: 3500, curr loss: 0.2501678764820099, avg loss: 0.17502753177285194\n",
      "trial: 3, iter: 4000, curr loss: 0.14064830541610718, avg loss: 0.17010351774096488\n",
      "trial: 3, iter: 4500, curr loss: 0.10192389041185379, avg loss: 0.1655511042252183\n",
      "trial: 3, iter: 5000, curr loss: 0.12490817904472351, avg loss: 0.1621165644824505\n",
      "trial: 3, iter: 5500, curr loss: 0.1374182403087616, avg loss: 0.15744017255306245\n",
      "trial: 3, iter: 6000, curr loss: 0.17667871713638306, avg loss: 0.1557688409537077\n",
      "trial: 3, ldr: 2.865222454071045, dv: 1.4322288036346436, nwj: -0.3260049819946289\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.1705256700515747, avg loss: 0.3506033798456192\n",
      "trial: 4, iter: 1000, curr loss: 0.1931115686893463, avg loss: 0.20617969033122063\n",
      "trial: 4, iter: 1500, curr loss: 0.27756595611572266, avg loss: 0.19916067919135094\n",
      "trial: 4, iter: 2000, curr loss: 0.13810019195079803, avg loss: 0.1899681013673544\n",
      "trial: 4, iter: 2500, curr loss: 0.25768721103668213, avg loss: 0.18546808251738547\n",
      "trial: 4, iter: 3000, curr loss: 0.20196416974067688, avg loss: 0.183286327034235\n",
      "trial: 4, iter: 3500, curr loss: 0.1404053121805191, avg loss: 0.17860055810213088\n",
      "trial: 4, iter: 4000, curr loss: 0.19236017763614655, avg loss: 0.17372885496914386\n",
      "trial: 4, iter: 4500, curr loss: 0.14537672698497772, avg loss: 0.16830767834186555\n",
      "trial: 4, iter: 5000, curr loss: 0.09736990928649902, avg loss: 0.16417914760112762\n",
      "trial: 4, iter: 5500, curr loss: 0.139544278383255, avg loss: 0.15905308312177657\n",
      "trial: 4, iter: 6000, curr loss: 0.18782323598861694, avg loss: 0.15849104510247708\n",
      "trial: 4, ldr: 2.506226062774658, dv: 1.4216004610061646, nwj: 0.5478940010070801\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.32089775800704956, avg loss: 0.3604357720464468\n",
      "trial: 5, iter: 1000, curr loss: 0.2367659956216812, avg loss: 0.2053221457898617\n",
      "trial: 5, iter: 1500, curr loss: 0.20882892608642578, avg loss: 0.19677851861715318\n",
      "trial: 5, iter: 2000, curr loss: 0.21505533158779144, avg loss: 0.19248400369286536\n",
      "trial: 5, iter: 2500, curr loss: 0.17886732518672943, avg loss: 0.18779950934648515\n",
      "trial: 5, iter: 3000, curr loss: 0.1873140037059784, avg loss: 0.18355722838640212\n",
      "trial: 5, iter: 3500, curr loss: 0.15574465692043304, avg loss: 0.18065045754611492\n",
      "trial: 5, iter: 4000, curr loss: 0.13958251476287842, avg loss: 0.1710216674953699\n",
      "trial: 5, iter: 4500, curr loss: 0.1552247405052185, avg loss: 0.1712115411311388\n",
      "trial: 5, iter: 5000, curr loss: 0.2081776261329651, avg loss: 0.16351150846481324\n",
      "trial: 5, iter: 5500, curr loss: 0.1288403570652008, avg loss: 0.16051837925612927\n",
      "trial: 5, iter: 6000, curr loss: 0.15106424689292908, avg loss: 0.16111662529408932\n",
      "trial: 5, ldr: 2.9140331745147705, dv: 1.4540753364562988, nwj: -0.39174485206604004\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.8279977798461915\n",
      "\tdv: 1.500331950187683\n",
      "\tnwj: -0.014649772644042968\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6954103708267212, avg loss: 0.6926936453580856\n",
      "trial: 1, iter: 1000, curr loss: 0.6830962896347046, avg loss: 0.691120803117752\n",
      "trial: 1, iter: 1500, curr loss: 0.6727657318115234, avg loss: 0.6871617629528045\n",
      "trial: 1, iter: 2000, curr loss: 0.6823735237121582, avg loss: 0.6820171948671341\n",
      "trial: 1, iter: 2500, curr loss: 0.6366498470306396, avg loss: 0.6756692708730697\n",
      "trial: 1, iter: 3000, curr loss: 0.6853227615356445, avg loss: 0.6691130871772766\n",
      "trial: 1, iter: 3500, curr loss: 0.6624414920806885, avg loss: 0.6629876269102096\n",
      "trial: 1, iter: 4000, curr loss: 0.619210958480835, avg loss: 0.6558818256855011\n",
      "trial: 1, iter: 4500, curr loss: 0.6372513771057129, avg loss: 0.651293323636055\n",
      "trial: 1, iter: 5000, curr loss: 0.6041077375411987, avg loss: 0.6441948150396347\n",
      "trial: 1, iter: 5500, curr loss: 0.6191496253013611, avg loss: 0.6400403867959976\n",
      "trial: 1, iter: 6000, curr loss: 0.6271524429321289, avg loss: 0.6327328464984894\n",
      "trial: 1, ldr: -0.07014305144548416, dv: -0.4779147505760193, nwj: -0.5736069679260254\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6867070198059082, avg loss: 0.6928091955184936\n",
      "trial: 2, iter: 1000, curr loss: 0.6780904531478882, avg loss: 0.6911091969013214\n",
      "trial: 2, iter: 1500, curr loss: 0.6980715394020081, avg loss: 0.6882274047136306\n",
      "trial: 2, iter: 2000, curr loss: 0.7039861679077148, avg loss: 0.6816766848564147\n",
      "trial: 2, iter: 2500, curr loss: 0.6730364561080933, avg loss: 0.6743307766914368\n",
      "trial: 2, iter: 3000, curr loss: 0.7015233039855957, avg loss: 0.666707671046257\n",
      "trial: 2, iter: 3500, curr loss: 0.6453251838684082, avg loss: 0.6608029067516327\n",
      "trial: 2, iter: 4000, curr loss: 0.6562986373901367, avg loss: 0.6521763725280761\n",
      "trial: 2, iter: 4500, curr loss: 0.644286036491394, avg loss: 0.6483510637283325\n",
      "trial: 2, iter: 5000, curr loss: 0.6194542646408081, avg loss: 0.6405651233196259\n",
      "trial: 2, iter: 5500, curr loss: 0.6285630464553833, avg loss: 0.6365237648487091\n",
      "trial: 2, iter: 6000, curr loss: 0.6224545836448669, avg loss: 0.6299764976501465\n",
      "trial: 2, ldr: -0.08524401485919952, dv: -0.5066802501678467, nwj: -0.6093931198120117\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6978223323822021, avg loss: 0.6928142540454865\n",
      "trial: 3, iter: 1000, curr loss: 0.691051185131073, avg loss: 0.6911810048818589\n",
      "trial: 3, iter: 1500, curr loss: 0.6909806132316589, avg loss: 0.6892885563373565\n",
      "trial: 3, iter: 2000, curr loss: 0.7013369798660278, avg loss: 0.6847039844989776\n",
      "trial: 3, iter: 2500, curr loss: 0.6707644462585449, avg loss: 0.6791052749156952\n",
      "trial: 3, iter: 3000, curr loss: 0.6606442928314209, avg loss: 0.6731109900474548\n",
      "trial: 3, iter: 3500, curr loss: 0.6642870903015137, avg loss: 0.664707909822464\n",
      "trial: 3, iter: 4000, curr loss: 0.6721663475036621, avg loss: 0.6588459235429763\n",
      "trial: 3, iter: 4500, curr loss: 0.6606908440589905, avg loss: 0.6514201664924621\n",
      "trial: 3, iter: 5000, curr loss: 0.6474384069442749, avg loss: 0.6460564184188843\n",
      "trial: 3, iter: 5500, curr loss: 0.6067187786102295, avg loss: 0.63708775639534\n",
      "trial: 3, iter: 6000, curr loss: 0.5838549137115479, avg loss: 0.6353944237232209\n",
      "trial: 3, ldr: -0.1111852377653122, dv: -0.42424964904785156, nwj: -0.47879481315612793\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6941351294517517, avg loss: 0.6927892717123032\n",
      "trial: 4, iter: 1000, curr loss: 0.6850482225418091, avg loss: 0.6909000860452652\n",
      "trial: 4, iter: 1500, curr loss: 0.6843467354774475, avg loss: 0.6883593142032624\n",
      "trial: 4, iter: 2000, curr loss: 0.6859604716300964, avg loss: 0.684209827542305\n",
      "trial: 4, iter: 2500, curr loss: 0.6629984378814697, avg loss: 0.6776323739290238\n",
      "trial: 4, iter: 3000, curr loss: 0.6704500317573547, avg loss: 0.6715097206830979\n",
      "trial: 4, iter: 3500, curr loss: 0.6661246418952942, avg loss: 0.6655023820400238\n",
      "trial: 4, iter: 4000, curr loss: 0.6217461824417114, avg loss: 0.6583699070215225\n",
      "trial: 4, iter: 4500, curr loss: 0.6464254856109619, avg loss: 0.6513102060556412\n",
      "trial: 4, iter: 5000, curr loss: 0.681449294090271, avg loss: 0.6453062274456024\n",
      "trial: 4, iter: 5500, curr loss: 0.6514378786087036, avg loss: 0.6388497622013092\n",
      "trial: 4, iter: 6000, curr loss: 0.6129610538482666, avg loss: 0.6339607064723969\n",
      "trial: 4, ldr: -0.12134532630443573, dv: -0.4657709002494812, nwj: -0.5325243473052979\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6931121945381165, avg loss: 0.6927780615091323\n",
      "trial: 5, iter: 1000, curr loss: 0.6829004287719727, avg loss: 0.6906690640449524\n",
      "trial: 5, iter: 1500, curr loss: 0.6733783483505249, avg loss: 0.6869693900346756\n",
      "trial: 5, iter: 2000, curr loss: 0.6614953279495239, avg loss: 0.6812143300771714\n",
      "trial: 5, iter: 2500, curr loss: 0.6869401931762695, avg loss: 0.6741786028146743\n",
      "trial: 5, iter: 3000, curr loss: 0.6727709770202637, avg loss: 0.6662551292181015\n",
      "trial: 5, iter: 3500, curr loss: 0.7138687372207642, avg loss: 0.6583778338432312\n",
      "trial: 5, iter: 4000, curr loss: 0.6283143758773804, avg loss: 0.652729725599289\n",
      "trial: 5, iter: 4500, curr loss: 0.6530982255935669, avg loss: 0.644693833231926\n",
      "trial: 5, iter: 5000, curr loss: 0.6006536483764648, avg loss: 0.6388450330495834\n",
      "trial: 5, iter: 5500, curr loss: 0.6571711301803589, avg loss: 0.6336444923877717\n",
      "trial: 5, iter: 6000, curr loss: 0.6112641096115112, avg loss: 0.6292815328836441\n",
      "trial: 5, ldr: -0.1107170507311821, dv: -0.5264873504638672, nwj: -0.6262547969818115\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.09972693622112275\n",
      "\tdv: -0.4802205801010132\n",
      "\tnwj: -0.5641148090362549\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.22756223380565643, avg loss: 0.3474832743704319\n",
      "trial: 1, iter: 1000, curr loss: 0.20993784070014954, avg loss: 0.2061565222889185\n",
      "trial: 1, iter: 1500, curr loss: 0.20483002066612244, avg loss: 0.19518000708520414\n",
      "trial: 1, iter: 2000, curr loss: 0.13318385183811188, avg loss: 0.1872431892901659\n",
      "trial: 1, iter: 2500, curr loss: 0.1635178178548813, avg loss: 0.18153334860503673\n",
      "trial: 1, iter: 3000, curr loss: 0.20290715992450714, avg loss: 0.17648809456825257\n",
      "trial: 1, iter: 3500, curr loss: 0.21425500512123108, avg loss: 0.17254134601354598\n",
      "trial: 1, iter: 4000, curr loss: 0.14245708286762238, avg loss: 0.16727300743758677\n",
      "trial: 1, iter: 4500, curr loss: 0.14675264060497284, avg loss: 0.16283919695019722\n",
      "trial: 1, iter: 5000, curr loss: 0.09444301575422287, avg loss: 0.1600968617349863\n",
      "trial: 1, iter: 5500, curr loss: 0.21324807405471802, avg loss: 0.15754811643064023\n",
      "trial: 1, iter: 6000, curr loss: 0.1859089732170105, avg loss: 0.15277827397733926\n",
      "trial: 1, ldr: 3.0751590728759766, dv: 1.62407648563385, nwj: -0.19257307052612305\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.20571750402450562, avg loss: 0.3424469489455223\n",
      "trial: 2, iter: 1000, curr loss: 0.21944062411785126, avg loss: 0.20437846410274504\n",
      "trial: 2, iter: 1500, curr loss: 0.17892339825630188, avg loss: 0.19530600142478943\n",
      "trial: 2, iter: 2000, curr loss: 0.18163767457008362, avg loss: 0.18821055695414543\n",
      "trial: 2, iter: 2500, curr loss: 0.16209210455417633, avg loss: 0.18098365761339663\n",
      "trial: 2, iter: 3000, curr loss: 0.2509100139141083, avg loss: 0.1792122566252947\n",
      "trial: 2, iter: 3500, curr loss: 0.224439799785614, avg loss: 0.17161183658242227\n",
      "trial: 2, iter: 4000, curr loss: 0.23969869315624237, avg loss: 0.16835825952887534\n",
      "trial: 2, iter: 4500, curr loss: 0.1966475397348404, avg loss: 0.16544373751431704\n",
      "trial: 2, iter: 5000, curr loss: 0.11348022520542145, avg loss: 0.1616924544274807\n",
      "trial: 2, iter: 5500, curr loss: 0.12333033978939056, avg loss: 0.15889605437219143\n",
      "trial: 2, iter: 6000, curr loss: 0.22626183927059174, avg loss: 0.15581356421113013\n",
      "trial: 2, ldr: 3.025749683380127, dv: 1.4763261079788208, nwj: -0.6830053329467773\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.14497928321361542, avg loss: 0.3533444263339043\n",
      "trial: 3, iter: 1000, curr loss: 0.28165918588638306, avg loss: 0.1991357464939356\n",
      "trial: 3, iter: 1500, curr loss: 0.22565551102161407, avg loss: 0.1948824841082096\n",
      "trial: 3, iter: 2000, curr loss: 0.23603969812393188, avg loss: 0.18643049509823323\n",
      "trial: 3, iter: 2500, curr loss: 0.18693864345550537, avg loss: 0.17796085615456103\n",
      "trial: 3, iter: 3000, curr loss: 0.21348631381988525, avg loss: 0.17841961428523065\n",
      "trial: 3, iter: 3500, curr loss: 0.19981682300567627, avg loss: 0.16905179522186517\n",
      "trial: 3, iter: 4000, curr loss: 0.12821435928344727, avg loss: 0.16259982562065126\n",
      "trial: 3, iter: 4500, curr loss: 0.17960503697395325, avg loss: 0.1617052749544382\n",
      "trial: 3, iter: 5000, curr loss: 0.10847818851470947, avg loss: 0.15737751021236182\n",
      "trial: 3, iter: 5500, curr loss: 0.11859119683504105, avg loss: 0.15434276772290467\n",
      "trial: 3, iter: 6000, curr loss: 0.15277791023254395, avg loss: 0.15052995900809765\n",
      "trial: 3, ldr: 2.905261278152466, dv: 1.3472343683242798, nwj: -0.8441793918609619\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.16693711280822754, avg loss: 0.35793685138225556\n",
      "trial: 4, iter: 1000, curr loss: 0.20728231966495514, avg loss: 0.2052985875159502\n",
      "trial: 4, iter: 1500, curr loss: 0.15493938326835632, avg loss: 0.194101285725832\n",
      "trial: 4, iter: 2000, curr loss: 0.24196961522102356, avg loss: 0.18589235557615758\n",
      "trial: 4, iter: 2500, curr loss: 0.2308966964483261, avg loss: 0.18255776223540307\n",
      "trial: 4, iter: 3000, curr loss: 0.12832209467887878, avg loss: 0.17510622154176236\n",
      "trial: 4, iter: 3500, curr loss: 0.1515215039253235, avg loss: 0.17241187059879304\n",
      "trial: 4, iter: 4000, curr loss: 0.1493649184703827, avg loss: 0.16691479805111886\n",
      "trial: 4, iter: 4500, curr loss: 0.20956513285636902, avg loss: 0.16232349021732806\n",
      "trial: 4, iter: 5000, curr loss: 0.17206458747386932, avg loss: 0.15865161918103696\n",
      "trial: 4, iter: 5500, curr loss: 0.14438092708587646, avg loss: 0.15627715595811606\n",
      "trial: 4, iter: 6000, curr loss: 0.14189760386943817, avg loss: 0.1496207536831498\n",
      "trial: 4, ldr: 3.099648952484131, dv: 1.296281099319458, nwj: -1.970407485961914\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.21688145399093628, avg loss: 0.3500581040382385\n",
      "trial: 5, iter: 1000, curr loss: 0.18419232964515686, avg loss: 0.20075849850475788\n",
      "trial: 5, iter: 1500, curr loss: 0.19545942544937134, avg loss: 0.19351886923611164\n",
      "trial: 5, iter: 2000, curr loss: 0.1995595246553421, avg loss: 0.18687490604817866\n",
      "trial: 5, iter: 2500, curr loss: 0.23318706452846527, avg loss: 0.18208107210695743\n",
      "trial: 5, iter: 3000, curr loss: 0.16967777907848358, avg loss: 0.17731184208393097\n",
      "trial: 5, iter: 3500, curr loss: 0.19493228197097778, avg loss: 0.16900111167132856\n",
      "trial: 5, iter: 4000, curr loss: 0.18139682710170746, avg loss: 0.1676312910169363\n",
      "trial: 5, iter: 4500, curr loss: 0.09096233546733856, avg loss: 0.16215592221915723\n",
      "trial: 5, iter: 5000, curr loss: 0.13671031594276428, avg loss: 0.1576529233902693\n",
      "trial: 5, iter: 5500, curr loss: 0.13407927751541138, avg loss: 0.1533421891629696\n",
      "trial: 5, iter: 6000, curr loss: 0.1493365466594696, avg loss: 0.15043555588275195\n",
      "trial: 5, ldr: 2.633009910583496, dv: 1.3551405668258667, nwj: 0.04402518272399902\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.9477657794952394\n",
      "\tdv: 1.419811725616455\n",
      "\tnwj: -0.7292280197143555\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6940542459487915, avg loss: 0.6926752872467041\n",
      "trial: 1, iter: 1000, curr loss: 0.6909747123718262, avg loss: 0.6911606060266495\n",
      "trial: 1, iter: 1500, curr loss: 0.690838634967804, avg loss: 0.6875938841104507\n",
      "trial: 1, iter: 2000, curr loss: 0.6661155819892883, avg loss: 0.6827247043848038\n",
      "trial: 1, iter: 2500, curr loss: 0.6569068431854248, avg loss: 0.676160325884819\n",
      "trial: 1, iter: 3000, curr loss: 0.6695337891578674, avg loss: 0.6702466154098511\n",
      "trial: 1, iter: 3500, curr loss: 0.6503788232803345, avg loss: 0.6628599436283111\n",
      "trial: 1, iter: 4000, curr loss: 0.6815400123596191, avg loss: 0.6558744832277298\n",
      "trial: 1, iter: 4500, curr loss: 0.629547655582428, avg loss: 0.6515545703172684\n",
      "trial: 1, iter: 5000, curr loss: 0.6758975982666016, avg loss: 0.6436879750490189\n",
      "trial: 1, iter: 5500, curr loss: 0.6259304881095886, avg loss: 0.6415168744325638\n",
      "trial: 1, iter: 6000, curr loss: 0.6426545977592468, avg loss: 0.6333885451555252\n",
      "trial: 1, ldr: -0.11307980865240097, dv: -0.4704137146472931, nwj: -0.5425928831100464\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.691720724105835, avg loss: 0.692852555513382\n",
      "trial: 2, iter: 1000, curr loss: 0.6892220973968506, avg loss: 0.6909201139211655\n",
      "trial: 2, iter: 1500, curr loss: 0.6865519285202026, avg loss: 0.6881382224559784\n",
      "trial: 2, iter: 2000, curr loss: 0.6803220510482788, avg loss: 0.6831879756450653\n",
      "trial: 2, iter: 2500, curr loss: 0.6727115511894226, avg loss: 0.6778362402915955\n",
      "trial: 2, iter: 3000, curr loss: 0.666553795337677, avg loss: 0.6707708381414413\n",
      "trial: 2, iter: 3500, curr loss: 0.6798734664916992, avg loss: 0.6629943207502366\n",
      "trial: 2, iter: 4000, curr loss: 0.6990169882774353, avg loss: 0.6582527966499329\n",
      "trial: 2, iter: 4500, curr loss: 0.6400001049041748, avg loss: 0.6519334876537323\n",
      "trial: 2, iter: 5000, curr loss: 0.662036120891571, avg loss: 0.6476335104703903\n",
      "trial: 2, iter: 5500, curr loss: 0.637352466583252, avg loss: 0.6397166863679886\n",
      "trial: 2, iter: 6000, curr loss: 0.5952945947647095, avg loss: 0.6341154396533966\n",
      "trial: 2, ldr: -0.04627077281475067, dv: -0.44506120681762695, nwj: -0.5362920761108398\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6943545341491699, avg loss: 0.6924514664411545\n",
      "trial: 3, iter: 1000, curr loss: 0.6814565658569336, avg loss: 0.6910297439098358\n",
      "trial: 3, iter: 1500, curr loss: 0.6928653717041016, avg loss: 0.6879912860393524\n",
      "trial: 3, iter: 2000, curr loss: 0.6964535713195801, avg loss: 0.6843783670663833\n",
      "trial: 3, iter: 2500, curr loss: 0.6831133365631104, avg loss: 0.677595642209053\n",
      "trial: 3, iter: 3000, curr loss: 0.663590669631958, avg loss: 0.6692407302856446\n",
      "trial: 3, iter: 3500, curr loss: 0.6673076748847961, avg loss: 0.6630512444972992\n",
      "trial: 3, iter: 4000, curr loss: 0.6443531513214111, avg loss: 0.6552256996631622\n",
      "trial: 3, iter: 4500, curr loss: 0.6180751323699951, avg loss: 0.6490629217624664\n",
      "trial: 3, iter: 5000, curr loss: 0.6439740657806396, avg loss: 0.6446691538095475\n",
      "trial: 3, iter: 5500, curr loss: 0.6291661262512207, avg loss: 0.6389062867164612\n",
      "trial: 3, iter: 6000, curr loss: 0.6441552639007568, avg loss: 0.6329928047657013\n",
      "trial: 3, ldr: -0.10610828548669815, dv: -0.4957083761692047, nwj: -0.5824985504150391\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.698528528213501, avg loss: 0.6927965978384018\n",
      "trial: 4, iter: 1000, curr loss: 0.6907918453216553, avg loss: 0.6905994652509689\n",
      "trial: 4, iter: 1500, curr loss: 0.7027769088745117, avg loss: 0.6874492841959\n",
      "trial: 4, iter: 2000, curr loss: 0.6872145533561707, avg loss: 0.6840469372272492\n",
      "trial: 4, iter: 2500, curr loss: 0.674083948135376, avg loss: 0.6768075609207154\n",
      "trial: 4, iter: 3000, curr loss: 0.6799396872520447, avg loss: 0.6706374251842498\n",
      "trial: 4, iter: 3500, curr loss: 0.6468512415885925, avg loss: 0.6650375388860702\n",
      "trial: 4, iter: 4000, curr loss: 0.6427206993103027, avg loss: 0.6572471928596496\n",
      "trial: 4, iter: 4500, curr loss: 0.6422297358512878, avg loss: 0.6513361489772796\n",
      "trial: 4, iter: 5000, curr loss: 0.6286014318466187, avg loss: 0.6453398127555847\n",
      "trial: 4, iter: 5500, curr loss: 0.5918148159980774, avg loss: 0.6392858572006226\n",
      "trial: 4, iter: 6000, curr loss: 0.6415712237358093, avg loss: 0.631050649881363\n",
      "trial: 4, ldr: -0.062320783734321594, dv: -0.5212275981903076, nwj: -0.6446640491485596\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6939302682876587, avg loss: 0.6925383437871933\n",
      "trial: 5, iter: 1000, curr loss: 0.6805263757705688, avg loss: 0.6903460589647293\n",
      "trial: 5, iter: 1500, curr loss: 0.6849193572998047, avg loss: 0.6875010219812393\n",
      "trial: 5, iter: 2000, curr loss: 0.6603785753250122, avg loss: 0.6836228715181351\n",
      "trial: 5, iter: 2500, curr loss: 0.6727266907691956, avg loss: 0.6773367210626602\n",
      "trial: 5, iter: 3000, curr loss: 0.6696025133132935, avg loss: 0.6698185518980027\n",
      "trial: 5, iter: 3500, curr loss: 0.6870254874229431, avg loss: 0.6619664483070373\n",
      "trial: 5, iter: 4000, curr loss: 0.6273543834686279, avg loss: 0.657059008717537\n",
      "trial: 5, iter: 4500, curr loss: 0.608680009841919, avg loss: 0.6493712249994278\n",
      "trial: 5, iter: 5000, curr loss: 0.6247068047523499, avg loss: 0.642683320760727\n",
      "trial: 5, iter: 5500, curr loss: 0.6242153644561768, avg loss: 0.6386157283782959\n",
      "trial: 5, iter: 6000, curr loss: 0.6390578746795654, avg loss: 0.6299189758300782\n",
      "trial: 5, ldr: -0.0699513778090477, dv: -0.5087648630142212, nwj: -0.6208174228668213\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.07954620569944382\n",
      "\tdv: -0.4882351517677307\n",
      "\tnwj: -0.5853729963302612\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.2016521692276001, avg loss: 0.3574345840215683\n",
      "trial: 1, iter: 1000, curr loss: 0.16391001641750336, avg loss: 0.2045189301967621\n",
      "trial: 1, iter: 1500, curr loss: 0.18026700615882874, avg loss: 0.18926199185848236\n",
      "trial: 1, iter: 2000, curr loss: 0.19420257210731506, avg loss: 0.1869575452953577\n",
      "trial: 1, iter: 2500, curr loss: 0.17805138230323792, avg loss: 0.18632085360586642\n",
      "trial: 1, iter: 3000, curr loss: 0.30774596333503723, avg loss: 0.17760172425210477\n",
      "trial: 1, iter: 3500, curr loss: 0.3064185082912445, avg loss: 0.17411884590238333\n",
      "trial: 1, iter: 4000, curr loss: 0.08136547356843948, avg loss: 0.1705875305980444\n",
      "trial: 1, iter: 4500, curr loss: 0.20765241980552673, avg loss: 0.16769056533277035\n",
      "trial: 1, iter: 5000, curr loss: 0.11656980216503143, avg loss: 0.16071944436430932\n",
      "trial: 1, iter: 5500, curr loss: 0.16901344060897827, avg loss: 0.16025405741482973\n",
      "trial: 1, iter: 6000, curr loss: 0.11211376637220383, avg loss: 0.15515026906132698\n",
      "trial: 1, ldr: 2.7566230297088623, dv: 1.4625176191329956, nwj: 0.10889172554016113\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.18200644850730896, avg loss: 0.33935163274407387\n",
      "trial: 2, iter: 1000, curr loss: 0.1809287965297699, avg loss: 0.19871581792831422\n",
      "trial: 2, iter: 1500, curr loss: 0.1870437115430832, avg loss: 0.1944021695703268\n",
      "trial: 2, iter: 2000, curr loss: 0.20406386256217957, avg loss: 0.18838574357330798\n",
      "trial: 2, iter: 2500, curr loss: 0.10701944679021835, avg loss: 0.1834893783479929\n",
      "trial: 2, iter: 3000, curr loss: 0.16805009543895721, avg loss: 0.17586583462357522\n",
      "trial: 2, iter: 3500, curr loss: 0.18855001032352448, avg loss: 0.17263099313527347\n",
      "trial: 2, iter: 4000, curr loss: 0.18222454190254211, avg loss: 0.1676691642701626\n",
      "trial: 2, iter: 4500, curr loss: 0.1316150426864624, avg loss: 0.16147623121738433\n",
      "trial: 2, iter: 5000, curr loss: 0.11393094807863235, avg loss: 0.1599971446841955\n",
      "trial: 2, iter: 5500, curr loss: 0.12456176429986954, avg loss: 0.156324584543705\n",
      "trial: 2, iter: 6000, curr loss: 0.11193661391735077, avg loss: 0.1537871242687106\n",
      "trial: 2, ldr: 2.946925401687622, dv: 1.355629324913025, nwj: -0.9631831645965576\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.29023951292037964, avg loss: 0.3581474216580391\n",
      "trial: 3, iter: 1000, curr loss: 0.10852096974849701, avg loss: 0.2043384824246168\n",
      "trial: 3, iter: 1500, curr loss: 0.15796321630477905, avg loss: 0.19211141395568848\n",
      "trial: 3, iter: 2000, curr loss: 0.19390150904655457, avg loss: 0.18412936337292193\n",
      "trial: 3, iter: 2500, curr loss: 0.1769656389951706, avg loss: 0.18321765732765197\n",
      "trial: 3, iter: 3000, curr loss: 0.21403464674949646, avg loss: 0.17499618561565877\n",
      "trial: 3, iter: 3500, curr loss: 0.1397285759449005, avg loss: 0.17303098577260972\n",
      "trial: 3, iter: 4000, curr loss: 0.12728765606880188, avg loss: 0.1714830304980278\n",
      "trial: 3, iter: 4500, curr loss: 0.17586123943328857, avg loss: 0.1646163930594921\n",
      "trial: 3, iter: 5000, curr loss: 0.20981180667877197, avg loss: 0.161821363940835\n",
      "trial: 3, iter: 5500, curr loss: 0.19518323242664337, avg loss: 0.15922861992567777\n",
      "trial: 3, iter: 6000, curr loss: 0.19724729657173157, avg loss: 0.15716573536396028\n",
      "trial: 3, ldr: 3.0621161460876465, dv: 1.4113759994506836, nwj: -1.1487188339233398\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.17528925836086273, avg loss: 0.33912302419543267\n",
      "trial: 4, iter: 1000, curr loss: 0.2035825550556183, avg loss: 0.20202895894646644\n",
      "trial: 4, iter: 1500, curr loss: 0.2091676890850067, avg loss: 0.19383624970912933\n",
      "trial: 4, iter: 2000, curr loss: 0.2768946588039398, avg loss: 0.18470702347159385\n",
      "trial: 4, iter: 2500, curr loss: 0.21166644990444183, avg loss: 0.18286090096831323\n",
      "trial: 4, iter: 3000, curr loss: 0.20625752210617065, avg loss: 0.17731818264722823\n",
      "trial: 4, iter: 3500, curr loss: 0.18067653477191925, avg loss: 0.17867160798609258\n",
      "trial: 4, iter: 4000, curr loss: 0.134246364235878, avg loss: 0.16824146676063537\n",
      "trial: 4, iter: 4500, curr loss: 0.2776482105255127, avg loss: 0.1683347009718418\n",
      "trial: 4, iter: 5000, curr loss: 0.13138073682785034, avg loss: 0.16124993942677976\n",
      "trial: 4, iter: 5500, curr loss: 0.1487940549850464, avg loss: 0.1559358093738556\n",
      "trial: 4, iter: 6000, curr loss: 0.13916140794754028, avg loss: 0.15522441598773\n",
      "trial: 4, ldr: 2.913475751876831, dv: 1.5202593803405762, nwj: -0.11430811882019043\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.17640507221221924, avg loss: 0.34283104425668715\n",
      "trial: 5, iter: 1000, curr loss: 0.18861499428749084, avg loss: 0.20452912332117557\n",
      "trial: 5, iter: 1500, curr loss: 0.20500636100769043, avg loss: 0.19540810166299344\n",
      "trial: 5, iter: 2000, curr loss: 0.1368856281042099, avg loss: 0.18477531179785728\n",
      "trial: 5, iter: 2500, curr loss: 0.16700802743434906, avg loss: 0.18415498475730419\n",
      "trial: 5, iter: 3000, curr loss: 0.14687953889369965, avg loss: 0.17590069614350795\n",
      "trial: 5, iter: 3500, curr loss: 0.2104337364435196, avg loss: 0.17106223955750466\n",
      "trial: 5, iter: 4000, curr loss: 0.1273101270198822, avg loss: 0.16573285007476807\n",
      "trial: 5, iter: 4500, curr loss: 0.13291841745376587, avg loss: 0.1638349235355854\n",
      "trial: 5, iter: 5000, curr loss: 0.16490492224693298, avg loss: 0.15667365324497223\n",
      "trial: 5, iter: 5500, curr loss: 0.10749977082014084, avg loss: 0.1518684340119362\n",
      "trial: 5, iter: 6000, curr loss: 0.20482322573661804, avg loss: 0.15172947216033936\n",
      "trial: 5, ldr: 2.845487117767334, dv: 1.4837223291397095, nwj: -0.05758833885192871\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.904925489425659\n",
      "\tdv: 1.446700930595398\n",
      "\tnwj: -0.4349813461303711\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6905592679977417, avg loss: 0.6929647283554077\n",
      "trial: 1, iter: 1000, curr loss: 0.6851423978805542, avg loss: 0.6916441943645477\n",
      "trial: 1, iter: 1500, curr loss: 0.692954957485199, avg loss: 0.6886806387901306\n",
      "trial: 1, iter: 2000, curr loss: 0.675248384475708, avg loss: 0.6842384153604507\n",
      "trial: 1, iter: 2500, curr loss: 0.6778271794319153, avg loss: 0.6771473950147628\n",
      "trial: 1, iter: 3000, curr loss: 0.681606650352478, avg loss: 0.6703360915184021\n",
      "trial: 1, iter: 3500, curr loss: 0.7009199857711792, avg loss: 0.6653359898328781\n",
      "trial: 1, iter: 4000, curr loss: 0.6379082798957825, avg loss: 0.6581487065553665\n",
      "trial: 1, iter: 4500, curr loss: 0.6253736019134521, avg loss: 0.6528766347169876\n",
      "trial: 1, iter: 5000, curr loss: 0.641205370426178, avg loss: 0.6468398561477661\n",
      "trial: 1, iter: 5500, curr loss: 0.6466854214668274, avg loss: 0.641533991575241\n",
      "trial: 1, iter: 6000, curr loss: 0.674433708190918, avg loss: 0.6373878638744355\n",
      "trial: 1, ldr: -0.045673612505197525, dv: -0.4314110577106476, nwj: -0.5163720846176147\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6922502517700195, avg loss: 0.6926653507947922\n",
      "trial: 2, iter: 1000, curr loss: 0.6911627650260925, avg loss: 0.6907297110557556\n",
      "trial: 2, iter: 1500, curr loss: 0.6822315454483032, avg loss: 0.6870817263126373\n",
      "trial: 2, iter: 2000, curr loss: 0.6741173267364502, avg loss: 0.6809056537151337\n",
      "trial: 2, iter: 2500, curr loss: 0.6475046873092651, avg loss: 0.6725874727964402\n",
      "trial: 2, iter: 3000, curr loss: 0.6518255472183228, avg loss: 0.6683228038549424\n",
      "trial: 2, iter: 3500, curr loss: 0.6691609025001526, avg loss: 0.6592302356958389\n",
      "trial: 2, iter: 4000, curr loss: 0.6255186796188354, avg loss: 0.6532817848920822\n",
      "trial: 2, iter: 4500, curr loss: 0.6153798699378967, avg loss: 0.6469459015130997\n",
      "trial: 2, iter: 5000, curr loss: 0.6438482999801636, avg loss: 0.6428340553045273\n",
      "trial: 2, iter: 5500, curr loss: 0.6449453830718994, avg loss: 0.6352881729602814\n",
      "trial: 2, iter: 6000, curr loss: 0.6498826146125793, avg loss: 0.6319451612234116\n",
      "trial: 2, ldr: -0.09849754720926285, dv: -0.4569344222545624, nwj: -0.5295882225036621\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6907403469085693, avg loss: 0.6926772474050522\n",
      "trial: 3, iter: 1000, curr loss: 0.6938009262084961, avg loss: 0.6915771523714066\n",
      "trial: 3, iter: 1500, curr loss: 0.6912510395050049, avg loss: 0.6880829432010651\n",
      "trial: 3, iter: 2000, curr loss: 0.6627525091171265, avg loss: 0.6835213344097137\n",
      "trial: 3, iter: 2500, curr loss: 0.6643178462982178, avg loss: 0.6765205681324005\n",
      "trial: 3, iter: 3000, curr loss: 0.674053966999054, avg loss: 0.6710446257591247\n",
      "trial: 3, iter: 3500, curr loss: 0.6748147010803223, avg loss: 0.6634653344154358\n",
      "trial: 3, iter: 4000, curr loss: 0.6650002598762512, avg loss: 0.6585335307121277\n",
      "trial: 3, iter: 4500, curr loss: 0.6673750877380371, avg loss: 0.6507095143795013\n",
      "trial: 3, iter: 5000, curr loss: 0.6111567616462708, avg loss: 0.6459014532566071\n",
      "trial: 3, iter: 5500, curr loss: 0.6227009892463684, avg loss: 0.6400147143602372\n",
      "trial: 3, iter: 6000, curr loss: 0.6301509141921997, avg loss: 0.6353682464361191\n",
      "trial: 3, ldr: -0.11721388250589371, dv: -0.5161981582641602, nwj: -0.607524037361145\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6903822422027588, avg loss: 0.6928553634881973\n",
      "trial: 4, iter: 1000, curr loss: 0.6879924535751343, avg loss: 0.6910787011384965\n",
      "trial: 4, iter: 1500, curr loss: 0.6791285276412964, avg loss: 0.6870016663074493\n",
      "trial: 4, iter: 2000, curr loss: 0.6951137781143188, avg loss: 0.6803535331487656\n",
      "trial: 4, iter: 2500, curr loss: 0.6617398262023926, avg loss: 0.6741498337984085\n",
      "trial: 4, iter: 3000, curr loss: 0.6692817211151123, avg loss: 0.6680227067470551\n",
      "trial: 4, iter: 3500, curr loss: 0.6660730242729187, avg loss: 0.6615389358997344\n",
      "trial: 4, iter: 4000, curr loss: 0.6461479663848877, avg loss: 0.6553744226694107\n",
      "trial: 4, iter: 4500, curr loss: 0.6737545728683472, avg loss: 0.6495007067918778\n",
      "trial: 4, iter: 5000, curr loss: 0.6725635528564453, avg loss: 0.6443798041343689\n",
      "trial: 4, iter: 5500, curr loss: 0.6167166233062744, avg loss: 0.6363735086917878\n",
      "trial: 4, iter: 6000, curr loss: 0.6262874007225037, avg loss: 0.6317239127159119\n",
      "trial: 4, ldr: -0.10322760790586472, dv: -0.46202513575553894, nwj: -0.5348345041275024\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6984381079673767, avg loss: 0.6927444188594818\n",
      "trial: 5, iter: 1000, curr loss: 0.6873290538787842, avg loss: 0.6911888723373413\n",
      "trial: 5, iter: 1500, curr loss: 0.6857926249504089, avg loss: 0.6888709678649902\n",
      "trial: 5, iter: 2000, curr loss: 0.6790417432785034, avg loss: 0.683052391409874\n",
      "trial: 5, iter: 2500, curr loss: 0.6829392313957214, avg loss: 0.674747178196907\n",
      "trial: 5, iter: 3000, curr loss: 0.6623799800872803, avg loss: 0.6675189117193222\n",
      "trial: 5, iter: 3500, curr loss: 0.6511775255203247, avg loss: 0.6621594061851501\n",
      "trial: 5, iter: 4000, curr loss: 0.6516573429107666, avg loss: 0.6543114244937897\n",
      "trial: 5, iter: 4500, curr loss: 0.6379170417785645, avg loss: 0.6495516226291657\n",
      "trial: 5, iter: 5000, curr loss: 0.6405004262924194, avg loss: 0.6425692623853684\n",
      "trial: 5, iter: 5500, curr loss: 0.6755750775337219, avg loss: 0.637138679265976\n",
      "trial: 5, iter: 6000, curr loss: 0.6605849266052246, avg loss: 0.6303423066139221\n",
      "trial: 5, ldr: -0.06338711827993393, dv: -0.4889695644378662, nwj: -0.5938687324523926\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.08559995368123055\n",
      "\tdv: -0.47110766768455503\n",
      "\tnwj: -0.5564375162124634\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.17291033267974854, avg loss: 0.3356614549607039\n",
      "trial: 1, iter: 1000, curr loss: 0.1629534661769867, avg loss: 0.20425946809351445\n",
      "trial: 1, iter: 1500, curr loss: 0.2137722373008728, avg loss: 0.1965925774872303\n",
      "trial: 1, iter: 2000, curr loss: 0.17001430690288544, avg loss: 0.19078258082270622\n",
      "trial: 1, iter: 2500, curr loss: 0.17188626527786255, avg loss: 0.18459770399332046\n",
      "trial: 1, iter: 3000, curr loss: 0.22355419397354126, avg loss: 0.17777337823808192\n",
      "trial: 1, iter: 3500, curr loss: 0.140044704079628, avg loss: 0.17417965480685235\n",
      "trial: 1, iter: 4000, curr loss: 0.2274690717458725, avg loss: 0.17013344271481037\n",
      "trial: 1, iter: 4500, curr loss: 0.15518516302108765, avg loss: 0.1699031473621726\n",
      "trial: 1, iter: 5000, curr loss: 0.10048030316829681, avg loss: 0.162574327416718\n",
      "trial: 1, iter: 5500, curr loss: 0.12340472638607025, avg loss: 0.1603117289021611\n",
      "trial: 1, iter: 6000, curr loss: 0.15954367816448212, avg loss: 0.15828707291185856\n",
      "trial: 1, ldr: 2.706997871398926, dv: 1.6508933305740356, nwj: 0.8318488597869873\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.23245351016521454, avg loss: 0.35436745050549506\n",
      "trial: 2, iter: 1000, curr loss: 0.211332306265831, avg loss: 0.20222951066493988\n",
      "trial: 2, iter: 1500, curr loss: 0.13828957080841064, avg loss: 0.19754969510436057\n",
      "trial: 2, iter: 2000, curr loss: 0.142991840839386, avg loss: 0.1886900855153799\n",
      "trial: 2, iter: 2500, curr loss: 0.1822197139263153, avg loss: 0.1861642900109291\n",
      "trial: 2, iter: 3000, curr loss: 0.15584444999694824, avg loss: 0.17894779746234418\n",
      "trial: 2, iter: 3500, curr loss: 0.18825232982635498, avg loss: 0.1756839505583048\n",
      "trial: 2, iter: 4000, curr loss: 0.1829787790775299, avg loss: 0.1688945247977972\n",
      "trial: 2, iter: 4500, curr loss: 0.18914122879505157, avg loss: 0.16482272279262541\n",
      "trial: 2, iter: 5000, curr loss: 0.11808997392654419, avg loss: 0.1631371669843793\n",
      "trial: 2, iter: 5500, curr loss: 0.21793130040168762, avg loss: 0.1626942859441042\n",
      "trial: 2, iter: 6000, curr loss: 0.2000647485256195, avg loss: 0.15499794985353946\n",
      "trial: 2, ldr: 3.0716447830200195, dv: 1.4281350374221802, nwj: -1.1016497611999512\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.20284347236156464, avg loss: 0.35129751631617545\n",
      "trial: 3, iter: 1000, curr loss: 0.18501460552215576, avg loss: 0.20714434960484504\n",
      "trial: 3, iter: 1500, curr loss: 0.1268802285194397, avg loss: 0.19703288426995277\n",
      "trial: 3, iter: 2000, curr loss: 0.19842374324798584, avg loss: 0.19259046244621278\n",
      "trial: 3, iter: 2500, curr loss: 0.26697203516960144, avg loss: 0.18777567697316408\n",
      "trial: 3, iter: 3000, curr loss: 0.22664418816566467, avg loss: 0.1789739628136158\n",
      "trial: 3, iter: 3500, curr loss: 0.17274996638298035, avg loss: 0.17675912381708622\n",
      "trial: 3, iter: 4000, curr loss: 0.18565072119235992, avg loss: 0.17256128767132758\n",
      "trial: 3, iter: 4500, curr loss: 0.15486232936382294, avg loss: 0.16673284555971624\n",
      "trial: 3, iter: 5000, curr loss: 0.14075250923633575, avg loss: 0.16172766725718976\n",
      "trial: 3, iter: 5500, curr loss: 0.20558138191699982, avg loss: 0.16154867093265057\n",
      "trial: 3, iter: 6000, curr loss: 0.15381772816181183, avg loss: 0.15716869601607322\n",
      "trial: 3, ldr: 2.6447622776031494, dv: 1.6503040790557861, nwj: 0.9415030479431152\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.21381047368049622, avg loss: 0.3370418711900711\n",
      "trial: 4, iter: 1000, curr loss: 0.2446431666612625, avg loss: 0.20310071635246277\n",
      "trial: 4, iter: 1500, curr loss: 0.21900546550750732, avg loss: 0.19777485913038254\n",
      "trial: 4, iter: 2000, curr loss: 0.2240981012582779, avg loss: 0.19187062318623066\n",
      "trial: 4, iter: 2500, curr loss: 0.13670018315315247, avg loss: 0.1842645340412855\n",
      "trial: 4, iter: 3000, curr loss: 0.19353505969047546, avg loss: 0.18262887816131115\n",
      "trial: 4, iter: 3500, curr loss: 0.1822066605091095, avg loss: 0.17733870294690132\n",
      "trial: 4, iter: 4000, curr loss: 0.17753542959690094, avg loss: 0.17569137421250344\n",
      "trial: 4, iter: 4500, curr loss: 0.15641772747039795, avg loss: 0.17201981995254756\n",
      "trial: 4, iter: 5000, curr loss: 0.2372426688671112, avg loss: 0.16464595392346382\n",
      "trial: 4, iter: 5500, curr loss: 0.1871301233768463, avg loss: 0.16033325067907572\n",
      "trial: 4, iter: 6000, curr loss: 0.2661956250667572, avg loss: 0.1583661787211895\n",
      "trial: 4, ldr: 2.643134117126465, dv: 1.6564743518829346, nwj: 0.960874080657959\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.24372044205665588, avg loss: 0.340938416570425\n",
      "trial: 5, iter: 1000, curr loss: 0.16680723428726196, avg loss: 0.20446373036503793\n",
      "trial: 5, iter: 1500, curr loss: 0.20578637719154358, avg loss: 0.1985649751573801\n",
      "trial: 5, iter: 2000, curr loss: 0.21204453706741333, avg loss: 0.1879700497984886\n",
      "trial: 5, iter: 2500, curr loss: 0.20326527953147888, avg loss: 0.1863020552843809\n",
      "trial: 5, iter: 3000, curr loss: 0.177590012550354, avg loss: 0.18190913344919682\n",
      "trial: 5, iter: 3500, curr loss: 0.2121811807155609, avg loss: 0.17655990140140057\n",
      "trial: 5, iter: 4000, curr loss: 0.22221562266349792, avg loss: 0.17171381139755248\n",
      "trial: 5, iter: 4500, curr loss: 0.11343854665756226, avg loss: 0.16757295240461825\n",
      "trial: 5, iter: 5000, curr loss: 0.22566191852092743, avg loss: 0.1643365630209446\n",
      "trial: 5, iter: 5500, curr loss: 0.1158677190542221, avg loss: 0.15990629084408284\n",
      "trial: 5, iter: 6000, curr loss: 0.15756107866764069, avg loss: 0.15400412115454673\n",
      "trial: 5, ldr: 2.7346158027648926, dv: 1.658801555633545, nwj: 0.8022360801696777\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.7602309703826906\n",
      "\tdv: 1.6089216709136962\n",
      "\tnwj: 0.48696246147155764\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6816755533218384, avg loss: 0.6924886555671692\n",
      "trial: 1, iter: 1000, curr loss: 0.6879532933235168, avg loss: 0.6910460957288742\n",
      "trial: 1, iter: 1500, curr loss: 0.6708645224571228, avg loss: 0.6880648530721665\n",
      "trial: 1, iter: 2000, curr loss: 0.6833457946777344, avg loss: 0.6824630742073059\n",
      "trial: 1, iter: 2500, curr loss: 0.6640413999557495, avg loss: 0.6762250113487244\n",
      "trial: 1, iter: 3000, curr loss: 0.6914473176002502, avg loss: 0.667579307436943\n",
      "trial: 1, iter: 3500, curr loss: 0.7202446460723877, avg loss: 0.6613001116514206\n",
      "trial: 1, iter: 4000, curr loss: 0.6655393838882446, avg loss: 0.6548618015050888\n",
      "trial: 1, iter: 4500, curr loss: 0.6371119618415833, avg loss: 0.6482245965003968\n",
      "trial: 1, iter: 5000, curr loss: 0.6598500609397888, avg loss: 0.6451098511219024\n",
      "trial: 1, iter: 5500, curr loss: 0.6132936477661133, avg loss: 0.6381062841415406\n",
      "trial: 1, iter: 6000, curr loss: 0.5956360101699829, avg loss: 0.6305542291402817\n",
      "trial: 1, ldr: -0.1179174929857254, dv: -0.47100359201431274, nwj: -0.54137122631073\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6900098323822021, avg loss: 0.6928303802013397\n",
      "trial: 2, iter: 1000, curr loss: 0.690091609954834, avg loss: 0.6910568759441376\n",
      "trial: 2, iter: 1500, curr loss: 0.6866976022720337, avg loss: 0.6880244184732437\n",
      "trial: 2, iter: 2000, curr loss: 0.6908203363418579, avg loss: 0.6825439766645431\n",
      "trial: 2, iter: 2500, curr loss: 0.6428133249282837, avg loss: 0.6770609685182571\n",
      "trial: 2, iter: 3000, curr loss: 0.677683413028717, avg loss: 0.6706012527942657\n",
      "trial: 2, iter: 3500, curr loss: 0.7009282112121582, avg loss: 0.6641413331031799\n",
      "trial: 2, iter: 4000, curr loss: 0.6300566792488098, avg loss: 0.6554906232357025\n",
      "trial: 2, iter: 4500, curr loss: 0.6431591510772705, avg loss: 0.650529698729515\n",
      "trial: 2, iter: 5000, curr loss: 0.6475268006324768, avg loss: 0.6460742107629776\n",
      "trial: 2, iter: 5500, curr loss: 0.6400268077850342, avg loss: 0.6403795785903931\n",
      "trial: 2, iter: 6000, curr loss: 0.6288439035415649, avg loss: 0.6349397122859954\n",
      "trial: 2, ldr: -0.043251048773527145, dv: -0.4588667154312134, nwj: -0.5585544109344482\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6948446035385132, avg loss: 0.6927670631408691\n",
      "trial: 3, iter: 1000, curr loss: 0.6881622076034546, avg loss: 0.6907565448284149\n",
      "trial: 3, iter: 1500, curr loss: 0.684297502040863, avg loss: 0.6875563974380493\n",
      "trial: 3, iter: 2000, curr loss: 0.6659456491470337, avg loss: 0.6836394830942154\n",
      "trial: 3, iter: 2500, curr loss: 0.6746420860290527, avg loss: 0.6774288574457169\n",
      "trial: 3, iter: 3000, curr loss: 0.6519385576248169, avg loss: 0.6711605958938599\n",
      "trial: 3, iter: 3500, curr loss: 0.6546236276626587, avg loss: 0.6626730414628983\n",
      "trial: 3, iter: 4000, curr loss: 0.6555085778236389, avg loss: 0.6560827379226685\n",
      "trial: 3, iter: 4500, curr loss: 0.6383887529373169, avg loss: 0.6506163908243179\n",
      "trial: 3, iter: 5000, curr loss: 0.6597777009010315, avg loss: 0.6441264296770096\n",
      "trial: 3, iter: 5500, curr loss: 0.6197034120559692, avg loss: 0.6372029268741608\n",
      "trial: 3, iter: 6000, curr loss: 0.5928932428359985, avg loss: 0.6329637417793273\n",
      "trial: 3, ldr: -0.1154223382472992, dv: -0.45768141746520996, nwj: -0.5235474109649658\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6947008371353149, avg loss: 0.6924661419391632\n",
      "trial: 4, iter: 1000, curr loss: 0.6909459829330444, avg loss: 0.6910760933160782\n",
      "trial: 4, iter: 1500, curr loss: 0.6877723932266235, avg loss: 0.6878403786420823\n",
      "trial: 4, iter: 2000, curr loss: 0.6767804622650146, avg loss: 0.6838365060091018\n",
      "trial: 4, iter: 2500, curr loss: 0.689378023147583, avg loss: 0.6780848370790482\n",
      "trial: 4, iter: 3000, curr loss: 0.6910890340805054, avg loss: 0.6713765051364898\n",
      "trial: 4, iter: 3500, curr loss: 0.6312662959098816, avg loss: 0.6653752455711365\n",
      "trial: 4, iter: 4000, curr loss: 0.6501110792160034, avg loss: 0.6572903332710266\n",
      "trial: 4, iter: 4500, curr loss: 0.6089037656784058, avg loss: 0.6488774147033691\n",
      "trial: 4, iter: 5000, curr loss: 0.6693029403686523, avg loss: 0.6438229250907898\n",
      "trial: 4, iter: 5500, curr loss: 0.672104001045227, avg loss: 0.6404067182540893\n",
      "trial: 4, iter: 6000, curr loss: 0.6589988470077515, avg loss: 0.6321044340133667\n",
      "trial: 4, ldr: -0.12605904042720795, dv: -0.5155303478240967, nwj: -0.6022591590881348\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6947500705718994, avg loss: 0.6927622574567794\n",
      "trial: 5, iter: 1000, curr loss: 0.6901785135269165, avg loss: 0.6910122382640839\n",
      "trial: 5, iter: 1500, curr loss: 0.6888623833656311, avg loss: 0.6867614922523498\n",
      "trial: 5, iter: 2000, curr loss: 0.6719487905502319, avg loss: 0.6814980994462967\n",
      "trial: 5, iter: 2500, curr loss: 0.6650717258453369, avg loss: 0.6754979370832443\n",
      "trial: 5, iter: 3000, curr loss: 0.6761609315872192, avg loss: 0.6672517331838608\n",
      "trial: 5, iter: 3500, curr loss: 0.6314351558685303, avg loss: 0.6597454053163528\n",
      "trial: 5, iter: 4000, curr loss: 0.6717115044593811, avg loss: 0.6552921137809753\n",
      "trial: 5, iter: 4500, curr loss: 0.589718759059906, avg loss: 0.6493003984689713\n",
      "trial: 5, iter: 5000, curr loss: 0.6194616556167603, avg loss: 0.6409845207929611\n",
      "trial: 5, iter: 5500, curr loss: 0.6455518007278442, avg loss: 0.6367897627353668\n",
      "trial: 5, iter: 6000, curr loss: 0.6439075469970703, avg loss: 0.6313538736104966\n",
      "trial: 5, ldr: -0.07161906361579895, dv: -0.508796215057373, nwj: -0.6199493408203125\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.09485379680991173\n",
      "\tdv: -0.48237565755844114\n",
      "\tnwj: -0.5691363096237183\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.21098080277442932, avg loss: 0.35271572473645213\n",
      "trial: 1, iter: 1000, curr loss: 0.18579566478729248, avg loss: 0.20284983421862127\n",
      "trial: 1, iter: 1500, curr loss: 0.14958249032497406, avg loss: 0.19189593850076198\n",
      "trial: 1, iter: 2000, curr loss: 0.2025946080684662, avg loss: 0.1833441650122404\n",
      "trial: 1, iter: 2500, curr loss: 0.2740996479988098, avg loss: 0.18142911814153195\n",
      "trial: 1, iter: 3000, curr loss: 0.1637791246175766, avg loss: 0.17712214209139346\n",
      "trial: 1, iter: 3500, curr loss: 0.12029924243688583, avg loss: 0.17012033109366895\n",
      "trial: 1, iter: 4000, curr loss: 0.21648582816123962, avg loss: 0.16309660114347935\n",
      "trial: 1, iter: 4500, curr loss: 0.22216200828552246, avg loss: 0.16107958208024503\n",
      "trial: 1, iter: 5000, curr loss: 0.16093000769615173, avg loss: 0.1573519530147314\n",
      "trial: 1, iter: 5500, curr loss: 0.1870211511850357, avg loss: 0.1528476684987545\n",
      "trial: 1, iter: 6000, curr loss: 0.08537685871124268, avg loss: 0.15210343223810197\n",
      "trial: 1, ldr: 2.8135182857513428, dv: 1.5085581541061401, nwj: 0.1259760856628418\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.24799112975597382, avg loss: 0.3478914491981268\n",
      "trial: 2, iter: 1000, curr loss: 0.18806439638137817, avg loss: 0.2056619195640087\n",
      "trial: 2, iter: 1500, curr loss: 0.14657138288021088, avg loss: 0.19459365406632423\n",
      "trial: 2, iter: 2000, curr loss: 0.13517141342163086, avg loss: 0.1863062415868044\n",
      "trial: 2, iter: 2500, curr loss: 0.15181732177734375, avg loss: 0.18598485043644905\n",
      "trial: 2, iter: 3000, curr loss: 0.13565613329410553, avg loss: 0.18199302154779434\n",
      "trial: 2, iter: 3500, curr loss: 0.14763081073760986, avg loss: 0.17454069973528386\n",
      "trial: 2, iter: 4000, curr loss: 0.13214382529258728, avg loss: 0.16812819492816924\n",
      "trial: 2, iter: 4500, curr loss: 0.13308149576187134, avg loss: 0.16697809464484453\n",
      "trial: 2, iter: 5000, curr loss: 0.15961740911006927, avg loss: 0.1592663300037384\n",
      "trial: 2, iter: 5500, curr loss: 0.16000516712665558, avg loss: 0.15950404097139836\n",
      "trial: 2, iter: 6000, curr loss: 0.138517826795578, avg loss: 0.15570604287087916\n",
      "trial: 2, ldr: 2.838060140609741, dv: 1.7042005062103271, nwj: 0.7304325103759766\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.21049651503562927, avg loss: 0.34842440235614774\n",
      "trial: 3, iter: 1000, curr loss: 0.16404004395008087, avg loss: 0.20050995977222918\n",
      "trial: 3, iter: 1500, curr loss: 0.22307555377483368, avg loss: 0.19218233524262904\n",
      "trial: 3, iter: 2000, curr loss: 0.17136402428150177, avg loss: 0.18410177713632583\n",
      "trial: 3, iter: 2500, curr loss: 0.1344660520553589, avg loss: 0.17889071732759476\n",
      "trial: 3, iter: 3000, curr loss: 0.12052954733371735, avg loss: 0.17420804239809512\n",
      "trial: 3, iter: 3500, curr loss: 0.11989244818687439, avg loss: 0.1714684420078993\n",
      "trial: 3, iter: 4000, curr loss: 0.15936815738677979, avg loss: 0.16565991269797087\n",
      "trial: 3, iter: 4500, curr loss: 0.13789471983909607, avg loss: 0.16036338926851748\n",
      "trial: 3, iter: 5000, curr loss: 0.15480148792266846, avg loss: 0.15818795196712018\n",
      "trial: 3, iter: 5500, curr loss: 0.1285485178232193, avg loss: 0.15439628945291042\n",
      "trial: 3, iter: 6000, curr loss: 0.126883864402771, avg loss: 0.15126441125571727\n",
      "trial: 3, ldr: 2.9261910915374756, dv: 1.5092697143554688, nwj: -0.1982123851776123\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.19438859820365906, avg loss: 0.34936510133743287\n",
      "trial: 4, iter: 1000, curr loss: 0.19621923565864563, avg loss: 0.1985794329494238\n",
      "trial: 4, iter: 1500, curr loss: 0.14806655049324036, avg loss: 0.19068499171733858\n",
      "trial: 4, iter: 2000, curr loss: 0.12797784805297852, avg loss: 0.18152671220898628\n",
      "trial: 4, iter: 2500, curr loss: 0.19792909920215607, avg loss: 0.1790392359048128\n",
      "trial: 4, iter: 3000, curr loss: 0.21813175082206726, avg loss: 0.17593911018967628\n",
      "trial: 4, iter: 3500, curr loss: 0.13187460601329803, avg loss: 0.1685983503162861\n",
      "trial: 4, iter: 4000, curr loss: 0.13375329971313477, avg loss: 0.16630235062539578\n",
      "trial: 4, iter: 4500, curr loss: 0.13257892429828644, avg loss: 0.16379199544340373\n",
      "trial: 4, iter: 5000, curr loss: 0.1263468861579895, avg loss: 0.15709840995073318\n",
      "trial: 4, iter: 5500, curr loss: 0.22023317217826843, avg loss: 0.15502530713379384\n",
      "trial: 4, iter: 6000, curr loss: 0.10817740112543106, avg loss: 0.14994459838420152\n",
      "trial: 4, ldr: 2.9397218227386475, dv: 1.3221526145935059, nwj: -1.1011006832122803\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.19372227787971497, avg loss: 0.35382957059144976\n",
      "trial: 5, iter: 1000, curr loss: 0.22161056101322174, avg loss: 0.2021205232590437\n",
      "trial: 5, iter: 1500, curr loss: 0.1653939187526703, avg loss: 0.19379548516869544\n",
      "trial: 5, iter: 2000, curr loss: 0.07843556255102158, avg loss: 0.1845228039175272\n",
      "trial: 5, iter: 2500, curr loss: 0.1882224828004837, avg loss: 0.18293655647337437\n",
      "trial: 5, iter: 3000, curr loss: 0.13405674695968628, avg loss: 0.1780995743125677\n",
      "trial: 5, iter: 3500, curr loss: 0.24543845653533936, avg loss: 0.16903794074058534\n",
      "trial: 5, iter: 4000, curr loss: 0.16571354866027832, avg loss: 0.1694498377889395\n",
      "trial: 5, iter: 4500, curr loss: 0.17475664615631104, avg loss: 0.16023266790807247\n",
      "trial: 5, iter: 5000, curr loss: 0.1598978042602539, avg loss: 0.15764150429517032\n",
      "trial: 5, iter: 5500, curr loss: 0.07631966471672058, avg loss: 0.1540053555816412\n",
      "trial: 5, iter: 6000, curr loss: 0.18394190073013306, avg loss: 0.1531757980287075\n",
      "trial: 5, ldr: 2.800631284713745, dv: 1.5450897216796875, nwj: 0.2908926010131836\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.8636245250701906\n",
      "\tdv: 1.517854142189026\n",
      "\tnwj: -0.030402374267578126\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6946463584899902, avg loss: 0.6928308546543122\n",
      "trial: 1, iter: 1000, curr loss: 0.6865864992141724, avg loss: 0.6914901819229126\n",
      "trial: 1, iter: 1500, curr loss: 0.7008336782455444, avg loss: 0.6879954382181167\n",
      "trial: 1, iter: 2000, curr loss: 0.6801191568374634, avg loss: 0.6847853533029556\n",
      "trial: 1, iter: 2500, curr loss: 0.6749787330627441, avg loss: 0.6774388592243195\n",
      "trial: 1, iter: 3000, curr loss: 0.6966229677200317, avg loss: 0.6718137203454971\n",
      "trial: 1, iter: 3500, curr loss: 0.65798020362854, avg loss: 0.6671502696275711\n",
      "trial: 1, iter: 4000, curr loss: 0.6876184940338135, avg loss: 0.6600625061988831\n",
      "trial: 1, iter: 4500, curr loss: 0.6821902394294739, avg loss: 0.654142582654953\n",
      "trial: 1, iter: 5000, curr loss: 0.63631671667099, avg loss: 0.6490621827840805\n",
      "trial: 1, iter: 5500, curr loss: 0.6378464698791504, avg loss: 0.6434120635986328\n",
      "trial: 1, iter: 6000, curr loss: 0.6139932870864868, avg loss: 0.6384313217401505\n",
      "trial: 1, ldr: -0.12290658056735992, dv: -0.4430173635482788, nwj: -0.5001869201660156\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6984659433364868, avg loss: 0.6927588698863983\n",
      "trial: 2, iter: 1000, curr loss: 0.6869193911552429, avg loss: 0.6912746931314468\n",
      "trial: 2, iter: 1500, curr loss: 0.662585973739624, avg loss: 0.6874149776697159\n",
      "trial: 2, iter: 2000, curr loss: 0.6874821186065674, avg loss: 0.6825547505617142\n",
      "trial: 2, iter: 2500, curr loss: 0.6782876253128052, avg loss: 0.6757855098247528\n",
      "trial: 2, iter: 3000, curr loss: 0.6863830089569092, avg loss: 0.6679326957464218\n",
      "trial: 2, iter: 3500, curr loss: 0.6289467811584473, avg loss: 0.6615171701908111\n",
      "trial: 2, iter: 4000, curr loss: 0.6770812273025513, avg loss: 0.653961324930191\n",
      "trial: 2, iter: 4500, curr loss: 0.6280555725097656, avg loss: 0.6483165159225464\n",
      "trial: 2, iter: 5000, curr loss: 0.6406007409095764, avg loss: 0.6409243465662002\n",
      "trial: 2, iter: 5500, curr loss: 0.641682505607605, avg loss: 0.6353234609365463\n",
      "trial: 2, iter: 6000, curr loss: 0.607525646686554, avg loss: 0.6304689627885819\n",
      "trial: 2, ldr: -0.11771613359451294, dv: -0.5469221472740173, nwj: -0.6537535190582275\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.6902886629104614, avg loss: 0.6928651125431061\n",
      "trial: 3, iter: 1000, curr loss: 0.6835735440254211, avg loss: 0.6910585861206054\n",
      "trial: 3, iter: 1500, curr loss: 0.6963348388671875, avg loss: 0.6877801914215088\n",
      "trial: 3, iter: 2000, curr loss: 0.6654557585716248, avg loss: 0.6829837988615036\n",
      "trial: 3, iter: 2500, curr loss: 0.6761159896850586, avg loss: 0.6763346636295319\n",
      "trial: 3, iter: 3000, curr loss: 0.6637764573097229, avg loss: 0.6689253466129303\n",
      "trial: 3, iter: 3500, curr loss: 0.6585292816162109, avg loss: 0.6630879067182541\n",
      "trial: 3, iter: 4000, curr loss: 0.6234855055809021, avg loss: 0.6575291105508805\n",
      "trial: 3, iter: 4500, curr loss: 0.6687819361686707, avg loss: 0.6498637758493423\n",
      "trial: 3, iter: 5000, curr loss: 0.6512866616249084, avg loss: 0.6435996712446213\n",
      "trial: 3, iter: 5500, curr loss: 0.6224124431610107, avg loss: 0.6382670933008194\n",
      "trial: 3, iter: 6000, curr loss: 0.6022101044654846, avg loss: 0.6339076343774795\n",
      "trial: 3, ldr: -0.19089576601982117, dv: -0.4891093373298645, nwj: -0.5383453369140625\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6977666020393372, avg loss: 0.6926465448141098\n",
      "trial: 4, iter: 1000, curr loss: 0.6956398487091064, avg loss: 0.6908718910217285\n",
      "trial: 4, iter: 1500, curr loss: 0.6888008117675781, avg loss: 0.6875133057832717\n",
      "trial: 4, iter: 2000, curr loss: 0.6966286301612854, avg loss: 0.6828052996397018\n",
      "trial: 4, iter: 2500, curr loss: 0.6724292039871216, avg loss: 0.6776494244337082\n",
      "trial: 4, iter: 3000, curr loss: 0.6881113052368164, avg loss: 0.6701103428602219\n",
      "trial: 4, iter: 3500, curr loss: 0.6465746164321899, avg loss: 0.6637902837991715\n",
      "trial: 4, iter: 4000, curr loss: 0.6722049713134766, avg loss: 0.656115851521492\n",
      "trial: 4, iter: 4500, curr loss: 0.6190164089202881, avg loss: 0.648288293838501\n",
      "trial: 4, iter: 5000, curr loss: 0.6774676442146301, avg loss: 0.6408083480596543\n",
      "trial: 4, iter: 5500, curr loss: 0.6387572288513184, avg loss: 0.6388678925037384\n",
      "trial: 4, iter: 6000, curr loss: 0.638205349445343, avg loss: 0.6320469489097595\n",
      "trial: 4, ldr: -0.16382110118865967, dv: -0.5357027053833008, nwj: -0.6142823696136475\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6902323961257935, avg loss: 0.6926801887750625\n",
      "trial: 5, iter: 1000, curr loss: 0.6875041723251343, avg loss: 0.6912549730539322\n",
      "trial: 5, iter: 1500, curr loss: 0.6872873306274414, avg loss: 0.6882983456850051\n",
      "trial: 5, iter: 2000, curr loss: 0.6581322550773621, avg loss: 0.683416127204895\n",
      "trial: 5, iter: 2500, curr loss: 0.6643406748771667, avg loss: 0.6779414281845093\n",
      "trial: 5, iter: 3000, curr loss: 0.6725630760192871, avg loss: 0.6702459217309952\n",
      "trial: 5, iter: 3500, curr loss: 0.6749377250671387, avg loss: 0.6614445894956589\n",
      "trial: 5, iter: 4000, curr loss: 0.6648886203765869, avg loss: 0.6541481338739396\n",
      "trial: 5, iter: 4500, curr loss: 0.6598799824714661, avg loss: 0.6490151754617691\n",
      "trial: 5, iter: 5000, curr loss: 0.6504223942756653, avg loss: 0.6413462873697281\n",
      "trial: 5, iter: 5500, curr loss: 0.6736235022544861, avg loss: 0.6374058417081833\n",
      "trial: 5, iter: 6000, curr loss: 0.6356900930404663, avg loss: 0.6319189913272858\n",
      "trial: 5, ldr: -0.0511995293200016, dv: -0.49876168370246887, nwj: -0.6156930923461914\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.12930782213807107\n",
      "\tdv: -0.5027026474475861\n",
      "\tnwj: -0.5844522476196289\n",
      "\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.1359667330980301, avg loss: 0.35580090153217314\n",
      "trial: 1, iter: 1000, curr loss: 0.24109727144241333, avg loss: 0.2093573446571827\n",
      "trial: 1, iter: 1500, curr loss: 0.192101389169693, avg loss: 0.19588960707187653\n",
      "trial: 1, iter: 2000, curr loss: 0.217967689037323, avg loss: 0.1923301064223051\n",
      "trial: 1, iter: 2500, curr loss: 0.16770058870315552, avg loss: 0.18602350226044656\n",
      "trial: 1, iter: 3000, curr loss: 0.18409070372581482, avg loss: 0.18050491243600844\n",
      "trial: 1, iter: 3500, curr loss: 0.1931193470954895, avg loss: 0.17630188971757887\n",
      "trial: 1, iter: 4000, curr loss: 0.18911871314048767, avg loss: 0.17361928834021093\n",
      "trial: 1, iter: 4500, curr loss: 0.23157066106796265, avg loss: 0.17019563683867456\n",
      "trial: 1, iter: 5000, curr loss: 0.19157783687114716, avg loss: 0.16326284762471915\n",
      "trial: 1, iter: 5500, curr loss: 0.19465197622776031, avg loss: 0.15940875974297525\n",
      "trial: 1, iter: 6000, curr loss: 0.2058258056640625, avg loss: 0.15686178962886332\n",
      "trial: 1, ldr: 2.7936689853668213, dv: 1.4733556509017944, nwj: 0.049074649810791016\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.1821753829717636, avg loss: 0.34684851026535035\n",
      "trial: 2, iter: 1000, curr loss: 0.2642645835876465, avg loss: 0.2105505669862032\n",
      "trial: 2, iter: 1500, curr loss: 0.13124965131282806, avg loss: 0.1961102552562952\n",
      "trial: 2, iter: 2000, curr loss: 0.1296798586845398, avg loss: 0.19569699132442475\n",
      "trial: 2, iter: 2500, curr loss: 0.1965392678976059, avg loss: 0.19101916332542895\n",
      "trial: 2, iter: 3000, curr loss: 0.23500627279281616, avg loss: 0.18562781950831414\n",
      "trial: 2, iter: 3500, curr loss: 0.19767068326473236, avg loss: 0.18463865676522254\n",
      "trial: 2, iter: 4000, curr loss: 0.14539656043052673, avg loss: 0.17343967975676058\n",
      "trial: 2, iter: 4500, curr loss: 0.16046752035617828, avg loss: 0.1729700405150652\n",
      "trial: 2, iter: 5000, curr loss: 0.2116112858057022, avg loss: 0.17054597215354442\n",
      "trial: 2, iter: 5500, curr loss: 0.12694309651851654, avg loss: 0.16681832604110242\n",
      "trial: 2, iter: 6000, curr loss: 0.17062249779701233, avg loss: 0.16261940458416937\n",
      "trial: 2, ldr: 2.544489860534668, dv: 1.5349786281585693, nwj: 0.8002305030822754\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.251568466424942, avg loss: 0.3557894777357578\n",
      "trial: 3, iter: 1000, curr loss: 0.19959048926830292, avg loss: 0.21147748887538909\n",
      "trial: 3, iter: 1500, curr loss: 0.12910541892051697, avg loss: 0.2009091603010893\n",
      "trial: 3, iter: 2000, curr loss: 0.22449594736099243, avg loss: 0.19426206490397455\n",
      "trial: 3, iter: 2500, curr loss: 0.20429730415344238, avg loss: 0.19189378321170808\n",
      "trial: 3, iter: 3000, curr loss: 0.17965742945671082, avg loss: 0.18169212293624878\n",
      "trial: 3, iter: 3500, curr loss: 0.16615301370620728, avg loss: 0.17761910274624826\n",
      "trial: 3, iter: 4000, curr loss: 0.12288052588701248, avg loss: 0.17320359781384467\n",
      "trial: 3, iter: 4500, curr loss: 0.17758050560951233, avg loss: 0.1705624615624547\n",
      "trial: 3, iter: 5000, curr loss: 0.14459529519081116, avg loss: 0.166239079028368\n",
      "trial: 3, iter: 5500, curr loss: 0.12665297091007233, avg loss: 0.16074980299174785\n",
      "trial: 3, iter: 6000, curr loss: 0.23223629593849182, avg loss: 0.15829044845700263\n",
      "trial: 3, ldr: 2.7525510787963867, dv: 1.5193076133728027, nwj: 0.320206880569458\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.28207433223724365, avg loss: 0.3566614459455013\n",
      "trial: 4, iter: 1000, curr loss: 0.2774066627025604, avg loss: 0.20739827252924442\n",
      "trial: 4, iter: 1500, curr loss: 0.13792684674263, avg loss: 0.20087972147762775\n",
      "trial: 4, iter: 2000, curr loss: 0.20761770009994507, avg loss: 0.19734928672015667\n",
      "trial: 4, iter: 2500, curr loss: 0.1873534619808197, avg loss: 0.18725442923605443\n",
      "trial: 4, iter: 3000, curr loss: 0.16739720106124878, avg loss: 0.18222883485257627\n",
      "trial: 4, iter: 3500, curr loss: 0.10087235271930695, avg loss: 0.1785908141732216\n",
      "trial: 4, iter: 4000, curr loss: 0.22723564505577087, avg loss: 0.17583096058666706\n",
      "trial: 4, iter: 4500, curr loss: 0.13532257080078125, avg loss: 0.1721588524132967\n",
      "trial: 4, iter: 5000, curr loss: 0.14603659510612488, avg loss: 0.16397650124132634\n",
      "trial: 4, iter: 5500, curr loss: 0.17493723332881927, avg loss: 0.16404932514578105\n",
      "trial: 4, iter: 6000, curr loss: 0.15827403962612152, avg loss: 0.16136358505487441\n",
      "trial: 4, ldr: 2.630791664123535, dv: 1.5156373977661133, nwj: 0.5807530879974365\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.2598634362220764, avg loss: 0.3684536644667387\n",
      "trial: 5, iter: 1000, curr loss: 0.1633475422859192, avg loss: 0.20405764529109002\n",
      "trial: 5, iter: 1500, curr loss: 0.1429668664932251, avg loss: 0.1972366518229246\n",
      "trial: 5, iter: 2000, curr loss: 0.1577940285205841, avg loss: 0.19143296305835247\n",
      "trial: 5, iter: 2500, curr loss: 0.16753274202346802, avg loss: 0.18680246962606906\n",
      "trial: 5, iter: 3000, curr loss: 0.18649576604366302, avg loss: 0.1831905313283205\n",
      "trial: 5, iter: 3500, curr loss: 0.18383771181106567, avg loss: 0.17786339154839514\n",
      "trial: 5, iter: 4000, curr loss: 0.2017105221748352, avg loss: 0.17361548712849617\n",
      "trial: 5, iter: 4500, curr loss: 0.1900271475315094, avg loss: 0.1678266352713108\n",
      "trial: 5, iter: 5000, curr loss: 0.15214961767196655, avg loss: 0.16500701525807382\n",
      "trial: 5, iter: 5500, curr loss: 0.16571244597434998, avg loss: 0.16450516721606254\n",
      "trial: 5, iter: 6000, curr loss: 0.07441743463277817, avg loss: 0.15975679853558541\n",
      "trial: 5, ldr: 2.7872672080993652, dv: 1.2152347564697266, nwj: -1.0291600227355957\n",
      "################################################################\n",
      "\n",
      "final estimations first:\n",
      "\tldr: 2.701753759384155\n",
      "\tdv: 1.4517028093338014\n",
      "\tnwj: 0.14422101974487306\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.6916857957839966, avg loss: 0.6925189429521561\n",
      "trial: 1, iter: 1000, curr loss: 0.6832147836685181, avg loss: 0.6906432905197144\n",
      "trial: 1, iter: 1500, curr loss: 0.687259316444397, avg loss: 0.687375434756279\n",
      "trial: 1, iter: 2000, curr loss: 0.6742213368415833, avg loss: 0.6818848004341126\n",
      "trial: 1, iter: 2500, curr loss: 0.6564452052116394, avg loss: 0.675182133436203\n",
      "trial: 1, iter: 3000, curr loss: 0.6425600647926331, avg loss: 0.668210393667221\n",
      "trial: 1, iter: 3500, curr loss: 0.6960293054580688, avg loss: 0.6623110691308975\n",
      "trial: 1, iter: 4000, curr loss: 0.6331267356872559, avg loss: 0.654825630068779\n",
      "trial: 1, iter: 4500, curr loss: 0.6047428846359253, avg loss: 0.6476995309591294\n",
      "trial: 1, iter: 5000, curr loss: 0.6489471793174744, avg loss: 0.6419044463634491\n",
      "trial: 1, iter: 5500, curr loss: 0.6067739725112915, avg loss: 0.6368345756530762\n",
      "trial: 1, iter: 6000, curr loss: 0.6191384792327881, avg loss: 0.6307550595998764\n",
      "trial: 1, ldr: -0.10288694500923157, dv: -0.49081212282180786, nwj: -0.5768064260482788\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.6927288770675659, avg loss: 0.6927306147813796\n",
      "trial: 2, iter: 1000, curr loss: 0.6856594085693359, avg loss: 0.6910599434375763\n",
      "trial: 2, iter: 1500, curr loss: 0.6798275709152222, avg loss: 0.688282662987709\n",
      "trial: 2, iter: 2000, curr loss: 0.6656175851821899, avg loss: 0.6838126293420792\n",
      "trial: 2, iter: 2500, curr loss: 0.6822063326835632, avg loss: 0.6788840517997742\n",
      "trial: 2, iter: 3000, curr loss: 0.6473551988601685, avg loss: 0.6714509711265564\n",
      "trial: 2, iter: 3500, curr loss: 0.684384286403656, avg loss: 0.6645077278614044\n",
      "trial: 2, iter: 4000, curr loss: 0.6631617546081543, avg loss: 0.6581096450090408\n",
      "trial: 2, iter: 4500, curr loss: 0.6423671245574951, avg loss: 0.6524511847496033\n",
      "trial: 2, iter: 5000, curr loss: 0.6332345604896545, avg loss: 0.6457840181589126\n",
      "trial: 2, iter: 5500, curr loss: 0.6741617321968079, avg loss: 0.6387222986221314\n",
      "trial: 2, iter: 6000, curr loss: 0.6298236846923828, avg loss: 0.6334673357009888\n",
      "trial: 2, ldr: -0.10221484303474426, dv: -0.43320879340171814, nwj: -0.4945662021636963\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.69432532787323, avg loss: 0.6929381135702133\n",
      "trial: 3, iter: 1000, curr loss: 0.690339207649231, avg loss: 0.6910117104053497\n",
      "trial: 3, iter: 1500, curr loss: 0.6972811818122864, avg loss: 0.6872067540884018\n",
      "trial: 3, iter: 2000, curr loss: 0.689525842666626, avg loss: 0.6808762055635452\n",
      "trial: 3, iter: 2500, curr loss: 0.6464923620223999, avg loss: 0.6750568994283677\n",
      "trial: 3, iter: 3000, curr loss: 0.6906716823577881, avg loss: 0.6683806246519088\n",
      "trial: 3, iter: 3500, curr loss: 0.6693636775016785, avg loss: 0.6602208030223846\n",
      "trial: 3, iter: 4000, curr loss: 0.620549201965332, avg loss: 0.6545291993618011\n",
      "trial: 3, iter: 4500, curr loss: 0.6588116884231567, avg loss: 0.646752254486084\n",
      "trial: 3, iter: 5000, curr loss: 0.635856032371521, avg loss: 0.6402198083400726\n",
      "trial: 3, iter: 5500, curr loss: 0.6630077362060547, avg loss: 0.6367811682224274\n",
      "trial: 3, iter: 6000, curr loss: 0.6208310127258301, avg loss: 0.6307479326725006\n",
      "trial: 3, ldr: -0.12256091088056564, dv: -0.4830804765224457, nwj: -0.5566351413726807\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.6921504139900208, avg loss: 0.6925600906610488\n",
      "trial: 4, iter: 1000, curr loss: 0.7001044750213623, avg loss: 0.6909025402069092\n",
      "trial: 4, iter: 1500, curr loss: 0.6870663166046143, avg loss: 0.6876393228769302\n",
      "trial: 4, iter: 2000, curr loss: 0.7043329477310181, avg loss: 0.6831616606712342\n",
      "trial: 4, iter: 2500, curr loss: 0.663682758808136, avg loss: 0.6778335020542144\n",
      "trial: 4, iter: 3000, curr loss: 0.6765172481536865, avg loss: 0.6704156099557876\n",
      "trial: 4, iter: 3500, curr loss: 0.6350122690200806, avg loss: 0.6653180364370346\n",
      "trial: 4, iter: 4000, curr loss: 0.663392961025238, avg loss: 0.6586541981697083\n",
      "trial: 4, iter: 4500, curr loss: 0.6600819826126099, avg loss: 0.6523521547317505\n",
      "trial: 4, iter: 5000, curr loss: 0.6496776342391968, avg loss: 0.6476424684524537\n",
      "trial: 4, iter: 5500, curr loss: 0.6358802318572998, avg loss: 0.6403517603874207\n",
      "trial: 4, iter: 6000, curr loss: 0.6268071532249451, avg loss: 0.6375162720680236\n",
      "trial: 4, ldr: -0.15585559606552124, dv: -0.42632293701171875, nwj: -0.4664323329925537\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.6958518624305725, avg loss: 0.6927592536211014\n",
      "trial: 5, iter: 1000, curr loss: 0.6896811723709106, avg loss: 0.6906224058866501\n",
      "trial: 5, iter: 1500, curr loss: 0.6784522533416748, avg loss: 0.6873957318067551\n",
      "trial: 5, iter: 2000, curr loss: 0.648415207862854, avg loss: 0.6816805211305619\n",
      "trial: 5, iter: 2500, curr loss: 0.6680526733398438, avg loss: 0.6761788113117218\n",
      "trial: 5, iter: 3000, curr loss: 0.6714116334915161, avg loss: 0.6669193733930587\n",
      "trial: 5, iter: 3500, curr loss: 0.6526809930801392, avg loss: 0.6598971178531646\n",
      "trial: 5, iter: 4000, curr loss: 0.674463152885437, avg loss: 0.6553596639633179\n",
      "trial: 5, iter: 4500, curr loss: 0.6899405717849731, avg loss: 0.6486089090108872\n",
      "trial: 5, iter: 5000, curr loss: 0.6336022615432739, avg loss: 0.6421528213024139\n",
      "trial: 5, iter: 5500, curr loss: 0.6153378486633301, avg loss: 0.6390545735359192\n",
      "trial: 5, iter: 6000, curr loss: 0.5999435186386108, avg loss: 0.6330260728597641\n",
      "trial: 5, ldr: -0.18752992153167725, dv: -0.4666754901409149, nwj: -0.509529709815979\n",
      "################################################################\n",
      "\n",
      "final estimations second:\n",
      "\tldr: -0.13420964330434798\n",
      "\tdv: -0.46001996397972106\n",
      "\tnwj: -0.5207939624786377\n"
     ]
    }
   ],
   "source": [
    "ldr_arr = []\n",
    "dv_arr = []\n",
    "nwj_arr = []\n",
    "for i in range(num_of_outer_iteration):\n",
    "    ldr, dv, nwj = ccmi_experiment(prime, data_range, num_of_samples, weight, feature_size, beta_arr, alpha_arr, para_param, priv_param, x_idx, y_idx, z_idx, hidden_size_arr, lr, num_of_mid_iteration, num_of_inner_iteration, batch_size, load_data='./data/catF/data.20k.dz50.seed0.npy', save_avg=500)\n",
    "    ldr_arr.append(ldr)\n",
    "    dv_arr.append(dv)\n",
    "    nwj_arr.append(nwj)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:17:00.306462842Z",
     "start_time": "2023-12-12T22:07:56.733058739Z"
    }
   },
   "id": "a207951bd578c28d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ldr_mean = np.mean(np.asarray(ldr_arr))\n",
    "dv_mean = np.mean(np.asarray(dv_arr))\n",
    "nwj_mean = np.mean(np.asarray(nwj_arr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:21:05.608872422Z",
     "start_time": "2023-12-12T22:21:05.598932359Z"
    }
   },
   "id": "2370e3d7f41b8a24"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "2.9436627362482253"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldr_mean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:21:10.773984513Z",
     "start_time": "2023-12-12T22:21:10.767806220Z"
    }
   },
   "id": "9af8b3b4388e92ac"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1.9288736069202421"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_mean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:21:15.307763104Z",
     "start_time": "2023-12-12T22:21:15.295400017Z"
    }
   },
   "id": "9270cf10bb9cc011"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.25373025655746456"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwj_mean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:21:20.314249295Z",
     "start_time": "2023-12-12T22:21:20.303053415Z"
    }
   },
   "id": "9484a60318daa232"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from probabilistic_classifier.experiment import multiclass_probabilistic_classifier_experiment "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:10:40.647819059Z",
     "start_time": "2023-12-12T23:10:40.638969128Z"
    }
   },
   "id": "4e368aa2350beb49"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "prime = None\n",
    "data_range = None\n",
    "num_of_samples = 20000\n",
    "\n",
    "hidden_size_arr = [64, 64]\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "num_of_outer_iteration = 10\n",
    "num_of_mid_iteration = 5\n",
    "num_of_inner_iteration = int(20 * num_of_samples / batch_size)\n",
    "\n",
    "para_param, priv_param = None, None\n",
    "beta_arr, alpha_arr = None, None\n",
    "\n",
    "feature_size = None\n",
    "weight = None\n",
    "z_dim = 50\n",
    "x_idx, y_idx, z_idx = [0], [1], list(range(2, z_dim + 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:10:41.404625507Z",
     "start_time": "2023-12-12T23:10:41.401869146Z"
    }
   },
   "id": "8e9338874cf5256f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.015608310699463, avg loss: 1.11142626452446\n",
      "trial: 1, iter: 1000, curr loss: 0.994904100894928, avg loss: 1.0225000791549683\n",
      "trial: 1, iter: 1500, curr loss: 1.0337951183319092, avg loss: 1.0184510542154313\n",
      "trial: 1, iter: 2000, curr loss: 1.0048125982284546, avg loss: 1.0130441261529923\n",
      "trial: 1, iter: 2500, curr loss: 0.9748364090919495, avg loss: 1.0126178849935532\n",
      "trial: 1, iter: 3000, curr loss: 1.0499565601348877, avg loss: 1.010376746416092\n",
      "trial: 1, iter: 3500, curr loss: 1.0191967487335205, avg loss: 1.0077497515678406\n",
      "trial: 1, iter: 4000, curr loss: 1.015520453453064, avg loss: 1.0068033428192138\n",
      "trial: 1, iter: 4500, curr loss: 0.9917696118354797, avg loss: 1.0069286541938782\n",
      "trial: 1, iter: 5000, curr loss: 0.9496415853500366, avg loss: 1.0043276954889298\n",
      "trial: 1, iter: 5500, curr loss: 1.0380719900131226, avg loss: 1.0040132948160172\n",
      "trial: 1, iter: 6000, curr loss: 0.9705076813697815, avg loss: 1.0027611808776855\n",
      "trial: 1, ldr: 2.379472017288208\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.9969671964645386, avg loss: 1.1361123175621033\n",
      "trial: 2, iter: 1000, curr loss: 1.0187714099884033, avg loss: 1.023726158261299\n",
      "trial: 2, iter: 1500, curr loss: 1.0104825496673584, avg loss: 1.0156963646411896\n",
      "trial: 2, iter: 2000, curr loss: 0.9784070253372192, avg loss: 1.0129672091007234\n",
      "trial: 2, iter: 2500, curr loss: 1.0289559364318848, avg loss: 1.012871363401413\n",
      "trial: 2, iter: 3000, curr loss: 0.9853927493095398, avg loss: 1.0105943772792816\n",
      "trial: 2, iter: 3500, curr loss: 1.0498123168945312, avg loss: 1.0083400336503983\n",
      "trial: 2, iter: 4000, curr loss: 1.0062448978424072, avg loss: 1.0078398388624192\n",
      "trial: 2, iter: 4500, curr loss: 0.9771898984909058, avg loss: 1.0056583304405213\n",
      "trial: 2, iter: 5000, curr loss: 0.9982569217681885, avg loss: 1.0032348796129227\n",
      "trial: 2, iter: 5500, curr loss: 0.9495248198509216, avg loss: 1.003318295121193\n",
      "trial: 2, iter: 6000, curr loss: 1.041937232017517, avg loss: 1.003514327764511\n",
      "trial: 2, ldr: 2.475311040878296\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0622249841690063, avg loss: 1.121434764623642\n",
      "trial: 3, iter: 1000, curr loss: 1.0420666933059692, avg loss: 1.0246134169101715\n",
      "trial: 3, iter: 1500, curr loss: 0.9899032711982727, avg loss: 1.0185329766273499\n",
      "trial: 3, iter: 2000, curr loss: 1.0225428342819214, avg loss: 1.0152704921960831\n",
      "trial: 3, iter: 2500, curr loss: 1.0334869623184204, avg loss: 1.011458260536194\n",
      "trial: 3, iter: 3000, curr loss: 0.9929444789886475, avg loss: 1.0090015845298768\n",
      "trial: 3, iter: 3500, curr loss: 1.0265682935714722, avg loss: 1.0069802359342575\n",
      "trial: 3, iter: 4000, curr loss: 0.997012734413147, avg loss: 1.0073403494358062\n",
      "trial: 3, iter: 4500, curr loss: 0.9476429224014282, avg loss: 1.0047224113941193\n",
      "trial: 3, iter: 5000, curr loss: 1.01436185836792, avg loss: 1.0028580856323241\n",
      "trial: 3, iter: 5500, curr loss: 0.961708664894104, avg loss: 1.0022035592794418\n",
      "trial: 3, iter: 6000, curr loss: 1.0167485475540161, avg loss: 1.0002677906751634\n",
      "trial: 3, ldr: 2.5089550018310547\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.020779013633728, avg loss: 1.1243564270734787\n",
      "trial: 4, iter: 1000, curr loss: 1.017567753791809, avg loss: 1.0234259960651397\n",
      "trial: 4, iter: 1500, curr loss: 1.0768423080444336, avg loss: 1.017013563156128\n",
      "trial: 4, iter: 2000, curr loss: 1.0462669134140015, avg loss: 1.0138029401302338\n",
      "trial: 4, iter: 2500, curr loss: 1.0036176443099976, avg loss: 1.0111110012531281\n",
      "trial: 4, iter: 3000, curr loss: 1.033250331878662, avg loss: 1.0113007476329803\n",
      "trial: 4, iter: 3500, curr loss: 1.0270558595657349, avg loss: 1.0070019519329072\n",
      "trial: 4, iter: 4000, curr loss: 1.004243016242981, avg loss: 1.0047938762903212\n",
      "trial: 4, iter: 4500, curr loss: 1.003591537475586, avg loss: 1.0059105166196822\n",
      "trial: 4, iter: 5000, curr loss: 1.0217851400375366, avg loss: 1.0030237255096435\n",
      "trial: 4, iter: 5500, curr loss: 1.0095442533493042, avg loss: 1.0008551226854325\n",
      "trial: 4, iter: 6000, curr loss: 0.9484487175941467, avg loss: 1.0016753276586532\n",
      "trial: 4, ldr: 2.4183666706085205\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0290526151657104, avg loss: 1.1268458585739136\n",
      "trial: 5, iter: 1000, curr loss: 1.013181209564209, avg loss: 1.0254934668540954\n",
      "trial: 5, iter: 1500, curr loss: 1.002090573310852, avg loss: 1.019050779223442\n",
      "trial: 5, iter: 2000, curr loss: 0.9898689985275269, avg loss: 1.0157310428619384\n",
      "trial: 5, iter: 2500, curr loss: 0.9673054814338684, avg loss: 1.0119807006120682\n",
      "trial: 5, iter: 3000, curr loss: 0.9752979278564453, avg loss: 1.0083852158784867\n",
      "trial: 5, iter: 3500, curr loss: 1.0173033475875854, avg loss: 1.0078865671157837\n",
      "trial: 5, iter: 4000, curr loss: 0.9936479330062866, avg loss: 1.0074059592485427\n",
      "trial: 5, iter: 4500, curr loss: 1.0131064653396606, avg loss: 1.0049463766813278\n",
      "trial: 5, iter: 5000, curr loss: 1.0142862796783447, avg loss: 1.006185665011406\n",
      "trial: 5, iter: 5500, curr loss: 1.0208563804626465, avg loss: 1.0015651894807815\n",
      "trial: 5, iter: 6000, curr loss: 1.0664043426513672, avg loss: 1.0033298741579055\n",
      "trial: 5, ldr: 2.522824764251709\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.4609858989715576\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.024552345275879, avg loss: 1.1222719156742096\n",
      "trial: 1, iter: 1000, curr loss: 1.0471235513687134, avg loss: 1.0197814267873764\n",
      "trial: 1, iter: 1500, curr loss: 0.9848718047142029, avg loss: 1.0153910961151122\n",
      "trial: 1, iter: 2000, curr loss: 1.0326210260391235, avg loss: 1.0129153566360474\n",
      "trial: 1, iter: 2500, curr loss: 0.9999184608459473, avg loss: 1.0089839514493941\n",
      "trial: 1, iter: 3000, curr loss: 1.0290906429290771, avg loss: 1.010768503665924\n",
      "trial: 1, iter: 3500, curr loss: 1.0188549757003784, avg loss: 1.0061097598075868\n",
      "trial: 1, iter: 4000, curr loss: 0.9714201092720032, avg loss: 1.0067082446813584\n",
      "trial: 1, iter: 4500, curr loss: 1.003485083580017, avg loss: 1.0031384340524674\n",
      "trial: 1, iter: 5000, curr loss: 1.0064880847930908, avg loss: 1.0025781074762343\n",
      "trial: 1, iter: 5500, curr loss: 0.9635096788406372, avg loss: 0.9998549844026565\n",
      "trial: 1, iter: 6000, curr loss: 0.9687359929084778, avg loss: 0.9994001078605652\n",
      "trial: 1, ldr: 2.4282124042510986\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.0236456394195557, avg loss: 1.1133802587985993\n",
      "trial: 2, iter: 1000, curr loss: 1.0125142335891724, avg loss: 1.021773178935051\n",
      "trial: 2, iter: 1500, curr loss: 0.9887416958808899, avg loss: 1.0140412660837173\n",
      "trial: 2, iter: 2000, curr loss: 1.069516897201538, avg loss: 1.012621165752411\n",
      "trial: 2, iter: 2500, curr loss: 1.0288829803466797, avg loss: 1.010330085992813\n",
      "trial: 2, iter: 3000, curr loss: 0.9965245723724365, avg loss: 1.0086401188373566\n",
      "trial: 2, iter: 3500, curr loss: 1.03271484375, avg loss: 1.0079556741714477\n",
      "trial: 2, iter: 4000, curr loss: 0.9769014120101929, avg loss: 1.0064584401845933\n",
      "trial: 2, iter: 4500, curr loss: 0.9620465040206909, avg loss: 1.0049978210926056\n",
      "trial: 2, iter: 5000, curr loss: 0.9762255549430847, avg loss: 1.0026875910758972\n",
      "trial: 2, iter: 5500, curr loss: 1.0096980333328247, avg loss: 0.9989419790506363\n",
      "trial: 2, iter: 6000, curr loss: 1.0344434976577759, avg loss: 1.0025889630317688\n",
      "trial: 2, ldr: 2.263641119003296\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.9853718876838684, avg loss: 1.1279390258789062\n",
      "trial: 3, iter: 1000, curr loss: 1.0438560247421265, avg loss: 1.0220598539113999\n",
      "trial: 3, iter: 1500, curr loss: 0.9827187657356262, avg loss: 1.0150305191278457\n",
      "trial: 3, iter: 2000, curr loss: 1.0153635740280151, avg loss: 1.0121138169765473\n",
      "trial: 3, iter: 2500, curr loss: 0.9886929392814636, avg loss: 1.0089720029830933\n",
      "trial: 3, iter: 3000, curr loss: 1.0097562074661255, avg loss: 1.0082520703077316\n",
      "trial: 3, iter: 3500, curr loss: 1.0019177198410034, avg loss: 1.0058599746227264\n",
      "trial: 3, iter: 4000, curr loss: 0.9610302448272705, avg loss: 1.0035504269599915\n",
      "trial: 3, iter: 4500, curr loss: 0.9667486548423767, avg loss: 1.0012415459156037\n",
      "trial: 3, iter: 5000, curr loss: 1.0252642631530762, avg loss: 1.0024284262657166\n",
      "trial: 3, iter: 5500, curr loss: 1.0014783143997192, avg loss: 0.9989906038045884\n",
      "trial: 3, iter: 6000, curr loss: 1.0174906253814697, avg loss: 0.9995474849939346\n",
      "trial: 3, ldr: 2.39174485206604\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0541315078735352, avg loss: 1.1301201021671294\n",
      "trial: 4, iter: 1000, curr loss: 1.0140862464904785, avg loss: 1.0222352952957154\n",
      "trial: 4, iter: 1500, curr loss: 0.9620445966720581, avg loss: 1.0173278250694275\n",
      "trial: 4, iter: 2000, curr loss: 0.9935053586959839, avg loss: 1.012514170408249\n",
      "trial: 4, iter: 2500, curr loss: 1.0281596183776855, avg loss: 1.009974761724472\n",
      "trial: 4, iter: 3000, curr loss: 0.9825646877288818, avg loss: 1.0062548975944519\n",
      "trial: 4, iter: 3500, curr loss: 1.0156230926513672, avg loss: 1.007162889957428\n",
      "trial: 4, iter: 4000, curr loss: 1.0186917781829834, avg loss: 1.0027079405784607\n",
      "trial: 4, iter: 4500, curr loss: 0.9983088374137878, avg loss: 1.00219033908844\n",
      "trial: 4, iter: 5000, curr loss: 0.9969529509544373, avg loss: 1.0030705081224442\n",
      "trial: 4, iter: 5500, curr loss: 1.0202875137329102, avg loss: 1.0015427919626236\n",
      "trial: 4, iter: 6000, curr loss: 0.99275141954422, avg loss: 0.9966507580280304\n",
      "trial: 4, ldr: 2.287870407104492\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.002795934677124, avg loss: 1.1229410959482193\n",
      "trial: 5, iter: 1000, curr loss: 1.0449198484420776, avg loss: 1.0223652905225753\n",
      "trial: 5, iter: 1500, curr loss: 1.0401276350021362, avg loss: 1.0147074122428894\n",
      "trial: 5, iter: 2000, curr loss: 0.9772253632545471, avg loss: 1.011800581216812\n",
      "trial: 5, iter: 2500, curr loss: 1.0010665655136108, avg loss: 1.009481830239296\n",
      "trial: 5, iter: 3000, curr loss: 0.996808648109436, avg loss: 1.006627622127533\n",
      "trial: 5, iter: 3500, curr loss: 1.038000464439392, avg loss: 1.0054880348443984\n",
      "trial: 5, iter: 4000, curr loss: 0.9690501093864441, avg loss: 1.0032537285089493\n",
      "trial: 5, iter: 4500, curr loss: 0.971015989780426, avg loss: 1.003034929871559\n",
      "trial: 5, iter: 5000, curr loss: 1.018410563468933, avg loss: 1.0028013619184495\n",
      "trial: 5, iter: 5500, curr loss: 0.9399533271789551, avg loss: 0.9982278740406036\n",
      "trial: 5, iter: 6000, curr loss: 1.0181546211242676, avg loss: 0.9985914289951324\n",
      "trial: 5, ldr: 2.2187507152557373\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.318043899536133\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0453484058380127, avg loss: 1.1328404304981232\n",
      "trial: 1, iter: 1000, curr loss: 0.9759055376052856, avg loss: 1.0211734894514084\n",
      "trial: 1, iter: 1500, curr loss: 1.0153954029083252, avg loss: 1.0142266763448715\n",
      "trial: 1, iter: 2000, curr loss: 1.0468287467956543, avg loss: 1.014863965988159\n",
      "trial: 1, iter: 2500, curr loss: 1.002849817276001, avg loss: 1.0098562376499176\n",
      "trial: 1, iter: 3000, curr loss: 1.0247350931167603, avg loss: 1.0092395647764205\n",
      "trial: 1, iter: 3500, curr loss: 0.9640811681747437, avg loss: 1.0062723470926285\n",
      "trial: 1, iter: 4000, curr loss: 0.9762704968452454, avg loss: 1.0053181983232498\n",
      "trial: 1, iter: 4500, curr loss: 1.0332908630371094, avg loss: 1.004991902589798\n",
      "trial: 1, iter: 5000, curr loss: 1.03361177444458, avg loss: 1.0004986983537674\n",
      "trial: 1, iter: 5500, curr loss: 1.026415228843689, avg loss: 1.0011443736553192\n",
      "trial: 1, iter: 6000, curr loss: 1.0259268283843994, avg loss: 0.9986553702354432\n",
      "trial: 1, ldr: 2.460158586502075\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.0332801342010498, avg loss: 1.1152220908403396\n",
      "trial: 2, iter: 1000, curr loss: 1.02275812625885, avg loss: 1.0212000955343246\n",
      "trial: 2, iter: 1500, curr loss: 1.0120692253112793, avg loss: 1.0142988041639327\n",
      "trial: 2, iter: 2000, curr loss: 1.0144014358520508, avg loss: 1.0131791914701462\n",
      "trial: 2, iter: 2500, curr loss: 1.0298283100128174, avg loss: 1.0102079976797105\n",
      "trial: 2, iter: 3000, curr loss: 1.039473533630371, avg loss: 1.0096888865232467\n",
      "trial: 2, iter: 3500, curr loss: 0.9961889386177063, avg loss: 1.007820907354355\n",
      "trial: 2, iter: 4000, curr loss: 0.9739713072776794, avg loss: 1.0049323210716248\n",
      "trial: 2, iter: 4500, curr loss: 0.9721664786338806, avg loss: 1.0041156369447708\n",
      "trial: 2, iter: 5000, curr loss: 1.0356425046920776, avg loss: 1.0033028222322464\n",
      "trial: 2, iter: 5500, curr loss: 1.0011719465255737, avg loss: 1.0001063776016235\n",
      "trial: 2, iter: 6000, curr loss: 1.006189227104187, avg loss: 1.0006569228172302\n",
      "trial: 2, ldr: 2.474161148071289\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0210920572280884, avg loss: 1.1239930174350738\n",
      "trial: 3, iter: 1000, curr loss: 1.035515546798706, avg loss: 1.0211556959152222\n",
      "trial: 3, iter: 1500, curr loss: 0.9906995892524719, avg loss: 1.015205586194992\n",
      "trial: 3, iter: 2000, curr loss: 1.0114927291870117, avg loss: 1.011114730000496\n",
      "trial: 3, iter: 2500, curr loss: 1.020251989364624, avg loss: 1.0089293510913848\n",
      "trial: 3, iter: 3000, curr loss: 1.04654860496521, avg loss: 1.0089034206867218\n",
      "trial: 3, iter: 3500, curr loss: 1.0187021493911743, avg loss: 1.0081571530103683\n",
      "trial: 3, iter: 4000, curr loss: 1.0577276945114136, avg loss: 1.0068394750356675\n",
      "trial: 3, iter: 4500, curr loss: 1.0343694686889648, avg loss: 1.0030833979845046\n",
      "trial: 3, iter: 5000, curr loss: 1.0102201700210571, avg loss: 1.0028519282341004\n",
      "trial: 3, iter: 5500, curr loss: 1.061141014099121, avg loss: 0.9994064271450043\n",
      "trial: 3, iter: 6000, curr loss: 0.9984498620033264, avg loss: 1.0001049181222916\n",
      "trial: 3, ldr: 2.6160597801208496\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.040320873260498, avg loss: 1.1262286039590836\n",
      "trial: 4, iter: 1000, curr loss: 0.9958570599555969, avg loss: 1.0214871252775193\n",
      "trial: 4, iter: 1500, curr loss: 1.0322319269180298, avg loss: 1.0175480651855469\n",
      "trial: 4, iter: 2000, curr loss: 0.9862104058265686, avg loss: 1.0113199177980423\n",
      "trial: 4, iter: 2500, curr loss: 1.065051555633545, avg loss: 1.0106601563692093\n",
      "trial: 4, iter: 3000, curr loss: 1.0146534442901611, avg loss: 1.0082262500524521\n",
      "trial: 4, iter: 3500, curr loss: 1.0077545642852783, avg loss: 1.0077667149305343\n",
      "trial: 4, iter: 4000, curr loss: 0.9794187545776367, avg loss: 1.0023333373069763\n",
      "trial: 4, iter: 4500, curr loss: 1.052018404006958, avg loss: 1.0030728558301925\n",
      "trial: 4, iter: 5000, curr loss: 1.0214767456054688, avg loss: 0.9994547321796418\n",
      "trial: 4, iter: 5500, curr loss: 1.030922532081604, avg loss: 0.9999681113958359\n",
      "trial: 4, iter: 6000, curr loss: 0.985683023929596, avg loss: 1.0005306531190872\n",
      "trial: 4, ldr: 2.2509541511535645\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0068340301513672, avg loss: 1.1299623235464096\n",
      "trial: 5, iter: 1000, curr loss: 1.0550652742385864, avg loss: 1.0192232497930527\n",
      "trial: 5, iter: 1500, curr loss: 1.0734492540359497, avg loss: 1.018059290766716\n",
      "trial: 5, iter: 2000, curr loss: 1.0284239053726196, avg loss: 1.0137417570352554\n",
      "trial: 5, iter: 2500, curr loss: 1.0372657775878906, avg loss: 1.0109278367757797\n",
      "trial: 5, iter: 3000, curr loss: 1.0233640670776367, avg loss: 1.0081990910768508\n",
      "trial: 5, iter: 3500, curr loss: 1.032159447669983, avg loss: 1.0077188280820846\n",
      "trial: 5, iter: 4000, curr loss: 0.9928245544433594, avg loss: 1.0062234263420105\n",
      "trial: 5, iter: 4500, curr loss: 1.0249037742614746, avg loss: 1.0047303446531295\n",
      "trial: 5, iter: 5000, curr loss: 1.0000324249267578, avg loss: 1.0049436014890671\n",
      "trial: 5, iter: 5500, curr loss: 0.9588676691055298, avg loss: 1.0028272467851638\n",
      "trial: 5, iter: 6000, curr loss: 1.02907395362854, avg loss: 0.9985993183851242\n",
      "trial: 5, ldr: 2.4013803005218506\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.440542793273926\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.058733344078064, avg loss: 1.1289172497987747\n",
      "trial: 1, iter: 1000, curr loss: 1.035232663154602, avg loss: 1.0211083697080612\n",
      "trial: 1, iter: 1500, curr loss: 0.9996709823608398, avg loss: 1.0141158541440964\n",
      "trial: 1, iter: 2000, curr loss: 1.0699971914291382, avg loss: 1.0133822623491286\n",
      "trial: 1, iter: 2500, curr loss: 1.01060950756073, avg loss: 1.010341551065445\n",
      "trial: 1, iter: 3000, curr loss: 0.9853745698928833, avg loss: 1.0085826486349105\n",
      "trial: 1, iter: 3500, curr loss: 1.0025774240493774, avg loss: 1.005710524559021\n",
      "trial: 1, iter: 4000, curr loss: 1.0093607902526855, avg loss: 1.0058038688898085\n",
      "trial: 1, iter: 4500, curr loss: 0.9918081760406494, avg loss: 1.001885061264038\n",
      "trial: 1, iter: 5000, curr loss: 0.9483736157417297, avg loss: 1.0000826404094696\n",
      "trial: 1, iter: 5500, curr loss: 1.0282717943191528, avg loss: 1.0002071971893312\n",
      "trial: 1, iter: 6000, curr loss: 1.0036587715148926, avg loss: 0.9964459857940674\n",
      "trial: 1, ldr: 2.654573917388916\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.021971344947815, avg loss: 1.1252721368074416\n",
      "trial: 2, iter: 1000, curr loss: 0.9740733504295349, avg loss: 1.0217302432060242\n",
      "trial: 2, iter: 1500, curr loss: 1.0884668827056885, avg loss: 1.0142619955539702\n",
      "trial: 2, iter: 2000, curr loss: 0.9999451041221619, avg loss: 1.0127777615785598\n",
      "trial: 2, iter: 2500, curr loss: 1.0002198219299316, avg loss: 1.0082131527662277\n",
      "trial: 2, iter: 3000, curr loss: 1.0291343927383423, avg loss: 1.0074305015802383\n",
      "trial: 2, iter: 3500, curr loss: 0.9930278062820435, avg loss: 1.0065421644449235\n",
      "trial: 2, iter: 4000, curr loss: 0.9913326501846313, avg loss: 1.0049413623809815\n",
      "trial: 2, iter: 4500, curr loss: 1.0265971422195435, avg loss: 1.0031893496513367\n",
      "trial: 2, iter: 5000, curr loss: 1.0295084714889526, avg loss: 1.0017015336751938\n",
      "trial: 2, iter: 5500, curr loss: 1.025291919708252, avg loss: 1.0010046590566635\n",
      "trial: 2, iter: 6000, curr loss: 0.9671652913093567, avg loss: 0.9996011201143264\n",
      "trial: 2, ldr: 2.2820823192596436\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.9948848485946655, avg loss: 1.1265381977558135\n",
      "trial: 3, iter: 1000, curr loss: 1.0188404321670532, avg loss: 1.019455697774887\n",
      "trial: 3, iter: 1500, curr loss: 0.9707396030426025, avg loss: 1.0175115772485732\n",
      "trial: 3, iter: 2000, curr loss: 0.9767037034034729, avg loss: 1.0130941517353058\n",
      "trial: 3, iter: 2500, curr loss: 0.9997283220291138, avg loss: 1.0116664587259292\n",
      "trial: 3, iter: 3000, curr loss: 0.9915544986724854, avg loss: 1.0086683222055435\n",
      "trial: 3, iter: 3500, curr loss: 1.0692898035049438, avg loss: 1.0052304244041443\n",
      "trial: 3, iter: 4000, curr loss: 1.013670802116394, avg loss: 1.0064263700246812\n",
      "trial: 3, iter: 4500, curr loss: 0.9939846992492676, avg loss: 1.0048203605413437\n",
      "trial: 3, iter: 5000, curr loss: 1.0019387006759644, avg loss: 1.001944208741188\n",
      "trial: 3, iter: 5500, curr loss: 1.0158761739730835, avg loss: 1.0017701748609542\n",
      "trial: 3, iter: 6000, curr loss: 1.038249135017395, avg loss: 1.000834686756134\n",
      "trial: 3, ldr: 2.303879976272583\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 0.9991047382354736, avg loss: 1.1304059088230134\n",
      "trial: 4, iter: 1000, curr loss: 0.9917598366737366, avg loss: 1.0218007097244262\n",
      "trial: 4, iter: 1500, curr loss: 1.0196152925491333, avg loss: 1.0150063732862473\n",
      "trial: 4, iter: 2000, curr loss: 1.0095274448394775, avg loss: 1.012969582438469\n",
      "trial: 4, iter: 2500, curr loss: 1.0270729064941406, avg loss: 1.0109836387634277\n",
      "trial: 4, iter: 3000, curr loss: 1.0052629709243774, avg loss: 1.011534335374832\n",
      "trial: 4, iter: 3500, curr loss: 1.0170197486877441, avg loss: 1.0072065883874892\n",
      "trial: 4, iter: 4000, curr loss: 0.9962712526321411, avg loss: 1.0060052874088288\n",
      "trial: 4, iter: 4500, curr loss: 0.9766402244567871, avg loss: 1.003981983780861\n",
      "trial: 4, iter: 5000, curr loss: 0.9933573007583618, avg loss: 1.0050047763586045\n",
      "trial: 4, iter: 5500, curr loss: 1.0091270208358765, avg loss: 1.0034621013402938\n",
      "trial: 4, iter: 6000, curr loss: 1.0332822799682617, avg loss: 1.0011991196870804\n",
      "trial: 4, ldr: 2.1891047954559326\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 0.9895654916763306, avg loss: 1.1150070267915726\n",
      "trial: 5, iter: 1000, curr loss: 1.0351669788360596, avg loss: 1.0206309971809386\n",
      "trial: 5, iter: 1500, curr loss: 1.0627987384796143, avg loss: 1.0164007368087769\n",
      "trial: 5, iter: 2000, curr loss: 1.0563772916793823, avg loss: 1.0133534492254257\n",
      "trial: 5, iter: 2500, curr loss: 1.034567952156067, avg loss: 1.0102197844982148\n",
      "trial: 5, iter: 3000, curr loss: 1.0136915445327759, avg loss: 1.0092477502822876\n",
      "trial: 5, iter: 3500, curr loss: 1.0348916053771973, avg loss: 1.0065681099891663\n",
      "trial: 5, iter: 4000, curr loss: 1.033348560333252, avg loss: 1.0056841354370116\n",
      "trial: 5, iter: 4500, curr loss: 0.9750117659568787, avg loss: 1.0024932689666748\n",
      "trial: 5, iter: 5000, curr loss: 1.0020817518234253, avg loss: 1.0020624685287476\n",
      "trial: 5, iter: 5500, curr loss: 1.0397478342056274, avg loss: 1.0018462015390397\n",
      "trial: 5, iter: 6000, curr loss: 0.9414930939674377, avg loss: 0.9993420128822327\n",
      "trial: 5, ldr: 2.356879234313965\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.357304048538208\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0446821451187134, avg loss: 1.1192400982379913\n",
      "trial: 1, iter: 1000, curr loss: 1.0047998428344727, avg loss: 1.0201617741584779\n",
      "trial: 1, iter: 1500, curr loss: 1.0170422792434692, avg loss: 1.0183376885652542\n",
      "trial: 1, iter: 2000, curr loss: 1.0068519115447998, avg loss: 1.0129978359937668\n",
      "trial: 1, iter: 2500, curr loss: 1.04224693775177, avg loss: 1.0105882853269577\n",
      "trial: 1, iter: 3000, curr loss: 0.9923811554908752, avg loss: 1.008423700094223\n",
      "trial: 1, iter: 3500, curr loss: 1.0243775844573975, avg loss: 1.005333844780922\n",
      "trial: 1, iter: 4000, curr loss: 1.001430869102478, avg loss: 1.00311044383049\n",
      "trial: 1, iter: 4500, curr loss: 0.9711430072784424, avg loss: 1.004247180223465\n",
      "trial: 1, iter: 5000, curr loss: 1.033230185508728, avg loss: 0.9998110373020173\n",
      "trial: 1, iter: 5500, curr loss: 0.958902895450592, avg loss: 1.0017444870471954\n",
      "trial: 1, iter: 6000, curr loss: 0.9702872633934021, avg loss: 0.9958130663633347\n",
      "trial: 1, ldr: 2.302833318710327\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.014593482017517, avg loss: 1.1252976226806641\n",
      "trial: 2, iter: 1000, curr loss: 1.0011579990386963, avg loss: 1.0227511004209517\n",
      "trial: 2, iter: 1500, curr loss: 1.053044080734253, avg loss: 1.0169371682405473\n",
      "trial: 2, iter: 2000, curr loss: 1.0307568311691284, avg loss: 1.0130076698064805\n",
      "trial: 2, iter: 2500, curr loss: 1.0405315160751343, avg loss: 1.0087808264493943\n",
      "trial: 2, iter: 3000, curr loss: 1.0092740058898926, avg loss: 1.0068738924264908\n",
      "trial: 2, iter: 3500, curr loss: 1.0383297204971313, avg loss: 1.0066853137016296\n",
      "trial: 2, iter: 4000, curr loss: 1.0212780237197876, avg loss: 1.003674599289894\n",
      "trial: 2, iter: 4500, curr loss: 1.058222770690918, avg loss: 1.0027906960248947\n",
      "trial: 2, iter: 5000, curr loss: 1.0226435661315918, avg loss: 1.0019932956695556\n",
      "trial: 2, iter: 5500, curr loss: 1.0094867944717407, avg loss: 0.999547847032547\n",
      "trial: 2, iter: 6000, curr loss: 0.9867920875549316, avg loss: 0.9994391981363296\n",
      "trial: 2, ldr: 2.5717968940734863\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0305681228637695, avg loss: 1.1265619136095046\n",
      "trial: 3, iter: 1000, curr loss: 1.0239553451538086, avg loss: 1.020509469628334\n",
      "trial: 3, iter: 1500, curr loss: 0.9750517010688782, avg loss: 1.0159515776634216\n",
      "trial: 3, iter: 2000, curr loss: 1.0109676122665405, avg loss: 1.010645728468895\n",
      "trial: 3, iter: 2500, curr loss: 0.993399441242218, avg loss: 1.0107328168153762\n",
      "trial: 3, iter: 3000, curr loss: 1.0070381164550781, avg loss: 1.0087175459861755\n",
      "trial: 3, iter: 3500, curr loss: 1.0021705627441406, avg loss: 1.0049027053117752\n",
      "trial: 3, iter: 4000, curr loss: 0.9708489179611206, avg loss: 1.0037401894330977\n",
      "trial: 3, iter: 4500, curr loss: 1.0169951915740967, avg loss: 1.0022999242544175\n",
      "trial: 3, iter: 5000, curr loss: 1.0124353170394897, avg loss: 1.0023736124038696\n",
      "trial: 3, iter: 5500, curr loss: 0.9623637199401855, avg loss: 1.001033287525177\n",
      "trial: 3, iter: 6000, curr loss: 1.0030732154846191, avg loss: 0.9990333249568939\n",
      "trial: 3, ldr: 2.4442596435546875\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0491485595703125, avg loss: 1.1327726219892502\n",
      "trial: 4, iter: 1000, curr loss: 1.030012607574463, avg loss: 1.0248321053981782\n",
      "trial: 4, iter: 1500, curr loss: 1.017362356185913, avg loss: 1.0166718788146973\n",
      "trial: 4, iter: 2000, curr loss: 0.9927012920379639, avg loss: 1.0112992551326752\n",
      "trial: 4, iter: 2500, curr loss: 1.0104259252548218, avg loss: 1.0081410361528396\n",
      "trial: 4, iter: 3000, curr loss: 1.033713936805725, avg loss: 1.006925983786583\n",
      "trial: 4, iter: 3500, curr loss: 1.0553593635559082, avg loss: 1.0041430406570435\n",
      "trial: 4, iter: 4000, curr loss: 1.0042513608932495, avg loss: 1.0043987275362014\n",
      "trial: 4, iter: 4500, curr loss: 0.9526696801185608, avg loss: 1.0033698023557662\n",
      "trial: 4, iter: 5000, curr loss: 0.9478135704994202, avg loss: 1.0004057079553603\n",
      "trial: 4, iter: 5500, curr loss: 1.0170648097991943, avg loss: 0.9990129179954529\n",
      "trial: 4, iter: 6000, curr loss: 0.9842352867126465, avg loss: 1.0022256447076798\n",
      "trial: 4, ldr: 2.216283082962036\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0483944416046143, avg loss: 1.1155656969547272\n",
      "trial: 5, iter: 1000, curr loss: 1.0059404373168945, avg loss: 1.0192487077713013\n",
      "trial: 5, iter: 1500, curr loss: 1.065154790878296, avg loss: 1.0143884910345078\n",
      "trial: 5, iter: 2000, curr loss: 1.001487374305725, avg loss: 1.0112259138822555\n",
      "trial: 5, iter: 2500, curr loss: 0.9770175218582153, avg loss: 1.0109297542572022\n",
      "trial: 5, iter: 3000, curr loss: 1.0031235218048096, avg loss: 1.0080069000720977\n",
      "trial: 5, iter: 3500, curr loss: 0.9805132150650024, avg loss: 1.0055856360197066\n",
      "trial: 5, iter: 4000, curr loss: 0.9990344047546387, avg loss: 1.0043928549289702\n",
      "trial: 5, iter: 4500, curr loss: 0.9695183634757996, avg loss: 1.005556831598282\n",
      "trial: 5, iter: 5000, curr loss: 1.0014727115631104, avg loss: 0.9992712477445602\n",
      "trial: 5, iter: 5500, curr loss: 0.9986076354980469, avg loss: 1.000547454714775\n",
      "trial: 5, iter: 6000, curr loss: 1.0148861408233643, avg loss: 0.9982111151218415\n",
      "trial: 5, ldr: 2.418883800506592\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.3908113479614257\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0184882879257202, avg loss: 1.1208628861904144\n",
      "trial: 1, iter: 1000, curr loss: 0.9670395851135254, avg loss: 1.0222836873531342\n",
      "trial: 1, iter: 1500, curr loss: 1.083532452583313, avg loss: 1.0156046397686005\n",
      "trial: 1, iter: 2000, curr loss: 1.028896450996399, avg loss: 1.0125747106075287\n",
      "trial: 1, iter: 2500, curr loss: 0.9751837849617004, avg loss: 1.0100393483638763\n",
      "trial: 1, iter: 3000, curr loss: 0.9892000555992126, avg loss: 1.0070407792329787\n",
      "trial: 1, iter: 3500, curr loss: 1.018668293952942, avg loss: 1.002880809545517\n",
      "trial: 1, iter: 4000, curr loss: 1.0325548648834229, avg loss: 1.0046614587306977\n",
      "trial: 1, iter: 4500, curr loss: 1.0401248931884766, avg loss: 1.0031392444372178\n",
      "trial: 1, iter: 5000, curr loss: 0.9935561418533325, avg loss: 1.0027647352218627\n",
      "trial: 1, iter: 5500, curr loss: 1.0533000230789185, avg loss: 0.9997381218671799\n",
      "trial: 1, iter: 6000, curr loss: 0.9692310094833374, avg loss: 0.997700308084488\n",
      "trial: 1, ldr: 2.5456931591033936\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.0203529596328735, avg loss: 1.1181104148626329\n",
      "trial: 2, iter: 1000, curr loss: 1.0073399543762207, avg loss: 1.0197079445123673\n",
      "trial: 2, iter: 1500, curr loss: 1.0396250486373901, avg loss: 1.0159245990514756\n",
      "trial: 2, iter: 2000, curr loss: 1.0389606952667236, avg loss: 1.0114699085950851\n",
      "trial: 2, iter: 2500, curr loss: 1.001928687095642, avg loss: 1.0078874574899674\n",
      "trial: 2, iter: 3000, curr loss: 1.0238722562789917, avg loss: 1.0048712358474732\n",
      "trial: 2, iter: 3500, curr loss: 0.9739498496055603, avg loss: 1.0058549282550813\n",
      "trial: 2, iter: 4000, curr loss: 1.0161973237991333, avg loss: 1.0030261764526367\n",
      "trial: 2, iter: 4500, curr loss: 0.9678078293800354, avg loss: 1.0031139357089995\n",
      "trial: 2, iter: 5000, curr loss: 0.990558385848999, avg loss: 1.0019362448453903\n",
      "trial: 2, iter: 5500, curr loss: 0.9633745551109314, avg loss: 1.0013730449676514\n",
      "trial: 2, iter: 6000, curr loss: 0.9570631980895996, avg loss: 0.9982291498184204\n",
      "trial: 2, ldr: 2.443505048751831\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0147768259048462, avg loss: 1.1302057090997697\n",
      "trial: 3, iter: 1000, curr loss: 0.9993174076080322, avg loss: 1.0204975447654725\n",
      "trial: 3, iter: 1500, curr loss: 1.0049517154693604, avg loss: 1.0151923159360885\n",
      "trial: 3, iter: 2000, curr loss: 1.054368495941162, avg loss: 1.0092312890291213\n",
      "trial: 3, iter: 2500, curr loss: 1.0650745630264282, avg loss: 1.0071159071922302\n",
      "trial: 3, iter: 3000, curr loss: 1.0050650835037231, avg loss: 1.0081145281791688\n",
      "trial: 3, iter: 3500, curr loss: 0.9850941300392151, avg loss: 1.0056806553602218\n",
      "trial: 3, iter: 4000, curr loss: 0.9936243295669556, avg loss: 1.0040925803184508\n",
      "trial: 3, iter: 4500, curr loss: 0.963473379611969, avg loss: 1.0007763164043426\n",
      "trial: 3, iter: 5000, curr loss: 1.0244920253753662, avg loss: 1.0023060615062713\n",
      "trial: 3, iter: 5500, curr loss: 1.0160586833953857, avg loss: 1.000441185593605\n",
      "trial: 3, iter: 6000, curr loss: 0.9938685894012451, avg loss: 0.9984293029308319\n",
      "trial: 3, ldr: 2.417421817779541\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0452299118041992, avg loss: 1.1295068835020066\n",
      "trial: 4, iter: 1000, curr loss: 0.9729471802711487, avg loss: 1.0209056838750838\n",
      "trial: 4, iter: 1500, curr loss: 1.0285719633102417, avg loss: 1.0154787548780442\n",
      "trial: 4, iter: 2000, curr loss: 0.9946326017379761, avg loss: 1.0133617604970933\n",
      "trial: 4, iter: 2500, curr loss: 1.0252501964569092, avg loss: 1.0099689716100693\n",
      "trial: 4, iter: 3000, curr loss: 1.0399192571640015, avg loss: 1.007334667801857\n",
      "trial: 4, iter: 3500, curr loss: 0.9759766459465027, avg loss: 1.006229347705841\n",
      "trial: 4, iter: 4000, curr loss: 1.0053963661193848, avg loss: 1.0055172015428544\n",
      "trial: 4, iter: 4500, curr loss: 0.9979329109191895, avg loss: 1.003180753827095\n",
      "trial: 4, iter: 5000, curr loss: 0.9919208884239197, avg loss: 1.0039868183135987\n",
      "trial: 4, iter: 5500, curr loss: 1.0030834674835205, avg loss: 1.0003816794157028\n",
      "trial: 4, iter: 6000, curr loss: 1.0048279762268066, avg loss: 1.0009717202186585\n",
      "trial: 4, ldr: 2.3764283657073975\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0047523975372314, avg loss: 1.1277919178009033\n",
      "trial: 5, iter: 1000, curr loss: 1.0378116369247437, avg loss: 1.0235242224931718\n",
      "trial: 5, iter: 1500, curr loss: 0.987444281578064, avg loss: 1.0122241687774658\n",
      "trial: 5, iter: 2000, curr loss: 1.0228856801986694, avg loss: 1.0106273415088654\n",
      "trial: 5, iter: 2500, curr loss: 1.0000776052474976, avg loss: 1.009531172990799\n",
      "trial: 5, iter: 3000, curr loss: 1.0161303281784058, avg loss: 1.0095752260684967\n",
      "trial: 5, iter: 3500, curr loss: 1.0165125131607056, avg loss: 1.0065120698213577\n",
      "trial: 5, iter: 4000, curr loss: 1.0015473365783691, avg loss: 1.0048121615648269\n",
      "trial: 5, iter: 4500, curr loss: 0.9978428483009338, avg loss: 1.0026637128591538\n",
      "trial: 5, iter: 5000, curr loss: 0.9579862356185913, avg loss: 1.000160975575447\n",
      "trial: 5, iter: 5500, curr loss: 0.9764206409454346, avg loss: 1.0004407370090485\n",
      "trial: 5, iter: 6000, curr loss: 1.034157156944275, avg loss: 0.9988210241794586\n",
      "trial: 5, ldr: 2.3717575073242188\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.430961179733276\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0290477275848389, avg loss: 1.1280290050506592\n",
      "trial: 1, iter: 1000, curr loss: 1.0371900796890259, avg loss: 1.021602858543396\n",
      "trial: 1, iter: 1500, curr loss: 1.0102823972702026, avg loss: 1.0144080226421357\n",
      "trial: 1, iter: 2000, curr loss: 1.0324937105178833, avg loss: 1.0113866363763808\n",
      "trial: 1, iter: 2500, curr loss: 1.0080883502960205, avg loss: 1.0079074782133102\n",
      "trial: 1, iter: 3000, curr loss: 0.9706451296806335, avg loss: 1.0057041646242142\n",
      "trial: 1, iter: 3500, curr loss: 1.0342191457748413, avg loss: 1.0058526421785354\n",
      "trial: 1, iter: 4000, curr loss: 1.0010335445404053, avg loss: 1.0032357120513915\n",
      "trial: 1, iter: 4500, curr loss: 1.0181277990341187, avg loss: 1.0026159833669663\n",
      "trial: 1, iter: 5000, curr loss: 0.9983164668083191, avg loss: 0.9999840782880783\n",
      "trial: 1, iter: 5500, curr loss: 0.9932277202606201, avg loss: 0.9981862984895706\n",
      "trial: 1, iter: 6000, curr loss: 1.0275931358337402, avg loss: 0.9950889110565185\n",
      "trial: 1, ldr: 2.307065725326538\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.0655643939971924, avg loss: 1.1250000669956208\n",
      "trial: 2, iter: 1000, curr loss: 0.98793625831604, avg loss: 1.0212594722509385\n",
      "trial: 2, iter: 1500, curr loss: 1.0510085821151733, avg loss: 1.0135543438196182\n",
      "trial: 2, iter: 2000, curr loss: 1.0116584300994873, avg loss: 1.00934896337986\n",
      "trial: 2, iter: 2500, curr loss: 0.9681299328804016, avg loss: 1.0099698387384415\n",
      "trial: 2, iter: 3000, curr loss: 0.9767844080924988, avg loss: 1.0076833053827285\n",
      "trial: 2, iter: 3500, curr loss: 1.0055488348007202, avg loss: 1.005729921221733\n",
      "trial: 2, iter: 4000, curr loss: 0.9968786239624023, avg loss: 1.0062615188360213\n",
      "trial: 2, iter: 4500, curr loss: 0.9713876843452454, avg loss: 1.004377942919731\n",
      "trial: 2, iter: 5000, curr loss: 0.973441481590271, avg loss: 1.0014178818464279\n",
      "trial: 2, iter: 5500, curr loss: 1.0086041688919067, avg loss: 0.9997783843278885\n",
      "trial: 2, iter: 6000, curr loss: 0.9912683963775635, avg loss: 0.9998941053152084\n",
      "trial: 2, ldr: 2.38568377494812\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0130178928375244, avg loss: 1.122504227757454\n",
      "trial: 3, iter: 1000, curr loss: 1.0389389991760254, avg loss: 1.022579085111618\n",
      "trial: 3, iter: 1500, curr loss: 0.950660765171051, avg loss: 1.0155662338733673\n",
      "trial: 3, iter: 2000, curr loss: 1.0282000303268433, avg loss: 1.0090333505868911\n",
      "trial: 3, iter: 2500, curr loss: 1.0253355503082275, avg loss: 1.008451305270195\n",
      "trial: 3, iter: 3000, curr loss: 0.99454665184021, avg loss: 1.0094970797300338\n",
      "trial: 3, iter: 3500, curr loss: 1.0148926973342896, avg loss: 1.0084615943431854\n",
      "trial: 3, iter: 4000, curr loss: 0.9946330189704895, avg loss: 1.004508656144142\n",
      "trial: 3, iter: 4500, curr loss: 0.9848908185958862, avg loss: 1.005342015028\n",
      "trial: 3, iter: 5000, curr loss: 1.0042989253997803, avg loss: 1.0019741798639297\n",
      "trial: 3, iter: 5500, curr loss: 0.9900178909301758, avg loss: 1.0011423081159592\n",
      "trial: 3, iter: 6000, curr loss: 0.9569888114929199, avg loss: 0.9985905132293701\n",
      "trial: 3, ldr: 2.4577722549438477\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0018353462219238, avg loss: 1.1225354952812194\n",
      "trial: 4, iter: 1000, curr loss: 0.9757693409919739, avg loss: 1.0208179069757461\n",
      "trial: 4, iter: 1500, curr loss: 1.0245181322097778, avg loss: 1.0151159075498581\n",
      "trial: 4, iter: 2000, curr loss: 1.0078705549240112, avg loss: 1.0114660634994508\n",
      "trial: 4, iter: 2500, curr loss: 0.9924499988555908, avg loss: 1.009021701812744\n",
      "trial: 4, iter: 3000, curr loss: 0.9756891131401062, avg loss: 1.0075695888996123\n",
      "trial: 4, iter: 3500, curr loss: 1.0196123123168945, avg loss: 1.007761574268341\n",
      "trial: 4, iter: 4000, curr loss: 1.0053762197494507, avg loss: 1.0055598901510239\n",
      "trial: 4, iter: 4500, curr loss: 1.000591516494751, avg loss: 1.0021531938314439\n",
      "trial: 4, iter: 5000, curr loss: 1.0365787744522095, avg loss: 1.003579741358757\n",
      "trial: 4, iter: 5500, curr loss: 1.0089014768600464, avg loss: 1.000034975528717\n",
      "trial: 4, iter: 6000, curr loss: 1.0005087852478027, avg loss: 0.9977648791074752\n",
      "trial: 4, ldr: 2.59891414642334\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0436477661132812, avg loss: 1.1271903116703033\n",
      "trial: 5, iter: 1000, curr loss: 1.0325257778167725, avg loss: 1.0200012160539627\n",
      "trial: 5, iter: 1500, curr loss: 0.9990745782852173, avg loss: 1.0134732986688615\n",
      "trial: 5, iter: 2000, curr loss: 1.0330805778503418, avg loss: 1.0132787005901336\n",
      "trial: 5, iter: 2500, curr loss: 1.0233973264694214, avg loss: 1.012175858259201\n",
      "trial: 5, iter: 3000, curr loss: 0.9903917908668518, avg loss: 1.0085949473381042\n",
      "trial: 5, iter: 3500, curr loss: 1.0496773719787598, avg loss: 1.0063781292438507\n",
      "trial: 5, iter: 4000, curr loss: 0.963130533695221, avg loss: 1.0048417838811874\n",
      "trial: 5, iter: 4500, curr loss: 1.0458276271820068, avg loss: 1.0043245220184327\n",
      "trial: 5, iter: 5000, curr loss: 1.0133215188980103, avg loss: 1.003614533662796\n",
      "trial: 5, iter: 5500, curr loss: 1.0144567489624023, avg loss: 1.0025161888599396\n",
      "trial: 5, iter: 6000, curr loss: 1.0254580974578857, avg loss: 0.9988418848514556\n",
      "trial: 5, ldr: 2.320483922958374\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.413983964920044\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0060005187988281, avg loss: 1.1298326607942581\n",
      "trial: 1, iter: 1000, curr loss: 1.053541898727417, avg loss: 1.0182428911924362\n",
      "trial: 1, iter: 1500, curr loss: 0.9866953492164612, avg loss: 1.0134061753749848\n",
      "trial: 1, iter: 2000, curr loss: 1.0042105913162231, avg loss: 1.0092902926206588\n",
      "trial: 1, iter: 2500, curr loss: 1.0015208721160889, avg loss: 1.009420352578163\n",
      "trial: 1, iter: 3000, curr loss: 1.0214120149612427, avg loss: 1.0055742400884629\n",
      "trial: 1, iter: 3500, curr loss: 0.976995050907135, avg loss: 1.0052267572879792\n",
      "trial: 1, iter: 4000, curr loss: 0.980197012424469, avg loss: 1.0028582575321197\n",
      "trial: 1, iter: 4500, curr loss: 0.9847375750541687, avg loss: 1.0025059847831725\n",
      "trial: 1, iter: 5000, curr loss: 1.0027904510498047, avg loss: 1.0006128088235855\n",
      "trial: 1, iter: 5500, curr loss: 0.9968940615653992, avg loss: 0.9995304781198502\n",
      "trial: 1, iter: 6000, curr loss: 1.018823504447937, avg loss: 1.0024730377197266\n",
      "trial: 1, ldr: 2.211669683456421\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.9709492325782776, avg loss: 1.1121995261907578\n",
      "trial: 2, iter: 1000, curr loss: 0.9920863509178162, avg loss: 1.0190482071638107\n",
      "trial: 2, iter: 1500, curr loss: 1.0101029872894287, avg loss: 1.0118029574155807\n",
      "trial: 2, iter: 2000, curr loss: 1.030723214149475, avg loss: 1.0110815494060517\n",
      "trial: 2, iter: 2500, curr loss: 1.0058512687683105, avg loss: 1.00828575527668\n",
      "trial: 2, iter: 3000, curr loss: 0.9812735319137573, avg loss: 1.0080751671791077\n",
      "trial: 2, iter: 3500, curr loss: 0.9916574358940125, avg loss: 1.0028943532705308\n",
      "trial: 2, iter: 4000, curr loss: 0.9664114713668823, avg loss: 1.0007375460863113\n",
      "trial: 2, iter: 4500, curr loss: 1.0069608688354492, avg loss: 1.0020084747076035\n",
      "trial: 2, iter: 5000, curr loss: 0.9690073132514954, avg loss: 0.9996198230981826\n",
      "trial: 2, iter: 5500, curr loss: 0.9693294167518616, avg loss: 0.9984557267427444\n",
      "trial: 2, iter: 6000, curr loss: 1.0223674774169922, avg loss: 0.998388543844223\n",
      "trial: 2, ldr: 2.302779197692871\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0103412866592407, avg loss: 1.1208135411739348\n",
      "trial: 3, iter: 1000, curr loss: 1.0005382299423218, avg loss: 1.0202725129127503\n",
      "trial: 3, iter: 1500, curr loss: 1.0145448446273804, avg loss: 1.014191348195076\n",
      "trial: 3, iter: 2000, curr loss: 1.0275845527648926, avg loss: 1.0130785118341445\n",
      "trial: 3, iter: 2500, curr loss: 0.9667416214942932, avg loss: 1.011839606642723\n",
      "trial: 3, iter: 3000, curr loss: 1.0577985048294067, avg loss: 1.0047810635566712\n",
      "trial: 3, iter: 3500, curr loss: 1.0419707298278809, avg loss: 1.0039178122282029\n",
      "trial: 3, iter: 4000, curr loss: 0.9438223838806152, avg loss: 1.0020912948846816\n",
      "trial: 3, iter: 4500, curr loss: 1.0176464319229126, avg loss: 1.0015084320306777\n",
      "trial: 3, iter: 5000, curr loss: 1.0417330265045166, avg loss: 1.001202980875969\n",
      "trial: 3, iter: 5500, curr loss: 0.9575287103652954, avg loss: 0.9988516706228256\n",
      "trial: 3, iter: 6000, curr loss: 1.0068094730377197, avg loss: 0.9961357202529907\n",
      "trial: 3, ldr: 2.2989370822906494\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0355082750320435, avg loss: 1.124823235630989\n",
      "trial: 4, iter: 1000, curr loss: 1.0481473207473755, avg loss: 1.0202987306118012\n",
      "trial: 4, iter: 1500, curr loss: 1.0314576625823975, avg loss: 1.015909789085388\n",
      "trial: 4, iter: 2000, curr loss: 1.0062792301177979, avg loss: 1.010878223657608\n",
      "trial: 4, iter: 2500, curr loss: 0.9994425773620605, avg loss: 1.007272168636322\n",
      "trial: 4, iter: 3000, curr loss: 1.0630182027816772, avg loss: 1.0068941216468812\n",
      "trial: 4, iter: 3500, curr loss: 0.9905568361282349, avg loss: 1.0056400182247163\n",
      "trial: 4, iter: 4000, curr loss: 0.995868980884552, avg loss: 1.0030654071569443\n",
      "trial: 4, iter: 4500, curr loss: 1.0099527835845947, avg loss: 1.0024504421949387\n",
      "trial: 4, iter: 5000, curr loss: 1.0245589017868042, avg loss: 0.9976474905014038\n",
      "trial: 4, iter: 5500, curr loss: 1.0159398317337036, avg loss: 0.9990233761072159\n",
      "trial: 4, iter: 6000, curr loss: 1.0159718990325928, avg loss: 0.9970734081268311\n",
      "trial: 4, ldr: 2.1008450984954834\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0563733577728271, avg loss: 1.1225947703123094\n",
      "trial: 5, iter: 1000, curr loss: 0.980379045009613, avg loss: 1.0210825319290162\n",
      "trial: 5, iter: 1500, curr loss: 1.006212592124939, avg loss: 1.01320436501503\n",
      "trial: 5, iter: 2000, curr loss: 1.0544284582138062, avg loss: 1.0132704923152924\n",
      "trial: 5, iter: 2500, curr loss: 0.9670264720916748, avg loss: 1.0096776204109192\n",
      "trial: 5, iter: 3000, curr loss: 1.0168606042861938, avg loss: 1.007798612356186\n",
      "trial: 5, iter: 3500, curr loss: 0.9998519420623779, avg loss: 1.005305801987648\n",
      "trial: 5, iter: 4000, curr loss: 0.9836645722389221, avg loss: 1.003840258717537\n",
      "trial: 5, iter: 4500, curr loss: 0.9889843463897705, avg loss: 1.0008881846666335\n",
      "trial: 5, iter: 5000, curr loss: 1.0364290475845337, avg loss: 1.000670468568802\n",
      "trial: 5, iter: 5500, curr loss: 1.0265867710113525, avg loss: 0.9999714090824127\n",
      "trial: 5, iter: 6000, curr loss: 0.9930295944213867, avg loss: 0.9982400603294372\n",
      "trial: 5, ldr: 2.5339488983154297\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.289635992050171\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 1.0727328062057495, avg loss: 1.1197710285186768\n",
      "trial: 1, iter: 1000, curr loss: 1.0114721059799194, avg loss: 1.01945278775692\n",
      "trial: 1, iter: 1500, curr loss: 1.0283135175704956, avg loss: 1.01146360039711\n",
      "trial: 1, iter: 2000, curr loss: 0.9907785654067993, avg loss: 1.0099867252111434\n",
      "trial: 1, iter: 2500, curr loss: 1.0256508588790894, avg loss: 1.0053723406791688\n",
      "trial: 1, iter: 3000, curr loss: 0.9568051695823669, avg loss: 1.0032047402858735\n",
      "trial: 1, iter: 3500, curr loss: 1.000839352607727, avg loss: 1.0022688252925873\n",
      "trial: 1, iter: 4000, curr loss: 0.967553973197937, avg loss: 1.0000271894931794\n",
      "trial: 1, iter: 4500, curr loss: 1.0355963706970215, avg loss: 0.9980818449258805\n",
      "trial: 1, iter: 5000, curr loss: 1.024619698524475, avg loss: 1.0007399121522904\n",
      "trial: 1, iter: 5500, curr loss: 0.9925220608711243, avg loss: 0.9940063498020172\n",
      "trial: 1, iter: 6000, curr loss: 0.9855961799621582, avg loss: 0.9952694035768509\n",
      "trial: 1, ldr: 2.5152316093444824\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 1.0211824178695679, avg loss: 1.124056990981102\n",
      "trial: 2, iter: 1000, curr loss: 1.0046898126602173, avg loss: 1.0177625000476838\n",
      "trial: 2, iter: 1500, curr loss: 1.0360584259033203, avg loss: 1.0133911060094833\n",
      "trial: 2, iter: 2000, curr loss: 1.0024337768554688, avg loss: 1.0087372121810914\n",
      "trial: 2, iter: 2500, curr loss: 0.9889931678771973, avg loss: 1.0076240915060044\n",
      "trial: 2, iter: 3000, curr loss: 1.0504101514816284, avg loss: 1.0040746233463287\n",
      "trial: 2, iter: 3500, curr loss: 1.0490766763687134, avg loss: 1.0046321550607682\n",
      "trial: 2, iter: 4000, curr loss: 0.9813206791877747, avg loss: 1.00024356508255\n",
      "trial: 2, iter: 4500, curr loss: 1.0185909271240234, avg loss: 0.9992075383663177\n",
      "trial: 2, iter: 5000, curr loss: 0.9996576309204102, avg loss: 0.9966722697019577\n",
      "trial: 2, iter: 5500, curr loss: 1.0303634405136108, avg loss: 0.9981167904138565\n",
      "trial: 2, iter: 6000, curr loss: 1.0572396516799927, avg loss: 0.9967689461708069\n",
      "trial: 2, ldr: 2.4474635124206543\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 0.9972498416900635, avg loss: 1.1332082879543304\n",
      "trial: 3, iter: 1000, curr loss: 1.040794849395752, avg loss: 1.0180450112819672\n",
      "trial: 3, iter: 1500, curr loss: 0.9601098299026489, avg loss: 1.013740385055542\n",
      "trial: 3, iter: 2000, curr loss: 0.984350323677063, avg loss: 1.0075523134469986\n",
      "trial: 3, iter: 2500, curr loss: 0.9757243394851685, avg loss: 1.0065883289575577\n",
      "trial: 3, iter: 3000, curr loss: 1.0221072435379028, avg loss: 1.0024441395998\n",
      "trial: 3, iter: 3500, curr loss: 1.0083385705947876, avg loss: 1.0035759921073915\n",
      "trial: 3, iter: 4000, curr loss: 1.052323579788208, avg loss: 1.0015430001020431\n",
      "trial: 3, iter: 4500, curr loss: 0.9393638372421265, avg loss: 0.9991138944625855\n",
      "trial: 3, iter: 5000, curr loss: 1.0147745609283447, avg loss: 0.9954498422145843\n",
      "trial: 3, iter: 5500, curr loss: 0.9627412557601929, avg loss: 0.9973116536140442\n",
      "trial: 3, iter: 6000, curr loss: 1.0391566753387451, avg loss: 0.9942247972488404\n",
      "trial: 3, ldr: 2.7351222038269043\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.020908236503601, avg loss: 1.1288709143400193\n",
      "trial: 4, iter: 1000, curr loss: 0.9761468768119812, avg loss: 1.0171802221536637\n",
      "trial: 4, iter: 1500, curr loss: 0.9724756479263306, avg loss: 1.0117158271074296\n",
      "trial: 4, iter: 2000, curr loss: 1.0825406312942505, avg loss: 1.0084124670028687\n",
      "trial: 4, iter: 2500, curr loss: 1.0207222700119019, avg loss: 1.0082360059022903\n",
      "trial: 4, iter: 3000, curr loss: 1.0268374681472778, avg loss: 1.0045651955604553\n",
      "trial: 4, iter: 3500, curr loss: 1.0364961624145508, avg loss: 1.003470535159111\n",
      "trial: 4, iter: 4000, curr loss: 0.94760662317276, avg loss: 1.0002337464094162\n",
      "trial: 4, iter: 4500, curr loss: 1.0370762348175049, avg loss: 0.9990259914398193\n",
      "trial: 4, iter: 5000, curr loss: 0.9759855270385742, avg loss: 0.9990179425477982\n",
      "trial: 4, iter: 5500, curr loss: 0.9651682376861572, avg loss: 0.9951215051412582\n",
      "trial: 4, iter: 6000, curr loss: 1.0124235153198242, avg loss: 0.9954820685386657\n",
      "trial: 4, ldr: 2.3993334770202637\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.0067236423492432, avg loss: 1.1199602996110916\n",
      "trial: 5, iter: 1000, curr loss: 0.9794413447380066, avg loss: 1.0182430180311204\n",
      "trial: 5, iter: 1500, curr loss: 1.016229510307312, avg loss: 1.0098406307697296\n",
      "trial: 5, iter: 2000, curr loss: 0.9765673875808716, avg loss: 1.0084487990140916\n",
      "trial: 5, iter: 2500, curr loss: 0.9857657551765442, avg loss: 1.0068599709272386\n",
      "trial: 5, iter: 3000, curr loss: 0.9970704913139343, avg loss: 1.0040483586788178\n",
      "trial: 5, iter: 3500, curr loss: 1.0150774717330933, avg loss: 1.0007312706708908\n",
      "trial: 5, iter: 4000, curr loss: 0.9836903214454651, avg loss: 1.0021160947084427\n",
      "trial: 5, iter: 4500, curr loss: 1.0070133209228516, avg loss: 0.9986554039716721\n",
      "trial: 5, iter: 5000, curr loss: 0.9843352437019348, avg loss: 0.9986452194452285\n",
      "trial: 5, iter: 5500, curr loss: 0.97441166639328, avg loss: 0.9961608723402023\n",
      "trial: 5, iter: 6000, curr loss: 0.9826656579971313, avg loss: 0.9944533672332764\n",
      "trial: 5, ldr: 2.7503559589385986\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.569501352310181\n",
      "################################################################\n",
      "trial: 1, iter: 500, curr loss: 0.9842231869697571, avg loss: 1.1304118267297745\n",
      "trial: 1, iter: 1000, curr loss: 1.0091153383255005, avg loss: 1.0217660225629805\n",
      "trial: 1, iter: 1500, curr loss: 0.9790799617767334, avg loss: 1.0151358460187911\n",
      "trial: 1, iter: 2000, curr loss: 0.9950986504554749, avg loss: 1.0094888886213302\n",
      "trial: 1, iter: 2500, curr loss: 0.9756600260734558, avg loss: 1.0088685723543167\n",
      "trial: 1, iter: 3000, curr loss: 0.9603310227394104, avg loss: 1.0053935667276384\n",
      "trial: 1, iter: 3500, curr loss: 1.008459448814392, avg loss: 1.0035509238243103\n",
      "trial: 1, iter: 4000, curr loss: 0.9747725129127502, avg loss: 1.0042205740213395\n",
      "trial: 1, iter: 4500, curr loss: 0.9621878266334534, avg loss: 1.0022976299524307\n",
      "trial: 1, iter: 5000, curr loss: 1.0272859334945679, avg loss: 1.0029114941358566\n",
      "trial: 1, iter: 5500, curr loss: 1.0102049112319946, avg loss: 1.0000448297262192\n",
      "trial: 1, iter: 6000, curr loss: 0.9741737246513367, avg loss: 0.9978741433620453\n",
      "trial: 1, ldr: 2.4366812705993652\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, iter: 500, curr loss: 0.9870020151138306, avg loss: 1.1299278657436371\n",
      "trial: 2, iter: 1000, curr loss: 1.003971815109253, avg loss: 1.020614655971527\n",
      "trial: 2, iter: 1500, curr loss: 0.985556960105896, avg loss: 1.0145425970554351\n",
      "trial: 2, iter: 2000, curr loss: 0.9861799478530884, avg loss: 1.0138658870458603\n",
      "trial: 2, iter: 2500, curr loss: 1.0467350482940674, avg loss: 1.0099568289518357\n",
      "trial: 2, iter: 3000, curr loss: 1.0417511463165283, avg loss: 1.0104065169095993\n",
      "trial: 2, iter: 3500, curr loss: 0.9971646070480347, avg loss: 1.0072347229719163\n",
      "trial: 2, iter: 4000, curr loss: 0.987816333770752, avg loss: 1.005610512971878\n",
      "trial: 2, iter: 4500, curr loss: 1.036313533782959, avg loss: 1.0050073268413544\n",
      "trial: 2, iter: 5000, curr loss: 1.0226718187332153, avg loss: 1.001770074248314\n",
      "trial: 2, iter: 5500, curr loss: 0.9712661504745483, avg loss: 1.0018599511384965\n",
      "trial: 2, iter: 6000, curr loss: 0.9423259496688843, avg loss: 0.9985808300971984\n",
      "trial: 2, ldr: 2.293816328048706\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, iter: 500, curr loss: 1.0443298816680908, avg loss: 1.1335688683986664\n",
      "trial: 3, iter: 1000, curr loss: 1.0344650745391846, avg loss: 1.0205238143205642\n",
      "trial: 3, iter: 1500, curr loss: 1.0025136470794678, avg loss: 1.0133890200853348\n",
      "trial: 3, iter: 2000, curr loss: 1.010414481163025, avg loss: 1.013154483795166\n",
      "trial: 3, iter: 2500, curr loss: 1.0132648944854736, avg loss: 1.0108482867479325\n",
      "trial: 3, iter: 3000, curr loss: 0.9914237260818481, avg loss: 1.0088993512392044\n",
      "trial: 3, iter: 3500, curr loss: 0.9799874424934387, avg loss: 1.0067326275110244\n",
      "trial: 3, iter: 4000, curr loss: 0.9622907042503357, avg loss: 1.0033246787786483\n",
      "trial: 3, iter: 4500, curr loss: 1.0151227712631226, avg loss: 1.0031325504779816\n",
      "trial: 3, iter: 5000, curr loss: 0.9967797994613647, avg loss: 0.9999748817682266\n",
      "trial: 3, iter: 5500, curr loss: 1.0195163488388062, avg loss: 0.9998345108032226\n",
      "trial: 3, iter: 6000, curr loss: 0.9681333899497986, avg loss: 0.9985808769464493\n",
      "trial: 3, ldr: 2.2107903957366943\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, iter: 500, curr loss: 1.0140396356582642, avg loss: 1.1310929874181748\n",
      "trial: 4, iter: 1000, curr loss: 1.0285744667053223, avg loss: 1.020401175379753\n",
      "trial: 4, iter: 1500, curr loss: 0.9735127091407776, avg loss: 1.0140893704891205\n",
      "trial: 4, iter: 2000, curr loss: 1.016484022140503, avg loss: 1.0123038747310638\n",
      "trial: 4, iter: 2500, curr loss: 1.0047721862792969, avg loss: 1.010890254497528\n",
      "trial: 4, iter: 3000, curr loss: 1.0006093978881836, avg loss: 1.008573718547821\n",
      "trial: 4, iter: 3500, curr loss: 1.0209779739379883, avg loss: 1.0054494578838349\n",
      "trial: 4, iter: 4000, curr loss: 1.0742037296295166, avg loss: 1.0034643173217774\n",
      "trial: 4, iter: 4500, curr loss: 0.9959192872047424, avg loss: 1.0004406274557114\n",
      "trial: 4, iter: 5000, curr loss: 0.9709670543670654, avg loss: 0.9993052588701248\n",
      "trial: 4, iter: 5500, curr loss: 0.9863829612731934, avg loss: 1.0003265458345414\n",
      "trial: 4, iter: 6000, curr loss: 0.9464290142059326, avg loss: 0.9991954597234726\n",
      "trial: 4, ldr: 2.3264153003692627\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, iter: 500, curr loss: 1.027925729751587, avg loss: 1.1204537065029145\n",
      "trial: 5, iter: 1000, curr loss: 1.0362818241119385, avg loss: 1.0174060150384903\n",
      "trial: 5, iter: 1500, curr loss: 1.0162525177001953, avg loss: 1.0162059636116028\n",
      "trial: 5, iter: 2000, curr loss: 1.013912320137024, avg loss: 1.0118270055055618\n",
      "trial: 5, iter: 2500, curr loss: 0.9723789691925049, avg loss: 1.0110956993103026\n",
      "trial: 5, iter: 3000, curr loss: 1.001086711883545, avg loss: 1.0090829594135284\n",
      "trial: 5, iter: 3500, curr loss: 1.002326488494873, avg loss: 1.0063381032943726\n",
      "trial: 5, iter: 4000, curr loss: 1.0179098844528198, avg loss: 1.0034085698127746\n",
      "trial: 5, iter: 4500, curr loss: 0.9975166916847229, avg loss: 1.0016954482793807\n",
      "trial: 5, iter: 5000, curr loss: 1.0010478496551514, avg loss: 1.0027363584041595\n",
      "trial: 5, iter: 5500, curr loss: 0.9904224276542664, avg loss: 1.0014685255289077\n",
      "trial: 5, iter: 6000, curr loss: 1.0344164371490479, avg loss: 0.9987971926927567\n",
      "trial: 5, ldr: 2.306748628616333\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 2.3148903846740723\n"
     ]
    }
   ],
   "source": [
    "ldr_arr_multi = []\n",
    "for i in range(num_of_outer_iteration):\n",
    "    ldr = multiclass_probabilistic_classifier_experiment(prime, data_range, num_of_samples, weight, feature_size, beta_arr, alpha_arr, para_param, priv_param, x_idx, y_idx, z_idx, hidden_size_arr, lr, num_of_mid_iteration, num_of_inner_iteration, batch_size, load_data='./data/catF/data.20k.dz50.seed0.npy', save_avg=500)\n",
    "    ldr_arr_multi.append(ldr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:17:33.790418748Z",
     "start_time": "2023-12-12T23:10:42.012356870Z"
    }
   },
   "id": "96ca868b1ad72df3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3986660861968994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ldr_multi_mean = np.mean(np.asarray(ldr_arr_multi))\n",
    "print(ldr_multi_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:19:07.932143559Z",
     "start_time": "2023-12-12T23:19:07.873954681Z"
    }
   },
   "id": "284db425800f4c7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
