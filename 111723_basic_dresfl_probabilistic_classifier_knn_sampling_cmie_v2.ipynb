{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:55:06.245574976Z",
     "start_time": "2023-11-18T03:55:06.202338322Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from probabilistic_classifier.dataset import create_knn_sampling_joint_cond_marginal_dataset\n",
    "from probabilistic_classifier.probabilistic_classifier import ProbabilisticClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# create the basis dataset\n",
    "mean = [0, 0, 0]\n",
    "cov = [[1, 0.8, 0.5],\n",
    "       [0.8, 1, 0],\n",
    "       [0.5, 0, 1]]\n",
    "num_of_samples = 10000\n",
    "dataset = np.random.multivariate_normal(mean=mean, cov=cov, size=num_of_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:55:06.795808632Z",
     "start_time": "2023-11-18T03:55:06.793669410Z"
    }
   },
   "id": "d52797b0247350ca"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "num_of_neighbors = 4\n",
    "x_idx, y_idx, z_idx = [0], [1], [2]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_knn_sampling_joint_cond_marginal_dataset(dataset, 2,\n",
    "                                                                                                         [0], [1], [2])\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:55:07.489006046Z",
     "start_time": "2023-11-18T03:55:07.457456552Z"
    }
   },
   "id": "62da61c8fc32e6fa"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(y_idx) + len(z_idx)\n",
    "hidden_size_arr = [64]\n",
    "num_output_features = 2\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:55:08.204040856Z",
     "start_time": "2023-11-18T03:55:08.202338173Z"
    }
   },
   "id": "4cb99642d6db7215"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1, iter: 1, curr loss: 0.692747950553894, avg loss: 0.692747950553894\n",
      "trial: 1, iter: 100, curr loss: 0.5982009172439575, avg loss: 0.6452596783638\n",
      "trial: 1, iter: 200, curr loss: 0.49811217188835144, avg loss: 0.5952605031430721\n",
      "trial: 1, iter: 300, curr loss: 0.4440138339996338, avg loss: 0.5530812853574752\n",
      "trial: 1, iter: 400, curr loss: 0.4260384440422058, avg loss: 0.523169476389885\n",
      "trial: 1, iter: 500, curr loss: 0.42652058601379395, avg loss: 0.5028366670608521\n",
      "trial: 1, iter: 600, curr loss: 0.4219977557659149, avg loss: 0.4887246939043204\n",
      "trial: 1, iter: 700, curr loss: 0.41412353515625, avg loss: 0.4782590565936906\n",
      "trial: 1, iter: 800, curr loss: 0.4160095453262329, avg loss: 0.4702806865051389\n",
      "trial: 1, iter: 900, curr loss: 0.41736942529678345, avg loss: 0.46402409040265613\n",
      "trial: 1, iter: 1000, curr loss: 0.4124114215373993, avg loss: 0.4590521534979343\n",
      "trial: 1, iter: 1100, curr loss: 0.404771625995636, avg loss: 0.4549628913944418\n",
      "trial: 1, iter: 1200, curr loss: 0.4080609679222107, avg loss: 0.4515328199168046\n",
      "trial: 1, iter: 1300, curr loss: 0.4159511923789978, avg loss: 0.44850542295437595\n",
      "trial: 1, iter: 1400, curr loss: 0.417965829372406, avg loss: 0.4459165371954441\n",
      "trial: 1, iter: 1500, curr loss: 0.40846672654151917, avg loss: 0.4435680666764577\n",
      "trial: 1, iter: 1600, curr loss: 0.4204738140106201, avg loss: 0.44154157415032386\n",
      "trial: 1, iter: 1700, curr loss: 0.41490089893341064, avg loss: 0.4396552088155466\n",
      "trial: 1, iter: 1800, curr loss: 0.4174868166446686, avg loss: 0.43809561640024186\n",
      "trial: 1, iter: 1900, curr loss: 0.4106673002243042, avg loss: 0.4365687095177801\n",
      "trial: 1, iter: 2000, curr loss: 0.4042831063270569, avg loss: 0.4352608396857977\n",
      "trial: 1, iter: 2100, curr loss: 0.4166789650917053, avg loss: 0.43411038212832953\n",
      "trial: 1, iter: 2200, curr loss: 0.42030027508735657, avg loss: 0.43300788271156226\n",
      "trial: 1, iter: 2300, curr loss: 0.4124901294708252, avg loss: 0.4320589136429455\n",
      "trial: 1, iter: 2400, curr loss: 0.40356114506721497, avg loss: 0.43112590090682107\n",
      "trial: 1, iter: 2500, curr loss: 0.40206483006477356, avg loss: 0.43021917477846144\n",
      "trial: 1, iter: 2600, curr loss: 0.3988381624221802, avg loss: 0.4294803353227102\n",
      "trial: 1, iter: 2700, curr loss: 0.41321736574172974, avg loss: 0.4287595884667503\n",
      "trial: 1, iter: 2800, curr loss: 0.4063285291194916, avg loss: 0.4280624442441123\n",
      "trial: 1, iter: 2900, curr loss: 0.40411102771759033, avg loss: 0.4274392294575428\n",
      "trial: 1, iter: 3000, curr loss: 0.41186287999153137, avg loss: 0.42684317060311633\n",
      "trial: 1, iter: 3100, curr loss: 0.4095436930656433, avg loss: 0.42627334931204397\n",
      "trial: 1, iter: 3200, curr loss: 0.4124324917793274, avg loss: 0.42573411780409515\n",
      "trial: 1, iter: 3300, curr loss: 0.42717844247817993, avg loss: 0.42525630485830884\n",
      "trial: 1, iter: 3400, curr loss: 0.40761831402778625, avg loss: 0.4248236286990783\n",
      "trial: 1, iter: 3500, curr loss: 0.41542428731918335, avg loss: 0.42438740199804303\n",
      "trial: 1, iter: 3600, curr loss: 0.39921653270721436, avg loss: 0.42398057145377\n",
      "trial: 1, iter: 3700, curr loss: 0.4093720316886902, avg loss: 0.4235964352617393\n",
      "trial: 1, iter: 3800, curr loss: 0.40300023555755615, avg loss: 0.42321970081643057\n",
      "trial: 1, iter: 3900, curr loss: 0.4094499945640564, avg loss: 0.42285542344435667\n",
      "trial: 1, iter: 4000, curr loss: 0.39489638805389404, avg loss: 0.422475002259016\n",
      "trial: 1, iter: 4100, curr loss: 0.41196948289871216, avg loss: 0.42216872418072166\n",
      "trial: 1, iter: 4200, curr loss: 0.39803045988082886, avg loss: 0.4218452104074614\n",
      "trial: 1, iter: 4300, curr loss: 0.39973539113998413, avg loss: 0.42156081367370696\n",
      "trial: 1, iter: 4400, curr loss: 0.41635245084762573, avg loss: 0.42125407672741194\n",
      "trial: 1, iter: 4500, curr loss: 0.4101794362068176, avg loss: 0.42097544869449405\n",
      "trial: 1, iter: 4600, curr loss: 0.40932002663612366, avg loss: 0.42073313358685244\n",
      "trial: 1, iter: 4700, curr loss: 0.4201515316963196, avg loss: 0.4204906687901375\n",
      "trial: 1, iter: 4800, curr loss: 0.40517574548721313, avg loss: 0.42024360031510394\n",
      "trial: 1, iter: 4900, curr loss: 0.41182270646095276, avg loss: 0.42002742438900226\n",
      "trial: 1, iter: 5000, curr loss: 0.40811535716056824, avg loss: 0.4198033976554871\n",
      "trial: 1, iter: 5100, curr loss: 0.4104052186012268, avg loss: 0.41958736342542313\n",
      "trial: 1, iter: 5200, curr loss: 0.41147536039352417, avg loss: 0.4193703068105074\n",
      "trial: 1, iter: 5300, curr loss: 0.39400750398635864, avg loss: 0.41918597504777727\n",
      "trial: 1, iter: 5400, curr loss: 0.4032970070838928, avg loss: 0.41900608797316197\n",
      "trial: 1, iter: 5500, curr loss: 0.4127463698387146, avg loss: 0.4188188180381601\n",
      "trial: 1, iter: 5600, curr loss: 0.41606444120407104, avg loss: 0.4186565804108977\n",
      "trial: 1, iter: 5700, curr loss: 0.415145605802536, avg loss: 0.41846516994530697\n",
      "trial: 1, iter: 5800, curr loss: 0.39331790804862976, avg loss: 0.41828289232377347\n",
      "trial: 1, iter: 5900, curr loss: 0.40181082487106323, avg loss: 0.4181197980753446\n",
      "trial: 1, iter: 6000, curr loss: 0.4134027659893036, avg loss: 0.417956634948651\n",
      "trial: 1, iter: 6100, curr loss: 0.401344358921051, avg loss: 0.41781436060784294\n",
      "trial: 1, iter: 6200, curr loss: 0.40666335821151733, avg loss: 0.41765964715711534\n",
      "trial: 1, iter: 6300, curr loss: 0.4063017666339874, avg loss: 0.4175278631798805\n",
      "trial: 1, iter: 6400, curr loss: 0.4109930992126465, avg loss: 0.41739807116333394\n",
      "trial: 1, iter: 6500, curr loss: 0.3938480019569397, avg loss: 0.4172609108319649\n",
      "trial: 1, iter: 6600, curr loss: 0.4147213101387024, avg loss: 0.41711657978368527\n",
      "trial: 1, iter: 6700, curr loss: 0.4093141257762909, avg loss: 0.4170071056307252\n",
      "trial: 1, iter: 6800, curr loss: 0.3970562219619751, avg loss: 0.4168888656707371\n",
      "trial: 1, iter: 6900, curr loss: 0.4007231593132019, avg loss: 0.41677991728419844\n",
      "trial: 1, iter: 7000, curr loss: 0.4032009243965149, avg loss: 0.41666644952126913\n",
      "trial: 1, iter: 7100, curr loss: 0.4255253076553345, avg loss: 0.41656214172571476\n",
      "trial: 1, iter: 7200, curr loss: 0.3995399475097656, avg loss: 0.41646199393189615\n",
      "trial: 1, iter: 7300, curr loss: 0.4022853970527649, avg loss: 0.4163437654302545\n",
      "trial: 1, iter: 7400, curr loss: 0.40313607454299927, avg loss: 0.4162472806709844\n",
      "trial: 1, iter: 7500, curr loss: 0.413115918636322, avg loss: 0.4161582788825035\n",
      "trial: 1, iter: 7600, curr loss: 0.3982272148132324, avg loss: 0.4160529123207456\n",
      "trial: 1, iter: 7700, curr loss: 0.4096261262893677, avg loss: 0.4159553114586062\n",
      "trial: 1, iter: 7800, curr loss: 0.4043641984462738, avg loss: 0.4158661753856219\n",
      "trial: 1, iter: 7900, curr loss: 0.4016205668449402, avg loss: 0.4157712375287768\n",
      "trial: 1, iter: 8000, curr loss: 0.41756391525268555, avg loss: 0.4156805993616581\n",
      "trial: 1, iter: 8100, curr loss: 0.4236055910587311, avg loss: 0.41558477771870883\n",
      "trial: 1, iter: 8200, curr loss: 0.41304826736450195, avg loss: 0.4154934466830114\n",
      "trial: 1, iter: 8300, curr loss: 0.41043567657470703, avg loss: 0.41540635674114684\n",
      "trial: 1, iter: 8400, curr loss: 0.4001396894454956, avg loss: 0.4153163706688654\n",
      "trial: 1, iter: 8500, curr loss: 0.39676013588905334, avg loss: 0.41523088058303387\n",
      "trial: 1, iter: 8600, curr loss: 0.40861213207244873, avg loss: 0.41515148905127547\n",
      "trial: 1, iter: 8700, curr loss: 0.409112811088562, avg loss: 0.41506179888015504\n",
      "trial: 1, iter: 8800, curr loss: 0.40677714347839355, avg loss: 0.4149753307618878\n",
      "trial: 1, iter: 8900, curr loss: 0.4137863516807556, avg loss: 0.4149033749438404\n",
      "trial: 1, iter: 9000, curr loss: 0.39888912439346313, avg loss: 0.4148292404545678\n",
      "trial: 1, iter: 9100, curr loss: 0.41259872913360596, avg loss: 0.4147627277328418\n",
      "trial: 1, iter: 9200, curr loss: 0.38604575395584106, avg loss: 0.4146905348871065\n",
      "trial: 1, iter: 9300, curr loss: 0.3992926776409149, avg loss: 0.4146279774654296\n",
      "trial: 1, iter: 9400, curr loss: 0.40828490257263184, avg loss: 0.4145581842895518\n",
      "trial: 1, iter: 9500, curr loss: 0.4149401783943176, avg loss: 0.4144983616126211\n",
      "trial: 1, iter: 9600, curr loss: 0.40372294187545776, avg loss: 0.41443199910533923\n",
      "trial: 1, iter: 9700, curr loss: 0.41868990659713745, avg loss: 0.4143635172542838\n",
      "trial: 1, iter: 9800, curr loss: 0.40787792205810547, avg loss: 0.41430268747770055\n",
      "trial: 1, iter: 9900, curr loss: 0.3990008234977722, avg loss: 0.41423589267212935\n",
      "trial: 1, iter: 10000, curr loss: 0.40556544065475464, avg loss: 0.4141748335748911\n",
      "trial: 1, iter: 10100, curr loss: 0.404877632856369, avg loss: 0.41411519558122845\n",
      "trial: 1, iter: 10200, curr loss: 0.407877117395401, avg loss: 0.41404814059243483\n",
      "trial: 1, iter: 10300, curr loss: 0.40675532817840576, avg loss: 0.4139885764822219\n",
      "trial: 1, iter: 10400, curr loss: 0.3928556442260742, avg loss: 0.41393043239529315\n",
      "trial: 1, iter: 10500, curr loss: 0.4145105481147766, avg loss: 0.4138740200882866\n",
      "trial: 1, iter: 10600, curr loss: 0.4189743101596832, avg loss: 0.41381373901693325\n",
      "trial: 1, iter: 10700, curr loss: 0.40736085176467896, avg loss: 0.4137513985255054\n",
      "trial: 1, iter: 10800, curr loss: 0.412445604801178, avg loss: 0.41369977355555254\n",
      "trial: 1, iter: 10900, curr loss: 0.40002700686454773, avg loss: 0.413641142139741\n",
      "trial: 1, iter: 11000, curr loss: 0.39984309673309326, avg loss: 0.4135916786383499\n",
      "trial: 1, iter: 11100, curr loss: 0.41111117601394653, avg loss: 0.41354449013868966\n",
      "trial: 1, iter: 11200, curr loss: 0.4163837432861328, avg loss: 0.4134898938637759\n",
      "trial: 1, iter: 11300, curr loss: 0.409895122051239, avg loss: 0.4134512974308655\n",
      "trial: 1, iter: 11400, curr loss: 0.398826539516449, avg loss: 0.41340157012144724\n",
      "trial: 1, iter: 11500, curr loss: 0.4043964743614197, avg loss: 0.41335296832219415\n",
      "trial: 1, iter: 11600, curr loss: 0.4114210903644562, avg loss: 0.4133071433187559\n",
      "trial: 1, iter: 11700, curr loss: 0.42243653535842896, avg loss: 0.4132711523516565\n",
      "trial: 1, iter: 11800, curr loss: 0.4054870307445526, avg loss: 0.4132236863369659\n",
      "trial: 1, iter: 11900, curr loss: 0.4058026373386383, avg loss: 0.4131947440184465\n",
      "trial: 1, iter: 12000, curr loss: 0.4003981649875641, avg loss: 0.41314597059041264\n",
      "trial: 1, iter: 12100, curr loss: 0.401056170463562, avg loss: 0.41310342436733327\n",
      "trial: 1, iter: 12200, curr loss: 0.4021734595298767, avg loss: 0.41305185817548484\n",
      "trial: 1, iter: 12300, curr loss: 0.4105736017227173, avg loss: 0.41300972188633633\n",
      "trial: 1, iter: 12400, curr loss: 0.39799296855926514, avg loss: 0.41296748954682583\n",
      "trial: 1, iter: 12500, curr loss: 0.4084029793739319, avg loss: 0.412920522403717\n",
      "trial: 1, iter: 12600, curr loss: 0.41342151165008545, avg loss: 0.4128802750578948\n",
      "trial: 1, iter: 12700, curr loss: 0.40110844373703003, avg loss: 0.4128447492784402\n",
      "trial: 1, iter: 12800, curr loss: 0.40064314007759094, avg loss: 0.4128070801845752\n",
      "trial: 1, iter: 12900, curr loss: 0.4055708050727844, avg loss: 0.4127694590216459\n",
      "trial: 1, iter: 13000, curr loss: 0.41331303119659424, avg loss: 0.4127253699715321\n",
      "trial: 1, iter: 13100, curr loss: 0.40310561656951904, avg loss: 0.4126917166587051\n",
      "trial: 1, iter: 13200, curr loss: 0.41469353437423706, avg loss: 0.41266337936348985\n",
      "trial: 1, iter: 13300, curr loss: 0.3941572308540344, avg loss: 0.4126263271059309\n",
      "trial: 1, iter: 13400, curr loss: 0.40750372409820557, avg loss: 0.4125942965029781\n",
      "trial: 1, iter: 13500, curr loss: 0.42401838302612305, avg loss: 0.4125671194990476\n",
      "trial: 1, iter: 13600, curr loss: 0.41880667209625244, avg loss: 0.41253157311940897\n",
      "trial: 1, iter: 13700, curr loss: 0.4062234163284302, avg loss: 0.41250238314814813\n",
      "trial: 1, iter: 13800, curr loss: 0.40098798274993896, avg loss: 0.4124735355852307\n",
      "trial: 1, iter: 13900, curr loss: 0.408921480178833, avg loss: 0.41243699056210276\n",
      "trial: 1, iter: 14000, curr loss: 0.39835065603256226, avg loss: 0.41240708358372963\n",
      "trial: 1, iter: 14100, curr loss: 0.4097389578819275, avg loss: 0.4123710507851966\n",
      "trial: 1, iter: 14200, curr loss: 0.4007250964641571, avg loss: 0.4123434479870427\n",
      "trial: 1, iter: 14300, curr loss: 0.39777296781539917, avg loss: 0.41230393898237\n",
      "trial: 1, iter: 14400, curr loss: 0.42472726106643677, avg loss: 0.412273452969061\n",
      "trial: 1, iter: 14500, curr loss: 0.416195273399353, avg loss: 0.4122340571839234\n",
      "trial: 1, iter: 14600, curr loss: 0.4004248380661011, avg loss: 0.4122010795343412\n",
      "trial: 1, iter: 14700, curr loss: 0.4136441648006439, avg loss: 0.41217415286164705\n",
      "trial: 1, iter: 14800, curr loss: 0.4084463119506836, avg loss: 0.41213962481231303\n",
      "trial: 1, iter: 14900, curr loss: 0.4039166569709778, avg loss: 0.41211800396842446\n",
      "trial: 1, iter: 15000, curr loss: 0.4196331202983856, avg loss: 0.41208702252109847\n",
      "trial: 1, iter: 15100, curr loss: 0.40806519985198975, avg loss: 0.4120607230560669\n",
      "trial: 1, iter: 15200, curr loss: 0.40734338760375977, avg loss: 0.4120301269386944\n",
      "trial: 1, iter: 15300, curr loss: 0.4073494076728821, avg loss: 0.4120060042501275\n",
      "trial: 1, iter: 15400, curr loss: 0.40900886058807373, avg loss: 0.4119774467120697\n",
      "trial: 1, iter: 15500, curr loss: 0.4064647853374481, avg loss: 0.4119570874648709\n",
      "trial: 1, iter: 15600, curr loss: 0.40478086471557617, avg loss: 0.41194031851796004\n",
      "trial: 1, iter: 15700, curr loss: 0.40994149446487427, avg loss: 0.4119111195073766\n",
      "trial: 1, iter: 15800, curr loss: 0.39953166246414185, avg loss: 0.41188308238983157\n",
      "trial: 1, iter: 15900, curr loss: 0.39628803730010986, avg loss: 0.411853869278101\n",
      "trial: 1, iter: 16000, curr loss: 0.41345542669296265, avg loss: 0.4118249476607889\n",
      "trial: 1, iter: 16100, curr loss: 0.41715043783187866, avg loss: 0.41180733733295655\n",
      "trial: 1, iter: 16200, curr loss: 0.4099150002002716, avg loss: 0.41178179209798943\n",
      "trial: 1, iter: 16300, curr loss: 0.4105035960674286, avg loss: 0.4117586193768525\n",
      "trial: 1, iter: 16400, curr loss: 0.41672253608703613, avg loss: 0.4117265069375678\n",
      "trial: 1, iter: 16500, curr loss: 0.40299659967422485, avg loss: 0.4116941204052983\n",
      "trial: 1, iter: 16600, curr loss: 0.4034755825996399, avg loss: 0.41166794998997663\n",
      "trial: 1, iter: 16700, curr loss: 0.4121210277080536, avg loss: 0.41164457266737603\n",
      "trial: 1, iter: 16800, curr loss: 0.41049158573150635, avg loss: 0.411615637618871\n",
      "trial: 1, iter: 16900, curr loss: 0.41158607602119446, avg loss: 0.41159681745711163\n",
      "trial: 1, iter: 17000, curr loss: 0.412666916847229, avg loss: 0.4115697538098868\n",
      "trial: 1, iter: 17100, curr loss: 0.4106476902961731, avg loss: 0.4115514894047676\n",
      "trial: 1, iter: 17200, curr loss: 0.40271925926208496, avg loss: 0.4115211869724268\n",
      "trial: 1, iter: 17300, curr loss: 0.40674716234207153, avg loss: 0.41149450123482356\n",
      "trial: 1, iter: 17400, curr loss: 0.417100191116333, avg loss: 0.41147637666470704\n",
      "trial: 1, iter: 17500, curr loss: 0.41093572974205017, avg loss: 0.4114596680538995\n",
      "trial: 1, iter: 17600, curr loss: 0.40602150559425354, avg loss: 0.411437587807463\n",
      "trial: 1, iter: 17700, curr loss: 0.3958841562271118, avg loss: 0.411412503359008\n",
      "trial: 1, iter: 17800, curr loss: 0.3952474594116211, avg loss: 0.41139181659965035\n",
      "trial: 1, iter: 17900, curr loss: 0.4031163454055786, avg loss: 0.4113761204963956\n",
      "trial: 1, iter: 18000, curr loss: 0.4152826964855194, avg loss: 0.4113584386623568\n",
      "trial: 1, iter: 18100, curr loss: 0.41184115409851074, avg loss: 0.41134031426017453\n",
      "trial: 1, iter: 18200, curr loss: 0.4190398156642914, avg loss: 0.41132425358825986\n",
      "trial: 1, iter: 18300, curr loss: 0.4050248861312866, avg loss: 0.4113028648251393\n",
      "trial: 1, iter: 18400, curr loss: 0.39986246824264526, avg loss: 0.411288002036188\n",
      "trial: 1, iter: 18500, curr loss: 0.39867353439331055, avg loss: 0.4112687607455898\n",
      "trial: 1, iter: 18600, curr loss: 0.42090344429016113, avg loss: 0.41125873160298154\n",
      "trial: 1, iter: 18700, curr loss: 0.40652135014533997, avg loss: 0.41124169015788775\n",
      "trial: 1, iter: 18800, curr loss: 0.3988396227359772, avg loss: 0.41122833967525907\n",
      "trial: 1, iter: 18900, curr loss: 0.4135271906852722, avg loss: 0.41121278930751104\n",
      "trial: 1, iter: 19000, curr loss: 0.40787142515182495, avg loss: 0.4111972694334231\n",
      "trial: 1, iter: 19100, curr loss: 0.40448299050331116, avg loss: 0.4111712417412179\n",
      "trial: 1, iter: 19200, curr loss: 0.4098549783229828, avg loss: 0.41115234886916974\n",
      "trial: 1, iter: 19300, curr loss: 0.39240264892578125, avg loss: 0.411135216329073\n",
      "trial: 1, iter: 19400, curr loss: 0.4018559455871582, avg loss: 0.4111137794050359\n",
      "trial: 1, iter: 19500, curr loss: 0.4006505012512207, avg loss: 0.41109896445885685\n",
      "trial: 1, iter: 19600, curr loss: 0.41841089725494385, avg loss: 0.4110816190817526\n",
      "trial: 1, iter: 19700, curr loss: 0.4100744128227234, avg loss: 0.4110621416871318\n",
      "trial: 1, iter: 19800, curr loss: 0.4091498851776123, avg loss: 0.4110437597093558\n",
      "trial: 1, iter: 19900, curr loss: 0.40449726581573486, avg loss: 0.4110261535824244\n",
      "trial: 1, iter: 20000, curr loss: 0.4103427827358246, avg loss: 0.41101080875843765\n",
      "trial: 1, iter: 20100, curr loss: 0.4225200414657593, avg loss: 0.41099168822095167\n",
      "trial: 1, iter: 20200, curr loss: 0.4046165943145752, avg loss: 0.4109736381854751\n",
      "trial: 1, iter: 20300, curr loss: 0.40611982345581055, avg loss: 0.4109557077538204\n",
      "trial: 1, iter: 20400, curr loss: 0.4094665050506592, avg loss: 0.41094071849450176\n",
      "trial: 1, iter: 20500, curr loss: 0.420828640460968, avg loss: 0.4109228090905562\n",
      "trial: 1, iter: 20600, curr loss: 0.41018903255462646, avg loss: 0.4109100024011529\n",
      "trial: 1, iter: 20700, curr loss: 0.40904533863067627, avg loss: 0.4108924632803829\n",
      "trial: 1, iter: 20800, curr loss: 0.4035502076148987, avg loss: 0.41087310200413835\n",
      "trial: 1, iter: 20900, curr loss: 0.4119691252708435, avg loss: 0.41085570967511126\n",
      "trial: 1, iter: 21000, curr loss: 0.4176141023635864, avg loss: 0.41084660465376716\n",
      "trial: 1, iter: 21100, curr loss: 0.41473254561424255, avg loss: 0.41082243279399466\n",
      "trial: 1, iter: 21200, curr loss: 0.411298930644989, avg loss: 0.4108087470494914\n",
      "trial: 1, iter: 21300, curr loss: 0.4055916368961334, avg loss: 0.4107896377572991\n",
      "trial: 1, iter: 21400, curr loss: 0.4139086604118347, avg loss: 0.4107693219505181\n",
      "trial: 1, iter: 21500, curr loss: 0.40841567516326904, avg loss: 0.4107515557768733\n",
      "trial: 1, iter: 21600, curr loss: 0.41006797552108765, avg loss: 0.41073819701180414\n",
      "trial: 1, iter: 21700, curr loss: 0.41093719005584717, avg loss: 0.41072176539815514\n",
      "trial: 1, iter: 21800, curr loss: 0.4101371169090271, avg loss: 0.4107077478678948\n",
      "trial: 1, iter: 21900, curr loss: 0.41331344842910767, avg loss: 0.4106915220958457\n",
      "trial: 1, iter: 22000, curr loss: 0.40935757756233215, avg loss: 0.4106783169196411\n",
      "trial: 1, iter: 22100, curr loss: 0.40713316202163696, avg loss: 0.41066236321742716\n",
      "trial: 1, iter: 22200, curr loss: 0.40729811787605286, avg loss: 0.4106461373240024\n",
      "trial: 1, iter: 22300, curr loss: 0.40398719906806946, avg loss: 0.410631952671994\n",
      "trial: 1, iter: 22400, curr loss: 0.403847336769104, avg loss: 0.41061685663914044\n",
      "trial: 1, iter: 22500, curr loss: 0.40967923402786255, avg loss: 0.41059788602325653\n",
      "trial: 1, iter: 22600, curr loss: 0.403028666973114, avg loss: 0.41058233538955713\n",
      "trial: 1, iter: 22700, curr loss: 0.40969178080558777, avg loss: 0.4105657084200876\n",
      "trial: 1, iter: 22800, curr loss: 0.39763325452804565, avg loss: 0.41055187910533786\n",
      "trial: 1, iter: 22900, curr loss: 0.40762418508529663, avg loss: 0.4105382084755398\n",
      "trial: 1, iter: 23000, curr loss: 0.41242334246635437, avg loss: 0.41052684407000956\n",
      "trial: 1, iter: 23100, curr loss: 0.4104892909526825, avg loss: 0.4105134748896479\n",
      "trial: 1, iter: 23200, curr loss: 0.41614729166030884, avg loss: 0.4104988065785889\n",
      "trial: 1, iter: 23300, curr loss: 0.4099601209163666, avg loss: 0.4104837351692081\n",
      "trial: 1, iter: 23400, curr loss: 0.4090248942375183, avg loss: 0.4104776559808315\n",
      "trial: 1, iter: 23500, curr loss: 0.40138351917266846, avg loss: 0.41045941929994745\n",
      "trial: 1, iter: 23600, curr loss: 0.40831539034843445, avg loss: 0.41044609070960747\n",
      "trial: 1, iter: 23700, curr loss: 0.40490081906318665, avg loss: 0.4104275203757145\n",
      "trial: 1, iter: 23800, curr loss: 0.40807968378067017, avg loss: 0.41042180422850016\n",
      "trial: 1, iter: 23900, curr loss: 0.40324777364730835, avg loss: 0.4104119187930139\n",
      "trial: 1, iter: 24000, curr loss: 0.40425246953964233, avg loss: 0.4103976145486037\n",
      "trial: 1, iter: 24100, curr loss: 0.41505464911460876, avg loss: 0.4103829962250108\n",
      "trial: 1, iter: 24200, curr loss: 0.4287410080432892, avg loss: 0.4103709404096623\n",
      "trial: 1, iter: 24300, curr loss: 0.4110835790634155, avg loss: 0.41035811194421823\n",
      "trial: 1, iter: 24400, curr loss: 0.40407228469848633, avg loss: 0.4103477258772635\n",
      "trial: 1, iter: 24500, curr loss: 0.4168251156806946, avg loss: 0.4103335089890324\n",
      "trial: 1, iter: 24600, curr loss: 0.39631181955337524, avg loss: 0.4103219209260088\n",
      "trial: 1, iter: 24700, curr loss: 0.3953239917755127, avg loss: 0.41031337937242107\n",
      "trial: 1, iter: 24800, curr loss: 0.40866297483444214, avg loss: 0.41030447666082653\n",
      "trial: 1, iter: 24900, curr loss: 0.4022091031074524, avg loss: 0.4102903924984147\n",
      "trial: 1, iter: 25000, curr loss: 0.40031078457832336, avg loss: 0.41027897343993186\n",
      "trial: 1, iter: 25100, curr loss: 0.4104852080345154, avg loss: 0.41027019327499004\n",
      "trial: 1, iter: 25200, curr loss: 0.4062215983867645, avg loss: 0.41026388158400856\n",
      "trial: 1, iter: 25300, curr loss: 0.4042127728462219, avg loss: 0.41025274098155057\n",
      "trial: 1, iter: 25400, curr loss: 0.40489912033081055, avg loss: 0.4102372583171983\n",
      "trial: 1, iter: 25500, curr loss: 0.39555615186691284, avg loss: 0.4102256418069204\n",
      "trial: 1, iter: 25600, curr loss: 0.39896583557128906, avg loss: 0.41021355316974223\n",
      "trial: 1, iter: 25700, curr loss: 0.4046824276447296, avg loss: 0.4102024116938216\n",
      "trial: 1, iter: 25800, curr loss: 0.39887332916259766, avg loss: 0.410192744067704\n",
      "trial: 1, iter: 25900, curr loss: 0.4139745831489563, avg loss: 0.4101796614709508\n",
      "trial: 1, iter: 26000, curr loss: 0.4023618698120117, avg loss: 0.4101693429488402\n",
      "trial: 1, iter: 26100, curr loss: 0.4115111827850342, avg loss: 0.41016362951176377\n",
      "trial: 1, iter: 26200, curr loss: 0.3959096670150757, avg loss: 0.4101505438573943\n",
      "trial: 1, iter: 26300, curr loss: 0.40978318452835083, avg loss: 0.4101417176147831\n",
      "trial: 1, iter: 26400, curr loss: 0.4115545451641083, avg loss: 0.4101308952226783\n",
      "trial: 1, iter: 26500, curr loss: 0.39749303460121155, avg loss: 0.4101206290080862\n",
      "trial: 1, iter: 26600, curr loss: 0.4026503562927246, avg loss: 0.4101072665141489\n",
      "trial: 1, iter: 26700, curr loss: 0.4028474688529968, avg loss: 0.41009562401959065\n",
      "trial: 1, iter: 26800, curr loss: 0.4021981954574585, avg loss: 0.4100831566662041\n",
      "trial: 1, iter: 26900, curr loss: 0.41641148924827576, avg loss: 0.4100735990331962\n",
      "trial: 1, iter: 27000, curr loss: 0.4030084013938904, avg loss: 0.41006290284461444\n",
      "trial: 1, iter: 27100, curr loss: 0.4072876572608948, avg loss: 0.41004920287545754\n",
      "trial: 1, iter: 27200, curr loss: 0.41297927498817444, avg loss: 0.41004163011251127\n",
      "trial: 1, iter: 27300, curr loss: 0.39853131771087646, avg loss: 0.4100340823081387\n",
      "trial: 1, iter: 27400, curr loss: 0.40376609563827515, avg loss: 0.4100245827218912\n",
      "trial: 1, iter: 27500, curr loss: 0.41476738452911377, avg loss: 0.41001217766458337\n",
      "trial: 1, iter: 27600, curr loss: 0.41623055934906006, avg loss: 0.4100021823636\n",
      "trial: 1, iter: 27700, curr loss: 0.41563671827316284, avg loss: 0.40999496100826816\n",
      "trial: 1, iter: 27800, curr loss: 0.4006984829902649, avg loss: 0.40998752170436675\n",
      "trial: 1, iter: 27900, curr loss: 0.40301454067230225, avg loss: 0.40997895821021024\n",
      "trial: 1, iter: 28000, curr loss: 0.3947373032569885, avg loss: 0.4099680634790233\n",
      "trial: 1, iter: 28100, curr loss: 0.4049762487411499, avg loss: 0.4099601316706566\n",
      "trial: 1, iter: 28200, curr loss: 0.40978533029556274, avg loss: 0.40994868544822044\n",
      "trial: 1, iter: 28300, curr loss: 0.3959246873855591, avg loss: 0.40993789954130727\n",
      "trial: 1, iter: 28400, curr loss: 0.396776020526886, avg loss: 0.40992938861250877\n",
      "trial: 1, iter: 28500, curr loss: 0.4003010094165802, avg loss: 0.4099202671197423\n",
      "trial: 1, iter: 28600, curr loss: 0.39739683270454407, avg loss: 0.4099108886218571\n",
      "trial: 1, iter: 28700, curr loss: 0.39916402101516724, avg loss: 0.40989976699343955\n",
      "trial: 1, iter: 28800, curr loss: 0.40028834342956543, avg loss: 0.4098885796684772\n",
      "trial: 1, iter: 28900, curr loss: 0.40093541145324707, avg loss: 0.40987821291474735\n",
      "trial: 1, iter: 29000, curr loss: 0.3987652659416199, avg loss: 0.40987180376155624\n",
      "trial: 1, iter: 29100, curr loss: 0.4008350372314453, avg loss: 0.40985977291958436\n",
      "trial: 1, iter: 29200, curr loss: 0.40553173422813416, avg loss: 0.4098517885385719\n",
      "trial: 1, iter: 29300, curr loss: 0.4049106240272522, avg loss: 0.4098382335504574\n",
      "trial: 1, iter: 29400, curr loss: 0.4148571491241455, avg loss: 0.40983352637412596\n",
      "trial: 1, iter: 29500, curr loss: 0.4032214283943176, avg loss: 0.40982211899959436\n",
      "trial: 1, iter: 29600, curr loss: 0.41717323660850525, avg loss: 0.4098127899651189\n",
      "trial: 1, iter: 29700, curr loss: 0.4097902476787567, avg loss: 0.4098045967775162\n",
      "trial: 1, iter: 29800, curr loss: 0.3994673788547516, avg loss: 0.40979567977806064\n",
      "trial: 1, iter: 29900, curr loss: 0.417317271232605, avg loss: 0.40978919709605915\n",
      "trial: 1, iter: 30000, curr loss: 0.4077589213848114, avg loss: 0.4097815968622764\n",
      "trial: 1, iter: 30100, curr loss: 0.4003121256828308, avg loss: 0.4097741613326675\n",
      "trial: 1, iter: 30200, curr loss: 0.40729349851608276, avg loss: 0.4097668965604921\n",
      "trial: 1, iter: 30300, curr loss: 0.42240825295448303, avg loss: 0.4097587647847217\n",
      "trial: 1, iter: 30400, curr loss: 0.398188054561615, avg loss: 0.40975388704455995\n",
      "trial: 1, iter: 30500, curr loss: 0.4027061462402344, avg loss: 0.409748011009615\n",
      "trial: 1, iter: 30600, curr loss: 0.41095834970474243, avg loss: 0.4097392927528986\n",
      "trial: 1, iter: 30700, curr loss: 0.3993963599205017, avg loss: 0.409730245606907\n",
      "trial: 1, iter: 30800, curr loss: 0.40027251839637756, avg loss: 0.40972198387535363\n",
      "trial: 1, iter: 30900, curr loss: 0.40553736686706543, avg loss: 0.40971200873261515\n",
      "trial: 1, iter: 31000, curr loss: 0.40596136450767517, avg loss: 0.4097056393238806\n",
      "trial: 1, iter: 31100, curr loss: 0.39774397015571594, avg loss: 0.4096997395454879\n",
      "trial: 1, iter: 31200, curr loss: 0.40106838941574097, avg loss: 0.4096928478213839\n",
      "trial: 1, iter: 31300, curr loss: 0.3991827070713043, avg loss: 0.40968315391875687\n",
      "trial: 1, iter: 31400, curr loss: 0.40476176142692566, avg loss: 0.40967334943971817\n",
      "trial: 1, iter: 31500, curr loss: 0.41031473875045776, avg loss: 0.40966527301640737\n",
      "trial: 1, iter: 31600, curr loss: 0.4008466899394989, avg loss: 0.4096571793275166\n",
      "trial: 1, iter: 31700, curr loss: 0.3882560133934021, avg loss: 0.40964936162113014\n",
      "trial: 1, iter: 31800, curr loss: 0.41116511821746826, avg loss: 0.409636354263661\n",
      "trial: 1, iter: 31900, curr loss: 0.4044843316078186, avg loss: 0.40962436862406687\n",
      "trial: 1, iter: 32000, curr loss: 0.4173629879951477, avg loss: 0.4096166244857013\n",
      "trial: 1, iter: 32100, curr loss: 0.3895241320133209, avg loss: 0.4096096055279268\n",
      "trial: 1, iter: 32200, curr loss: 0.4017573595046997, avg loss: 0.40959826036177066\n",
      "trial: 1, iter: 32300, curr loss: 0.402654767036438, avg loss: 0.4095886458451903\n",
      "trial: 1, iter: 32400, curr loss: 0.40316304564476013, avg loss: 0.4095836939331558\n",
      "trial: 1, iter: 32500, curr loss: 0.4047708213329315, avg loss: 0.4095790701279273\n",
      "trial: 1, iter: 32600, curr loss: 0.41071218252182007, avg loss: 0.4095742979983976\n",
      "trial: 1, iter: 32700, curr loss: 0.4127342700958252, avg loss: 0.4095704942121418\n",
      "trial: 1, iter: 32800, curr loss: 0.4217991828918457, avg loss: 0.40956590971387014\n",
      "trial: 1, iter: 32900, curr loss: 0.41726356744766235, avg loss: 0.40956101242985044\n",
      "trial: 1, iter: 33000, curr loss: 0.39399462938308716, avg loss: 0.4095549911567659\n",
      "trial: 1, iter: 33100, curr loss: 0.4110734462738037, avg loss: 0.40955106857680124\n",
      "trial: 1, iter: 33200, curr loss: 0.42222315073013306, avg loss: 0.40954564756478173\n",
      "trial: 1, iter: 33300, curr loss: 0.41395848989486694, avg loss: 0.4095393036596768\n",
      "trial: 1, iter: 33400, curr loss: 0.3976662755012512, avg loss: 0.40953210360008085\n",
      "trial: 1, iter: 33500, curr loss: 0.3987813889980316, avg loss: 0.4095216534440197\n",
      "trial: 1, iter: 33600, curr loss: 0.41952264308929443, avg loss: 0.4095150792545506\n",
      "trial: 1, iter: 33700, curr loss: 0.40655282139778137, avg loss: 0.40950498629217685\n",
      "trial: 1, iter: 33800, curr loss: 0.400454044342041, avg loss: 0.409497899325818\n",
      "trial: 1, iter: 33900, curr loss: 0.4142177104949951, avg loss: 0.40948856308221115\n",
      "trial: 1, iter: 34000, curr loss: 0.40133994817733765, avg loss: 0.40948240189955515\n",
      "trial: 1, iter: 34100, curr loss: 0.4056239128112793, avg loss: 0.4094738882762596\n",
      "trial: 1, iter: 34200, curr loss: 0.413463830947876, avg loss: 0.40946973580888835\n",
      "trial: 1, iter: 34300, curr loss: 0.40137919783592224, avg loss: 0.40946198602720185\n",
      "trial: 1, iter: 34400, curr loss: 0.4009935259819031, avg loss: 0.4094551301106464\n",
      "trial: 1, iter: 34500, curr loss: 0.41331490874290466, avg loss: 0.4094495320510173\n",
      "trial: 1, iter: 34600, curr loss: 0.41618162393569946, avg loss: 0.40944395381677356\n",
      "trial: 1, iter: 34700, curr loss: 0.4051916003227234, avg loss: 0.4094393623811367\n",
      "trial: 1, iter: 34800, curr loss: 0.40019315481185913, avg loss: 0.409430441516398\n",
      "trial: 1, iter: 34900, curr loss: 0.4203864634037018, avg loss: 0.4094215986610825\n",
      "trial: 1, iter: 35000, curr loss: 0.4097747206687927, avg loss: 0.40941459859779905\n",
      "trial: 1, iter: 35100, curr loss: 0.4038023352622986, avg loss: 0.40940384614501585\n",
      "trial: 1, iter: 35200, curr loss: 0.40143412351608276, avg loss: 0.4093959638078443\n",
      "trial: 1, iter: 35300, curr loss: 0.3972723186016083, avg loss: 0.40938704929676\n",
      "trial: 1, iter: 35400, curr loss: 0.403653085231781, avg loss: 0.40938091308467806\n",
      "trial: 1, iter: 35500, curr loss: 0.4024633765220642, avg loss: 0.4093734498443738\n",
      "trial: 1, iter: 35600, curr loss: 0.4074257016181946, avg loss: 0.4093661200949985\n",
      "trial: 1, iter: 35700, curr loss: 0.4100149869918823, avg loss: 0.4093597703470903\n",
      "trial: 1, iter: 35800, curr loss: 0.40192967653274536, avg loss: 0.40935615739093145\n",
      "trial: 1, iter: 35900, curr loss: 0.4138341546058655, avg loss: 0.40934905763622115\n",
      "trial: 1, iter: 36000, curr loss: 0.40321579575538635, avg loss: 0.40934200299614004\n",
      "trial: 1, iter: 36100, curr loss: 0.3927704691886902, avg loss: 0.40933751762408627\n",
      "trial: 1, iter: 36200, curr loss: 0.4008287191390991, avg loss: 0.40932901811122235\n",
      "trial: 1, iter: 36300, curr loss: 0.3971341550350189, avg loss: 0.4093236579333455\n",
      "trial: 1, iter: 36400, curr loss: 0.39972394704818726, avg loss: 0.4093198223559411\n",
      "trial: 1, iter: 36500, curr loss: 0.4034285247325897, avg loss: 0.4093114700603159\n",
      "trial: 1, iter: 36600, curr loss: 0.39614948630332947, avg loss: 0.4093060504176903\n",
      "trial: 1, iter: 36700, curr loss: 0.41409480571746826, avg loss: 0.40929801165083124\n",
      "trial: 1, iter: 36800, curr loss: 0.4067203104496002, avg loss: 0.4092924094175839\n",
      "trial: 1, iter: 36900, curr loss: 0.4193117022514343, avg loss: 0.4092850043860877\n",
      "trial: 1, iter: 37000, curr loss: 0.4216765761375427, avg loss: 0.4092774468201238\n",
      "trial: 1, iter: 37100, curr loss: 0.4027065634727478, avg loss: 0.4092704149928054\n",
      "trial: 1, iter: 37200, curr loss: 0.4069906175136566, avg loss: 0.40926427169993357\n",
      "trial: 1, iter: 37300, curr loss: 0.40158289670944214, avg loss: 0.4092576218945731\n",
      "trial: 1, iter: 37400, curr loss: 0.40261515974998474, avg loss: 0.409255456643946\n",
      "trial: 1, iter: 37500, curr loss: 0.4148637056350708, avg loss: 0.4092476993083954\n",
      "trial: 1, iter: 37600, curr loss: 0.40403735637664795, avg loss: 0.40924461146380675\n",
      "trial: 1, iter: 37700, curr loss: 0.4169504642486572, avg loss: 0.4092402615597773\n",
      "trial: 1, iter: 37800, curr loss: 0.4037405252456665, avg loss: 0.40923590094718354\n",
      "trial: 1, iter: 37900, curr loss: 0.4087672233581543, avg loss: 0.4092280799732359\n",
      "trial: 1, iter: 38000, curr loss: 0.3960784375667572, avg loss: 0.4092226748905684\n",
      "trial: 1, iter: 38100, curr loss: 0.40708136558532715, avg loss: 0.40921811061894175\n",
      "trial: 1, iter: 38200, curr loss: 0.40625718235969543, avg loss: 0.409212835421737\n",
      "trial: 1, iter: 38300, curr loss: 0.40549546480178833, avg loss: 0.4092102516016512\n",
      "trial: 1, iter: 38400, curr loss: 0.41379737854003906, avg loss: 0.40920669259193043\n",
      "trial: 1, iter: 38500, curr loss: 0.401228666305542, avg loss: 0.4092032324749154\n",
      "trial: 1, iter: 38600, curr loss: 0.41413432359695435, avg loss: 0.40920024335615995\n",
      "trial: 1, iter: 38700, curr loss: 0.40597161650657654, avg loss: 0.40919288645265023\n",
      "trial: 1, iter: 38800, curr loss: 0.40350815653800964, avg loss: 0.40918508724760766\n",
      "trial: 1, iter: 38900, curr loss: 0.4176824688911438, avg loss: 0.4091835801797538\n",
      "trial: 1, iter: 39000, curr loss: 0.39710375666618347, avg loss: 0.4091803418245071\n",
      "trial: 1, iter: 39100, curr loss: 0.41108742356300354, avg loss: 0.40917537775719565\n",
      "trial: 1, iter: 39200, curr loss: 0.39972057938575745, avg loss: 0.40917025962578396\n",
      "trial: 1, iter: 39300, curr loss: 0.40144485235214233, avg loss: 0.40916680377251624\n",
      "trial: 1, iter: 39400, curr loss: 0.40808039903640747, avg loss: 0.4091609210577713\n",
      "trial: 1, iter: 39500, curr loss: 0.4003790318965912, avg loss: 0.409151446150828\n",
      "trial: 1, iter: 39600, curr loss: 0.40802380442619324, avg loss: 0.4091447647081481\n",
      "trial: 1, iter: 39700, curr loss: 0.40505895018577576, avg loss: 0.4091392495605147\n",
      "trial: 1, iter: 39800, curr loss: 0.41215795278549194, avg loss: 0.40913488196443076\n",
      "trial: 1, iter: 39900, curr loss: 0.4148184061050415, avg loss: 0.40912982207865345\n",
      "trial: 1, iter: 40000, curr loss: 0.4068598449230194, avg loss: 0.40912721560522913\n",
      "trial: 1, iter: 40100, curr loss: 0.4086778461933136, avg loss: 0.40912173328925844\n",
      "trial: 1, iter: 40200, curr loss: 0.39965057373046875, avg loss: 0.4091155582421751\n",
      "trial: 1, iter: 40300, curr loss: 0.40096038579940796, avg loss: 0.40911009342513666\n",
      "trial: 1, iter: 40400, curr loss: 0.39544904232025146, avg loss: 0.4091062924789615\n",
      "trial: 1, iter: 40500, curr loss: 0.4145745635032654, avg loss: 0.4091021831455054\n",
      "trial: 1, iter: 40600, curr loss: 0.4019550085067749, avg loss: 0.4090943593535517\n",
      "trial: 1, iter: 40700, curr loss: 0.4170107841491699, avg loss: 0.409093311045328\n",
      "trial: 1, iter: 40800, curr loss: 0.4170672595500946, avg loss: 0.40908888592658676\n",
      "trial: 1, iter: 40900, curr loss: 0.41469281911849976, avg loss: 0.4090853062468811\n",
      "trial: 1, iter: 41000, curr loss: 0.40787404775619507, avg loss: 0.40908191581906345\n",
      "trial: 1, iter: 41100, curr loss: 0.41736745834350586, avg loss: 0.4090774527235623\n",
      "trial: 1, iter: 41200, curr loss: 0.40399056673049927, avg loss: 0.4090706178864229\n",
      "trial: 1, iter: 41300, curr loss: 0.4142169952392578, avg loss: 0.4090672246408232\n",
      "trial: 1, iter: 41400, curr loss: 0.4034344553947449, avg loss: 0.4090616838324473\n",
      "trial: 1, iter: 41500, curr loss: 0.3960154950618744, avg loss: 0.4090565169460802\n",
      "trial: 1, iter: 41600, curr loss: 0.41471368074417114, avg loss: 0.4090505920565472\n",
      "trial: 1, iter: 41700, curr loss: 0.402748167514801, avg loss: 0.40904566595094094\n",
      "trial: 1, iter: 41800, curr loss: 0.41652804613113403, avg loss: 0.40904326544994374\n",
      "trial: 1, iter: 41900, curr loss: 0.4063330292701721, avg loss: 0.40903820351086256\n",
      "trial: 1, iter: 42000, curr loss: 0.40483176708221436, avg loss: 0.4090338446462438\n",
      "trial: 1, iter: 42100, curr loss: 0.41205036640167236, avg loss: 0.40903223711634473\n",
      "trial: 1, iter: 42200, curr loss: 0.397116482257843, avg loss: 0.40902660888165093\n",
      "trial: 1, iter: 42300, curr loss: 0.4078676402568817, avg loss: 0.40902396743320124\n",
      "trial: 1, iter: 42400, curr loss: 0.4040488004684448, avg loss: 0.40902074151936\n",
      "trial: 1, iter: 42500, curr loss: 0.4056246280670166, avg loss: 0.40901501945607804\n",
      "trial: 1, iter: 42600, curr loss: 0.4026731550693512, avg loss: 0.4090082604049797\n",
      "trial: 1, iter: 42700, curr loss: 0.4062931537628174, avg loss: 0.40900468732489914\n",
      "trial: 1, iter: 42800, curr loss: 0.412121057510376, avg loss: 0.4090016947686672\n",
      "trial: 1, iter: 42900, curr loss: 0.41519588232040405, avg loss: 0.40899492374944796\n",
      "trial: 1, iter: 43000, curr loss: 0.4037112593650818, avg loss: 0.4089884911096373\n",
      "trial: 1, iter: 43100, curr loss: 0.4155600070953369, avg loss: 0.4089836138721962\n",
      "trial: 1, iter: 43200, curr loss: 0.4055975675582886, avg loss: 0.408978004352776\n",
      "trial: 1, iter: 43300, curr loss: 0.3942868411540985, avg loss: 0.40897307179472464\n",
      "trial: 1, iter: 43400, curr loss: 0.41149741411209106, avg loss: 0.4089660002696349\n",
      "trial: 1, iter: 43500, curr loss: 0.4170653223991394, avg loss: 0.40896509963548044\n",
      "trial: 1, iter: 43600, curr loss: 0.4232144355773926, avg loss: 0.40896198154794516\n",
      "trial: 1, iter: 43700, curr loss: 0.4034232497215271, avg loss: 0.40895771646390516\n",
      "trial: 1, iter: 43800, curr loss: 0.40524160861968994, avg loss: 0.40895252797633547\n",
      "trial: 1, iter: 43900, curr loss: 0.4169674813747406, avg loss: 0.4089490407834292\n",
      "trial: 1, iter: 44000, curr loss: 0.41149863600730896, avg loss: 0.4089442855661566\n",
      "trial: 1, iter: 44100, curr loss: 0.4116992950439453, avg loss: 0.4089420220451831\n",
      "trial: 1, iter: 44200, curr loss: 0.42241019010543823, avg loss: 0.4089372770730996\n",
      "trial: 1, iter: 44300, curr loss: 0.41335630416870117, avg loss: 0.4089335021726434\n",
      "trial: 1, iter: 44400, curr loss: 0.4080219268798828, avg loss: 0.40892935093257343\n",
      "trial: 1, iter: 44500, curr loss: 0.4072657823562622, avg loss: 0.408923362571202\n",
      "trial: 1, iter: 44600, curr loss: 0.41415727138519287, avg loss: 0.40891945604919855\n",
      "trial: 1, iter: 44700, curr loss: 0.40755271911621094, avg loss: 0.4089157357291887\n",
      "trial: 1, iter: 44800, curr loss: 0.39767688512802124, avg loss: 0.40891015405700143\n",
      "trial: 1, iter: 44900, curr loss: 0.41007208824157715, avg loss: 0.40890547278729206\n",
      "trial: 1, iter: 45000, curr loss: 0.4137413203716278, avg loss: 0.4088983161403073\n",
      "trial: 1, iter: 45100, curr loss: 0.40459632873535156, avg loss: 0.4088945654067655\n",
      "trial: 1, iter: 45200, curr loss: 0.41429704427719116, avg loss: 0.40889106157738553\n",
      "trial: 1, iter: 45300, curr loss: 0.4071349501609802, avg loss: 0.40888552662223643\n",
      "trial: 1, iter: 45400, curr loss: 0.40995484590530396, avg loss: 0.4088800244440329\n",
      "trial: 1, iter: 45500, curr loss: 0.4127234220504761, avg loss: 0.40887591858355554\n",
      "trial: 1, iter: 45600, curr loss: 0.4070899486541748, avg loss: 0.4088695281913929\n",
      "trial: 1, iter: 45700, curr loss: 0.40717601776123047, avg loss: 0.4088632675901023\n",
      "trial: 1, iter: 45800, curr loss: 0.40040123462677, avg loss: 0.40885952455377994\n",
      "trial: 1, iter: 45900, curr loss: 0.40709421038627625, avg loss: 0.4088589872741232\n",
      "trial: 1, iter: 46000, curr loss: 0.4026269316673279, avg loss: 0.4088539055696\n",
      "trial: 1, iter: 46100, curr loss: 0.400138795375824, avg loss: 0.4088516829510314\n",
      "trial: 1, iter: 46200, curr loss: 0.41036099195480347, avg loss: 0.40884827789483646\n",
      "trial: 1, iter: 46300, curr loss: 0.4034174680709839, avg loss: 0.4088464665940719\n",
      "trial: 1, iter: 46400, curr loss: 0.38920775055885315, avg loss: 0.4088428806031829\n",
      "trial: 1, iter: 46500, curr loss: 0.4147558808326721, avg loss: 0.40883450407046146\n",
      "trial: 1, iter: 46600, curr loss: 0.4181627631187439, avg loss: 0.40882817581807596\n",
      "trial: 1, iter: 46700, curr loss: 0.4078826308250427, avg loss: 0.4088265391367406\n",
      "trial: 1, iter: 46800, curr loss: 0.39911627769470215, avg loss: 0.40882502683844324\n",
      "trial: 1, iter: 46900, curr loss: 0.40566959977149963, avg loss: 0.40882168049941947\n",
      "trial: 1, iter: 47000, curr loss: 0.4045482575893402, avg loss: 0.4088169135521067\n",
      "trial: 1, iter: 47100, curr loss: 0.40272465348243713, avg loss: 0.40881416190518444\n",
      "trial: 1, iter: 47200, curr loss: 0.40483558177948, avg loss: 0.40880747095002967\n",
      "trial: 1, iter: 47300, curr loss: 0.420532763004303, avg loss: 0.4088022073479586\n",
      "trial: 1, iter: 47400, curr loss: 0.4001559913158417, avg loss: 0.40879882526234235\n",
      "trial: 1, iter: 47500, curr loss: 0.4037564694881439, avg loss: 0.4087938658049232\n",
      "trial: 1, iter: 47600, curr loss: 0.3992278575897217, avg loss: 0.4087908953797667\n",
      "trial: 1, iter: 47700, curr loss: 0.4041453003883362, avg loss: 0.4087858824203849\n",
      "trial: 1, iter: 47800, curr loss: 0.4053666293621063, avg loss: 0.4087831429812948\n",
      "trial: 1, iter: 47900, curr loss: 0.40697193145751953, avg loss: 0.40877933418203244\n",
      "trial: 1, iter: 48000, curr loss: 0.3996696472167969, avg loss: 0.40877542120218274\n",
      "trial: 1, iter: 48100, curr loss: 0.40213248133659363, avg loss: 0.40877285009486264\n",
      "trial: 1, iter: 48200, curr loss: 0.4084635078907013, avg loss: 0.40877048845545877\n",
      "trial: 1, iter: 48300, curr loss: 0.40952110290527344, avg loss: 0.4087691498703591\n",
      "trial: 1, iter: 48400, curr loss: 0.4066733717918396, avg loss: 0.4087644637148242\n",
      "trial: 1, iter: 48500, curr loss: 0.40568649768829346, avg loss: 0.40876078971636665\n",
      "trial: 1, iter: 48600, curr loss: 0.408712238073349, avg loss: 0.4087564206546471\n",
      "trial: 1, iter: 48700, curr loss: 0.41616708040237427, avg loss: 0.4087516622040306\n",
      "trial: 1, iter: 48800, curr loss: 0.40205347537994385, avg loss: 0.4087503262597029\n",
      "trial: 1, iter: 48900, curr loss: 0.406951904296875, avg loss: 0.4087470063896267\n",
      "trial: 1, iter: 49000, curr loss: 0.39479851722717285, avg loss: 0.40874238122725975\n",
      "trial: 1, iter: 49100, curr loss: 0.4019145369529724, avg loss: 0.408737543622855\n",
      "trial: 1, iter: 49200, curr loss: 0.3964836001396179, avg loss: 0.4087335474098601\n",
      "trial: 1, iter: 49300, curr loss: 0.4002498984336853, avg loss: 0.40872869983587495\n",
      "trial: 1, iter: 49400, curr loss: 0.3991243243217468, avg loss: 0.40872259752410145\n",
      "trial: 1, iter: 49500, curr loss: 0.40957576036453247, avg loss: 0.40871797794224035\n",
      "trial: 1, iter: 49600, curr loss: 0.4023946523666382, avg loss: 0.40871319275769974\n",
      "trial: 1, iter: 49700, curr loss: 0.4006907641887665, avg loss: 0.4087093862681322\n",
      "trial: 1, iter: 49800, curr loss: 0.41021010279655457, avg loss: 0.40870460519769103\n",
      "trial: 1, iter: 49900, curr loss: 0.40753382444381714, avg loss: 0.40870217779774465\n",
      "trial: 1, iter: 50000, curr loss: 0.401267945766449, avg loss: 0.40869700238108636\n",
      "trial: 1, iter: 50100, curr loss: 0.39588895440101624, avg loss: 0.40869457392278546\n",
      "trial: 1, iter: 50200, curr loss: 0.40689361095428467, avg loss: 0.4086897868398889\n",
      "trial: 1, iter: 50300, curr loss: 0.41247203946113586, avg loss: 0.40868714603171435\n",
      "trial: 1, iter: 50400, curr loss: 0.42568299174308777, avg loss: 0.4086838399618864\n",
      "trial: 1, iter: 50500, curr loss: 0.4088572859764099, avg loss: 0.4086807531543297\n",
      "trial: 1, iter: 50600, curr loss: 0.40717121958732605, avg loss: 0.4086784864485028\n",
      "trial: 1, iter: 50700, curr loss: 0.4076959192752838, avg loss: 0.40867412367457234\n",
      "trial: 1, iter: 50800, curr loss: 0.4122583866119385, avg loss: 0.40867097699618715\n",
      "trial: 1, iter: 50900, curr loss: 0.3924911320209503, avg loss: 0.4086679474561528\n",
      "trial: 1, iter: 51000, curr loss: 0.41031649708747864, avg loss: 0.40866284950866416\n",
      "trial: 1, iter: 51100, curr loss: 0.40535661578178406, avg loss: 0.4086595952784945\n",
      "trial: 1, iter: 51200, curr loss: 0.410859078168869, avg loss: 0.4086564382800134\n",
      "trial: 1, iter: 51300, curr loss: 0.4182750880718231, avg loss: 0.40865358915245326\n",
      "trial: 1, iter: 51400, curr loss: 0.40834712982177734, avg loss: 0.4086479671177697\n",
      "trial: 1, iter: 51500, curr loss: 0.40345942974090576, avg loss: 0.4086442539778728\n",
      "trial: 1, iter: 51600, curr loss: 0.39564839005470276, avg loss: 0.40863830013272834\n",
      "trial: 1, iter: 51700, curr loss: 0.40655994415283203, avg loss: 0.4086342905055393\n",
      "trial: 1, iter: 51800, curr loss: 0.402689665555954, avg loss: 0.40862919605779374\n",
      "trial: 1, iter: 51900, curr loss: 0.397705614566803, avg loss: 0.4086267885829902\n",
      "trial: 1, iter: 52000, curr loss: 0.40549248456954956, avg loss: 0.40862260684600243\n",
      "trial: 1, iter: 52100, curr loss: 0.40289992094039917, avg loss: 0.4086191013758562\n",
      "trial: 1, iter: 52200, curr loss: 0.4090334177017212, avg loss: 0.40861721917415944\n",
      "trial: 1, iter: 52300, curr loss: 0.40224915742874146, avg loss: 0.40861345601070453\n",
      "trial: 1, iter: 52400, curr loss: 0.3951874375343323, avg loss: 0.4086101808859647\n",
      "trial: 1, iter: 52500, curr loss: 0.39686310291290283, avg loss: 0.4086077182372411\n",
      "trial: 1, iter: 52600, curr loss: 0.4221455454826355, avg loss: 0.4086041745073215\n",
      "trial: 1, iter: 52700, curr loss: 0.4028538465499878, avg loss: 0.4086020715418758\n",
      "trial: 1, iter: 52800, curr loss: 0.41037672758102417, avg loss: 0.40859749578052396\n",
      "trial: 1, iter: 52900, curr loss: 0.40849044919013977, avg loss: 0.4085945897900089\n",
      "trial: 1, iter: 53000, curr loss: 0.4103161096572876, avg loss: 0.40859166931881097\n",
      "trial: 1, iter: 53100, curr loss: 0.4099767208099365, avg loss: 0.408588397612904\n",
      "trial: 1, iter: 53200, curr loss: 0.42014533281326294, avg loss: 0.40858519165643625\n",
      "trial: 1, iter: 53300, curr loss: 0.4038388431072235, avg loss: 0.4085813487051352\n",
      "trial: 1, iter: 53400, curr loss: 0.4099215269088745, avg loss: 0.4085792637647091\n",
      "trial: 1, iter: 53500, curr loss: 0.40494459867477417, avg loss: 0.4085759976545227\n",
      "trial: 1, iter: 53600, curr loss: 0.40613052248954773, avg loss: 0.40857503506285486\n",
      "trial: 1, iter: 53700, curr loss: 0.39325952529907227, avg loss: 0.40856983244974077\n",
      "trial: 1, iter: 53800, curr loss: 0.40931183099746704, avg loss: 0.4085657459403281\n",
      "trial: 1, iter: 53900, curr loss: 0.4064503312110901, avg loss: 0.40856240847446923\n",
      "trial: 1, iter: 54000, curr loss: 0.4055006206035614, avg loss: 0.408558289817086\n",
      "trial: 1, iter: 54100, curr loss: 0.4005732536315918, avg loss: 0.408553494191324\n",
      "trial: 1, iter: 54200, curr loss: 0.408099889755249, avg loss: 0.40854954765126716\n",
      "trial: 1, iter: 54300, curr loss: 0.4094202518463135, avg loss: 0.40854675762231835\n",
      "trial: 1, iter: 54400, curr loss: 0.415175199508667, avg loss: 0.4085438398655285\n",
      "trial: 1, iter: 54500, curr loss: 0.4050057530403137, avg loss: 0.40853957274802233\n",
      "trial: 1, iter: 54600, curr loss: 0.41895800828933716, avg loss: 0.4085343380064973\n",
      "trial: 1, iter: 54700, curr loss: 0.40952426195144653, avg loss: 0.40853059220030713\n",
      "trial: 1, iter: 54800, curr loss: 0.4063660204410553, avg loss: 0.40852769281035356\n",
      "trial: 1, iter: 54900, curr loss: 0.4096919000148773, avg loss: 0.4085229024893599\n",
      "trial: 1, iter: 55000, curr loss: 0.4056207537651062, avg loss: 0.40851848689263515\n",
      "trial: 1, iter: 55100, curr loss: 0.4113413095474243, avg loss: 0.40851806348064634\n",
      "trial: 1, iter: 55200, curr loss: 0.3977237045764923, avg loss: 0.40851357177223846\n",
      "trial: 1, iter: 55300, curr loss: 0.42600321769714355, avg loss: 0.4085100140526325\n",
      "trial: 1, iter: 55400, curr loss: 0.416110634803772, avg loss: 0.40850656903069804\n",
      "trial: 1, iter: 55500, curr loss: 0.39949727058410645, avg loss: 0.4085031941447172\n",
      "trial: 1, iter: 55600, curr loss: 0.4092715084552765, avg loss: 0.40850210044506213\n",
      "trial: 1, iter: 55700, curr loss: 0.40546661615371704, avg loss: 0.4084983519993094\n",
      "trial: 1, iter: 55800, curr loss: 0.4188461899757385, avg loss: 0.408493729758754\n",
      "trial: 1, iter: 55900, curr loss: 0.40484872460365295, avg loss: 0.408490439760557\n",
      "trial: 1, iter: 56000, curr loss: 0.39899054169654846, avg loss: 0.4084853429166334\n",
      "trial: 1, iter: 56100, curr loss: 0.405562162399292, avg loss: 0.40848258162405404\n",
      "trial: 1, iter: 56200, curr loss: 0.3931959271430969, avg loss: 0.40847829477271574\n",
      "trial: 1, iter: 56300, curr loss: 0.40668827295303345, avg loss: 0.40847572851032815\n",
      "trial: 1, iter: 56400, curr loss: 0.41710174083709717, avg loss: 0.40847297773663455\n",
      "trial: 1, iter: 56500, curr loss: 0.40679866075515747, avg loss: 0.40846984019005195\n",
      "trial: 1, iter: 56600, curr loss: 0.4105919897556305, avg loss: 0.40846496383156033\n",
      "trial: 1, iter: 56700, curr loss: 0.4146360158920288, avg loss: 0.4084623483522439\n",
      "trial: 1, iter: 56800, curr loss: 0.39482325315475464, avg loss: 0.40845873687468787\n",
      "trial: 1, iter: 56900, curr loss: 0.4067893624305725, avg loss: 0.40845534706471887\n",
      "trial: 1, iter: 57000, curr loss: 0.39911481738090515, avg loss: 0.40845015127512446\n",
      "trial: 1, iter: 57100, curr loss: 0.39957234263420105, avg loss: 0.4084463280522886\n",
      "trial: 1, iter: 57200, curr loss: 0.3992137908935547, avg loss: 0.40844267500655634\n",
      "trial: 1, iter: 57300, curr loss: 0.39882200956344604, avg loss: 0.4084390476548859\n",
      "trial: 1, iter: 57400, curr loss: 0.41602474451065063, avg loss: 0.4084354018801596\n",
      "trial: 1, iter: 57500, curr loss: 0.40130043029785156, avg loss: 0.4084323012481565\n",
      "trial: 1, iter: 57600, curr loss: 0.40715357661247253, avg loss: 0.4084294825150735\n",
      "trial: 1, iter: 57700, curr loss: 0.404031366109848, avg loss: 0.4084255207772891\n",
      "trial: 1, iter: 57800, curr loss: 0.40161818265914917, avg loss: 0.40842190354907804\n",
      "trial: 1, iter: 57900, curr loss: 0.4038807153701782, avg loss: 0.40841795846382367\n",
      "trial: 1, iter: 58000, curr loss: 0.41473883390426636, avg loss: 0.4084138100224322\n",
      "trial: 1, iter: 58100, curr loss: 0.4159652292728424, avg loss: 0.4084097930722311\n",
      "trial: 1, iter: 58200, curr loss: 0.41794419288635254, avg loss: 0.4084090401196398\n",
      "trial: 1, iter: 58300, curr loss: 0.4021441638469696, avg loss: 0.4084063669119037\n",
      "trial: 1, iter: 58400, curr loss: 0.39116421341896057, avg loss: 0.4084014268959426\n",
      "trial: 1, iter: 58500, curr loss: 0.3978826701641083, avg loss: 0.40839842818995825\n",
      "trial: 1, iter: 58600, curr loss: 0.41321924328804016, avg loss: 0.408395009643999\n",
      "trial: 1, iter: 58700, curr loss: 0.39929550886154175, avg loss: 0.4083933853712155\n",
      "trial: 1, iter: 58800, curr loss: 0.41070690751075745, avg loss: 0.4083908993811632\n",
      "trial: 1, iter: 58900, curr loss: 0.39884451031684875, avg loss: 0.4083888928559316\n",
      "trial: 1, iter: 59000, curr loss: 0.41312694549560547, avg loss: 0.408387585694507\n",
      "trial: 1, iter: 59100, curr loss: 0.40804827213287354, avg loss: 0.4083834388050331\n",
      "trial: 1, iter: 59200, curr loss: 0.40299832820892334, avg loss: 0.40837947000271163\n",
      "trial: 1, iter: 59300, curr loss: 0.4149773120880127, avg loss: 0.40837615289233786\n",
      "trial: 1, iter: 59400, curr loss: 0.4184671640396118, avg loss: 0.40837421209473\n",
      "trial: 1, iter: 59500, curr loss: 0.40288037061691284, avg loss: 0.4083717265404573\n",
      "trial: 1, iter: 59600, curr loss: 0.41896647214889526, avg loss: 0.4083694901102341\n",
      "trial: 1, iter: 59700, curr loss: 0.3990793526172638, avg loss: 0.408366868433541\n",
      "trial: 1, iter: 59800, curr loss: 0.41001251339912415, avg loss: 0.4083629238042345\n",
      "trial: 1, iter: 59900, curr loss: 0.40467894077301025, avg loss: 0.4083599354219755\n",
      "trial: 1, iter: 60000, curr loss: 0.40850305557250977, avg loss: 0.40835661329776046\n",
      "trial: 1, iter: 60100, curr loss: 0.39255523681640625, avg loss: 0.40835478053414287\n",
      "trial: 1, iter: 60200, curr loss: 0.41090524196624756, avg loss: 0.4083509839590998\n",
      "trial: 1, iter: 60300, curr loss: 0.40371018648147583, avg loss: 0.40834947498728386\n",
      "trial: 1, iter: 60400, curr loss: 0.40980052947998047, avg loss: 0.4083465951523244\n",
      "trial: 1, iter: 60500, curr loss: 0.41759932041168213, avg loss: 0.40834467792905066\n",
      "trial: 1, iter: 60600, curr loss: 0.40366965532302856, avg loss: 0.40834170675956377\n",
      "trial: 1, iter: 60700, curr loss: 0.410277396440506, avg loss: 0.40834063540720666\n",
      "trial: 1, iter: 60800, curr loss: 0.39730480313301086, avg loss: 0.40833790011262816\n",
      "trial: 1, iter: 60900, curr loss: 0.40284597873687744, avg loss: 0.4083346058557969\n",
      "trial: 1, iter: 61000, curr loss: 0.41124218702316284, avg loss: 0.4083313819238397\n",
      "trial: 1, iter: 61100, curr loss: 0.40361279249191284, avg loss: 0.40832925068132225\n",
      "trial: 1, iter: 61200, curr loss: 0.4079033434391022, avg loss: 0.408325364362765\n",
      "trial: 1, iter: 61300, curr loss: 0.40627753734588623, avg loss: 0.4083213726036117\n",
      "trial: 1, iter: 61400, curr loss: 0.4055989980697632, avg loss: 0.40831833907709447\n",
      "trial: 1, iter: 61500, curr loss: 0.40572696924209595, avg loss: 0.4083148001529337\n",
      "trial: 1, iter: 61600, curr loss: 0.4010927677154541, avg loss: 0.4083114866201173\n",
      "trial: 1, iter: 61700, curr loss: 0.39354103803634644, avg loss: 0.40830901060295643\n",
      "trial: 1, iter: 61800, curr loss: 0.40394771099090576, avg loss: 0.4083078593816186\n",
      "trial: 1, iter: 61900, curr loss: 0.408907949924469, avg loss: 0.40830476469918486\n",
      "trial: 1, iter: 62000, curr loss: 0.41641753911972046, avg loss: 0.4083003546307164\n",
      "trial: 1, iter: 62100, curr loss: 0.40829741954803467, avg loss: 0.40829697215326743\n",
      "trial: 1, iter: 62200, curr loss: 0.4136749505996704, avg loss: 0.40829305425382123\n",
      "trial: 1, iter: 62300, curr loss: 0.40050211548805237, avg loss: 0.4082911464600655\n",
      "trial: 1, iter: 62400, curr loss: 0.40487754344940186, avg loss: 0.40828786969423675\n",
      "trial: 1, iter: 62500, curr loss: 0.4094529151916504, avg loss: 0.4082848469634056\n",
      "trial: 1, iter: 62600, curr loss: 0.4051972031593323, avg loss: 0.40828134593062887\n",
      "trial: 1, iter: 62700, curr loss: 0.40522682666778564, avg loss: 0.40827941107597837\n",
      "trial: 1, iter: 62800, curr loss: 0.3996509313583374, avg loss: 0.40827673594805464\n",
      "trial: 1, iter: 62900, curr loss: 0.39833545684814453, avg loss: 0.408274359076694\n",
      "trial: 1, iter: 63000, curr loss: 0.4032914638519287, avg loss: 0.4082723678189611\n",
      "trial: 1, iter: 63100, curr loss: 0.4104273021221161, avg loss: 0.40826778552706006\n",
      "trial: 1, iter: 63200, curr loss: 0.40043243765830994, avg loss: 0.4082638703970404\n",
      "trial: 1, iter: 63300, curr loss: 0.41266804933547974, avg loss: 0.40826244264181943\n",
      "trial: 1, iter: 63400, curr loss: 0.4092986583709717, avg loss: 0.40826054330033834\n",
      "trial: 1, iter: 63500, curr loss: 0.40137967467308044, avg loss: 0.40825830842894834\n",
      "trial: 1, iter: 63600, curr loss: 0.4073150157928467, avg loss: 0.40825452066301926\n",
      "trial: 1, iter: 63700, curr loss: 0.40269243717193604, avg loss: 0.4082518078117767\n",
      "trial: 1, iter: 63800, curr loss: 0.4141268730163574, avg loss: 0.4082480855832653\n",
      "trial: 1, iter: 63900, curr loss: 0.40811872482299805, avg loss: 0.40824639054391304\n",
      "trial: 1, iter: 64000, curr loss: 0.40225744247436523, avg loss: 0.40824414500035344\n",
      "trial: 1, iter: 64100, curr loss: 0.4067138433456421, avg loss: 0.4082426088216152\n",
      "trial: 1, iter: 64200, curr loss: 0.402118057012558, avg loss: 0.40824186445721583\n",
      "trial: 1, iter: 64300, curr loss: 0.4100983142852783, avg loss: 0.408240781723526\n",
      "trial: 1, iter: 64400, curr loss: 0.3947735130786896, avg loss: 0.40823968519057546\n",
      "trial: 1, iter: 64500, curr loss: 0.41485506296157837, avg loss: 0.4082369210438211\n",
      "trial: 1, iter: 64600, curr loss: 0.4123494625091553, avg loss: 0.4082345372885927\n",
      "trial: 1, iter: 64700, curr loss: 0.39808255434036255, avg loss: 0.4082301159712041\n",
      "trial: 1, iter: 64800, curr loss: 0.4169275164604187, avg loss: 0.40822827280211593\n",
      "trial: 1, iter: 64900, curr loss: 0.39866214990615845, avg loss: 0.4082249947707348\n",
      "trial: 1, iter: 65000, curr loss: 0.42127880454063416, avg loss: 0.4082227028026031\n",
      "trial: 1, iter: 65100, curr loss: 0.4053531885147095, avg loss: 0.4082207367272787\n",
      "trial: 1, iter: 65200, curr loss: 0.4088563323020935, avg loss: 0.40821897044503613\n",
      "trial: 1, iter: 65300, curr loss: 0.4048035442829132, avg loss: 0.40821812822616116\n",
      "trial: 1, iter: 65400, curr loss: 0.4052962362766266, avg loss: 0.408216776950826\n",
      "trial: 1, iter: 65500, curr loss: 0.39804813265800476, avg loss: 0.40821430032125866\n",
      "trial: 1, iter: 65600, curr loss: 0.4099976420402527, avg loss: 0.4082124790517477\n",
      "trial: 1, iter: 65700, curr loss: 0.40407735109329224, avg loss: 0.40821157941263014\n",
      "trial: 1, iter: 65800, curr loss: 0.40102922916412354, avg loss: 0.4082103943466959\n",
      "trial: 1, iter: 65900, curr loss: 0.40908053517341614, avg loss: 0.40820764431054385\n",
      "trial: 1, iter: 66000, curr loss: 0.4119255244731903, avg loss: 0.40820499600379756\n",
      "trial: 1, iter: 66100, curr loss: 0.41934216022491455, avg loss: 0.4082017041605287\n",
      "trial: 1, iter: 66200, curr loss: 0.4019818902015686, avg loss: 0.40819944880295017\n",
      "trial: 1, iter: 66300, curr loss: 0.4031467139720917, avg loss: 0.40819753928601654\n",
      "trial: 1, iter: 66400, curr loss: 0.40157631039619446, avg loss: 0.4081944277447211\n",
      "trial: 1, iter: 66500, curr loss: 0.4035595655441284, avg loss: 0.4081938987401195\n",
      "trial: 1, iter: 66600, curr loss: 0.40622881054878235, avg loss: 0.4081909482641979\n",
      "trial: 1, iter: 66700, curr loss: 0.40541210770606995, avg loss: 0.4081884932044385\n",
      "trial: 1, iter: 66800, curr loss: 0.3943687677383423, avg loss: 0.4081861194771921\n",
      "trial: 1, iter: 66900, curr loss: 0.4118468463420868, avg loss: 0.40818423478236293\n",
      "trial: 1, iter: 67000, curr loss: 0.391985684633255, avg loss: 0.4081805144953194\n",
      "trial: 1, iter: 67100, curr loss: 0.4068715274333954, avg loss: 0.4081787380078688\n",
      "trial: 1, iter: 67200, curr loss: 0.41110289096832275, avg loss: 0.40817593892415366\n",
      "trial: 1, iter: 67300, curr loss: 0.4114897847175598, avg loss: 0.4081754004472609\n",
      "trial: 1, iter: 67400, curr loss: 0.40492022037506104, avg loss: 0.40817342273117174\n",
      "trial: 1, iter: 67500, curr loss: 0.3958760201931, avg loss: 0.40817132173688325\n",
      "trial: 1, iter: 67600, curr loss: 0.4073171019554138, avg loss: 0.4081696711877394\n",
      "trial: 1, iter: 67700, curr loss: 0.4156624674797058, avg loss: 0.4081673414721271\n",
      "trial: 1, iter: 67800, curr loss: 0.4088936448097229, avg loss: 0.408164669403636\n",
      "trial: 1, iter: 67900, curr loss: 0.40877020359039307, avg loss: 0.4081625575024706\n",
      "trial: 1, iter: 68000, curr loss: 0.3928626775741577, avg loss: 0.4081590601801872\n",
      "trial: 1, iter: 68100, curr loss: 0.40701425075531006, avg loss: 0.4081588354943082\n",
      "trial: 1, iter: 68200, curr loss: 0.4006223678588867, avg loss: 0.408157631040843\n",
      "trial: 1, iter: 68300, curr loss: 0.4035995304584503, avg loss: 0.4081537345920091\n",
      "trial: 1, iter: 68400, curr loss: 0.4143751859664917, avg loss: 0.40815150959493474\n",
      "trial: 1, iter: 68500, curr loss: 0.40714436769485474, avg loss: 0.40814811783637445\n",
      "trial: 1, iter: 68600, curr loss: 0.4267725348472595, avg loss: 0.40814533431919253\n",
      "trial: 1, iter: 68700, curr loss: 0.41341492533683777, avg loss: 0.4081416518641351\n",
      "trial: 1, iter: 68800, curr loss: 0.40291735529899597, avg loss: 0.40813988819068603\n",
      "trial: 1, iter: 68900, curr loss: 0.41189807653427124, avg loss: 0.4081383401566389\n",
      "trial: 1, iter: 69000, curr loss: 0.4054318070411682, avg loss: 0.4081354577619096\n",
      "trial: 1, iter: 69100, curr loss: 0.40385472774505615, avg loss: 0.40813316444369024\n",
      "trial: 1, iter: 69200, curr loss: 0.39461973309516907, avg loss: 0.4081296941241777\n",
      "trial: 1, iter: 69300, curr loss: 0.4223547577857971, avg loss: 0.4081280123632708\n",
      "trial: 1, iter: 69400, curr loss: 0.4040476679801941, avg loss: 0.40812506783721425\n",
      "trial: 1, iter: 69500, curr loss: 0.41780734062194824, avg loss: 0.408122235621051\n",
      "trial: 1, iter: 69600, curr loss: 0.3993273973464966, avg loss: 0.4081191484236169\n",
      "trial: 1, iter: 69700, curr loss: 0.39788854122161865, avg loss: 0.40811688436882054\n",
      "trial: 1, iter: 69800, curr loss: 0.4064735770225525, avg loss: 0.4081145399181242\n",
      "trial: 1, iter: 69900, curr loss: 0.41174930334091187, avg loss: 0.40811300592915356\n",
      "trial: 1, iter: 70000, curr loss: 0.40641191601753235, avg loss: 0.40811036683448726\n",
      "trial: 1, iter: 70100, curr loss: 0.40345561504364014, avg loss: 0.40810669516615794\n",
      "trial: 1, iter: 70200, curr loss: 0.4215250015258789, avg loss: 0.40810554001957944\n",
      "trial: 1, iter: 70300, curr loss: 0.41123372316360474, avg loss: 0.40810317207578234\n",
      "trial: 1, iter: 70400, curr loss: 0.39575156569480896, avg loss: 0.408101893983866\n",
      "trial: 1, iter: 70500, curr loss: 0.41704294085502625, avg loss: 0.4081004762319808\n",
      "trial: 1, iter: 70600, curr loss: 0.408317506313324, avg loss: 0.40809858272332306\n",
      "trial: 1, iter: 70700, curr loss: 0.39963141083717346, avg loss: 0.4080972858508878\n",
      "trial: 1, iter: 70800, curr loss: 0.4148215651512146, avg loss: 0.40809550667128996\n",
      "trial: 1, iter: 70900, curr loss: 0.41110914945602417, avg loss: 0.4080942285077696\n",
      "trial: 1, iter: 71000, curr loss: 0.4116073250770569, avg loss: 0.4080922851583488\n",
      "trial: 1, iter: 71100, curr loss: 0.3907949924468994, avg loss: 0.40808913543925174\n",
      "trial: 1, iter: 71200, curr loss: 0.41026800870895386, avg loss: 0.4080875768223673\n",
      "trial: 1, iter: 71300, curr loss: 0.4085389971733093, avg loss: 0.40808335489594755\n",
      "trial: 1, iter: 71400, curr loss: 0.40483543276786804, avg loss: 0.40808125138867135\n",
      "trial: 1, iter: 71500, curr loss: 0.3942923843860626, avg loss: 0.4080781362240131\n",
      "trial: 1, iter: 71600, curr loss: 0.40883365273475647, avg loss: 0.4080765296006835\n",
      "trial: 1, iter: 71700, curr loss: 0.40885061025619507, avg loss: 0.4080736935167798\n",
      "trial: 1, iter: 71800, curr loss: 0.4207521677017212, avg loss: 0.4080712134745958\n",
      "trial: 1, iter: 71900, curr loss: 0.41682523488998413, avg loss: 0.4080709451644245\n",
      "trial: 1, iter: 72000, curr loss: 0.4061598479747772, avg loss: 0.4080679894801643\n",
      "trial: 1, iter: 72100, curr loss: 0.40445297956466675, avg loss: 0.40806719766741156\n",
      "trial: 1, iter: 72200, curr loss: 0.4164104759693146, avg loss: 0.40806573475744584\n",
      "trial: 1, iter: 72300, curr loss: 0.41014012694358826, avg loss: 0.4080666024123485\n",
      "trial: 1, iter: 72400, curr loss: 0.41067370772361755, avg loss: 0.40806525691396955\n",
      "trial: 1, iter: 72500, curr loss: 0.3942893147468567, avg loss: 0.4080621539559858\n",
      "trial: 1, iter: 72600, curr loss: 0.41784775257110596, avg loss: 0.4080614476299976\n",
      "trial: 1, iter: 72700, curr loss: 0.4138838052749634, avg loss: 0.40806111047569626\n",
      "trial: 1, iter: 72800, curr loss: 0.4023502469062805, avg loss: 0.40805824315769007\n",
      "trial: 1, iter: 72900, curr loss: 0.38608604669570923, avg loss: 0.40805861737543336\n",
      "trial: 1, iter: 73000, curr loss: 0.41507065296173096, avg loss: 0.40805633428366217\n",
      "trial: 1, iter: 73100, curr loss: 0.39308464527130127, avg loss: 0.4080550060014555\n",
      "trial: 1, iter: 73200, curr loss: 0.41153061389923096, avg loss: 0.408053932546185\n",
      "trial: 1, iter: 73300, curr loss: 0.4115028381347656, avg loss: 0.4080492446859244\n",
      "trial: 1, iter: 73400, curr loss: 0.4019100069999695, avg loss: 0.4080459169215175\n",
      "trial: 1, iter: 73500, curr loss: 0.42063724994659424, avg loss: 0.4080438632356877\n",
      "trial: 1, iter: 73600, curr loss: 0.41263508796691895, avg loss: 0.40804149058687944\n",
      "trial: 1, iter: 73700, curr loss: 0.41274505853652954, avg loss: 0.4080390524569004\n",
      "trial: 1, iter: 73800, curr loss: 0.4076106548309326, avg loss: 0.408036426532317\n",
      "trial: 1, iter: 73900, curr loss: 0.41710925102233887, avg loss: 0.4080335967095521\n",
      "trial: 1, iter: 74000, curr loss: 0.41295015811920166, avg loss: 0.4080313192102555\n",
      "trial: 1, iter: 74100, curr loss: 0.4069937765598297, avg loss: 0.40802654585334774\n",
      "trial: 1, iter: 74200, curr loss: 0.40331071615219116, avg loss: 0.4080254266288563\n",
      "trial: 1, iter: 74300, curr loss: 0.39938294887542725, avg loss: 0.40802228323904693\n",
      "trial: 1, iter: 74400, curr loss: 0.40351366996765137, avg loss: 0.4080197010253386\n",
      "trial: 1, iter: 74500, curr loss: 0.41541817784309387, avg loss: 0.40801787045017984\n",
      "trial: 1, iter: 74600, curr loss: 0.41086405515670776, avg loss: 0.4080156544593959\n",
      "trial: 1, iter: 74700, curr loss: 0.4095436632633209, avg loss: 0.40801615759670495\n",
      "trial: 1, iter: 74800, curr loss: 0.4021722078323364, avg loss: 0.408014363990748\n",
      "trial: 1, iter: 74900, curr loss: 0.41342902183532715, avg loss: 0.4080126879713405\n",
      "trial: 1, iter: 75000, curr loss: 0.4035030007362366, avg loss: 0.40800842625379563\n",
      "trial: 1, iter: 75100, curr loss: 0.41741418838500977, avg loss: 0.40800593046786465\n",
      "trial: 1, iter: 75200, curr loss: 0.4167313575744629, avg loss: 0.408003630125697\n",
      "trial: 1, iter: 75300, curr loss: 0.4072608947753906, avg loss: 0.4080008848935643\n",
      "trial: 1, iter: 75400, curr loss: 0.408348023891449, avg loss: 0.40799786513933134\n",
      "trial: 1, iter: 75500, curr loss: 0.40473562479019165, avg loss: 0.4079945530054585\n",
      "trial: 1, iter: 75600, curr loss: 0.4151708483695984, avg loss: 0.4079930495498357\n",
      "trial: 1, iter: 75700, curr loss: 0.41501355171203613, avg loss: 0.40799011954070713\n",
      "trial: 1, iter: 75800, curr loss: 0.40650686621665955, avg loss: 0.4079893214277196\n",
      "trial: 1, iter: 75900, curr loss: 0.4115210473537445, avg loss: 0.40798862435011995\n",
      "trial: 1, iter: 76000, curr loss: 0.40932589769363403, avg loss: 0.4079890298372821\n",
      "trial: 1, iter: 76100, curr loss: 0.41575419902801514, avg loss: 0.40798862532074914\n",
      "trial: 1, iter: 76200, curr loss: 0.40875428915023804, avg loss: 0.40798596443975066\n",
      "trial: 1, iter: 76300, curr loss: 0.40460920333862305, avg loss: 0.4079837662356553\n",
      "trial: 1, iter: 76400, curr loss: 0.39883291721343994, avg loss: 0.40798044825177543\n",
      "trial: 1, iter: 76500, curr loss: 0.41319483518600464, avg loss: 0.4079767734143469\n",
      "trial: 1, iter: 76600, curr loss: 0.4057175815105438, avg loss: 0.40797610359271264\n",
      "trial: 1, iter: 76700, curr loss: 0.39837953448295593, avg loss: 0.40797326420051333\n",
      "trial: 1, iter: 76800, curr loss: 0.39420729875564575, avg loss: 0.4079705159253596\n",
      "trial: 1, iter: 76900, curr loss: 0.4071565270423889, avg loss: 0.4079686025827542\n",
      "trial: 1, iter: 77000, curr loss: 0.4035302400588989, avg loss: 0.4079659561789655\n",
      "trial: 1, iter: 77100, curr loss: 0.4142950773239136, avg loss: 0.40796263134007943\n",
      "trial: 1, iter: 77200, curr loss: 0.3966524600982666, avg loss: 0.4079602246611847\n",
      "trial: 1, iter: 77300, curr loss: 0.41283634305000305, avg loss: 0.4079587931512707\n",
      "trial: 1, iter: 77400, curr loss: 0.41118404269218445, avg loss: 0.4079556942371127\n",
      "trial: 1, iter: 77500, curr loss: 0.40745389461517334, avg loss: 0.40795286234540323\n",
      "trial: 1, iter: 77600, curr loss: 0.4016485810279846, avg loss: 0.4079504371949078\n",
      "trial: 1, iter: 77700, curr loss: 0.40706929564476013, avg loss: 0.40794883022897493\n",
      "trial: 1, iter: 77800, curr loss: 0.41025304794311523, avg loss: 0.4079471827185399\n",
      "trial: 1, iter: 77900, curr loss: 0.4063703417778015, avg loss: 0.40794454122461926\n",
      "trial: 1, iter: 78000, curr loss: 0.40069836378097534, avg loss: 0.4079438284677573\n",
      "trial: 1, iter: 78100, curr loss: 0.4191468358039856, avg loss: 0.40794246756198616\n",
      "trial: 1, iter: 78200, curr loss: 0.4027450680732727, avg loss: 0.4079399173964015\n",
      "trial: 1, iter: 78300, curr loss: 0.41771551966667175, avg loss: 0.40793819999862296\n",
      "trial: 1, iter: 78400, curr loss: 0.40402060747146606, avg loss: 0.40793609279378945\n",
      "trial: 1, iter: 78500, curr loss: 0.40876585245132446, avg loss: 0.40793617013533406\n",
      "trial: 1, iter: 78600, curr loss: 0.4038839638233185, avg loss: 0.4079342358697765\n",
      "trial: 1, iter: 78700, curr loss: 0.40520885586738586, avg loss: 0.40793291637221923\n",
      "trial: 1, iter: 78800, curr loss: 0.4050642251968384, avg loss: 0.4079320330505595\n",
      "trial: 1, iter: 78900, curr loss: 0.4030988812446594, avg loss: 0.40793120181001485\n",
      "trial: 1, iter: 79000, curr loss: 0.40371018648147583, avg loss: 0.40792967915384076\n",
      "trial: 1, iter: 79100, curr loss: 0.4131048917770386, avg loss: 0.40792925470283753\n",
      "trial: 1, iter: 79200, curr loss: 0.3909105360507965, avg loss: 0.40792786257021657\n",
      "trial: 1, iter: 79300, curr loss: 0.40846574306488037, avg loss: 0.40792656983733927\n",
      "trial: 1, iter: 79400, curr loss: 0.40301764011383057, avg loss: 0.40792459517417085\n",
      "trial: 1, iter: 79500, curr loss: 0.4127798080444336, avg loss: 0.40792242244317095\n",
      "trial: 1, iter: 79600, curr loss: 0.41011643409729004, avg loss: 0.4079205100784949\n",
      "trial: 1, iter: 79700, curr loss: 0.4089246988296509, avg loss: 0.40791785281380566\n",
      "trial: 1, iter: 79800, curr loss: 0.4131588637828827, avg loss: 0.40791511572542644\n",
      "trial: 1, iter: 79900, curr loss: 0.4046587646007538, avg loss: 0.4079131589231264\n",
      "trial: 1, iter: 80000, curr loss: 0.4037776589393616, avg loss: 0.40791020973026754\n",
      "trial: 1, ldr: 1.1410621404647827, dv: 1.1515320539474487, nwj: 1.1514774560928345\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 1\n",
    "num_of_inner_iteration = 80000\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    model = ProbabilisticClassifier(num_input_features, hidden_size_arr, num_output_features).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    ## train classifier\n",
    "    model.train()\n",
    "    inner_running_loss = []\n",
    "    inner_running_loss_avg = []\n",
    "    curr_inner_running_loss_avg = 0\n",
    "    \n",
    "    num_of_joint = 0\n",
    "    num_of_marginal = 0\n",
    "    for inner_iter in range(num_of_inner_iteration):\n",
    "        selected_samples = np.random.choice(num_of_samples * 2, batch_size, replace=False)\n",
    "        batch_data, batch_label = data[selected_samples], label[selected_samples]\n",
    "        batch_data, batch_label = torch.from_numpy(batch_data).to(torch.float32), torch.from_numpy(batch_label).to(torch.long)\n",
    "        num_of_marginal += torch.count_nonzero(batch_label)\n",
    "        num_of_joint += batch_size - torch.count_nonzero(batch_label)\n",
    "        batch_label = one_hot(batch_label, num_classes=num_output_features).to(torch.float32)\n",
    "        batch_data, batch_label = batch_data.to(device), batch_label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_data)\n",
    "        loss = criterion(logits, batch_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        curr_inner_running_loss_avg += loss.item()\n",
    "        \n",
    "        if inner_iter == 0 or ((inner_iter + 1) % 100) == 0:\n",
    "            print('trial: {}, iter: {}, curr loss: {}, avg loss: {}'.format(outer_iter + 1, inner_iter + 1, loss.item(), curr_inner_running_loss_avg / (inner_iter + 1)))\n",
    "            inner_running_loss_avg.append(curr_inner_running_loss_avg / (inner_iter + 1))\n",
    "            \n",
    "        inner_running_loss.append(loss.item())\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model = model.to('cpu')\n",
    "        estimated_logits_for_joint = model(torch.from_numpy(joint_data).to(torch.float32))\n",
    "        estimated_logits_for_marginal = model(torch.from_numpy(marginal_data).to(torch.float32))\n",
    "        joint_cond_prob = torch.sigmoid(estimated_logits_for_joint)\n",
    "        marginal_cond_prob = torch.sigmoid(estimated_logits_for_marginal)\n",
    "        class_distribution = num_of_marginal / num_of_joint\n",
    "        pointwise_dependency_joint = torch.log(torch.div(joint_cond_prob[:, 0], joint_cond_prob[:, 1]) * class_distribution)\n",
    "        pointwise_dependency_marginal = torch.div(marginal_cond_prob[:, 0], marginal_cond_prob[:, 1]) * class_distribution\n",
    "        curr_ldr = torch.sum(pointwise_dependency_joint) / pointwise_dependency_joint.size(0)\n",
    "        curr_dv = (torch.sum(pointwise_dependency_joint) / pointwise_dependency_joint.size(0)) - torch.log(torch.sum(pointwise_dependency_marginal) / pointwise_dependency_marginal.size(0))\n",
    "        curr_nwj = (torch.sum(pointwise_dependency_joint) / pointwise_dependency_joint.size(0)) - (torch.sum(pointwise_dependency_marginal) / pointwise_dependency_marginal.size(0)) + 1\n",
    "        print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "        ldr_estimations.append(curr_ldr.item())\n",
    "        dv_estimations.append(curr_dv.item())\n",
    "        nwj_estimations.append(curr_nwj.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:56:12.335542306Z",
     "start_time": "2023-11-18T03:55:08.988608807Z"
    }
   },
   "id": "146b880bcd657c43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
