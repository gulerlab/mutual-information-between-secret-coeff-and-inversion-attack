{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DReS-FL Experiment \n",
    "\n",
    "- K = 1\n",
    "- T = 1\n",
    "- input dimension = 1 -> scalar\n",
    "- linear regression\n",
    "- w = 1\n",
    "- finite field size = 5\n",
    "- inputs are selected from {0, 1}\n",
    "- no relationship between x and y\n",
    "- the gradient is supposed to be revealed at the end of each training round\n",
    "\n",
    "Basically, our objective function is $l = (y - xw)^2$ and our gradient is $g = -2(xy - x^2w)$ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b3c4298b0e65eb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lcc.polynomials import LCCPoly, InterpolatedPoly\n",
    "from mutual_information.estimators.neural.benchmark import neural_estimator_benchmark\n",
    "from lcc.domain import create_lcc_gradient_domain_basic_setup_no_relationship\n",
    "from mutual_information.exhaustive_search_mutual_information import calculate_mutual_information_domain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:53:45.960752158Z",
     "start_time": "2023-11-15T22:53:45.917913361Z"
    }
   },
   "id": "5ecd3014be47b957"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "prime = 5\n",
    "data_range = 2\n",
    "para_param = 1 # K\n",
    "priv_param = 1 # T\n",
    "\n",
    "num_of_samples = 10000\n",
    "beta_arr = [0, 1]\n",
    "alpha_arr = [2, 3, 4] # number of clients = 3\n",
    "weight = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:53:46.661721759Z",
     "start_time": "2023-11-15T22:53:46.659052568Z"
    }
   },
   "id": "cea634fe6a81f53"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_encoded_dataset(encoded_data_pol, encoded_label_pol, alpha):\n",
    "    encoded_dataset = np.empty((len(encoded_data_pol), 2)) \n",
    "    for idx, (data_pol, label_pol) in enumerate(zip(encoded_data_pol, encoded_label_pol)):\n",
    "        encoded_dataset[idx][0] = data_pol(alpha)\n",
    "        encoded_dataset[idx][1] = label_pol(alpha)\n",
    "    return encoded_dataset\n",
    "\n",
    "def calculate_gradient(encoded_dataset, curr_weight, p):\n",
    "    encoded_data = encoded_dataset[:, 0].reshape(-1, 1)\n",
    "    encoded_label = encoded_dataset[:, 1].reshape(-1, 1)\n",
    "    \n",
    "    gradient = (encoded_label - encoded_data @ curr_weight) % p\n",
    "    gradient = (encoded_data.T @ gradient) % p\n",
    "    gradient = (-2 * gradient) % p\n",
    "    return gradient\n",
    "\n",
    "def calculate_gradient_samplewise(encoded_dataset, curr_weight, p):\n",
    "    # g = -2(xy - x^2w)\n",
    "    gradient = np.empty(encoded_dataset.shape[0])\n",
    "    for idx, encoded_sample in enumerate(encoded_dataset):\n",
    "        data, label = encoded_sample[0], encoded_sample[1]\n",
    "        gradient[idx] = (label - data * curr_weight) % p\n",
    "        gradient[idx] = (data * gradient[idx]) % p\n",
    "        gradient[idx] = (-2 * gradient[idx]) % p\n",
    "    gradient = gradient.astype(int)\n",
    "    return gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:53:47.418578754Z",
     "start_time": "2023-11-15T22:53:47.415730636Z"
    }
   },
   "id": "2d6a184396caa636"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "secret_data = np.random.randint(low=0, high=2, size=(num_of_samples, 1))\n",
    "secret_label = np.random.randint(low=0, high=2, size=(num_of_samples, 1))\n",
    "encoded_secret_data_pol = [LCCPoly(beta_arr, [x[0]], para_param, priv_param, prime) for x in secret_data]\n",
    "encoded_secret_label_pol = [LCCPoly(beta_arr, [x[0]], para_param, priv_param, prime) for x in secret_label]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:53:55.385549684Z",
     "start_time": "2023-11-15T22:53:48.153476491Z"
    }
   },
   "id": "705f968c5d9b62fc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# client 0\n",
    "client_0_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[0])\n",
    "client_0_encoded_gradient = calculate_gradient_samplewise(client_0_encoded_data, weight, prime)\n",
    "\n",
    "# client 1\n",
    "client_1_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[1])\n",
    "client_1_encoded_gradient = calculate_gradient_samplewise(client_1_encoded_data, weight, prime)\n",
    "\n",
    "# client 2\n",
    "client_2_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[2])\n",
    "client_2_encoded_gradient = calculate_gradient_samplewise(client_2_encoded_data, weight, prime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:53:55.559551790Z",
     "start_time": "2023-11-15T22:53:55.401007690Z"
    }
   },
   "id": "ac2d268532e1f34a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "revealed_poly_arr = [] \n",
    "revealed_gradients = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_random = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_poly_constructed_coeff = np.empty((client_0_encoded_gradient.shape[0], 2 * para_param + 1))\n",
    "for gradient_idx in range(client_0_encoded_gradient.shape[0]):\n",
    "    revealed_poly = InterpolatedPoly([int(client_0_encoded_gradient[gradient_idx]), int(client_1_encoded_gradient[gradient_idx]), int(client_2_encoded_gradient[gradient_idx])], alpha_arr, prime)\n",
    "    revealed_gradients[gradient_idx][0] = revealed_poly(beta_arr[0])\n",
    "    revealed_random[gradient_idx][0] = revealed_poly(beta_arr[1])\n",
    "    revealed_poly_constructed_coeff[gradient_idx] = revealed_poly.coefficients\n",
    "    revealed_poly_arr.append(revealed_poly)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:54:00.161050162Z",
     "start_time": "2023-11-15T22:53:55.564885411Z"
    }
   },
   "id": "a77a29cfacc3050a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# create dataset\n",
    "resulting_dataset = np.concatenate([secret_data, secret_label, revealed_gradients, revealed_random, revealed_poly_constructed_coeff], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:54:00.163725675Z",
     "start_time": "2023-11-15T22:54:00.162125959Z"
    }
   },
   "id": "4566e622a38e75c5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▋                                              | 1250/10000 [02:47<19:31,  7.47step/s, test=0.89, train=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▏                                              | 1000/10000 [00:05<00:51, 174.47step/s, test=0.87, train=0.90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████▎                                           | 1750/10000 [03:40<17:21,  7.92step/s, test=0.90, train=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▋                                              | 1250/10000 [02:35<18:06,  8.06step/s, test=0.89, train=0.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_all, results_all = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 4:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:03:09.696640405Z",
     "start_time": "2023-11-15T22:54:00.165953061Z"
    }
   },
   "id": "4e4d497917e37ba1"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▉                                             | 1500/10000 [04:17<24:20,  5.82step/s, test=0.56, train=0.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▏                                              | 1000/10000 [00:05<00:52, 171.88step/s, test=0.55, train=0.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                                  | 750/10000 [02:07<26:15,  5.87step/s, test=0.56, train=0.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▎                                               | 1000/10000 [02:51<25:39,  5.85step/s, test=0.56, train=0.48]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_revealed_gradient, results_revealed_gradient = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 2].reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:12:32.304218004Z",
     "start_time": "2023-11-15T23:03:09.696417192Z"
    }
   },
   "id": "f4987aa6326c8320"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100/12500\n",
      "iteration 200/12500\n",
      "iteration 300/12500\n",
      "iteration 400/12500\n",
      "iteration 500/12500\n",
      "iteration 600/12500\n",
      "iteration 700/12500\n",
      "iteration 800/12500\n",
      "iteration 900/12500\n",
      "iteration 1000/12500\n",
      "iteration 1100/12500\n",
      "iteration 1200/12500\n",
      "iteration 1300/12500\n",
      "iteration 1400/12500\n",
      "iteration 1500/12500\n",
      "iteration 1600/12500\n",
      "iteration 1700/12500\n",
      "iteration 1800/12500\n",
      "iteration 1900/12500\n",
      "iteration 2000/12500\n",
      "iteration 2100/12500\n",
      "iteration 2200/12500\n",
      "iteration 2300/12500\n",
      "iteration 2400/12500\n",
      "iteration 2500/12500\n",
      "iteration 2600/12500\n",
      "iteration 2700/12500\n",
      "iteration 2800/12500\n",
      "iteration 2900/12500\n",
      "iteration 3000/12500\n",
      "iteration 3100/12500\n",
      "iteration 3200/12500\n",
      "iteration 3300/12500\n",
      "iteration 3400/12500\n",
      "iteration 3500/12500\n",
      "iteration 3600/12500\n",
      "iteration 3700/12500\n",
      "iteration 3800/12500\n",
      "iteration 3900/12500\n",
      "iteration 4000/12500\n",
      "iteration 4100/12500\n",
      "iteration 4200/12500\n",
      "iteration 4300/12500\n",
      "iteration 4400/12500\n",
      "iteration 4500/12500\n",
      "iteration 4600/12500\n",
      "iteration 4700/12500\n",
      "iteration 4800/12500\n",
      "iteration 4900/12500\n",
      "iteration 5000/12500\n",
      "iteration 5100/12500\n",
      "iteration 5200/12500\n",
      "iteration 5300/12500\n",
      "iteration 5400/12500\n",
      "iteration 5500/12500\n",
      "iteration 5600/12500\n",
      "iteration 5700/12500\n",
      "iteration 5800/12500\n",
      "iteration 5900/12500\n",
      "iteration 6000/12500\n",
      "iteration 6100/12500\n",
      "iteration 6200/12500\n",
      "iteration 6300/12500\n",
      "iteration 6400/12500\n",
      "iteration 6500/12500\n",
      "iteration 6600/12500\n",
      "iteration 6700/12500\n",
      "iteration 6800/12500\n",
      "iteration 6900/12500\n",
      "iteration 7000/12500\n",
      "iteration 7100/12500\n",
      "iteration 7200/12500\n",
      "iteration 7300/12500\n",
      "iteration 7400/12500\n",
      "iteration 7500/12500\n",
      "iteration 7600/12500\n",
      "iteration 7700/12500\n",
      "iteration 7800/12500\n",
      "iteration 7900/12500\n",
      "iteration 8000/12500\n",
      "iteration 8100/12500\n",
      "iteration 8200/12500\n",
      "iteration 8300/12500\n",
      "iteration 8400/12500\n",
      "iteration 8500/12500\n",
      "iteration 8600/12500\n",
      "iteration 8700/12500\n",
      "iteration 8800/12500\n",
      "iteration 8900/12500\n",
      "iteration 9000/12500\n",
      "iteration 9100/12500\n",
      "iteration 9200/12500\n",
      "iteration 9300/12500\n",
      "iteration 9400/12500\n",
      "iteration 9500/12500\n",
      "iteration 9600/12500\n",
      "iteration 9700/12500\n",
      "iteration 9800/12500\n",
      "iteration 9900/12500\n",
      "iteration 10000/12500\n",
      "iteration 10100/12500\n",
      "iteration 10200/12500\n",
      "iteration 10300/12500\n",
      "iteration 10400/12500\n",
      "iteration 10500/12500\n",
      "iteration 10600/12500\n",
      "iteration 10700/12500\n",
      "iteration 10800/12500\n",
      "iteration 10900/12500\n",
      "iteration 11000/12500\n",
      "iteration 11100/12500\n",
      "iteration 11200/12500\n",
      "iteration 11300/12500\n",
      "iteration 11400/12500\n",
      "iteration 11500/12500\n",
      "iteration 11600/12500\n",
      "iteration 11700/12500\n",
      "iteration 11800/12500\n",
      "iteration 11900/12500\n",
      "iteration 12000/12500\n",
      "iteration 12100/12500\n",
      "iteration 12200/12500\n",
      "iteration 12300/12500\n",
      "iteration 12400/12500\n",
      "iteration 12500/12500\n",
      "0.9082860860579589 0.5623351446188083\n"
     ]
    }
   ],
   "source": [
    "basic_experiment_domain = create_lcc_gradient_domain_basic_setup_no_relationship(data_range, beta_arr, alpha_arr, weight, prime)\n",
    "all_coeff_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4, 5, 6, 7, 8], [data_range, data_range], [prime, prime, prime, prime, prime])\n",
    "revealed_gradient_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4], [data_range, data_range], [prime])\n",
    "print(all_coeff_mi, revealed_gradient_mi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:12:41.199629109Z",
     "start_time": "2023-11-15T23:12:32.304803712Z"
    }
   },
   "id": "e5c2fec600e08573"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
