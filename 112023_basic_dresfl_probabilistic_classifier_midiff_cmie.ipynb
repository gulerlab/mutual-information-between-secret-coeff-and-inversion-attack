{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:30:54.140818912Z",
     "start_time": "2023-11-21T09:30:53.091707858Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulerlab/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lcc.dataset import create_lcc_dataset_k1_t1_scalar\n",
    "\n",
    "from probabilistic_classifier.dataset import create_joint_marginal_dataset\n",
    "from probabilistic_classifier.estimate import estimate_mi_for_binary_classification\n",
    "from probabilistic_classifier.train import train_binary_classifier_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52797b0247350ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:31:59.296101312Z",
     "start_time": "2023-11-21T09:30:54.985354773Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pols created\n",
      "dataset is created\n"
     ]
    }
   ],
   "source": [
    "# create the basis dataset\n",
    "prime = 5\n",
    "data_range = 2\n",
    "num_of_samples = 800000\n",
    "weight = np.asarray([[1]])\n",
    "dataset = create_lcc_dataset_k1_t1_scalar(prime, data_range, num_of_samples, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62da61c8fc32e6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:31:59.296379675Z",
     "start_time": "2023-11-21T09:31:59.296217843Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "x_idx, y_idx, z_idx = [0, 1], [3, 4, 5], [2]\n",
    "yz_idx = [2, 3, 4, 5]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_joint_marginal_dataset(dataset, x_idx, yz_idx)\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb99642d6db7215",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:59.296305455Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(yz_idx)\n",
    "hidden_size_arr = [256, 256, 256]\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146b880bcd657c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T09:31:59.297036289Z",
     "start_time": "2023-11-21T09:31:59.296624259Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, epoch, 1, iter: 1, curr loss: 0.6940299868583679, avg loss: 0.6940299868583679\n",
      "trial: 1, epoch, 1, iter: 200, curr loss: 0.44217681884765625, avg loss: 0.4565826053917408\n",
      "trial: 1, epoch, 2, iter: 1, curr loss: 0.4305155277252197, avg loss: 0.4305155277252197\n",
      "trial: 1, epoch, 2, iter: 200, curr loss: 0.43757250905036926, avg loss: 0.4301589366793632\n",
      "trial: 1, epoch, 3, iter: 1, curr loss: 0.4406145215034485, avg loss: 0.4406145215034485\n",
      "trial: 1, epoch, 3, iter: 200, curr loss: 0.41929250955581665, avg loss: 0.42972503215074537\n",
      "trial: 1, epoch, 4, iter: 1, curr loss: 0.42699992656707764, avg loss: 0.42699992656707764\n",
      "trial: 1, epoch, 4, iter: 200, curr loss: 0.42695939540863037, avg loss: 0.42881056413054464\n",
      "trial: 1, epoch, 5, iter: 1, curr loss: 0.42707228660583496, avg loss: 0.42707228660583496\n",
      "trial: 1, epoch, 5, iter: 200, curr loss: 0.42135727405548096, avg loss: 0.4281506833434105\n",
      "trial: 1, epoch, 6, iter: 1, curr loss: 0.41085222363471985, avg loss: 0.41085222363471985\n",
      "trial: 1, epoch, 6, iter: 200, curr loss: 0.42989733815193176, avg loss: 0.428896798491478\n",
      "trial: 1, epoch, 7, iter: 1, curr loss: 0.44126081466674805, avg loss: 0.44126081466674805\n",
      "trial: 1, epoch, 7, iter: 200, curr loss: 0.4260444641113281, avg loss: 0.4288224139809608\n",
      "trial: 1, epoch, 8, iter: 1, curr loss: 0.43012484908103943, avg loss: 0.43012484908103943\n",
      "trial: 1, epoch, 8, iter: 200, curr loss: 0.4450072646141052, avg loss: 0.42952053993940353\n",
      "trial: 1, epoch, 9, iter: 1, curr loss: 0.4393131136894226, avg loss: 0.4393131136894226\n",
      "trial: 1, epoch, 9, iter: 200, curr loss: 0.43135637044906616, avg loss: 0.4292987401783466\n",
      "trial: 1, epoch, 10, iter: 1, curr loss: 0.4334929883480072, avg loss: 0.4334929883480072\n",
      "trial: 1, epoch, 10, iter: 200, curr loss: 0.43369683623313904, avg loss: 0.42917378574609755\n",
      "trial: 1, epoch, 11, iter: 1, curr loss: 0.41730043292045593, avg loss: 0.41730043292045593\n",
      "trial: 1, epoch, 11, iter: 200, curr loss: 0.4309925138950348, avg loss: 0.4291465459764004\n",
      "trial: 1, epoch, 12, iter: 1, curr loss: 0.43582600355148315, avg loss: 0.43582600355148315\n",
      "trial: 1, epoch, 12, iter: 200, curr loss: 0.42998287081718445, avg loss: 0.42911987885832786\n",
      "trial: 1, epoch, 13, iter: 1, curr loss: 0.42651063203811646, avg loss: 0.42651063203811646\n",
      "trial: 1, epoch, 13, iter: 200, curr loss: 0.43406036496162415, avg loss: 0.4291019381582737\n",
      "trial: 1, epoch, 14, iter: 1, curr loss: 0.4359115958213806, avg loss: 0.4359115958213806\n",
      "trial: 1, epoch, 14, iter: 200, curr loss: 0.43161195516586304, avg loss: 0.42915493190288545\n",
      "trial: 1, epoch, 15, iter: 1, curr loss: 0.4345242381095886, avg loss: 0.4345242381095886\n",
      "trial: 1, epoch, 15, iter: 200, curr loss: 0.43097972869873047, avg loss: 0.42872569113969805\n",
      "trial: 1, epoch, 16, iter: 1, curr loss: 0.4247181713581085, avg loss: 0.4247181713581085\n",
      "trial: 1, epoch, 16, iter: 200, curr loss: 0.44064682722091675, avg loss: 0.42909464210271836\n",
      "trial: 1, epoch, 17, iter: 1, curr loss: 0.4308259189128876, avg loss: 0.4308259189128876\n",
      "trial: 1, epoch, 17, iter: 200, curr loss: 0.42576301097869873, avg loss: 0.42863005176186564\n",
      "trial: 1, epoch, 18, iter: 1, curr loss: 0.43253883719444275, avg loss: 0.43253883719444275\n",
      "trial: 1, epoch, 18, iter: 200, curr loss: 0.4263172149658203, avg loss: 0.42918475151062013\n",
      "trial: 1, epoch, 19, iter: 1, curr loss: 0.42237603664398193, avg loss: 0.42237603664398193\n",
      "trial: 1, epoch, 19, iter: 200, curr loss: 0.4390714764595032, avg loss: 0.4287324933707714\n",
      "trial: 1, epoch, 20, iter: 1, curr loss: 0.4187660813331604, avg loss: 0.4187660813331604\n",
      "trial: 1, epoch, 20, iter: 200, curr loss: 0.43585726618766785, avg loss: 0.42916978523135185\n",
      "trial: 1, epoch, 21, iter: 1, curr loss: 0.42189887166023254, avg loss: 0.42189887166023254\n",
      "trial: 1, epoch, 21, iter: 200, curr loss: 0.4289471209049225, avg loss: 0.4280095015466213\n",
      "trial: 1, epoch, 22, iter: 1, curr loss: 0.42464643716812134, avg loss: 0.42464643716812134\n",
      "trial: 1, epoch, 22, iter: 200, curr loss: 0.4176066815853119, avg loss: 0.4286212702095509\n",
      "trial: 1, epoch, 23, iter: 1, curr loss: 0.43497541546821594, avg loss: 0.43497541546821594\n",
      "trial: 1, epoch, 23, iter: 200, curr loss: 0.427021324634552, avg loss: 0.4288326759636402\n",
      "trial: 1, epoch, 24, iter: 1, curr loss: 0.4319069981575012, avg loss: 0.4319069981575012\n",
      "trial: 1, epoch, 24, iter: 200, curr loss: 0.4285903573036194, avg loss: 0.429146086871624\n",
      "trial: 1, epoch, 25, iter: 1, curr loss: 0.4351484477519989, avg loss: 0.4351484477519989\n",
      "trial: 1, epoch, 25, iter: 200, curr loss: 0.43470555543899536, avg loss: 0.42891252756118775\n",
      "trial: 1, epoch, 26, iter: 1, curr loss: 0.43210452795028687, avg loss: 0.43210452795028687\n",
      "trial: 1, epoch, 26, iter: 200, curr loss: 0.42902109026908875, avg loss: 0.4283335167169571\n",
      "trial: 1, epoch, 27, iter: 1, curr loss: 0.42953670024871826, avg loss: 0.42953670024871826\n",
      "trial: 1, epoch, 27, iter: 200, curr loss: 0.4399394392967224, avg loss: 0.42901487946510314\n",
      "trial: 1, epoch, 28, iter: 1, curr loss: 0.42739632725715637, avg loss: 0.42739632725715637\n",
      "trial: 1, epoch, 28, iter: 200, curr loss: 0.42270177602767944, avg loss: 0.4287341156601906\n",
      "trial: 1, epoch, 29, iter: 1, curr loss: 0.43097245693206787, avg loss: 0.43097245693206787\n",
      "trial: 1, epoch, 29, iter: 200, curr loss: 0.44369202852249146, avg loss: 0.428920274078846\n",
      "trial: 1, epoch, 30, iter: 1, curr loss: 0.4369000196456909, avg loss: 0.4369000196456909\n",
      "trial: 1, epoch, 30, iter: 200, curr loss: 0.43386781215667725, avg loss: 0.4293985505402088\n",
      "trial: 1, epoch, 31, iter: 1, curr loss: 0.4300267696380615, avg loss: 0.4300267696380615\n",
      "trial: 1, epoch, 31, iter: 200, curr loss: 0.43516838550567627, avg loss: 0.42889604836702344\n",
      "trial: 1, epoch, 32, iter: 1, curr loss: 0.4305647015571594, avg loss: 0.4305647015571594\n",
      "trial: 1, epoch, 32, iter: 200, curr loss: 0.42056798934936523, avg loss: 0.4290612265467644\n",
      "trial: 1, epoch, 33, iter: 1, curr loss: 0.4327097535133362, avg loss: 0.4327097535133362\n",
      "trial: 1, epoch, 33, iter: 200, curr loss: 0.4270641803741455, avg loss: 0.4288713131844997\n",
      "trial: 1, epoch, 34, iter: 1, curr loss: 0.416405588388443, avg loss: 0.416405588388443\n",
      "trial: 1, epoch, 34, iter: 200, curr loss: 0.4244203269481659, avg loss: 0.4288620725274086\n",
      "trial: 1, epoch, 35, iter: 1, curr loss: 0.43825238943099976, avg loss: 0.43825238943099976\n",
      "trial: 1, epoch, 35, iter: 200, curr loss: 0.4328977167606354, avg loss: 0.42835218116641044\n",
      "trial: 1, epoch, 36, iter: 1, curr loss: 0.42624491453170776, avg loss: 0.42624491453170776\n",
      "trial: 1, epoch, 36, iter: 200, curr loss: 0.4209228754043579, avg loss: 0.42828722968697547\n",
      "trial: 1, epoch, 37, iter: 1, curr loss: 0.43065690994262695, avg loss: 0.43065690994262695\n",
      "trial: 1, epoch, 37, iter: 200, curr loss: 0.43629124760627747, avg loss: 0.4286565771698952\n",
      "trial: 1, epoch, 38, iter: 1, curr loss: 0.41911137104034424, avg loss: 0.41911137104034424\n",
      "trial: 1, epoch, 38, iter: 200, curr loss: 0.42754775285720825, avg loss: 0.4288259227573872\n",
      "trial: 1, epoch, 39, iter: 1, curr loss: 0.43307554721832275, avg loss: 0.43307554721832275\n",
      "trial: 1, epoch, 39, iter: 200, curr loss: 0.44397133588790894, avg loss: 0.4287005791068077\n",
      "trial: 1, epoch, 40, iter: 1, curr loss: 0.4350394010543823, avg loss: 0.4350394010543823\n",
      "trial: 1, epoch, 40, iter: 200, curr loss: 0.42324692010879517, avg loss: 0.4281732252240181\n",
      "trial: 1, epoch, 41, iter: 1, curr loss: 0.4364446997642517, avg loss: 0.4364446997642517\n",
      "trial: 1, epoch, 41, iter: 200, curr loss: 0.4286745488643646, avg loss: 0.4284470063447952\n",
      "trial: 1, epoch, 42, iter: 1, curr loss: 0.42858532071113586, avg loss: 0.42858532071113586\n",
      "trial: 1, epoch, 42, iter: 200, curr loss: 0.42336076498031616, avg loss: 0.42898745596408844\n",
      "trial: 1, epoch, 43, iter: 1, curr loss: 0.43536293506622314, avg loss: 0.43536293506622314\n",
      "trial: 1, epoch, 43, iter: 200, curr loss: 0.42653948068618774, avg loss: 0.4287781631946564\n",
      "trial: 1, epoch, 44, iter: 1, curr loss: 0.43982160091400146, avg loss: 0.43982160091400146\n",
      "trial: 1, epoch, 44, iter: 200, curr loss: 0.4350055456161499, avg loss: 0.42845932349562643\n",
      "trial: 1, epoch, 45, iter: 1, curr loss: 0.43599554896354675, avg loss: 0.43599554896354675\n",
      "trial: 1, epoch, 45, iter: 200, curr loss: 0.4392331838607788, avg loss: 0.4287809346616268\n",
      "trial: 1, epoch, 46, iter: 1, curr loss: 0.4299226999282837, avg loss: 0.4299226999282837\n",
      "trial: 1, epoch, 46, iter: 200, curr loss: 0.4358273446559906, avg loss: 0.4285696791112423\n",
      "trial: 1, epoch, 47, iter: 1, curr loss: 0.43148553371429443, avg loss: 0.43148553371429443\n",
      "trial: 1, epoch, 47, iter: 200, curr loss: 0.42729452252388, avg loss: 0.4290098199248314\n",
      "trial: 1, epoch, 48, iter: 1, curr loss: 0.4328837990760803, avg loss: 0.4328837990760803\n",
      "trial: 1, epoch, 48, iter: 200, curr loss: 0.44116300344467163, avg loss: 0.42841377153992655\n",
      "trial: 1, epoch, 49, iter: 1, curr loss: 0.43245837092399597, avg loss: 0.43245837092399597\n",
      "trial: 1, epoch, 49, iter: 200, curr loss: 0.43827158212661743, avg loss: 0.42892985478043555\n",
      "trial: 1, epoch, 50, iter: 1, curr loss: 0.42638301849365234, avg loss: 0.42638301849365234\n",
      "trial: 1, epoch, 50, iter: 200, curr loss: 0.43180638551712036, avg loss: 0.428677476644516\n",
      "trial: 1, ldr: 0.9110201597213745, dv: 0.9087951183319092, nwj: 0.9087926149368286\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, epoch, 1, iter: 1, curr loss: 0.6937545537948608, avg loss: 0.6937545537948608\n",
      "trial: 2, epoch, 1, iter: 200, curr loss: 0.4453613758087158, avg loss: 0.45822293117642404\n",
      "trial: 2, epoch, 2, iter: 1, curr loss: 0.42479920387268066, avg loss: 0.42479920387268066\n",
      "trial: 2, epoch, 2, iter: 200, curr loss: 0.4305359721183777, avg loss: 0.43059201911091805\n",
      "trial: 2, epoch, 3, iter: 1, curr loss: 0.4295008182525635, avg loss: 0.4295008182525635\n",
      "trial: 2, epoch, 3, iter: 200, curr loss: 0.4274711608886719, avg loss: 0.42937205359339714\n",
      "trial: 2, epoch, 4, iter: 1, curr loss: 0.4231104254722595, avg loss: 0.4231104254722595\n",
      "trial: 2, epoch, 4, iter: 200, curr loss: 0.4345475435256958, avg loss: 0.4295567962527275\n",
      "trial: 2, epoch, 5, iter: 1, curr loss: 0.42854660749435425, avg loss: 0.42854660749435425\n",
      "trial: 2, epoch, 5, iter: 200, curr loss: 0.4349648952484131, avg loss: 0.42929432466626166\n",
      "trial: 2, epoch, 6, iter: 1, curr loss: 0.42401355504989624, avg loss: 0.42401355504989624\n",
      "trial: 2, epoch, 6, iter: 200, curr loss: 0.4335021376609802, avg loss: 0.4296876884996891\n",
      "trial: 2, epoch, 7, iter: 1, curr loss: 0.41415661573410034, avg loss: 0.41415661573410034\n",
      "trial: 2, epoch, 7, iter: 200, curr loss: 0.43962475657463074, avg loss: 0.42916816666722296\n",
      "trial: 2, epoch, 8, iter: 1, curr loss: 0.43943309783935547, avg loss: 0.43943309783935547\n",
      "trial: 2, epoch, 8, iter: 200, curr loss: 0.4269786477088928, avg loss: 0.42920875653624535\n",
      "trial: 2, epoch, 9, iter: 1, curr loss: 0.425831139087677, avg loss: 0.425831139087677\n",
      "trial: 2, epoch, 9, iter: 200, curr loss: 0.4410266876220703, avg loss: 0.4292324462532997\n",
      "trial: 2, epoch, 10, iter: 1, curr loss: 0.4285767078399658, avg loss: 0.4285767078399658\n",
      "trial: 2, epoch, 10, iter: 200, curr loss: 0.44640859961509705, avg loss: 0.42925525829195976\n",
      "trial: 2, epoch, 11, iter: 1, curr loss: 0.42337656021118164, avg loss: 0.42337656021118164\n",
      "trial: 2, epoch, 11, iter: 200, curr loss: 0.4387744665145874, avg loss: 0.4285413156449795\n",
      "trial: 2, epoch, 12, iter: 1, curr loss: 0.4339561462402344, avg loss: 0.4339561462402344\n",
      "trial: 2, epoch, 12, iter: 200, curr loss: 0.42411771416664124, avg loss: 0.42903790980577466\n",
      "trial: 2, epoch, 13, iter: 1, curr loss: 0.42097538709640503, avg loss: 0.42097538709640503\n",
      "trial: 2, epoch, 13, iter: 200, curr loss: 0.4241441488265991, avg loss: 0.42909101366996766\n",
      "trial: 2, epoch, 14, iter: 1, curr loss: 0.44360607862472534, avg loss: 0.44360607862472534\n",
      "trial: 2, epoch, 14, iter: 200, curr loss: 0.4379635751247406, avg loss: 0.4287265196442604\n",
      "trial: 2, epoch, 15, iter: 1, curr loss: 0.44514086842536926, avg loss: 0.44514086842536926\n",
      "trial: 2, epoch, 15, iter: 200, curr loss: 0.437353253364563, avg loss: 0.4289972770214081\n",
      "trial: 2, epoch, 16, iter: 1, curr loss: 0.4325103759765625, avg loss: 0.4325103759765625\n",
      "trial: 2, epoch, 16, iter: 200, curr loss: 0.43556249141693115, avg loss: 0.4283681209385395\n",
      "trial: 2, epoch, 17, iter: 1, curr loss: 0.44152215123176575, avg loss: 0.44152215123176575\n",
      "trial: 2, epoch, 17, iter: 200, curr loss: 0.43014267086982727, avg loss: 0.4286910109221935\n",
      "trial: 2, epoch, 18, iter: 1, curr loss: 0.42596113681793213, avg loss: 0.42596113681793213\n",
      "trial: 2, epoch, 18, iter: 200, curr loss: 0.42655640840530396, avg loss: 0.42906561568379403\n",
      "trial: 2, epoch, 19, iter: 1, curr loss: 0.42617267370224, avg loss: 0.42617267370224\n",
      "trial: 2, epoch, 19, iter: 200, curr loss: 0.43501052260398865, avg loss: 0.4287175504863262\n",
      "trial: 2, epoch, 20, iter: 1, curr loss: 0.4290205240249634, avg loss: 0.4290205240249634\n",
      "trial: 2, epoch, 20, iter: 200, curr loss: 0.4373305141925812, avg loss: 0.428394525796175\n",
      "trial: 2, epoch, 21, iter: 1, curr loss: 0.4359363913536072, avg loss: 0.4359363913536072\n",
      "trial: 2, epoch, 21, iter: 200, curr loss: 0.4413177967071533, avg loss: 0.42917398080229757\n",
      "trial: 2, epoch, 22, iter: 1, curr loss: 0.4382743537425995, avg loss: 0.4382743537425995\n",
      "trial: 2, epoch, 22, iter: 200, curr loss: 0.4313536286354065, avg loss: 0.42829499319195746\n",
      "trial: 2, epoch, 23, iter: 1, curr loss: 0.4312725365161896, avg loss: 0.4312725365161896\n",
      "trial: 2, epoch, 23, iter: 200, curr loss: 0.435763955116272, avg loss: 0.4285749515891075\n",
      "trial: 2, epoch, 24, iter: 1, curr loss: 0.43812721967697144, avg loss: 0.43812721967697144\n",
      "trial: 2, epoch, 24, iter: 200, curr loss: 0.42587921023368835, avg loss: 0.42919013619422913\n",
      "trial: 2, epoch, 25, iter: 1, curr loss: 0.4255515933036804, avg loss: 0.4255515933036804\n",
      "trial: 2, epoch, 25, iter: 200, curr loss: 0.4404933452606201, avg loss: 0.4292237186431885\n",
      "trial: 2, epoch, 26, iter: 1, curr loss: 0.4331347644329071, avg loss: 0.4331347644329071\n",
      "trial: 2, epoch, 26, iter: 200, curr loss: 0.4477580189704895, avg loss: 0.4286784249544144\n",
      "trial: 2, epoch, 27, iter: 1, curr loss: 0.4347302317619324, avg loss: 0.4347302317619324\n",
      "trial: 2, epoch, 27, iter: 200, curr loss: 0.4298219084739685, avg loss: 0.4294029825925827\n",
      "trial: 2, epoch, 28, iter: 1, curr loss: 0.43624305725097656, avg loss: 0.43624305725097656\n",
      "trial: 2, epoch, 28, iter: 200, curr loss: 0.43323272466659546, avg loss: 0.42821272641420366\n",
      "trial: 2, epoch, 29, iter: 1, curr loss: 0.43293941020965576, avg loss: 0.43293941020965576\n",
      "trial: 2, epoch, 29, iter: 200, curr loss: 0.435562402009964, avg loss: 0.42860530853271483\n",
      "trial: 2, epoch, 30, iter: 1, curr loss: 0.4387008547782898, avg loss: 0.4387008547782898\n",
      "trial: 2, epoch, 30, iter: 200, curr loss: 0.4404444992542267, avg loss: 0.4292030701041222\n",
      "trial: 2, epoch, 31, iter: 1, curr loss: 0.4264718294143677, avg loss: 0.4264718294143677\n",
      "trial: 2, epoch, 31, iter: 200, curr loss: 0.42838364839553833, avg loss: 0.42902453035116195\n",
      "trial: 2, epoch, 32, iter: 1, curr loss: 0.4392825961112976, avg loss: 0.4392825961112976\n",
      "trial: 2, epoch, 32, iter: 200, curr loss: 0.4406753480434418, avg loss: 0.42932243660092356\n",
      "trial: 2, epoch, 33, iter: 1, curr loss: 0.42905908823013306, avg loss: 0.42905908823013306\n",
      "trial: 2, epoch, 33, iter: 200, curr loss: 0.41891759634017944, avg loss: 0.4287376423180103\n",
      "trial: 2, epoch, 34, iter: 1, curr loss: 0.4209875762462616, avg loss: 0.4209875762462616\n",
      "trial: 2, epoch, 34, iter: 200, curr loss: 0.4383472502231598, avg loss: 0.42812749147415163\n",
      "trial: 2, epoch, 35, iter: 1, curr loss: 0.4359029233455658, avg loss: 0.4359029233455658\n",
      "trial: 2, epoch, 35, iter: 200, curr loss: 0.42426633834838867, avg loss: 0.4290872031450272\n",
      "trial: 2, epoch, 36, iter: 1, curr loss: 0.43338000774383545, avg loss: 0.43338000774383545\n",
      "trial: 2, epoch, 36, iter: 200, curr loss: 0.43192794919013977, avg loss: 0.4288944262266159\n",
      "trial: 2, epoch, 37, iter: 1, curr loss: 0.4386093318462372, avg loss: 0.4386093318462372\n",
      "trial: 2, epoch, 37, iter: 200, curr loss: 0.42603641748428345, avg loss: 0.42896305069327356\n",
      "trial: 2, epoch, 38, iter: 1, curr loss: 0.4335741698741913, avg loss: 0.4335741698741913\n",
      "trial: 2, epoch, 38, iter: 200, curr loss: 0.4355021119117737, avg loss: 0.42908578023314475\n",
      "trial: 2, epoch, 39, iter: 1, curr loss: 0.43760383129119873, avg loss: 0.43760383129119873\n",
      "trial: 2, epoch, 39, iter: 200, curr loss: 0.4381045401096344, avg loss: 0.4284559789299965\n",
      "trial: 2, epoch, 40, iter: 1, curr loss: 0.43173283338546753, avg loss: 0.43173283338546753\n",
      "trial: 2, epoch, 40, iter: 200, curr loss: 0.4401378333568573, avg loss: 0.42870133817195893\n",
      "trial: 2, epoch, 41, iter: 1, curr loss: 0.42957887053489685, avg loss: 0.42957887053489685\n",
      "trial: 2, epoch, 41, iter: 200, curr loss: 0.42841386795043945, avg loss: 0.42834378555417063\n",
      "trial: 2, epoch, 42, iter: 1, curr loss: 0.4329287111759186, avg loss: 0.4329287111759186\n",
      "trial: 2, epoch, 42, iter: 200, curr loss: 0.4378587603569031, avg loss: 0.4290068855881691\n",
      "trial: 2, epoch, 43, iter: 1, curr loss: 0.4358017146587372, avg loss: 0.4358017146587372\n",
      "trial: 2, epoch, 43, iter: 200, curr loss: 0.4326018989086151, avg loss: 0.4286813089251518\n",
      "trial: 2, epoch, 44, iter: 1, curr loss: 0.43367308378219604, avg loss: 0.43367308378219604\n",
      "trial: 2, epoch, 44, iter: 200, curr loss: 0.4289045035839081, avg loss: 0.4288042443990707\n",
      "trial: 2, epoch, 45, iter: 1, curr loss: 0.44116711616516113, avg loss: 0.44116711616516113\n",
      "trial: 2, epoch, 45, iter: 200, curr loss: 0.4357452690601349, avg loss: 0.42948580652475354\n",
      "trial: 2, epoch, 46, iter: 1, curr loss: 0.4287494719028473, avg loss: 0.4287494719028473\n",
      "trial: 2, epoch, 46, iter: 200, curr loss: 0.43515974283218384, avg loss: 0.4290906585752964\n",
      "trial: 2, epoch, 47, iter: 1, curr loss: 0.4341031014919281, avg loss: 0.4341031014919281\n",
      "trial: 2, epoch, 47, iter: 200, curr loss: 0.4253150522708893, avg loss: 0.4293875376880169\n",
      "trial: 2, epoch, 48, iter: 1, curr loss: 0.43492764234542847, avg loss: 0.43492764234542847\n",
      "trial: 2, epoch, 48, iter: 200, curr loss: 0.4423544704914093, avg loss: 0.4296096256375313\n",
      "trial: 2, epoch, 49, iter: 1, curr loss: 0.4306095242500305, avg loss: 0.4306095242500305\n",
      "trial: 2, epoch, 49, iter: 200, curr loss: 0.41847479343414307, avg loss: 0.4281907944381237\n",
      "trial: 2, epoch, 50, iter: 1, curr loss: 0.4258585274219513, avg loss: 0.4258585274219513\n",
      "trial: 2, epoch, 50, iter: 200, curr loss: 0.4344080090522766, avg loss: 0.429303757250309\n",
      "trial: 2, ldr: 0.9155406951904297, dv: 0.9086450338363647, nwj: 0.9086211919784546\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, epoch, 1, iter: 1, curr loss: 0.693657636642456, avg loss: 0.693657636642456\n",
      "trial: 3, epoch, 1, iter: 200, curr loss: 0.42409610748291016, avg loss: 0.4571705359220505\n",
      "trial: 3, epoch, 2, iter: 1, curr loss: 0.4365578889846802, avg loss: 0.4365578889846802\n",
      "trial: 3, epoch, 2, iter: 200, curr loss: 0.4267978370189667, avg loss: 0.4303451718389988\n",
      "trial: 3, epoch, 3, iter: 1, curr loss: 0.4375844895839691, avg loss: 0.4375844895839691\n",
      "trial: 3, epoch, 3, iter: 200, curr loss: 0.4327211380004883, avg loss: 0.4293685220181942\n",
      "trial: 3, epoch, 4, iter: 1, curr loss: 0.42872512340545654, avg loss: 0.42872512340545654\n",
      "trial: 3, epoch, 4, iter: 200, curr loss: 0.43713274598121643, avg loss: 0.4293390102684498\n",
      "trial: 3, epoch, 5, iter: 1, curr loss: 0.43799859285354614, avg loss: 0.43799859285354614\n",
      "trial: 3, epoch, 5, iter: 200, curr loss: 0.4322114586830139, avg loss: 0.42890160575509073\n",
      "trial: 3, epoch, 6, iter: 1, curr loss: 0.42984163761138916, avg loss: 0.42984163761138916\n",
      "trial: 3, epoch, 6, iter: 200, curr loss: 0.42954403162002563, avg loss: 0.4288439905643463\n",
      "trial: 3, epoch, 7, iter: 1, curr loss: 0.420315146446228, avg loss: 0.420315146446228\n",
      "trial: 3, epoch, 7, iter: 200, curr loss: 0.4388475716114044, avg loss: 0.4291525700688362\n",
      "trial: 3, epoch, 8, iter: 1, curr loss: 0.42349106073379517, avg loss: 0.42349106073379517\n",
      "trial: 3, epoch, 8, iter: 200, curr loss: 0.432125985622406, avg loss: 0.42865747258067133\n",
      "trial: 3, epoch, 9, iter: 1, curr loss: 0.42767244577407837, avg loss: 0.42767244577407837\n",
      "trial: 3, epoch, 9, iter: 200, curr loss: 0.4243708848953247, avg loss: 0.4283861121535301\n",
      "trial: 3, epoch, 10, iter: 1, curr loss: 0.43648552894592285, avg loss: 0.43648552894592285\n",
      "trial: 3, epoch, 10, iter: 200, curr loss: 0.4453289806842804, avg loss: 0.4287636524438858\n",
      "trial: 3, epoch, 11, iter: 1, curr loss: 0.4353116750717163, avg loss: 0.4353116750717163\n",
      "trial: 3, epoch, 11, iter: 200, curr loss: 0.4263559579849243, avg loss: 0.4286000508069992\n",
      "trial: 3, epoch, 12, iter: 1, curr loss: 0.43544578552246094, avg loss: 0.43544578552246094\n",
      "trial: 3, epoch, 12, iter: 200, curr loss: 0.4170931577682495, avg loss: 0.42901794373989105\n",
      "trial: 3, epoch, 13, iter: 1, curr loss: 0.4271068572998047, avg loss: 0.4271068572998047\n",
      "trial: 3, epoch, 13, iter: 200, curr loss: 0.42883172631263733, avg loss: 0.42897044256329536\n",
      "trial: 3, epoch, 14, iter: 1, curr loss: 0.43983471393585205, avg loss: 0.43983471393585205\n",
      "trial: 3, epoch, 14, iter: 200, curr loss: 0.4260750412940979, avg loss: 0.4295060943067074\n",
      "trial: 3, epoch, 15, iter: 1, curr loss: 0.4349055290222168, avg loss: 0.4349055290222168\n",
      "trial: 3, epoch, 15, iter: 200, curr loss: 0.43542012572288513, avg loss: 0.42881364762783053\n",
      "trial: 3, epoch, 16, iter: 1, curr loss: 0.42949336767196655, avg loss: 0.42949336767196655\n",
      "trial: 3, epoch, 16, iter: 200, curr loss: 0.42605316638946533, avg loss: 0.42886962592601774\n",
      "trial: 3, epoch, 17, iter: 1, curr loss: 0.40950846672058105, avg loss: 0.40950846672058105\n",
      "trial: 3, epoch, 17, iter: 200, curr loss: 0.43899333477020264, avg loss: 0.4290871351957321\n",
      "trial: 3, epoch, 18, iter: 1, curr loss: 0.4410746693611145, avg loss: 0.4410746693611145\n",
      "trial: 3, epoch, 18, iter: 200, curr loss: 0.42716550827026367, avg loss: 0.42888460591435434\n",
      "trial: 3, epoch, 19, iter: 1, curr loss: 0.438137412071228, avg loss: 0.438137412071228\n",
      "trial: 3, epoch, 19, iter: 200, curr loss: 0.4294344186782837, avg loss: 0.4291467742621899\n",
      "trial: 3, epoch, 20, iter: 1, curr loss: 0.43105193972587585, avg loss: 0.43105193972587585\n",
      "trial: 3, epoch, 20, iter: 200, curr loss: 0.431843101978302, avg loss: 0.42871075108647344\n",
      "trial: 3, epoch, 21, iter: 1, curr loss: 0.4285469353199005, avg loss: 0.4285469353199005\n",
      "trial: 3, epoch, 21, iter: 200, curr loss: 0.4272458255290985, avg loss: 0.4284553489089012\n",
      "trial: 3, epoch, 22, iter: 1, curr loss: 0.4315093755722046, avg loss: 0.4315093755722046\n",
      "trial: 3, epoch, 22, iter: 200, curr loss: 0.42631593346595764, avg loss: 0.42888761520385743\n",
      "trial: 3, epoch, 23, iter: 1, curr loss: 0.42100322246551514, avg loss: 0.42100322246551514\n",
      "trial: 3, epoch, 23, iter: 200, curr loss: 0.4235694706439972, avg loss: 0.42800325646996495\n",
      "trial: 3, epoch, 24, iter: 1, curr loss: 0.427387535572052, avg loss: 0.427387535572052\n",
      "trial: 3, epoch, 24, iter: 200, curr loss: 0.4356200098991394, avg loss: 0.4289454072713852\n",
      "trial: 3, epoch, 25, iter: 1, curr loss: 0.4345308542251587, avg loss: 0.4345308542251587\n",
      "trial: 3, epoch, 25, iter: 200, curr loss: 0.4389073848724365, avg loss: 0.4288243792951107\n",
      "trial: 3, epoch, 26, iter: 1, curr loss: 0.42847707867622375, avg loss: 0.42847707867622375\n",
      "trial: 3, epoch, 26, iter: 200, curr loss: 0.4329812526702881, avg loss: 0.42883944779634475\n",
      "trial: 3, epoch, 27, iter: 1, curr loss: 0.42577219009399414, avg loss: 0.42577219009399414\n",
      "trial: 3, epoch, 27, iter: 200, curr loss: 0.4327971041202545, avg loss: 0.4287612934410572\n",
      "trial: 3, epoch, 28, iter: 1, curr loss: 0.4250781536102295, avg loss: 0.4250781536102295\n",
      "trial: 3, epoch, 28, iter: 200, curr loss: 0.44027847051620483, avg loss: 0.42861071780323984\n",
      "trial: 3, epoch, 29, iter: 1, curr loss: 0.4320261776447296, avg loss: 0.4320261776447296\n",
      "trial: 3, epoch, 29, iter: 200, curr loss: 0.44251444935798645, avg loss: 0.4289010736346245\n",
      "trial: 3, epoch, 30, iter: 1, curr loss: 0.4234939515590668, avg loss: 0.4234939515590668\n",
      "trial: 3, epoch, 30, iter: 200, curr loss: 0.4407985806465149, avg loss: 0.42822482690215113\n",
      "trial: 3, epoch, 31, iter: 1, curr loss: 0.4326387643814087, avg loss: 0.4326387643814087\n",
      "trial: 3, epoch, 31, iter: 200, curr loss: 0.43623650074005127, avg loss: 0.428499226719141\n",
      "trial: 3, epoch, 32, iter: 1, curr loss: 0.4301272928714752, avg loss: 0.4301272928714752\n",
      "trial: 3, epoch, 32, iter: 200, curr loss: 0.4278992712497711, avg loss: 0.42889189630746843\n",
      "trial: 3, epoch, 33, iter: 1, curr loss: 0.42852145433425903, avg loss: 0.42852145433425903\n",
      "trial: 3, epoch, 33, iter: 200, curr loss: 0.4296867549419403, avg loss: 0.4284262262284756\n",
      "trial: 3, epoch, 34, iter: 1, curr loss: 0.416986882686615, avg loss: 0.416986882686615\n",
      "trial: 3, epoch, 34, iter: 200, curr loss: 0.42881256341934204, avg loss: 0.42852121606469157\n",
      "trial: 3, epoch, 35, iter: 1, curr loss: 0.4337289333343506, avg loss: 0.4337289333343506\n",
      "trial: 3, epoch, 35, iter: 200, curr loss: 0.44448861479759216, avg loss: 0.429271569699049\n",
      "trial: 3, epoch, 36, iter: 1, curr loss: 0.4396444261074066, avg loss: 0.4396444261074066\n",
      "trial: 3, epoch, 36, iter: 200, curr loss: 0.4314000606536865, avg loss: 0.42830166295170785\n",
      "trial: 3, epoch, 37, iter: 1, curr loss: 0.42155784368515015, avg loss: 0.42155784368515015\n",
      "trial: 3, epoch, 37, iter: 200, curr loss: 0.4228624701499939, avg loss: 0.4287783323228359\n",
      "trial: 3, epoch, 38, iter: 1, curr loss: 0.4277564585208893, avg loss: 0.4277564585208893\n",
      "trial: 3, epoch, 38, iter: 200, curr loss: 0.418724924325943, avg loss: 0.429012526422739\n",
      "trial: 3, epoch, 39, iter: 1, curr loss: 0.42973703145980835, avg loss: 0.42973703145980835\n",
      "trial: 3, epoch, 39, iter: 200, curr loss: 0.4292357861995697, avg loss: 0.4280207911133766\n",
      "trial: 3, epoch, 40, iter: 1, curr loss: 0.43371278047561646, avg loss: 0.43371278047561646\n",
      "trial: 3, epoch, 40, iter: 200, curr loss: 0.4249253273010254, avg loss: 0.4286972600221634\n",
      "trial: 3, epoch, 41, iter: 1, curr loss: 0.43063271045684814, avg loss: 0.43063271045684814\n",
      "trial: 3, epoch, 41, iter: 200, curr loss: 0.42151403427124023, avg loss: 0.42916194915771483\n",
      "trial: 3, epoch, 42, iter: 1, curr loss: 0.4203052520751953, avg loss: 0.4203052520751953\n",
      "trial: 3, epoch, 42, iter: 200, curr loss: 0.4258359968662262, avg loss: 0.4285896869003773\n",
      "trial: 3, epoch, 43, iter: 1, curr loss: 0.4311252236366272, avg loss: 0.4311252236366272\n",
      "trial: 3, epoch, 43, iter: 200, curr loss: 0.44268837571144104, avg loss: 0.42883789494633673\n",
      "trial: 3, epoch, 44, iter: 1, curr loss: 0.42240455746650696, avg loss: 0.42240455746650696\n",
      "trial: 3, epoch, 44, iter: 200, curr loss: 0.43053898215293884, avg loss: 0.42904123187065124\n",
      "trial: 3, epoch, 45, iter: 1, curr loss: 0.4395027756690979, avg loss: 0.4395027756690979\n",
      "trial: 3, epoch, 45, iter: 200, curr loss: 0.42930877208709717, avg loss: 0.42898602232336996\n",
      "trial: 3, epoch, 46, iter: 1, curr loss: 0.4281766414642334, avg loss: 0.4281766414642334\n",
      "trial: 3, epoch, 46, iter: 200, curr loss: 0.4174012243747711, avg loss: 0.42901605769991874\n",
      "trial: 3, epoch, 47, iter: 1, curr loss: 0.4275050163269043, avg loss: 0.4275050163269043\n",
      "trial: 3, epoch, 47, iter: 200, curr loss: 0.4282979369163513, avg loss: 0.4283572290837765\n",
      "trial: 3, epoch, 48, iter: 1, curr loss: 0.42114803194999695, avg loss: 0.42114803194999695\n",
      "trial: 3, epoch, 48, iter: 200, curr loss: 0.4220081865787506, avg loss: 0.42888292208313944\n",
      "trial: 3, epoch, 49, iter: 1, curr loss: 0.4337611794471741, avg loss: 0.4337611794471741\n",
      "trial: 3, epoch, 49, iter: 200, curr loss: 0.4306495189666748, avg loss: 0.42879811123013495\n",
      "trial: 3, epoch, 50, iter: 1, curr loss: 0.44021689891815186, avg loss: 0.44021689891815186\n",
      "trial: 3, epoch, 50, iter: 200, curr loss: 0.43698325753211975, avg loss: 0.42863978430628774\n",
      "trial: 3, ldr: 0.878940761089325, dv: 0.9087679982185364, nwj: 0.908327579498291\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, epoch, 1, iter: 1, curr loss: 0.6949923038482666, avg loss: 0.6949923038482666\n",
      "trial: 4, epoch, 1, iter: 200, curr loss: 0.43828505277633667, avg loss: 0.4569877344369888\n",
      "trial: 4, epoch, 2, iter: 1, curr loss: 0.4393630027770996, avg loss: 0.4393630027770996\n",
      "trial: 4, epoch, 2, iter: 200, curr loss: 0.43534916639328003, avg loss: 0.4291461230814457\n",
      "trial: 4, epoch, 3, iter: 1, curr loss: 0.42337048053741455, avg loss: 0.42337048053741455\n",
      "trial: 4, epoch, 3, iter: 200, curr loss: 0.4307818114757538, avg loss: 0.429419272840023\n",
      "trial: 4, epoch, 4, iter: 1, curr loss: 0.4402453899383545, avg loss: 0.4402453899383545\n",
      "trial: 4, epoch, 4, iter: 200, curr loss: 0.43379971385002136, avg loss: 0.42930449441075325\n",
      "trial: 4, epoch, 5, iter: 1, curr loss: 0.43614301085472107, avg loss: 0.43614301085472107\n",
      "trial: 4, epoch, 5, iter: 200, curr loss: 0.42296072840690613, avg loss: 0.4288053061068058\n",
      "trial: 4, epoch, 6, iter: 1, curr loss: 0.4413996934890747, avg loss: 0.4413996934890747\n",
      "trial: 4, epoch, 6, iter: 200, curr loss: 0.4349246621131897, avg loss: 0.4284842735528946\n",
      "trial: 4, epoch, 7, iter: 1, curr loss: 0.43107977509498596, avg loss: 0.43107977509498596\n",
      "trial: 4, epoch, 7, iter: 200, curr loss: 0.4257488250732422, avg loss: 0.42886518716812133\n",
      "trial: 4, epoch, 8, iter: 1, curr loss: 0.4190271198749542, avg loss: 0.4190271198749542\n",
      "trial: 4, epoch, 8, iter: 200, curr loss: 0.43686407804489136, avg loss: 0.4289022135734558\n",
      "trial: 4, epoch, 9, iter: 1, curr loss: 0.4227430820465088, avg loss: 0.4227430820465088\n",
      "trial: 4, epoch, 9, iter: 200, curr loss: 0.43265867233276367, avg loss: 0.4291374859213829\n",
      "trial: 4, epoch, 10, iter: 1, curr loss: 0.423772931098938, avg loss: 0.423772931098938\n",
      "trial: 4, epoch, 10, iter: 200, curr loss: 0.4354621171951294, avg loss: 0.42878081306815147\n",
      "trial: 4, epoch, 11, iter: 1, curr loss: 0.4298858046531677, avg loss: 0.4298858046531677\n",
      "trial: 4, epoch, 11, iter: 200, curr loss: 0.4290579855442047, avg loss: 0.4288602389395237\n",
      "trial: 4, epoch, 12, iter: 1, curr loss: 0.43171054124832153, avg loss: 0.43171054124832153\n",
      "trial: 4, epoch, 12, iter: 200, curr loss: 0.4317381680011749, avg loss: 0.4287983313202858\n",
      "trial: 4, epoch, 13, iter: 1, curr loss: 0.42921990156173706, avg loss: 0.42921990156173706\n",
      "trial: 4, epoch, 13, iter: 200, curr loss: 0.43691664934158325, avg loss: 0.4286094219982624\n",
      "trial: 4, epoch, 14, iter: 1, curr loss: 0.43183302879333496, avg loss: 0.43183302879333496\n",
      "trial: 4, epoch, 14, iter: 200, curr loss: 0.42558032274246216, avg loss: 0.4288064494729042\n",
      "trial: 4, epoch, 15, iter: 1, curr loss: 0.4361145794391632, avg loss: 0.4361145794391632\n",
      "trial: 4, epoch, 15, iter: 200, curr loss: 0.4551405608654022, avg loss: 0.42896814897656443\n",
      "trial: 4, epoch, 16, iter: 1, curr loss: 0.43545079231262207, avg loss: 0.43545079231262207\n",
      "trial: 4, epoch, 16, iter: 200, curr loss: 0.4286367893218994, avg loss: 0.4280651618540287\n",
      "trial: 4, epoch, 17, iter: 1, curr loss: 0.4180262088775635, avg loss: 0.4180262088775635\n",
      "trial: 4, epoch, 17, iter: 200, curr loss: 0.43142902851104736, avg loss: 0.4287450757622719\n",
      "trial: 4, epoch, 18, iter: 1, curr loss: 0.42581602931022644, avg loss: 0.42581602931022644\n",
      "trial: 4, epoch, 18, iter: 200, curr loss: 0.43048250675201416, avg loss: 0.42870718076825143\n",
      "trial: 4, epoch, 19, iter: 1, curr loss: 0.4355461001396179, avg loss: 0.4355461001396179\n",
      "trial: 4, epoch, 19, iter: 200, curr loss: 0.43334025144577026, avg loss: 0.42878562420606614\n",
      "trial: 4, epoch, 20, iter: 1, curr loss: 0.4304383397102356, avg loss: 0.4304383397102356\n",
      "trial: 4, epoch, 20, iter: 200, curr loss: 0.42950159311294556, avg loss: 0.42887426778674126\n",
      "trial: 4, epoch, 21, iter: 1, curr loss: 0.42868125438690186, avg loss: 0.42868125438690186\n",
      "trial: 4, epoch, 21, iter: 200, curr loss: 0.4442140758037567, avg loss: 0.42881050929427145\n",
      "trial: 4, epoch, 22, iter: 1, curr loss: 0.4319600462913513, avg loss: 0.4319600462913513\n",
      "trial: 4, epoch, 22, iter: 200, curr loss: 0.435926616191864, avg loss: 0.4292686954140663\n",
      "trial: 4, epoch, 23, iter: 1, curr loss: 0.4234462082386017, avg loss: 0.4234462082386017\n",
      "trial: 4, epoch, 23, iter: 200, curr loss: 0.43323689699172974, avg loss: 0.42860171273350717\n",
      "trial: 4, epoch, 24, iter: 1, curr loss: 0.42935532331466675, avg loss: 0.42935532331466675\n",
      "trial: 4, epoch, 24, iter: 200, curr loss: 0.4374333620071411, avg loss: 0.42869350433349607\n",
      "trial: 4, epoch, 25, iter: 1, curr loss: 0.4241464138031006, avg loss: 0.4241464138031006\n",
      "trial: 4, epoch, 25, iter: 200, curr loss: 0.4244742691516876, avg loss: 0.4282538552582264\n",
      "trial: 4, epoch, 26, iter: 1, curr loss: 0.4196588099002838, avg loss: 0.4196588099002838\n",
      "trial: 4, epoch, 26, iter: 200, curr loss: 0.42648476362228394, avg loss: 0.42910670295357706\n",
      "trial: 4, epoch, 27, iter: 1, curr loss: 0.42522114515304565, avg loss: 0.42522114515304565\n",
      "trial: 4, epoch, 27, iter: 200, curr loss: 0.4319044351577759, avg loss: 0.42820650815963746\n",
      "trial: 4, epoch, 28, iter: 1, curr loss: 0.4449341297149658, avg loss: 0.4449341297149658\n",
      "trial: 4, epoch, 28, iter: 200, curr loss: 0.4228026270866394, avg loss: 0.42907575964927674\n",
      "trial: 4, epoch, 29, iter: 1, curr loss: 0.4221363663673401, avg loss: 0.4221363663673401\n",
      "trial: 4, epoch, 29, iter: 200, curr loss: 0.4360162913799286, avg loss: 0.428429162055254\n",
      "trial: 4, epoch, 30, iter: 1, curr loss: 0.4248020350933075, avg loss: 0.4248020350933075\n",
      "trial: 4, epoch, 30, iter: 200, curr loss: 0.4352012872695923, avg loss: 0.4291559475660324\n",
      "trial: 4, epoch, 31, iter: 1, curr loss: 0.4324324131011963, avg loss: 0.4324324131011963\n",
      "trial: 4, epoch, 31, iter: 200, curr loss: 0.4258509874343872, avg loss: 0.4284514024853706\n",
      "trial: 4, epoch, 32, iter: 1, curr loss: 0.4276503920555115, avg loss: 0.4276503920555115\n",
      "trial: 4, epoch, 32, iter: 200, curr loss: 0.4317663609981537, avg loss: 0.42898640006780625\n",
      "trial: 4, epoch, 33, iter: 1, curr loss: 0.4329952001571655, avg loss: 0.4329952001571655\n",
      "trial: 4, epoch, 33, iter: 200, curr loss: 0.4309462308883667, avg loss: 0.429057754278183\n",
      "trial: 4, epoch, 34, iter: 1, curr loss: 0.43227335810661316, avg loss: 0.43227335810661316\n",
      "trial: 4, epoch, 34, iter: 200, curr loss: 0.4266308546066284, avg loss: 0.42815819174051284\n",
      "trial: 4, epoch, 35, iter: 1, curr loss: 0.43664273619651794, avg loss: 0.43664273619651794\n",
      "trial: 4, epoch, 35, iter: 200, curr loss: 0.439583420753479, avg loss: 0.4284232664108276\n",
      "trial: 4, epoch, 36, iter: 1, curr loss: 0.42914289236068726, avg loss: 0.42914289236068726\n",
      "trial: 4, epoch, 36, iter: 200, curr loss: 0.4184432625770569, avg loss: 0.42883946031332015\n",
      "trial: 4, epoch, 37, iter: 1, curr loss: 0.4275265336036682, avg loss: 0.4275265336036682\n",
      "trial: 4, epoch, 37, iter: 200, curr loss: 0.42848849296569824, avg loss: 0.4286979115009308\n",
      "trial: 4, epoch, 38, iter: 1, curr loss: 0.41262537240982056, avg loss: 0.41262537240982056\n",
      "trial: 4, epoch, 38, iter: 200, curr loss: 0.4259603023529053, avg loss: 0.4288299797475338\n",
      "trial: 4, epoch, 39, iter: 1, curr loss: 0.4286908507347107, avg loss: 0.4286908507347107\n",
      "trial: 4, epoch, 39, iter: 200, curr loss: 0.42634329199790955, avg loss: 0.42903231710195544\n",
      "trial: 4, epoch, 40, iter: 1, curr loss: 0.44027167558670044, avg loss: 0.44027167558670044\n",
      "trial: 4, epoch, 40, iter: 200, curr loss: 0.4350900650024414, avg loss: 0.4284710265696049\n",
      "trial: 4, epoch, 41, iter: 1, curr loss: 0.43771737813949585, avg loss: 0.43771737813949585\n",
      "trial: 4, epoch, 41, iter: 200, curr loss: 0.43008747696876526, avg loss: 0.42867925435304643\n",
      "trial: 4, epoch, 42, iter: 1, curr loss: 0.4297357201576233, avg loss: 0.4297357201576233\n",
      "trial: 4, epoch, 42, iter: 200, curr loss: 0.42844870686531067, avg loss: 0.4286078958213329\n",
      "trial: 4, epoch, 43, iter: 1, curr loss: 0.4302462935447693, avg loss: 0.4302462935447693\n",
      "trial: 4, epoch, 43, iter: 200, curr loss: 0.42492347955703735, avg loss: 0.42891147032380106\n",
      "trial: 4, epoch, 44, iter: 1, curr loss: 0.42670512199401855, avg loss: 0.42670512199401855\n",
      "trial: 4, epoch, 44, iter: 200, curr loss: 0.4382752776145935, avg loss: 0.42836290910840036\n",
      "trial: 4, epoch, 45, iter: 1, curr loss: 0.41576385498046875, avg loss: 0.41576385498046875\n",
      "trial: 4, epoch, 45, iter: 200, curr loss: 0.4261660873889923, avg loss: 0.4285929535329342\n",
      "trial: 4, epoch, 46, iter: 1, curr loss: 0.4368615746498108, avg loss: 0.4368615746498108\n",
      "trial: 4, epoch, 46, iter: 200, curr loss: 0.4416133165359497, avg loss: 0.42876476407051084\n",
      "trial: 4, epoch, 47, iter: 1, curr loss: 0.44081780314445496, avg loss: 0.44081780314445496\n",
      "trial: 4, epoch, 47, iter: 200, curr loss: 0.4322395324707031, avg loss: 0.4288447241485119\n",
      "trial: 4, epoch, 48, iter: 1, curr loss: 0.42294633388519287, avg loss: 0.42294633388519287\n",
      "trial: 4, epoch, 48, iter: 200, curr loss: 0.43289124965667725, avg loss: 0.4289044666290283\n",
      "trial: 4, epoch, 49, iter: 1, curr loss: 0.43499821424484253, avg loss: 0.43499821424484253\n",
      "trial: 4, epoch, 49, iter: 200, curr loss: 0.4431353807449341, avg loss: 0.42875787302851676\n",
      "trial: 4, epoch, 50, iter: 1, curr loss: 0.42449134588241577, avg loss: 0.42449134588241577\n",
      "trial: 4, epoch, 50, iter: 200, curr loss: 0.4300708770751953, avg loss: 0.4285580176115036\n",
      "trial: 4, ldr: 0.9266800284385681, dv: 0.9084411263465881, nwj: 0.9082737565040588\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, epoch, 1, iter: 1, curr loss: 0.693271279335022, avg loss: 0.693271279335022\n",
      "trial: 5, epoch, 1, iter: 200, curr loss: 0.4356215298175812, avg loss: 0.45535132989287375\n",
      "trial: 5, epoch, 2, iter: 1, curr loss: 0.42496374249458313, avg loss: 0.42496374249458313\n",
      "trial: 5, epoch, 2, iter: 200, curr loss: 0.4404233694076538, avg loss: 0.4306999433040619\n",
      "trial: 5, epoch, 3, iter: 1, curr loss: 0.42633336782455444, avg loss: 0.42633336782455444\n",
      "trial: 5, epoch, 3, iter: 200, curr loss: 0.43962323665618896, avg loss: 0.4289859649538994\n",
      "trial: 5, epoch, 4, iter: 1, curr loss: 0.4355621337890625, avg loss: 0.4355621337890625\n",
      "trial: 5, epoch, 4, iter: 200, curr loss: 0.4257764220237732, avg loss: 0.4287830327451229\n",
      "trial: 5, epoch, 5, iter: 1, curr loss: 0.425915390253067, avg loss: 0.425915390253067\n",
      "trial: 5, epoch, 5, iter: 200, curr loss: 0.4304138123989105, avg loss: 0.4289670649170876\n",
      "trial: 5, epoch, 6, iter: 1, curr loss: 0.4249580502510071, avg loss: 0.4249580502510071\n",
      "trial: 5, epoch, 6, iter: 200, curr loss: 0.41313013434410095, avg loss: 0.42948117703199384\n",
      "trial: 5, epoch, 7, iter: 1, curr loss: 0.43719083070755005, avg loss: 0.43719083070755005\n",
      "trial: 5, epoch, 7, iter: 200, curr loss: 0.4318116307258606, avg loss: 0.42842881083488465\n",
      "trial: 5, epoch, 8, iter: 1, curr loss: 0.4282531440258026, avg loss: 0.4282531440258026\n",
      "trial: 5, epoch, 8, iter: 200, curr loss: 0.435273140668869, avg loss: 0.42941524550318716\n",
      "trial: 5, epoch, 9, iter: 1, curr loss: 0.4186933636665344, avg loss: 0.4186933636665344\n",
      "trial: 5, epoch, 9, iter: 200, curr loss: 0.4207518994808197, avg loss: 0.4289633795619011\n",
      "trial: 5, epoch, 10, iter: 1, curr loss: 0.42058420181274414, avg loss: 0.42058420181274414\n",
      "trial: 5, epoch, 10, iter: 200, curr loss: 0.4415363073348999, avg loss: 0.4285390095412731\n",
      "trial: 5, epoch, 11, iter: 1, curr loss: 0.44128984212875366, avg loss: 0.44128984212875366\n",
      "trial: 5, epoch, 11, iter: 200, curr loss: 0.4306778907775879, avg loss: 0.4287844805419445\n",
      "trial: 5, epoch, 12, iter: 1, curr loss: 0.4281626343727112, avg loss: 0.4281626343727112\n",
      "trial: 5, epoch, 12, iter: 200, curr loss: 0.4147934317588806, avg loss: 0.429078032374382\n",
      "trial: 5, epoch, 13, iter: 1, curr loss: 0.4367922842502594, avg loss: 0.4367922842502594\n",
      "trial: 5, epoch, 13, iter: 200, curr loss: 0.43169254064559937, avg loss: 0.42879540488123896\n",
      "trial: 5, epoch, 14, iter: 1, curr loss: 0.42501816153526306, avg loss: 0.42501816153526306\n",
      "trial: 5, epoch, 14, iter: 200, curr loss: 0.4384515881538391, avg loss: 0.4284770427644253\n",
      "trial: 5, epoch, 15, iter: 1, curr loss: 0.42387673258781433, avg loss: 0.42387673258781433\n",
      "trial: 5, epoch, 15, iter: 200, curr loss: 0.43530821800231934, avg loss: 0.42909072995185854\n",
      "trial: 5, epoch, 16, iter: 1, curr loss: 0.4342591464519501, avg loss: 0.4342591464519501\n",
      "trial: 5, epoch, 16, iter: 200, curr loss: 0.4443424642086029, avg loss: 0.4290404491126537\n",
      "trial: 5, epoch, 17, iter: 1, curr loss: 0.42516788840293884, avg loss: 0.42516788840293884\n",
      "trial: 5, epoch, 17, iter: 200, curr loss: 0.4302622973918915, avg loss: 0.42914527654647827\n",
      "trial: 5, epoch, 18, iter: 1, curr loss: 0.42789676785469055, avg loss: 0.42789676785469055\n",
      "trial: 5, epoch, 18, iter: 200, curr loss: 0.43310633301734924, avg loss: 0.4286798293888569\n",
      "trial: 5, epoch, 19, iter: 1, curr loss: 0.4269893765449524, avg loss: 0.4269893765449524\n",
      "trial: 5, epoch, 19, iter: 200, curr loss: 0.44041991233825684, avg loss: 0.4289707177877426\n",
      "trial: 5, epoch, 20, iter: 1, curr loss: 0.4344174265861511, avg loss: 0.4344174265861511\n",
      "trial: 5, epoch, 20, iter: 200, curr loss: 0.43177735805511475, avg loss: 0.42844506666064264\n",
      "trial: 5, epoch, 21, iter: 1, curr loss: 0.42397427558898926, avg loss: 0.42397427558898926\n",
      "trial: 5, epoch, 21, iter: 200, curr loss: 0.4234151840209961, avg loss: 0.4287735597789288\n",
      "trial: 5, epoch, 22, iter: 1, curr loss: 0.4303424060344696, avg loss: 0.4303424060344696\n",
      "trial: 5, epoch, 22, iter: 200, curr loss: 0.42620131373405457, avg loss: 0.4289896149933338\n",
      "trial: 5, epoch, 23, iter: 1, curr loss: 0.4352782368659973, avg loss: 0.4352782368659973\n",
      "trial: 5, epoch, 23, iter: 200, curr loss: 0.42486003041267395, avg loss: 0.42904317915439605\n",
      "trial: 5, epoch, 24, iter: 1, curr loss: 0.42266207933425903, avg loss: 0.42266207933425903\n",
      "trial: 5, epoch, 24, iter: 200, curr loss: 0.4456576108932495, avg loss: 0.42877810686826706\n",
      "trial: 5, epoch, 25, iter: 1, curr loss: 0.4328341484069824, avg loss: 0.4328341484069824\n",
      "trial: 5, epoch, 25, iter: 200, curr loss: 0.4215404689311981, avg loss: 0.4291469545662403\n",
      "trial: 5, epoch, 26, iter: 1, curr loss: 0.42894357442855835, avg loss: 0.42894357442855835\n",
      "trial: 5, epoch, 26, iter: 200, curr loss: 0.44502419233322144, avg loss: 0.4285368379950523\n",
      "trial: 5, epoch, 27, iter: 1, curr loss: 0.42696213722229004, avg loss: 0.42696213722229004\n",
      "trial: 5, epoch, 27, iter: 200, curr loss: 0.4306405186653137, avg loss: 0.4294547025859356\n",
      "trial: 5, epoch, 28, iter: 1, curr loss: 0.4366323947906494, avg loss: 0.4366323947906494\n",
      "trial: 5, epoch, 28, iter: 200, curr loss: 0.43187379837036133, avg loss: 0.4290938962996006\n",
      "trial: 5, epoch, 29, iter: 1, curr loss: 0.41933292150497437, avg loss: 0.41933292150497437\n",
      "trial: 5, epoch, 29, iter: 200, curr loss: 0.44016921520233154, avg loss: 0.42893665581941604\n",
      "trial: 5, epoch, 30, iter: 1, curr loss: 0.42779970169067383, avg loss: 0.42779970169067383\n",
      "trial: 5, epoch, 30, iter: 200, curr loss: 0.4259960651397705, avg loss: 0.4287329867482185\n",
      "trial: 5, epoch, 31, iter: 1, curr loss: 0.4392910301685333, avg loss: 0.4392910301685333\n",
      "trial: 5, epoch, 31, iter: 200, curr loss: 0.426827073097229, avg loss: 0.42825860500335694\n",
      "trial: 5, epoch, 32, iter: 1, curr loss: 0.42809197306632996, avg loss: 0.42809197306632996\n",
      "trial: 5, epoch, 32, iter: 200, curr loss: 0.43756529688835144, avg loss: 0.4290232917666435\n",
      "trial: 5, epoch, 33, iter: 1, curr loss: 0.4315055012702942, avg loss: 0.4315055012702942\n",
      "trial: 5, epoch, 33, iter: 200, curr loss: 0.4243829846382141, avg loss: 0.42837144181132314\n",
      "trial: 5, epoch, 34, iter: 1, curr loss: 0.4299931228160858, avg loss: 0.4299931228160858\n",
      "trial: 5, epoch, 34, iter: 200, curr loss: 0.4160304069519043, avg loss: 0.4289602561295032\n",
      "trial: 5, epoch, 35, iter: 1, curr loss: 0.4267670512199402, avg loss: 0.4267670512199402\n",
      "trial: 5, epoch, 35, iter: 200, curr loss: 0.42967361211776733, avg loss: 0.42854575008153917\n",
      "trial: 5, epoch, 36, iter: 1, curr loss: 0.4367738366127014, avg loss: 0.4367738366127014\n",
      "trial: 5, epoch, 36, iter: 200, curr loss: 0.43494918942451477, avg loss: 0.42880664676427843\n",
      "trial: 5, epoch, 37, iter: 1, curr loss: 0.41971343755722046, avg loss: 0.41971343755722046\n",
      "trial: 5, epoch, 37, iter: 200, curr loss: 0.432400643825531, avg loss: 0.42844160452485086\n",
      "trial: 5, epoch, 38, iter: 1, curr loss: 0.43152785301208496, avg loss: 0.43152785301208496\n",
      "trial: 5, epoch, 38, iter: 200, curr loss: 0.4365226626396179, avg loss: 0.4289247593283653\n",
      "trial: 5, epoch, 39, iter: 1, curr loss: 0.4286198914051056, avg loss: 0.4286198914051056\n",
      "trial: 5, epoch, 39, iter: 200, curr loss: 0.4274032711982727, avg loss: 0.42930414140224454\n",
      "trial: 5, epoch, 40, iter: 1, curr loss: 0.42861831188201904, avg loss: 0.42861831188201904\n",
      "trial: 5, epoch, 40, iter: 200, curr loss: 0.42409393191337585, avg loss: 0.4289737768471241\n",
      "trial: 5, epoch, 41, iter: 1, curr loss: 0.4301874041557312, avg loss: 0.4301874041557312\n",
      "trial: 5, epoch, 41, iter: 200, curr loss: 0.433672696352005, avg loss: 0.428654495626688\n",
      "trial: 5, epoch, 42, iter: 1, curr loss: 0.4282309412956238, avg loss: 0.4282309412956238\n",
      "trial: 5, epoch, 42, iter: 200, curr loss: 0.42748144268989563, avg loss: 0.4286376743018627\n",
      "trial: 5, epoch, 43, iter: 1, curr loss: 0.43285566568374634, avg loss: 0.43285566568374634\n",
      "trial: 5, epoch, 43, iter: 200, curr loss: 0.4152708053588867, avg loss: 0.4285924144089222\n",
      "trial: 5, epoch, 44, iter: 1, curr loss: 0.43790560960769653, avg loss: 0.43790560960769653\n",
      "trial: 5, epoch, 44, iter: 200, curr loss: 0.42561715841293335, avg loss: 0.42864311739802363\n",
      "trial: 5, epoch, 45, iter: 1, curr loss: 0.4155066907405853, avg loss: 0.4155066907405853\n",
      "trial: 5, epoch, 45, iter: 200, curr loss: 0.42986440658569336, avg loss: 0.42860486507415774\n",
      "trial: 5, epoch, 46, iter: 1, curr loss: 0.4219895899295807, avg loss: 0.4219895899295807\n",
      "trial: 5, epoch, 46, iter: 200, curr loss: 0.434065580368042, avg loss: 0.42873160764575\n",
      "trial: 5, epoch, 47, iter: 1, curr loss: 0.42450809478759766, avg loss: 0.42450809478759766\n",
      "trial: 5, epoch, 47, iter: 200, curr loss: 0.43091318011283875, avg loss: 0.4286423450708389\n",
      "trial: 5, epoch, 48, iter: 1, curr loss: 0.4313962459564209, avg loss: 0.4313962459564209\n",
      "trial: 5, epoch, 48, iter: 200, curr loss: 0.43610310554504395, avg loss: 0.4290253859758377\n",
      "trial: 5, epoch, 49, iter: 1, curr loss: 0.4325256645679474, avg loss: 0.4325256645679474\n",
      "trial: 5, epoch, 49, iter: 200, curr loss: 0.43462181091308594, avg loss: 0.42901826098561285\n",
      "trial: 5, epoch, 50, iter: 1, curr loss: 0.4291936159133911, avg loss: 0.4291936159133911\n",
      "trial: 5, epoch, 50, iter: 200, curr loss: 0.4418105483055115, avg loss: 0.4290227496623993\n",
      "trial: 5, ldr: 0.9214947819709778, dv: 0.9087039828300476, nwj: 0.9086218476295471\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 6, epoch, 1, iter: 1, curr loss: 0.6938400268554688, avg loss: 0.6938400268554688\n",
      "trial: 6, epoch, 1, iter: 200, curr loss: 0.43933892250061035, avg loss: 0.45702118635177613\n",
      "trial: 6, epoch, 2, iter: 1, curr loss: 0.4257694482803345, avg loss: 0.4257694482803345\n",
      "trial: 6, epoch, 2, iter: 200, curr loss: 0.43182432651519775, avg loss: 0.4306369985640049\n",
      "trial: 6, epoch, 3, iter: 1, curr loss: 0.42943865060806274, avg loss: 0.42943865060806274\n",
      "trial: 6, epoch, 3, iter: 200, curr loss: 0.43109557032585144, avg loss: 0.4293993699550629\n",
      "trial: 6, epoch, 4, iter: 1, curr loss: 0.4297374486923218, avg loss: 0.4297374486923218\n",
      "trial: 6, epoch, 4, iter: 200, curr loss: 0.43492627143859863, avg loss: 0.4288491363823414\n",
      "trial: 6, epoch, 5, iter: 1, curr loss: 0.44857272505760193, avg loss: 0.44857272505760193\n",
      "trial: 6, epoch, 5, iter: 200, curr loss: 0.43958622217178345, avg loss: 0.4288186402618885\n",
      "trial: 6, epoch, 6, iter: 1, curr loss: 0.4280075430870056, avg loss: 0.4280075430870056\n",
      "trial: 6, epoch, 6, iter: 200, curr loss: 0.4264370799064636, avg loss: 0.4288336943089962\n",
      "trial: 6, epoch, 7, iter: 1, curr loss: 0.42873018980026245, avg loss: 0.42873018980026245\n",
      "trial: 6, epoch, 7, iter: 200, curr loss: 0.43608200550079346, avg loss: 0.4285417540371418\n",
      "trial: 6, epoch, 8, iter: 1, curr loss: 0.44000375270843506, avg loss: 0.44000375270843506\n",
      "trial: 6, epoch, 8, iter: 200, curr loss: 0.42682066559791565, avg loss: 0.4284131325781345\n",
      "trial: 6, epoch, 9, iter: 1, curr loss: 0.4350730776786804, avg loss: 0.4350730776786804\n",
      "trial: 6, epoch, 9, iter: 200, curr loss: 0.4305573105812073, avg loss: 0.428466065376997\n",
      "trial: 6, epoch, 10, iter: 1, curr loss: 0.434477835893631, avg loss: 0.434477835893631\n",
      "trial: 6, epoch, 10, iter: 200, curr loss: 0.4351051449775696, avg loss: 0.42886165112257\n",
      "trial: 6, epoch, 11, iter: 1, curr loss: 0.42479202151298523, avg loss: 0.42479202151298523\n",
      "trial: 6, epoch, 11, iter: 200, curr loss: 0.43192002177238464, avg loss: 0.4287344099581242\n",
      "trial: 6, epoch, 12, iter: 1, curr loss: 0.4248833954334259, avg loss: 0.4248833954334259\n",
      "trial: 6, epoch, 12, iter: 200, curr loss: 0.4359259605407715, avg loss: 0.4290170778334141\n",
      "trial: 6, epoch, 13, iter: 1, curr loss: 0.4415176510810852, avg loss: 0.4415176510810852\n",
      "trial: 6, epoch, 13, iter: 200, curr loss: 0.42683905363082886, avg loss: 0.4287948633730412\n",
      "trial: 6, epoch, 14, iter: 1, curr loss: 0.4407118558883667, avg loss: 0.4407118558883667\n",
      "trial: 6, epoch, 14, iter: 200, curr loss: 0.44018101692199707, avg loss: 0.42867093995213507\n",
      "trial: 6, epoch, 15, iter: 1, curr loss: 0.43473321199417114, avg loss: 0.43473321199417114\n",
      "trial: 6, epoch, 15, iter: 200, curr loss: 0.4397367238998413, avg loss: 0.42839921951293947\n",
      "trial: 6, epoch, 16, iter: 1, curr loss: 0.43490350246429443, avg loss: 0.43490350246429443\n",
      "trial: 6, epoch, 16, iter: 200, curr loss: 0.4377378225326538, avg loss: 0.42938037678599356\n",
      "trial: 6, epoch, 17, iter: 1, curr loss: 0.4362366497516632, avg loss: 0.4362366497516632\n",
      "trial: 6, epoch, 17, iter: 200, curr loss: 0.42479896545410156, avg loss: 0.4292587120831013\n",
      "trial: 6, epoch, 18, iter: 1, curr loss: 0.41844987869262695, avg loss: 0.41844987869262695\n",
      "trial: 6, epoch, 18, iter: 200, curr loss: 0.42788344621658325, avg loss: 0.4284670853614807\n",
      "trial: 6, epoch, 19, iter: 1, curr loss: 0.4274669885635376, avg loss: 0.4274669885635376\n",
      "trial: 6, epoch, 19, iter: 200, curr loss: 0.438180148601532, avg loss: 0.42867139682173727\n",
      "trial: 6, epoch, 20, iter: 1, curr loss: 0.4277142286300659, avg loss: 0.4277142286300659\n",
      "trial: 6, epoch, 20, iter: 200, curr loss: 0.4254908263683319, avg loss: 0.42987557128071785\n",
      "trial: 6, epoch, 21, iter: 1, curr loss: 0.4192470908164978, avg loss: 0.4192470908164978\n",
      "trial: 6, epoch, 21, iter: 200, curr loss: 0.4368543326854706, avg loss: 0.42812886342406276\n",
      "trial: 6, epoch, 22, iter: 1, curr loss: 0.43038830161094666, avg loss: 0.43038830161094666\n",
      "trial: 6, epoch, 22, iter: 200, curr loss: 0.42694684863090515, avg loss: 0.42836317390203477\n",
      "trial: 6, epoch, 23, iter: 1, curr loss: 0.43847331404685974, avg loss: 0.43847331404685974\n",
      "trial: 6, epoch, 23, iter: 200, curr loss: 0.4435044825077057, avg loss: 0.4279728695750237\n",
      "trial: 6, epoch, 24, iter: 1, curr loss: 0.42894092202186584, avg loss: 0.42894092202186584\n",
      "trial: 6, epoch, 24, iter: 200, curr loss: 0.4322800040245056, avg loss: 0.42875716343522075\n",
      "trial: 6, epoch, 25, iter: 1, curr loss: 0.429910808801651, avg loss: 0.429910808801651\n",
      "trial: 6, epoch, 25, iter: 200, curr loss: 0.4355403184890747, avg loss: 0.42882839202880857\n",
      "trial: 6, epoch, 26, iter: 1, curr loss: 0.43944504857063293, avg loss: 0.43944504857063293\n",
      "trial: 6, epoch, 26, iter: 200, curr loss: 0.42770057916641235, avg loss: 0.42879490807652476\n",
      "trial: 6, epoch, 27, iter: 1, curr loss: 0.433912992477417, avg loss: 0.433912992477417\n",
      "trial: 6, epoch, 27, iter: 200, curr loss: 0.4189787805080414, avg loss: 0.42887418627738955\n",
      "trial: 6, epoch, 28, iter: 1, curr loss: 0.4435656666755676, avg loss: 0.4435656666755676\n",
      "trial: 6, epoch, 28, iter: 200, curr loss: 0.4407193660736084, avg loss: 0.42835320711135866\n",
      "trial: 6, epoch, 29, iter: 1, curr loss: 0.4353299140930176, avg loss: 0.4353299140930176\n",
      "trial: 6, epoch, 29, iter: 200, curr loss: 0.4361388087272644, avg loss: 0.42881805524230004\n",
      "trial: 6, epoch, 30, iter: 1, curr loss: 0.4289644956588745, avg loss: 0.4289644956588745\n",
      "trial: 6, epoch, 30, iter: 200, curr loss: 0.4325735569000244, avg loss: 0.42940145149827\n",
      "trial: 6, epoch, 31, iter: 1, curr loss: 0.4393276870250702, avg loss: 0.4393276870250702\n",
      "trial: 6, epoch, 31, iter: 200, curr loss: 0.4365931749343872, avg loss: 0.42857304885983466\n",
      "trial: 6, epoch, 32, iter: 1, curr loss: 0.4273010492324829, avg loss: 0.4273010492324829\n",
      "trial: 6, epoch, 32, iter: 200, curr loss: 0.43500977754592896, avg loss: 0.42880217388272285\n",
      "trial: 6, epoch, 33, iter: 1, curr loss: 0.42863723635673523, avg loss: 0.42863723635673523\n",
      "trial: 6, epoch, 33, iter: 200, curr loss: 0.43467530608177185, avg loss: 0.42887636736035345\n",
      "trial: 6, epoch, 34, iter: 1, curr loss: 0.4227808117866516, avg loss: 0.4227808117866516\n",
      "trial: 6, epoch, 34, iter: 200, curr loss: 0.43269413709640503, avg loss: 0.42838791012763977\n",
      "trial: 6, epoch, 35, iter: 1, curr loss: 0.4185122847557068, avg loss: 0.4185122847557068\n",
      "trial: 6, epoch, 35, iter: 200, curr loss: 0.4311104416847229, avg loss: 0.4281513583660126\n",
      "trial: 6, epoch, 36, iter: 1, curr loss: 0.433042049407959, avg loss: 0.433042049407959\n",
      "trial: 6, epoch, 36, iter: 200, curr loss: 0.4329473376274109, avg loss: 0.42815622091293337\n",
      "trial: 6, epoch, 37, iter: 1, curr loss: 0.4269275963306427, avg loss: 0.4269275963306427\n",
      "trial: 6, epoch, 37, iter: 200, curr loss: 0.43387043476104736, avg loss: 0.429972737878561\n",
      "trial: 6, epoch, 38, iter: 1, curr loss: 0.43808406591415405, avg loss: 0.43808406591415405\n",
      "trial: 6, epoch, 38, iter: 200, curr loss: 0.43394240736961365, avg loss: 0.4285968044400215\n",
      "trial: 6, epoch, 39, iter: 1, curr loss: 0.4291992485523224, avg loss: 0.4291992485523224\n",
      "trial: 6, epoch, 39, iter: 200, curr loss: 0.4212782084941864, avg loss: 0.42864818006753924\n",
      "trial: 6, epoch, 40, iter: 1, curr loss: 0.42109617590904236, avg loss: 0.42109617590904236\n",
      "trial: 6, epoch, 40, iter: 200, curr loss: 0.42507404088974, avg loss: 0.4289602723717689\n",
      "trial: 6, epoch, 41, iter: 1, curr loss: 0.4359551966190338, avg loss: 0.4359551966190338\n",
      "trial: 6, epoch, 41, iter: 200, curr loss: 0.4337117671966553, avg loss: 0.42842809155583383\n",
      "trial: 6, epoch, 42, iter: 1, curr loss: 0.44109830260276794, avg loss: 0.44109830260276794\n",
      "trial: 6, epoch, 42, iter: 200, curr loss: 0.41814517974853516, avg loss: 0.4289493444561958\n",
      "trial: 6, epoch, 43, iter: 1, curr loss: 0.42782917618751526, avg loss: 0.42782917618751526\n",
      "trial: 6, epoch, 43, iter: 200, curr loss: 0.43366479873657227, avg loss: 0.42870010107755663\n",
      "trial: 6, epoch, 44, iter: 1, curr loss: 0.4404466152191162, avg loss: 0.4404466152191162\n",
      "trial: 6, epoch, 44, iter: 200, curr loss: 0.4311704635620117, avg loss: 0.4286336790025234\n",
      "trial: 6, epoch, 45, iter: 1, curr loss: 0.43057242035865784, avg loss: 0.43057242035865784\n",
      "trial: 6, epoch, 45, iter: 200, curr loss: 0.42731213569641113, avg loss: 0.4286573413014412\n",
      "trial: 6, epoch, 46, iter: 1, curr loss: 0.42929670214653015, avg loss: 0.42929670214653015\n",
      "trial: 6, epoch, 46, iter: 200, curr loss: 0.42762234807014465, avg loss: 0.4286105296015739\n",
      "trial: 6, epoch, 47, iter: 1, curr loss: 0.4432395398616791, avg loss: 0.4432395398616791\n",
      "trial: 6, epoch, 47, iter: 200, curr loss: 0.4280470907688141, avg loss: 0.4280808065831661\n",
      "trial: 6, epoch, 48, iter: 1, curr loss: 0.42048054933547974, avg loss: 0.42048054933547974\n",
      "trial: 6, epoch, 48, iter: 200, curr loss: 0.4265376925468445, avg loss: 0.42894513443112375\n",
      "trial: 6, epoch, 49, iter: 1, curr loss: 0.4265088140964508, avg loss: 0.4265088140964508\n",
      "trial: 6, epoch, 49, iter: 200, curr loss: 0.4305747449398041, avg loss: 0.42839953422546384\n",
      "trial: 6, epoch, 50, iter: 1, curr loss: 0.4331413209438324, avg loss: 0.4331413209438324\n",
      "trial: 6, epoch, 50, iter: 200, curr loss: 0.4139038920402527, avg loss: 0.428632929623127\n",
      "trial: 6, ldr: 0.9056710004806519, dv: 0.9087392091751099, nwj: 0.9087345004081726\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 7, epoch, 1, iter: 1, curr loss: 0.6954258680343628, avg loss: 0.6954258680343628\n",
      "trial: 7, epoch, 1, iter: 200, curr loss: 0.42680680751800537, avg loss: 0.45969643756747247\n",
      "trial: 7, epoch, 2, iter: 1, curr loss: 0.4406678378582001, avg loss: 0.4406678378582001\n",
      "trial: 7, epoch, 2, iter: 200, curr loss: 0.4429057836532593, avg loss: 0.4309266030788422\n",
      "trial: 7, epoch, 3, iter: 1, curr loss: 0.4284237027168274, avg loss: 0.4284237027168274\n",
      "trial: 7, epoch, 3, iter: 200, curr loss: 0.4268277585506439, avg loss: 0.42956183686852456\n",
      "trial: 7, epoch, 4, iter: 1, curr loss: 0.4410877227783203, avg loss: 0.4410877227783203\n",
      "trial: 7, epoch, 4, iter: 200, curr loss: 0.42774462699890137, avg loss: 0.4291828154027462\n",
      "trial: 7, epoch, 5, iter: 1, curr loss: 0.42797696590423584, avg loss: 0.42797696590423584\n",
      "trial: 7, epoch, 5, iter: 200, curr loss: 0.42675769329071045, avg loss: 0.4291729900240898\n",
      "trial: 7, epoch, 6, iter: 1, curr loss: 0.43452996015548706, avg loss: 0.43452996015548706\n",
      "trial: 7, epoch, 6, iter: 200, curr loss: 0.4258871376514435, avg loss: 0.4292580018937588\n",
      "trial: 7, epoch, 7, iter: 1, curr loss: 0.435790091753006, avg loss: 0.435790091753006\n",
      "trial: 7, epoch, 7, iter: 200, curr loss: 0.42168664932250977, avg loss: 0.42856273949146273\n",
      "trial: 7, epoch, 8, iter: 1, curr loss: 0.42690688371658325, avg loss: 0.42690688371658325\n",
      "trial: 7, epoch, 8, iter: 200, curr loss: 0.43311503529548645, avg loss: 0.42916710048913953\n",
      "trial: 7, epoch, 9, iter: 1, curr loss: 0.421894371509552, avg loss: 0.421894371509552\n",
      "trial: 7, epoch, 9, iter: 200, curr loss: 0.4373195171356201, avg loss: 0.4288083483278751\n",
      "trial: 7, epoch, 10, iter: 1, curr loss: 0.43379664421081543, avg loss: 0.43379664421081543\n",
      "trial: 7, epoch, 10, iter: 200, curr loss: 0.43889233469963074, avg loss: 0.42842078700661657\n",
      "trial: 7, epoch, 11, iter: 1, curr loss: 0.42190128564834595, avg loss: 0.42190128564834595\n",
      "trial: 7, epoch, 11, iter: 200, curr loss: 0.42970991134643555, avg loss: 0.42856842175126075\n",
      "trial: 7, epoch, 12, iter: 1, curr loss: 0.4319036602973938, avg loss: 0.4319036602973938\n",
      "trial: 7, epoch, 12, iter: 200, curr loss: 0.4293447732925415, avg loss: 0.4294092942774296\n",
      "trial: 7, epoch, 13, iter: 1, curr loss: 0.4290999174118042, avg loss: 0.4290999174118042\n",
      "trial: 7, epoch, 13, iter: 200, curr loss: 0.4289829432964325, avg loss: 0.4284138059616089\n",
      "trial: 7, epoch, 14, iter: 1, curr loss: 0.4265255928039551, avg loss: 0.4265255928039551\n",
      "trial: 7, epoch, 14, iter: 200, curr loss: 0.43950143456459045, avg loss: 0.428938165307045\n",
      "trial: 7, epoch, 15, iter: 1, curr loss: 0.4296356439590454, avg loss: 0.4296356439590454\n",
      "trial: 7, epoch, 15, iter: 200, curr loss: 0.4296247959136963, avg loss: 0.42920613959431647\n",
      "trial: 7, epoch, 16, iter: 1, curr loss: 0.44047853350639343, avg loss: 0.44047853350639343\n",
      "trial: 7, epoch, 16, iter: 200, curr loss: 0.424233078956604, avg loss: 0.4285792900621891\n",
      "trial: 7, epoch, 17, iter: 1, curr loss: 0.4399687945842743, avg loss: 0.4399687945842743\n",
      "trial: 7, epoch, 17, iter: 200, curr loss: 0.4231087565422058, avg loss: 0.4294003140926361\n",
      "trial: 7, epoch, 18, iter: 1, curr loss: 0.4307960569858551, avg loss: 0.4307960569858551\n",
      "trial: 7, epoch, 18, iter: 200, curr loss: 0.4374985694885254, avg loss: 0.4285192383825779\n",
      "trial: 7, epoch, 19, iter: 1, curr loss: 0.4305598735809326, avg loss: 0.4305598735809326\n",
      "trial: 7, epoch, 19, iter: 200, curr loss: 0.42871612310409546, avg loss: 0.42893552154302594\n",
      "trial: 7, epoch, 20, iter: 1, curr loss: 0.433918833732605, avg loss: 0.433918833732605\n",
      "trial: 7, epoch, 20, iter: 200, curr loss: 0.42207667231559753, avg loss: 0.4285009367763996\n",
      "trial: 7, epoch, 21, iter: 1, curr loss: 0.43799570202827454, avg loss: 0.43799570202827454\n",
      "trial: 7, epoch, 21, iter: 200, curr loss: 0.4274998605251312, avg loss: 0.4288086391985416\n",
      "trial: 7, epoch, 22, iter: 1, curr loss: 0.43287140130996704, avg loss: 0.43287140130996704\n",
      "trial: 7, epoch, 22, iter: 200, curr loss: 0.44077181816101074, avg loss: 0.428617969751358\n",
      "trial: 7, epoch, 23, iter: 1, curr loss: 0.4360693097114563, avg loss: 0.4360693097114563\n",
      "trial: 7, epoch, 23, iter: 200, curr loss: 0.4336451590061188, avg loss: 0.4290884593129158\n",
      "trial: 7, epoch, 24, iter: 1, curr loss: 0.42908576130867004, avg loss: 0.42908576130867004\n",
      "trial: 7, epoch, 24, iter: 200, curr loss: 0.4355473816394806, avg loss: 0.4295958411693573\n",
      "trial: 7, epoch, 25, iter: 1, curr loss: 0.4221576452255249, avg loss: 0.4221576452255249\n",
      "trial: 7, epoch, 25, iter: 200, curr loss: 0.42685240507125854, avg loss: 0.42836550772190096\n",
      "trial: 7, epoch, 26, iter: 1, curr loss: 0.42559733986854553, avg loss: 0.42559733986854553\n",
      "trial: 7, epoch, 26, iter: 200, curr loss: 0.45041272044181824, avg loss: 0.42858078837394714\n",
      "trial: 7, epoch, 27, iter: 1, curr loss: 0.4203157424926758, avg loss: 0.4203157424926758\n",
      "trial: 7, epoch, 27, iter: 200, curr loss: 0.4419826865196228, avg loss: 0.42903581261634827\n",
      "trial: 7, epoch, 28, iter: 1, curr loss: 0.4272943139076233, avg loss: 0.4272943139076233\n",
      "trial: 7, epoch, 28, iter: 200, curr loss: 0.41469627618789673, avg loss: 0.4289197227358818\n",
      "trial: 7, epoch, 29, iter: 1, curr loss: 0.43313467502593994, avg loss: 0.43313467502593994\n",
      "trial: 7, epoch, 29, iter: 200, curr loss: 0.4334992468357086, avg loss: 0.42848509281873703\n",
      "trial: 7, epoch, 30, iter: 1, curr loss: 0.4333048462867737, avg loss: 0.4333048462867737\n",
      "trial: 7, epoch, 30, iter: 200, curr loss: 0.4345734715461731, avg loss: 0.4291062435507774\n",
      "trial: 7, epoch, 31, iter: 1, curr loss: 0.4232944846153259, avg loss: 0.4232944846153259\n",
      "trial: 7, epoch, 31, iter: 200, curr loss: 0.4283430874347687, avg loss: 0.42852579593658446\n",
      "trial: 7, epoch, 32, iter: 1, curr loss: 0.42761656641960144, avg loss: 0.42761656641960144\n",
      "trial: 7, epoch, 32, iter: 200, curr loss: 0.43072348833084106, avg loss: 0.4286533844470978\n",
      "trial: 7, epoch, 33, iter: 1, curr loss: 0.43587225675582886, avg loss: 0.43587225675582886\n",
      "trial: 7, epoch, 33, iter: 200, curr loss: 0.4288513660430908, avg loss: 0.4288548023998737\n",
      "trial: 7, epoch, 34, iter: 1, curr loss: 0.4415755569934845, avg loss: 0.4415755569934845\n",
      "trial: 7, epoch, 34, iter: 200, curr loss: 0.4392033517360687, avg loss: 0.42843432575464246\n",
      "trial: 7, epoch, 35, iter: 1, curr loss: 0.43220090866088867, avg loss: 0.43220090866088867\n",
      "trial: 7, epoch, 35, iter: 200, curr loss: 0.44062066078186035, avg loss: 0.4290397179126739\n",
      "trial: 7, epoch, 36, iter: 1, curr loss: 0.43378809094429016, avg loss: 0.43378809094429016\n",
      "trial: 7, epoch, 36, iter: 200, curr loss: 0.4385732412338257, avg loss: 0.42890881896018984\n",
      "trial: 7, epoch, 37, iter: 1, curr loss: 0.42728984355926514, avg loss: 0.42728984355926514\n",
      "trial: 7, epoch, 37, iter: 200, curr loss: 0.4240732192993164, avg loss: 0.42878719300031665\n",
      "trial: 7, epoch, 38, iter: 1, curr loss: 0.4368242621421814, avg loss: 0.4368242621421814\n",
      "trial: 7, epoch, 38, iter: 200, curr loss: 0.4259956479072571, avg loss: 0.42842004641890524\n",
      "trial: 7, epoch, 39, iter: 1, curr loss: 0.43496811389923096, avg loss: 0.43496811389923096\n",
      "trial: 7, epoch, 39, iter: 200, curr loss: 0.42638128995895386, avg loss: 0.42844959840178487\n",
      "trial: 7, epoch, 40, iter: 1, curr loss: 0.43010413646698, avg loss: 0.43010413646698\n",
      "trial: 7, epoch, 40, iter: 200, curr loss: 0.4390348792076111, avg loss: 0.4286665138602257\n",
      "trial: 7, epoch, 41, iter: 1, curr loss: 0.4337318539619446, avg loss: 0.4337318539619446\n",
      "trial: 7, epoch, 41, iter: 200, curr loss: 0.4279082119464874, avg loss: 0.4286337646842003\n",
      "trial: 7, epoch, 42, iter: 1, curr loss: 0.42299777269363403, avg loss: 0.42299777269363403\n",
      "trial: 7, epoch, 42, iter: 200, curr loss: 0.42363473773002625, avg loss: 0.4291816531121731\n",
      "trial: 7, epoch, 43, iter: 1, curr loss: 0.42401987314224243, avg loss: 0.42401987314224243\n",
      "trial: 7, epoch, 43, iter: 200, curr loss: 0.4357292652130127, avg loss: 0.42911175683140756\n",
      "trial: 7, epoch, 44, iter: 1, curr loss: 0.4260026812553406, avg loss: 0.4260026812553406\n",
      "trial: 7, epoch, 44, iter: 200, curr loss: 0.4278416633605957, avg loss: 0.4285407541692257\n",
      "trial: 7, epoch, 45, iter: 1, curr loss: 0.4313606023788452, avg loss: 0.4313606023788452\n",
      "trial: 7, epoch, 45, iter: 200, curr loss: 0.43353164196014404, avg loss: 0.4288164101541042\n",
      "trial: 7, epoch, 46, iter: 1, curr loss: 0.42785292863845825, avg loss: 0.42785292863845825\n",
      "trial: 7, epoch, 46, iter: 200, curr loss: 0.4184685945510864, avg loss: 0.4290914799273014\n",
      "trial: 7, epoch, 47, iter: 1, curr loss: 0.4255779981613159, avg loss: 0.4255779981613159\n",
      "trial: 7, epoch, 47, iter: 200, curr loss: 0.426077663898468, avg loss: 0.42851595014333727\n",
      "trial: 7, epoch, 48, iter: 1, curr loss: 0.4404732584953308, avg loss: 0.4404732584953308\n",
      "trial: 7, epoch, 48, iter: 200, curr loss: 0.42553263902664185, avg loss: 0.4288280963897705\n",
      "trial: 7, epoch, 49, iter: 1, curr loss: 0.43232807517051697, avg loss: 0.43232807517051697\n",
      "trial: 7, epoch, 49, iter: 200, curr loss: 0.43332573771476746, avg loss: 0.4290951858460903\n",
      "trial: 7, epoch, 50, iter: 1, curr loss: 0.4303467273712158, avg loss: 0.4303467273712158\n",
      "trial: 7, epoch, 50, iter: 200, curr loss: 0.41974613070487976, avg loss: 0.42812721729278563\n",
      "trial: 7, ldr: 0.919594943523407, dv: 0.9086486101150513, nwj: 0.9085884690284729\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 8, epoch, 1, iter: 1, curr loss: 0.6936432123184204, avg loss: 0.6936432123184204\n",
      "trial: 8, epoch, 1, iter: 200, curr loss: 0.4322184920310974, avg loss: 0.45753181502223017\n",
      "trial: 8, epoch, 2, iter: 1, curr loss: 0.4321073889732361, avg loss: 0.4321073889732361\n",
      "trial: 8, epoch, 2, iter: 200, curr loss: 0.42860594391822815, avg loss: 0.4304707981646061\n",
      "trial: 8, epoch, 3, iter: 1, curr loss: 0.445466011762619, avg loss: 0.445466011762619\n",
      "trial: 8, epoch, 3, iter: 200, curr loss: 0.4307253062725067, avg loss: 0.4287870539724827\n",
      "trial: 8, epoch, 4, iter: 1, curr loss: 0.41371577978134155, avg loss: 0.41371577978134155\n",
      "trial: 8, epoch, 4, iter: 200, curr loss: 0.42933419346809387, avg loss: 0.42913118124008176\n",
      "trial: 8, epoch, 5, iter: 1, curr loss: 0.4366856813430786, avg loss: 0.4366856813430786\n",
      "trial: 8, epoch, 5, iter: 200, curr loss: 0.4320492744445801, avg loss: 0.42902362287044526\n",
      "trial: 8, epoch, 6, iter: 1, curr loss: 0.4389880299568176, avg loss: 0.4389880299568176\n",
      "trial: 8, epoch, 6, iter: 200, curr loss: 0.41661572456359863, avg loss: 0.42917661011219027\n",
      "trial: 8, epoch, 7, iter: 1, curr loss: 0.4237843453884125, avg loss: 0.4237843453884125\n",
      "trial: 8, epoch, 7, iter: 200, curr loss: 0.4395955502986908, avg loss: 0.42891871109604834\n",
      "trial: 8, epoch, 8, iter: 1, curr loss: 0.42475995421409607, avg loss: 0.42475995421409607\n",
      "trial: 8, epoch, 8, iter: 200, curr loss: 0.42369866371154785, avg loss: 0.42847026079893114\n",
      "trial: 8, epoch, 9, iter: 1, curr loss: 0.43245381116867065, avg loss: 0.43245381116867065\n",
      "trial: 8, epoch, 9, iter: 200, curr loss: 0.42249390482902527, avg loss: 0.42846562281250955\n",
      "trial: 8, epoch, 10, iter: 1, curr loss: 0.4282703995704651, avg loss: 0.4282703995704651\n",
      "trial: 8, epoch, 10, iter: 200, curr loss: 0.4336557984352112, avg loss: 0.428305654078722\n",
      "trial: 8, epoch, 11, iter: 1, curr loss: 0.43475258350372314, avg loss: 0.43475258350372314\n",
      "trial: 8, epoch, 11, iter: 200, curr loss: 0.44022417068481445, avg loss: 0.4291629494726658\n",
      "trial: 8, epoch, 12, iter: 1, curr loss: 0.4385368824005127, avg loss: 0.4385368824005127\n",
      "trial: 8, epoch, 12, iter: 200, curr loss: 0.43016695976257324, avg loss: 0.4289238612353802\n",
      "trial: 8, epoch, 13, iter: 1, curr loss: 0.4287201762199402, avg loss: 0.4287201762199402\n",
      "trial: 8, epoch, 13, iter: 200, curr loss: 0.4483431279659271, avg loss: 0.4289115838706493\n",
      "trial: 8, epoch, 14, iter: 1, curr loss: 0.436217337846756, avg loss: 0.436217337846756\n",
      "trial: 8, epoch, 14, iter: 200, curr loss: 0.4250277578830719, avg loss: 0.42904703617095946\n",
      "trial: 8, epoch, 15, iter: 1, curr loss: 0.425057590007782, avg loss: 0.425057590007782\n",
      "trial: 8, epoch, 15, iter: 200, curr loss: 0.43411368131637573, avg loss: 0.42897655203938484\n",
      "trial: 8, epoch, 16, iter: 1, curr loss: 0.4413111209869385, avg loss: 0.4413111209869385\n",
      "trial: 8, epoch, 16, iter: 200, curr loss: 0.43782564997673035, avg loss: 0.42871972993016244\n",
      "trial: 8, epoch, 17, iter: 1, curr loss: 0.4318701922893524, avg loss: 0.4318701922893524\n",
      "trial: 8, epoch, 17, iter: 200, curr loss: 0.44097772240638733, avg loss: 0.4288686588406563\n",
      "trial: 8, epoch, 18, iter: 1, curr loss: 0.43931373953819275, avg loss: 0.43931373953819275\n",
      "trial: 8, epoch, 18, iter: 200, curr loss: 0.42594361305236816, avg loss: 0.4291151274740696\n",
      "trial: 8, epoch, 19, iter: 1, curr loss: 0.4297162890434265, avg loss: 0.4297162890434265\n",
      "trial: 8, epoch, 19, iter: 200, curr loss: 0.4296399652957916, avg loss: 0.428757568448782\n",
      "trial: 8, epoch, 20, iter: 1, curr loss: 0.4311130940914154, avg loss: 0.4311130940914154\n",
      "trial: 8, epoch, 20, iter: 200, curr loss: 0.41799789667129517, avg loss: 0.4280206286907196\n",
      "trial: 8, epoch, 21, iter: 1, curr loss: 0.42515313625335693, avg loss: 0.42515313625335693\n",
      "trial: 8, epoch, 21, iter: 200, curr loss: 0.42928647994995117, avg loss: 0.4292644676566124\n",
      "trial: 8, epoch, 22, iter: 1, curr loss: 0.4318150281906128, avg loss: 0.4318150281906128\n",
      "trial: 8, epoch, 22, iter: 200, curr loss: 0.42975541949272156, avg loss: 0.4288015469908714\n",
      "trial: 8, epoch, 23, iter: 1, curr loss: 0.4160372316837311, avg loss: 0.4160372316837311\n",
      "trial: 8, epoch, 23, iter: 200, curr loss: 0.4291459321975708, avg loss: 0.4285958659648895\n",
      "trial: 8, epoch, 24, iter: 1, curr loss: 0.414387583732605, avg loss: 0.414387583732605\n",
      "trial: 8, epoch, 24, iter: 200, curr loss: 0.4356648921966553, avg loss: 0.4292232319712639\n",
      "trial: 8, epoch, 25, iter: 1, curr loss: 0.43180036544799805, avg loss: 0.43180036544799805\n",
      "trial: 8, epoch, 25, iter: 200, curr loss: 0.4417973756790161, avg loss: 0.42951852574944493\n",
      "trial: 8, epoch, 26, iter: 1, curr loss: 0.4255661964416504, avg loss: 0.4255661964416504\n",
      "trial: 8, epoch, 26, iter: 200, curr loss: 0.4340643882751465, avg loss: 0.42866409733891486\n",
      "trial: 8, epoch, 27, iter: 1, curr loss: 0.4260799288749695, avg loss: 0.4260799288749695\n",
      "trial: 8, epoch, 27, iter: 200, curr loss: 0.42548835277557373, avg loss: 0.42850393906235695\n",
      "trial: 8, epoch, 28, iter: 1, curr loss: 0.44225358963012695, avg loss: 0.44225358963012695\n",
      "trial: 8, epoch, 28, iter: 200, curr loss: 0.42986342310905457, avg loss: 0.428997328877449\n",
      "trial: 8, epoch, 29, iter: 1, curr loss: 0.4381351172924042, avg loss: 0.4381351172924042\n",
      "trial: 8, epoch, 29, iter: 200, curr loss: 0.42736637592315674, avg loss: 0.4288162264227867\n",
      "trial: 8, epoch, 30, iter: 1, curr loss: 0.43115997314453125, avg loss: 0.43115997314453125\n",
      "trial: 8, epoch, 30, iter: 200, curr loss: 0.4234843850135803, avg loss: 0.42838055700063704\n",
      "trial: 8, epoch, 31, iter: 1, curr loss: 0.42737042903900146, avg loss: 0.42737042903900146\n",
      "trial: 8, epoch, 31, iter: 200, curr loss: 0.4388526678085327, avg loss: 0.42920343786478043\n",
      "trial: 8, epoch, 32, iter: 1, curr loss: 0.43878763914108276, avg loss: 0.43878763914108276\n",
      "trial: 8, epoch, 32, iter: 200, curr loss: 0.425998330116272, avg loss: 0.4287289835512638\n",
      "trial: 8, epoch, 33, iter: 1, curr loss: 0.43024682998657227, avg loss: 0.43024682998657227\n",
      "trial: 8, epoch, 33, iter: 200, curr loss: 0.42910265922546387, avg loss: 0.42905704602599143\n",
      "trial: 8, epoch, 34, iter: 1, curr loss: 0.4324873685836792, avg loss: 0.4324873685836792\n",
      "trial: 8, epoch, 34, iter: 200, curr loss: 0.43334418535232544, avg loss: 0.4287954005599022\n",
      "trial: 8, epoch, 35, iter: 1, curr loss: 0.43074604868888855, avg loss: 0.43074604868888855\n",
      "trial: 8, epoch, 35, iter: 200, curr loss: 0.4297361969947815, avg loss: 0.42828342616558074\n",
      "trial: 8, epoch, 36, iter: 1, curr loss: 0.4376722574234009, avg loss: 0.4376722574234009\n",
      "trial: 8, epoch, 36, iter: 200, curr loss: 0.4170365333557129, avg loss: 0.4290884755551815\n",
      "trial: 8, epoch, 37, iter: 1, curr loss: 0.43335187435150146, avg loss: 0.43335187435150146\n",
      "trial: 8, epoch, 37, iter: 200, curr loss: 0.4403632581233978, avg loss: 0.4288366165757179\n",
      "trial: 8, epoch, 38, iter: 1, curr loss: 0.4416728615760803, avg loss: 0.4416728615760803\n",
      "trial: 8, epoch, 38, iter: 200, curr loss: 0.4413938522338867, avg loss: 0.4290159636735916\n",
      "trial: 8, epoch, 39, iter: 1, curr loss: 0.4330064356327057, avg loss: 0.4330064356327057\n",
      "trial: 8, epoch, 39, iter: 200, curr loss: 0.44556117057800293, avg loss: 0.42868429601192476\n",
      "trial: 8, epoch, 40, iter: 1, curr loss: 0.4335651397705078, avg loss: 0.4335651397705078\n",
      "trial: 8, epoch, 40, iter: 200, curr loss: 0.42780280113220215, avg loss: 0.4292501994967461\n",
      "trial: 8, epoch, 41, iter: 1, curr loss: 0.42381054162979126, avg loss: 0.42381054162979126\n",
      "trial: 8, epoch, 41, iter: 200, curr loss: 0.43140676617622375, avg loss: 0.4286371526122093\n",
      "trial: 8, epoch, 42, iter: 1, curr loss: 0.4444565176963806, avg loss: 0.4444565176963806\n",
      "trial: 8, epoch, 42, iter: 200, curr loss: 0.4422271251678467, avg loss: 0.4287261414527893\n",
      "trial: 8, epoch, 43, iter: 1, curr loss: 0.4251796007156372, avg loss: 0.4251796007156372\n",
      "trial: 8, epoch, 43, iter: 200, curr loss: 0.4250097870826721, avg loss: 0.4292922581732273\n",
      "trial: 8, epoch, 44, iter: 1, curr loss: 0.43381547927856445, avg loss: 0.43381547927856445\n",
      "trial: 8, epoch, 44, iter: 200, curr loss: 0.4363878071308136, avg loss: 0.42912198215723035\n",
      "trial: 8, epoch, 45, iter: 1, curr loss: 0.4294453561306, avg loss: 0.4294453561306\n",
      "trial: 8, epoch, 45, iter: 200, curr loss: 0.4263480603694916, avg loss: 0.4286953327059746\n",
      "trial: 8, epoch, 46, iter: 1, curr loss: 0.4308537244796753, avg loss: 0.4308537244796753\n",
      "trial: 8, epoch, 46, iter: 200, curr loss: 0.42196059226989746, avg loss: 0.42885000094771386\n",
      "trial: 8, epoch, 47, iter: 1, curr loss: 0.41802990436553955, avg loss: 0.41802990436553955\n",
      "trial: 8, epoch, 47, iter: 200, curr loss: 0.43565717339515686, avg loss: 0.4290889056026936\n",
      "trial: 8, epoch, 48, iter: 1, curr loss: 0.4368184208869934, avg loss: 0.4368184208869934\n",
      "trial: 8, epoch, 48, iter: 200, curr loss: 0.43751758337020874, avg loss: 0.4290306848287582\n",
      "trial: 8, epoch, 49, iter: 1, curr loss: 0.4267013967037201, avg loss: 0.4267013967037201\n",
      "trial: 8, epoch, 49, iter: 200, curr loss: 0.431365966796875, avg loss: 0.4278974078595638\n",
      "trial: 8, epoch, 50, iter: 1, curr loss: 0.44157344102859497, avg loss: 0.44157344102859497\n",
      "trial: 8, epoch, 50, iter: 200, curr loss: 0.4197174906730652, avg loss: 0.4295279662311077\n",
      "trial: 8, ldr: 0.9439167380332947, dv: 0.9086761474609375, nwj: 0.9080478549003601\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 9, epoch, 1, iter: 1, curr loss: 0.6945571899414062, avg loss: 0.6945571899414062\n",
      "trial: 9, epoch, 1, iter: 200, curr loss: 0.4339902400970459, avg loss: 0.4578270189464092\n",
      "trial: 9, epoch, 2, iter: 1, curr loss: 0.42680686712265015, avg loss: 0.42680686712265015\n",
      "trial: 9, epoch, 2, iter: 200, curr loss: 0.4319068193435669, avg loss: 0.42934141382575036\n",
      "trial: 9, epoch, 3, iter: 1, curr loss: 0.42827022075653076, avg loss: 0.42827022075653076\n",
      "trial: 9, epoch, 3, iter: 200, curr loss: 0.423042356967926, avg loss: 0.42894515216350554\n",
      "trial: 9, epoch, 4, iter: 1, curr loss: 0.43509209156036377, avg loss: 0.43509209156036377\n",
      "trial: 9, epoch, 4, iter: 200, curr loss: 0.42273226380348206, avg loss: 0.4290225726366043\n",
      "trial: 9, epoch, 5, iter: 1, curr loss: 0.4332621991634369, avg loss: 0.4332621991634369\n",
      "trial: 9, epoch, 5, iter: 200, curr loss: 0.4231666326522827, avg loss: 0.42853912219405177\n",
      "trial: 9, epoch, 6, iter: 1, curr loss: 0.42782503366470337, avg loss: 0.42782503366470337\n",
      "trial: 9, epoch, 6, iter: 200, curr loss: 0.43014177680015564, avg loss: 0.42876566886901857\n",
      "trial: 9, epoch, 7, iter: 1, curr loss: 0.42914676666259766, avg loss: 0.42914676666259766\n",
      "trial: 9, epoch, 7, iter: 200, curr loss: 0.42391806840896606, avg loss: 0.4283644810318947\n",
      "trial: 9, epoch, 8, iter: 1, curr loss: 0.4232493042945862, avg loss: 0.4232493042945862\n",
      "trial: 9, epoch, 8, iter: 200, curr loss: 0.42433127760887146, avg loss: 0.4285593229532242\n",
      "trial: 9, epoch, 9, iter: 1, curr loss: 0.43756377696990967, avg loss: 0.43756377696990967\n",
      "trial: 9, epoch, 9, iter: 200, curr loss: 0.43104249238967896, avg loss: 0.42841560631990433\n",
      "trial: 9, epoch, 10, iter: 1, curr loss: 0.4317183494567871, avg loss: 0.4317183494567871\n",
      "trial: 9, epoch, 10, iter: 200, curr loss: 0.41000527143478394, avg loss: 0.42904501110315324\n",
      "trial: 9, epoch, 11, iter: 1, curr loss: 0.434530109167099, avg loss: 0.434530109167099\n",
      "trial: 9, epoch, 11, iter: 200, curr loss: 0.4341790974140167, avg loss: 0.4285082580149174\n",
      "trial: 9, epoch, 12, iter: 1, curr loss: 0.43039363622665405, avg loss: 0.43039363622665405\n",
      "trial: 9, epoch, 12, iter: 200, curr loss: 0.4364877939224243, avg loss: 0.4292578785121441\n",
      "trial: 9, epoch, 13, iter: 1, curr loss: 0.4440631568431854, avg loss: 0.4440631568431854\n",
      "trial: 9, epoch, 13, iter: 200, curr loss: 0.4362887740135193, avg loss: 0.42859332531690597\n",
      "trial: 9, epoch, 14, iter: 1, curr loss: 0.4366985559463501, avg loss: 0.4366985559463501\n",
      "trial: 9, epoch, 14, iter: 200, curr loss: 0.4302440881729126, avg loss: 0.4281254969537258\n",
      "trial: 9, epoch, 15, iter: 1, curr loss: 0.4273255467414856, avg loss: 0.4273255467414856\n",
      "trial: 9, epoch, 15, iter: 200, curr loss: 0.448199987411499, avg loss: 0.4286157584190369\n",
      "trial: 9, epoch, 16, iter: 1, curr loss: 0.4378359615802765, avg loss: 0.4378359615802765\n",
      "trial: 9, epoch, 16, iter: 200, curr loss: 0.4326375126838684, avg loss: 0.42898920342326163\n",
      "trial: 9, epoch, 17, iter: 1, curr loss: 0.43196016550064087, avg loss: 0.43196016550064087\n",
      "trial: 9, epoch, 17, iter: 200, curr loss: 0.4216386675834656, avg loss: 0.428671897649765\n",
      "trial: 9, epoch, 18, iter: 1, curr loss: 0.43225759267807007, avg loss: 0.43225759267807007\n",
      "trial: 9, epoch, 18, iter: 200, curr loss: 0.4191668629646301, avg loss: 0.42830650106072427\n",
      "trial: 9, epoch, 19, iter: 1, curr loss: 0.42705440521240234, avg loss: 0.42705440521240234\n",
      "trial: 9, epoch, 19, iter: 200, curr loss: 0.4286581873893738, avg loss: 0.42907167494297027\n",
      "trial: 9, epoch, 20, iter: 1, curr loss: 0.4172621965408325, avg loss: 0.4172621965408325\n",
      "trial: 9, epoch, 20, iter: 200, curr loss: 0.44178682565689087, avg loss: 0.4290208195149898\n",
      "trial: 9, epoch, 21, iter: 1, curr loss: 0.43227827548980713, avg loss: 0.43227827548980713\n",
      "trial: 9, epoch, 21, iter: 200, curr loss: 0.4440878629684448, avg loss: 0.42805280923843386\n",
      "trial: 9, epoch, 22, iter: 1, curr loss: 0.4273640513420105, avg loss: 0.4273640513420105\n",
      "trial: 9, epoch, 22, iter: 200, curr loss: 0.43457889556884766, avg loss: 0.42890197202563285\n",
      "trial: 9, epoch, 23, iter: 1, curr loss: 0.43884968757629395, avg loss: 0.43884968757629395\n",
      "trial: 9, epoch, 23, iter: 200, curr loss: 0.4192952513694763, avg loss: 0.4293741898238659\n",
      "trial: 9, epoch, 24, iter: 1, curr loss: 0.4267887473106384, avg loss: 0.4267887473106384\n",
      "trial: 9, epoch, 24, iter: 200, curr loss: 0.4244687259197235, avg loss: 0.42906467512249946\n",
      "trial: 9, epoch, 25, iter: 1, curr loss: 0.4124663174152374, avg loss: 0.4124663174152374\n",
      "trial: 9, epoch, 25, iter: 200, curr loss: 0.43336981534957886, avg loss: 0.4290878216922283\n",
      "trial: 9, epoch, 26, iter: 1, curr loss: 0.438881516456604, avg loss: 0.438881516456604\n",
      "trial: 9, epoch, 26, iter: 200, curr loss: 0.4376411736011505, avg loss: 0.4287415736913681\n",
      "trial: 9, epoch, 27, iter: 1, curr loss: 0.41423407196998596, avg loss: 0.41423407196998596\n",
      "trial: 9, epoch, 27, iter: 200, curr loss: 0.43538227677345276, avg loss: 0.4288574269413948\n",
      "trial: 9, epoch, 28, iter: 1, curr loss: 0.433621883392334, avg loss: 0.433621883392334\n",
      "trial: 9, epoch, 28, iter: 200, curr loss: 0.4299565553665161, avg loss: 0.4286116625368595\n",
      "trial: 9, epoch, 29, iter: 1, curr loss: 0.428823858499527, avg loss: 0.428823858499527\n",
      "trial: 9, epoch, 29, iter: 200, curr loss: 0.4226837754249573, avg loss: 0.42870949909090994\n",
      "trial: 9, epoch, 30, iter: 1, curr loss: 0.4331851005554199, avg loss: 0.4331851005554199\n",
      "trial: 9, epoch, 30, iter: 200, curr loss: 0.42759591341018677, avg loss: 0.42861286357045175\n",
      "trial: 9, epoch, 31, iter: 1, curr loss: 0.44564592838287354, avg loss: 0.44564592838287354\n",
      "trial: 9, epoch, 31, iter: 200, curr loss: 0.4245374798774719, avg loss: 0.4287672501802444\n",
      "trial: 9, epoch, 32, iter: 1, curr loss: 0.42854493856430054, avg loss: 0.42854493856430054\n",
      "trial: 9, epoch, 32, iter: 200, curr loss: 0.43242335319519043, avg loss: 0.42892245784401895\n",
      "trial: 9, epoch, 33, iter: 1, curr loss: 0.435242623090744, avg loss: 0.435242623090744\n",
      "trial: 9, epoch, 33, iter: 200, curr loss: 0.43451374769210815, avg loss: 0.42946246922016146\n",
      "trial: 9, epoch, 34, iter: 1, curr loss: 0.4232914447784424, avg loss: 0.4232914447784424\n",
      "trial: 9, epoch, 34, iter: 200, curr loss: 0.43486130237579346, avg loss: 0.4292291520535946\n",
      "trial: 9, epoch, 35, iter: 1, curr loss: 0.42802494764328003, avg loss: 0.42802494764328003\n",
      "trial: 9, epoch, 35, iter: 200, curr loss: 0.44150686264038086, avg loss: 0.42873759374022485\n",
      "trial: 9, epoch, 36, iter: 1, curr loss: 0.42479825019836426, avg loss: 0.42479825019836426\n",
      "trial: 9, epoch, 36, iter: 200, curr loss: 0.43034717440605164, avg loss: 0.42902021273970603\n",
      "trial: 9, epoch, 37, iter: 1, curr loss: 0.43402838706970215, avg loss: 0.43402838706970215\n",
      "trial: 9, epoch, 37, iter: 200, curr loss: 0.4366167187690735, avg loss: 0.429277803003788\n",
      "trial: 9, epoch, 38, iter: 1, curr loss: 0.4281921982765198, avg loss: 0.4281921982765198\n",
      "trial: 9, epoch, 38, iter: 200, curr loss: 0.42630523443222046, avg loss: 0.42894300669431684\n",
      "trial: 9, epoch, 39, iter: 1, curr loss: 0.4202546179294586, avg loss: 0.4202546179294586\n",
      "trial: 9, epoch, 39, iter: 200, curr loss: 0.4334261417388916, avg loss: 0.42879326686263086\n",
      "trial: 9, epoch, 40, iter: 1, curr loss: 0.4306389093399048, avg loss: 0.4306389093399048\n",
      "trial: 9, epoch, 40, iter: 200, curr loss: 0.4376637041568756, avg loss: 0.42906870126724245\n",
      "trial: 9, epoch, 41, iter: 1, curr loss: 0.4440430998802185, avg loss: 0.4440430998802185\n",
      "trial: 9, epoch, 41, iter: 200, curr loss: 0.4385211169719696, avg loss: 0.42873718827962876\n",
      "trial: 9, epoch, 42, iter: 1, curr loss: 0.4306883215904236, avg loss: 0.4306883215904236\n",
      "trial: 9, epoch, 42, iter: 200, curr loss: 0.43004924058914185, avg loss: 0.4280082814395428\n",
      "trial: 9, epoch, 43, iter: 1, curr loss: 0.44158273935317993, avg loss: 0.44158273935317993\n",
      "trial: 9, epoch, 43, iter: 200, curr loss: 0.4398370385169983, avg loss: 0.4290862123668194\n",
      "trial: 9, epoch, 44, iter: 1, curr loss: 0.42751842737197876, avg loss: 0.42751842737197876\n",
      "trial: 9, epoch, 44, iter: 200, curr loss: 0.42613685131073, avg loss: 0.4287487934529781\n",
      "trial: 9, epoch, 45, iter: 1, curr loss: 0.42520207166671753, avg loss: 0.42520207166671753\n",
      "trial: 9, epoch, 45, iter: 200, curr loss: 0.4352461099624634, avg loss: 0.4289819476008415\n",
      "trial: 9, epoch, 46, iter: 1, curr loss: 0.4365137219429016, avg loss: 0.4365137219429016\n",
      "trial: 9, epoch, 46, iter: 200, curr loss: 0.42471152544021606, avg loss: 0.42805700078606607\n",
      "trial: 9, epoch, 47, iter: 1, curr loss: 0.4202559292316437, avg loss: 0.4202559292316437\n",
      "trial: 9, epoch, 47, iter: 200, curr loss: 0.4276413917541504, avg loss: 0.4288258138298988\n",
      "trial: 9, epoch, 48, iter: 1, curr loss: 0.42986181378364563, avg loss: 0.42986181378364563\n",
      "trial: 9, epoch, 48, iter: 200, curr loss: 0.42261290550231934, avg loss: 0.42865330025553705\n",
      "trial: 9, epoch, 49, iter: 1, curr loss: 0.42898669838905334, avg loss: 0.42898669838905334\n",
      "trial: 9, epoch, 49, iter: 200, curr loss: 0.4294557571411133, avg loss: 0.42822236225008964\n",
      "trial: 9, epoch, 50, iter: 1, curr loss: 0.43136656284332275, avg loss: 0.43136656284332275\n",
      "trial: 9, epoch, 50, iter: 200, curr loss: 0.4348433315753937, avg loss: 0.428744230568409\n",
      "trial: 9, ldr: 0.8751596212387085, dv: 0.9085190892219543, nwj: 0.9079688191413879\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 10, epoch, 1, iter: 1, curr loss: 0.6934652328491211, avg loss: 0.6934652328491211\n",
      "trial: 10, epoch, 1, iter: 200, curr loss: 0.4287225008010864, avg loss: 0.4555934171378613\n",
      "trial: 10, epoch, 2, iter: 1, curr loss: 0.420320600271225, avg loss: 0.420320600271225\n",
      "trial: 10, epoch, 2, iter: 200, curr loss: 0.4331750273704529, avg loss: 0.4297022119164467\n",
      "trial: 10, epoch, 3, iter: 1, curr loss: 0.44235649704933167, avg loss: 0.44235649704933167\n",
      "trial: 10, epoch, 3, iter: 200, curr loss: 0.4439844489097595, avg loss: 0.4298653993010521\n",
      "trial: 10, epoch, 4, iter: 1, curr loss: 0.42299431562423706, avg loss: 0.42299431562423706\n",
      "trial: 10, epoch, 4, iter: 200, curr loss: 0.43003442883491516, avg loss: 0.42859706103801726\n",
      "trial: 10, epoch, 5, iter: 1, curr loss: 0.4391186237335205, avg loss: 0.4391186237335205\n",
      "trial: 10, epoch, 5, iter: 200, curr loss: 0.4420640766620636, avg loss: 0.4293173255026341\n",
      "trial: 10, epoch, 6, iter: 1, curr loss: 0.42120736837387085, avg loss: 0.42120736837387085\n",
      "trial: 10, epoch, 6, iter: 200, curr loss: 0.4296494424343109, avg loss: 0.4290570169687271\n",
      "trial: 10, epoch, 7, iter: 1, curr loss: 0.4339335560798645, avg loss: 0.4339335560798645\n",
      "trial: 10, epoch, 7, iter: 200, curr loss: 0.426241397857666, avg loss: 0.42892541527748107\n",
      "trial: 10, epoch, 8, iter: 1, curr loss: 0.4437949061393738, avg loss: 0.4437949061393738\n",
      "trial: 10, epoch, 8, iter: 200, curr loss: 0.42803239822387695, avg loss: 0.42877711072564123\n",
      "trial: 10, epoch, 9, iter: 1, curr loss: 0.4208844304084778, avg loss: 0.4208844304084778\n",
      "trial: 10, epoch, 9, iter: 200, curr loss: 0.43082085251808167, avg loss: 0.42844878807663916\n",
      "trial: 10, epoch, 10, iter: 1, curr loss: 0.4336893558502197, avg loss: 0.4336893558502197\n",
      "trial: 10, epoch, 10, iter: 200, curr loss: 0.4369799494743347, avg loss: 0.4287457977235317\n",
      "trial: 10, epoch, 11, iter: 1, curr loss: 0.4200885593891144, avg loss: 0.4200885593891144\n",
      "trial: 10, epoch, 11, iter: 200, curr loss: 0.4281770586967468, avg loss: 0.42825513511896135\n",
      "trial: 10, epoch, 12, iter: 1, curr loss: 0.446897029876709, avg loss: 0.446897029876709\n",
      "trial: 10, epoch, 12, iter: 200, curr loss: 0.44467222690582275, avg loss: 0.42917010858654975\n",
      "trial: 10, epoch, 13, iter: 1, curr loss: 0.4276779294013977, avg loss: 0.4276779294013977\n",
      "trial: 10, epoch, 13, iter: 200, curr loss: 0.42615193128585815, avg loss: 0.42907578200101854\n",
      "trial: 10, epoch, 14, iter: 1, curr loss: 0.42658939957618713, avg loss: 0.42658939957618713\n",
      "trial: 10, epoch, 14, iter: 200, curr loss: 0.43148982524871826, avg loss: 0.42877561405301096\n",
      "trial: 10, epoch, 15, iter: 1, curr loss: 0.4413480758666992, avg loss: 0.4413480758666992\n",
      "trial: 10, epoch, 15, iter: 200, curr loss: 0.4251791834831238, avg loss: 0.4292704625427723\n",
      "trial: 10, epoch, 16, iter: 1, curr loss: 0.44982248544692993, avg loss: 0.44982248544692993\n",
      "trial: 10, epoch, 16, iter: 200, curr loss: 0.42099887132644653, avg loss: 0.4289303655922413\n",
      "trial: 10, epoch, 17, iter: 1, curr loss: 0.4297753572463989, avg loss: 0.4297753572463989\n",
      "trial: 10, epoch, 17, iter: 200, curr loss: 0.4389275908470154, avg loss: 0.4285714554786682\n",
      "trial: 10, epoch, 18, iter: 1, curr loss: 0.43471628427505493, avg loss: 0.43471628427505493\n",
      "trial: 10, epoch, 18, iter: 200, curr loss: 0.4223983883857727, avg loss: 0.4283813728392124\n",
      "trial: 10, epoch, 19, iter: 1, curr loss: 0.43061938881874084, avg loss: 0.43061938881874084\n",
      "trial: 10, epoch, 19, iter: 200, curr loss: 0.4335384964942932, avg loss: 0.42856467962265016\n",
      "trial: 10, epoch, 20, iter: 1, curr loss: 0.4228098392486572, avg loss: 0.4228098392486572\n",
      "trial: 10, epoch, 20, iter: 200, curr loss: 0.4333028197288513, avg loss: 0.4289599673449993\n",
      "trial: 10, epoch, 21, iter: 1, curr loss: 0.43327316641807556, avg loss: 0.43327316641807556\n",
      "trial: 10, epoch, 21, iter: 200, curr loss: 0.4273899793624878, avg loss: 0.4284741733968258\n",
      "trial: 10, epoch, 22, iter: 1, curr loss: 0.4214528501033783, avg loss: 0.4214528501033783\n",
      "trial: 10, epoch, 22, iter: 200, curr loss: 0.42791444063186646, avg loss: 0.4283128187060356\n",
      "trial: 10, epoch, 23, iter: 1, curr loss: 0.4362919330596924, avg loss: 0.4362919330596924\n",
      "trial: 10, epoch, 23, iter: 200, curr loss: 0.41972410678863525, avg loss: 0.4286600169539452\n",
      "trial: 10, epoch, 24, iter: 1, curr loss: 0.4283953905105591, avg loss: 0.4283953905105591\n",
      "trial: 10, epoch, 24, iter: 200, curr loss: 0.4353371858596802, avg loss: 0.42887241512537\n",
      "trial: 10, epoch, 25, iter: 1, curr loss: 0.4344871938228607, avg loss: 0.4344871938228607\n",
      "trial: 10, epoch, 25, iter: 200, curr loss: 0.44161099195480347, avg loss: 0.428818579018116\n",
      "trial: 10, epoch, 26, iter: 1, curr loss: 0.43293869495391846, avg loss: 0.43293869495391846\n",
      "trial: 10, epoch, 26, iter: 200, curr loss: 0.441142201423645, avg loss: 0.42858007565140727\n",
      "trial: 10, epoch, 27, iter: 1, curr loss: 0.43058061599731445, avg loss: 0.43058061599731445\n",
      "trial: 10, epoch, 27, iter: 200, curr loss: 0.43187516927719116, avg loss: 0.42826347902417183\n",
      "trial: 10, epoch, 28, iter: 1, curr loss: 0.43398070335388184, avg loss: 0.43398070335388184\n",
      "trial: 10, epoch, 28, iter: 200, curr loss: 0.4380898177623749, avg loss: 0.4278409019112587\n",
      "trial: 10, epoch, 29, iter: 1, curr loss: 0.43358972668647766, avg loss: 0.43358972668647766\n",
      "trial: 10, epoch, 29, iter: 200, curr loss: 0.42854174971580505, avg loss: 0.4284835836291313\n",
      "trial: 10, epoch, 30, iter: 1, curr loss: 0.4235784411430359, avg loss: 0.4235784411430359\n",
      "trial: 10, epoch, 30, iter: 200, curr loss: 0.4208952784538269, avg loss: 0.4287606680393219\n",
      "trial: 10, epoch, 31, iter: 1, curr loss: 0.434817373752594, avg loss: 0.434817373752594\n",
      "trial: 10, epoch, 31, iter: 200, curr loss: 0.4354170262813568, avg loss: 0.4287466663122177\n",
      "trial: 10, epoch, 32, iter: 1, curr loss: 0.43500474095344543, avg loss: 0.43500474095344543\n",
      "trial: 10, epoch, 32, iter: 200, curr loss: 0.43242573738098145, avg loss: 0.42878590792417526\n",
      "trial: 10, epoch, 33, iter: 1, curr loss: 0.42838120460510254, avg loss: 0.42838120460510254\n",
      "trial: 10, epoch, 33, iter: 200, curr loss: 0.4252340793609619, avg loss: 0.4288440790772438\n",
      "trial: 10, epoch, 34, iter: 1, curr loss: 0.42646217346191406, avg loss: 0.42646217346191406\n",
      "trial: 10, epoch, 34, iter: 200, curr loss: 0.441247820854187, avg loss: 0.4284516449272633\n",
      "trial: 10, epoch, 35, iter: 1, curr loss: 0.4135052561759949, avg loss: 0.4135052561759949\n",
      "trial: 10, epoch, 35, iter: 200, curr loss: 0.43339765071868896, avg loss: 0.42875771567225457\n",
      "trial: 10, epoch, 36, iter: 1, curr loss: 0.414169579744339, avg loss: 0.414169579744339\n",
      "trial: 10, epoch, 36, iter: 200, curr loss: 0.4157184958457947, avg loss: 0.42929633244872095\n",
      "trial: 10, epoch, 37, iter: 1, curr loss: 0.4139454960823059, avg loss: 0.4139454960823059\n",
      "trial: 10, epoch, 37, iter: 200, curr loss: 0.4290732145309448, avg loss: 0.42855608701705933\n",
      "trial: 10, epoch, 38, iter: 1, curr loss: 0.43077489733695984, avg loss: 0.43077489733695984\n",
      "trial: 10, epoch, 38, iter: 200, curr loss: 0.4205600619316101, avg loss: 0.4283444096148014\n",
      "trial: 10, epoch, 39, iter: 1, curr loss: 0.44736799597740173, avg loss: 0.44736799597740173\n",
      "trial: 10, epoch, 39, iter: 200, curr loss: 0.4247489273548126, avg loss: 0.42831777304410934\n",
      "trial: 10, epoch, 40, iter: 1, curr loss: 0.42879241704940796, avg loss: 0.42879241704940796\n",
      "trial: 10, epoch, 40, iter: 200, curr loss: 0.43146055936813354, avg loss: 0.4286541372537613\n",
      "trial: 10, epoch, 41, iter: 1, curr loss: 0.4289284646511078, avg loss: 0.4289284646511078\n",
      "trial: 10, epoch, 41, iter: 200, curr loss: 0.417143315076828, avg loss: 0.4287054154276848\n",
      "trial: 10, epoch, 42, iter: 1, curr loss: 0.4429909586906433, avg loss: 0.4429909586906433\n",
      "trial: 10, epoch, 42, iter: 200, curr loss: 0.4363471269607544, avg loss: 0.428588984310627\n",
      "trial: 10, epoch, 43, iter: 1, curr loss: 0.43396681547164917, avg loss: 0.43396681547164917\n",
      "trial: 10, epoch, 43, iter: 200, curr loss: 0.44611167907714844, avg loss: 0.42852927729487417\n",
      "trial: 10, epoch, 44, iter: 1, curr loss: 0.418500155210495, avg loss: 0.418500155210495\n",
      "trial: 10, epoch, 44, iter: 200, curr loss: 0.4294823408126831, avg loss: 0.4284998770058155\n",
      "trial: 10, epoch, 45, iter: 1, curr loss: 0.4224233031272888, avg loss: 0.4224233031272888\n",
      "trial: 10, epoch, 45, iter: 200, curr loss: 0.43982774019241333, avg loss: 0.42886980265378954\n",
      "trial: 10, epoch, 46, iter: 1, curr loss: 0.44306087493896484, avg loss: 0.44306087493896484\n",
      "trial: 10, epoch, 46, iter: 200, curr loss: 0.4302688241004944, avg loss: 0.42913351908326147\n",
      "trial: 10, epoch, 47, iter: 1, curr loss: 0.4359169602394104, avg loss: 0.4359169602394104\n",
      "trial: 10, epoch, 47, iter: 200, curr loss: 0.4355813264846802, avg loss: 0.42806736439466475\n",
      "trial: 10, epoch, 48, iter: 1, curr loss: 0.4192366600036621, avg loss: 0.4192366600036621\n",
      "trial: 10, epoch, 48, iter: 200, curr loss: 0.43417948484420776, avg loss: 0.42915969491004946\n",
      "trial: 10, epoch, 49, iter: 1, curr loss: 0.43768659234046936, avg loss: 0.43768659234046936\n",
      "trial: 10, epoch, 49, iter: 200, curr loss: 0.4310198426246643, avg loss: 0.42894173189997675\n",
      "trial: 10, epoch, 50, iter: 1, curr loss: 0.42442604899406433, avg loss: 0.42442604899406433\n",
      "trial: 10, epoch, 50, iter: 200, curr loss: 0.43547219038009644, avg loss: 0.42902776136994364\n",
      "trial: 10, ldr: 0.9174236059188843, dv: 0.9088253974914551, nwj: 0.9087883234024048\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 11, epoch, 1, iter: 1, curr loss: 0.6930997371673584, avg loss: 0.6930997371673584\n",
      "trial: 11, epoch, 1, iter: 200, curr loss: 0.4332854449748993, avg loss: 0.4561419695615768\n",
      "trial: 11, epoch, 2, iter: 1, curr loss: 0.4290592074394226, avg loss: 0.4290592074394226\n",
      "trial: 11, epoch, 2, iter: 200, curr loss: 0.426297664642334, avg loss: 0.43055160105228424\n",
      "trial: 11, epoch, 3, iter: 1, curr loss: 0.42701706290245056, avg loss: 0.42701706290245056\n",
      "trial: 11, epoch, 3, iter: 200, curr loss: 0.4309862554073334, avg loss: 0.4292122878134251\n",
      "trial: 11, epoch, 4, iter: 1, curr loss: 0.42704498767852783, avg loss: 0.42704498767852783\n",
      "trial: 11, epoch, 4, iter: 200, curr loss: 0.4342154562473297, avg loss: 0.42889107897877693\n",
      "trial: 11, epoch, 5, iter: 1, curr loss: 0.43588027358055115, avg loss: 0.43588027358055115\n",
      "trial: 11, epoch, 5, iter: 200, curr loss: 0.4222663640975952, avg loss: 0.42925903350114825\n",
      "trial: 11, epoch, 6, iter: 1, curr loss: 0.4320957660675049, avg loss: 0.4320957660675049\n",
      "trial: 11, epoch, 6, iter: 200, curr loss: 0.4372178912162781, avg loss: 0.42851423263549804\n",
      "trial: 11, epoch, 7, iter: 1, curr loss: 0.42560529708862305, avg loss: 0.42560529708862305\n",
      "trial: 11, epoch, 7, iter: 200, curr loss: 0.434778094291687, avg loss: 0.4290653499960899\n",
      "trial: 11, epoch, 8, iter: 1, curr loss: 0.4367617964744568, avg loss: 0.4367617964744568\n",
      "trial: 11, epoch, 8, iter: 200, curr loss: 0.422671914100647, avg loss: 0.42866170287132266\n",
      "trial: 11, epoch, 9, iter: 1, curr loss: 0.4505373537540436, avg loss: 0.4505373537540436\n",
      "trial: 11, epoch, 9, iter: 200, curr loss: 0.4206833243370056, avg loss: 0.4284347029030323\n",
      "trial: 11, epoch, 10, iter: 1, curr loss: 0.42479294538497925, avg loss: 0.42479294538497925\n",
      "trial: 11, epoch, 10, iter: 200, curr loss: 0.4264444410800934, avg loss: 0.4285516269505024\n",
      "trial: 11, epoch, 11, iter: 1, curr loss: 0.43597888946533203, avg loss: 0.43597888946533203\n",
      "trial: 11, epoch, 11, iter: 200, curr loss: 0.42401617765426636, avg loss: 0.4290365955233574\n",
      "trial: 11, epoch, 12, iter: 1, curr loss: 0.4395875930786133, avg loss: 0.4395875930786133\n",
      "trial: 11, epoch, 12, iter: 200, curr loss: 0.43425023555755615, avg loss: 0.42905766174197196\n",
      "trial: 11, epoch, 13, iter: 1, curr loss: 0.43589234352111816, avg loss: 0.43589234352111816\n",
      "trial: 11, epoch, 13, iter: 200, curr loss: 0.4237697124481201, avg loss: 0.42865530014038083\n",
      "trial: 11, epoch, 14, iter: 1, curr loss: 0.4295122027397156, avg loss: 0.4295122027397156\n",
      "trial: 11, epoch, 14, iter: 200, curr loss: 0.43399548530578613, avg loss: 0.4293733134865761\n",
      "trial: 11, epoch, 15, iter: 1, curr loss: 0.419270783662796, avg loss: 0.419270783662796\n",
      "trial: 11, epoch, 15, iter: 200, curr loss: 0.43235620856285095, avg loss: 0.42819350823760033\n",
      "trial: 11, epoch, 16, iter: 1, curr loss: 0.4284525513648987, avg loss: 0.4284525513648987\n",
      "trial: 11, epoch, 16, iter: 200, curr loss: 0.4342052638530731, avg loss: 0.4283528292179108\n",
      "trial: 11, epoch, 17, iter: 1, curr loss: 0.4266725182533264, avg loss: 0.4266725182533264\n",
      "trial: 11, epoch, 17, iter: 200, curr loss: 0.423711359500885, avg loss: 0.4289140725135803\n",
      "trial: 11, epoch, 18, iter: 1, curr loss: 0.43072599172592163, avg loss: 0.43072599172592163\n",
      "trial: 11, epoch, 18, iter: 200, curr loss: 0.4375069737434387, avg loss: 0.42900791376829145\n",
      "trial: 11, epoch, 19, iter: 1, curr loss: 0.4307195544242859, avg loss: 0.4307195544242859\n",
      "trial: 11, epoch, 19, iter: 200, curr loss: 0.4311731159687042, avg loss: 0.42832203313708306\n",
      "trial: 11, epoch, 20, iter: 1, curr loss: 0.43132928013801575, avg loss: 0.43132928013801575\n",
      "trial: 11, epoch, 20, iter: 200, curr loss: 0.42647498846054077, avg loss: 0.42843640327453614\n",
      "trial: 11, epoch, 21, iter: 1, curr loss: 0.43385565280914307, avg loss: 0.43385565280914307\n",
      "trial: 11, epoch, 21, iter: 200, curr loss: 0.4457687735557556, avg loss: 0.42902905836701394\n",
      "trial: 11, epoch, 22, iter: 1, curr loss: 0.43202218413352966, avg loss: 0.43202218413352966\n",
      "trial: 11, epoch, 22, iter: 200, curr loss: 0.436156302690506, avg loss: 0.4294960084557533\n",
      "trial: 11, epoch, 23, iter: 1, curr loss: 0.43817371129989624, avg loss: 0.43817371129989624\n",
      "trial: 11, epoch, 23, iter: 200, curr loss: 0.4175083041191101, avg loss: 0.42891795113682746\n",
      "trial: 11, epoch, 24, iter: 1, curr loss: 0.4325673580169678, avg loss: 0.4325673580169678\n",
      "trial: 11, epoch, 24, iter: 200, curr loss: 0.434245228767395, avg loss: 0.4282545590400696\n",
      "trial: 11, epoch, 25, iter: 1, curr loss: 0.43253082036972046, avg loss: 0.43253082036972046\n",
      "trial: 11, epoch, 25, iter: 200, curr loss: 0.4386630058288574, avg loss: 0.4287428040802479\n",
      "trial: 11, epoch, 26, iter: 1, curr loss: 0.43952152132987976, avg loss: 0.43952152132987976\n",
      "trial: 11, epoch, 26, iter: 200, curr loss: 0.44398051500320435, avg loss: 0.42888419434428215\n",
      "trial: 11, epoch, 27, iter: 1, curr loss: 0.42695116996765137, avg loss: 0.42695116996765137\n",
      "trial: 11, epoch, 27, iter: 200, curr loss: 0.42755353450775146, avg loss: 0.4288447956740856\n",
      "trial: 11, epoch, 28, iter: 1, curr loss: 0.438177227973938, avg loss: 0.438177227973938\n",
      "trial: 11, epoch, 28, iter: 200, curr loss: 0.43879270553588867, avg loss: 0.428951300829649\n",
      "trial: 11, epoch, 29, iter: 1, curr loss: 0.43544238805770874, avg loss: 0.43544238805770874\n",
      "trial: 11, epoch, 29, iter: 200, curr loss: 0.42946764826774597, avg loss: 0.42848109304904936\n",
      "trial: 11, epoch, 30, iter: 1, curr loss: 0.4320957660675049, avg loss: 0.4320957660675049\n",
      "trial: 11, epoch, 30, iter: 200, curr loss: 0.42569512128829956, avg loss: 0.42888741225004196\n",
      "trial: 11, epoch, 31, iter: 1, curr loss: 0.4237871766090393, avg loss: 0.4237871766090393\n",
      "trial: 11, epoch, 31, iter: 200, curr loss: 0.4222770929336548, avg loss: 0.4283114260435104\n",
      "trial: 11, epoch, 32, iter: 1, curr loss: 0.4364050626754761, avg loss: 0.4364050626754761\n",
      "trial: 11, epoch, 32, iter: 200, curr loss: 0.4368492364883423, avg loss: 0.4282288557291031\n",
      "trial: 11, epoch, 33, iter: 1, curr loss: 0.43277502059936523, avg loss: 0.43277502059936523\n",
      "trial: 11, epoch, 33, iter: 200, curr loss: 0.4293572008609772, avg loss: 0.4288502372801304\n",
      "trial: 11, epoch, 34, iter: 1, curr loss: 0.42603209614753723, avg loss: 0.42603209614753723\n",
      "trial: 11, epoch, 34, iter: 200, curr loss: 0.42263150215148926, avg loss: 0.4285926488041878\n",
      "trial: 11, epoch, 35, iter: 1, curr loss: 0.4350298047065735, avg loss: 0.4350298047065735\n",
      "trial: 11, epoch, 35, iter: 200, curr loss: 0.4390336275100708, avg loss: 0.4287681947648525\n",
      "trial: 11, epoch, 36, iter: 1, curr loss: 0.4368743300437927, avg loss: 0.4368743300437927\n",
      "trial: 11, epoch, 36, iter: 200, curr loss: 0.4263424277305603, avg loss: 0.42908439293503764\n",
      "trial: 11, epoch, 37, iter: 1, curr loss: 0.42999446392059326, avg loss: 0.42999446392059326\n",
      "trial: 11, epoch, 37, iter: 200, curr loss: 0.42802488803863525, avg loss: 0.4290048187971115\n",
      "trial: 11, epoch, 38, iter: 1, curr loss: 0.43544086813926697, avg loss: 0.43544086813926697\n",
      "trial: 11, epoch, 38, iter: 200, curr loss: 0.4151630103588104, avg loss: 0.4282687708735466\n",
      "trial: 11, epoch, 39, iter: 1, curr loss: 0.43109527230262756, avg loss: 0.43109527230262756\n",
      "trial: 11, epoch, 39, iter: 200, curr loss: 0.4340704083442688, avg loss: 0.42981149077415465\n",
      "trial: 11, epoch, 40, iter: 1, curr loss: 0.42753905057907104, avg loss: 0.42753905057907104\n",
      "trial: 11, epoch, 40, iter: 200, curr loss: 0.4317534863948822, avg loss: 0.4289629799127579\n",
      "trial: 11, epoch, 41, iter: 1, curr loss: 0.4360494017601013, avg loss: 0.4360494017601013\n",
      "trial: 11, epoch, 41, iter: 200, curr loss: 0.43540453910827637, avg loss: 0.428754114061594\n",
      "trial: 11, epoch, 42, iter: 1, curr loss: 0.42058223485946655, avg loss: 0.42058223485946655\n",
      "trial: 11, epoch, 42, iter: 200, curr loss: 0.44667935371398926, avg loss: 0.42841549932956696\n",
      "trial: 11, epoch, 43, iter: 1, curr loss: 0.427792489528656, avg loss: 0.427792489528656\n",
      "trial: 11, epoch, 43, iter: 200, curr loss: 0.4408043622970581, avg loss: 0.42879234373569486\n",
      "trial: 11, epoch, 44, iter: 1, curr loss: 0.4362030029296875, avg loss: 0.4362030029296875\n",
      "trial: 11, epoch, 44, iter: 200, curr loss: 0.43079322576522827, avg loss: 0.4288089726865292\n",
      "trial: 11, epoch, 45, iter: 1, curr loss: 0.4301338195800781, avg loss: 0.4301338195800781\n",
      "trial: 11, epoch, 45, iter: 200, curr loss: 0.42979657649993896, avg loss: 0.4287516823410988\n",
      "trial: 11, epoch, 46, iter: 1, curr loss: 0.43012773990631104, avg loss: 0.43012773990631104\n",
      "trial: 11, epoch, 46, iter: 200, curr loss: 0.42956334352493286, avg loss: 0.42827147752046585\n",
      "trial: 11, epoch, 47, iter: 1, curr loss: 0.4285762906074524, avg loss: 0.4285762906074524\n",
      "trial: 11, epoch, 47, iter: 200, curr loss: 0.42790597677230835, avg loss: 0.4283421975374222\n",
      "trial: 11, epoch, 48, iter: 1, curr loss: 0.4258810579776764, avg loss: 0.4258810579776764\n",
      "trial: 11, epoch, 48, iter: 200, curr loss: 0.4264877438545227, avg loss: 0.42883471205830576\n",
      "trial: 11, epoch, 49, iter: 1, curr loss: 0.42778530716896057, avg loss: 0.42778530716896057\n",
      "trial: 11, epoch, 49, iter: 200, curr loss: 0.4329301416873932, avg loss: 0.4293074171245098\n",
      "trial: 11, epoch, 50, iter: 1, curr loss: 0.42466944456100464, avg loss: 0.42466944456100464\n",
      "trial: 11, epoch, 50, iter: 200, curr loss: 0.42852845788002014, avg loss: 0.4288936385512352\n",
      "trial: 11, ldr: 0.8967441320419312, dv: 0.9084964394569397, nwj: 0.9084276556968689\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 12, epoch, 1, iter: 1, curr loss: 0.6928414106369019, avg loss: 0.6928414106369019\n",
      "trial: 12, epoch, 1, iter: 200, curr loss: 0.42150360345840454, avg loss: 0.45575236320495605\n",
      "trial: 12, epoch, 2, iter: 1, curr loss: 0.4375103712081909, avg loss: 0.4375103712081909\n",
      "trial: 12, epoch, 2, iter: 200, curr loss: 0.41876283288002014, avg loss: 0.4298926904797554\n",
      "trial: 12, epoch, 3, iter: 1, curr loss: 0.4219794273376465, avg loss: 0.4219794273376465\n",
      "trial: 12, epoch, 3, iter: 200, curr loss: 0.44024398922920227, avg loss: 0.42888652011752126\n",
      "trial: 12, epoch, 4, iter: 1, curr loss: 0.43054133653640747, avg loss: 0.43054133653640747\n",
      "trial: 12, epoch, 4, iter: 200, curr loss: 0.43522292375564575, avg loss: 0.42904608517885207\n",
      "trial: 12, epoch, 5, iter: 1, curr loss: 0.43165767192840576, avg loss: 0.43165767192840576\n",
      "trial: 12, epoch, 5, iter: 200, curr loss: 0.4304041862487793, avg loss: 0.4288255785405636\n",
      "trial: 12, epoch, 6, iter: 1, curr loss: 0.4236593246459961, avg loss: 0.4236593246459961\n",
      "trial: 12, epoch, 6, iter: 200, curr loss: 0.4332161545753479, avg loss: 0.4287270627915859\n",
      "trial: 12, epoch, 7, iter: 1, curr loss: 0.43182995915412903, avg loss: 0.43182995915412903\n",
      "trial: 12, epoch, 7, iter: 200, curr loss: 0.4414861798286438, avg loss: 0.4288831430673599\n",
      "trial: 12, epoch, 8, iter: 1, curr loss: 0.43522363901138306, avg loss: 0.43522363901138306\n",
      "trial: 12, epoch, 8, iter: 200, curr loss: 0.42387691140174866, avg loss: 0.42862297117710113\n",
      "trial: 12, epoch, 9, iter: 1, curr loss: 0.42195963859558105, avg loss: 0.42195963859558105\n",
      "trial: 12, epoch, 9, iter: 200, curr loss: 0.43067634105682373, avg loss: 0.4288710115849972\n",
      "trial: 12, epoch, 10, iter: 1, curr loss: 0.41879943013191223, avg loss: 0.41879943013191223\n",
      "trial: 12, epoch, 10, iter: 200, curr loss: 0.41917937994003296, avg loss: 0.42863236159086227\n",
      "trial: 12, epoch, 11, iter: 1, curr loss: 0.4204166829586029, avg loss: 0.4204166829586029\n",
      "trial: 12, epoch, 11, iter: 200, curr loss: 0.4281398355960846, avg loss: 0.42939860105514527\n",
      "trial: 12, epoch, 12, iter: 1, curr loss: 0.43267005681991577, avg loss: 0.43267005681991577\n",
      "trial: 12, epoch, 12, iter: 200, curr loss: 0.43630450963974, avg loss: 0.42812132626771926\n",
      "trial: 12, epoch, 13, iter: 1, curr loss: 0.4324503540992737, avg loss: 0.4324503540992737\n",
      "trial: 12, epoch, 13, iter: 200, curr loss: 0.4309612512588501, avg loss: 0.42931493327021597\n",
      "trial: 12, epoch, 14, iter: 1, curr loss: 0.43452274799346924, avg loss: 0.43452274799346924\n",
      "trial: 12, epoch, 14, iter: 200, curr loss: 0.4403155744075775, avg loss: 0.42965030029416085\n",
      "trial: 12, epoch, 15, iter: 1, curr loss: 0.4242318868637085, avg loss: 0.4242318868637085\n",
      "trial: 12, epoch, 15, iter: 200, curr loss: 0.42110222578048706, avg loss: 0.4284774285554886\n",
      "trial: 12, epoch, 16, iter: 1, curr loss: 0.43069034814834595, avg loss: 0.43069034814834595\n",
      "trial: 12, epoch, 16, iter: 200, curr loss: 0.4306640028953552, avg loss: 0.42891486614942553\n",
      "trial: 12, epoch, 17, iter: 1, curr loss: 0.43207550048828125, avg loss: 0.43207550048828125\n",
      "trial: 12, epoch, 17, iter: 200, curr loss: 0.431696355342865, avg loss: 0.42891629979014395\n",
      "trial: 12, epoch, 18, iter: 1, curr loss: 0.4338318407535553, avg loss: 0.4338318407535553\n",
      "trial: 12, epoch, 18, iter: 200, curr loss: 0.4247491955757141, avg loss: 0.4284931127727032\n",
      "trial: 12, epoch, 19, iter: 1, curr loss: 0.43415695428848267, avg loss: 0.43415695428848267\n",
      "trial: 12, epoch, 19, iter: 200, curr loss: 0.43088391423225403, avg loss: 0.4289239950478077\n",
      "trial: 12, epoch, 20, iter: 1, curr loss: 0.43911126255989075, avg loss: 0.43911126255989075\n",
      "trial: 12, epoch, 20, iter: 200, curr loss: 0.43495696783065796, avg loss: 0.42878454700112345\n",
      "trial: 12, epoch, 21, iter: 1, curr loss: 0.41725656390190125, avg loss: 0.41725656390190125\n",
      "trial: 12, epoch, 21, iter: 200, curr loss: 0.430915504693985, avg loss: 0.42905142560601234\n",
      "trial: 12, epoch, 22, iter: 1, curr loss: 0.42436566948890686, avg loss: 0.42436566948890686\n",
      "trial: 12, epoch, 22, iter: 200, curr loss: 0.4302064776420593, avg loss: 0.4288911764323711\n",
      "trial: 12, epoch, 23, iter: 1, curr loss: 0.43172532320022583, avg loss: 0.43172532320022583\n",
      "trial: 12, epoch, 23, iter: 200, curr loss: 0.42297351360321045, avg loss: 0.42897120282053947\n",
      "trial: 12, epoch, 24, iter: 1, curr loss: 0.4314579665660858, avg loss: 0.4314579665660858\n",
      "trial: 12, epoch, 24, iter: 200, curr loss: 0.43209153413772583, avg loss: 0.4306255288422108\n",
      "trial: 12, epoch, 25, iter: 1, curr loss: 0.420093834400177, avg loss: 0.420093834400177\n",
      "trial: 12, epoch, 25, iter: 200, curr loss: 0.4271586537361145, avg loss: 0.42882276251912116\n",
      "trial: 12, epoch, 26, iter: 1, curr loss: 0.435272753238678, avg loss: 0.435272753238678\n",
      "trial: 12, epoch, 26, iter: 200, curr loss: 0.4220123887062073, avg loss: 0.4292095986008644\n",
      "trial: 12, epoch, 27, iter: 1, curr loss: 0.42475420236587524, avg loss: 0.42475420236587524\n",
      "trial: 12, epoch, 27, iter: 200, curr loss: 0.43540602922439575, avg loss: 0.4285763254761696\n",
      "trial: 12, epoch, 28, iter: 1, curr loss: 0.4326857030391693, avg loss: 0.4326857030391693\n",
      "trial: 12, epoch, 28, iter: 200, curr loss: 0.4227502942085266, avg loss: 0.42908790335059166\n",
      "trial: 12, epoch, 29, iter: 1, curr loss: 0.4327130913734436, avg loss: 0.4327130913734436\n",
      "trial: 12, epoch, 29, iter: 200, curr loss: 0.42824190855026245, avg loss: 0.4288904593884945\n",
      "trial: 12, epoch, 30, iter: 1, curr loss: 0.42254555225372314, avg loss: 0.42254555225372314\n",
      "trial: 12, epoch, 30, iter: 200, curr loss: 0.42370501160621643, avg loss: 0.4295585457980633\n",
      "trial: 12, epoch, 31, iter: 1, curr loss: 0.42964857816696167, avg loss: 0.42964857816696167\n",
      "trial: 12, epoch, 31, iter: 200, curr loss: 0.4198431968688965, avg loss: 0.42844040378928183\n",
      "trial: 12, epoch, 32, iter: 1, curr loss: 0.4208838641643524, avg loss: 0.4208838641643524\n",
      "trial: 12, epoch, 32, iter: 200, curr loss: 0.4328533411026001, avg loss: 0.42859158471226694\n",
      "trial: 12, epoch, 33, iter: 1, curr loss: 0.4244594871997833, avg loss: 0.4244594871997833\n",
      "trial: 12, epoch, 33, iter: 200, curr loss: 0.43201228976249695, avg loss: 0.4287792873382568\n",
      "trial: 12, epoch, 34, iter: 1, curr loss: 0.4302368760108948, avg loss: 0.4302368760108948\n",
      "trial: 12, epoch, 34, iter: 200, curr loss: 0.42249566316604614, avg loss: 0.42879769697785375\n",
      "trial: 12, epoch, 35, iter: 1, curr loss: 0.42746636271476746, avg loss: 0.42746636271476746\n",
      "trial: 12, epoch, 35, iter: 200, curr loss: 0.43121057748794556, avg loss: 0.4283264078199863\n",
      "trial: 12, epoch, 36, iter: 1, curr loss: 0.42807379364967346, avg loss: 0.42807379364967346\n",
      "trial: 12, epoch, 36, iter: 200, curr loss: 0.4398045241832733, avg loss: 0.4291696755588055\n",
      "trial: 12, epoch, 37, iter: 1, curr loss: 0.4271140396595001, avg loss: 0.4271140396595001\n",
      "trial: 12, epoch, 37, iter: 200, curr loss: 0.41361096501350403, avg loss: 0.4282925289869308\n",
      "trial: 12, epoch, 38, iter: 1, curr loss: 0.4283626079559326, avg loss: 0.4283626079559326\n",
      "trial: 12, epoch, 38, iter: 200, curr loss: 0.42495453357696533, avg loss: 0.4288166879117489\n",
      "trial: 12, epoch, 39, iter: 1, curr loss: 0.42559924721717834, avg loss: 0.42559924721717834\n",
      "trial: 12, epoch, 39, iter: 200, curr loss: 0.44608354568481445, avg loss: 0.4286085832118988\n",
      "trial: 12, epoch, 40, iter: 1, curr loss: 0.4273654520511627, avg loss: 0.4273654520511627\n",
      "trial: 12, epoch, 40, iter: 200, curr loss: 0.43678271770477295, avg loss: 0.42893663093447687\n",
      "trial: 12, epoch, 41, iter: 1, curr loss: 0.4299449026584625, avg loss: 0.4299449026584625\n",
      "trial: 12, epoch, 41, iter: 200, curr loss: 0.4304341971874237, avg loss: 0.42883903488516806\n",
      "trial: 12, epoch, 42, iter: 1, curr loss: 0.44013512134552, avg loss: 0.44013512134552\n",
      "trial: 12, epoch, 42, iter: 200, curr loss: 0.4325123131275177, avg loss: 0.42889115408062933\n",
      "trial: 12, epoch, 43, iter: 1, curr loss: 0.42071276903152466, avg loss: 0.42071276903152466\n",
      "trial: 12, epoch, 43, iter: 200, curr loss: 0.43982183933258057, avg loss: 0.4289811971783638\n",
      "trial: 12, epoch, 44, iter: 1, curr loss: 0.43321049213409424, avg loss: 0.43321049213409424\n",
      "trial: 12, epoch, 44, iter: 200, curr loss: 0.4163426458835602, avg loss: 0.42873862385749817\n",
      "trial: 12, epoch, 45, iter: 1, curr loss: 0.42448854446411133, avg loss: 0.42448854446411133\n",
      "trial: 12, epoch, 45, iter: 200, curr loss: 0.42817097902297974, avg loss: 0.4289791092276573\n",
      "trial: 12, epoch, 46, iter: 1, curr loss: 0.43648383021354675, avg loss: 0.43648383021354675\n",
      "trial: 12, epoch, 46, iter: 200, curr loss: 0.4282916784286499, avg loss: 0.42896140545606615\n",
      "trial: 12, epoch, 47, iter: 1, curr loss: 0.4271615743637085, avg loss: 0.4271615743637085\n",
      "trial: 12, epoch, 47, iter: 200, curr loss: 0.45322367548942566, avg loss: 0.4290527135133743\n",
      "trial: 12, epoch, 48, iter: 1, curr loss: 0.42279520630836487, avg loss: 0.42279520630836487\n",
      "trial: 12, epoch, 48, iter: 200, curr loss: 0.4147791266441345, avg loss: 0.4290177583694458\n",
      "trial: 12, epoch, 49, iter: 1, curr loss: 0.4371752142906189, avg loss: 0.4371752142906189\n",
      "trial: 12, epoch, 49, iter: 200, curr loss: 0.42598190903663635, avg loss: 0.42910281524062155\n",
      "trial: 12, epoch, 50, iter: 1, curr loss: 0.4295195937156677, avg loss: 0.4295195937156677\n",
      "trial: 12, epoch, 50, iter: 200, curr loss: 0.4418504238128662, avg loss: 0.42927281886339186\n",
      "trial: 12, ldr: 0.9164705276489258, dv: 0.9088551998138428, nwj: 0.9088261127471924\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 13, epoch, 1, iter: 1, curr loss: 0.6931477785110474, avg loss: 0.6931477785110474\n",
      "trial: 13, epoch, 1, iter: 200, curr loss: 0.43831390142440796, avg loss: 0.4577137266099453\n",
      "trial: 13, epoch, 2, iter: 1, curr loss: 0.43279510736465454, avg loss: 0.43279510736465454\n",
      "trial: 13, epoch, 2, iter: 200, curr loss: 0.4336487352848053, avg loss: 0.4299637845158577\n",
      "trial: 13, epoch, 3, iter: 1, curr loss: 0.43511053919792175, avg loss: 0.43511053919792175\n",
      "trial: 13, epoch, 3, iter: 200, curr loss: 0.42499154806137085, avg loss: 0.42901782542467115\n",
      "trial: 13, epoch, 4, iter: 1, curr loss: 0.4351750612258911, avg loss: 0.4351750612258911\n",
      "trial: 13, epoch, 4, iter: 200, curr loss: 0.43039584159851074, avg loss: 0.4289409965276718\n",
      "trial: 13, epoch, 5, iter: 1, curr loss: 0.43306028842926025, avg loss: 0.43306028842926025\n",
      "trial: 13, epoch, 5, iter: 200, curr loss: 0.42532533407211304, avg loss: 0.4293201480805874\n",
      "trial: 13, epoch, 6, iter: 1, curr loss: 0.435899019241333, avg loss: 0.435899019241333\n",
      "trial: 13, epoch, 6, iter: 200, curr loss: 0.4243587851524353, avg loss: 0.4291154159605503\n",
      "trial: 13, epoch, 7, iter: 1, curr loss: 0.4329453110694885, avg loss: 0.4329453110694885\n",
      "trial: 13, epoch, 7, iter: 200, curr loss: 0.4315027594566345, avg loss: 0.42873873993754386\n",
      "trial: 13, epoch, 8, iter: 1, curr loss: 0.4274141788482666, avg loss: 0.4274141788482666\n",
      "trial: 13, epoch, 8, iter: 200, curr loss: 0.43735358119010925, avg loss: 0.4289198437333107\n",
      "trial: 13, epoch, 9, iter: 1, curr loss: 0.4222319722175598, avg loss: 0.4222319722175598\n",
      "trial: 13, epoch, 9, iter: 200, curr loss: 0.42841067910194397, avg loss: 0.4286817726492882\n",
      "trial: 13, epoch, 10, iter: 1, curr loss: 0.43769407272338867, avg loss: 0.43769407272338867\n",
      "trial: 13, epoch, 10, iter: 200, curr loss: 0.4288201332092285, avg loss: 0.429296073615551\n",
      "trial: 13, epoch, 11, iter: 1, curr loss: 0.43512213230133057, avg loss: 0.43512213230133057\n",
      "trial: 13, epoch, 11, iter: 200, curr loss: 0.42268839478492737, avg loss: 0.428768232613802\n",
      "trial: 13, epoch, 12, iter: 1, curr loss: 0.42484250664711, avg loss: 0.42484250664711\n",
      "trial: 13, epoch, 12, iter: 200, curr loss: 0.42999139428138733, avg loss: 0.42842301398515703\n",
      "trial: 13, epoch, 13, iter: 1, curr loss: 0.44553884863853455, avg loss: 0.44553884863853455\n",
      "trial: 13, epoch, 13, iter: 200, curr loss: 0.4153400659561157, avg loss: 0.4285489901900291\n",
      "trial: 13, epoch, 14, iter: 1, curr loss: 0.4322281777858734, avg loss: 0.4322281777858734\n",
      "trial: 13, epoch, 14, iter: 200, curr loss: 0.4420284032821655, avg loss: 0.42877235531806945\n",
      "trial: 13, epoch, 15, iter: 1, curr loss: 0.41913342475891113, avg loss: 0.41913342475891113\n",
      "trial: 13, epoch, 15, iter: 200, curr loss: 0.42521244287490845, avg loss: 0.4290049614012241\n",
      "trial: 13, epoch, 16, iter: 1, curr loss: 0.43449580669403076, avg loss: 0.43449580669403076\n",
      "trial: 13, epoch, 16, iter: 200, curr loss: 0.43390583992004395, avg loss: 0.429060740172863\n",
      "trial: 13, epoch, 17, iter: 1, curr loss: 0.4242973327636719, avg loss: 0.4242973327636719\n",
      "trial: 13, epoch, 17, iter: 200, curr loss: 0.43154460191726685, avg loss: 0.42828850835561755\n",
      "trial: 13, epoch, 18, iter: 1, curr loss: 0.43681633472442627, avg loss: 0.43681633472442627\n",
      "trial: 13, epoch, 18, iter: 200, curr loss: 0.42613548040390015, avg loss: 0.4289454986155033\n",
      "trial: 13, epoch, 19, iter: 1, curr loss: 0.43975409865379333, avg loss: 0.43975409865379333\n",
      "trial: 13, epoch, 19, iter: 200, curr loss: 0.4329778552055359, avg loss: 0.4284390707314014\n",
      "trial: 13, epoch, 20, iter: 1, curr loss: 0.42677050828933716, avg loss: 0.42677050828933716\n",
      "trial: 13, epoch, 20, iter: 200, curr loss: 0.4321810007095337, avg loss: 0.42926713451743126\n",
      "trial: 13, epoch, 21, iter: 1, curr loss: 0.4338448643684387, avg loss: 0.4338448643684387\n",
      "trial: 13, epoch, 21, iter: 200, curr loss: 0.4274359345436096, avg loss: 0.42915127128362657\n",
      "trial: 13, epoch, 22, iter: 1, curr loss: 0.44183772802352905, avg loss: 0.44183772802352905\n",
      "trial: 13, epoch, 22, iter: 200, curr loss: 0.4158136248588562, avg loss: 0.4288038203120232\n",
      "trial: 13, epoch, 23, iter: 1, curr loss: 0.4236055910587311, avg loss: 0.4236055910587311\n",
      "trial: 13, epoch, 23, iter: 200, curr loss: 0.42506539821624756, avg loss: 0.42853970527648927\n",
      "trial: 13, epoch, 24, iter: 1, curr loss: 0.4346649646759033, avg loss: 0.4346649646759033\n",
      "trial: 13, epoch, 24, iter: 200, curr loss: 0.4301554560661316, avg loss: 0.4283489860594273\n",
      "trial: 13, epoch, 25, iter: 1, curr loss: 0.4293659031391144, avg loss: 0.4293659031391144\n",
      "trial: 13, epoch, 25, iter: 200, curr loss: 0.4231317341327667, avg loss: 0.4285181540250778\n",
      "trial: 13, epoch, 26, iter: 1, curr loss: 0.43876221776008606, avg loss: 0.43876221776008606\n",
      "trial: 13, epoch, 26, iter: 200, curr loss: 0.4169641137123108, avg loss: 0.4285500195622444\n",
      "trial: 13, epoch, 27, iter: 1, curr loss: 0.41898778080940247, avg loss: 0.41898778080940247\n",
      "trial: 13, epoch, 27, iter: 200, curr loss: 0.4230439066886902, avg loss: 0.4288464629650116\n",
      "trial: 13, epoch, 28, iter: 1, curr loss: 0.42767971754074097, avg loss: 0.42767971754074097\n",
      "trial: 13, epoch, 28, iter: 200, curr loss: 0.43082815408706665, avg loss: 0.4288350585103035\n",
      "trial: 13, epoch, 29, iter: 1, curr loss: 0.4237421452999115, avg loss: 0.4237421452999115\n",
      "trial: 13, epoch, 29, iter: 200, curr loss: 0.42584460973739624, avg loss: 0.4285169941186905\n",
      "trial: 13, epoch, 30, iter: 1, curr loss: 0.4317392110824585, avg loss: 0.4317392110824585\n",
      "trial: 13, epoch, 30, iter: 200, curr loss: 0.4296966791152954, avg loss: 0.4284741799533367\n",
      "trial: 13, epoch, 31, iter: 1, curr loss: 0.4338288903236389, avg loss: 0.4338288903236389\n",
      "trial: 13, epoch, 31, iter: 200, curr loss: 0.42371445894241333, avg loss: 0.4289229576289654\n",
      "trial: 13, epoch, 32, iter: 1, curr loss: 0.4232753813266754, avg loss: 0.4232753813266754\n",
      "trial: 13, epoch, 32, iter: 200, curr loss: 0.4398501515388489, avg loss: 0.42915790259838105\n",
      "trial: 13, epoch, 33, iter: 1, curr loss: 0.4388124942779541, avg loss: 0.4388124942779541\n",
      "trial: 13, epoch, 33, iter: 200, curr loss: 0.42485567927360535, avg loss: 0.42855155825614927\n",
      "trial: 13, epoch, 34, iter: 1, curr loss: 0.4261416792869568, avg loss: 0.4261416792869568\n",
      "trial: 13, epoch, 34, iter: 200, curr loss: 0.4395180344581604, avg loss: 0.4289173918962479\n",
      "trial: 13, epoch, 35, iter: 1, curr loss: 0.43701499700546265, avg loss: 0.43701499700546265\n",
      "trial: 13, epoch, 35, iter: 200, curr loss: 0.423808217048645, avg loss: 0.42857327923178673\n",
      "trial: 13, epoch, 36, iter: 1, curr loss: 0.4247075915336609, avg loss: 0.4247075915336609\n",
      "trial: 13, epoch, 36, iter: 200, curr loss: 0.42522338032722473, avg loss: 0.429404786080122\n",
      "trial: 13, epoch, 37, iter: 1, curr loss: 0.42325925827026367, avg loss: 0.42325925827026367\n",
      "trial: 13, epoch, 37, iter: 200, curr loss: 0.41939786076545715, avg loss: 0.42843111902475356\n",
      "trial: 13, epoch, 38, iter: 1, curr loss: 0.42654862999916077, avg loss: 0.42654862999916077\n",
      "trial: 13, epoch, 38, iter: 200, curr loss: 0.4313259720802307, avg loss: 0.4284968447685242\n",
      "trial: 13, epoch, 39, iter: 1, curr loss: 0.43375301361083984, avg loss: 0.43375301361083984\n",
      "trial: 13, epoch, 39, iter: 200, curr loss: 0.4290507435798645, avg loss: 0.42857551425695417\n",
      "trial: 13, epoch, 40, iter: 1, curr loss: 0.423427939414978, avg loss: 0.423427939414978\n",
      "trial: 13, epoch, 40, iter: 200, curr loss: 0.4231369197368622, avg loss: 0.4288073033094406\n",
      "trial: 13, epoch, 41, iter: 1, curr loss: 0.4284111559391022, avg loss: 0.4284111559391022\n",
      "trial: 13, epoch, 41, iter: 200, curr loss: 0.4276999235153198, avg loss: 0.4280837807059288\n",
      "trial: 13, epoch, 42, iter: 1, curr loss: 0.429697722196579, avg loss: 0.429697722196579\n",
      "trial: 13, epoch, 42, iter: 200, curr loss: 0.43245023488998413, avg loss: 0.4285974909365177\n",
      "trial: 13, epoch, 43, iter: 1, curr loss: 0.4306931793689728, avg loss: 0.4306931793689728\n",
      "trial: 13, epoch, 43, iter: 200, curr loss: 0.43441373109817505, avg loss: 0.428830863982439\n",
      "trial: 13, epoch, 44, iter: 1, curr loss: 0.43584710359573364, avg loss: 0.43584710359573364\n",
      "trial: 13, epoch, 44, iter: 200, curr loss: 0.42197883129119873, avg loss: 0.42854617178440096\n",
      "trial: 13, epoch, 45, iter: 1, curr loss: 0.4350753426551819, avg loss: 0.4350753426551819\n",
      "trial: 13, epoch, 45, iter: 200, curr loss: 0.43328404426574707, avg loss: 0.429539086073637\n",
      "trial: 13, epoch, 46, iter: 1, curr loss: 0.4336913228034973, avg loss: 0.4336913228034973\n",
      "trial: 13, epoch, 46, iter: 200, curr loss: 0.42397597432136536, avg loss: 0.42830440431833267\n",
      "trial: 13, epoch, 47, iter: 1, curr loss: 0.4136158227920532, avg loss: 0.4136158227920532\n",
      "trial: 13, epoch, 47, iter: 200, curr loss: 0.4328955113887787, avg loss: 0.4288893286883831\n",
      "trial: 13, epoch, 48, iter: 1, curr loss: 0.43433964252471924, avg loss: 0.43433964252471924\n",
      "trial: 13, epoch, 48, iter: 200, curr loss: 0.43307971954345703, avg loss: 0.4286756268143654\n",
      "trial: 13, epoch, 49, iter: 1, curr loss: 0.439357727766037, avg loss: 0.439357727766037\n",
      "trial: 13, epoch, 49, iter: 200, curr loss: 0.43477439880371094, avg loss: 0.4280566707253456\n",
      "trial: 13, epoch, 50, iter: 1, curr loss: 0.4279531240463257, avg loss: 0.4279531240463257\n",
      "trial: 13, epoch, 50, iter: 200, curr loss: 0.44248372316360474, avg loss: 0.42869011759757997\n",
      "trial: 13, ldr: 0.8844284415245056, dv: 0.9087115526199341, nwj: 0.9084190726280212\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 14, epoch, 1, iter: 1, curr loss: 0.6937882304191589, avg loss: 0.6937882304191589\n",
      "trial: 14, epoch, 1, iter: 200, curr loss: 0.4423369765281677, avg loss: 0.4579078401625156\n",
      "trial: 14, epoch, 2, iter: 1, curr loss: 0.44172725081443787, avg loss: 0.44172725081443787\n",
      "trial: 14, epoch, 2, iter: 200, curr loss: 0.41717198491096497, avg loss: 0.4304508446156979\n",
      "trial: 14, epoch, 3, iter: 1, curr loss: 0.44317442178726196, avg loss: 0.44317442178726196\n",
      "trial: 14, epoch, 3, iter: 200, curr loss: 0.43099433183670044, avg loss: 0.4294515056908131\n",
      "trial: 14, epoch, 4, iter: 1, curr loss: 0.4311724305152893, avg loss: 0.4311724305152893\n",
      "trial: 14, epoch, 4, iter: 200, curr loss: 0.43017640709877014, avg loss: 0.4290919151902199\n",
      "trial: 14, epoch, 5, iter: 1, curr loss: 0.40599876642227173, avg loss: 0.40599876642227173\n",
      "trial: 14, epoch, 5, iter: 200, curr loss: 0.43664637207984924, avg loss: 0.42900159895420076\n",
      "trial: 14, epoch, 6, iter: 1, curr loss: 0.4400806427001953, avg loss: 0.4400806427001953\n",
      "trial: 14, epoch, 6, iter: 200, curr loss: 0.42750293016433716, avg loss: 0.42925496727228163\n",
      "trial: 14, epoch, 7, iter: 1, curr loss: 0.42137882113456726, avg loss: 0.42137882113456726\n",
      "trial: 14, epoch, 7, iter: 200, curr loss: 0.4418039917945862, avg loss: 0.4295627237856388\n",
      "trial: 14, epoch, 8, iter: 1, curr loss: 0.42593538761138916, avg loss: 0.42593538761138916\n",
      "trial: 14, epoch, 8, iter: 200, curr loss: 0.43012329936027527, avg loss: 0.42825300976634023\n",
      "trial: 14, epoch, 9, iter: 1, curr loss: 0.4265097379684448, avg loss: 0.4265097379684448\n",
      "trial: 14, epoch, 9, iter: 200, curr loss: 0.4332108497619629, avg loss: 0.4285272113978863\n",
      "trial: 14, epoch, 10, iter: 1, curr loss: 0.4419841468334198, avg loss: 0.4419841468334198\n",
      "trial: 14, epoch, 10, iter: 200, curr loss: 0.42473894357681274, avg loss: 0.42903775662183763\n",
      "trial: 14, epoch, 11, iter: 1, curr loss: 0.4411628842353821, avg loss: 0.4411628842353821\n",
      "trial: 14, epoch, 11, iter: 200, curr loss: 0.43823742866516113, avg loss: 0.42807292819023135\n",
      "trial: 14, epoch, 12, iter: 1, curr loss: 0.4353094696998596, avg loss: 0.4353094696998596\n",
      "trial: 14, epoch, 12, iter: 200, curr loss: 0.4318212866783142, avg loss: 0.42891389831900595\n",
      "trial: 14, epoch, 13, iter: 1, curr loss: 0.4228909909725189, avg loss: 0.4228909909725189\n",
      "trial: 14, epoch, 13, iter: 200, curr loss: 0.42858317494392395, avg loss: 0.4291273026168346\n",
      "trial: 14, epoch, 14, iter: 1, curr loss: 0.452825665473938, avg loss: 0.452825665473938\n",
      "trial: 14, epoch, 14, iter: 200, curr loss: 0.43663090467453003, avg loss: 0.4287672209739685\n",
      "trial: 14, epoch, 15, iter: 1, curr loss: 0.4310322403907776, avg loss: 0.4310322403907776\n",
      "trial: 14, epoch, 15, iter: 200, curr loss: 0.4208458662033081, avg loss: 0.4290757744014263\n",
      "trial: 14, epoch, 16, iter: 1, curr loss: 0.42598956823349, avg loss: 0.42598956823349\n",
      "trial: 14, epoch, 16, iter: 200, curr loss: 0.43247324228286743, avg loss: 0.4289169581234455\n",
      "trial: 14, epoch, 17, iter: 1, curr loss: 0.4333570897579193, avg loss: 0.4333570897579193\n",
      "trial: 14, epoch, 17, iter: 200, curr loss: 0.4268181622028351, avg loss: 0.42871964395046236\n",
      "trial: 14, epoch, 18, iter: 1, curr loss: 0.43079185485839844, avg loss: 0.43079185485839844\n",
      "trial: 14, epoch, 18, iter: 200, curr loss: 0.4309574067592621, avg loss: 0.42893663376569746\n",
      "trial: 14, epoch, 19, iter: 1, curr loss: 0.43595051765441895, avg loss: 0.43595051765441895\n",
      "trial: 14, epoch, 19, iter: 200, curr loss: 0.4220847487449646, avg loss: 0.428428930491209\n",
      "trial: 14, epoch, 20, iter: 1, curr loss: 0.42789894342422485, avg loss: 0.42789894342422485\n",
      "trial: 14, epoch, 20, iter: 200, curr loss: 0.44658756256103516, avg loss: 0.4286745148897171\n",
      "trial: 14, epoch, 21, iter: 1, curr loss: 0.4560545086860657, avg loss: 0.4560545086860657\n",
      "trial: 14, epoch, 21, iter: 200, curr loss: 0.4396393895149231, avg loss: 0.4286037890613079\n",
      "trial: 14, epoch, 22, iter: 1, curr loss: 0.43641403317451477, avg loss: 0.43641403317451477\n",
      "trial: 14, epoch, 22, iter: 200, curr loss: 0.44486695528030396, avg loss: 0.4286573627591133\n",
      "trial: 14, epoch, 23, iter: 1, curr loss: 0.4372972846031189, avg loss: 0.4372972846031189\n",
      "trial: 14, epoch, 23, iter: 200, curr loss: 0.4373883008956909, avg loss: 0.4290404751896858\n",
      "trial: 14, epoch, 24, iter: 1, curr loss: 0.4309903681278229, avg loss: 0.4309903681278229\n",
      "trial: 14, epoch, 24, iter: 200, curr loss: 0.4321911931037903, avg loss: 0.4284446632862091\n",
      "trial: 14, epoch, 25, iter: 1, curr loss: 0.43037277460098267, avg loss: 0.43037277460098267\n",
      "trial: 14, epoch, 25, iter: 200, curr loss: 0.4290039539337158, avg loss: 0.4286232951283455\n",
      "trial: 14, epoch, 26, iter: 1, curr loss: 0.423432320356369, avg loss: 0.423432320356369\n",
      "trial: 14, epoch, 26, iter: 200, curr loss: 0.4346134066581726, avg loss: 0.42913977190852165\n",
      "trial: 14, epoch, 27, iter: 1, curr loss: 0.4253964424133301, avg loss: 0.4253964424133301\n",
      "trial: 14, epoch, 27, iter: 200, curr loss: 0.42400920391082764, avg loss: 0.4285347719490528\n",
      "trial: 14, epoch, 28, iter: 1, curr loss: 0.4251326322555542, avg loss: 0.4251326322555542\n",
      "trial: 14, epoch, 28, iter: 200, curr loss: 0.4130186140537262, avg loss: 0.4289930222928524\n",
      "trial: 14, epoch, 29, iter: 1, curr loss: 0.43472158908843994, avg loss: 0.43472158908843994\n",
      "trial: 14, epoch, 29, iter: 200, curr loss: 0.4328693747520447, avg loss: 0.42901220470666884\n",
      "trial: 14, epoch, 30, iter: 1, curr loss: 0.41466784477233887, avg loss: 0.41466784477233887\n",
      "trial: 14, epoch, 30, iter: 200, curr loss: 0.4262394905090332, avg loss: 0.4287101174890995\n",
      "trial: 14, epoch, 31, iter: 1, curr loss: 0.4360933005809784, avg loss: 0.4360933005809784\n",
      "trial: 14, epoch, 31, iter: 200, curr loss: 0.4263090491294861, avg loss: 0.42835367009043696\n",
      "trial: 14, epoch, 32, iter: 1, curr loss: 0.42078930139541626, avg loss: 0.42078930139541626\n",
      "trial: 14, epoch, 32, iter: 200, curr loss: 0.4362320899963379, avg loss: 0.42921163856983185\n",
      "trial: 14, epoch, 33, iter: 1, curr loss: 0.4258456230163574, avg loss: 0.4258456230163574\n",
      "trial: 14, epoch, 33, iter: 200, curr loss: 0.435918927192688, avg loss: 0.4282745254039764\n",
      "trial: 14, epoch, 34, iter: 1, curr loss: 0.42890554666519165, avg loss: 0.42890554666519165\n",
      "trial: 14, epoch, 34, iter: 200, curr loss: 0.4224294424057007, avg loss: 0.4291043815016746\n",
      "trial: 14, epoch, 35, iter: 1, curr loss: 0.4266517758369446, avg loss: 0.4266517758369446\n",
      "trial: 14, epoch, 35, iter: 200, curr loss: 0.43160879611968994, avg loss: 0.4283455215394497\n",
      "trial: 14, epoch, 36, iter: 1, curr loss: 0.43356460332870483, avg loss: 0.43356460332870483\n",
      "trial: 14, epoch, 36, iter: 200, curr loss: 0.4327038526535034, avg loss: 0.4287717768549919\n",
      "trial: 14, epoch, 37, iter: 1, curr loss: 0.4253492057323456, avg loss: 0.4253492057323456\n",
      "trial: 14, epoch, 37, iter: 200, curr loss: 0.4238521456718445, avg loss: 0.42876538276672366\n",
      "trial: 14, epoch, 38, iter: 1, curr loss: 0.4285666048526764, avg loss: 0.4285666048526764\n",
      "trial: 14, epoch, 38, iter: 200, curr loss: 0.44373857975006104, avg loss: 0.428566847294569\n",
      "trial: 14, epoch, 39, iter: 1, curr loss: 0.4292636513710022, avg loss: 0.4292636513710022\n",
      "trial: 14, epoch, 39, iter: 200, curr loss: 0.4238223731517792, avg loss: 0.4285794100165367\n",
      "trial: 14, epoch, 40, iter: 1, curr loss: 0.4353123903274536, avg loss: 0.4353123903274536\n",
      "trial: 14, epoch, 40, iter: 200, curr loss: 0.4236341714859009, avg loss: 0.42826597034931185\n",
      "trial: 14, epoch, 41, iter: 1, curr loss: 0.43990829586982727, avg loss: 0.43990829586982727\n",
      "trial: 14, epoch, 41, iter: 200, curr loss: 0.43705010414123535, avg loss: 0.4288345022499561\n",
      "trial: 14, epoch, 42, iter: 1, curr loss: 0.42454153299331665, avg loss: 0.42454153299331665\n",
      "trial: 14, epoch, 42, iter: 200, curr loss: 0.427337110042572, avg loss: 0.428962482213974\n",
      "trial: 14, epoch, 43, iter: 1, curr loss: 0.43325942754745483, avg loss: 0.43325942754745483\n",
      "trial: 14, epoch, 43, iter: 200, curr loss: 0.43851685523986816, avg loss: 0.4290956893563271\n",
      "trial: 14, epoch, 44, iter: 1, curr loss: 0.42455923557281494, avg loss: 0.42455923557281494\n",
      "trial: 14, epoch, 44, iter: 200, curr loss: 0.4292527139186859, avg loss: 0.4284232832491398\n",
      "trial: 14, epoch, 45, iter: 1, curr loss: 0.43511438369750977, avg loss: 0.43511438369750977\n",
      "trial: 14, epoch, 45, iter: 200, curr loss: 0.4217972159385681, avg loss: 0.42858981862664225\n",
      "trial: 14, epoch, 46, iter: 1, curr loss: 0.430630624294281, avg loss: 0.430630624294281\n",
      "trial: 14, epoch, 46, iter: 200, curr loss: 0.43917566537857056, avg loss: 0.4286655615270138\n",
      "trial: 14, epoch, 47, iter: 1, curr loss: 0.4212990403175354, avg loss: 0.4212990403175354\n",
      "trial: 14, epoch, 47, iter: 200, curr loss: 0.4434432089328766, avg loss: 0.4286933785676956\n",
      "trial: 14, epoch, 48, iter: 1, curr loss: 0.42709505558013916, avg loss: 0.42709505558013916\n",
      "trial: 14, epoch, 48, iter: 200, curr loss: 0.4298531413078308, avg loss: 0.4289727123081684\n",
      "trial: 14, epoch, 49, iter: 1, curr loss: 0.42812228202819824, avg loss: 0.42812228202819824\n",
      "trial: 14, epoch, 49, iter: 200, curr loss: 0.42778444290161133, avg loss: 0.4285712994635105\n",
      "trial: 14, epoch, 50, iter: 1, curr loss: 0.4397372603416443, avg loss: 0.4397372603416443\n",
      "trial: 14, epoch, 50, iter: 200, curr loss: 0.4240753650665283, avg loss: 0.42817767456173894\n",
      "trial: 14, ldr: 0.938231885433197, dv: 0.9083431959152222, nwj: 0.9078920483589172\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 15, epoch, 1, iter: 1, curr loss: 0.6951887607574463, avg loss: 0.6951887607574463\n",
      "trial: 15, epoch, 1, iter: 200, curr loss: 0.43632256984710693, avg loss: 0.45566880390048026\n",
      "trial: 15, epoch, 2, iter: 1, curr loss: 0.4409804344177246, avg loss: 0.4409804344177246\n",
      "trial: 15, epoch, 2, iter: 200, curr loss: 0.42544347047805786, avg loss: 0.4300841473042965\n",
      "trial: 15, epoch, 3, iter: 1, curr loss: 0.4268302917480469, avg loss: 0.4268302917480469\n",
      "trial: 15, epoch, 3, iter: 200, curr loss: 0.43465888500213623, avg loss: 0.42967766270041463\n",
      "trial: 15, epoch, 4, iter: 1, curr loss: 0.4376700520515442, avg loss: 0.4376700520515442\n",
      "trial: 15, epoch, 4, iter: 200, curr loss: 0.4447152018547058, avg loss: 0.4287608949840069\n",
      "trial: 15, epoch, 5, iter: 1, curr loss: 0.4285736083984375, avg loss: 0.4285736083984375\n",
      "trial: 15, epoch, 5, iter: 200, curr loss: 0.44070249795913696, avg loss: 0.4286982581019402\n",
      "trial: 15, epoch, 6, iter: 1, curr loss: 0.4342000186443329, avg loss: 0.4342000186443329\n",
      "trial: 15, epoch, 6, iter: 200, curr loss: 0.4373801052570343, avg loss: 0.42846692323684693\n",
      "trial: 15, epoch, 7, iter: 1, curr loss: 0.427761435508728, avg loss: 0.427761435508728\n",
      "trial: 15, epoch, 7, iter: 200, curr loss: 0.4321613013744354, avg loss: 0.429376335889101\n",
      "trial: 15, epoch, 8, iter: 1, curr loss: 0.42540329694747925, avg loss: 0.42540329694747925\n",
      "trial: 15, epoch, 8, iter: 200, curr loss: 0.445883184671402, avg loss: 0.4288168244063854\n",
      "trial: 15, epoch, 9, iter: 1, curr loss: 0.427440345287323, avg loss: 0.427440345287323\n",
      "trial: 15, epoch, 9, iter: 200, curr loss: 0.43224823474884033, avg loss: 0.4294762320816517\n",
      "trial: 15, epoch, 10, iter: 1, curr loss: 0.4321390688419342, avg loss: 0.4321390688419342\n",
      "trial: 15, epoch, 10, iter: 200, curr loss: 0.43511340022087097, avg loss: 0.4288709858059883\n",
      "trial: 15, epoch, 11, iter: 1, curr loss: 0.43422552943229675, avg loss: 0.43422552943229675\n",
      "trial: 15, epoch, 11, iter: 200, curr loss: 0.4358069896697998, avg loss: 0.4293284425139427\n",
      "trial: 15, epoch, 12, iter: 1, curr loss: 0.4254004955291748, avg loss: 0.4254004955291748\n",
      "trial: 15, epoch, 12, iter: 200, curr loss: 0.42465391755104065, avg loss: 0.4290550611913204\n",
      "trial: 15, epoch, 13, iter: 1, curr loss: 0.4337499737739563, avg loss: 0.4337499737739563\n",
      "trial: 15, epoch, 13, iter: 200, curr loss: 0.4293680787086487, avg loss: 0.42930478051304816\n",
      "trial: 15, epoch, 14, iter: 1, curr loss: 0.4269218444824219, avg loss: 0.4269218444824219\n",
      "trial: 15, epoch, 14, iter: 200, curr loss: 0.427731990814209, avg loss: 0.42835699453949927\n",
      "trial: 15, epoch, 15, iter: 1, curr loss: 0.435446172952652, avg loss: 0.435446172952652\n",
      "trial: 15, epoch, 15, iter: 200, curr loss: 0.43229854106903076, avg loss: 0.42924421101808546\n",
      "trial: 15, epoch, 16, iter: 1, curr loss: 0.4293481111526489, avg loss: 0.4293481111526489\n",
      "trial: 15, epoch, 16, iter: 200, curr loss: 0.42035111784935, avg loss: 0.4287530170381069\n",
      "trial: 15, epoch, 17, iter: 1, curr loss: 0.4405165910720825, avg loss: 0.4405165910720825\n",
      "trial: 15, epoch, 17, iter: 200, curr loss: 0.4297039210796356, avg loss: 0.4292536300420761\n",
      "trial: 15, epoch, 18, iter: 1, curr loss: 0.4216098189353943, avg loss: 0.4216098189353943\n",
      "trial: 15, epoch, 18, iter: 200, curr loss: 0.4447806477546692, avg loss: 0.42954092383384707\n",
      "trial: 15, epoch, 19, iter: 1, curr loss: 0.42519640922546387, avg loss: 0.42519640922546387\n",
      "trial: 15, epoch, 19, iter: 200, curr loss: 0.43291157484054565, avg loss: 0.4284351319074631\n",
      "trial: 15, epoch, 20, iter: 1, curr loss: 0.42041414976119995, avg loss: 0.42041414976119995\n",
      "trial: 15, epoch, 20, iter: 200, curr loss: 0.4385558068752289, avg loss: 0.42836575359106066\n",
      "trial: 15, epoch, 21, iter: 1, curr loss: 0.42346620559692383, avg loss: 0.42346620559692383\n",
      "trial: 15, epoch, 21, iter: 200, curr loss: 0.4192051887512207, avg loss: 0.42891687735915185\n",
      "trial: 15, epoch, 22, iter: 1, curr loss: 0.4265974760055542, avg loss: 0.4265974760055542\n",
      "trial: 15, epoch, 22, iter: 200, curr loss: 0.42419788241386414, avg loss: 0.4287800492346287\n",
      "trial: 15, epoch, 23, iter: 1, curr loss: 0.42913156747817993, avg loss: 0.42913156747817993\n",
      "trial: 15, epoch, 23, iter: 200, curr loss: 0.43076229095458984, avg loss: 0.42904495537281034\n",
      "trial: 15, epoch, 24, iter: 1, curr loss: 0.43538713455200195, avg loss: 0.43538713455200195\n",
      "trial: 15, epoch, 24, iter: 200, curr loss: 0.4285387396812439, avg loss: 0.4289815640449524\n",
      "trial: 15, epoch, 25, iter: 1, curr loss: 0.43558964133262634, avg loss: 0.43558964133262634\n",
      "trial: 15, epoch, 25, iter: 200, curr loss: 0.4342796206474304, avg loss: 0.4291109685599804\n",
      "trial: 15, epoch, 26, iter: 1, curr loss: 0.43171772360801697, avg loss: 0.43171772360801697\n",
      "trial: 15, epoch, 26, iter: 200, curr loss: 0.4370739161968231, avg loss: 0.42896055668592453\n",
      "trial: 15, epoch, 27, iter: 1, curr loss: 0.43168535828590393, avg loss: 0.43168535828590393\n",
      "trial: 15, epoch, 27, iter: 200, curr loss: 0.422989159822464, avg loss: 0.4290049946308136\n",
      "trial: 15, epoch, 28, iter: 1, curr loss: 0.4271079897880554, avg loss: 0.4271079897880554\n",
      "trial: 15, epoch, 28, iter: 200, curr loss: 0.430070161819458, avg loss: 0.4286587162315845\n",
      "trial: 15, epoch, 29, iter: 1, curr loss: 0.4399944841861725, avg loss: 0.4399944841861725\n",
      "trial: 15, epoch, 29, iter: 200, curr loss: 0.43599599599838257, avg loss: 0.4288107752799988\n",
      "trial: 15, epoch, 30, iter: 1, curr loss: 0.42879992723464966, avg loss: 0.42879992723464966\n",
      "trial: 15, epoch, 30, iter: 200, curr loss: 0.4253675639629364, avg loss: 0.4281000091135502\n",
      "trial: 15, epoch, 31, iter: 1, curr loss: 0.4236035943031311, avg loss: 0.4236035943031311\n",
      "trial: 15, epoch, 31, iter: 200, curr loss: 0.4370808005332947, avg loss: 0.4284783412516117\n",
      "trial: 15, epoch, 32, iter: 1, curr loss: 0.4196617007255554, avg loss: 0.4196617007255554\n",
      "trial: 15, epoch, 32, iter: 200, curr loss: 0.4266326427459717, avg loss: 0.42902426213026046\n",
      "trial: 15, epoch, 33, iter: 1, curr loss: 0.43220824003219604, avg loss: 0.43220824003219604\n",
      "trial: 15, epoch, 33, iter: 200, curr loss: 0.4330284893512726, avg loss: 0.42802524343132975\n",
      "trial: 15, epoch, 34, iter: 1, curr loss: 0.4344974458217621, avg loss: 0.4344974458217621\n",
      "trial: 15, epoch, 34, iter: 200, curr loss: 0.424353688955307, avg loss: 0.4289873722195625\n",
      "trial: 15, epoch, 35, iter: 1, curr loss: 0.4338311553001404, avg loss: 0.4338311553001404\n",
      "trial: 15, epoch, 35, iter: 200, curr loss: 0.4388377368450165, avg loss: 0.4288444672524929\n",
      "trial: 15, epoch, 36, iter: 1, curr loss: 0.4309353232383728, avg loss: 0.4309353232383728\n",
      "trial: 15, epoch, 36, iter: 200, curr loss: 0.4307287335395813, avg loss: 0.42898724555969237\n",
      "trial: 15, epoch, 37, iter: 1, curr loss: 0.43424439430236816, avg loss: 0.43424439430236816\n",
      "trial: 15, epoch, 37, iter: 200, curr loss: 0.435586154460907, avg loss: 0.42848888888955117\n",
      "trial: 15, epoch, 38, iter: 1, curr loss: 0.43448004126548767, avg loss: 0.43448004126548767\n",
      "trial: 15, epoch, 38, iter: 200, curr loss: 0.4305645823478699, avg loss: 0.42833594486117366\n",
      "trial: 15, epoch, 39, iter: 1, curr loss: 0.42835110425949097, avg loss: 0.42835110425949097\n",
      "trial: 15, epoch, 39, iter: 200, curr loss: 0.43435484170913696, avg loss: 0.4287263998389244\n",
      "trial: 15, epoch, 40, iter: 1, curr loss: 0.43446874618530273, avg loss: 0.43446874618530273\n",
      "trial: 15, epoch, 40, iter: 200, curr loss: 0.42956942319869995, avg loss: 0.42775071039795876\n",
      "trial: 15, epoch, 41, iter: 1, curr loss: 0.43125391006469727, avg loss: 0.43125391006469727\n",
      "trial: 15, epoch, 41, iter: 200, curr loss: 0.43883687257766724, avg loss: 0.4288957488536835\n",
      "trial: 15, epoch, 42, iter: 1, curr loss: 0.44533729553222656, avg loss: 0.44533729553222656\n",
      "trial: 15, epoch, 42, iter: 200, curr loss: 0.4465487599372864, avg loss: 0.42904445543885233\n",
      "trial: 15, epoch, 43, iter: 1, curr loss: 0.4295108914375305, avg loss: 0.4295108914375305\n",
      "trial: 15, epoch, 43, iter: 200, curr loss: 0.4245508909225464, avg loss: 0.4294429592788219\n",
      "trial: 15, epoch, 44, iter: 1, curr loss: 0.42933914065361023, avg loss: 0.42933914065361023\n",
      "trial: 15, epoch, 44, iter: 200, curr loss: 0.4270873963832855, avg loss: 0.4288593043386936\n",
      "trial: 15, epoch, 45, iter: 1, curr loss: 0.4412359595298767, avg loss: 0.4412359595298767\n",
      "trial: 15, epoch, 45, iter: 200, curr loss: 0.43512019515037537, avg loss: 0.4288958019018173\n",
      "trial: 15, epoch, 46, iter: 1, curr loss: 0.43516626954078674, avg loss: 0.43516626954078674\n",
      "trial: 15, epoch, 46, iter: 200, curr loss: 0.4211176633834839, avg loss: 0.4286924520134926\n",
      "trial: 15, epoch, 47, iter: 1, curr loss: 0.4339852035045624, avg loss: 0.4339852035045624\n",
      "trial: 15, epoch, 47, iter: 200, curr loss: 0.44367480278015137, avg loss: 0.42897350385785105\n",
      "trial: 15, epoch, 48, iter: 1, curr loss: 0.43633127212524414, avg loss: 0.43633127212524414\n",
      "trial: 15, epoch, 48, iter: 200, curr loss: 0.4261549711227417, avg loss: 0.42853726163506506\n",
      "trial: 15, epoch, 49, iter: 1, curr loss: 0.42382627725601196, avg loss: 0.42382627725601196\n",
      "trial: 15, epoch, 49, iter: 200, curr loss: 0.43903371691703796, avg loss: 0.4288960003852844\n",
      "trial: 15, epoch, 50, iter: 1, curr loss: 0.4231722354888916, avg loss: 0.4231722354888916\n",
      "trial: 15, epoch, 50, iter: 200, curr loss: 0.42760369181632996, avg loss: 0.4284923757612705\n",
      "trial: 15, ldr: 0.8957305550575256, dv: 0.9088579416275024, nwj: 0.9087721705436707\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 16, epoch, 1, iter: 1, curr loss: 0.6932544112205505, avg loss: 0.6932544112205505\n",
      "trial: 16, epoch, 1, iter: 200, curr loss: 0.4427981376647949, avg loss: 0.4587409035861492\n",
      "trial: 16, epoch, 2, iter: 1, curr loss: 0.4342613220214844, avg loss: 0.4342613220214844\n",
      "trial: 16, epoch, 2, iter: 200, curr loss: 0.4215892553329468, avg loss: 0.4305285860598087\n",
      "trial: 16, epoch, 3, iter: 1, curr loss: 0.4219270944595337, avg loss: 0.4219270944595337\n",
      "trial: 16, epoch, 3, iter: 200, curr loss: 0.41565534472465515, avg loss: 0.4296883481740952\n",
      "trial: 16, epoch, 4, iter: 1, curr loss: 0.42506709694862366, avg loss: 0.42506709694862366\n",
      "trial: 16, epoch, 4, iter: 200, curr loss: 0.42843908071517944, avg loss: 0.4286235195398331\n",
      "trial: 16, epoch, 5, iter: 1, curr loss: 0.4274829924106598, avg loss: 0.4274829924106598\n",
      "trial: 16, epoch, 5, iter: 200, curr loss: 0.43972158432006836, avg loss: 0.42888970047235486\n",
      "trial: 16, epoch, 6, iter: 1, curr loss: 0.4215748608112335, avg loss: 0.4215748608112335\n",
      "trial: 16, epoch, 6, iter: 200, curr loss: 0.43215304613113403, avg loss: 0.42936438873410226\n",
      "trial: 16, epoch, 7, iter: 1, curr loss: 0.43288421630859375, avg loss: 0.43288421630859375\n",
      "trial: 16, epoch, 7, iter: 200, curr loss: 0.43709808588027954, avg loss: 0.4291632942855358\n",
      "trial: 16, epoch, 8, iter: 1, curr loss: 0.43478602170944214, avg loss: 0.43478602170944214\n",
      "trial: 16, epoch, 8, iter: 200, curr loss: 0.4272589385509491, avg loss: 0.42918953821063044\n",
      "trial: 16, epoch, 9, iter: 1, curr loss: 0.4376046061515808, avg loss: 0.4376046061515808\n",
      "trial: 16, epoch, 9, iter: 200, curr loss: 0.42989981174468994, avg loss: 0.4289314603805542\n",
      "trial: 16, epoch, 10, iter: 1, curr loss: 0.41147956252098083, avg loss: 0.41147956252098083\n",
      "trial: 16, epoch, 10, iter: 200, curr loss: 0.4361051321029663, avg loss: 0.4291068062186241\n",
      "trial: 16, epoch, 11, iter: 1, curr loss: 0.43979156017303467, avg loss: 0.43979156017303467\n",
      "trial: 16, epoch, 11, iter: 200, curr loss: 0.42294174432754517, avg loss: 0.42822460845112803\n",
      "trial: 16, epoch, 12, iter: 1, curr loss: 0.41616299748420715, avg loss: 0.41616299748420715\n",
      "trial: 16, epoch, 12, iter: 200, curr loss: 0.4310673475265503, avg loss: 0.42874789163470267\n",
      "trial: 16, epoch, 13, iter: 1, curr loss: 0.42775875329971313, avg loss: 0.42775875329971313\n",
      "trial: 16, epoch, 13, iter: 200, curr loss: 0.4297827482223511, avg loss: 0.428720962703228\n",
      "trial: 16, epoch, 14, iter: 1, curr loss: 0.4302867650985718, avg loss: 0.4302867650985718\n",
      "trial: 16, epoch, 14, iter: 200, curr loss: 0.4284677803516388, avg loss: 0.42855962842702866\n",
      "trial: 16, epoch, 15, iter: 1, curr loss: 0.43844956159591675, avg loss: 0.43844956159591675\n",
      "trial: 16, epoch, 15, iter: 200, curr loss: 0.4241785407066345, avg loss: 0.42838481470942497\n",
      "trial: 16, epoch, 16, iter: 1, curr loss: 0.4403073191642761, avg loss: 0.4403073191642761\n",
      "trial: 16, epoch, 16, iter: 200, curr loss: 0.4348997175693512, avg loss: 0.4288469375669956\n",
      "trial: 16, epoch, 17, iter: 1, curr loss: 0.43113887310028076, avg loss: 0.43113887310028076\n",
      "trial: 16, epoch, 17, iter: 200, curr loss: 0.4302540123462677, avg loss: 0.428827099353075\n",
      "trial: 16, epoch, 18, iter: 1, curr loss: 0.43466073274612427, avg loss: 0.43466073274612427\n",
      "trial: 16, epoch, 18, iter: 200, curr loss: 0.43548107147216797, avg loss: 0.42928716614842416\n",
      "trial: 16, epoch, 19, iter: 1, curr loss: 0.4320027828216553, avg loss: 0.4320027828216553\n",
      "trial: 16, epoch, 19, iter: 200, curr loss: 0.4361772835254669, avg loss: 0.42853768199682235\n",
      "trial: 16, epoch, 20, iter: 1, curr loss: 0.42343199253082275, avg loss: 0.42343199253082275\n",
      "trial: 16, epoch, 20, iter: 200, curr loss: 0.43122637271881104, avg loss: 0.42856904059648515\n",
      "trial: 16, epoch, 21, iter: 1, curr loss: 0.4310700297355652, avg loss: 0.4310700297355652\n",
      "trial: 16, epoch, 21, iter: 200, curr loss: 0.4310299754142761, avg loss: 0.4282411277294159\n",
      "trial: 16, epoch, 22, iter: 1, curr loss: 0.42892253398895264, avg loss: 0.42892253398895264\n",
      "trial: 16, epoch, 22, iter: 200, curr loss: 0.42848584055900574, avg loss: 0.4289644077420235\n",
      "trial: 16, epoch, 23, iter: 1, curr loss: 0.4210168123245239, avg loss: 0.4210168123245239\n",
      "trial: 16, epoch, 23, iter: 200, curr loss: 0.4222942292690277, avg loss: 0.42845101058483126\n",
      "trial: 16, epoch, 24, iter: 1, curr loss: 0.43906036019325256, avg loss: 0.43906036019325256\n",
      "trial: 16, epoch, 24, iter: 200, curr loss: 0.42802274227142334, avg loss: 0.4284027634561062\n",
      "trial: 16, epoch, 25, iter: 1, curr loss: 0.4225074052810669, avg loss: 0.4225074052810669\n",
      "trial: 16, epoch, 25, iter: 200, curr loss: 0.42051470279693604, avg loss: 0.42894970417022704\n",
      "trial: 16, epoch, 26, iter: 1, curr loss: 0.4360487461090088, avg loss: 0.4360487461090088\n",
      "trial: 16, epoch, 26, iter: 200, curr loss: 0.4314771294593811, avg loss: 0.42939934983849526\n",
      "trial: 16, epoch, 27, iter: 1, curr loss: 0.43000584840774536, avg loss: 0.43000584840774536\n",
      "trial: 16, epoch, 27, iter: 200, curr loss: 0.4375033378601074, avg loss: 0.42884367242455484\n",
      "trial: 16, epoch, 28, iter: 1, curr loss: 0.4343636631965637, avg loss: 0.4343636631965637\n",
      "trial: 16, epoch, 28, iter: 200, curr loss: 0.4241785407066345, avg loss: 0.4291291582584381\n",
      "trial: 16, epoch, 29, iter: 1, curr loss: 0.44250136613845825, avg loss: 0.44250136613845825\n",
      "trial: 16, epoch, 29, iter: 200, curr loss: 0.4296410083770752, avg loss: 0.4282364249229431\n",
      "trial: 16, epoch, 30, iter: 1, curr loss: 0.4348030090332031, avg loss: 0.4348030090332031\n",
      "trial: 16, epoch, 30, iter: 200, curr loss: 0.4320344030857086, avg loss: 0.42858815878629686\n",
      "trial: 16, epoch, 31, iter: 1, curr loss: 0.43065372109413147, avg loss: 0.43065372109413147\n",
      "trial: 16, epoch, 31, iter: 200, curr loss: 0.42792990803718567, avg loss: 0.4285353384912014\n",
      "trial: 16, epoch, 32, iter: 1, curr loss: 0.42015907168388367, avg loss: 0.42015907168388367\n",
      "trial: 16, epoch, 32, iter: 200, curr loss: 0.4230114221572876, avg loss: 0.4285984916985035\n",
      "trial: 16, epoch, 33, iter: 1, curr loss: 0.4375469982624054, avg loss: 0.4375469982624054\n",
      "trial: 16, epoch, 33, iter: 200, curr loss: 0.42803508043289185, avg loss: 0.42827944427728654\n",
      "trial: 16, epoch, 34, iter: 1, curr loss: 0.42811667919158936, avg loss: 0.42811667919158936\n",
      "trial: 16, epoch, 34, iter: 200, curr loss: 0.4160473942756653, avg loss: 0.42843219444155695\n",
      "trial: 16, epoch, 35, iter: 1, curr loss: 0.42431339621543884, avg loss: 0.42431339621543884\n",
      "trial: 16, epoch, 35, iter: 200, curr loss: 0.42208132147789, avg loss: 0.4283658593893051\n",
      "trial: 16, epoch, 36, iter: 1, curr loss: 0.42284321784973145, avg loss: 0.42284321784973145\n",
      "trial: 16, epoch, 36, iter: 200, curr loss: 0.43539705872535706, avg loss: 0.4289659008383751\n",
      "trial: 16, epoch, 37, iter: 1, curr loss: 0.42084676027297974, avg loss: 0.42084676027297974\n",
      "trial: 16, epoch, 37, iter: 200, curr loss: 0.4279947876930237, avg loss: 0.4288682393729687\n",
      "trial: 16, epoch, 38, iter: 1, curr loss: 0.42818665504455566, avg loss: 0.42818665504455566\n",
      "trial: 16, epoch, 38, iter: 200, curr loss: 0.4258962571620941, avg loss: 0.4287535160779953\n",
      "trial: 16, epoch, 39, iter: 1, curr loss: 0.4369269013404846, avg loss: 0.4369269013404846\n",
      "trial: 16, epoch, 39, iter: 200, curr loss: 0.4218466579914093, avg loss: 0.4284030328691006\n",
      "trial: 16, epoch, 40, iter: 1, curr loss: 0.43604737520217896, avg loss: 0.43604737520217896\n",
      "trial: 16, epoch, 40, iter: 200, curr loss: 0.4375869631767273, avg loss: 0.429010334610939\n",
      "trial: 16, epoch, 41, iter: 1, curr loss: 0.43545806407928467, avg loss: 0.43545806407928467\n",
      "trial: 16, epoch, 41, iter: 200, curr loss: 0.42648857831954956, avg loss: 0.42861168548464773\n",
      "trial: 16, epoch, 42, iter: 1, curr loss: 0.435127854347229, avg loss: 0.435127854347229\n",
      "trial: 16, epoch, 42, iter: 200, curr loss: 0.44204598665237427, avg loss: 0.4292909336090088\n",
      "trial: 16, epoch, 43, iter: 1, curr loss: 0.4264068603515625, avg loss: 0.4264068603515625\n",
      "trial: 16, epoch, 43, iter: 200, curr loss: 0.4378366768360138, avg loss: 0.42854391619563104\n",
      "trial: 16, epoch, 44, iter: 1, curr loss: 0.4204369783401489, avg loss: 0.4204369783401489\n",
      "trial: 16, epoch, 44, iter: 200, curr loss: 0.43072324991226196, avg loss: 0.42877261608839035\n",
      "trial: 16, epoch, 45, iter: 1, curr loss: 0.4299640655517578, avg loss: 0.4299640655517578\n",
      "trial: 16, epoch, 45, iter: 200, curr loss: 0.4349903464317322, avg loss: 0.42856755435466765\n",
      "trial: 16, epoch, 46, iter: 1, curr loss: 0.42113250494003296, avg loss: 0.42113250494003296\n",
      "trial: 16, epoch, 46, iter: 200, curr loss: 0.4365262985229492, avg loss: 0.42884672686457637\n",
      "trial: 16, epoch, 47, iter: 1, curr loss: 0.4291831851005554, avg loss: 0.4291831851005554\n",
      "trial: 16, epoch, 47, iter: 200, curr loss: 0.4286835789680481, avg loss: 0.42849750608205794\n",
      "trial: 16, epoch, 48, iter: 1, curr loss: 0.4269905686378479, avg loss: 0.4269905686378479\n",
      "trial: 16, epoch, 48, iter: 200, curr loss: 0.4217853546142578, avg loss: 0.4297268855571747\n",
      "trial: 16, epoch, 49, iter: 1, curr loss: 0.43665245175361633, avg loss: 0.43665245175361633\n",
      "trial: 16, epoch, 49, iter: 200, curr loss: 0.4304267168045044, avg loss: 0.4288369308412075\n",
      "trial: 16, epoch, 50, iter: 1, curr loss: 0.4308338165283203, avg loss: 0.4308338165283203\n",
      "trial: 16, epoch, 50, iter: 200, curr loss: 0.4286290407180786, avg loss: 0.4290466122329235\n",
      "trial: 16, ldr: 0.901008129119873, dv: 0.9087849855422974, nwj: 0.908754825592041\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 17, epoch, 1, iter: 1, curr loss: 0.6940277814865112, avg loss: 0.6940277814865112\n",
      "trial: 17, epoch, 1, iter: 200, curr loss: 0.425235778093338, avg loss: 0.4567072461545467\n",
      "trial: 17, epoch, 2, iter: 1, curr loss: 0.4372556805610657, avg loss: 0.4372556805610657\n",
      "trial: 17, epoch, 2, iter: 200, curr loss: 0.4414282739162445, avg loss: 0.4300676484405994\n",
      "trial: 17, epoch, 3, iter: 1, curr loss: 0.430076539516449, avg loss: 0.430076539516449\n",
      "trial: 17, epoch, 3, iter: 200, curr loss: 0.4359220862388611, avg loss: 0.42970309615135194\n",
      "trial: 17, epoch, 4, iter: 1, curr loss: 0.4228975772857666, avg loss: 0.4228975772857666\n",
      "trial: 17, epoch, 4, iter: 200, curr loss: 0.4194551110267639, avg loss: 0.42905308336019515\n",
      "trial: 17, epoch, 5, iter: 1, curr loss: 0.42792487144470215, avg loss: 0.42792487144470215\n",
      "trial: 17, epoch, 5, iter: 200, curr loss: 0.4385507106781006, avg loss: 0.42865269050002097\n",
      "trial: 17, epoch, 6, iter: 1, curr loss: 0.4299178123474121, avg loss: 0.4299178123474121\n",
      "trial: 17, epoch, 6, iter: 200, curr loss: 0.43297791481018066, avg loss: 0.42901128515601156\n",
      "trial: 17, epoch, 7, iter: 1, curr loss: 0.4363979697227478, avg loss: 0.4363979697227478\n",
      "trial: 17, epoch, 7, iter: 200, curr loss: 0.42536288499832153, avg loss: 0.4289928208291531\n",
      "trial: 17, epoch, 8, iter: 1, curr loss: 0.4328697919845581, avg loss: 0.4328697919845581\n",
      "trial: 17, epoch, 8, iter: 200, curr loss: 0.43812096118927, avg loss: 0.429124725908041\n",
      "trial: 17, epoch, 9, iter: 1, curr loss: 0.44392129778862, avg loss: 0.44392129778862\n",
      "trial: 17, epoch, 9, iter: 200, curr loss: 0.4221007227897644, avg loss: 0.4286403737962246\n",
      "trial: 17, epoch, 10, iter: 1, curr loss: 0.4342744052410126, avg loss: 0.4342744052410126\n",
      "trial: 17, epoch, 10, iter: 200, curr loss: 0.4376736283302307, avg loss: 0.42892474606633185\n",
      "trial: 17, epoch, 11, iter: 1, curr loss: 0.43390244245529175, avg loss: 0.43390244245529175\n",
      "trial: 17, epoch, 11, iter: 200, curr loss: 0.4409010410308838, avg loss: 0.42893380045890805\n",
      "trial: 17, epoch, 12, iter: 1, curr loss: 0.4310535788536072, avg loss: 0.4310535788536072\n",
      "trial: 17, epoch, 12, iter: 200, curr loss: 0.4352417290210724, avg loss: 0.4293603013455868\n",
      "trial: 17, epoch, 13, iter: 1, curr loss: 0.42900288105010986, avg loss: 0.42900288105010986\n",
      "trial: 17, epoch, 13, iter: 200, curr loss: 0.42527467012405396, avg loss: 0.42909141138195994\n",
      "trial: 17, epoch, 14, iter: 1, curr loss: 0.4351629912853241, avg loss: 0.4351629912853241\n",
      "trial: 17, epoch, 14, iter: 200, curr loss: 0.4297574758529663, avg loss: 0.42897418320178987\n",
      "trial: 17, epoch, 15, iter: 1, curr loss: 0.42077383399009705, avg loss: 0.42077383399009705\n",
      "trial: 17, epoch, 15, iter: 200, curr loss: 0.42833083868026733, avg loss: 0.4289132545888424\n",
      "trial: 17, epoch, 16, iter: 1, curr loss: 0.437853068113327, avg loss: 0.437853068113327\n",
      "trial: 17, epoch, 16, iter: 200, curr loss: 0.43190956115722656, avg loss: 0.42893353804945944\n",
      "trial: 17, epoch, 17, iter: 1, curr loss: 0.4354309141635895, avg loss: 0.4354309141635895\n",
      "trial: 17, epoch, 17, iter: 200, curr loss: 0.433466374874115, avg loss: 0.4288632872700691\n",
      "trial: 17, epoch, 18, iter: 1, curr loss: 0.434211790561676, avg loss: 0.434211790561676\n",
      "trial: 17, epoch, 18, iter: 200, curr loss: 0.4219697117805481, avg loss: 0.42863510906696317\n",
      "trial: 17, epoch, 19, iter: 1, curr loss: 0.43451350927352905, avg loss: 0.43451350927352905\n",
      "trial: 17, epoch, 19, iter: 200, curr loss: 0.44690972566604614, avg loss: 0.42827545627951624\n",
      "trial: 17, epoch, 20, iter: 1, curr loss: 0.42450082302093506, avg loss: 0.42450082302093506\n",
      "trial: 17, epoch, 20, iter: 200, curr loss: 0.42845964431762695, avg loss: 0.42880071997642516\n",
      "trial: 17, epoch, 21, iter: 1, curr loss: 0.44423961639404297, avg loss: 0.44423961639404297\n",
      "trial: 17, epoch, 21, iter: 200, curr loss: 0.44157645106315613, avg loss: 0.4291538491845131\n",
      "trial: 17, epoch, 22, iter: 1, curr loss: 0.4207223355770111, avg loss: 0.4207223355770111\n",
      "trial: 17, epoch, 22, iter: 200, curr loss: 0.4261518120765686, avg loss: 0.4285324490070343\n",
      "trial: 17, epoch, 23, iter: 1, curr loss: 0.4532378911972046, avg loss: 0.4532378911972046\n",
      "trial: 17, epoch, 23, iter: 200, curr loss: 0.43441328406333923, avg loss: 0.4284888772666454\n",
      "trial: 17, epoch, 24, iter: 1, curr loss: 0.42077070474624634, avg loss: 0.42077070474624634\n",
      "trial: 17, epoch, 24, iter: 200, curr loss: 0.44895729422569275, avg loss: 0.4282760679721832\n",
      "trial: 17, epoch, 25, iter: 1, curr loss: 0.4338854253292084, avg loss: 0.4338854253292084\n",
      "trial: 17, epoch, 25, iter: 200, curr loss: 0.43709486722946167, avg loss: 0.42839825585484503\n",
      "trial: 17, epoch, 26, iter: 1, curr loss: 0.41611143946647644, avg loss: 0.41611143946647644\n",
      "trial: 17, epoch, 26, iter: 200, curr loss: 0.43178418278694153, avg loss: 0.4281652647256851\n",
      "trial: 17, epoch, 27, iter: 1, curr loss: 0.430192768573761, avg loss: 0.430192768573761\n",
      "trial: 17, epoch, 27, iter: 200, curr loss: 0.4330320656299591, avg loss: 0.4287304885685444\n",
      "trial: 17, epoch, 28, iter: 1, curr loss: 0.4305739998817444, avg loss: 0.4305739998817444\n",
      "trial: 17, epoch, 28, iter: 200, curr loss: 0.43253451585769653, avg loss: 0.42856964498758315\n",
      "trial: 17, epoch, 29, iter: 1, curr loss: 0.43719977140426636, avg loss: 0.43719977140426636\n",
      "trial: 17, epoch, 29, iter: 200, curr loss: 0.42085587978363037, avg loss: 0.42879368364810944\n",
      "trial: 17, epoch, 30, iter: 1, curr loss: 0.43335431814193726, avg loss: 0.43335431814193726\n",
      "trial: 17, epoch, 30, iter: 200, curr loss: 0.42426568269729614, avg loss: 0.4285804469883442\n",
      "trial: 17, epoch, 31, iter: 1, curr loss: 0.4211859107017517, avg loss: 0.4211859107017517\n",
      "trial: 17, epoch, 31, iter: 200, curr loss: 0.43015873432159424, avg loss: 0.42841635599732397\n",
      "trial: 17, epoch, 32, iter: 1, curr loss: 0.43628787994384766, avg loss: 0.43628787994384766\n",
      "trial: 17, epoch, 32, iter: 200, curr loss: 0.4229780435562134, avg loss: 0.42869495883584025\n",
      "trial: 17, epoch, 33, iter: 1, curr loss: 0.42054635286331177, avg loss: 0.42054635286331177\n",
      "trial: 17, epoch, 33, iter: 200, curr loss: 0.4488086402416229, avg loss: 0.4288894318044186\n",
      "trial: 17, epoch, 34, iter: 1, curr loss: 0.4280966520309448, avg loss: 0.4280966520309448\n",
      "trial: 17, epoch, 34, iter: 200, curr loss: 0.43174952268600464, avg loss: 0.42904418632388114\n",
      "trial: 17, epoch, 35, iter: 1, curr loss: 0.42685967683792114, avg loss: 0.42685967683792114\n",
      "trial: 17, epoch, 35, iter: 200, curr loss: 0.4253789782524109, avg loss: 0.4279034803807735\n",
      "trial: 17, epoch, 36, iter: 1, curr loss: 0.43627727031707764, avg loss: 0.43627727031707764\n",
      "trial: 17, epoch, 36, iter: 200, curr loss: 0.4383470416069031, avg loss: 0.4285093630850315\n",
      "trial: 17, epoch, 37, iter: 1, curr loss: 0.43198397755622864, avg loss: 0.43198397755622864\n",
      "trial: 17, epoch, 37, iter: 200, curr loss: 0.42584091424942017, avg loss: 0.42865136951208116\n",
      "trial: 17, epoch, 38, iter: 1, curr loss: 0.42920517921447754, avg loss: 0.42920517921447754\n",
      "trial: 17, epoch, 38, iter: 200, curr loss: 0.42922383546829224, avg loss: 0.42915563568472864\n",
      "trial: 17, epoch, 39, iter: 1, curr loss: 0.4327002763748169, avg loss: 0.4327002763748169\n",
      "trial: 17, epoch, 39, iter: 200, curr loss: 0.429178386926651, avg loss: 0.42841697350144387\n",
      "trial: 17, epoch, 40, iter: 1, curr loss: 0.41844338178634644, avg loss: 0.41844338178634644\n",
      "trial: 17, epoch, 40, iter: 200, curr loss: 0.4324190616607666, avg loss: 0.429124096930027\n",
      "trial: 17, epoch, 41, iter: 1, curr loss: 0.43910256028175354, avg loss: 0.43910256028175354\n",
      "trial: 17, epoch, 41, iter: 200, curr loss: 0.4401074945926666, avg loss: 0.42904300555586816\n",
      "trial: 17, epoch, 42, iter: 1, curr loss: 0.43512725830078125, avg loss: 0.43512725830078125\n",
      "trial: 17, epoch, 42, iter: 200, curr loss: 0.4337491989135742, avg loss: 0.4286974410712719\n",
      "trial: 17, epoch, 43, iter: 1, curr loss: 0.4213690161705017, avg loss: 0.4213690161705017\n",
      "trial: 17, epoch, 43, iter: 200, curr loss: 0.4341910183429718, avg loss: 0.4282022726535797\n",
      "trial: 17, epoch, 44, iter: 1, curr loss: 0.42377060651779175, avg loss: 0.42377060651779175\n",
      "trial: 17, epoch, 44, iter: 200, curr loss: 0.434550017118454, avg loss: 0.4289462706446648\n",
      "trial: 17, epoch, 45, iter: 1, curr loss: 0.4177374541759491, avg loss: 0.4177374541759491\n",
      "trial: 17, epoch, 45, iter: 200, curr loss: 0.44181138277053833, avg loss: 0.42853624939918517\n",
      "trial: 17, epoch, 46, iter: 1, curr loss: 0.441008061170578, avg loss: 0.441008061170578\n",
      "trial: 17, epoch, 46, iter: 200, curr loss: 0.42675459384918213, avg loss: 0.42897204741835593\n",
      "trial: 17, epoch, 47, iter: 1, curr loss: 0.431423157453537, avg loss: 0.431423157453537\n",
      "trial: 17, epoch, 47, iter: 200, curr loss: 0.4276878833770752, avg loss: 0.4292242032289505\n",
      "trial: 17, epoch, 48, iter: 1, curr loss: 0.444307804107666, avg loss: 0.444307804107666\n",
      "trial: 17, epoch, 48, iter: 200, curr loss: 0.43502405285835266, avg loss: 0.4289527352154255\n",
      "trial: 17, epoch, 49, iter: 1, curr loss: 0.429667204618454, avg loss: 0.429667204618454\n",
      "trial: 17, epoch, 49, iter: 200, curr loss: 0.4322856664657593, avg loss: 0.4290778034925461\n",
      "trial: 17, epoch, 50, iter: 1, curr loss: 0.434589147567749, avg loss: 0.434589147567749\n",
      "trial: 17, epoch, 50, iter: 200, curr loss: 0.43486762046813965, avg loss: 0.4290290987491608\n",
      "trial: 17, ldr: 0.8874731063842773, dv: 0.9086766242980957, nwj: 0.9084534049034119\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 18, epoch, 1, iter: 1, curr loss: 0.6938086748123169, avg loss: 0.6938086748123169\n",
      "trial: 18, epoch, 1, iter: 200, curr loss: 0.4318639636039734, avg loss: 0.4574288675189018\n",
      "trial: 18, epoch, 2, iter: 1, curr loss: 0.4311671853065491, avg loss: 0.4311671853065491\n",
      "trial: 18, epoch, 2, iter: 200, curr loss: 0.4404231905937195, avg loss: 0.43109700486063957\n",
      "trial: 18, epoch, 3, iter: 1, curr loss: 0.43488818407058716, avg loss: 0.43488818407058716\n",
      "trial: 18, epoch, 3, iter: 200, curr loss: 0.4363821744918823, avg loss: 0.4292389343678951\n",
      "trial: 18, epoch, 4, iter: 1, curr loss: 0.43269574642181396, avg loss: 0.43269574642181396\n",
      "trial: 18, epoch, 4, iter: 200, curr loss: 0.4217411279678345, avg loss: 0.42879082798957824\n",
      "trial: 18, epoch, 5, iter: 1, curr loss: 0.4346393942832947, avg loss: 0.4346393942832947\n",
      "trial: 18, epoch, 5, iter: 200, curr loss: 0.4184389114379883, avg loss: 0.42990163251757624\n",
      "trial: 18, epoch, 6, iter: 1, curr loss: 0.4402049481868744, avg loss: 0.4402049481868744\n",
      "trial: 18, epoch, 6, iter: 200, curr loss: 0.42496615648269653, avg loss: 0.42853217631578444\n",
      "trial: 18, epoch, 7, iter: 1, curr loss: 0.4293426275253296, avg loss: 0.4293426275253296\n",
      "trial: 18, epoch, 7, iter: 200, curr loss: 0.43177148699760437, avg loss: 0.4292611311376095\n",
      "trial: 18, epoch, 8, iter: 1, curr loss: 0.44217532873153687, avg loss: 0.44217532873153687\n",
      "trial: 18, epoch, 8, iter: 200, curr loss: 0.4279068112373352, avg loss: 0.4293399895727634\n",
      "trial: 18, epoch, 9, iter: 1, curr loss: 0.43149006366729736, avg loss: 0.43149006366729736\n",
      "trial: 18, epoch, 9, iter: 200, curr loss: 0.4316807687282562, avg loss: 0.4291504111886024\n",
      "trial: 18, epoch, 10, iter: 1, curr loss: 0.4275578260421753, avg loss: 0.4275578260421753\n",
      "trial: 18, epoch, 10, iter: 200, curr loss: 0.42108356952667236, avg loss: 0.4286113639175892\n",
      "trial: 18, epoch, 11, iter: 1, curr loss: 0.4217008948326111, avg loss: 0.4217008948326111\n",
      "trial: 18, epoch, 11, iter: 200, curr loss: 0.44262439012527466, avg loss: 0.4290630370378494\n",
      "trial: 18, epoch, 12, iter: 1, curr loss: 0.4329042136669159, avg loss: 0.4329042136669159\n",
      "trial: 18, epoch, 12, iter: 200, curr loss: 0.44319629669189453, avg loss: 0.4280077649652958\n",
      "trial: 18, epoch, 13, iter: 1, curr loss: 0.42581355571746826, avg loss: 0.42581355571746826\n",
      "trial: 18, epoch, 13, iter: 200, curr loss: 0.4302898943424225, avg loss: 0.4288708512485027\n",
      "trial: 18, epoch, 14, iter: 1, curr loss: 0.42697522044181824, avg loss: 0.42697522044181824\n",
      "trial: 18, epoch, 14, iter: 200, curr loss: 0.4197613000869751, avg loss: 0.42948166757822037\n",
      "trial: 18, epoch, 15, iter: 1, curr loss: 0.42980316281318665, avg loss: 0.42980316281318665\n",
      "trial: 18, epoch, 15, iter: 200, curr loss: 0.43067747354507446, avg loss: 0.4287420806288719\n",
      "trial: 18, epoch, 16, iter: 1, curr loss: 0.41885364055633545, avg loss: 0.41885364055633545\n",
      "trial: 18, epoch, 16, iter: 200, curr loss: 0.4188370704650879, avg loss: 0.42878907278180123\n",
      "trial: 18, epoch, 17, iter: 1, curr loss: 0.42110997438430786, avg loss: 0.42110997438430786\n",
      "trial: 18, epoch, 17, iter: 200, curr loss: 0.4402526319026947, avg loss: 0.4293477723002434\n",
      "trial: 18, epoch, 18, iter: 1, curr loss: 0.4276010990142822, avg loss: 0.4276010990142822\n",
      "trial: 18, epoch, 18, iter: 200, curr loss: 0.4332859516143799, avg loss: 0.42845328867435456\n",
      "trial: 18, epoch, 19, iter: 1, curr loss: 0.42751544713974, avg loss: 0.42751544713974\n",
      "trial: 18, epoch, 19, iter: 200, curr loss: 0.4298233389854431, avg loss: 0.42852767691016197\n",
      "trial: 18, epoch, 20, iter: 1, curr loss: 0.42861804366111755, avg loss: 0.42861804366111755\n",
      "trial: 18, epoch, 20, iter: 200, curr loss: 0.4293401539325714, avg loss: 0.4285717026889324\n",
      "trial: 18, epoch, 21, iter: 1, curr loss: 0.4246644377708435, avg loss: 0.4246644377708435\n",
      "trial: 18, epoch, 21, iter: 200, curr loss: 0.43404796719551086, avg loss: 0.4291017831861973\n",
      "trial: 18, epoch, 22, iter: 1, curr loss: 0.42475390434265137, avg loss: 0.42475390434265137\n",
      "trial: 18, epoch, 22, iter: 200, curr loss: 0.43360939621925354, avg loss: 0.42854683443903924\n",
      "trial: 18, epoch, 23, iter: 1, curr loss: 0.43324947357177734, avg loss: 0.43324947357177734\n",
      "trial: 18, epoch, 23, iter: 200, curr loss: 0.426010400056839, avg loss: 0.4291216292977333\n",
      "trial: 18, epoch, 24, iter: 1, curr loss: 0.429873526096344, avg loss: 0.429873526096344\n",
      "trial: 18, epoch, 24, iter: 200, curr loss: 0.44179725646972656, avg loss: 0.42871122479438784\n",
      "trial: 18, epoch, 25, iter: 1, curr loss: 0.43277043104171753, avg loss: 0.43277043104171753\n",
      "trial: 18, epoch, 25, iter: 200, curr loss: 0.4357433319091797, avg loss: 0.4287239754199982\n",
      "trial: 18, epoch, 26, iter: 1, curr loss: 0.4387340545654297, avg loss: 0.4387340545654297\n",
      "trial: 18, epoch, 26, iter: 200, curr loss: 0.4311803877353668, avg loss: 0.42919085174798965\n",
      "trial: 18, epoch, 27, iter: 1, curr loss: 0.4352923631668091, avg loss: 0.4352923631668091\n",
      "trial: 18, epoch, 27, iter: 200, curr loss: 0.439142644405365, avg loss: 0.4289430660009384\n",
      "trial: 18, epoch, 28, iter: 1, curr loss: 0.4234650731086731, avg loss: 0.4234650731086731\n",
      "trial: 18, epoch, 28, iter: 200, curr loss: 0.4410068094730377, avg loss: 0.42848513409495353\n",
      "trial: 18, epoch, 29, iter: 1, curr loss: 0.4320354461669922, avg loss: 0.4320354461669922\n",
      "trial: 18, epoch, 29, iter: 200, curr loss: 0.4299781322479248, avg loss: 0.42853322744369504\n",
      "trial: 18, epoch, 30, iter: 1, curr loss: 0.4338114559650421, avg loss: 0.4338114559650421\n",
      "trial: 18, epoch, 30, iter: 200, curr loss: 0.4268264174461365, avg loss: 0.4287107582390308\n",
      "trial: 18, epoch, 31, iter: 1, curr loss: 0.43571317195892334, avg loss: 0.43571317195892334\n",
      "trial: 18, epoch, 31, iter: 200, curr loss: 0.4316466450691223, avg loss: 0.4288058836758137\n",
      "trial: 18, epoch, 32, iter: 1, curr loss: 0.4373818635940552, avg loss: 0.4373818635940552\n",
      "trial: 18, epoch, 32, iter: 200, curr loss: 0.42794913053512573, avg loss: 0.42846414014697076\n",
      "trial: 18, epoch, 33, iter: 1, curr loss: 0.4182002544403076, avg loss: 0.4182002544403076\n",
      "trial: 18, epoch, 33, iter: 200, curr loss: 0.42478832602500916, avg loss: 0.4285405072569847\n",
      "trial: 18, epoch, 34, iter: 1, curr loss: 0.4451909065246582, avg loss: 0.4451909065246582\n",
      "trial: 18, epoch, 34, iter: 200, curr loss: 0.42585620284080505, avg loss: 0.4282986576855183\n",
      "trial: 18, epoch, 35, iter: 1, curr loss: 0.43629753589630127, avg loss: 0.43629753589630127\n",
      "trial: 18, epoch, 35, iter: 200, curr loss: 0.42375028133392334, avg loss: 0.4288549765944481\n",
      "trial: 18, epoch, 36, iter: 1, curr loss: 0.42995014786720276, avg loss: 0.42995014786720276\n",
      "trial: 18, epoch, 36, iter: 200, curr loss: 0.4214302897453308, avg loss: 0.4288118514418602\n",
      "trial: 18, epoch, 37, iter: 1, curr loss: 0.43890875577926636, avg loss: 0.43890875577926636\n",
      "trial: 18, epoch, 37, iter: 200, curr loss: 0.43192967772483826, avg loss: 0.4282895694673061\n",
      "trial: 18, epoch, 38, iter: 1, curr loss: 0.4313812553882599, avg loss: 0.4313812553882599\n",
      "trial: 18, epoch, 38, iter: 200, curr loss: 0.4405055046081543, avg loss: 0.42849482014775275\n",
      "trial: 18, epoch, 39, iter: 1, curr loss: 0.43316036462783813, avg loss: 0.43316036462783813\n",
      "trial: 18, epoch, 39, iter: 200, curr loss: 0.42544060945510864, avg loss: 0.42882839977741244\n",
      "trial: 18, epoch, 40, iter: 1, curr loss: 0.427234947681427, avg loss: 0.427234947681427\n",
      "trial: 18, epoch, 40, iter: 200, curr loss: 0.43160873651504517, avg loss: 0.4285878935456276\n",
      "trial: 18, epoch, 41, iter: 1, curr loss: 0.43026936054229736, avg loss: 0.43026936054229736\n",
      "trial: 18, epoch, 41, iter: 200, curr loss: 0.4200795888900757, avg loss: 0.42797871962189676\n",
      "trial: 18, epoch, 42, iter: 1, curr loss: 0.44383206963539124, avg loss: 0.44383206963539124\n",
      "trial: 18, epoch, 42, iter: 200, curr loss: 0.43621641397476196, avg loss: 0.4287043756246567\n",
      "trial: 18, epoch, 43, iter: 1, curr loss: 0.4260229468345642, avg loss: 0.4260229468345642\n",
      "trial: 18, epoch, 43, iter: 200, curr loss: 0.43221527338027954, avg loss: 0.4283314535021782\n",
      "trial: 18, epoch, 44, iter: 1, curr loss: 0.43088603019714355, avg loss: 0.43088603019714355\n",
      "trial: 18, epoch, 44, iter: 200, curr loss: 0.4378708004951477, avg loss: 0.4284680972993374\n",
      "trial: 18, epoch, 45, iter: 1, curr loss: 0.4242568016052246, avg loss: 0.4242568016052246\n",
      "trial: 18, epoch, 45, iter: 200, curr loss: 0.4457535445690155, avg loss: 0.42879411071538925\n",
      "trial: 18, epoch, 46, iter: 1, curr loss: 0.4344106912612915, avg loss: 0.4344106912612915\n",
      "trial: 18, epoch, 46, iter: 200, curr loss: 0.44088900089263916, avg loss: 0.42880015760660173\n",
      "trial: 18, epoch, 47, iter: 1, curr loss: 0.42506957054138184, avg loss: 0.42506957054138184\n",
      "trial: 18, epoch, 47, iter: 200, curr loss: 0.42663049697875977, avg loss: 0.4285882617533207\n",
      "trial: 18, epoch, 48, iter: 1, curr loss: 0.44075432419776917, avg loss: 0.44075432419776917\n",
      "trial: 18, epoch, 48, iter: 200, curr loss: 0.422366201877594, avg loss: 0.42870992943644526\n",
      "trial: 18, epoch, 49, iter: 1, curr loss: 0.42752236127853394, avg loss: 0.42752236127853394\n",
      "trial: 18, epoch, 49, iter: 200, curr loss: 0.4433012008666992, avg loss: 0.4290003979206085\n",
      "trial: 18, epoch, 50, iter: 1, curr loss: 0.4330393671989441, avg loss: 0.4330393671989441\n",
      "trial: 18, epoch, 50, iter: 200, curr loss: 0.451190710067749, avg loss: 0.4286846296489239\n",
      "trial: 18, ldr: 0.9390839338302612, dv: 0.9085915684700012, nwj: 0.9081219434738159\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 19, epoch, 1, iter: 1, curr loss: 0.6930638551712036, avg loss: 0.6930638551712036\n",
      "trial: 19, epoch, 1, iter: 200, curr loss: 0.4271061420440674, avg loss: 0.45803799510002136\n",
      "trial: 19, epoch, 2, iter: 1, curr loss: 0.4242023229598999, avg loss: 0.4242023229598999\n",
      "trial: 19, epoch, 2, iter: 200, curr loss: 0.4196385145187378, avg loss: 0.4300058881938458\n",
      "trial: 19, epoch, 3, iter: 1, curr loss: 0.4429170787334442, avg loss: 0.4429170787334442\n",
      "trial: 19, epoch, 3, iter: 200, curr loss: 0.42455539107322693, avg loss: 0.42928129523992536\n",
      "trial: 19, epoch, 4, iter: 1, curr loss: 0.42574644088745117, avg loss: 0.42574644088745117\n",
      "trial: 19, epoch, 4, iter: 200, curr loss: 0.4330323040485382, avg loss: 0.42891674414277076\n",
      "trial: 19, epoch, 5, iter: 1, curr loss: 0.4275377690792084, avg loss: 0.4275377690792084\n",
      "trial: 19, epoch, 5, iter: 200, curr loss: 0.44874054193496704, avg loss: 0.42849802777171137\n",
      "trial: 19, epoch, 6, iter: 1, curr loss: 0.4416015148162842, avg loss: 0.4416015148162842\n",
      "trial: 19, epoch, 6, iter: 200, curr loss: 0.43156224489212036, avg loss: 0.42838432639837265\n",
      "trial: 19, epoch, 7, iter: 1, curr loss: 0.438963919878006, avg loss: 0.438963919878006\n",
      "trial: 19, epoch, 7, iter: 200, curr loss: 0.4304158687591553, avg loss: 0.4297423569858074\n",
      "trial: 19, epoch, 8, iter: 1, curr loss: 0.4371687173843384, avg loss: 0.4371687173843384\n",
      "trial: 19, epoch, 8, iter: 200, curr loss: 0.43421345949172974, avg loss: 0.4285812744498253\n",
      "trial: 19, epoch, 9, iter: 1, curr loss: 0.42964911460876465, avg loss: 0.42964911460876465\n",
      "trial: 19, epoch, 9, iter: 200, curr loss: 0.4273684620857239, avg loss: 0.42855647891759874\n",
      "trial: 19, epoch, 10, iter: 1, curr loss: 0.4383244812488556, avg loss: 0.4383244812488556\n",
      "trial: 19, epoch, 10, iter: 200, curr loss: 0.42334094643592834, avg loss: 0.4279103635251522\n",
      "trial: 19, epoch, 11, iter: 1, curr loss: 0.442552387714386, avg loss: 0.442552387714386\n",
      "trial: 19, epoch, 11, iter: 200, curr loss: 0.42259711027145386, avg loss: 0.42919796854257586\n",
      "trial: 19, epoch, 12, iter: 1, curr loss: 0.4370516538619995, avg loss: 0.4370516538619995\n",
      "trial: 19, epoch, 12, iter: 200, curr loss: 0.4377051293849945, avg loss: 0.42921829119324684\n",
      "trial: 19, epoch, 13, iter: 1, curr loss: 0.43624448776245117, avg loss: 0.43624448776245117\n",
      "trial: 19, epoch, 13, iter: 200, curr loss: 0.43080413341522217, avg loss: 0.4287163159251213\n",
      "trial: 19, epoch, 14, iter: 1, curr loss: 0.4384065568447113, avg loss: 0.4384065568447113\n",
      "trial: 19, epoch, 14, iter: 200, curr loss: 0.42776617407798767, avg loss: 0.4290794263780117\n",
      "trial: 19, epoch, 15, iter: 1, curr loss: 0.43529486656188965, avg loss: 0.43529486656188965\n",
      "trial: 19, epoch, 15, iter: 200, curr loss: 0.432503342628479, avg loss: 0.4287302331626415\n",
      "trial: 19, epoch, 16, iter: 1, curr loss: 0.4236878752708435, avg loss: 0.4236878752708435\n",
      "trial: 19, epoch, 16, iter: 200, curr loss: 0.42488276958465576, avg loss: 0.42879488930106163\n",
      "trial: 19, epoch, 17, iter: 1, curr loss: 0.43758952617645264, avg loss: 0.43758952617645264\n",
      "trial: 19, epoch, 17, iter: 200, curr loss: 0.43013373017311096, avg loss: 0.42848304837942125\n",
      "trial: 19, epoch, 18, iter: 1, curr loss: 0.4213927984237671, avg loss: 0.4213927984237671\n",
      "trial: 19, epoch, 18, iter: 200, curr loss: 0.43214261531829834, avg loss: 0.4281132312119007\n",
      "trial: 19, epoch, 19, iter: 1, curr loss: 0.44518959522247314, avg loss: 0.44518959522247314\n",
      "trial: 19, epoch, 19, iter: 200, curr loss: 0.4414721429347992, avg loss: 0.42859669387340543\n",
      "trial: 19, epoch, 20, iter: 1, curr loss: 0.43004462122917175, avg loss: 0.43004462122917175\n",
      "trial: 19, epoch, 20, iter: 200, curr loss: 0.4174391031265259, avg loss: 0.42833493277430534\n",
      "trial: 19, epoch, 21, iter: 1, curr loss: 0.4147169589996338, avg loss: 0.4147169589996338\n",
      "trial: 19, epoch, 21, iter: 200, curr loss: 0.42140746116638184, avg loss: 0.42889353424310683\n",
      "trial: 19, epoch, 22, iter: 1, curr loss: 0.4129655361175537, avg loss: 0.4129655361175537\n",
      "trial: 19, epoch, 22, iter: 200, curr loss: 0.43952566385269165, avg loss: 0.42902756705880163\n",
      "trial: 19, epoch, 23, iter: 1, curr loss: 0.4395602345466614, avg loss: 0.4395602345466614\n",
      "trial: 19, epoch, 23, iter: 200, curr loss: 0.416445255279541, avg loss: 0.4283982400596142\n",
      "trial: 19, epoch, 24, iter: 1, curr loss: 0.4313063621520996, avg loss: 0.4313063621520996\n",
      "trial: 19, epoch, 24, iter: 200, curr loss: 0.42797261476516724, avg loss: 0.42846355751156806\n",
      "trial: 19, epoch, 25, iter: 1, curr loss: 0.4257045388221741, avg loss: 0.4257045388221741\n",
      "trial: 19, epoch, 25, iter: 200, curr loss: 0.41755175590515137, avg loss: 0.4289173300564289\n",
      "trial: 19, epoch, 26, iter: 1, curr loss: 0.4297046661376953, avg loss: 0.4297046661376953\n",
      "trial: 19, epoch, 26, iter: 200, curr loss: 0.41650113463401794, avg loss: 0.42877485558390616\n",
      "trial: 19, epoch, 27, iter: 1, curr loss: 0.42634689807891846, avg loss: 0.42634689807891846\n",
      "trial: 19, epoch, 27, iter: 200, curr loss: 0.42568978667259216, avg loss: 0.42846273973584176\n",
      "trial: 19, epoch, 28, iter: 1, curr loss: 0.4316492974758148, avg loss: 0.4316492974758148\n",
      "trial: 19, epoch, 28, iter: 200, curr loss: 0.4272514879703522, avg loss: 0.42839584887027743\n",
      "trial: 19, epoch, 29, iter: 1, curr loss: 0.42899495363235474, avg loss: 0.42899495363235474\n",
      "trial: 19, epoch, 29, iter: 200, curr loss: 0.42902231216430664, avg loss: 0.4281027612090111\n",
      "trial: 19, epoch, 30, iter: 1, curr loss: 0.42269837856292725, avg loss: 0.42269837856292725\n",
      "trial: 19, epoch, 30, iter: 200, curr loss: 0.43351250886917114, avg loss: 0.4288082066178322\n",
      "trial: 19, epoch, 31, iter: 1, curr loss: 0.41898953914642334, avg loss: 0.41898953914642334\n",
      "trial: 19, epoch, 31, iter: 200, curr loss: 0.4448646306991577, avg loss: 0.42902363613247874\n",
      "trial: 19, epoch, 32, iter: 1, curr loss: 0.4229617118835449, avg loss: 0.4229617118835449\n",
      "trial: 19, epoch, 32, iter: 200, curr loss: 0.427115797996521, avg loss: 0.4285513797402382\n",
      "trial: 19, epoch, 33, iter: 1, curr loss: 0.4318047761917114, avg loss: 0.4318047761917114\n",
      "trial: 19, epoch, 33, iter: 200, curr loss: 0.436917245388031, avg loss: 0.428711004704237\n",
      "trial: 19, epoch, 34, iter: 1, curr loss: 0.42630377411842346, avg loss: 0.42630377411842346\n",
      "trial: 19, epoch, 34, iter: 200, curr loss: 0.4414862394332886, avg loss: 0.42888279765844345\n",
      "trial: 19, epoch, 35, iter: 1, curr loss: 0.4282378852367401, avg loss: 0.4282378852367401\n",
      "trial: 19, epoch, 35, iter: 200, curr loss: 0.41278666257858276, avg loss: 0.4283953508734703\n",
      "trial: 19, epoch, 36, iter: 1, curr loss: 0.4430983066558838, avg loss: 0.4430983066558838\n",
      "trial: 19, epoch, 36, iter: 200, curr loss: 0.4281593859195709, avg loss: 0.4284124095737934\n",
      "trial: 19, epoch, 37, iter: 1, curr loss: 0.43848931789398193, avg loss: 0.43848931789398193\n",
      "trial: 19, epoch, 37, iter: 200, curr loss: 0.4232980012893677, avg loss: 0.4281314668059349\n",
      "trial: 19, epoch, 38, iter: 1, curr loss: 0.42554157972335815, avg loss: 0.42554157972335815\n",
      "trial: 19, epoch, 38, iter: 200, curr loss: 0.41723698377609253, avg loss: 0.4294991680979729\n",
      "trial: 19, epoch, 39, iter: 1, curr loss: 0.44118088483810425, avg loss: 0.44118088483810425\n",
      "trial: 19, epoch, 39, iter: 200, curr loss: 0.4271419048309326, avg loss: 0.42843557476997374\n",
      "trial: 19, epoch, 40, iter: 1, curr loss: 0.43231436610221863, avg loss: 0.43231436610221863\n",
      "trial: 19, epoch, 40, iter: 200, curr loss: 0.4285946786403656, avg loss: 0.4291732259094715\n",
      "trial: 19, epoch, 41, iter: 1, curr loss: 0.44177234172821045, avg loss: 0.44177234172821045\n",
      "trial: 19, epoch, 41, iter: 200, curr loss: 0.4360673427581787, avg loss: 0.42842273160815236\n",
      "trial: 19, epoch, 42, iter: 1, curr loss: 0.4360164999961853, avg loss: 0.4360164999961853\n",
      "trial: 19, epoch, 42, iter: 200, curr loss: 0.42718228697776794, avg loss: 0.4285247577726841\n",
      "trial: 19, epoch, 43, iter: 1, curr loss: 0.4270823299884796, avg loss: 0.4270823299884796\n",
      "trial: 19, epoch, 43, iter: 200, curr loss: 0.4323892593383789, avg loss: 0.4288219539821148\n",
      "trial: 19, epoch, 44, iter: 1, curr loss: 0.40574169158935547, avg loss: 0.40574169158935547\n",
      "trial: 19, epoch, 44, iter: 200, curr loss: 0.43104177713394165, avg loss: 0.4291994199156761\n",
      "trial: 19, epoch, 45, iter: 1, curr loss: 0.42990684509277344, avg loss: 0.42990684509277344\n",
      "trial: 19, epoch, 45, iter: 200, curr loss: 0.4353552460670471, avg loss: 0.4284860306978226\n",
      "trial: 19, epoch, 46, iter: 1, curr loss: 0.43141406774520874, avg loss: 0.43141406774520874\n",
      "trial: 19, epoch, 46, iter: 200, curr loss: 0.4276480972766876, avg loss: 0.4287578596174717\n",
      "trial: 19, epoch, 47, iter: 1, curr loss: 0.43588191270828247, avg loss: 0.43588191270828247\n",
      "trial: 19, epoch, 47, iter: 200, curr loss: 0.4345046877861023, avg loss: 0.42845120444893836\n",
      "trial: 19, epoch, 48, iter: 1, curr loss: 0.4332048296928406, avg loss: 0.4332048296928406\n",
      "trial: 19, epoch, 48, iter: 200, curr loss: 0.4304099678993225, avg loss: 0.4284153850376606\n",
      "trial: 19, epoch, 49, iter: 1, curr loss: 0.4423547387123108, avg loss: 0.4423547387123108\n",
      "trial: 19, epoch, 49, iter: 200, curr loss: 0.42417436838150024, avg loss: 0.42823736146092417\n",
      "trial: 19, epoch, 50, iter: 1, curr loss: 0.4391494393348694, avg loss: 0.4391494393348694\n",
      "trial: 19, epoch, 50, iter: 200, curr loss: 0.4235432744026184, avg loss: 0.428024832457304\n",
      "trial: 19, ldr: 0.8943347930908203, dv: 0.9088155031204224, nwj: 0.9087111353874207\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 20, epoch, 1, iter: 1, curr loss: 0.6933465003967285, avg loss: 0.6933465003967285\n",
      "trial: 20, epoch, 1, iter: 200, curr loss: 0.4310612082481384, avg loss: 0.4574075910449028\n",
      "trial: 20, epoch, 2, iter: 1, curr loss: 0.4181362986564636, avg loss: 0.4181362986564636\n",
      "trial: 20, epoch, 2, iter: 200, curr loss: 0.4330675005912781, avg loss: 0.43039446786046026\n",
      "trial: 20, epoch, 3, iter: 1, curr loss: 0.43239009380340576, avg loss: 0.43239009380340576\n",
      "trial: 20, epoch, 3, iter: 200, curr loss: 0.43239378929138184, avg loss: 0.42835629120469093\n",
      "trial: 20, epoch, 4, iter: 1, curr loss: 0.4260099530220032, avg loss: 0.4260099530220032\n",
      "trial: 20, epoch, 4, iter: 200, curr loss: 0.4476028084754944, avg loss: 0.42910428777337073\n",
      "trial: 20, epoch, 5, iter: 1, curr loss: 0.42602264881134033, avg loss: 0.42602264881134033\n",
      "trial: 20, epoch, 5, iter: 200, curr loss: 0.43676894903182983, avg loss: 0.42798391669988634\n",
      "trial: 20, epoch, 6, iter: 1, curr loss: 0.4229316711425781, avg loss: 0.4229316711425781\n",
      "trial: 20, epoch, 6, iter: 200, curr loss: 0.4403057396411896, avg loss: 0.42865157917141916\n",
      "trial: 20, epoch, 7, iter: 1, curr loss: 0.43794357776641846, avg loss: 0.43794357776641846\n",
      "trial: 20, epoch, 7, iter: 200, curr loss: 0.42299699783325195, avg loss: 0.42928208589553835\n",
      "trial: 20, epoch, 8, iter: 1, curr loss: 0.41773170232772827, avg loss: 0.41773170232772827\n",
      "trial: 20, epoch, 8, iter: 200, curr loss: 0.4425068497657776, avg loss: 0.42829537197947504\n",
      "trial: 20, epoch, 9, iter: 1, curr loss: 0.43546342849731445, avg loss: 0.43546342849731445\n",
      "trial: 20, epoch, 9, iter: 200, curr loss: 0.43978041410446167, avg loss: 0.42828225404024123\n",
      "trial: 20, epoch, 10, iter: 1, curr loss: 0.4455986022949219, avg loss: 0.4455986022949219\n",
      "trial: 20, epoch, 10, iter: 200, curr loss: 0.4328628182411194, avg loss: 0.42869810670614245\n",
      "trial: 20, epoch, 11, iter: 1, curr loss: 0.4334787130355835, avg loss: 0.4334787130355835\n",
      "trial: 20, epoch, 11, iter: 200, curr loss: 0.4228525757789612, avg loss: 0.4288490378856659\n",
      "trial: 20, epoch, 12, iter: 1, curr loss: 0.4290446639060974, avg loss: 0.4290446639060974\n",
      "trial: 20, epoch, 12, iter: 200, curr loss: 0.4230373501777649, avg loss: 0.42825956746935845\n",
      "trial: 20, epoch, 13, iter: 1, curr loss: 0.43225520849227905, avg loss: 0.43225520849227905\n",
      "trial: 20, epoch, 13, iter: 200, curr loss: 0.4346146881580353, avg loss: 0.4291504780948162\n",
      "trial: 20, epoch, 14, iter: 1, curr loss: 0.41967499256134033, avg loss: 0.41967499256134033\n",
      "trial: 20, epoch, 14, iter: 200, curr loss: 0.4283781349658966, avg loss: 0.4294183985888958\n",
      "trial: 20, epoch, 15, iter: 1, curr loss: 0.43615254759788513, avg loss: 0.43615254759788513\n",
      "trial: 20, epoch, 15, iter: 200, curr loss: 0.4216756224632263, avg loss: 0.4288545924425125\n",
      "trial: 20, epoch, 16, iter: 1, curr loss: 0.43285828828811646, avg loss: 0.43285828828811646\n",
      "trial: 20, epoch, 16, iter: 200, curr loss: 0.4342586398124695, avg loss: 0.4290724214911461\n",
      "trial: 20, epoch, 17, iter: 1, curr loss: 0.4276057779788971, avg loss: 0.4276057779788971\n",
      "trial: 20, epoch, 17, iter: 200, curr loss: 0.4403776526451111, avg loss: 0.4288573287427425\n",
      "trial: 20, epoch, 18, iter: 1, curr loss: 0.42666536569595337, avg loss: 0.42666536569595337\n",
      "trial: 20, epoch, 18, iter: 200, curr loss: 0.4256399869918823, avg loss: 0.4285680778324604\n",
      "trial: 20, epoch, 19, iter: 1, curr loss: 0.42160218954086304, avg loss: 0.42160218954086304\n",
      "trial: 20, epoch, 19, iter: 200, curr loss: 0.4251434803009033, avg loss: 0.4282719247043133\n",
      "trial: 20, epoch, 20, iter: 1, curr loss: 0.44197922945022583, avg loss: 0.44197922945022583\n",
      "trial: 20, epoch, 20, iter: 200, curr loss: 0.42824244499206543, avg loss: 0.4290186369419098\n",
      "trial: 20, epoch, 21, iter: 1, curr loss: 0.4311232268810272, avg loss: 0.4311232268810272\n",
      "trial: 20, epoch, 21, iter: 200, curr loss: 0.42488157749176025, avg loss: 0.4286791820824146\n",
      "trial: 20, epoch, 22, iter: 1, curr loss: 0.41916537284851074, avg loss: 0.41916537284851074\n",
      "trial: 20, epoch, 22, iter: 200, curr loss: 0.4137086868286133, avg loss: 0.4287243613600731\n",
      "trial: 20, epoch, 23, iter: 1, curr loss: 0.43136292695999146, avg loss: 0.43136292695999146\n",
      "trial: 20, epoch, 23, iter: 200, curr loss: 0.4509790539741516, avg loss: 0.42855659529566764\n",
      "trial: 20, epoch, 24, iter: 1, curr loss: 0.43547025322914124, avg loss: 0.43547025322914124\n",
      "trial: 20, epoch, 24, iter: 200, curr loss: 0.4282991290092468, avg loss: 0.42840676009655\n",
      "trial: 20, epoch, 25, iter: 1, curr loss: 0.43104177713394165, avg loss: 0.43104177713394165\n",
      "trial: 20, epoch, 25, iter: 200, curr loss: 0.4293076992034912, avg loss: 0.42879793971776964\n",
      "trial: 20, epoch, 26, iter: 1, curr loss: 0.4163264036178589, avg loss: 0.4163264036178589\n",
      "trial: 20, epoch, 26, iter: 200, curr loss: 0.43586671352386475, avg loss: 0.42871465399861336\n",
      "trial: 20, epoch, 27, iter: 1, curr loss: 0.42704176902770996, avg loss: 0.42704176902770996\n",
      "trial: 20, epoch, 27, iter: 200, curr loss: 0.44041886925697327, avg loss: 0.42947985127568244\n",
      "trial: 20, epoch, 28, iter: 1, curr loss: 0.4219646453857422, avg loss: 0.4219646453857422\n",
      "trial: 20, epoch, 28, iter: 200, curr loss: 0.42073458433151245, avg loss: 0.42859435886144637\n",
      "trial: 20, epoch, 29, iter: 1, curr loss: 0.42562517523765564, avg loss: 0.42562517523765564\n",
      "trial: 20, epoch, 29, iter: 200, curr loss: 0.44618475437164307, avg loss: 0.4285656799376011\n",
      "trial: 20, epoch, 30, iter: 1, curr loss: 0.43165093660354614, avg loss: 0.43165093660354614\n",
      "trial: 20, epoch, 30, iter: 200, curr loss: 0.4301453232765198, avg loss: 0.4287913458049297\n",
      "trial: 20, epoch, 31, iter: 1, curr loss: 0.4208108186721802, avg loss: 0.4208108186721802\n",
      "trial: 20, epoch, 31, iter: 200, curr loss: 0.442455530166626, avg loss: 0.42863728910684584\n",
      "trial: 20, epoch, 32, iter: 1, curr loss: 0.43035420775413513, avg loss: 0.43035420775413513\n",
      "trial: 20, epoch, 32, iter: 200, curr loss: 0.4287044405937195, avg loss: 0.429090034365654\n",
      "trial: 20, epoch, 33, iter: 1, curr loss: 0.43621325492858887, avg loss: 0.43621325492858887\n",
      "trial: 20, epoch, 33, iter: 200, curr loss: 0.42939072847366333, avg loss: 0.4290102301537991\n",
      "trial: 20, epoch, 34, iter: 1, curr loss: 0.4338921904563904, avg loss: 0.4338921904563904\n",
      "trial: 20, epoch, 34, iter: 200, curr loss: 0.4327448606491089, avg loss: 0.428604756295681\n",
      "trial: 20, epoch, 35, iter: 1, curr loss: 0.4408283233642578, avg loss: 0.4408283233642578\n",
      "trial: 20, epoch, 35, iter: 200, curr loss: 0.42811012268066406, avg loss: 0.42894337490200996\n",
      "trial: 20, epoch, 36, iter: 1, curr loss: 0.440028578042984, avg loss: 0.440028578042984\n",
      "trial: 20, epoch, 36, iter: 200, curr loss: 0.41911232471466064, avg loss: 0.4290244053304195\n",
      "trial: 20, epoch, 37, iter: 1, curr loss: 0.4349788725376129, avg loss: 0.4349788725376129\n",
      "trial: 20, epoch, 37, iter: 200, curr loss: 0.43850773572921753, avg loss: 0.4283521457016468\n",
      "trial: 20, epoch, 38, iter: 1, curr loss: 0.4299839735031128, avg loss: 0.4299839735031128\n",
      "trial: 20, epoch, 38, iter: 200, curr loss: 0.4418770670890808, avg loss: 0.4291975128650665\n",
      "trial: 20, epoch, 39, iter: 1, curr loss: 0.4425572156906128, avg loss: 0.4425572156906128\n",
      "trial: 20, epoch, 39, iter: 200, curr loss: 0.4320122301578522, avg loss: 0.4291487255692482\n",
      "trial: 20, epoch, 40, iter: 1, curr loss: 0.4305915832519531, avg loss: 0.4305915832519531\n",
      "trial: 20, epoch, 40, iter: 200, curr loss: 0.42425090074539185, avg loss: 0.4285989317297936\n",
      "trial: 20, epoch, 41, iter: 1, curr loss: 0.43172135949134827, avg loss: 0.43172135949134827\n",
      "trial: 20, epoch, 41, iter: 200, curr loss: 0.4205327033996582, avg loss: 0.4284843309223652\n",
      "trial: 20, epoch, 42, iter: 1, curr loss: 0.44154128432273865, avg loss: 0.44154128432273865\n",
      "trial: 20, epoch, 42, iter: 200, curr loss: 0.4406537711620331, avg loss: 0.429232651591301\n",
      "trial: 20, epoch, 43, iter: 1, curr loss: 0.4233385920524597, avg loss: 0.4233385920524597\n",
      "trial: 20, epoch, 43, iter: 200, curr loss: 0.4189246892929077, avg loss: 0.4285043656826019\n",
      "trial: 20, epoch, 44, iter: 1, curr loss: 0.4212905466556549, avg loss: 0.4212905466556549\n",
      "trial: 20, epoch, 44, iter: 200, curr loss: 0.4298376441001892, avg loss: 0.4284223897755146\n",
      "trial: 20, epoch, 45, iter: 1, curr loss: 0.4321613907814026, avg loss: 0.4321613907814026\n",
      "trial: 20, epoch, 45, iter: 200, curr loss: 0.42746877670288086, avg loss: 0.4287348599731922\n",
      "trial: 20, epoch, 46, iter: 1, curr loss: 0.4216892123222351, avg loss: 0.4216892123222351\n",
      "trial: 20, epoch, 46, iter: 200, curr loss: 0.4414101541042328, avg loss: 0.4281222528219223\n",
      "trial: 20, epoch, 47, iter: 1, curr loss: 0.4312695264816284, avg loss: 0.4312695264816284\n",
      "trial: 20, epoch, 47, iter: 200, curr loss: 0.42600229382514954, avg loss: 0.4288107089698315\n",
      "trial: 20, epoch, 48, iter: 1, curr loss: 0.42948493361473083, avg loss: 0.42948493361473083\n",
      "trial: 20, epoch, 48, iter: 200, curr loss: 0.43146276473999023, avg loss: 0.4287547418475151\n",
      "trial: 20, epoch, 49, iter: 1, curr loss: 0.43598753213882446, avg loss: 0.43598753213882446\n",
      "trial: 20, epoch, 49, iter: 200, curr loss: 0.428713858127594, avg loss: 0.42834815695881845\n",
      "trial: 20, epoch, 50, iter: 1, curr loss: 0.4277828335762024, avg loss: 0.4277828335762024\n",
      "trial: 20, epoch, 50, iter: 200, curr loss: 0.4280283451080322, avg loss: 0.4286259540915489\n",
      "trial: 20, ldr: 0.9120711088180542, dv: 0.9086719155311584, nwj: 0.9086661338806152\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.9090509474277496\n",
      "\tdv: 0.9086783319711685\n",
      "\tnwj: 0.9084904730319977\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 20\n",
    "num_of_inner_iteration = 50\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    print('################################################################')\n",
    "    model, inner_running_loss, inner_running_loss_avg, num_of_joint, num_of_marginal = train_binary_classifier_v2(data, label, num_input_features, hidden_size_arr, lr, num_of_inner_iteration, batch_size, outer_iter, save_avg=200, print_progress=True)\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    curr_ldr, curr_dv, curr_nwj = estimate_mi_for_binary_classification(model, joint_data, num_of_joint, marginal_data, num_of_marginal)\n",
    "    print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "    print('################################################################\\n')\n",
    "    ldr_estimations.append(curr_ldr.item())\n",
    "    dv_estimations.append(curr_dv.item())\n",
    "    nwj_estimations.append(curr_nwj.item())\n",
    "    \n",
    "print('final estimations:\\n\\tldr: {}\\n\\tdv: {}\\n\\tnwj: {}'.format(np.mean(ldr_estimations), np.mean(dv_estimations), np.mean(nwj_estimations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71923f51216c14b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:59.296716737Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "x_idx, y_idx, z_idx = [0, 1], [3, 4, 5], [2]\n",
    "yz_idx = [2, 3, 4, 5]\n",
    "dataset = dataset[:, :3]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_joint_marginal_dataset(dataset, x_idx, z_idx)\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba58c3711e6fa58d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:59.296806800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(z_idx)\n",
    "hidden_size_arr = [256, 256, 256]\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdf107dc1fdd5ba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T09:31:59.296906794Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, epoch, 1, iter: 1, curr loss: 0.6922325491905212, avg loss: 0.6922325491905212\n",
      "trial: 1, epoch, 1, iter: 200, curr loss: 0.5293221473693848, avg loss: 0.5348994317650795\n",
      "trial: 1, epoch, 2, iter: 1, curr loss: 0.5356400012969971, avg loss: 0.5356400012969971\n",
      "trial: 1, epoch, 2, iter: 200, curr loss: 0.5210230946540833, avg loss: 0.5242860004305839\n",
      "trial: 1, epoch, 3, iter: 1, curr loss: 0.5239117741584778, avg loss: 0.5239117741584778\n",
      "trial: 1, epoch, 3, iter: 200, curr loss: 0.5202776193618774, avg loss: 0.5239950707554817\n",
      "trial: 1, epoch, 4, iter: 1, curr loss: 0.5150713920593262, avg loss: 0.5150713920593262\n",
      "trial: 1, epoch, 4, iter: 200, curr loss: 0.5196893215179443, avg loss: 0.5237035164237023\n",
      "trial: 1, epoch, 5, iter: 1, curr loss: 0.5267345905303955, avg loss: 0.5267345905303955\n",
      "trial: 1, epoch, 5, iter: 200, curr loss: 0.5248969793319702, avg loss: 0.5230937004089355\n",
      "trial: 1, epoch, 6, iter: 1, curr loss: 0.5209842920303345, avg loss: 0.5209842920303345\n",
      "trial: 1, epoch, 6, iter: 200, curr loss: 0.5170929431915283, avg loss: 0.5234052836894989\n",
      "trial: 1, epoch, 7, iter: 1, curr loss: 0.5307512879371643, avg loss: 0.5307512879371643\n",
      "trial: 1, epoch, 7, iter: 200, curr loss: 0.52910977602005, avg loss: 0.5229963678121566\n",
      "trial: 1, epoch, 8, iter: 1, curr loss: 0.5290571451187134, avg loss: 0.5290571451187134\n",
      "trial: 1, epoch, 8, iter: 200, curr loss: 0.5321846008300781, avg loss: 0.5232811567187309\n",
      "trial: 1, epoch, 9, iter: 1, curr loss: 0.5319583415985107, avg loss: 0.5319583415985107\n",
      "trial: 1, epoch, 9, iter: 200, curr loss: 0.5299316644668579, avg loss: 0.5237599068880081\n",
      "trial: 1, epoch, 10, iter: 1, curr loss: 0.5191736221313477, avg loss: 0.5191736221313477\n",
      "trial: 1, epoch, 10, iter: 200, curr loss: 0.5215603113174438, avg loss: 0.5231504774093628\n",
      "trial: 1, epoch, 11, iter: 1, curr loss: 0.5313683748245239, avg loss: 0.5313683748245239\n",
      "trial: 1, epoch, 11, iter: 200, curr loss: 0.5370835065841675, avg loss: 0.523089523613453\n",
      "trial: 1, epoch, 12, iter: 1, curr loss: 0.5183578133583069, avg loss: 0.5183578133583069\n",
      "trial: 1, epoch, 12, iter: 200, curr loss: 0.5348363518714905, avg loss: 0.5231290847063065\n",
      "trial: 1, epoch, 13, iter: 1, curr loss: 0.5285564661026001, avg loss: 0.5285564661026001\n",
      "trial: 1, epoch, 13, iter: 200, curr loss: 0.5323487520217896, avg loss: 0.5230796518921852\n",
      "trial: 1, epoch, 14, iter: 1, curr loss: 0.5257039666175842, avg loss: 0.5257039666175842\n",
      "trial: 1, epoch, 14, iter: 200, curr loss: 0.5321658849716187, avg loss: 0.5229850840568543\n",
      "trial: 1, epoch, 15, iter: 1, curr loss: 0.5190999507904053, avg loss: 0.5190999507904053\n",
      "trial: 1, epoch, 15, iter: 200, curr loss: 0.5371806025505066, avg loss: 0.5233724728226662\n",
      "trial: 1, epoch, 16, iter: 1, curr loss: 0.5308082103729248, avg loss: 0.5308082103729248\n",
      "trial: 1, epoch, 16, iter: 200, curr loss: 0.5310916304588318, avg loss: 0.5233437061309815\n",
      "trial: 1, epoch, 17, iter: 1, curr loss: 0.5243091583251953, avg loss: 0.5243091583251953\n",
      "trial: 1, epoch, 17, iter: 200, curr loss: 0.5241489410400391, avg loss: 0.523088911473751\n",
      "trial: 1, epoch, 18, iter: 1, curr loss: 0.5211844444274902, avg loss: 0.5211844444274902\n",
      "trial: 1, epoch, 18, iter: 200, curr loss: 0.5258102416992188, avg loss: 0.5239392632246017\n",
      "trial: 1, epoch, 19, iter: 1, curr loss: 0.5245497226715088, avg loss: 0.5245497226715088\n",
      "trial: 1, epoch, 19, iter: 200, curr loss: 0.5202590227127075, avg loss: 0.5230287179350853\n",
      "trial: 1, epoch, 20, iter: 1, curr loss: 0.5229710340499878, avg loss: 0.5229710340499878\n",
      "trial: 1, epoch, 20, iter: 200, curr loss: 0.5124058723449707, avg loss: 0.5235608956217765\n",
      "trial: 1, epoch, 21, iter: 1, curr loss: 0.5205414295196533, avg loss: 0.5205414295196533\n",
      "trial: 1, epoch, 21, iter: 200, curr loss: 0.531766951084137, avg loss: 0.5228820279240608\n",
      "trial: 1, epoch, 22, iter: 1, curr loss: 0.5202973484992981, avg loss: 0.5202973484992981\n",
      "trial: 1, epoch, 22, iter: 200, curr loss: 0.5346370935440063, avg loss: 0.5233374601602554\n",
      "trial: 1, epoch, 23, iter: 1, curr loss: 0.5328612327575684, avg loss: 0.5328612327575684\n",
      "trial: 1, epoch, 23, iter: 200, curr loss: 0.5138561725616455, avg loss: 0.5232132938504219\n",
      "trial: 1, epoch, 24, iter: 1, curr loss: 0.5329854488372803, avg loss: 0.5329854488372803\n",
      "trial: 1, epoch, 24, iter: 200, curr loss: 0.5229843854904175, avg loss: 0.5231630811095238\n",
      "trial: 1, epoch, 25, iter: 1, curr loss: 0.5248298048973083, avg loss: 0.5248298048973083\n",
      "trial: 1, epoch, 25, iter: 200, curr loss: 0.5190201997756958, avg loss: 0.523356023132801\n",
      "trial: 1, epoch, 26, iter: 1, curr loss: 0.5318297147750854, avg loss: 0.5318297147750854\n",
      "trial: 1, epoch, 26, iter: 200, curr loss: 0.5193026661872864, avg loss: 0.5229309746623039\n",
      "trial: 1, epoch, 27, iter: 1, curr loss: 0.5169752836227417, avg loss: 0.5169752836227417\n",
      "trial: 1, epoch, 27, iter: 200, curr loss: 0.5207585692405701, avg loss: 0.5235361301898956\n",
      "trial: 1, epoch, 28, iter: 1, curr loss: 0.5142984390258789, avg loss: 0.5142984390258789\n",
      "trial: 1, epoch, 28, iter: 200, curr loss: 0.5356858968734741, avg loss: 0.523510313630104\n",
      "trial: 1, epoch, 29, iter: 1, curr loss: 0.5163538455963135, avg loss: 0.5163538455963135\n",
      "trial: 1, epoch, 29, iter: 200, curr loss: 0.5237034559249878, avg loss: 0.5233305585384369\n",
      "trial: 1, epoch, 30, iter: 1, curr loss: 0.5256121158599854, avg loss: 0.5256121158599854\n",
      "trial: 1, epoch, 30, iter: 200, curr loss: 0.5232559442520142, avg loss: 0.5229047921299934\n",
      "trial: 1, epoch, 31, iter: 1, curr loss: 0.5247511863708496, avg loss: 0.5247511863708496\n",
      "trial: 1, epoch, 31, iter: 200, curr loss: 0.5337177515029907, avg loss: 0.523155906200409\n",
      "trial: 1, epoch, 32, iter: 1, curr loss: 0.5294784307479858, avg loss: 0.5294784307479858\n",
      "trial: 1, epoch, 32, iter: 200, curr loss: 0.5256901979446411, avg loss: 0.5234195911884307\n",
      "trial: 1, epoch, 33, iter: 1, curr loss: 0.5284582376480103, avg loss: 0.5284582376480103\n",
      "trial: 1, epoch, 33, iter: 200, curr loss: 0.5238142609596252, avg loss: 0.5232878908514976\n",
      "trial: 1, epoch, 34, iter: 1, curr loss: 0.5204092264175415, avg loss: 0.5204092264175415\n",
      "trial: 1, epoch, 34, iter: 200, curr loss: 0.5282028913497925, avg loss: 0.5235304728150367\n",
      "trial: 1, epoch, 35, iter: 1, curr loss: 0.5256983041763306, avg loss: 0.5256983041763306\n",
      "trial: 1, epoch, 35, iter: 200, curr loss: 0.5367990732192993, avg loss: 0.5233457636833191\n",
      "trial: 1, epoch, 36, iter: 1, curr loss: 0.5197522044181824, avg loss: 0.5197522044181824\n",
      "trial: 1, epoch, 36, iter: 200, curr loss: 0.5253942012786865, avg loss: 0.5230390805006028\n",
      "trial: 1, epoch, 37, iter: 1, curr loss: 0.5226714611053467, avg loss: 0.5226714611053467\n",
      "trial: 1, epoch, 37, iter: 200, curr loss: 0.5298461318016052, avg loss: 0.5227864027023316\n",
      "trial: 1, epoch, 38, iter: 1, curr loss: 0.5198323726654053, avg loss: 0.5198323726654053\n",
      "trial: 1, epoch, 38, iter: 200, curr loss: 0.5216410160064697, avg loss: 0.5235538521409034\n",
      "trial: 1, epoch, 39, iter: 1, curr loss: 0.5301071405410767, avg loss: 0.5301071405410767\n",
      "trial: 1, epoch, 39, iter: 200, curr loss: 0.5182116627693176, avg loss: 0.523262537419796\n",
      "trial: 1, epoch, 40, iter: 1, curr loss: 0.5230171084403992, avg loss: 0.5230171084403992\n",
      "trial: 1, epoch, 40, iter: 200, curr loss: 0.5245175957679749, avg loss: 0.5234423807263374\n",
      "trial: 1, epoch, 41, iter: 1, curr loss: 0.5329104065895081, avg loss: 0.5329104065895081\n",
      "trial: 1, epoch, 41, iter: 200, curr loss: 0.5203097462654114, avg loss: 0.5225405633449555\n",
      "trial: 1, epoch, 42, iter: 1, curr loss: 0.5232341289520264, avg loss: 0.5232341289520264\n",
      "trial: 1, epoch, 42, iter: 200, curr loss: 0.5269438624382019, avg loss: 0.5233986914157868\n",
      "trial: 1, epoch, 43, iter: 1, curr loss: 0.5189939737319946, avg loss: 0.5189939737319946\n",
      "trial: 1, epoch, 43, iter: 200, curr loss: 0.5234478712081909, avg loss: 0.5230648776888848\n",
      "trial: 1, epoch, 44, iter: 1, curr loss: 0.5113040208816528, avg loss: 0.5113040208816528\n",
      "trial: 1, epoch, 44, iter: 200, curr loss: 0.5140776038169861, avg loss: 0.5232509049773216\n",
      "trial: 1, epoch, 45, iter: 1, curr loss: 0.5347548127174377, avg loss: 0.5347548127174377\n",
      "trial: 1, epoch, 45, iter: 200, curr loss: 0.5235744118690491, avg loss: 0.5234510907530785\n",
      "trial: 1, epoch, 46, iter: 1, curr loss: 0.5249310731887817, avg loss: 0.5249310731887817\n",
      "trial: 1, epoch, 46, iter: 200, curr loss: 0.525023877620697, avg loss: 0.5233084598183632\n",
      "trial: 1, epoch, 47, iter: 1, curr loss: 0.5260322093963623, avg loss: 0.5260322093963623\n",
      "trial: 1, epoch, 47, iter: 200, curr loss: 0.5233129262924194, avg loss: 0.522926144003868\n",
      "trial: 1, epoch, 48, iter: 1, curr loss: 0.5218344330787659, avg loss: 0.5218344330787659\n",
      "trial: 1, epoch, 48, iter: 200, curr loss: 0.5334071516990662, avg loss: 0.5230006861686707\n",
      "trial: 1, epoch, 49, iter: 1, curr loss: 0.5241653323173523, avg loss: 0.5241653323173523\n",
      "trial: 1, epoch, 49, iter: 200, curr loss: 0.5255832076072693, avg loss: 0.5235464850068092\n",
      "trial: 1, epoch, 50, iter: 1, curr loss: 0.5304403305053711, avg loss: 0.5304403305053711\n",
      "trial: 1, epoch, 50, iter: 200, curr loss: 0.5284199714660645, avg loss: 0.52327442497015\n",
      "trial: 1, ldr: 0.5464870929718018, dv: 0.5634322166442871, nwj: 0.56328946352005\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, epoch, 1, iter: 1, curr loss: 0.6934664249420166, avg loss: 0.6934664249420166\n",
      "trial: 2, epoch, 1, iter: 200, curr loss: 0.524567723274231, avg loss: 0.5359839141368866\n",
      "trial: 2, epoch, 2, iter: 1, curr loss: 0.5150079727172852, avg loss: 0.5150079727172852\n",
      "trial: 2, epoch, 2, iter: 200, curr loss: 0.524320125579834, avg loss: 0.524589156806469\n",
      "trial: 2, epoch, 3, iter: 1, curr loss: 0.5348345041275024, avg loss: 0.5348345041275024\n",
      "trial: 2, epoch, 3, iter: 200, curr loss: 0.5232200622558594, avg loss: 0.5236561873555183\n",
      "trial: 2, epoch, 4, iter: 1, curr loss: 0.5357557535171509, avg loss: 0.5357557535171509\n",
      "trial: 2, epoch, 4, iter: 200, curr loss: 0.520186185836792, avg loss: 0.5233628934621811\n",
      "trial: 2, epoch, 5, iter: 1, curr loss: 0.5313307642936707, avg loss: 0.5313307642936707\n",
      "trial: 2, epoch, 5, iter: 200, curr loss: 0.5247348546981812, avg loss: 0.5233637458086013\n",
      "trial: 2, epoch, 6, iter: 1, curr loss: 0.516350507736206, avg loss: 0.516350507736206\n",
      "trial: 2, epoch, 6, iter: 200, curr loss: 0.5216553211212158, avg loss: 0.5233125358819961\n",
      "trial: 2, epoch, 7, iter: 1, curr loss: 0.5303798317909241, avg loss: 0.5303798317909241\n",
      "trial: 2, epoch, 7, iter: 200, curr loss: 0.5222955942153931, avg loss: 0.5231569054722786\n",
      "trial: 2, epoch, 8, iter: 1, curr loss: 0.5155413150787354, avg loss: 0.5155413150787354\n",
      "trial: 2, epoch, 8, iter: 200, curr loss: 0.5246358513832092, avg loss: 0.5235193514823914\n",
      "trial: 2, epoch, 9, iter: 1, curr loss: 0.5250289440155029, avg loss: 0.5250289440155029\n",
      "trial: 2, epoch, 9, iter: 200, curr loss: 0.5294881463050842, avg loss: 0.5231746301054955\n",
      "trial: 2, epoch, 10, iter: 1, curr loss: 0.5232656598091125, avg loss: 0.5232656598091125\n",
      "trial: 2, epoch, 10, iter: 200, curr loss: 0.5326628088951111, avg loss: 0.5236467546224595\n",
      "trial: 2, epoch, 11, iter: 1, curr loss: 0.5276764035224915, avg loss: 0.5276764035224915\n",
      "trial: 2, epoch, 11, iter: 200, curr loss: 0.5133881568908691, avg loss: 0.5232559317350387\n",
      "trial: 2, epoch, 12, iter: 1, curr loss: 0.526098370552063, avg loss: 0.526098370552063\n",
      "trial: 2, epoch, 12, iter: 200, curr loss: 0.5388036966323853, avg loss: 0.5231241157650948\n",
      "trial: 2, epoch, 13, iter: 1, curr loss: 0.5249170064926147, avg loss: 0.5249170064926147\n",
      "trial: 2, epoch, 13, iter: 200, curr loss: 0.5202183127403259, avg loss: 0.5234355616569519\n",
      "trial: 2, epoch, 14, iter: 1, curr loss: 0.5240384340286255, avg loss: 0.5240384340286255\n",
      "trial: 2, epoch, 14, iter: 200, curr loss: 0.5190913677215576, avg loss: 0.522748036980629\n",
      "trial: 2, epoch, 15, iter: 1, curr loss: 0.5127006769180298, avg loss: 0.5127006769180298\n",
      "trial: 2, epoch, 15, iter: 200, curr loss: 0.5332046747207642, avg loss: 0.5230651924014091\n",
      "trial: 2, epoch, 16, iter: 1, curr loss: 0.5249752402305603, avg loss: 0.5249752402305603\n",
      "trial: 2, epoch, 16, iter: 200, curr loss: 0.5255455374717712, avg loss: 0.523152443766594\n",
      "trial: 2, epoch, 17, iter: 1, curr loss: 0.5281809568405151, avg loss: 0.5281809568405151\n",
      "trial: 2, epoch, 17, iter: 200, curr loss: 0.5190657377243042, avg loss: 0.5229001265764236\n",
      "trial: 2, epoch, 18, iter: 1, curr loss: 0.5266506671905518, avg loss: 0.5266506671905518\n",
      "trial: 2, epoch, 18, iter: 200, curr loss: 0.5213850736618042, avg loss: 0.5231002596020699\n",
      "trial: 2, epoch, 19, iter: 1, curr loss: 0.5294297933578491, avg loss: 0.5294297933578491\n",
      "trial: 2, epoch, 19, iter: 200, curr loss: 0.5313273668289185, avg loss: 0.5234811371564865\n",
      "trial: 2, epoch, 20, iter: 1, curr loss: 0.5269970297813416, avg loss: 0.5269970297813416\n",
      "trial: 2, epoch, 20, iter: 200, curr loss: 0.519257128238678, avg loss: 0.5230895861983299\n",
      "trial: 2, epoch, 21, iter: 1, curr loss: 0.5294918417930603, avg loss: 0.5294918417930603\n",
      "trial: 2, epoch, 21, iter: 200, curr loss: 0.5266977548599243, avg loss: 0.5235267701745033\n",
      "trial: 2, epoch, 22, iter: 1, curr loss: 0.5309046506881714, avg loss: 0.5309046506881714\n",
      "trial: 2, epoch, 22, iter: 200, curr loss: 0.5256046056747437, avg loss: 0.5231173333525657\n",
      "trial: 2, epoch, 23, iter: 1, curr loss: 0.5338319540023804, avg loss: 0.5338319540023804\n",
      "trial: 2, epoch, 23, iter: 200, curr loss: 0.5293284058570862, avg loss: 0.5230299460887909\n",
      "trial: 2, epoch, 24, iter: 1, curr loss: 0.5279059410095215, avg loss: 0.5279059410095215\n",
      "trial: 2, epoch, 24, iter: 200, curr loss: 0.5249065160751343, avg loss: 0.5234103700518609\n",
      "trial: 2, epoch, 25, iter: 1, curr loss: 0.5254349112510681, avg loss: 0.5254349112510681\n",
      "trial: 2, epoch, 25, iter: 200, curr loss: 0.5302029848098755, avg loss: 0.5230505064129829\n",
      "trial: 2, epoch, 26, iter: 1, curr loss: 0.5287491083145142, avg loss: 0.5287491083145142\n",
      "trial: 2, epoch, 26, iter: 200, curr loss: 0.5159195065498352, avg loss: 0.5230945011973381\n",
      "trial: 2, epoch, 27, iter: 1, curr loss: 0.5241870284080505, avg loss: 0.5241870284080505\n",
      "trial: 2, epoch, 27, iter: 200, curr loss: 0.526213526725769, avg loss: 0.5227273154258728\n",
      "trial: 2, epoch, 28, iter: 1, curr loss: 0.5172372460365295, avg loss: 0.5172372460365295\n",
      "trial: 2, epoch, 28, iter: 200, curr loss: 0.5249919891357422, avg loss: 0.5230214449763299\n",
      "trial: 2, epoch, 29, iter: 1, curr loss: 0.5225526690483093, avg loss: 0.5225526690483093\n",
      "trial: 2, epoch, 29, iter: 200, curr loss: 0.5262874364852905, avg loss: 0.5233384165167808\n",
      "trial: 2, epoch, 30, iter: 1, curr loss: 0.5285558700561523, avg loss: 0.5285558700561523\n",
      "trial: 2, epoch, 30, iter: 200, curr loss: 0.5251936316490173, avg loss: 0.5234162676334381\n",
      "trial: 2, epoch, 31, iter: 1, curr loss: 0.5389111042022705, avg loss: 0.5389111042022705\n",
      "trial: 2, epoch, 31, iter: 200, curr loss: 0.5345118045806885, avg loss: 0.5230630978941917\n",
      "trial: 2, epoch, 32, iter: 1, curr loss: 0.5218803286552429, avg loss: 0.5218803286552429\n",
      "trial: 2, epoch, 32, iter: 200, curr loss: 0.5325416922569275, avg loss: 0.5230357006192208\n",
      "trial: 2, epoch, 33, iter: 1, curr loss: 0.5289511680603027, avg loss: 0.5289511680603027\n",
      "trial: 2, epoch, 33, iter: 200, curr loss: 0.5326699018478394, avg loss: 0.5232321953773499\n",
      "trial: 2, epoch, 34, iter: 1, curr loss: 0.5291628241539001, avg loss: 0.5291628241539001\n",
      "trial: 2, epoch, 34, iter: 200, curr loss: 0.5206961035728455, avg loss: 0.5228887143731117\n",
      "trial: 2, epoch, 35, iter: 1, curr loss: 0.5303241610527039, avg loss: 0.5303241610527039\n",
      "trial: 2, epoch, 35, iter: 200, curr loss: 0.5308257937431335, avg loss: 0.5232145178318024\n",
      "trial: 2, epoch, 36, iter: 1, curr loss: 0.5327214002609253, avg loss: 0.5327214002609253\n",
      "trial: 2, epoch, 36, iter: 200, curr loss: 0.5242341160774231, avg loss: 0.5234031066298485\n",
      "trial: 2, epoch, 37, iter: 1, curr loss: 0.5281295776367188, avg loss: 0.5281295776367188\n",
      "trial: 2, epoch, 37, iter: 200, curr loss: 0.5225975513458252, avg loss: 0.5233139330148697\n",
      "trial: 2, epoch, 38, iter: 1, curr loss: 0.5293929576873779, avg loss: 0.5293929576873779\n",
      "trial: 2, epoch, 38, iter: 200, curr loss: 0.5247963666915894, avg loss: 0.5235022753477097\n",
      "trial: 2, epoch, 39, iter: 1, curr loss: 0.5193907618522644, avg loss: 0.5193907618522644\n",
      "trial: 2, epoch, 39, iter: 200, curr loss: 0.5280781984329224, avg loss: 0.5232384619116783\n",
      "trial: 2, epoch, 40, iter: 1, curr loss: 0.5318312644958496, avg loss: 0.5318312644958496\n",
      "trial: 2, epoch, 40, iter: 200, curr loss: 0.5299064517021179, avg loss: 0.5231509539484978\n",
      "trial: 2, epoch, 41, iter: 1, curr loss: 0.5274215340614319, avg loss: 0.5274215340614319\n",
      "trial: 2, epoch, 41, iter: 200, curr loss: 0.5323788523674011, avg loss: 0.5228275310993195\n",
      "trial: 2, epoch, 42, iter: 1, curr loss: 0.5230785012245178, avg loss: 0.5230785012245178\n",
      "trial: 2, epoch, 42, iter: 200, curr loss: 0.5271191596984863, avg loss: 0.5230278447270393\n",
      "trial: 2, epoch, 43, iter: 1, curr loss: 0.5107324123382568, avg loss: 0.5107324123382568\n",
      "trial: 2, epoch, 43, iter: 200, curr loss: 0.5235933065414429, avg loss: 0.5230181035399437\n",
      "trial: 2, epoch, 44, iter: 1, curr loss: 0.530689537525177, avg loss: 0.530689537525177\n",
      "trial: 2, epoch, 44, iter: 200, curr loss: 0.5290619134902954, avg loss: 0.5234117877483367\n",
      "trial: 2, epoch, 45, iter: 1, curr loss: 0.5226294994354248, avg loss: 0.5226294994354248\n",
      "trial: 2, epoch, 45, iter: 200, curr loss: 0.5234146118164062, avg loss: 0.5233652284741401\n",
      "trial: 2, epoch, 46, iter: 1, curr loss: 0.5226387977600098, avg loss: 0.5226387977600098\n",
      "trial: 2, epoch, 46, iter: 200, curr loss: 0.524281919002533, avg loss: 0.5229400807619095\n",
      "trial: 2, epoch, 47, iter: 1, curr loss: 0.5278412103652954, avg loss: 0.5278412103652954\n",
      "trial: 2, epoch, 47, iter: 200, curr loss: 0.5218856334686279, avg loss: 0.5232337418198586\n",
      "trial: 2, epoch, 48, iter: 1, curr loss: 0.5299627780914307, avg loss: 0.5299627780914307\n",
      "trial: 2, epoch, 48, iter: 200, curr loss: 0.529786229133606, avg loss: 0.5230078464746475\n",
      "trial: 2, epoch, 49, iter: 1, curr loss: 0.5200217962265015, avg loss: 0.5200217962265015\n",
      "trial: 2, epoch, 49, iter: 200, curr loss: 0.516568660736084, avg loss: 0.5229430606961251\n",
      "trial: 2, epoch, 50, iter: 1, curr loss: 0.5316380262374878, avg loss: 0.5316380262374878\n",
      "trial: 2, epoch, 50, iter: 200, curr loss: 0.5280907154083252, avg loss: 0.5230480974912644\n",
      "trial: 2, ldr: 0.5515743494033813, dv: 0.5640096664428711, nwj: 0.5639326572418213\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, epoch, 1, iter: 1, curr loss: 0.6941548585891724, avg loss: 0.6941548585891724\n",
      "trial: 3, epoch, 1, iter: 200, curr loss: 0.5225723385810852, avg loss: 0.5348844087123871\n",
      "trial: 3, epoch, 2, iter: 1, curr loss: 0.5122225880622864, avg loss: 0.5122225880622864\n",
      "trial: 3, epoch, 2, iter: 200, curr loss: 0.5354233980178833, avg loss: 0.5237420475482941\n",
      "trial: 3, epoch, 3, iter: 1, curr loss: 0.5283958911895752, avg loss: 0.5283958911895752\n",
      "trial: 3, epoch, 3, iter: 200, curr loss: 0.5163737535476685, avg loss: 0.523439470231533\n",
      "trial: 3, epoch, 4, iter: 1, curr loss: 0.5225443840026855, avg loss: 0.5225443840026855\n",
      "trial: 3, epoch, 4, iter: 200, curr loss: 0.5362101793289185, avg loss: 0.5232004803419114\n",
      "trial: 3, epoch, 5, iter: 1, curr loss: 0.5347100496292114, avg loss: 0.5347100496292114\n",
      "trial: 3, epoch, 5, iter: 200, curr loss: 0.5357791185379028, avg loss: 0.5228975814580917\n",
      "trial: 3, epoch, 6, iter: 1, curr loss: 0.5297408103942871, avg loss: 0.5297408103942871\n",
      "trial: 3, epoch, 6, iter: 200, curr loss: 0.5224173665046692, avg loss: 0.5233791130781174\n",
      "trial: 3, epoch, 7, iter: 1, curr loss: 0.517966628074646, avg loss: 0.517966628074646\n",
      "trial: 3, epoch, 7, iter: 200, curr loss: 0.5315616726875305, avg loss: 0.5234103441238404\n",
      "trial: 3, epoch, 8, iter: 1, curr loss: 0.5181988477706909, avg loss: 0.5181988477706909\n",
      "trial: 3, epoch, 8, iter: 200, curr loss: 0.5216001272201538, avg loss: 0.523614841401577\n",
      "trial: 3, epoch, 9, iter: 1, curr loss: 0.5266929864883423, avg loss: 0.5266929864883423\n",
      "trial: 3, epoch, 9, iter: 200, curr loss: 0.5263373255729675, avg loss: 0.5235411956906318\n",
      "trial: 3, epoch, 10, iter: 1, curr loss: 0.5362403392791748, avg loss: 0.5362403392791748\n",
      "trial: 3, epoch, 10, iter: 200, curr loss: 0.5272288918495178, avg loss: 0.5232890883088112\n",
      "trial: 3, epoch, 11, iter: 1, curr loss: 0.5288639068603516, avg loss: 0.5288639068603516\n",
      "trial: 3, epoch, 11, iter: 200, curr loss: 0.5188578963279724, avg loss: 0.5230878958106041\n",
      "trial: 3, epoch, 12, iter: 1, curr loss: 0.522426962852478, avg loss: 0.522426962852478\n",
      "trial: 3, epoch, 12, iter: 200, curr loss: 0.5379540324211121, avg loss: 0.5232352727651596\n",
      "trial: 3, epoch, 13, iter: 1, curr loss: 0.5249741077423096, avg loss: 0.5249741077423096\n",
      "trial: 3, epoch, 13, iter: 200, curr loss: 0.521552562713623, avg loss: 0.523364953994751\n",
      "trial: 3, epoch, 14, iter: 1, curr loss: 0.5249850749969482, avg loss: 0.5249850749969482\n",
      "trial: 3, epoch, 14, iter: 200, curr loss: 0.5302003026008606, avg loss: 0.5234960842132569\n",
      "trial: 3, epoch, 15, iter: 1, curr loss: 0.5251731872558594, avg loss: 0.5251731872558594\n",
      "trial: 3, epoch, 15, iter: 200, curr loss: 0.5209563374519348, avg loss: 0.5231462207436561\n",
      "trial: 3, epoch, 16, iter: 1, curr loss: 0.5202981233596802, avg loss: 0.5202981233596802\n",
      "trial: 3, epoch, 16, iter: 200, curr loss: 0.5226085782051086, avg loss: 0.5232040122151375\n",
      "trial: 3, epoch, 17, iter: 1, curr loss: 0.5182971954345703, avg loss: 0.5182971954345703\n",
      "trial: 3, epoch, 17, iter: 200, curr loss: 0.527753472328186, avg loss: 0.5234158235788345\n",
      "trial: 3, epoch, 18, iter: 1, curr loss: 0.5201646089553833, avg loss: 0.5201646089553833\n",
      "trial: 3, epoch, 18, iter: 200, curr loss: 0.5265348553657532, avg loss: 0.5230119472742081\n",
      "trial: 3, epoch, 19, iter: 1, curr loss: 0.5295355916023254, avg loss: 0.5295355916023254\n",
      "trial: 3, epoch, 19, iter: 200, curr loss: 0.5222235918045044, avg loss: 0.5237450322508812\n",
      "trial: 3, epoch, 20, iter: 1, curr loss: 0.5143945217132568, avg loss: 0.5143945217132568\n",
      "trial: 3, epoch, 20, iter: 200, curr loss: 0.5338366031646729, avg loss: 0.5233515447378159\n",
      "trial: 3, epoch, 21, iter: 1, curr loss: 0.527789831161499, avg loss: 0.527789831161499\n",
      "trial: 3, epoch, 21, iter: 200, curr loss: 0.5341894626617432, avg loss: 0.5229432329535484\n",
      "trial: 3, epoch, 22, iter: 1, curr loss: 0.5199333429336548, avg loss: 0.5199333429336548\n",
      "trial: 3, epoch, 22, iter: 200, curr loss: 0.5213838815689087, avg loss: 0.5232551804184914\n",
      "trial: 3, epoch, 23, iter: 1, curr loss: 0.534622311592102, avg loss: 0.534622311592102\n",
      "trial: 3, epoch, 23, iter: 200, curr loss: 0.5295708179473877, avg loss: 0.5233377075195312\n",
      "trial: 3, epoch, 24, iter: 1, curr loss: 0.5309240221977234, avg loss: 0.5309240221977234\n",
      "trial: 3, epoch, 24, iter: 200, curr loss: 0.5329710841178894, avg loss: 0.5237817287445068\n",
      "trial: 3, epoch, 25, iter: 1, curr loss: 0.5292308330535889, avg loss: 0.5292308330535889\n",
      "trial: 3, epoch, 25, iter: 200, curr loss: 0.5278341770172119, avg loss: 0.5230499452352524\n",
      "trial: 3, epoch, 26, iter: 1, curr loss: 0.5290266275405884, avg loss: 0.5290266275405884\n",
      "trial: 3, epoch, 26, iter: 200, curr loss: 0.5221952795982361, avg loss: 0.5234673234820366\n",
      "trial: 3, epoch, 27, iter: 1, curr loss: 0.5285036563873291, avg loss: 0.5285036563873291\n",
      "trial: 3, epoch, 27, iter: 200, curr loss: 0.5239511132240295, avg loss: 0.5234723502397537\n",
      "trial: 3, epoch, 28, iter: 1, curr loss: 0.5289942026138306, avg loss: 0.5289942026138306\n",
      "trial: 3, epoch, 28, iter: 200, curr loss: 0.5330978631973267, avg loss: 0.5231179052591324\n",
      "trial: 3, epoch, 29, iter: 1, curr loss: 0.526203989982605, avg loss: 0.526203989982605\n",
      "trial: 3, epoch, 29, iter: 200, curr loss: 0.522695004940033, avg loss: 0.5231040006875992\n",
      "trial: 3, epoch, 30, iter: 1, curr loss: 0.5302302837371826, avg loss: 0.5302302837371826\n",
      "trial: 3, epoch, 30, iter: 200, curr loss: 0.5271826982498169, avg loss: 0.5231789627671242\n",
      "trial: 3, epoch, 31, iter: 1, curr loss: 0.5359798073768616, avg loss: 0.5359798073768616\n",
      "trial: 3, epoch, 31, iter: 200, curr loss: 0.5264304876327515, avg loss: 0.5229822957515716\n",
      "trial: 3, epoch, 32, iter: 1, curr loss: 0.5177303552627563, avg loss: 0.5177303552627563\n",
      "trial: 3, epoch, 32, iter: 200, curr loss: 0.5264626145362854, avg loss: 0.5230834627151489\n",
      "trial: 3, epoch, 33, iter: 1, curr loss: 0.5166544318199158, avg loss: 0.5166544318199158\n",
      "trial: 3, epoch, 33, iter: 200, curr loss: 0.5202458500862122, avg loss: 0.5232210341095924\n",
      "trial: 3, epoch, 34, iter: 1, curr loss: 0.5167795419692993, avg loss: 0.5167795419692993\n",
      "trial: 3, epoch, 34, iter: 200, curr loss: 0.5175246596336365, avg loss: 0.5231805762648583\n",
      "trial: 3, epoch, 35, iter: 1, curr loss: 0.5357905626296997, avg loss: 0.5357905626296997\n",
      "trial: 3, epoch, 35, iter: 200, curr loss: 0.5233596563339233, avg loss: 0.5239912518858909\n",
      "trial: 3, epoch, 36, iter: 1, curr loss: 0.5164310336112976, avg loss: 0.5164310336112976\n",
      "trial: 3, epoch, 36, iter: 200, curr loss: 0.5343194007873535, avg loss: 0.5228706175088882\n",
      "trial: 3, epoch, 37, iter: 1, curr loss: 0.5264078378677368, avg loss: 0.5264078378677368\n",
      "trial: 3, epoch, 37, iter: 200, curr loss: 0.5338946580886841, avg loss: 0.5227519050240517\n",
      "trial: 3, epoch, 38, iter: 1, curr loss: 0.5289599895477295, avg loss: 0.5289599895477295\n",
      "trial: 3, epoch, 38, iter: 200, curr loss: 0.5184910297393799, avg loss: 0.523361439704895\n",
      "trial: 3, epoch, 39, iter: 1, curr loss: 0.5206570625305176, avg loss: 0.5206570625305176\n",
      "trial: 3, epoch, 39, iter: 200, curr loss: 0.53310227394104, avg loss: 0.5236394280195236\n",
      "trial: 3, epoch, 40, iter: 1, curr loss: 0.5180666446685791, avg loss: 0.5180666446685791\n",
      "trial: 3, epoch, 40, iter: 200, curr loss: 0.5244401693344116, avg loss: 0.5234117442369461\n",
      "trial: 3, epoch, 41, iter: 1, curr loss: 0.5272290706634521, avg loss: 0.5272290706634521\n",
      "trial: 3, epoch, 41, iter: 200, curr loss: 0.5309296250343323, avg loss: 0.523674713075161\n",
      "trial: 3, epoch, 42, iter: 1, curr loss: 0.5326177477836609, avg loss: 0.5326177477836609\n",
      "trial: 3, epoch, 42, iter: 200, curr loss: 0.5224349498748779, avg loss: 0.5236459818482398\n",
      "trial: 3, epoch, 43, iter: 1, curr loss: 0.5237371921539307, avg loss: 0.5237371921539307\n",
      "trial: 3, epoch, 43, iter: 200, curr loss: 0.526249349117279, avg loss: 0.5232908266782761\n",
      "trial: 3, epoch, 44, iter: 1, curr loss: 0.5191558599472046, avg loss: 0.5191558599472046\n",
      "trial: 3, epoch, 44, iter: 200, curr loss: 0.522229790687561, avg loss: 0.5232407832145691\n",
      "trial: 3, epoch, 45, iter: 1, curr loss: 0.5225688219070435, avg loss: 0.5225688219070435\n",
      "trial: 3, epoch, 45, iter: 200, curr loss: 0.5223404169082642, avg loss: 0.5231760820746422\n",
      "trial: 3, epoch, 46, iter: 1, curr loss: 0.5268984436988831, avg loss: 0.5268984436988831\n",
      "trial: 3, epoch, 46, iter: 200, curr loss: 0.5221958160400391, avg loss: 0.5228955999016762\n",
      "trial: 3, epoch, 47, iter: 1, curr loss: 0.5306742191314697, avg loss: 0.5306742191314697\n",
      "trial: 3, epoch, 47, iter: 200, curr loss: 0.5265714526176453, avg loss: 0.5234080216288567\n",
      "trial: 3, epoch, 48, iter: 1, curr loss: 0.5273498296737671, avg loss: 0.5273498296737671\n",
      "trial: 3, epoch, 48, iter: 200, curr loss: 0.5296101570129395, avg loss: 0.5232318159937859\n",
      "trial: 3, epoch, 49, iter: 1, curr loss: 0.5240585803985596, avg loss: 0.5240585803985596\n",
      "trial: 3, epoch, 49, iter: 200, curr loss: 0.5342610478401184, avg loss: 0.523081645667553\n",
      "trial: 3, epoch, 50, iter: 1, curr loss: 0.5357074737548828, avg loss: 0.5357074737548828\n",
      "trial: 3, epoch, 50, iter: 200, curr loss: 0.5340722799301147, avg loss: 0.5231777659058571\n",
      "trial: 3, ldr: 0.5637806057929993, dv: 0.5640106201171875, nwj: 0.5640106201171875\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, epoch, 1, iter: 1, curr loss: 0.6939913630485535, avg loss: 0.6939913630485535\n",
      "trial: 4, epoch, 1, iter: 200, curr loss: 0.522334098815918, avg loss: 0.535186319053173\n",
      "trial: 4, epoch, 2, iter: 1, curr loss: 0.5355405807495117, avg loss: 0.5355405807495117\n",
      "trial: 4, epoch, 2, iter: 200, curr loss: 0.5252856016159058, avg loss: 0.524646218419075\n",
      "trial: 4, epoch, 3, iter: 1, curr loss: 0.5222218036651611, avg loss: 0.5222218036651611\n",
      "trial: 4, epoch, 3, iter: 200, curr loss: 0.5272725224494934, avg loss: 0.5241037061810494\n",
      "trial: 4, epoch, 4, iter: 1, curr loss: 0.5262309312820435, avg loss: 0.5262309312820435\n",
      "trial: 4, epoch, 4, iter: 200, curr loss: 0.5271941423416138, avg loss: 0.5230813872814178\n",
      "trial: 4, epoch, 5, iter: 1, curr loss: 0.5284068584442139, avg loss: 0.5284068584442139\n",
      "trial: 4, epoch, 5, iter: 200, curr loss: 0.5332306623458862, avg loss: 0.5232567945122719\n",
      "trial: 4, epoch, 6, iter: 1, curr loss: 0.5191482901573181, avg loss: 0.5191482901573181\n",
      "trial: 4, epoch, 6, iter: 200, curr loss: 0.5216221213340759, avg loss: 0.523125465810299\n",
      "trial: 4, epoch, 7, iter: 1, curr loss: 0.5288615226745605, avg loss: 0.5288615226745605\n",
      "trial: 4, epoch, 7, iter: 200, curr loss: 0.5161889791488647, avg loss: 0.5233711695671082\n",
      "trial: 4, epoch, 8, iter: 1, curr loss: 0.5190843343734741, avg loss: 0.5190843343734741\n",
      "trial: 4, epoch, 8, iter: 200, curr loss: 0.5167431831359863, avg loss: 0.5238187083601952\n",
      "trial: 4, epoch, 9, iter: 1, curr loss: 0.5223863124847412, avg loss: 0.5223863124847412\n",
      "trial: 4, epoch, 9, iter: 200, curr loss: 0.5227006673812866, avg loss: 0.5233415591716767\n",
      "trial: 4, epoch, 10, iter: 1, curr loss: 0.539764404296875, avg loss: 0.539764404296875\n",
      "trial: 4, epoch, 10, iter: 200, curr loss: 0.5190833806991577, avg loss: 0.5236631587147713\n",
      "trial: 4, epoch, 11, iter: 1, curr loss: 0.5300289392471313, avg loss: 0.5300289392471313\n",
      "trial: 4, epoch, 11, iter: 200, curr loss: 0.5220470428466797, avg loss: 0.5233782449364662\n",
      "trial: 4, epoch, 12, iter: 1, curr loss: 0.5287483334541321, avg loss: 0.5287483334541321\n",
      "trial: 4, epoch, 12, iter: 200, curr loss: 0.5250555276870728, avg loss: 0.5229523068666458\n",
      "trial: 4, epoch, 13, iter: 1, curr loss: 0.5245763659477234, avg loss: 0.5245763659477234\n",
      "trial: 4, epoch, 13, iter: 200, curr loss: 0.5172246098518372, avg loss: 0.5231185922026634\n",
      "trial: 4, epoch, 14, iter: 1, curr loss: 0.526190996170044, avg loss: 0.526190996170044\n",
      "trial: 4, epoch, 14, iter: 200, curr loss: 0.5300370454788208, avg loss: 0.5232148140668869\n",
      "trial: 4, epoch, 15, iter: 1, curr loss: 0.5348682403564453, avg loss: 0.5348682403564453\n",
      "trial: 4, epoch, 15, iter: 200, curr loss: 0.5221951007843018, avg loss: 0.523129774928093\n",
      "trial: 4, epoch, 16, iter: 1, curr loss: 0.5291814208030701, avg loss: 0.5291814208030701\n",
      "trial: 4, epoch, 16, iter: 200, curr loss: 0.5228234529495239, avg loss: 0.523515812754631\n",
      "trial: 4, epoch, 17, iter: 1, curr loss: 0.5201548933982849, avg loss: 0.5201548933982849\n",
      "trial: 4, epoch, 17, iter: 200, curr loss: 0.5191069841384888, avg loss: 0.5233646243810653\n",
      "trial: 4, epoch, 18, iter: 1, curr loss: 0.5276352167129517, avg loss: 0.5276352167129517\n",
      "trial: 4, epoch, 18, iter: 200, curr loss: 0.5233696699142456, avg loss: 0.5232926422357559\n",
      "trial: 4, epoch, 19, iter: 1, curr loss: 0.5237611532211304, avg loss: 0.5237611532211304\n",
      "trial: 4, epoch, 19, iter: 200, curr loss: 0.5278409719467163, avg loss: 0.5231456673145294\n",
      "trial: 4, epoch, 20, iter: 1, curr loss: 0.5266593098640442, avg loss: 0.5266593098640442\n",
      "trial: 4, epoch, 20, iter: 200, curr loss: 0.5146124362945557, avg loss: 0.5230966103076935\n",
      "trial: 4, epoch, 21, iter: 1, curr loss: 0.534216582775116, avg loss: 0.534216582775116\n",
      "trial: 4, epoch, 21, iter: 200, curr loss: 0.5243634581565857, avg loss: 0.5227126434445382\n",
      "trial: 4, epoch, 22, iter: 1, curr loss: 0.5266306400299072, avg loss: 0.5266306400299072\n",
      "trial: 4, epoch, 22, iter: 200, curr loss: 0.5211905241012573, avg loss: 0.5228729408979416\n",
      "trial: 4, epoch, 23, iter: 1, curr loss: 0.5334209203720093, avg loss: 0.5334209203720093\n",
      "trial: 4, epoch, 23, iter: 200, curr loss: 0.5348168611526489, avg loss: 0.5238258334994316\n",
      "trial: 4, epoch, 24, iter: 1, curr loss: 0.5312619209289551, avg loss: 0.5312619209289551\n",
      "trial: 4, epoch, 24, iter: 200, curr loss: 0.527151882648468, avg loss: 0.5230369567871094\n",
      "trial: 4, epoch, 25, iter: 1, curr loss: 0.5268806219100952, avg loss: 0.5268806219100952\n",
      "trial: 4, epoch, 25, iter: 200, curr loss: 0.5283856391906738, avg loss: 0.5236080124974251\n",
      "trial: 4, epoch, 26, iter: 1, curr loss: 0.5235649347305298, avg loss: 0.5235649347305298\n",
      "trial: 4, epoch, 26, iter: 200, curr loss: 0.5356511473655701, avg loss: 0.5234306940436363\n",
      "trial: 4, epoch, 27, iter: 1, curr loss: 0.5217387676239014, avg loss: 0.5217387676239014\n",
      "trial: 4, epoch, 27, iter: 200, curr loss: 0.5264074802398682, avg loss: 0.5235847619175911\n",
      "trial: 4, epoch, 28, iter: 1, curr loss: 0.5286422967910767, avg loss: 0.5286422967910767\n",
      "trial: 4, epoch, 28, iter: 200, curr loss: 0.515907883644104, avg loss: 0.5228937247395515\n",
      "trial: 4, epoch, 29, iter: 1, curr loss: 0.522552490234375, avg loss: 0.522552490234375\n",
      "trial: 4, epoch, 29, iter: 200, curr loss: 0.5166628360748291, avg loss: 0.5233138772845268\n",
      "trial: 4, epoch, 30, iter: 1, curr loss: 0.5212299823760986, avg loss: 0.5212299823760986\n",
      "trial: 4, epoch, 30, iter: 200, curr loss: 0.522795557975769, avg loss: 0.5230152463912964\n",
      "trial: 4, epoch, 31, iter: 1, curr loss: 0.5265932083129883, avg loss: 0.5265932083129883\n",
      "trial: 4, epoch, 31, iter: 200, curr loss: 0.5226295590400696, avg loss: 0.5232037618756294\n",
      "trial: 4, epoch, 32, iter: 1, curr loss: 0.5287084579467773, avg loss: 0.5287084579467773\n",
      "trial: 4, epoch, 32, iter: 200, curr loss: 0.522657036781311, avg loss: 0.5230248978734017\n",
      "trial: 4, epoch, 33, iter: 1, curr loss: 0.5169532299041748, avg loss: 0.5169532299041748\n",
      "trial: 4, epoch, 33, iter: 200, curr loss: 0.5186522006988525, avg loss: 0.5232297804951668\n",
      "trial: 4, epoch, 34, iter: 1, curr loss: 0.524018406867981, avg loss: 0.524018406867981\n",
      "trial: 4, epoch, 34, iter: 200, curr loss: 0.529249370098114, avg loss: 0.5232625597715378\n",
      "trial: 4, epoch, 35, iter: 1, curr loss: 0.526269793510437, avg loss: 0.526269793510437\n",
      "trial: 4, epoch, 35, iter: 200, curr loss: 0.5175381898880005, avg loss: 0.5226996397972107\n",
      "trial: 4, epoch, 36, iter: 1, curr loss: 0.520622968673706, avg loss: 0.520622968673706\n",
      "trial: 4, epoch, 36, iter: 200, curr loss: 0.530910849571228, avg loss: 0.5228515756130219\n",
      "trial: 4, epoch, 37, iter: 1, curr loss: 0.5374028086662292, avg loss: 0.5374028086662292\n",
      "trial: 4, epoch, 37, iter: 200, curr loss: 0.5248551964759827, avg loss: 0.523251319527626\n",
      "trial: 4, epoch, 38, iter: 1, curr loss: 0.519952654838562, avg loss: 0.519952654838562\n",
      "trial: 4, epoch, 38, iter: 200, curr loss: 0.5244921445846558, avg loss: 0.5230266955494881\n",
      "trial: 4, epoch, 39, iter: 1, curr loss: 0.5236780643463135, avg loss: 0.5236780643463135\n",
      "trial: 4, epoch, 39, iter: 200, curr loss: 0.5229494571685791, avg loss: 0.5231448200345039\n",
      "trial: 4, epoch, 40, iter: 1, curr loss: 0.5282326340675354, avg loss: 0.5282326340675354\n",
      "trial: 4, epoch, 40, iter: 200, curr loss: 0.5212584733963013, avg loss: 0.5232330083847045\n",
      "trial: 4, epoch, 41, iter: 1, curr loss: 0.519507646560669, avg loss: 0.519507646560669\n",
      "trial: 4, epoch, 41, iter: 200, curr loss: 0.522889256477356, avg loss: 0.5234766864776611\n",
      "trial: 4, epoch, 42, iter: 1, curr loss: 0.5249600410461426, avg loss: 0.5249600410461426\n",
      "trial: 4, epoch, 42, iter: 200, curr loss: 0.5274338722229004, avg loss: 0.5228656777739524\n",
      "trial: 4, epoch, 43, iter: 1, curr loss: 0.5290216207504272, avg loss: 0.5290216207504272\n",
      "trial: 4, epoch, 43, iter: 200, curr loss: 0.5267788171768188, avg loss: 0.522871663570404\n",
      "trial: 4, epoch, 44, iter: 1, curr loss: 0.5209546685218811, avg loss: 0.5209546685218811\n",
      "trial: 4, epoch, 44, iter: 200, curr loss: 0.5258338451385498, avg loss: 0.5233748537302018\n",
      "trial: 4, epoch, 45, iter: 1, curr loss: 0.5260275602340698, avg loss: 0.5260275602340698\n",
      "trial: 4, epoch, 45, iter: 200, curr loss: 0.5196717977523804, avg loss: 0.5236940675973892\n",
      "trial: 4, epoch, 46, iter: 1, curr loss: 0.5288761854171753, avg loss: 0.5288761854171753\n",
      "trial: 4, epoch, 46, iter: 200, curr loss: 0.529520571231842, avg loss: 0.5235457876324654\n",
      "trial: 4, epoch, 47, iter: 1, curr loss: 0.5270214080810547, avg loss: 0.5270214080810547\n",
      "trial: 4, epoch, 47, iter: 200, curr loss: 0.5220140814781189, avg loss: 0.5235497844219208\n",
      "trial: 4, epoch, 48, iter: 1, curr loss: 0.5216256380081177, avg loss: 0.5216256380081177\n",
      "trial: 4, epoch, 48, iter: 200, curr loss: 0.5304011106491089, avg loss: 0.5231626158952714\n",
      "trial: 4, epoch, 49, iter: 1, curr loss: 0.5217390060424805, avg loss: 0.5217390060424805\n",
      "trial: 4, epoch, 49, iter: 200, curr loss: 0.5213050246238708, avg loss: 0.5236760127544403\n",
      "trial: 4, epoch, 50, iter: 1, curr loss: 0.5315706729888916, avg loss: 0.5315706729888916\n",
      "trial: 4, epoch, 50, iter: 200, curr loss: 0.5318618416786194, avg loss: 0.5234699308872223\n",
      "trial: 4, ldr: 0.5670950412750244, dv: 0.5640041828155518, nwj: 0.5639994144439697\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, epoch, 1, iter: 1, curr loss: 0.6927744150161743, avg loss: 0.6927744150161743\n",
      "trial: 5, epoch, 1, iter: 200, curr loss: 0.5233665704727173, avg loss: 0.5341343048214913\n",
      "trial: 5, epoch, 2, iter: 1, curr loss: 0.5340440273284912, avg loss: 0.5340440273284912\n",
      "trial: 5, epoch, 2, iter: 200, curr loss: 0.5246270895004272, avg loss: 0.5243182170391083\n",
      "trial: 5, epoch, 3, iter: 1, curr loss: 0.5286860466003418, avg loss: 0.5286860466003418\n",
      "trial: 5, epoch, 3, iter: 200, curr loss: 0.52301025390625, avg loss: 0.5236458623409271\n",
      "trial: 5, epoch, 4, iter: 1, curr loss: 0.5291734337806702, avg loss: 0.5291734337806702\n",
      "trial: 5, epoch, 4, iter: 200, curr loss: 0.5193602442741394, avg loss: 0.5234243333339691\n",
      "trial: 5, epoch, 5, iter: 1, curr loss: 0.5255658626556396, avg loss: 0.5255658626556396\n",
      "trial: 5, epoch, 5, iter: 200, curr loss: 0.5232506990432739, avg loss: 0.5233071485161781\n",
      "trial: 5, epoch, 6, iter: 1, curr loss: 0.532376766204834, avg loss: 0.532376766204834\n",
      "trial: 5, epoch, 6, iter: 200, curr loss: 0.5322860479354858, avg loss: 0.5229959526658058\n",
      "trial: 5, epoch, 7, iter: 1, curr loss: 0.5289677381515503, avg loss: 0.5289677381515503\n",
      "trial: 5, epoch, 7, iter: 200, curr loss: 0.5368356704711914, avg loss: 0.5232051312923431\n",
      "trial: 5, epoch, 8, iter: 1, curr loss: 0.5189598798751831, avg loss: 0.5189598798751831\n",
      "trial: 5, epoch, 8, iter: 200, curr loss: 0.5221471786499023, avg loss: 0.5238265946507454\n",
      "trial: 5, epoch, 9, iter: 1, curr loss: 0.5212072730064392, avg loss: 0.5212072730064392\n",
      "trial: 5, epoch, 9, iter: 200, curr loss: 0.5268482565879822, avg loss: 0.5236399933695793\n",
      "trial: 5, epoch, 10, iter: 1, curr loss: 0.523638129234314, avg loss: 0.523638129234314\n",
      "trial: 5, epoch, 10, iter: 200, curr loss: 0.5336704254150391, avg loss: 0.5232279944419861\n",
      "trial: 5, epoch, 11, iter: 1, curr loss: 0.5317786931991577, avg loss: 0.5317786931991577\n",
      "trial: 5, epoch, 11, iter: 200, curr loss: 0.5332226753234863, avg loss: 0.5233642968535424\n",
      "trial: 5, epoch, 12, iter: 1, curr loss: 0.5180004835128784, avg loss: 0.5180004835128784\n",
      "trial: 5, epoch, 12, iter: 200, curr loss: 0.5231294631958008, avg loss: 0.5230725806951523\n",
      "trial: 5, epoch, 13, iter: 1, curr loss: 0.5259256958961487, avg loss: 0.5259256958961487\n",
      "trial: 5, epoch, 13, iter: 200, curr loss: 0.5228714346885681, avg loss: 0.5235547676682473\n",
      "trial: 5, epoch, 14, iter: 1, curr loss: 0.5326272249221802, avg loss: 0.5326272249221802\n",
      "trial: 5, epoch, 14, iter: 200, curr loss: 0.5255395174026489, avg loss: 0.5231928732991219\n",
      "trial: 5, epoch, 15, iter: 1, curr loss: 0.5358082056045532, avg loss: 0.5358082056045532\n",
      "trial: 5, epoch, 15, iter: 200, curr loss: 0.5294317007064819, avg loss: 0.5233587270975113\n",
      "trial: 5, epoch, 16, iter: 1, curr loss: 0.534892737865448, avg loss: 0.534892737865448\n",
      "trial: 5, epoch, 16, iter: 200, curr loss: 0.5224869847297668, avg loss: 0.5233061921596527\n",
      "trial: 5, epoch, 17, iter: 1, curr loss: 0.5205943584442139, avg loss: 0.5205943584442139\n",
      "trial: 5, epoch, 17, iter: 200, curr loss: 0.5235968828201294, avg loss: 0.5234531882405281\n",
      "trial: 5, epoch, 18, iter: 1, curr loss: 0.5196537971496582, avg loss: 0.5196537971496582\n",
      "trial: 5, epoch, 18, iter: 200, curr loss: 0.5353704690933228, avg loss: 0.5232151019573211\n",
      "trial: 5, epoch, 19, iter: 1, curr loss: 0.5344942212104797, avg loss: 0.5344942212104797\n",
      "trial: 5, epoch, 19, iter: 200, curr loss: 0.5249279737472534, avg loss: 0.5233439525961876\n",
      "trial: 5, epoch, 20, iter: 1, curr loss: 0.536376416683197, avg loss: 0.536376416683197\n",
      "trial: 5, epoch, 20, iter: 200, curr loss: 0.5348542332649231, avg loss: 0.5235289049148559\n",
      "trial: 5, epoch, 21, iter: 1, curr loss: 0.5339059829711914, avg loss: 0.5339059829711914\n",
      "trial: 5, epoch, 21, iter: 200, curr loss: 0.5134496688842773, avg loss: 0.5229276424646377\n",
      "trial: 5, epoch, 22, iter: 1, curr loss: 0.5216644406318665, avg loss: 0.5216644406318665\n",
      "trial: 5, epoch, 22, iter: 200, curr loss: 0.520106315612793, avg loss: 0.5237083098292351\n",
      "trial: 5, epoch, 23, iter: 1, curr loss: 0.5208323001861572, avg loss: 0.5208323001861572\n",
      "trial: 5, epoch, 23, iter: 200, curr loss: 0.5297743082046509, avg loss: 0.5231633925437927\n",
      "trial: 5, epoch, 24, iter: 1, curr loss: 0.5195534229278564, avg loss: 0.5195534229278564\n",
      "trial: 5, epoch, 24, iter: 200, curr loss: 0.5179404020309448, avg loss: 0.5232735061645508\n",
      "trial: 5, epoch, 25, iter: 1, curr loss: 0.5269065499305725, avg loss: 0.5269065499305725\n",
      "trial: 5, epoch, 25, iter: 200, curr loss: 0.5364912748336792, avg loss: 0.5226391544938087\n",
      "trial: 5, epoch, 26, iter: 1, curr loss: 0.522320032119751, avg loss: 0.522320032119751\n",
      "trial: 5, epoch, 26, iter: 200, curr loss: 0.5242783427238464, avg loss: 0.5234754598140716\n",
      "trial: 5, epoch, 27, iter: 1, curr loss: 0.5244274139404297, avg loss: 0.5244274139404297\n",
      "trial: 5, epoch, 27, iter: 200, curr loss: 0.5305037498474121, avg loss: 0.5229439160227776\n",
      "trial: 5, epoch, 28, iter: 1, curr loss: 0.5314533710479736, avg loss: 0.5314533710479736\n",
      "trial: 5, epoch, 28, iter: 200, curr loss: 0.530444860458374, avg loss: 0.5229239699244499\n",
      "trial: 5, epoch, 29, iter: 1, curr loss: 0.5155368447303772, avg loss: 0.5155368447303772\n",
      "trial: 5, epoch, 29, iter: 200, curr loss: 0.5196372270584106, avg loss: 0.5230723875761032\n",
      "trial: 5, epoch, 30, iter: 1, curr loss: 0.5203053951263428, avg loss: 0.5203053951263428\n",
      "trial: 5, epoch, 30, iter: 200, curr loss: 0.5249435901641846, avg loss: 0.5229991194605828\n",
      "trial: 5, epoch, 31, iter: 1, curr loss: 0.5228694677352905, avg loss: 0.5228694677352905\n",
      "trial: 5, epoch, 31, iter: 200, curr loss: 0.5179468393325806, avg loss: 0.5232217326760292\n",
      "trial: 5, epoch, 32, iter: 1, curr loss: 0.529701828956604, avg loss: 0.529701828956604\n",
      "trial: 5, epoch, 32, iter: 200, curr loss: 0.5290919542312622, avg loss: 0.5236151570081711\n",
      "trial: 5, epoch, 33, iter: 1, curr loss: 0.5344686508178711, avg loss: 0.5344686508178711\n",
      "trial: 5, epoch, 33, iter: 200, curr loss: 0.5294208526611328, avg loss: 0.5226513490080833\n",
      "trial: 5, epoch, 34, iter: 1, curr loss: 0.5260502099990845, avg loss: 0.5260502099990845\n",
      "trial: 5, epoch, 34, iter: 200, curr loss: 0.5238093137741089, avg loss: 0.5230616343021393\n",
      "trial: 5, epoch, 35, iter: 1, curr loss: 0.5235778093338013, avg loss: 0.5235778093338013\n",
      "trial: 5, epoch, 35, iter: 200, curr loss: 0.5231494903564453, avg loss: 0.5230712503194809\n",
      "trial: 5, epoch, 36, iter: 1, curr loss: 0.5280284881591797, avg loss: 0.5280284881591797\n",
      "trial: 5, epoch, 36, iter: 200, curr loss: 0.5278009176254272, avg loss: 0.5231985956430435\n",
      "trial: 5, epoch, 37, iter: 1, curr loss: 0.5228824615478516, avg loss: 0.5228824615478516\n",
      "trial: 5, epoch, 37, iter: 200, curr loss: 0.5352978110313416, avg loss: 0.5230122980475426\n",
      "trial: 5, epoch, 38, iter: 1, curr loss: 0.5254631042480469, avg loss: 0.5254631042480469\n",
      "trial: 5, epoch, 38, iter: 200, curr loss: 0.53083336353302, avg loss: 0.5230418506264687\n",
      "trial: 5, epoch, 39, iter: 1, curr loss: 0.5328891277313232, avg loss: 0.5328891277313232\n",
      "trial: 5, epoch, 39, iter: 200, curr loss: 0.5260273218154907, avg loss: 0.5229700258374215\n",
      "trial: 5, epoch, 40, iter: 1, curr loss: 0.5278167724609375, avg loss: 0.5278167724609375\n",
      "trial: 5, epoch, 40, iter: 200, curr loss: 0.5169543027877808, avg loss: 0.5230068188905715\n",
      "trial: 5, epoch, 41, iter: 1, curr loss: 0.526141881942749, avg loss: 0.526141881942749\n",
      "trial: 5, epoch, 41, iter: 200, curr loss: 0.5218979120254517, avg loss: 0.5231542733311653\n",
      "trial: 5, epoch, 42, iter: 1, curr loss: 0.5208004117012024, avg loss: 0.5208004117012024\n",
      "trial: 5, epoch, 42, iter: 200, curr loss: 0.5193434357643127, avg loss: 0.5229848462343216\n",
      "trial: 5, epoch, 43, iter: 1, curr loss: 0.5273615121841431, avg loss: 0.5273615121841431\n",
      "trial: 5, epoch, 43, iter: 200, curr loss: 0.5282825231552124, avg loss: 0.5238383480906487\n",
      "trial: 5, epoch, 44, iter: 1, curr loss: 0.5363219380378723, avg loss: 0.5363219380378723\n",
      "trial: 5, epoch, 44, iter: 200, curr loss: 0.536170244216919, avg loss: 0.523411312699318\n",
      "trial: 5, epoch, 45, iter: 1, curr loss: 0.527808427810669, avg loss: 0.527808427810669\n",
      "trial: 5, epoch, 45, iter: 200, curr loss: 0.5227888822555542, avg loss: 0.5233119556307793\n",
      "trial: 5, epoch, 46, iter: 1, curr loss: 0.52367103099823, avg loss: 0.52367103099823\n",
      "trial: 5, epoch, 46, iter: 200, curr loss: 0.5132420063018799, avg loss: 0.5229894062876701\n",
      "trial: 5, epoch, 47, iter: 1, curr loss: 0.5224184989929199, avg loss: 0.5224184989929199\n",
      "trial: 5, epoch, 47, iter: 200, curr loss: 0.5260744094848633, avg loss: 0.5234905982017517\n",
      "trial: 5, epoch, 48, iter: 1, curr loss: 0.53419429063797, avg loss: 0.53419429063797\n",
      "trial: 5, epoch, 48, iter: 200, curr loss: 0.5212900638580322, avg loss: 0.523307534456253\n",
      "trial: 5, epoch, 49, iter: 1, curr loss: 0.5234413743019104, avg loss: 0.5234413743019104\n",
      "trial: 5, epoch, 49, iter: 200, curr loss: 0.5237506031990051, avg loss: 0.5232067257165909\n",
      "trial: 5, epoch, 50, iter: 1, curr loss: 0.5221400260925293, avg loss: 0.5221400260925293\n",
      "trial: 5, epoch, 50, iter: 200, curr loss: 0.5368709564208984, avg loss: 0.5232693469524383\n",
      "trial: 5, ldr: 0.5802093148231506, dv: 0.5635875463485718, nwj: 0.5634486079216003\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 6, epoch, 1, iter: 1, curr loss: 0.6924194097518921, avg loss: 0.6924194097518921\n",
      "trial: 6, epoch, 1, iter: 200, curr loss: 0.5214246511459351, avg loss: 0.5344334122538567\n",
      "trial: 6, epoch, 2, iter: 1, curr loss: 0.5181424617767334, avg loss: 0.5181424617767334\n",
      "trial: 6, epoch, 2, iter: 200, curr loss: 0.5245606899261475, avg loss: 0.5246620091795922\n",
      "trial: 6, epoch, 3, iter: 1, curr loss: 0.5163172483444214, avg loss: 0.5163172483444214\n",
      "trial: 6, epoch, 3, iter: 200, curr loss: 0.5298981070518494, avg loss: 0.5240436732769013\n",
      "trial: 6, epoch, 4, iter: 1, curr loss: 0.5205813050270081, avg loss: 0.5205813050270081\n",
      "trial: 6, epoch, 4, iter: 200, curr loss: 0.5229127407073975, avg loss: 0.5233360692858696\n",
      "trial: 6, epoch, 5, iter: 1, curr loss: 0.5225543975830078, avg loss: 0.5225543975830078\n",
      "trial: 6, epoch, 5, iter: 200, curr loss: 0.5242336988449097, avg loss: 0.523050762116909\n",
      "trial: 6, epoch, 6, iter: 1, curr loss: 0.5233662128448486, avg loss: 0.5233662128448486\n",
      "trial: 6, epoch, 6, iter: 200, curr loss: 0.5266746282577515, avg loss: 0.5232903179526329\n",
      "trial: 6, epoch, 7, iter: 1, curr loss: 0.5217958688735962, avg loss: 0.5217958688735962\n",
      "trial: 6, epoch, 7, iter: 200, curr loss: 0.5285164713859558, avg loss: 0.5230424785614014\n",
      "trial: 6, epoch, 8, iter: 1, curr loss: 0.5243489742279053, avg loss: 0.5243489742279053\n",
      "trial: 6, epoch, 8, iter: 200, curr loss: 0.5198793411254883, avg loss: 0.5231966748833656\n",
      "trial: 6, epoch, 9, iter: 1, curr loss: 0.5359833836555481, avg loss: 0.5359833836555481\n",
      "trial: 6, epoch, 9, iter: 200, curr loss: 0.5296054482460022, avg loss: 0.5230784854292869\n",
      "trial: 6, epoch, 10, iter: 1, curr loss: 0.537926435470581, avg loss: 0.537926435470581\n",
      "trial: 6, epoch, 10, iter: 200, curr loss: 0.5225082039833069, avg loss: 0.5232084718346596\n",
      "trial: 6, epoch, 11, iter: 1, curr loss: 0.5173693895339966, avg loss: 0.5173693895339966\n",
      "trial: 6, epoch, 11, iter: 200, curr loss: 0.5283942222595215, avg loss: 0.5227250647544861\n",
      "trial: 6, epoch, 12, iter: 1, curr loss: 0.509149432182312, avg loss: 0.509149432182312\n",
      "trial: 6, epoch, 12, iter: 200, curr loss: 0.5403263568878174, avg loss: 0.523297345340252\n",
      "trial: 6, epoch, 13, iter: 1, curr loss: 0.5294531583786011, avg loss: 0.5294531583786011\n",
      "trial: 6, epoch, 13, iter: 200, curr loss: 0.5255552530288696, avg loss: 0.5234077325463296\n",
      "trial: 6, epoch, 14, iter: 1, curr loss: 0.5205843448638916, avg loss: 0.5205843448638916\n",
      "trial: 6, epoch, 14, iter: 200, curr loss: 0.5341794490814209, avg loss: 0.5234804120659828\n",
      "trial: 6, epoch, 15, iter: 1, curr loss: 0.5313923358917236, avg loss: 0.5313923358917236\n",
      "trial: 6, epoch, 15, iter: 200, curr loss: 0.516079306602478, avg loss: 0.523536975979805\n",
      "trial: 6, epoch, 16, iter: 1, curr loss: 0.5362201929092407, avg loss: 0.5362201929092407\n",
      "trial: 6, epoch, 16, iter: 200, curr loss: 0.5192060470581055, avg loss: 0.5231794327497482\n",
      "trial: 6, epoch, 17, iter: 1, curr loss: 0.5166448354721069, avg loss: 0.5166448354721069\n",
      "trial: 6, epoch, 17, iter: 200, curr loss: 0.5240343809127808, avg loss: 0.5232698678970337\n",
      "trial: 6, epoch, 18, iter: 1, curr loss: 0.525748610496521, avg loss: 0.525748610496521\n",
      "trial: 6, epoch, 18, iter: 200, curr loss: 0.5260173678398132, avg loss: 0.5228567266464234\n",
      "trial: 6, epoch, 19, iter: 1, curr loss: 0.5300325155258179, avg loss: 0.5300325155258179\n",
      "trial: 6, epoch, 19, iter: 200, curr loss: 0.5282895565032959, avg loss: 0.5231109386682511\n",
      "trial: 6, epoch, 20, iter: 1, curr loss: 0.5245955586433411, avg loss: 0.5245955586433411\n",
      "trial: 6, epoch, 20, iter: 200, curr loss: 0.5308297872543335, avg loss: 0.5234854879975319\n",
      "trial: 6, epoch, 21, iter: 1, curr loss: 0.5213801264762878, avg loss: 0.5213801264762878\n",
      "trial: 6, epoch, 21, iter: 200, curr loss: 0.5257809162139893, avg loss: 0.5231635618209839\n",
      "trial: 6, epoch, 22, iter: 1, curr loss: 0.5332544445991516, avg loss: 0.5332544445991516\n",
      "trial: 6, epoch, 22, iter: 200, curr loss: 0.5287719368934631, avg loss: 0.5227925264835358\n",
      "trial: 6, epoch, 23, iter: 1, curr loss: 0.5328733921051025, avg loss: 0.5328733921051025\n",
      "trial: 6, epoch, 23, iter: 200, curr loss: 0.5246754288673401, avg loss: 0.5228074446320534\n",
      "trial: 6, epoch, 24, iter: 1, curr loss: 0.5237737894058228, avg loss: 0.5237737894058228\n",
      "trial: 6, epoch, 24, iter: 200, curr loss: 0.5350958704948425, avg loss: 0.5231980761885643\n",
      "trial: 6, epoch, 25, iter: 1, curr loss: 0.5120234489440918, avg loss: 0.5120234489440918\n",
      "trial: 6, epoch, 25, iter: 200, curr loss: 0.5292218923568726, avg loss: 0.5235190078616142\n",
      "trial: 6, epoch, 26, iter: 1, curr loss: 0.5274455547332764, avg loss: 0.5274455547332764\n",
      "trial: 6, epoch, 26, iter: 200, curr loss: 0.5315563678741455, avg loss: 0.5231093475222588\n",
      "trial: 6, epoch, 27, iter: 1, curr loss: 0.521400511264801, avg loss: 0.521400511264801\n",
      "trial: 6, epoch, 27, iter: 200, curr loss: 0.5256259441375732, avg loss: 0.5230238151550293\n",
      "trial: 6, epoch, 28, iter: 1, curr loss: 0.532818615436554, avg loss: 0.532818615436554\n",
      "trial: 6, epoch, 28, iter: 200, curr loss: 0.5195097327232361, avg loss: 0.5229679256677627\n",
      "trial: 6, epoch, 29, iter: 1, curr loss: 0.540295422077179, avg loss: 0.540295422077179\n",
      "trial: 6, epoch, 29, iter: 200, curr loss: 0.5110454559326172, avg loss: 0.5235319453477859\n",
      "trial: 6, epoch, 30, iter: 1, curr loss: 0.5188835859298706, avg loss: 0.5188835859298706\n",
      "trial: 6, epoch, 30, iter: 200, curr loss: 0.5196266174316406, avg loss: 0.52323327511549\n",
      "trial: 6, epoch, 31, iter: 1, curr loss: 0.5328160524368286, avg loss: 0.5328160524368286\n",
      "trial: 6, epoch, 31, iter: 200, curr loss: 0.527856707572937, avg loss: 0.5232858717441559\n",
      "trial: 6, epoch, 32, iter: 1, curr loss: 0.5251200199127197, avg loss: 0.5251200199127197\n",
      "trial: 6, epoch, 32, iter: 200, curr loss: 0.5360822677612305, avg loss: 0.5229999443888664\n",
      "trial: 6, epoch, 33, iter: 1, curr loss: 0.5214908123016357, avg loss: 0.5214908123016357\n",
      "trial: 6, epoch, 33, iter: 200, curr loss: 0.5227072834968567, avg loss: 0.5232857039570808\n",
      "trial: 6, epoch, 34, iter: 1, curr loss: 0.5212953090667725, avg loss: 0.5212953090667725\n",
      "trial: 6, epoch, 34, iter: 200, curr loss: 0.5234719514846802, avg loss: 0.5228425407409668\n",
      "trial: 6, epoch, 35, iter: 1, curr loss: 0.5205076336860657, avg loss: 0.5205076336860657\n",
      "trial: 6, epoch, 35, iter: 200, curr loss: 0.5157938003540039, avg loss: 0.5228816151618958\n",
      "trial: 6, epoch, 36, iter: 1, curr loss: 0.5227006673812866, avg loss: 0.5227006673812866\n",
      "trial: 6, epoch, 36, iter: 200, curr loss: 0.523922324180603, avg loss: 0.5230412447452545\n",
      "trial: 6, epoch, 37, iter: 1, curr loss: 0.5226478576660156, avg loss: 0.5226478576660156\n",
      "trial: 6, epoch, 37, iter: 200, curr loss: 0.5220617651939392, avg loss: 0.5229674664139747\n",
      "trial: 6, epoch, 38, iter: 1, curr loss: 0.5268623232841492, avg loss: 0.5268623232841492\n",
      "trial: 6, epoch, 38, iter: 200, curr loss: 0.5296039581298828, avg loss: 0.5233580869436264\n",
      "trial: 6, epoch, 39, iter: 1, curr loss: 0.5238705277442932, avg loss: 0.5238705277442932\n",
      "trial: 6, epoch, 39, iter: 200, curr loss: 0.5227901339530945, avg loss: 0.522930174767971\n",
      "trial: 6, epoch, 40, iter: 1, curr loss: 0.5280327796936035, avg loss: 0.5280327796936035\n",
      "trial: 6, epoch, 40, iter: 200, curr loss: 0.5367181897163391, avg loss: 0.5231728434562684\n",
      "trial: 6, epoch, 41, iter: 1, curr loss: 0.5298045873641968, avg loss: 0.5298045873641968\n",
      "trial: 6, epoch, 41, iter: 200, curr loss: 0.515828013420105, avg loss: 0.523095591366291\n",
      "trial: 6, epoch, 42, iter: 1, curr loss: 0.5330749154090881, avg loss: 0.5330749154090881\n",
      "trial: 6, epoch, 42, iter: 200, curr loss: 0.523639440536499, avg loss: 0.5231230330467224\n",
      "trial: 6, epoch, 43, iter: 1, curr loss: 0.5361676812171936, avg loss: 0.5361676812171936\n",
      "trial: 6, epoch, 43, iter: 200, curr loss: 0.5287908911705017, avg loss: 0.5230526846647262\n",
      "trial: 6, epoch, 44, iter: 1, curr loss: 0.532041072845459, avg loss: 0.532041072845459\n",
      "trial: 6, epoch, 44, iter: 200, curr loss: 0.5279126167297363, avg loss: 0.5231691920757293\n",
      "trial: 6, epoch, 45, iter: 1, curr loss: 0.5320733189582825, avg loss: 0.5320733189582825\n",
      "trial: 6, epoch, 45, iter: 200, curr loss: 0.5257700085639954, avg loss: 0.5231587505340576\n",
      "trial: 6, epoch, 46, iter: 1, curr loss: 0.5340094566345215, avg loss: 0.5340094566345215\n",
      "trial: 6, epoch, 46, iter: 200, curr loss: 0.5341346859931946, avg loss: 0.5238588306307793\n",
      "trial: 6, epoch, 47, iter: 1, curr loss: 0.5262904167175293, avg loss: 0.5262904167175293\n",
      "trial: 6, epoch, 47, iter: 200, curr loss: 0.5273361206054688, avg loss: 0.523101014494896\n",
      "trial: 6, epoch, 48, iter: 1, curr loss: 0.5151336193084717, avg loss: 0.5151336193084717\n",
      "trial: 6, epoch, 48, iter: 200, curr loss: 0.513633131980896, avg loss: 0.523305986225605\n",
      "trial: 6, epoch, 49, iter: 1, curr loss: 0.5303434133529663, avg loss: 0.5303434133529663\n",
      "trial: 6, epoch, 49, iter: 200, curr loss: 0.5380126237869263, avg loss: 0.5231944438815117\n",
      "trial: 6, epoch, 50, iter: 1, curr loss: 0.5261932611465454, avg loss: 0.5261932611465454\n",
      "trial: 6, epoch, 50, iter: 200, curr loss: 0.5279402732849121, avg loss: 0.5230951398611069\n",
      "trial: 6, ldr: 0.5783502459526062, dv: 0.563886284828186, nwj: 0.563781201839447\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 7, epoch, 1, iter: 1, curr loss: 0.6928194165229797, avg loss: 0.6928194165229797\n",
      "trial: 7, epoch, 1, iter: 200, curr loss: 0.5181818604469299, avg loss: 0.5347548443078994\n",
      "trial: 7, epoch, 2, iter: 1, curr loss: 0.5264477729797363, avg loss: 0.5264477729797363\n",
      "trial: 7, epoch, 2, iter: 200, curr loss: 0.5254740715026855, avg loss: 0.5242666870355606\n",
      "trial: 7, epoch, 3, iter: 1, curr loss: 0.5274620056152344, avg loss: 0.5274620056152344\n",
      "trial: 7, epoch, 3, iter: 200, curr loss: 0.5320430994033813, avg loss: 0.523868932723999\n",
      "trial: 7, epoch, 4, iter: 1, curr loss: 0.5362978577613831, avg loss: 0.5362978577613831\n",
      "trial: 7, epoch, 4, iter: 200, curr loss: 0.5289636850357056, avg loss: 0.5230520477890969\n",
      "trial: 7, epoch, 5, iter: 1, curr loss: 0.5354233384132385, avg loss: 0.5354233384132385\n",
      "trial: 7, epoch, 5, iter: 200, curr loss: 0.5296125411987305, avg loss: 0.5230065912008286\n",
      "trial: 7, epoch, 6, iter: 1, curr loss: 0.5349046587944031, avg loss: 0.5349046587944031\n",
      "trial: 7, epoch, 6, iter: 200, curr loss: 0.5216270089149475, avg loss: 0.5233148631453514\n",
      "trial: 7, epoch, 7, iter: 1, curr loss: 0.518944501876831, avg loss: 0.518944501876831\n",
      "trial: 7, epoch, 7, iter: 200, curr loss: 0.5282742977142334, avg loss: 0.5233328172564506\n",
      "trial: 7, epoch, 8, iter: 1, curr loss: 0.5294777154922485, avg loss: 0.5294777154922485\n",
      "trial: 7, epoch, 8, iter: 200, curr loss: 0.524617612361908, avg loss: 0.5235439780354499\n",
      "trial: 7, epoch, 9, iter: 1, curr loss: 0.5293580293655396, avg loss: 0.5293580293655396\n",
      "trial: 7, epoch, 9, iter: 200, curr loss: 0.5271443128585815, avg loss: 0.5235399487614631\n",
      "trial: 7, epoch, 10, iter: 1, curr loss: 0.5142525434494019, avg loss: 0.5142525434494019\n",
      "trial: 7, epoch, 10, iter: 200, curr loss: 0.530949592590332, avg loss: 0.5237645682692528\n",
      "trial: 7, epoch, 11, iter: 1, curr loss: 0.5231429934501648, avg loss: 0.5231429934501648\n",
      "trial: 7, epoch, 11, iter: 200, curr loss: 0.5219395160675049, avg loss: 0.5229733705520629\n",
      "trial: 7, epoch, 12, iter: 1, curr loss: 0.5360808968544006, avg loss: 0.5360808968544006\n",
      "trial: 7, epoch, 12, iter: 200, curr loss: 0.5235558748245239, avg loss: 0.5232480847835541\n",
      "trial: 7, epoch, 13, iter: 1, curr loss: 0.5271130800247192, avg loss: 0.5271130800247192\n",
      "trial: 7, epoch, 13, iter: 200, curr loss: 0.5271258354187012, avg loss: 0.5231417593359947\n",
      "trial: 7, epoch, 14, iter: 1, curr loss: 0.5287843346595764, avg loss: 0.5287843346595764\n",
      "trial: 7, epoch, 14, iter: 200, curr loss: 0.5181057453155518, avg loss: 0.5235392993688583\n",
      "trial: 7, epoch, 15, iter: 1, curr loss: 0.5300687551498413, avg loss: 0.5300687551498413\n",
      "trial: 7, epoch, 15, iter: 200, curr loss: 0.5240815877914429, avg loss: 0.5232248201966285\n",
      "trial: 7, epoch, 16, iter: 1, curr loss: 0.5350571870803833, avg loss: 0.5350571870803833\n",
      "trial: 7, epoch, 16, iter: 200, curr loss: 0.5257346034049988, avg loss: 0.5233287790417671\n",
      "trial: 7, epoch, 17, iter: 1, curr loss: 0.528685450553894, avg loss: 0.528685450553894\n",
      "trial: 7, epoch, 17, iter: 200, curr loss: 0.5210323333740234, avg loss: 0.5233659985661506\n",
      "trial: 7, epoch, 18, iter: 1, curr loss: 0.5269515514373779, avg loss: 0.5269515514373779\n",
      "trial: 7, epoch, 18, iter: 200, curr loss: 0.529107928276062, avg loss: 0.5232408097386361\n",
      "trial: 7, epoch, 19, iter: 1, curr loss: 0.522652268409729, avg loss: 0.522652268409729\n",
      "trial: 7, epoch, 19, iter: 200, curr loss: 0.5273066759109497, avg loss: 0.5229954022169113\n",
      "trial: 7, epoch, 20, iter: 1, curr loss: 0.5239388942718506, avg loss: 0.5239388942718506\n",
      "trial: 7, epoch, 20, iter: 200, curr loss: 0.5318180918693542, avg loss: 0.5236662635207177\n",
      "trial: 7, epoch, 21, iter: 1, curr loss: 0.5289506316184998, avg loss: 0.5289506316184998\n",
      "trial: 7, epoch, 21, iter: 200, curr loss: 0.5220166444778442, avg loss: 0.5236364406347275\n",
      "trial: 7, epoch, 22, iter: 1, curr loss: 0.5136520862579346, avg loss: 0.5136520862579346\n",
      "trial: 7, epoch, 22, iter: 200, curr loss: 0.5151925086975098, avg loss: 0.5230966579914093\n",
      "trial: 7, epoch, 23, iter: 1, curr loss: 0.5229135751724243, avg loss: 0.5229135751724243\n",
      "trial: 7, epoch, 23, iter: 200, curr loss: 0.5231527090072632, avg loss: 0.5233076354861259\n",
      "trial: 7, epoch, 24, iter: 1, curr loss: 0.5230640172958374, avg loss: 0.5230640172958374\n",
      "trial: 7, epoch, 24, iter: 200, curr loss: 0.5128463506698608, avg loss: 0.5236964759230613\n",
      "trial: 7, epoch, 25, iter: 1, curr loss: 0.5228063464164734, avg loss: 0.5228063464164734\n",
      "trial: 7, epoch, 25, iter: 200, curr loss: 0.5230624675750732, avg loss: 0.5232812142372132\n",
      "trial: 7, epoch, 26, iter: 1, curr loss: 0.5241066217422485, avg loss: 0.5241066217422485\n",
      "trial: 7, epoch, 26, iter: 200, curr loss: 0.5231361389160156, avg loss: 0.5230407819151879\n",
      "trial: 7, epoch, 27, iter: 1, curr loss: 0.5312072038650513, avg loss: 0.5312072038650513\n",
      "trial: 7, epoch, 27, iter: 200, curr loss: 0.5274222493171692, avg loss: 0.5234214478731155\n",
      "trial: 7, epoch, 28, iter: 1, curr loss: 0.5211691856384277, avg loss: 0.5211691856384277\n",
      "trial: 7, epoch, 28, iter: 200, curr loss: 0.5233767628669739, avg loss: 0.5233805453777314\n",
      "trial: 7, epoch, 29, iter: 1, curr loss: 0.5251502990722656, avg loss: 0.5251502990722656\n",
      "trial: 7, epoch, 29, iter: 200, curr loss: 0.5238893628120422, avg loss: 0.5230023795366288\n",
      "trial: 7, epoch, 30, iter: 1, curr loss: 0.5273780226707458, avg loss: 0.5273780226707458\n",
      "trial: 7, epoch, 30, iter: 200, curr loss: 0.5303117632865906, avg loss: 0.5233377972245217\n",
      "trial: 7, epoch, 31, iter: 1, curr loss: 0.518979549407959, avg loss: 0.518979549407959\n",
      "trial: 7, epoch, 31, iter: 200, curr loss: 0.5247099995613098, avg loss: 0.5234680044651031\n",
      "trial: 7, epoch, 32, iter: 1, curr loss: 0.5274840593338013, avg loss: 0.5274840593338013\n",
      "trial: 7, epoch, 32, iter: 200, curr loss: 0.5189430713653564, avg loss: 0.5233104857802391\n",
      "trial: 7, epoch, 33, iter: 1, curr loss: 0.5220001339912415, avg loss: 0.5220001339912415\n",
      "trial: 7, epoch, 33, iter: 200, curr loss: 0.5210908055305481, avg loss: 0.5231811735033989\n",
      "trial: 7, epoch, 34, iter: 1, curr loss: 0.5189642906188965, avg loss: 0.5189642906188965\n",
      "trial: 7, epoch, 34, iter: 200, curr loss: 0.5298898816108704, avg loss: 0.5225161448121071\n",
      "trial: 7, epoch, 35, iter: 1, curr loss: 0.5113874673843384, avg loss: 0.5113874673843384\n",
      "trial: 7, epoch, 35, iter: 200, curr loss: 0.5210543870925903, avg loss: 0.5230573469400406\n",
      "trial: 7, epoch, 36, iter: 1, curr loss: 0.5243542194366455, avg loss: 0.5243542194366455\n",
      "trial: 7, epoch, 36, iter: 200, curr loss: 0.5311939716339111, avg loss: 0.5231586533784867\n",
      "trial: 7, epoch, 37, iter: 1, curr loss: 0.5271652340888977, avg loss: 0.5271652340888977\n",
      "trial: 7, epoch, 37, iter: 200, curr loss: 0.5258033871650696, avg loss: 0.5229746860265732\n",
      "trial: 7, epoch, 38, iter: 1, curr loss: 0.5146582126617432, avg loss: 0.5146582126617432\n",
      "trial: 7, epoch, 38, iter: 200, curr loss: 0.5309505462646484, avg loss: 0.5236928963661194\n",
      "trial: 7, epoch, 39, iter: 1, curr loss: 0.5171105265617371, avg loss: 0.5171105265617371\n",
      "trial: 7, epoch, 39, iter: 200, curr loss: 0.5192365050315857, avg loss: 0.5229422643780708\n",
      "trial: 7, epoch, 40, iter: 1, curr loss: 0.5158507823944092, avg loss: 0.5158507823944092\n",
      "trial: 7, epoch, 40, iter: 200, curr loss: 0.5243169069290161, avg loss: 0.5236755913496017\n",
      "trial: 7, epoch, 41, iter: 1, curr loss: 0.5252403020858765, avg loss: 0.5252403020858765\n",
      "trial: 7, epoch, 41, iter: 200, curr loss: 0.5274636149406433, avg loss: 0.5231816318631172\n",
      "trial: 7, epoch, 42, iter: 1, curr loss: 0.5221351981163025, avg loss: 0.5221351981163025\n",
      "trial: 7, epoch, 42, iter: 200, curr loss: 0.5240501761436462, avg loss: 0.5234608301520347\n",
      "trial: 7, epoch, 43, iter: 1, curr loss: 0.5247578620910645, avg loss: 0.5247578620910645\n",
      "trial: 7, epoch, 43, iter: 200, curr loss: 0.5197989344596863, avg loss: 0.5231144639849663\n",
      "trial: 7, epoch, 44, iter: 1, curr loss: 0.5207087993621826, avg loss: 0.5207087993621826\n",
      "trial: 7, epoch, 44, iter: 200, curr loss: 0.5279868841171265, avg loss: 0.52326725512743\n",
      "trial: 7, epoch, 45, iter: 1, curr loss: 0.5254572033882141, avg loss: 0.5254572033882141\n",
      "trial: 7, epoch, 45, iter: 200, curr loss: 0.5217126607894897, avg loss: 0.5230485525727272\n",
      "trial: 7, epoch, 46, iter: 1, curr loss: 0.5298284292221069, avg loss: 0.5298284292221069\n",
      "trial: 7, epoch, 46, iter: 200, curr loss: 0.5258939862251282, avg loss: 0.5232217672467232\n",
      "trial: 7, epoch, 47, iter: 1, curr loss: 0.5259785652160645, avg loss: 0.5259785652160645\n",
      "trial: 7, epoch, 47, iter: 200, curr loss: 0.5244072079658508, avg loss: 0.5230237585306168\n",
      "trial: 7, epoch, 48, iter: 1, curr loss: 0.5306071043014526, avg loss: 0.5306071043014526\n",
      "trial: 7, epoch, 48, iter: 200, curr loss: 0.5411069393157959, avg loss: 0.5234777930378914\n",
      "trial: 7, epoch, 49, iter: 1, curr loss: 0.5152021646499634, avg loss: 0.5152021646499634\n",
      "trial: 7, epoch, 49, iter: 200, curr loss: 0.5309017896652222, avg loss: 0.5239044544100762\n",
      "trial: 7, epoch, 50, iter: 1, curr loss: 0.5239098072052002, avg loss: 0.5239098072052002\n",
      "trial: 7, epoch, 50, iter: 200, curr loss: 0.5209770202636719, avg loss: 0.522796718776226\n",
      "trial: 7, ldr: 0.5979098677635193, dv: 0.5627535581588745, nwj: 0.5621282458305359\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 8, epoch, 1, iter: 1, curr loss: 0.6936448216438293, avg loss: 0.6936448216438293\n",
      "trial: 8, epoch, 1, iter: 200, curr loss: 0.524531364440918, avg loss: 0.5343574947118759\n",
      "trial: 8, epoch, 2, iter: 1, curr loss: 0.5336054563522339, avg loss: 0.5336054563522339\n",
      "trial: 8, epoch, 2, iter: 200, curr loss: 0.5248799324035645, avg loss: 0.5240681102871895\n",
      "trial: 8, epoch, 3, iter: 1, curr loss: 0.5273777842521667, avg loss: 0.5273777842521667\n",
      "trial: 8, epoch, 3, iter: 200, curr loss: 0.529923677444458, avg loss: 0.5239296719431877\n",
      "trial: 8, epoch, 4, iter: 1, curr loss: 0.5280141830444336, avg loss: 0.5280141830444336\n",
      "trial: 8, epoch, 4, iter: 200, curr loss: 0.5274524688720703, avg loss: 0.5231968814134598\n",
      "trial: 8, epoch, 5, iter: 1, curr loss: 0.5279102921485901, avg loss: 0.5279102921485901\n",
      "trial: 8, epoch, 5, iter: 200, curr loss: 0.5215585827827454, avg loss: 0.5230883896350861\n",
      "trial: 8, epoch, 6, iter: 1, curr loss: 0.5270212888717651, avg loss: 0.5270212888717651\n",
      "trial: 8, epoch, 6, iter: 200, curr loss: 0.5316160917282104, avg loss: 0.5235935178399086\n",
      "trial: 8, epoch, 7, iter: 1, curr loss: 0.522040605545044, avg loss: 0.522040605545044\n",
      "trial: 8, epoch, 7, iter: 200, curr loss: 0.5243116617202759, avg loss: 0.5234304666519165\n",
      "trial: 8, epoch, 8, iter: 1, curr loss: 0.5209919810295105, avg loss: 0.5209919810295105\n",
      "trial: 8, epoch, 8, iter: 200, curr loss: 0.5216116905212402, avg loss: 0.5235910284519195\n",
      "trial: 8, epoch, 9, iter: 1, curr loss: 0.5223772525787354, avg loss: 0.5223772525787354\n",
      "trial: 8, epoch, 9, iter: 200, curr loss: 0.5280295014381409, avg loss: 0.5239574593305588\n",
      "trial: 8, epoch, 10, iter: 1, curr loss: 0.5256757736206055, avg loss: 0.5256757736206055\n",
      "trial: 8, epoch, 10, iter: 200, curr loss: 0.5194052457809448, avg loss: 0.523174948990345\n",
      "trial: 8, epoch, 11, iter: 1, curr loss: 0.5283864736557007, avg loss: 0.5283864736557007\n",
      "trial: 8, epoch, 11, iter: 200, curr loss: 0.5315475463867188, avg loss: 0.5236125734448432\n",
      "trial: 8, epoch, 12, iter: 1, curr loss: 0.5274855494499207, avg loss: 0.5274855494499207\n",
      "trial: 8, epoch, 12, iter: 200, curr loss: 0.524825930595398, avg loss: 0.5232288089394569\n",
      "trial: 8, epoch, 13, iter: 1, curr loss: 0.5138634443283081, avg loss: 0.5138634443283081\n",
      "trial: 8, epoch, 13, iter: 200, curr loss: 0.5272756218910217, avg loss: 0.5231491926312447\n",
      "trial: 8, epoch, 14, iter: 1, curr loss: 0.5339822173118591, avg loss: 0.5339822173118591\n",
      "trial: 8, epoch, 14, iter: 200, curr loss: 0.5278058052062988, avg loss: 0.5234838509559632\n",
      "trial: 8, epoch, 15, iter: 1, curr loss: 0.5252177119255066, avg loss: 0.5252177119255066\n",
      "trial: 8, epoch, 15, iter: 200, curr loss: 0.5314489603042603, avg loss: 0.5228749987483025\n",
      "trial: 8, epoch, 16, iter: 1, curr loss: 0.5209493041038513, avg loss: 0.5209493041038513\n",
      "trial: 8, epoch, 16, iter: 200, curr loss: 0.5215104818344116, avg loss: 0.5233215337991715\n",
      "trial: 8, epoch, 17, iter: 1, curr loss: 0.5209558606147766, avg loss: 0.5209558606147766\n",
      "trial: 8, epoch, 17, iter: 200, curr loss: 0.5340660810470581, avg loss: 0.5233097901940346\n",
      "trial: 8, epoch, 18, iter: 1, curr loss: 0.5184512734413147, avg loss: 0.5184512734413147\n",
      "trial: 8, epoch, 18, iter: 200, curr loss: 0.5158014893531799, avg loss: 0.523376250565052\n",
      "trial: 8, epoch, 19, iter: 1, curr loss: 0.5294572114944458, avg loss: 0.5294572114944458\n",
      "trial: 8, epoch, 19, iter: 200, curr loss: 0.5180226564407349, avg loss: 0.5235328158736229\n",
      "trial: 8, epoch, 20, iter: 1, curr loss: 0.5339273810386658, avg loss: 0.5339273810386658\n",
      "trial: 8, epoch, 20, iter: 200, curr loss: 0.5211564302444458, avg loss: 0.5231843027472496\n",
      "trial: 8, epoch, 21, iter: 1, curr loss: 0.5286388993263245, avg loss: 0.5286388993263245\n",
      "trial: 8, epoch, 21, iter: 200, curr loss: 0.5273178815841675, avg loss: 0.5230301931500435\n",
      "trial: 8, epoch, 22, iter: 1, curr loss: 0.5305351614952087, avg loss: 0.5305351614952087\n",
      "trial: 8, epoch, 22, iter: 200, curr loss: 0.5194417238235474, avg loss: 0.5237659418582916\n",
      "trial: 8, epoch, 23, iter: 1, curr loss: 0.5211458206176758, avg loss: 0.5211458206176758\n",
      "trial: 8, epoch, 23, iter: 200, curr loss: 0.5220704078674316, avg loss: 0.5234265425801277\n",
      "trial: 8, epoch, 24, iter: 1, curr loss: 0.5279110074043274, avg loss: 0.5279110074043274\n",
      "trial: 8, epoch, 24, iter: 200, curr loss: 0.5199114084243774, avg loss: 0.5232278504967689\n",
      "trial: 8, epoch, 25, iter: 1, curr loss: 0.5216666460037231, avg loss: 0.5216666460037231\n",
      "trial: 8, epoch, 25, iter: 200, curr loss: 0.5120556354522705, avg loss: 0.5234855717420578\n",
      "trial: 8, epoch, 26, iter: 1, curr loss: 0.5141065120697021, avg loss: 0.5141065120697021\n",
      "trial: 8, epoch, 26, iter: 200, curr loss: 0.5127112865447998, avg loss: 0.5227901691198349\n",
      "trial: 8, epoch, 27, iter: 1, curr loss: 0.5214983224868774, avg loss: 0.5214983224868774\n",
      "trial: 8, epoch, 27, iter: 200, curr loss: 0.529839038848877, avg loss: 0.5228832021355629\n",
      "trial: 8, epoch, 28, iter: 1, curr loss: 0.5371417999267578, avg loss: 0.5371417999267578\n",
      "trial: 8, epoch, 28, iter: 200, curr loss: 0.5233436822891235, avg loss: 0.5235304215550423\n",
      "trial: 8, epoch, 29, iter: 1, curr loss: 0.5145014524459839, avg loss: 0.5145014524459839\n",
      "trial: 8, epoch, 29, iter: 200, curr loss: 0.5177823305130005, avg loss: 0.5233173963427543\n",
      "trial: 8, epoch, 30, iter: 1, curr loss: 0.5291516184806824, avg loss: 0.5291516184806824\n",
      "trial: 8, epoch, 30, iter: 200, curr loss: 0.5262219309806824, avg loss: 0.5235395804047585\n",
      "trial: 8, epoch, 31, iter: 1, curr loss: 0.5271766185760498, avg loss: 0.5271766185760498\n",
      "trial: 8, epoch, 31, iter: 200, curr loss: 0.5228880643844604, avg loss: 0.5230650264024734\n",
      "trial: 8, epoch, 32, iter: 1, curr loss: 0.5239309072494507, avg loss: 0.5239309072494507\n",
      "trial: 8, epoch, 32, iter: 200, curr loss: 0.5199888348579407, avg loss: 0.5235738363862038\n",
      "trial: 8, epoch, 33, iter: 1, curr loss: 0.5204960107803345, avg loss: 0.5204960107803345\n",
      "trial: 8, epoch, 33, iter: 200, curr loss: 0.5264760255813599, avg loss: 0.5232715782523155\n",
      "trial: 8, epoch, 34, iter: 1, curr loss: 0.522853672504425, avg loss: 0.522853672504425\n",
      "trial: 8, epoch, 34, iter: 200, curr loss: 0.5194381475448608, avg loss: 0.5232232564687729\n",
      "trial: 8, epoch, 35, iter: 1, curr loss: 0.5232443809509277, avg loss: 0.5232443809509277\n",
      "trial: 8, epoch, 35, iter: 200, curr loss: 0.5249239206314087, avg loss: 0.522916396856308\n",
      "trial: 8, epoch, 36, iter: 1, curr loss: 0.5263361930847168, avg loss: 0.5263361930847168\n",
      "trial: 8, epoch, 36, iter: 200, curr loss: 0.5308641195297241, avg loss: 0.5232094851136208\n",
      "trial: 8, epoch, 37, iter: 1, curr loss: 0.5278728604316711, avg loss: 0.5278728604316711\n",
      "trial: 8, epoch, 37, iter: 200, curr loss: 0.5216973423957825, avg loss: 0.5231983837485313\n",
      "trial: 8, epoch, 38, iter: 1, curr loss: 0.5132647156715393, avg loss: 0.5132647156715393\n",
      "trial: 8, epoch, 38, iter: 200, curr loss: 0.5258787274360657, avg loss: 0.5228324055671691\n",
      "trial: 8, epoch, 39, iter: 1, curr loss: 0.5249715447425842, avg loss: 0.5249715447425842\n",
      "trial: 8, epoch, 39, iter: 200, curr loss: 0.5253726243972778, avg loss: 0.522847691476345\n",
      "trial: 8, epoch, 40, iter: 1, curr loss: 0.5316858291625977, avg loss: 0.5316858291625977\n",
      "trial: 8, epoch, 40, iter: 200, curr loss: 0.5201274156570435, avg loss: 0.5232046082615852\n",
      "trial: 8, epoch, 41, iter: 1, curr loss: 0.5250928401947021, avg loss: 0.5250928401947021\n",
      "trial: 8, epoch, 41, iter: 200, curr loss: 0.5298510789871216, avg loss: 0.5230115789175034\n",
      "trial: 8, epoch, 42, iter: 1, curr loss: 0.527173638343811, avg loss: 0.527173638343811\n",
      "trial: 8, epoch, 42, iter: 200, curr loss: 0.5329689979553223, avg loss: 0.5231133851408959\n",
      "trial: 8, epoch, 43, iter: 1, curr loss: 0.5270197987556458, avg loss: 0.5270197987556458\n",
      "trial: 8, epoch, 43, iter: 200, curr loss: 0.5213029384613037, avg loss: 0.522790659070015\n",
      "trial: 8, epoch, 44, iter: 1, curr loss: 0.5191188454627991, avg loss: 0.5191188454627991\n",
      "trial: 8, epoch, 44, iter: 200, curr loss: 0.5395487546920776, avg loss: 0.5232248738408088\n",
      "trial: 8, epoch, 45, iter: 1, curr loss: 0.5240134000778198, avg loss: 0.5240134000778198\n",
      "trial: 8, epoch, 45, iter: 200, curr loss: 0.5213642120361328, avg loss: 0.5228929325938225\n",
      "trial: 8, epoch, 46, iter: 1, curr loss: 0.5107365250587463, avg loss: 0.5107365250587463\n",
      "trial: 8, epoch, 46, iter: 200, curr loss: 0.525300145149231, avg loss: 0.5230118358135223\n",
      "trial: 8, epoch, 47, iter: 1, curr loss: 0.5151687860488892, avg loss: 0.5151687860488892\n",
      "trial: 8, epoch, 47, iter: 200, curr loss: 0.5192067623138428, avg loss: 0.5234236359596253\n",
      "trial: 8, epoch, 48, iter: 1, curr loss: 0.5185912847518921, avg loss: 0.5185912847518921\n",
      "trial: 8, epoch, 48, iter: 200, curr loss: 0.5313490629196167, avg loss: 0.5233010065555572\n",
      "trial: 8, epoch, 49, iter: 1, curr loss: 0.5263392925262451, avg loss: 0.5263392925262451\n",
      "trial: 8, epoch, 49, iter: 200, curr loss: 0.5318419933319092, avg loss: 0.5227602866291999\n",
      "trial: 8, epoch, 50, iter: 1, curr loss: 0.5268710851669312, avg loss: 0.5268710851669312\n",
      "trial: 8, epoch, 50, iter: 200, curr loss: 0.5311452150344849, avg loss: 0.5229716044664383\n",
      "trial: 8, ldr: 0.5672153234481812, dv: 0.5639793872833252, nwj: 0.563974142074585\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 9, epoch, 1, iter: 1, curr loss: 0.6936538219451904, avg loss: 0.6936538219451904\n",
      "trial: 9, epoch, 1, iter: 200, curr loss: 0.5134772658348083, avg loss: 0.5337801206111908\n",
      "trial: 9, epoch, 2, iter: 1, curr loss: 0.5317539572715759, avg loss: 0.5317539572715759\n",
      "trial: 9, epoch, 2, iter: 200, curr loss: 0.5275693535804749, avg loss: 0.5241465011239052\n",
      "trial: 9, epoch, 3, iter: 1, curr loss: 0.5262141227722168, avg loss: 0.5262141227722168\n",
      "trial: 9, epoch, 3, iter: 200, curr loss: 0.5314023494720459, avg loss: 0.5233179071545601\n",
      "trial: 9, epoch, 4, iter: 1, curr loss: 0.5152487754821777, avg loss: 0.5152487754821777\n",
      "trial: 9, epoch, 4, iter: 200, curr loss: 0.5242223143577576, avg loss: 0.5233809399604797\n",
      "trial: 9, epoch, 5, iter: 1, curr loss: 0.5277168154716492, avg loss: 0.5277168154716492\n",
      "trial: 9, epoch, 5, iter: 200, curr loss: 0.5221037864685059, avg loss: 0.5234698897600174\n",
      "trial: 9, epoch, 6, iter: 1, curr loss: 0.531699538230896, avg loss: 0.531699538230896\n",
      "trial: 9, epoch, 6, iter: 200, curr loss: 0.5247597694396973, avg loss: 0.5233735367655754\n",
      "trial: 9, epoch, 7, iter: 1, curr loss: 0.5228130221366882, avg loss: 0.5228130221366882\n",
      "trial: 9, epoch, 7, iter: 200, curr loss: 0.516480565071106, avg loss: 0.5228364500403404\n",
      "trial: 9, epoch, 8, iter: 1, curr loss: 0.5287517309188843, avg loss: 0.5287517309188843\n",
      "trial: 9, epoch, 8, iter: 200, curr loss: 0.5225675702095032, avg loss: 0.5238070341944695\n",
      "trial: 9, epoch, 9, iter: 1, curr loss: 0.5316457748413086, avg loss: 0.5316457748413086\n",
      "trial: 9, epoch, 9, iter: 200, curr loss: 0.5214866399765015, avg loss: 0.5235876455903054\n",
      "trial: 9, epoch, 10, iter: 1, curr loss: 0.5250754356384277, avg loss: 0.5250754356384277\n",
      "trial: 9, epoch, 10, iter: 200, curr loss: 0.5196037292480469, avg loss: 0.5231138104200364\n",
      "trial: 9, epoch, 11, iter: 1, curr loss: 0.5293489694595337, avg loss: 0.5293489694595337\n",
      "trial: 9, epoch, 11, iter: 200, curr loss: 0.5183635950088501, avg loss: 0.5237344947457313\n",
      "trial: 9, epoch, 12, iter: 1, curr loss: 0.5249987840652466, avg loss: 0.5249987840652466\n",
      "trial: 9, epoch, 12, iter: 200, curr loss: 0.5293728113174438, avg loss: 0.5229932820796966\n",
      "trial: 9, epoch, 13, iter: 1, curr loss: 0.5226579904556274, avg loss: 0.5226579904556274\n",
      "trial: 9, epoch, 13, iter: 200, curr loss: 0.521355152130127, avg loss: 0.5236474657058716\n",
      "trial: 9, epoch, 14, iter: 1, curr loss: 0.5248116254806519, avg loss: 0.5248116254806519\n",
      "trial: 9, epoch, 14, iter: 200, curr loss: 0.5179213285446167, avg loss: 0.5235603758692742\n",
      "trial: 9, epoch, 15, iter: 1, curr loss: 0.5275682210922241, avg loss: 0.5275682210922241\n",
      "trial: 9, epoch, 15, iter: 200, curr loss: 0.5227115750312805, avg loss: 0.523443052470684\n",
      "trial: 9, epoch, 16, iter: 1, curr loss: 0.524402379989624, avg loss: 0.524402379989624\n",
      "trial: 9, epoch, 16, iter: 200, curr loss: 0.5277978181838989, avg loss: 0.5230450761318207\n",
      "trial: 9, epoch, 17, iter: 1, curr loss: 0.5200134515762329, avg loss: 0.5200134515762329\n",
      "trial: 9, epoch, 17, iter: 200, curr loss: 0.5213029980659485, avg loss: 0.5230937707424164\n",
      "trial: 9, epoch, 18, iter: 1, curr loss: 0.5294004082679749, avg loss: 0.5294004082679749\n",
      "trial: 9, epoch, 18, iter: 200, curr loss: 0.5313639640808105, avg loss: 0.5233066925406455\n",
      "trial: 9, epoch, 19, iter: 1, curr loss: 0.5279128551483154, avg loss: 0.5279128551483154\n",
      "trial: 9, epoch, 19, iter: 200, curr loss: 0.5197954177856445, avg loss: 0.5233835524320603\n",
      "trial: 9, epoch, 20, iter: 1, curr loss: 0.5313140153884888, avg loss: 0.5313140153884888\n",
      "trial: 9, epoch, 20, iter: 200, curr loss: 0.5224798917770386, avg loss: 0.5231963035464287\n",
      "trial: 9, epoch, 21, iter: 1, curr loss: 0.5179922580718994, avg loss: 0.5179922580718994\n",
      "trial: 9, epoch, 21, iter: 200, curr loss: 0.5278432369232178, avg loss: 0.5234135723114014\n",
      "trial: 9, epoch, 22, iter: 1, curr loss: 0.5273780822753906, avg loss: 0.5273780822753906\n",
      "trial: 9, epoch, 22, iter: 200, curr loss: 0.5120011568069458, avg loss: 0.5232015162706375\n",
      "trial: 9, epoch, 23, iter: 1, curr loss: 0.5280355215072632, avg loss: 0.5280355215072632\n",
      "trial: 9, epoch, 23, iter: 200, curr loss: 0.5224016904830933, avg loss: 0.5230365195870399\n",
      "trial: 9, epoch, 24, iter: 1, curr loss: 0.520133376121521, avg loss: 0.520133376121521\n",
      "trial: 9, epoch, 24, iter: 200, curr loss: 0.5270090699195862, avg loss: 0.5239382350444793\n",
      "trial: 9, epoch, 25, iter: 1, curr loss: 0.5273717641830444, avg loss: 0.5273717641830444\n",
      "trial: 9, epoch, 25, iter: 200, curr loss: 0.5349334478378296, avg loss: 0.5233301049470902\n",
      "trial: 9, epoch, 26, iter: 1, curr loss: 0.5202760696411133, avg loss: 0.5202760696411133\n",
      "trial: 9, epoch, 26, iter: 200, curr loss: 0.5220199823379517, avg loss: 0.5230725175142288\n",
      "trial: 9, epoch, 27, iter: 1, curr loss: 0.5276790857315063, avg loss: 0.5276790857315063\n",
      "trial: 9, epoch, 27, iter: 200, curr loss: 0.5270631313323975, avg loss: 0.5234168544411659\n",
      "trial: 9, epoch, 28, iter: 1, curr loss: 0.5357666015625, avg loss: 0.5357666015625\n",
      "trial: 9, epoch, 28, iter: 200, curr loss: 0.5346252918243408, avg loss: 0.5231132832169533\n",
      "trial: 9, epoch, 29, iter: 1, curr loss: 0.528634250164032, avg loss: 0.528634250164032\n",
      "trial: 9, epoch, 29, iter: 200, curr loss: 0.5189276337623596, avg loss: 0.5235654813051224\n",
      "trial: 9, epoch, 30, iter: 1, curr loss: 0.5293577909469604, avg loss: 0.5293577909469604\n",
      "trial: 9, epoch, 30, iter: 200, curr loss: 0.5227553248405457, avg loss: 0.5233714404702187\n",
      "trial: 9, epoch, 31, iter: 1, curr loss: 0.5173278450965881, avg loss: 0.5173278450965881\n",
      "trial: 9, epoch, 31, iter: 200, curr loss: 0.5216476917266846, avg loss: 0.523644288778305\n",
      "trial: 9, epoch, 32, iter: 1, curr loss: 0.5294474363327026, avg loss: 0.5294474363327026\n",
      "trial: 9, epoch, 32, iter: 200, curr loss: 0.5383429527282715, avg loss: 0.5232249718904495\n",
      "trial: 9, epoch, 33, iter: 1, curr loss: 0.5232974290847778, avg loss: 0.5232974290847778\n",
      "trial: 9, epoch, 33, iter: 200, curr loss: 0.5296947360038757, avg loss: 0.5228235310316086\n",
      "trial: 9, epoch, 34, iter: 1, curr loss: 0.5260409712791443, avg loss: 0.5260409712791443\n",
      "trial: 9, epoch, 34, iter: 200, curr loss: 0.5397613048553467, avg loss: 0.5231328457593918\n",
      "trial: 9, epoch, 35, iter: 1, curr loss: 0.5277634263038635, avg loss: 0.5277634263038635\n",
      "trial: 9, epoch, 35, iter: 200, curr loss: 0.5202317237854004, avg loss: 0.5232262852787971\n",
      "trial: 9, epoch, 36, iter: 1, curr loss: 0.5224374532699585, avg loss: 0.5224374532699585\n",
      "trial: 9, epoch, 36, iter: 200, curr loss: 0.529059886932373, avg loss: 0.5236775296926498\n",
      "trial: 9, epoch, 37, iter: 1, curr loss: 0.5338872671127319, avg loss: 0.5338872671127319\n",
      "trial: 9, epoch, 37, iter: 200, curr loss: 0.5306980609893799, avg loss: 0.5236677595973015\n",
      "trial: 9, epoch, 38, iter: 1, curr loss: 0.5203045606613159, avg loss: 0.5203045606613159\n",
      "trial: 9, epoch, 38, iter: 200, curr loss: 0.5202077031135559, avg loss: 0.5232273644208908\n",
      "trial: 9, epoch, 39, iter: 1, curr loss: 0.5250572562217712, avg loss: 0.5250572562217712\n",
      "trial: 9, epoch, 39, iter: 200, curr loss: 0.5301451683044434, avg loss: 0.5230560874938965\n",
      "trial: 9, epoch, 40, iter: 1, curr loss: 0.529932975769043, avg loss: 0.529932975769043\n",
      "trial: 9, epoch, 40, iter: 200, curr loss: 0.5286222100257874, avg loss: 0.5232142132520675\n",
      "trial: 9, epoch, 41, iter: 1, curr loss: 0.531246542930603, avg loss: 0.531246542930603\n",
      "trial: 9, epoch, 41, iter: 200, curr loss: 0.5260275602340698, avg loss: 0.5231714576482773\n",
      "trial: 9, epoch, 42, iter: 1, curr loss: 0.5303571224212646, avg loss: 0.5303571224212646\n",
      "trial: 9, epoch, 42, iter: 200, curr loss: 0.5330618619918823, avg loss: 0.5236466670036316\n",
      "trial: 9, epoch, 43, iter: 1, curr loss: 0.5286294221878052, avg loss: 0.5286294221878052\n",
      "trial: 9, epoch, 43, iter: 200, curr loss: 0.5256691575050354, avg loss: 0.523695344030857\n",
      "trial: 9, epoch, 44, iter: 1, curr loss: 0.5268025398254395, avg loss: 0.5268025398254395\n",
      "trial: 9, epoch, 44, iter: 200, curr loss: 0.5381523370742798, avg loss: 0.5228517460823059\n",
      "trial: 9, epoch, 45, iter: 1, curr loss: 0.523469090461731, avg loss: 0.523469090461731\n",
      "trial: 9, epoch, 45, iter: 200, curr loss: 0.5222969055175781, avg loss: 0.5232314789295196\n",
      "trial: 9, epoch, 46, iter: 1, curr loss: 0.5297218561172485, avg loss: 0.5297218561172485\n",
      "trial: 9, epoch, 46, iter: 200, curr loss: 0.5286818146705627, avg loss: 0.5233196133375168\n",
      "trial: 9, epoch, 47, iter: 1, curr loss: 0.516514778137207, avg loss: 0.516514778137207\n",
      "trial: 9, epoch, 47, iter: 200, curr loss: 0.5288074016571045, avg loss: 0.523422209918499\n",
      "trial: 9, epoch, 48, iter: 1, curr loss: 0.5196901559829712, avg loss: 0.5196901559829712\n",
      "trial: 9, epoch, 48, iter: 200, curr loss: 0.5253750085830688, avg loss: 0.5228670418262482\n",
      "trial: 9, epoch, 49, iter: 1, curr loss: 0.5245935320854187, avg loss: 0.5245935320854187\n",
      "trial: 9, epoch, 49, iter: 200, curr loss: 0.5310535430908203, avg loss: 0.5233723571896554\n",
      "trial: 9, epoch, 50, iter: 1, curr loss: 0.5238078236579895, avg loss: 0.5238078236579895\n",
      "trial: 9, epoch, 50, iter: 200, curr loss: 0.5322535037994385, avg loss: 0.5232590043544769\n",
      "trial: 9, ldr: 0.5685842037200928, dv: 0.563981294631958, nwj: 0.563970685005188\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 10, epoch, 1, iter: 1, curr loss: 0.6944998502731323, avg loss: 0.6944998502731323\n",
      "trial: 10, epoch, 1, iter: 200, curr loss: 0.530297040939331, avg loss: 0.5348043715953827\n",
      "trial: 10, epoch, 2, iter: 1, curr loss: 0.5277100801467896, avg loss: 0.5277100801467896\n",
      "trial: 10, epoch, 2, iter: 200, curr loss: 0.5253068804740906, avg loss: 0.5237105855345726\n",
      "trial: 10, epoch, 3, iter: 1, curr loss: 0.5340532064437866, avg loss: 0.5340532064437866\n",
      "trial: 10, epoch, 3, iter: 200, curr loss: 0.5208451151847839, avg loss: 0.5237481841444969\n",
      "trial: 10, epoch, 4, iter: 1, curr loss: 0.5217458605766296, avg loss: 0.5217458605766296\n",
      "trial: 10, epoch, 4, iter: 200, curr loss: 0.5327386856079102, avg loss: 0.5236564382910729\n",
      "trial: 10, epoch, 5, iter: 1, curr loss: 0.5300806164741516, avg loss: 0.5300806164741516\n",
      "trial: 10, epoch, 5, iter: 200, curr loss: 0.5313503742218018, avg loss: 0.5231526315212249\n",
      "trial: 10, epoch, 6, iter: 1, curr loss: 0.5292237997055054, avg loss: 0.5292237997055054\n",
      "trial: 10, epoch, 6, iter: 200, curr loss: 0.5189083814620972, avg loss: 0.5230885076522828\n",
      "trial: 10, epoch, 7, iter: 1, curr loss: 0.5259483456611633, avg loss: 0.5259483456611633\n",
      "trial: 10, epoch, 7, iter: 200, curr loss: 0.5305091142654419, avg loss: 0.5236613097786903\n",
      "trial: 10, epoch, 8, iter: 1, curr loss: 0.5235176086425781, avg loss: 0.5235176086425781\n",
      "trial: 10, epoch, 8, iter: 200, curr loss: 0.5326306223869324, avg loss: 0.5232026547193527\n",
      "trial: 10, epoch, 9, iter: 1, curr loss: 0.5236080288887024, avg loss: 0.5236080288887024\n",
      "trial: 10, epoch, 9, iter: 200, curr loss: 0.5238676071166992, avg loss: 0.5234897574782371\n",
      "trial: 10, epoch, 10, iter: 1, curr loss: 0.5206735134124756, avg loss: 0.5206735134124756\n",
      "trial: 10, epoch, 10, iter: 200, curr loss: 0.5247476100921631, avg loss: 0.5235573962330818\n",
      "trial: 10, epoch, 11, iter: 1, curr loss: 0.5222136378288269, avg loss: 0.5222136378288269\n",
      "trial: 10, epoch, 11, iter: 200, curr loss: 0.5251254439353943, avg loss: 0.5237241324782371\n",
      "trial: 10, epoch, 12, iter: 1, curr loss: 0.5235235691070557, avg loss: 0.5235235691070557\n",
      "trial: 10, epoch, 12, iter: 200, curr loss: 0.5279267430305481, avg loss: 0.5232206183671951\n",
      "trial: 10, epoch, 13, iter: 1, curr loss: 0.5165724754333496, avg loss: 0.5165724754333496\n",
      "trial: 10, epoch, 13, iter: 200, curr loss: 0.5336493849754333, avg loss: 0.5237660336494446\n",
      "trial: 10, epoch, 14, iter: 1, curr loss: 0.5241066217422485, avg loss: 0.5241066217422485\n",
      "trial: 10, epoch, 14, iter: 200, curr loss: 0.5187891721725464, avg loss: 0.523422110080719\n",
      "trial: 10, epoch, 15, iter: 1, curr loss: 0.5297107696533203, avg loss: 0.5297107696533203\n",
      "trial: 10, epoch, 15, iter: 200, curr loss: 0.5328149795532227, avg loss: 0.5237911698222161\n",
      "trial: 10, epoch, 16, iter: 1, curr loss: 0.5189575552940369, avg loss: 0.5189575552940369\n",
      "trial: 10, epoch, 16, iter: 200, curr loss: 0.5254329442977905, avg loss: 0.5231244498491288\n",
      "trial: 10, epoch, 17, iter: 1, curr loss: 0.5245048999786377, avg loss: 0.5245048999786377\n",
      "trial: 10, epoch, 17, iter: 200, curr loss: 0.5286831855773926, avg loss: 0.523308416903019\n",
      "trial: 10, epoch, 18, iter: 1, curr loss: 0.5242630243301392, avg loss: 0.5242630243301392\n",
      "trial: 10, epoch, 18, iter: 200, curr loss: 0.5349404215812683, avg loss: 0.5233253011107445\n",
      "trial: 10, epoch, 19, iter: 1, curr loss: 0.5175163745880127, avg loss: 0.5175163745880127\n",
      "trial: 10, epoch, 19, iter: 200, curr loss: 0.524526059627533, avg loss: 0.5233931878209114\n",
      "trial: 10, epoch, 20, iter: 1, curr loss: 0.5269701480865479, avg loss: 0.5269701480865479\n",
      "trial: 10, epoch, 20, iter: 200, curr loss: 0.5140866637229919, avg loss: 0.5230169755220413\n",
      "trial: 10, epoch, 21, iter: 1, curr loss: 0.518683910369873, avg loss: 0.518683910369873\n",
      "trial: 10, epoch, 21, iter: 200, curr loss: 0.5172858238220215, avg loss: 0.5228127625584602\n",
      "trial: 10, epoch, 22, iter: 1, curr loss: 0.5233428478240967, avg loss: 0.5233428478240967\n",
      "trial: 10, epoch, 22, iter: 200, curr loss: 0.5208727121353149, avg loss: 0.5234710735082626\n",
      "trial: 10, epoch, 23, iter: 1, curr loss: 0.5297582149505615, avg loss: 0.5297582149505615\n",
      "trial: 10, epoch, 23, iter: 200, curr loss: 0.5366547107696533, avg loss: 0.5233967280387879\n",
      "trial: 10, epoch, 24, iter: 1, curr loss: 0.5266938805580139, avg loss: 0.5266938805580139\n",
      "trial: 10, epoch, 24, iter: 200, curr loss: 0.5387799739837646, avg loss: 0.5232413226366043\n",
      "trial: 10, epoch, 25, iter: 1, curr loss: 0.512873649597168, avg loss: 0.512873649597168\n",
      "trial: 10, epoch, 25, iter: 200, curr loss: 0.5222986936569214, avg loss: 0.5236276653409004\n",
      "trial: 10, epoch, 26, iter: 1, curr loss: 0.5329995155334473, avg loss: 0.5329995155334473\n",
      "trial: 10, epoch, 26, iter: 200, curr loss: 0.5393019318580627, avg loss: 0.5231378495693206\n",
      "trial: 10, epoch, 27, iter: 1, curr loss: 0.5247786641120911, avg loss: 0.5247786641120911\n",
      "trial: 10, epoch, 27, iter: 200, curr loss: 0.5265350937843323, avg loss: 0.5236355683207512\n",
      "trial: 10, epoch, 28, iter: 1, curr loss: 0.5231349468231201, avg loss: 0.5231349468231201\n",
      "trial: 10, epoch, 28, iter: 200, curr loss: 0.5184199810028076, avg loss: 0.5231240421533585\n",
      "trial: 10, epoch, 29, iter: 1, curr loss: 0.518303394317627, avg loss: 0.518303394317627\n",
      "trial: 10, epoch, 29, iter: 200, curr loss: 0.5325109958648682, avg loss: 0.523443055152893\n",
      "trial: 10, epoch, 30, iter: 1, curr loss: 0.5351999998092651, avg loss: 0.5351999998092651\n",
      "trial: 10, epoch, 30, iter: 200, curr loss: 0.5210255980491638, avg loss: 0.5235048270225525\n",
      "trial: 10, epoch, 31, iter: 1, curr loss: 0.5248423218727112, avg loss: 0.5248423218727112\n",
      "trial: 10, epoch, 31, iter: 200, curr loss: 0.5161055326461792, avg loss: 0.5227159261703491\n",
      "trial: 10, epoch, 32, iter: 1, curr loss: 0.5180791616439819, avg loss: 0.5180791616439819\n",
      "trial: 10, epoch, 32, iter: 200, curr loss: 0.5332366228103638, avg loss: 0.5235992449522019\n",
      "trial: 10, epoch, 33, iter: 1, curr loss: 0.5286555290222168, avg loss: 0.5286555290222168\n",
      "trial: 10, epoch, 33, iter: 200, curr loss: 0.5369988679885864, avg loss: 0.5228746542334557\n",
      "trial: 10, epoch, 34, iter: 1, curr loss: 0.5249656438827515, avg loss: 0.5249656438827515\n",
      "trial: 10, epoch, 34, iter: 200, curr loss: 0.5324633121490479, avg loss: 0.523577838242054\n",
      "trial: 10, epoch, 35, iter: 1, curr loss: 0.530481219291687, avg loss: 0.530481219291687\n",
      "trial: 10, epoch, 35, iter: 200, curr loss: 0.5244311094284058, avg loss: 0.5228518098592758\n",
      "trial: 10, epoch, 36, iter: 1, curr loss: 0.5315065383911133, avg loss: 0.5315065383911133\n",
      "trial: 10, epoch, 36, iter: 200, curr loss: 0.5245794057846069, avg loss: 0.5231622773408889\n",
      "trial: 10, epoch, 37, iter: 1, curr loss: 0.5345694422721863, avg loss: 0.5345694422721863\n",
      "trial: 10, epoch, 37, iter: 200, curr loss: 0.5331494808197021, avg loss: 0.5231469184160232\n",
      "trial: 10, epoch, 38, iter: 1, curr loss: 0.5332177877426147, avg loss: 0.5332177877426147\n",
      "trial: 10, epoch, 38, iter: 200, curr loss: 0.5334159135818481, avg loss: 0.5235748395323754\n",
      "trial: 10, epoch, 39, iter: 1, curr loss: 0.5299792885780334, avg loss: 0.5299792885780334\n",
      "trial: 10, epoch, 39, iter: 200, curr loss: 0.5234278440475464, avg loss: 0.5233490240573883\n",
      "trial: 10, epoch, 40, iter: 1, curr loss: 0.5253859758377075, avg loss: 0.5253859758377075\n",
      "trial: 10, epoch, 40, iter: 200, curr loss: 0.5300893187522888, avg loss: 0.5228752946853638\n",
      "trial: 10, epoch, 41, iter: 1, curr loss: 0.5364609956741333, avg loss: 0.5364609956741333\n",
      "trial: 10, epoch, 41, iter: 200, curr loss: 0.5289225578308105, avg loss: 0.5230715775489807\n",
      "trial: 10, epoch, 42, iter: 1, curr loss: 0.5342522859573364, avg loss: 0.5342522859573364\n",
      "trial: 10, epoch, 42, iter: 200, curr loss: 0.5130081176757812, avg loss: 0.5231541687250137\n",
      "trial: 10, epoch, 43, iter: 1, curr loss: 0.5211798548698425, avg loss: 0.5211798548698425\n",
      "trial: 10, epoch, 43, iter: 200, curr loss: 0.5249519944190979, avg loss: 0.5237942165136338\n",
      "trial: 10, epoch, 44, iter: 1, curr loss: 0.5210627317428589, avg loss: 0.5210627317428589\n",
      "trial: 10, epoch, 44, iter: 200, curr loss: 0.5287573337554932, avg loss: 0.5236172267794609\n",
      "trial: 10, epoch, 45, iter: 1, curr loss: 0.5162057280540466, avg loss: 0.5162057280540466\n",
      "trial: 10, epoch, 45, iter: 200, curr loss: 0.5299673080444336, avg loss: 0.5235242545604706\n",
      "trial: 10, epoch, 46, iter: 1, curr loss: 0.5265786647796631, avg loss: 0.5265786647796631\n",
      "trial: 10, epoch, 46, iter: 200, curr loss: 0.5279892683029175, avg loss: 0.5236622849106789\n",
      "trial: 10, epoch, 47, iter: 1, curr loss: 0.5280819535255432, avg loss: 0.5280819535255432\n",
      "trial: 10, epoch, 47, iter: 200, curr loss: 0.5308910012245178, avg loss: 0.5231728613376617\n",
      "trial: 10, epoch, 48, iter: 1, curr loss: 0.527039110660553, avg loss: 0.527039110660553\n",
      "trial: 10, epoch, 48, iter: 200, curr loss: 0.5291366577148438, avg loss: 0.5236677235364914\n",
      "trial: 10, epoch, 49, iter: 1, curr loss: 0.5281317830085754, avg loss: 0.5281317830085754\n",
      "trial: 10, epoch, 49, iter: 200, curr loss: 0.527489423751831, avg loss: 0.5228929662704468\n",
      "trial: 10, epoch, 50, iter: 1, curr loss: 0.5208494663238525, avg loss: 0.5208494663238525\n",
      "trial: 10, epoch, 50, iter: 200, curr loss: 0.5186465978622437, avg loss: 0.5234049627184868\n",
      "trial: 10, ldr: 0.5726993083953857, dv: 0.5639764070510864, nwj: 0.5639382600784302\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 11, epoch, 1, iter: 1, curr loss: 0.6930529475212097, avg loss: 0.6930529475212097\n",
      "trial: 11, epoch, 1, iter: 200, curr loss: 0.5361603498458862, avg loss: 0.5337851527333259\n",
      "trial: 11, epoch, 2, iter: 1, curr loss: 0.5271069407463074, avg loss: 0.5271069407463074\n",
      "trial: 11, epoch, 2, iter: 200, curr loss: 0.5240143537521362, avg loss: 0.5240879353880882\n",
      "trial: 11, epoch, 3, iter: 1, curr loss: 0.5248360633850098, avg loss: 0.5248360633850098\n",
      "trial: 11, epoch, 3, iter: 200, curr loss: 0.5272465944290161, avg loss: 0.5236391887068749\n",
      "trial: 11, epoch, 4, iter: 1, curr loss: 0.5271981954574585, avg loss: 0.5271981954574585\n",
      "trial: 11, epoch, 4, iter: 200, curr loss: 0.5297069549560547, avg loss: 0.5236985325813294\n",
      "trial: 11, epoch, 5, iter: 1, curr loss: 0.5263776183128357, avg loss: 0.5263776183128357\n",
      "trial: 11, epoch, 5, iter: 200, curr loss: 0.5347102284431458, avg loss: 0.5229694521427155\n",
      "trial: 11, epoch, 6, iter: 1, curr loss: 0.5316585898399353, avg loss: 0.5316585898399353\n",
      "trial: 11, epoch, 6, iter: 200, curr loss: 0.5329477190971375, avg loss: 0.5234735396504402\n",
      "trial: 11, epoch, 7, iter: 1, curr loss: 0.5321506261825562, avg loss: 0.5321506261825562\n",
      "trial: 11, epoch, 7, iter: 200, curr loss: 0.5346004962921143, avg loss: 0.5235443192720414\n",
      "trial: 11, epoch, 8, iter: 1, curr loss: 0.525375247001648, avg loss: 0.525375247001648\n",
      "trial: 11, epoch, 8, iter: 200, curr loss: 0.524840772151947, avg loss: 0.5239465165138245\n",
      "trial: 11, epoch, 9, iter: 1, curr loss: 0.5248786211013794, avg loss: 0.5248786211013794\n",
      "trial: 11, epoch, 9, iter: 200, curr loss: 0.5298364162445068, avg loss: 0.5235199180245399\n",
      "trial: 11, epoch, 10, iter: 1, curr loss: 0.5214359164237976, avg loss: 0.5214359164237976\n",
      "trial: 11, epoch, 10, iter: 200, curr loss: 0.5360943078994751, avg loss: 0.5232274472713471\n",
      "trial: 11, epoch, 11, iter: 1, curr loss: 0.5174994468688965, avg loss: 0.5174994468688965\n",
      "trial: 11, epoch, 11, iter: 200, curr loss: 0.522790253162384, avg loss: 0.5234445956349373\n",
      "trial: 11, epoch, 12, iter: 1, curr loss: 0.5271468758583069, avg loss: 0.5271468758583069\n",
      "trial: 11, epoch, 12, iter: 200, curr loss: 0.5282070636749268, avg loss: 0.5233377653360367\n",
      "trial: 11, epoch, 13, iter: 1, curr loss: 0.5273319482803345, avg loss: 0.5273319482803345\n",
      "trial: 11, epoch, 13, iter: 200, curr loss: 0.5356174111366272, avg loss: 0.5233405861258507\n",
      "trial: 11, epoch, 14, iter: 1, curr loss: 0.5219993591308594, avg loss: 0.5219993591308594\n",
      "trial: 11, epoch, 14, iter: 200, curr loss: 0.5176028609275818, avg loss: 0.5233064648509026\n",
      "trial: 11, epoch, 15, iter: 1, curr loss: 0.5253485441207886, avg loss: 0.5253485441207886\n",
      "trial: 11, epoch, 15, iter: 200, curr loss: 0.5267480611801147, avg loss: 0.5229629781842232\n",
      "trial: 11, epoch, 16, iter: 1, curr loss: 0.5227541923522949, avg loss: 0.5227541923522949\n",
      "trial: 11, epoch, 16, iter: 200, curr loss: 0.5278325080871582, avg loss: 0.523292820751667\n",
      "trial: 11, epoch, 17, iter: 1, curr loss: 0.5226171612739563, avg loss: 0.5226171612739563\n",
      "trial: 11, epoch, 17, iter: 200, curr loss: 0.5180455446243286, avg loss: 0.5232481163740158\n",
      "trial: 11, epoch, 18, iter: 1, curr loss: 0.5333836078643799, avg loss: 0.5333836078643799\n",
      "trial: 11, epoch, 18, iter: 200, curr loss: 0.5245166420936584, avg loss: 0.5238459771871566\n",
      "trial: 11, epoch, 19, iter: 1, curr loss: 0.5237296223640442, avg loss: 0.5237296223640442\n",
      "trial: 11, epoch, 19, iter: 200, curr loss: 0.5290107727050781, avg loss: 0.52355543166399\n",
      "trial: 11, epoch, 20, iter: 1, curr loss: 0.5195925235748291, avg loss: 0.5195925235748291\n",
      "trial: 11, epoch, 20, iter: 200, curr loss: 0.5248473882675171, avg loss: 0.5236324647068977\n",
      "trial: 11, epoch, 21, iter: 1, curr loss: 0.5333268046379089, avg loss: 0.5333268046379089\n",
      "trial: 11, epoch, 21, iter: 200, curr loss: 0.5366361737251282, avg loss: 0.5233520784974098\n",
      "trial: 11, epoch, 22, iter: 1, curr loss: 0.5260095596313477, avg loss: 0.5260095596313477\n",
      "trial: 11, epoch, 22, iter: 200, curr loss: 0.5206114649772644, avg loss: 0.522849387228489\n",
      "trial: 11, epoch, 23, iter: 1, curr loss: 0.5284614562988281, avg loss: 0.5284614562988281\n",
      "trial: 11, epoch, 23, iter: 200, curr loss: 0.5181436538696289, avg loss: 0.523527309000492\n",
      "trial: 11, epoch, 24, iter: 1, curr loss: 0.5225237011909485, avg loss: 0.5225237011909485\n",
      "trial: 11, epoch, 24, iter: 200, curr loss: 0.5360782742500305, avg loss: 0.5229869177937507\n",
      "trial: 11, epoch, 25, iter: 1, curr loss: 0.5255687236785889, avg loss: 0.5255687236785889\n",
      "trial: 11, epoch, 25, iter: 200, curr loss: 0.5121109485626221, avg loss: 0.523174694776535\n",
      "trial: 11, epoch, 26, iter: 1, curr loss: 0.5272457003593445, avg loss: 0.5272457003593445\n",
      "trial: 11, epoch, 26, iter: 200, curr loss: 0.5233355760574341, avg loss: 0.5232022655010223\n",
      "trial: 11, epoch, 27, iter: 1, curr loss: 0.5359107255935669, avg loss: 0.5359107255935669\n",
      "trial: 11, epoch, 27, iter: 200, curr loss: 0.5259295701980591, avg loss: 0.5232282912731171\n",
      "trial: 11, epoch, 28, iter: 1, curr loss: 0.524075984954834, avg loss: 0.524075984954834\n",
      "trial: 11, epoch, 28, iter: 200, curr loss: 0.5263757109642029, avg loss: 0.5235948875546456\n",
      "trial: 11, epoch, 29, iter: 1, curr loss: 0.5324150323867798, avg loss: 0.5324150323867798\n",
      "trial: 11, epoch, 29, iter: 200, curr loss: 0.5196547508239746, avg loss: 0.5234904387593269\n",
      "trial: 11, epoch, 30, iter: 1, curr loss: 0.5316317081451416, avg loss: 0.5316317081451416\n",
      "trial: 11, epoch, 30, iter: 200, curr loss: 0.5218021273612976, avg loss: 0.5230162984132767\n",
      "trial: 11, epoch, 31, iter: 1, curr loss: 0.5207729935646057, avg loss: 0.5207729935646057\n",
      "trial: 11, epoch, 31, iter: 200, curr loss: 0.5227917432785034, avg loss: 0.523164128959179\n",
      "trial: 11, epoch, 32, iter: 1, curr loss: 0.5282524824142456, avg loss: 0.5282524824142456\n",
      "trial: 11, epoch, 32, iter: 200, curr loss: 0.5240528583526611, avg loss: 0.523652873635292\n",
      "trial: 11, epoch, 33, iter: 1, curr loss: 0.5378331542015076, avg loss: 0.5378331542015076\n",
      "trial: 11, epoch, 33, iter: 200, curr loss: 0.5315194725990295, avg loss: 0.5235157954692841\n",
      "trial: 11, epoch, 34, iter: 1, curr loss: 0.5307533740997314, avg loss: 0.5307533740997314\n",
      "trial: 11, epoch, 34, iter: 200, curr loss: 0.5146021842956543, avg loss: 0.5227082768082618\n",
      "trial: 11, epoch, 35, iter: 1, curr loss: 0.5267171859741211, avg loss: 0.5267171859741211\n",
      "trial: 11, epoch, 35, iter: 200, curr loss: 0.5225422978401184, avg loss: 0.5233167135715484\n",
      "trial: 11, epoch, 36, iter: 1, curr loss: 0.5264770984649658, avg loss: 0.5264770984649658\n",
      "trial: 11, epoch, 36, iter: 200, curr loss: 0.5190994739532471, avg loss: 0.5229516810178757\n",
      "trial: 11, epoch, 37, iter: 1, curr loss: 0.5282964706420898, avg loss: 0.5282964706420898\n",
      "trial: 11, epoch, 37, iter: 200, curr loss: 0.5233494639396667, avg loss: 0.5234258788824081\n",
      "trial: 11, epoch, 38, iter: 1, curr loss: 0.5317317247390747, avg loss: 0.5317317247390747\n",
      "trial: 11, epoch, 38, iter: 200, curr loss: 0.5330888032913208, avg loss: 0.5235497739911079\n",
      "trial: 11, epoch, 39, iter: 1, curr loss: 0.5072720646858215, avg loss: 0.5072720646858215\n",
      "trial: 11, epoch, 39, iter: 200, curr loss: 0.5275732278823853, avg loss: 0.5231809523701668\n",
      "trial: 11, epoch, 40, iter: 1, curr loss: 0.5281246304512024, avg loss: 0.5281246304512024\n",
      "trial: 11, epoch, 40, iter: 200, curr loss: 0.5278504490852356, avg loss: 0.5232628336548806\n",
      "trial: 11, epoch, 41, iter: 1, curr loss: 0.5233673453330994, avg loss: 0.5233673453330994\n",
      "trial: 11, epoch, 41, iter: 200, curr loss: 0.5291845798492432, avg loss: 0.523375717997551\n",
      "trial: 11, epoch, 42, iter: 1, curr loss: 0.5294872522354126, avg loss: 0.5294872522354126\n",
      "trial: 11, epoch, 42, iter: 200, curr loss: 0.5162719488143921, avg loss: 0.5232783427834511\n",
      "trial: 11, epoch, 43, iter: 1, curr loss: 0.5301809906959534, avg loss: 0.5301809906959534\n",
      "trial: 11, epoch, 43, iter: 200, curr loss: 0.5136721134185791, avg loss: 0.5227738913893699\n",
      "trial: 11, epoch, 44, iter: 1, curr loss: 0.5377607345581055, avg loss: 0.5377607345581055\n",
      "trial: 11, epoch, 44, iter: 200, curr loss: 0.5234709978103638, avg loss: 0.5228119331598282\n",
      "trial: 11, epoch, 45, iter: 1, curr loss: 0.51987624168396, avg loss: 0.51987624168396\n",
      "trial: 11, epoch, 45, iter: 200, curr loss: 0.5279943943023682, avg loss: 0.5234615015983581\n",
      "trial: 11, epoch, 46, iter: 1, curr loss: 0.5247736573219299, avg loss: 0.5247736573219299\n",
      "trial: 11, epoch, 46, iter: 200, curr loss: 0.5248070359230042, avg loss: 0.52335484623909\n",
      "trial: 11, epoch, 47, iter: 1, curr loss: 0.5266827344894409, avg loss: 0.5266827344894409\n",
      "trial: 11, epoch, 47, iter: 200, curr loss: 0.5133078098297119, avg loss: 0.5231053528189659\n",
      "trial: 11, epoch, 48, iter: 1, curr loss: 0.5202150344848633, avg loss: 0.5202150344848633\n",
      "trial: 11, epoch, 48, iter: 200, curr loss: 0.5285704135894775, avg loss: 0.5235717445611954\n",
      "trial: 11, epoch, 49, iter: 1, curr loss: 0.5310206413269043, avg loss: 0.5310206413269043\n",
      "trial: 11, epoch, 49, iter: 200, curr loss: 0.5266033411026001, avg loss: 0.5232106041908264\n",
      "trial: 11, epoch, 50, iter: 1, curr loss: 0.5273172855377197, avg loss: 0.5273172855377197\n",
      "trial: 11, epoch, 50, iter: 200, curr loss: 0.5169961452484131, avg loss: 0.5228634539246559\n",
      "trial: 11, ldr: 0.5785403251647949, dv: 0.5639115571975708, nwj: 0.563804030418396\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 12, epoch, 1, iter: 1, curr loss: 0.6940184235572815, avg loss: 0.6940184235572815\n",
      "trial: 12, epoch, 1, iter: 200, curr loss: 0.5207351446151733, avg loss: 0.5358770343661309\n",
      "trial: 12, epoch, 2, iter: 1, curr loss: 0.5337380170822144, avg loss: 0.5337380170822144\n",
      "trial: 12, epoch, 2, iter: 200, curr loss: 0.5221500992774963, avg loss: 0.5243102192878724\n",
      "trial: 12, epoch, 3, iter: 1, curr loss: 0.5178806781768799, avg loss: 0.5178806781768799\n",
      "trial: 12, epoch, 3, iter: 200, curr loss: 0.5326031446456909, avg loss: 0.524356444478035\n",
      "trial: 12, epoch, 4, iter: 1, curr loss: 0.5286471843719482, avg loss: 0.5286471843719482\n",
      "trial: 12, epoch, 4, iter: 200, curr loss: 0.5207586288452148, avg loss: 0.5233104240894317\n",
      "trial: 12, epoch, 5, iter: 1, curr loss: 0.5325796604156494, avg loss: 0.5325796604156494\n",
      "trial: 12, epoch, 5, iter: 200, curr loss: 0.5234972834587097, avg loss: 0.5236377039551735\n",
      "trial: 12, epoch, 6, iter: 1, curr loss: 0.5256130695343018, avg loss: 0.5256130695343018\n",
      "trial: 12, epoch, 6, iter: 200, curr loss: 0.5214369297027588, avg loss: 0.5234109267592431\n",
      "trial: 12, epoch, 7, iter: 1, curr loss: 0.5283390879631042, avg loss: 0.5283390879631042\n",
      "trial: 12, epoch, 7, iter: 200, curr loss: 0.5288118720054626, avg loss: 0.5232771822810173\n",
      "trial: 12, epoch, 8, iter: 1, curr loss: 0.5249096155166626, avg loss: 0.5249096155166626\n",
      "trial: 12, epoch, 8, iter: 200, curr loss: 0.5329651236534119, avg loss: 0.5231823179125786\n",
      "trial: 12, epoch, 9, iter: 1, curr loss: 0.5283605456352234, avg loss: 0.5283605456352234\n",
      "trial: 12, epoch, 9, iter: 200, curr loss: 0.528710663318634, avg loss: 0.5233489856123924\n",
      "trial: 12, epoch, 10, iter: 1, curr loss: 0.5189995765686035, avg loss: 0.5189995765686035\n",
      "trial: 12, epoch, 10, iter: 200, curr loss: 0.5275353193283081, avg loss: 0.5235541090369225\n",
      "trial: 12, epoch, 11, iter: 1, curr loss: 0.5166765451431274, avg loss: 0.5166765451431274\n",
      "trial: 12, epoch, 11, iter: 200, curr loss: 0.5244582891464233, avg loss: 0.5234961193799973\n",
      "trial: 12, epoch, 12, iter: 1, curr loss: 0.5294996500015259, avg loss: 0.5294996500015259\n",
      "trial: 12, epoch, 12, iter: 200, curr loss: 0.5214834809303284, avg loss: 0.5234236851334572\n",
      "trial: 12, epoch, 13, iter: 1, curr loss: 0.5264071226119995, avg loss: 0.5264071226119995\n",
      "trial: 12, epoch, 13, iter: 200, curr loss: 0.5201260447502136, avg loss: 0.5233951908349991\n",
      "trial: 12, epoch, 14, iter: 1, curr loss: 0.533960223197937, avg loss: 0.533960223197937\n",
      "trial: 12, epoch, 14, iter: 200, curr loss: 0.5261452794075012, avg loss: 0.5232624641060829\n",
      "trial: 12, epoch, 15, iter: 1, curr loss: 0.5320335030555725, avg loss: 0.5320335030555725\n",
      "trial: 12, epoch, 15, iter: 200, curr loss: 0.522375762462616, avg loss: 0.5232712385058403\n",
      "trial: 12, epoch, 16, iter: 1, curr loss: 0.5250614881515503, avg loss: 0.5250614881515503\n",
      "trial: 12, epoch, 16, iter: 200, curr loss: 0.5271844863891602, avg loss: 0.5232303872704506\n",
      "trial: 12, epoch, 17, iter: 1, curr loss: 0.5307058691978455, avg loss: 0.5307058691978455\n",
      "trial: 12, epoch, 17, iter: 200, curr loss: 0.5359487533569336, avg loss: 0.5228930833935738\n",
      "trial: 12, epoch, 18, iter: 1, curr loss: 0.5205872058868408, avg loss: 0.5205872058868408\n",
      "trial: 12, epoch, 18, iter: 200, curr loss: 0.521356463432312, avg loss: 0.5233931663632393\n",
      "trial: 12, epoch, 19, iter: 1, curr loss: 0.5337059497833252, avg loss: 0.5337059497833252\n",
      "trial: 12, epoch, 19, iter: 200, curr loss: 0.5223052501678467, avg loss: 0.5228810983896256\n",
      "trial: 12, epoch, 20, iter: 1, curr loss: 0.5241149663925171, avg loss: 0.5241149663925171\n",
      "trial: 12, epoch, 20, iter: 200, curr loss: 0.5321869254112244, avg loss: 0.524093354344368\n",
      "trial: 12, epoch, 21, iter: 1, curr loss: 0.5264464616775513, avg loss: 0.5264464616775513\n",
      "trial: 12, epoch, 21, iter: 200, curr loss: 0.527716338634491, avg loss: 0.5231785660982132\n",
      "trial: 12, epoch, 22, iter: 1, curr loss: 0.5289448499679565, avg loss: 0.5289448499679565\n",
      "trial: 12, epoch, 22, iter: 200, curr loss: 0.5253643989562988, avg loss: 0.5232817262411118\n",
      "trial: 12, epoch, 23, iter: 1, curr loss: 0.5252939462661743, avg loss: 0.5252939462661743\n",
      "trial: 12, epoch, 23, iter: 200, curr loss: 0.5213394165039062, avg loss: 0.5232257914543151\n",
      "trial: 12, epoch, 24, iter: 1, curr loss: 0.5222539305686951, avg loss: 0.5222539305686951\n",
      "trial: 12, epoch, 24, iter: 200, curr loss: 0.5176516175270081, avg loss: 0.5236782163381577\n",
      "trial: 12, epoch, 25, iter: 1, curr loss: 0.5257992744445801, avg loss: 0.5257992744445801\n",
      "trial: 12, epoch, 25, iter: 200, curr loss: 0.5182819366455078, avg loss: 0.5227476355433464\n",
      "trial: 12, epoch, 26, iter: 1, curr loss: 0.535770058631897, avg loss: 0.535770058631897\n",
      "trial: 12, epoch, 26, iter: 200, curr loss: 0.5248629450798035, avg loss: 0.5230346974730492\n",
      "trial: 12, epoch, 27, iter: 1, curr loss: 0.5359784960746765, avg loss: 0.5359784960746765\n",
      "trial: 12, epoch, 27, iter: 200, curr loss: 0.5327273607254028, avg loss: 0.5231197437644005\n",
      "trial: 12, epoch, 28, iter: 1, curr loss: 0.5261636972427368, avg loss: 0.5261636972427368\n",
      "trial: 12, epoch, 28, iter: 200, curr loss: 0.5192499160766602, avg loss: 0.5235572502017021\n",
      "trial: 12, epoch, 29, iter: 1, curr loss: 0.5203415155410767, avg loss: 0.5203415155410767\n",
      "trial: 12, epoch, 29, iter: 200, curr loss: 0.5208072662353516, avg loss: 0.5235460275411605\n",
      "trial: 12, epoch, 30, iter: 1, curr loss: 0.5289387702941895, avg loss: 0.5289387702941895\n",
      "trial: 12, epoch, 30, iter: 200, curr loss: 0.5332997441291809, avg loss: 0.5235725674033165\n",
      "trial: 12, epoch, 31, iter: 1, curr loss: 0.5366286039352417, avg loss: 0.5366286039352417\n",
      "trial: 12, epoch, 31, iter: 200, curr loss: 0.5285447239875793, avg loss: 0.5226734685897827\n",
      "trial: 12, epoch, 32, iter: 1, curr loss: 0.529515266418457, avg loss: 0.529515266418457\n",
      "trial: 12, epoch, 32, iter: 200, curr loss: 0.5219153165817261, avg loss: 0.5231125956773758\n",
      "trial: 12, epoch, 33, iter: 1, curr loss: 0.5212879180908203, avg loss: 0.5212879180908203\n",
      "trial: 12, epoch, 33, iter: 200, curr loss: 0.5279034972190857, avg loss: 0.52335284024477\n",
      "trial: 12, epoch, 34, iter: 1, curr loss: 0.5247320532798767, avg loss: 0.5247320532798767\n",
      "trial: 12, epoch, 34, iter: 200, curr loss: 0.5216246843338013, avg loss: 0.5229858240485191\n",
      "trial: 12, epoch, 35, iter: 1, curr loss: 0.5308787822723389, avg loss: 0.5308787822723389\n",
      "trial: 12, epoch, 35, iter: 200, curr loss: 0.5150323510169983, avg loss: 0.523895905315876\n",
      "trial: 12, epoch, 36, iter: 1, curr loss: 0.5341231822967529, avg loss: 0.5341231822967529\n",
      "trial: 12, epoch, 36, iter: 200, curr loss: 0.5225667953491211, avg loss: 0.5232136964797973\n",
      "trial: 12, epoch, 37, iter: 1, curr loss: 0.5251856446266174, avg loss: 0.5251856446266174\n",
      "trial: 12, epoch, 37, iter: 200, curr loss: 0.5370985865592957, avg loss: 0.5230770334601402\n",
      "trial: 12, epoch, 38, iter: 1, curr loss: 0.5257220268249512, avg loss: 0.5257220268249512\n",
      "trial: 12, epoch, 38, iter: 200, curr loss: 0.5141580104827881, avg loss: 0.5227067732810974\n",
      "trial: 12, epoch, 39, iter: 1, curr loss: 0.5289022922515869, avg loss: 0.5289022922515869\n",
      "trial: 12, epoch, 39, iter: 200, curr loss: 0.5259117484092712, avg loss: 0.5234014794230462\n",
      "trial: 12, epoch, 40, iter: 1, curr loss: 0.5278277397155762, avg loss: 0.5278277397155762\n",
      "trial: 12, epoch, 40, iter: 200, curr loss: 0.5186487436294556, avg loss: 0.5232292664051056\n",
      "trial: 12, epoch, 41, iter: 1, curr loss: 0.5285124182701111, avg loss: 0.5285124182701111\n",
      "trial: 12, epoch, 41, iter: 200, curr loss: 0.5292439460754395, avg loss: 0.5231300497055054\n",
      "trial: 12, epoch, 42, iter: 1, curr loss: 0.5276484489440918, avg loss: 0.5276484489440918\n",
      "trial: 12, epoch, 42, iter: 200, curr loss: 0.5277656316757202, avg loss: 0.5234924933314323\n",
      "trial: 12, epoch, 43, iter: 1, curr loss: 0.5273723602294922, avg loss: 0.5273723602294922\n",
      "trial: 12, epoch, 43, iter: 200, curr loss: 0.5245704650878906, avg loss: 0.5233557194471359\n",
      "trial: 12, epoch, 44, iter: 1, curr loss: 0.5297691226005554, avg loss: 0.5297691226005554\n",
      "trial: 12, epoch, 44, iter: 200, curr loss: 0.5281276106834412, avg loss: 0.5231999245285988\n",
      "trial: 12, epoch, 45, iter: 1, curr loss: 0.5217594504356384, avg loss: 0.5217594504356384\n",
      "trial: 12, epoch, 45, iter: 200, curr loss: 0.5285478830337524, avg loss: 0.5233063352108002\n",
      "trial: 12, epoch, 46, iter: 1, curr loss: 0.5309507846832275, avg loss: 0.5309507846832275\n",
      "trial: 12, epoch, 46, iter: 200, curr loss: 0.5271456241607666, avg loss: 0.5232603150606155\n",
      "trial: 12, epoch, 47, iter: 1, curr loss: 0.5318524837493896, avg loss: 0.5318524837493896\n",
      "trial: 12, epoch, 47, iter: 200, curr loss: 0.5215386152267456, avg loss: 0.5239064076542854\n",
      "trial: 12, epoch, 48, iter: 1, curr loss: 0.5167747139930725, avg loss: 0.5167747139930725\n",
      "trial: 12, epoch, 48, iter: 200, curr loss: 0.5267479419708252, avg loss: 0.5235227590799332\n",
      "trial: 12, epoch, 49, iter: 1, curr loss: 0.5294798016548157, avg loss: 0.5294798016548157\n",
      "trial: 12, epoch, 49, iter: 200, curr loss: 0.5290569067001343, avg loss: 0.5233616903424263\n",
      "trial: 12, epoch, 50, iter: 1, curr loss: 0.5304481983184814, avg loss: 0.5304481983184814\n",
      "trial: 12, epoch, 50, iter: 200, curr loss: 0.5274720191955566, avg loss: 0.5229091864824295\n",
      "trial: 12, ldr: 0.5570744276046753, dv: 0.563841700553894, nwj: 0.5638188719749451\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 13, epoch, 1, iter: 1, curr loss: 0.6926186680793762, avg loss: 0.6926186680793762\n",
      "trial: 13, epoch, 1, iter: 200, curr loss: 0.5255929231643677, avg loss: 0.5350768473744393\n",
      "trial: 13, epoch, 2, iter: 1, curr loss: 0.5343002080917358, avg loss: 0.5343002080917358\n",
      "trial: 13, epoch, 2, iter: 200, curr loss: 0.5289124250411987, avg loss: 0.524617676436901\n",
      "trial: 13, epoch, 3, iter: 1, curr loss: 0.5298380851745605, avg loss: 0.5298380851745605\n",
      "trial: 13, epoch, 3, iter: 200, curr loss: 0.5183970928192139, avg loss: 0.5231999856233597\n",
      "trial: 13, epoch, 4, iter: 1, curr loss: 0.5234241485595703, avg loss: 0.5234241485595703\n",
      "trial: 13, epoch, 4, iter: 200, curr loss: 0.5265820026397705, avg loss: 0.5234769517183304\n",
      "trial: 13, epoch, 5, iter: 1, curr loss: 0.5205508470535278, avg loss: 0.5205508470535278\n",
      "trial: 13, epoch, 5, iter: 200, curr loss: 0.5351643562316895, avg loss: 0.5238461470603943\n",
      "trial: 13, epoch, 6, iter: 1, curr loss: 0.5257376432418823, avg loss: 0.5257376432418823\n",
      "trial: 13, epoch, 6, iter: 200, curr loss: 0.5220897197723389, avg loss: 0.5230446577072143\n",
      "trial: 13, epoch, 7, iter: 1, curr loss: 0.5206360220909119, avg loss: 0.5206360220909119\n",
      "trial: 13, epoch, 7, iter: 200, curr loss: 0.5290454626083374, avg loss: 0.5230041721463203\n",
      "trial: 13, epoch, 8, iter: 1, curr loss: 0.5333884954452515, avg loss: 0.5333884954452515\n",
      "trial: 13, epoch, 8, iter: 200, curr loss: 0.5317164063453674, avg loss: 0.5235245895385742\n",
      "trial: 13, epoch, 9, iter: 1, curr loss: 0.5360207557678223, avg loss: 0.5360207557678223\n",
      "trial: 13, epoch, 9, iter: 200, curr loss: 0.5280529260635376, avg loss: 0.5232006421685219\n",
      "trial: 13, epoch, 10, iter: 1, curr loss: 0.5278618931770325, avg loss: 0.5278618931770325\n",
      "trial: 13, epoch, 10, iter: 200, curr loss: 0.5302621126174927, avg loss: 0.5236649081110955\n",
      "trial: 13, epoch, 11, iter: 1, curr loss: 0.536812961101532, avg loss: 0.536812961101532\n",
      "trial: 13, epoch, 11, iter: 200, curr loss: 0.5230816602706909, avg loss: 0.5232159242033958\n",
      "trial: 13, epoch, 12, iter: 1, curr loss: 0.529975414276123, avg loss: 0.529975414276123\n",
      "trial: 13, epoch, 12, iter: 200, curr loss: 0.5283424854278564, avg loss: 0.5230377727746963\n",
      "trial: 13, epoch, 13, iter: 1, curr loss: 0.5129005908966064, avg loss: 0.5129005908966064\n",
      "trial: 13, epoch, 13, iter: 200, curr loss: 0.5218755006790161, avg loss: 0.5230118250846862\n",
      "trial: 13, epoch, 14, iter: 1, curr loss: 0.5235186219215393, avg loss: 0.5235186219215393\n",
      "trial: 13, epoch, 14, iter: 200, curr loss: 0.5263760089874268, avg loss: 0.52340027987957\n",
      "trial: 13, epoch, 15, iter: 1, curr loss: 0.5291150808334351, avg loss: 0.5291150808334351\n",
      "trial: 13, epoch, 15, iter: 200, curr loss: 0.5240611433982849, avg loss: 0.5234201076626778\n",
      "trial: 13, epoch, 16, iter: 1, curr loss: 0.5269297957420349, avg loss: 0.5269297957420349\n",
      "trial: 13, epoch, 16, iter: 200, curr loss: 0.5322637557983398, avg loss: 0.5233614739775657\n",
      "trial: 13, epoch, 17, iter: 1, curr loss: 0.527788519859314, avg loss: 0.527788519859314\n",
      "trial: 13, epoch, 17, iter: 200, curr loss: 0.518907368183136, avg loss: 0.523512358367443\n",
      "trial: 13, epoch, 18, iter: 1, curr loss: 0.5284121632575989, avg loss: 0.5284121632575989\n",
      "trial: 13, epoch, 18, iter: 200, curr loss: 0.5248662233352661, avg loss: 0.5235843819379806\n",
      "trial: 13, epoch, 19, iter: 1, curr loss: 0.5257096290588379, avg loss: 0.5257096290588379\n",
      "trial: 13, epoch, 19, iter: 200, curr loss: 0.537655234336853, avg loss: 0.5235573035478592\n",
      "trial: 13, epoch, 20, iter: 1, curr loss: 0.5245704650878906, avg loss: 0.5245704650878906\n",
      "trial: 13, epoch, 20, iter: 200, curr loss: 0.5223649144172668, avg loss: 0.5234651494026185\n",
      "trial: 13, epoch, 21, iter: 1, curr loss: 0.5264768004417419, avg loss: 0.5264768004417419\n",
      "trial: 13, epoch, 21, iter: 200, curr loss: 0.5245682001113892, avg loss: 0.5236125659942626\n",
      "trial: 13, epoch, 22, iter: 1, curr loss: 0.5259969234466553, avg loss: 0.5259969234466553\n",
      "trial: 13, epoch, 22, iter: 200, curr loss: 0.5288605093955994, avg loss: 0.5232718265056611\n",
      "trial: 13, epoch, 23, iter: 1, curr loss: 0.5211864113807678, avg loss: 0.5211864113807678\n",
      "trial: 13, epoch, 23, iter: 200, curr loss: 0.5216952562332153, avg loss: 0.5230968245863914\n",
      "trial: 13, epoch, 24, iter: 1, curr loss: 0.5356115102767944, avg loss: 0.5356115102767944\n",
      "trial: 13, epoch, 24, iter: 200, curr loss: 0.5202414393424988, avg loss: 0.5228681311011314\n",
      "trial: 13, epoch, 25, iter: 1, curr loss: 0.5276371240615845, avg loss: 0.5276371240615845\n",
      "trial: 13, epoch, 25, iter: 200, curr loss: 0.5257638692855835, avg loss: 0.5233098736405373\n",
      "trial: 13, epoch, 26, iter: 1, curr loss: 0.5245915651321411, avg loss: 0.5245915651321411\n",
      "trial: 13, epoch, 26, iter: 200, curr loss: 0.5261175036430359, avg loss: 0.5231178912520409\n",
      "trial: 13, epoch, 27, iter: 1, curr loss: 0.5125513672828674, avg loss: 0.5125513672828674\n",
      "trial: 13, epoch, 27, iter: 200, curr loss: 0.5213117003440857, avg loss: 0.5233035996556282\n",
      "trial: 13, epoch, 28, iter: 1, curr loss: 0.5173310041427612, avg loss: 0.5173310041427612\n",
      "trial: 13, epoch, 28, iter: 200, curr loss: 0.5229531526565552, avg loss: 0.5237048441171646\n",
      "trial: 13, epoch, 29, iter: 1, curr loss: 0.5345845818519592, avg loss: 0.5345845818519592\n",
      "trial: 13, epoch, 29, iter: 200, curr loss: 0.5232882499694824, avg loss: 0.5229102030396462\n",
      "trial: 13, epoch, 30, iter: 1, curr loss: 0.5217804908752441, avg loss: 0.5217804908752441\n",
      "trial: 13, epoch, 30, iter: 200, curr loss: 0.5230711102485657, avg loss: 0.5229496231675148\n",
      "trial: 13, epoch, 31, iter: 1, curr loss: 0.5253570079803467, avg loss: 0.5253570079803467\n",
      "trial: 13, epoch, 31, iter: 200, curr loss: 0.5352314710617065, avg loss: 0.5228106573224067\n",
      "trial: 13, epoch, 32, iter: 1, curr loss: 0.5267723798751831, avg loss: 0.5267723798751831\n",
      "trial: 13, epoch, 32, iter: 200, curr loss: 0.5105381011962891, avg loss: 0.5230073368549347\n",
      "trial: 13, epoch, 33, iter: 1, curr loss: 0.5301907062530518, avg loss: 0.5301907062530518\n",
      "trial: 13, epoch, 33, iter: 200, curr loss: 0.5172615647315979, avg loss: 0.5235697636008263\n",
      "trial: 13, epoch, 34, iter: 1, curr loss: 0.534987211227417, avg loss: 0.534987211227417\n",
      "trial: 13, epoch, 34, iter: 200, curr loss: 0.5267044305801392, avg loss: 0.5231088307499886\n",
      "trial: 13, epoch, 35, iter: 1, curr loss: 0.5299540758132935, avg loss: 0.5299540758132935\n",
      "trial: 13, epoch, 35, iter: 200, curr loss: 0.5320190191268921, avg loss: 0.5230306452512741\n",
      "trial: 13, epoch, 36, iter: 1, curr loss: 0.5201685428619385, avg loss: 0.5201685428619385\n",
      "trial: 13, epoch, 36, iter: 200, curr loss: 0.5070902705192566, avg loss: 0.5229193350672722\n",
      "trial: 13, epoch, 37, iter: 1, curr loss: 0.5322466492652893, avg loss: 0.5322466492652893\n",
      "trial: 13, epoch, 37, iter: 200, curr loss: 0.5270603895187378, avg loss: 0.5231749814748764\n",
      "trial: 13, epoch, 38, iter: 1, curr loss: 0.5368645787239075, avg loss: 0.5368645787239075\n",
      "trial: 13, epoch, 38, iter: 200, curr loss: 0.5262402296066284, avg loss: 0.5234166178107261\n",
      "trial: 13, epoch, 39, iter: 1, curr loss: 0.5222747325897217, avg loss: 0.5222747325897217\n",
      "trial: 13, epoch, 39, iter: 200, curr loss: 0.5317448377609253, avg loss: 0.5237589034438134\n",
      "trial: 13, epoch, 40, iter: 1, curr loss: 0.5213868618011475, avg loss: 0.5213868618011475\n",
      "trial: 13, epoch, 40, iter: 200, curr loss: 0.5302451252937317, avg loss: 0.5231232985854148\n",
      "trial: 13, epoch, 41, iter: 1, curr loss: 0.5253003835678101, avg loss: 0.5253003835678101\n",
      "trial: 13, epoch, 41, iter: 200, curr loss: 0.5159095525741577, avg loss: 0.5233864411711693\n",
      "trial: 13, epoch, 42, iter: 1, curr loss: 0.5251307487487793, avg loss: 0.5251307487487793\n",
      "trial: 13, epoch, 42, iter: 200, curr loss: 0.5333410501480103, avg loss: 0.523039900958538\n",
      "trial: 13, epoch, 43, iter: 1, curr loss: 0.5315229892730713, avg loss: 0.5315229892730713\n",
      "trial: 13, epoch, 43, iter: 200, curr loss: 0.5243520736694336, avg loss: 0.5236395385861397\n",
      "trial: 13, epoch, 44, iter: 1, curr loss: 0.5247800350189209, avg loss: 0.5247800350189209\n",
      "trial: 13, epoch, 44, iter: 200, curr loss: 0.519010603427887, avg loss: 0.5232942432165146\n",
      "trial: 13, epoch, 45, iter: 1, curr loss: 0.5331586599349976, avg loss: 0.5331586599349976\n",
      "trial: 13, epoch, 45, iter: 200, curr loss: 0.5263569355010986, avg loss: 0.5233158740401268\n",
      "trial: 13, epoch, 46, iter: 1, curr loss: 0.5155469179153442, avg loss: 0.5155469179153442\n",
      "trial: 13, epoch, 46, iter: 200, curr loss: 0.5314705967903137, avg loss: 0.5226348868012428\n",
      "trial: 13, epoch, 47, iter: 1, curr loss: 0.5292291045188904, avg loss: 0.5292291045188904\n",
      "trial: 13, epoch, 47, iter: 200, curr loss: 0.5147196054458618, avg loss: 0.5232514530420304\n",
      "trial: 13, epoch, 48, iter: 1, curr loss: 0.5276974439620972, avg loss: 0.5276974439620972\n",
      "trial: 13, epoch, 48, iter: 200, curr loss: 0.5219032764434814, avg loss: 0.5227354377508163\n",
      "trial: 13, epoch, 49, iter: 1, curr loss: 0.5227538347244263, avg loss: 0.5227538347244263\n",
      "trial: 13, epoch, 49, iter: 200, curr loss: 0.5264531373977661, avg loss: 0.5233557206392289\n",
      "trial: 13, epoch, 50, iter: 1, curr loss: 0.5230955481529236, avg loss: 0.5230955481529236\n",
      "trial: 13, epoch, 50, iter: 200, curr loss: 0.5307675004005432, avg loss: 0.522930696606636\n",
      "trial: 13, ldr: 0.5713005661964417, dv: 0.5639972686767578, nwj: 0.5639705061912537\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 14, epoch, 1, iter: 1, curr loss: 0.6928066611289978, avg loss: 0.6928066611289978\n",
      "trial: 14, epoch, 1, iter: 200, curr loss: 0.521592378616333, avg loss: 0.5350391310453415\n",
      "trial: 14, epoch, 2, iter: 1, curr loss: 0.5294753909111023, avg loss: 0.5294753909111023\n",
      "trial: 14, epoch, 2, iter: 200, curr loss: 0.5298699140548706, avg loss: 0.5243313878774643\n",
      "trial: 14, epoch, 3, iter: 1, curr loss: 0.5321692824363708, avg loss: 0.5321692824363708\n",
      "trial: 14, epoch, 3, iter: 200, curr loss: 0.5259697437286377, avg loss: 0.5236131179332734\n",
      "trial: 14, epoch, 4, iter: 1, curr loss: 0.5217956304550171, avg loss: 0.5217956304550171\n",
      "trial: 14, epoch, 4, iter: 200, curr loss: 0.529697060585022, avg loss: 0.5236126157641411\n",
      "trial: 14, epoch, 5, iter: 1, curr loss: 0.5262386798858643, avg loss: 0.5262386798858643\n",
      "trial: 14, epoch, 5, iter: 200, curr loss: 0.5115355849266052, avg loss: 0.523160633444786\n",
      "trial: 14, epoch, 6, iter: 1, curr loss: 0.531359851360321, avg loss: 0.531359851360321\n",
      "trial: 14, epoch, 6, iter: 200, curr loss: 0.5278955698013306, avg loss: 0.5235367262363434\n",
      "trial: 14, epoch, 7, iter: 1, curr loss: 0.5152376294136047, avg loss: 0.5152376294136047\n",
      "trial: 14, epoch, 7, iter: 200, curr loss: 0.5281695127487183, avg loss: 0.5238350647687912\n",
      "trial: 14, epoch, 8, iter: 1, curr loss: 0.5285871028900146, avg loss: 0.5285871028900146\n",
      "trial: 14, epoch, 8, iter: 200, curr loss: 0.5300338268280029, avg loss: 0.5233952328562737\n",
      "trial: 14, epoch, 9, iter: 1, curr loss: 0.5369864106178284, avg loss: 0.5369864106178284\n",
      "trial: 14, epoch, 9, iter: 200, curr loss: 0.5206143260002136, avg loss: 0.5228434365987777\n",
      "trial: 14, epoch, 10, iter: 1, curr loss: 0.53867107629776, avg loss: 0.53867107629776\n",
      "trial: 14, epoch, 10, iter: 200, curr loss: 0.5317151546478271, avg loss: 0.5236888501048088\n",
      "trial: 14, epoch, 11, iter: 1, curr loss: 0.5224199295043945, avg loss: 0.5224199295043945\n",
      "trial: 14, epoch, 11, iter: 200, curr loss: 0.5344089865684509, avg loss: 0.5233873209357262\n",
      "trial: 14, epoch, 12, iter: 1, curr loss: 0.5198076963424683, avg loss: 0.5198076963424683\n",
      "trial: 14, epoch, 12, iter: 200, curr loss: 0.5280956625938416, avg loss: 0.5236812388896942\n",
      "trial: 14, epoch, 13, iter: 1, curr loss: 0.5294895172119141, avg loss: 0.5294895172119141\n",
      "trial: 14, epoch, 13, iter: 200, curr loss: 0.5292966365814209, avg loss: 0.5234666857123375\n",
      "trial: 14, epoch, 14, iter: 1, curr loss: 0.5238193273544312, avg loss: 0.5238193273544312\n",
      "trial: 14, epoch, 14, iter: 200, curr loss: 0.5182496905326843, avg loss: 0.5231253063678741\n",
      "trial: 14, epoch, 15, iter: 1, curr loss: 0.528606653213501, avg loss: 0.528606653213501\n",
      "trial: 14, epoch, 15, iter: 200, curr loss: 0.5270648002624512, avg loss: 0.5232620143890381\n",
      "trial: 14, epoch, 16, iter: 1, curr loss: 0.529964804649353, avg loss: 0.529964804649353\n",
      "trial: 14, epoch, 16, iter: 200, curr loss: 0.52060866355896, avg loss: 0.5231244438886642\n",
      "trial: 14, epoch, 17, iter: 1, curr loss: 0.5126268863677979, avg loss: 0.5126268863677979\n",
      "trial: 14, epoch, 17, iter: 200, curr loss: 0.5318237543106079, avg loss: 0.5238113614916802\n",
      "trial: 14, epoch, 18, iter: 1, curr loss: 0.5113561153411865, avg loss: 0.5113561153411865\n",
      "trial: 14, epoch, 18, iter: 200, curr loss: 0.5264815092086792, avg loss: 0.5233758109807968\n",
      "trial: 14, epoch, 19, iter: 1, curr loss: 0.5287410616874695, avg loss: 0.5287410616874695\n",
      "trial: 14, epoch, 19, iter: 200, curr loss: 0.5326604843139648, avg loss: 0.5230307680368423\n",
      "trial: 14, epoch, 20, iter: 1, curr loss: 0.5303994417190552, avg loss: 0.5303994417190552\n",
      "trial: 14, epoch, 20, iter: 200, curr loss: 0.5260485410690308, avg loss: 0.5232423371076584\n",
      "trial: 14, epoch, 21, iter: 1, curr loss: 0.5255541801452637, avg loss: 0.5255541801452637\n",
      "trial: 14, epoch, 21, iter: 200, curr loss: 0.5321159958839417, avg loss: 0.5231178736686707\n",
      "trial: 14, epoch, 22, iter: 1, curr loss: 0.5310570001602173, avg loss: 0.5310570001602173\n",
      "trial: 14, epoch, 22, iter: 200, curr loss: 0.5302749276161194, avg loss: 0.5230671885609627\n",
      "trial: 14, epoch, 23, iter: 1, curr loss: 0.5317090749740601, avg loss: 0.5317090749740601\n",
      "trial: 14, epoch, 23, iter: 200, curr loss: 0.5290037393569946, avg loss: 0.5233091789484025\n",
      "trial: 14, epoch, 24, iter: 1, curr loss: 0.524429202079773, avg loss: 0.524429202079773\n",
      "trial: 14, epoch, 24, iter: 200, curr loss: 0.5182709693908691, avg loss: 0.5234621360898017\n",
      "trial: 14, epoch, 25, iter: 1, curr loss: 0.525446891784668, avg loss: 0.525446891784668\n",
      "trial: 14, epoch, 25, iter: 200, curr loss: 0.5262812376022339, avg loss: 0.5230206567049026\n",
      "trial: 14, epoch, 26, iter: 1, curr loss: 0.5285876989364624, avg loss: 0.5285876989364624\n",
      "trial: 14, epoch, 26, iter: 200, curr loss: 0.5321553945541382, avg loss: 0.5235175481438636\n",
      "trial: 14, epoch, 27, iter: 1, curr loss: 0.5329821109771729, avg loss: 0.5329821109771729\n",
      "trial: 14, epoch, 27, iter: 200, curr loss: 0.5195552706718445, avg loss: 0.5230720496177673\n",
      "trial: 14, epoch, 28, iter: 1, curr loss: 0.521645724773407, avg loss: 0.521645724773407\n",
      "trial: 14, epoch, 28, iter: 200, curr loss: 0.5211201310157776, avg loss: 0.5232743826508522\n",
      "trial: 14, epoch, 29, iter: 1, curr loss: 0.5207585096359253, avg loss: 0.5207585096359253\n",
      "trial: 14, epoch, 29, iter: 200, curr loss: 0.5378739833831787, avg loss: 0.523176948428154\n",
      "trial: 14, epoch, 30, iter: 1, curr loss: 0.5239792466163635, avg loss: 0.5239792466163635\n",
      "trial: 14, epoch, 30, iter: 200, curr loss: 0.5345649719238281, avg loss: 0.5230285453796387\n",
      "trial: 14, epoch, 31, iter: 1, curr loss: 0.5260769128799438, avg loss: 0.5260769128799438\n",
      "trial: 14, epoch, 31, iter: 200, curr loss: 0.5264275074005127, avg loss: 0.523070656657219\n",
      "trial: 14, epoch, 32, iter: 1, curr loss: 0.5270051956176758, avg loss: 0.5270051956176758\n",
      "trial: 14, epoch, 32, iter: 200, curr loss: 0.5230281352996826, avg loss: 0.5232068783044815\n",
      "trial: 14, epoch, 33, iter: 1, curr loss: 0.5347172021865845, avg loss: 0.5347172021865845\n",
      "trial: 14, epoch, 33, iter: 200, curr loss: 0.5339114665985107, avg loss: 0.5234358236193657\n",
      "trial: 14, epoch, 34, iter: 1, curr loss: 0.5328493118286133, avg loss: 0.5328493118286133\n",
      "trial: 14, epoch, 34, iter: 200, curr loss: 0.5288041830062866, avg loss: 0.5231673055887223\n",
      "trial: 14, epoch, 35, iter: 1, curr loss: 0.530461311340332, avg loss: 0.530461311340332\n",
      "trial: 14, epoch, 35, iter: 200, curr loss: 0.5293663740158081, avg loss: 0.5228822150826454\n",
      "trial: 14, epoch, 36, iter: 1, curr loss: 0.5247279405593872, avg loss: 0.5247279405593872\n",
      "trial: 14, epoch, 36, iter: 200, curr loss: 0.5286311507225037, avg loss: 0.523548050224781\n",
      "trial: 14, epoch, 37, iter: 1, curr loss: 0.5217245817184448, avg loss: 0.5217245817184448\n",
      "trial: 14, epoch, 37, iter: 200, curr loss: 0.518977165222168, avg loss: 0.5238000276684761\n",
      "trial: 14, epoch, 38, iter: 1, curr loss: 0.5216017365455627, avg loss: 0.5216017365455627\n",
      "trial: 14, epoch, 38, iter: 200, curr loss: 0.5188705921173096, avg loss: 0.5235815298557281\n",
      "trial: 14, epoch, 39, iter: 1, curr loss: 0.5300706624984741, avg loss: 0.5300706624984741\n",
      "trial: 14, epoch, 39, iter: 200, curr loss: 0.5264211893081665, avg loss: 0.5233437675237655\n",
      "trial: 14, epoch, 40, iter: 1, curr loss: 0.5268987417221069, avg loss: 0.5268987417221069\n",
      "trial: 14, epoch, 40, iter: 200, curr loss: 0.5261712074279785, avg loss: 0.523073678612709\n",
      "trial: 14, epoch, 41, iter: 1, curr loss: 0.5399274230003357, avg loss: 0.5399274230003357\n",
      "trial: 14, epoch, 41, iter: 200, curr loss: 0.5358279943466187, avg loss: 0.5230433240532875\n",
      "trial: 14, epoch, 42, iter: 1, curr loss: 0.5253045558929443, avg loss: 0.5253045558929443\n",
      "trial: 14, epoch, 42, iter: 200, curr loss: 0.530797004699707, avg loss: 0.5233221507072449\n",
      "trial: 14, epoch, 43, iter: 1, curr loss: 0.5404092073440552, avg loss: 0.5404092073440552\n",
      "trial: 14, epoch, 43, iter: 200, curr loss: 0.5347217917442322, avg loss: 0.5232188585400581\n",
      "trial: 14, epoch, 44, iter: 1, curr loss: 0.5306357145309448, avg loss: 0.5306357145309448\n",
      "trial: 14, epoch, 44, iter: 200, curr loss: 0.5258466005325317, avg loss: 0.5232642996311188\n",
      "trial: 14, epoch, 45, iter: 1, curr loss: 0.5119467973709106, avg loss: 0.5119467973709106\n",
      "trial: 14, epoch, 45, iter: 200, curr loss: 0.5258433222770691, avg loss: 0.5235760128498077\n",
      "trial: 14, epoch, 46, iter: 1, curr loss: 0.5152589082717896, avg loss: 0.5152589082717896\n",
      "trial: 14, epoch, 46, iter: 200, curr loss: 0.5264102816581726, avg loss: 0.523149094581604\n",
      "trial: 14, epoch, 47, iter: 1, curr loss: 0.5183219909667969, avg loss: 0.5183219909667969\n",
      "trial: 14, epoch, 47, iter: 200, curr loss: 0.5286373496055603, avg loss: 0.5230377316474915\n",
      "trial: 14, epoch, 48, iter: 1, curr loss: 0.5280288457870483, avg loss: 0.5280288457870483\n",
      "trial: 14, epoch, 48, iter: 200, curr loss: 0.5110217332839966, avg loss: 0.5240503677725792\n",
      "trial: 14, epoch, 49, iter: 1, curr loss: 0.525689959526062, avg loss: 0.525689959526062\n",
      "trial: 14, epoch, 49, iter: 200, curr loss: 0.5247873663902283, avg loss: 0.5234586426615715\n",
      "trial: 14, epoch, 50, iter: 1, curr loss: 0.5213141441345215, avg loss: 0.5213141441345215\n",
      "trial: 14, epoch, 50, iter: 200, curr loss: 0.512847363948822, avg loss: 0.5230710220336914\n",
      "trial: 14, ldr: 0.5612410306930542, dv: 0.5640050768852234, nwj: 0.5640012621879578\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 15, epoch, 1, iter: 1, curr loss: 0.6936441659927368, avg loss: 0.6936441659927368\n",
      "trial: 15, epoch, 1, iter: 200, curr loss: 0.5348665714263916, avg loss: 0.5348254323005677\n",
      "trial: 15, epoch, 2, iter: 1, curr loss: 0.5201549530029297, avg loss: 0.5201549530029297\n",
      "trial: 15, epoch, 2, iter: 200, curr loss: 0.5266644954681396, avg loss: 0.524407751262188\n",
      "trial: 15, epoch, 3, iter: 1, curr loss: 0.5265250205993652, avg loss: 0.5265250205993652\n",
      "trial: 15, epoch, 3, iter: 200, curr loss: 0.523219108581543, avg loss: 0.5231523633003234\n",
      "trial: 15, epoch, 4, iter: 1, curr loss: 0.5200291872024536, avg loss: 0.5200291872024536\n",
      "trial: 15, epoch, 4, iter: 200, curr loss: 0.5270166397094727, avg loss: 0.5234266006946564\n",
      "trial: 15, epoch, 5, iter: 1, curr loss: 0.5230064988136292, avg loss: 0.5230064988136292\n",
      "trial: 15, epoch, 5, iter: 200, curr loss: 0.5225483775138855, avg loss: 0.522959098815918\n",
      "trial: 15, epoch, 6, iter: 1, curr loss: 0.5211991667747498, avg loss: 0.5211991667747498\n",
      "trial: 15, epoch, 6, iter: 200, curr loss: 0.5449416041374207, avg loss: 0.5236310482025146\n",
      "trial: 15, epoch, 7, iter: 1, curr loss: 0.5235151052474976, avg loss: 0.5235151052474976\n",
      "trial: 15, epoch, 7, iter: 200, curr loss: 0.5222305655479431, avg loss: 0.5236457633972168\n",
      "trial: 15, epoch, 8, iter: 1, curr loss: 0.5297574996948242, avg loss: 0.5297574996948242\n",
      "trial: 15, epoch, 8, iter: 200, curr loss: 0.5342614650726318, avg loss: 0.5232747521996498\n",
      "trial: 15, epoch, 9, iter: 1, curr loss: 0.5309919118881226, avg loss: 0.5309919118881226\n",
      "trial: 15, epoch, 9, iter: 200, curr loss: 0.5258191823959351, avg loss: 0.5230827823281288\n",
      "trial: 15, epoch, 10, iter: 1, curr loss: 0.5294674634933472, avg loss: 0.5294674634933472\n",
      "trial: 15, epoch, 10, iter: 200, curr loss: 0.5258132219314575, avg loss: 0.523346769809723\n",
      "trial: 15, epoch, 11, iter: 1, curr loss: 0.5226287841796875, avg loss: 0.5226287841796875\n",
      "trial: 15, epoch, 11, iter: 200, curr loss: 0.5175836086273193, avg loss: 0.5236536049842835\n",
      "trial: 15, epoch, 12, iter: 1, curr loss: 0.5225995182991028, avg loss: 0.5225995182991028\n",
      "trial: 15, epoch, 12, iter: 200, curr loss: 0.5205732583999634, avg loss: 0.5230362510681152\n",
      "trial: 15, epoch, 13, iter: 1, curr loss: 0.5174126625061035, avg loss: 0.5174126625061035\n",
      "trial: 15, epoch, 13, iter: 200, curr loss: 0.5274003744125366, avg loss: 0.5235867550969124\n",
      "trial: 15, epoch, 14, iter: 1, curr loss: 0.5275706052780151, avg loss: 0.5275706052780151\n",
      "trial: 15, epoch, 14, iter: 200, curr loss: 0.5322935581207275, avg loss: 0.5233323693275451\n",
      "trial: 15, epoch, 15, iter: 1, curr loss: 0.5315295457839966, avg loss: 0.5315295457839966\n",
      "trial: 15, epoch, 15, iter: 200, curr loss: 0.5270571708679199, avg loss: 0.5234896656870842\n",
      "trial: 15, epoch, 16, iter: 1, curr loss: 0.525355875492096, avg loss: 0.525355875492096\n",
      "trial: 15, epoch, 16, iter: 200, curr loss: 0.5259853601455688, avg loss: 0.5228342536091805\n",
      "trial: 15, epoch, 17, iter: 1, curr loss: 0.5220811367034912, avg loss: 0.5220811367034912\n",
      "trial: 15, epoch, 17, iter: 200, curr loss: 0.5232027769088745, avg loss: 0.5234176751971245\n",
      "trial: 15, epoch, 18, iter: 1, curr loss: 0.5278379917144775, avg loss: 0.5278379917144775\n",
      "trial: 15, epoch, 18, iter: 200, curr loss: 0.5216563940048218, avg loss: 0.5235837948322296\n",
      "trial: 15, epoch, 19, iter: 1, curr loss: 0.5283868312835693, avg loss: 0.5283868312835693\n",
      "trial: 15, epoch, 19, iter: 200, curr loss: 0.5258110761642456, avg loss: 0.5233305785059928\n",
      "trial: 15, epoch, 20, iter: 1, curr loss: 0.5293254852294922, avg loss: 0.5293254852294922\n",
      "trial: 15, epoch, 20, iter: 200, curr loss: 0.53362637758255, avg loss: 0.5229991698265075\n",
      "trial: 15, epoch, 21, iter: 1, curr loss: 0.5328142642974854, avg loss: 0.5328142642974854\n",
      "trial: 15, epoch, 21, iter: 200, curr loss: 0.5244299173355103, avg loss: 0.5239996510744095\n",
      "trial: 15, epoch, 22, iter: 1, curr loss: 0.5227575898170471, avg loss: 0.5227575898170471\n",
      "trial: 15, epoch, 22, iter: 200, curr loss: 0.5168578028678894, avg loss: 0.5232907751202583\n",
      "trial: 15, epoch, 23, iter: 1, curr loss: 0.5220378637313843, avg loss: 0.5220378637313843\n",
      "trial: 15, epoch, 23, iter: 200, curr loss: 0.5282642841339111, avg loss: 0.5234740725159646\n",
      "trial: 15, epoch, 24, iter: 1, curr loss: 0.5239447355270386, avg loss: 0.5239447355270386\n",
      "trial: 15, epoch, 24, iter: 200, curr loss: 0.5147445201873779, avg loss: 0.5232889294624329\n",
      "trial: 15, epoch, 25, iter: 1, curr loss: 0.5318375825881958, avg loss: 0.5318375825881958\n",
      "trial: 15, epoch, 25, iter: 200, curr loss: 0.5202863812446594, avg loss: 0.5235479599237443\n",
      "trial: 15, epoch, 26, iter: 1, curr loss: 0.5218090415000916, avg loss: 0.5218090415000916\n",
      "trial: 15, epoch, 26, iter: 200, curr loss: 0.5282833576202393, avg loss: 0.523276592195034\n",
      "trial: 15, epoch, 27, iter: 1, curr loss: 0.5208063125610352, avg loss: 0.5208063125610352\n",
      "trial: 15, epoch, 27, iter: 200, curr loss: 0.5223650932312012, avg loss: 0.5236984723806382\n",
      "trial: 15, epoch, 28, iter: 1, curr loss: 0.5228967666625977, avg loss: 0.5228967666625977\n",
      "trial: 15, epoch, 28, iter: 200, curr loss: 0.5344047546386719, avg loss: 0.5226760366559029\n",
      "trial: 15, epoch, 29, iter: 1, curr loss: 0.5319720506668091, avg loss: 0.5319720506668091\n",
      "trial: 15, epoch, 29, iter: 200, curr loss: 0.5239556431770325, avg loss: 0.523150737285614\n",
      "trial: 15, epoch, 30, iter: 1, curr loss: 0.5289580225944519, avg loss: 0.5289580225944519\n",
      "trial: 15, epoch, 30, iter: 200, curr loss: 0.5200514793395996, avg loss: 0.5233255866169929\n",
      "trial: 15, epoch, 31, iter: 1, curr loss: 0.5212221145629883, avg loss: 0.5212221145629883\n",
      "trial: 15, epoch, 31, iter: 200, curr loss: 0.532405436038971, avg loss: 0.522891061604023\n",
      "trial: 15, epoch, 32, iter: 1, curr loss: 0.519818902015686, avg loss: 0.519818902015686\n",
      "trial: 15, epoch, 32, iter: 200, curr loss: 0.5372720956802368, avg loss: 0.5231890457868577\n",
      "trial: 15, epoch, 33, iter: 1, curr loss: 0.5164104104042053, avg loss: 0.5164104104042053\n",
      "trial: 15, epoch, 33, iter: 200, curr loss: 0.5264368057250977, avg loss: 0.5235763636231422\n",
      "trial: 15, epoch, 34, iter: 1, curr loss: 0.5176476836204529, avg loss: 0.5176476836204529\n",
      "trial: 15, epoch, 34, iter: 200, curr loss: 0.5342327952384949, avg loss: 0.523581660091877\n",
      "trial: 15, epoch, 35, iter: 1, curr loss: 0.5318512916564941, avg loss: 0.5318512916564941\n",
      "trial: 15, epoch, 35, iter: 200, curr loss: 0.5388936996459961, avg loss: 0.5230433189868927\n",
      "trial: 15, epoch, 36, iter: 1, curr loss: 0.5277427434921265, avg loss: 0.5277427434921265\n",
      "trial: 15, epoch, 36, iter: 200, curr loss: 0.5341092348098755, avg loss: 0.5230879694223404\n",
      "trial: 15, epoch, 37, iter: 1, curr loss: 0.5272018313407898, avg loss: 0.5272018313407898\n",
      "trial: 15, epoch, 37, iter: 200, curr loss: 0.5294950008392334, avg loss: 0.5230998963117599\n",
      "trial: 15, epoch, 38, iter: 1, curr loss: 0.524343729019165, avg loss: 0.524343729019165\n",
      "trial: 15, epoch, 38, iter: 200, curr loss: 0.5286882519721985, avg loss: 0.5230472710728645\n",
      "trial: 15, epoch, 39, iter: 1, curr loss: 0.5334861278533936, avg loss: 0.5334861278533936\n",
      "trial: 15, epoch, 39, iter: 200, curr loss: 0.5252898931503296, avg loss: 0.5230581200122834\n",
      "trial: 15, epoch, 40, iter: 1, curr loss: 0.5245139598846436, avg loss: 0.5245139598846436\n",
      "trial: 15, epoch, 40, iter: 200, curr loss: 0.522081732749939, avg loss: 0.523377061188221\n",
      "trial: 15, epoch, 41, iter: 1, curr loss: 0.5247274041175842, avg loss: 0.5247274041175842\n",
      "trial: 15, epoch, 41, iter: 200, curr loss: 0.5273818969726562, avg loss: 0.5234936618804932\n",
      "trial: 15, epoch, 42, iter: 1, curr loss: 0.5166014432907104, avg loss: 0.5166014432907104\n",
      "trial: 15, epoch, 42, iter: 200, curr loss: 0.5252473950386047, avg loss: 0.5236233353614808\n",
      "trial: 15, epoch, 43, iter: 1, curr loss: 0.5314334630966187, avg loss: 0.5314334630966187\n",
      "trial: 15, epoch, 43, iter: 200, curr loss: 0.5354675650596619, avg loss: 0.522652316391468\n",
      "trial: 15, epoch, 44, iter: 1, curr loss: 0.5282787680625916, avg loss: 0.5282787680625916\n",
      "trial: 15, epoch, 44, iter: 200, curr loss: 0.5304632186889648, avg loss: 0.5233157613873481\n",
      "trial: 15, epoch, 45, iter: 1, curr loss: 0.5245969295501709, avg loss: 0.5245969295501709\n",
      "trial: 15, epoch, 45, iter: 200, curr loss: 0.5288645029067993, avg loss: 0.523206068277359\n",
      "trial: 15, epoch, 46, iter: 1, curr loss: 0.5257255434989929, avg loss: 0.5257255434989929\n",
      "trial: 15, epoch, 46, iter: 200, curr loss: 0.5243117213249207, avg loss: 0.523216458261013\n",
      "trial: 15, epoch, 47, iter: 1, curr loss: 0.5269683003425598, avg loss: 0.5269683003425598\n",
      "trial: 15, epoch, 47, iter: 200, curr loss: 0.5331970453262329, avg loss: 0.5231105697154999\n",
      "trial: 15, epoch, 48, iter: 1, curr loss: 0.5349702835083008, avg loss: 0.5349702835083008\n",
      "trial: 15, epoch, 48, iter: 200, curr loss: 0.5249238014221191, avg loss: 0.5231662771105766\n",
      "trial: 15, epoch, 49, iter: 1, curr loss: 0.5314777493476868, avg loss: 0.5314777493476868\n",
      "trial: 15, epoch, 49, iter: 200, curr loss: 0.5265039205551147, avg loss: 0.5229025143384933\n",
      "trial: 15, epoch, 50, iter: 1, curr loss: 0.5275197625160217, avg loss: 0.5275197625160217\n",
      "trial: 15, epoch, 50, iter: 200, curr loss: 0.5280818939208984, avg loss: 0.5230160170793533\n",
      "trial: 15, ldr: 0.5591089725494385, dv: 0.5640147924423218, nwj: 0.5640027523040771\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 16, epoch, 1, iter: 1, curr loss: 0.693256676197052, avg loss: 0.693256676197052\n",
      "trial: 16, epoch, 1, iter: 200, curr loss: 0.5250329971313477, avg loss: 0.5353495427966117\n",
      "trial: 16, epoch, 2, iter: 1, curr loss: 0.52699214220047, avg loss: 0.52699214220047\n",
      "trial: 16, epoch, 2, iter: 200, curr loss: 0.5273901224136353, avg loss: 0.5238491895794869\n",
      "trial: 16, epoch, 3, iter: 1, curr loss: 0.5257189869880676, avg loss: 0.5257189869880676\n",
      "trial: 16, epoch, 3, iter: 200, curr loss: 0.5209769606590271, avg loss: 0.5238908031582832\n",
      "trial: 16, epoch, 4, iter: 1, curr loss: 0.5349152088165283, avg loss: 0.5349152088165283\n",
      "trial: 16, epoch, 4, iter: 200, curr loss: 0.5189924240112305, avg loss: 0.5235956898331642\n",
      "trial: 16, epoch, 5, iter: 1, curr loss: 0.5250754952430725, avg loss: 0.5250754952430725\n",
      "trial: 16, epoch, 5, iter: 200, curr loss: 0.5326250791549683, avg loss: 0.5233724027872085\n",
      "trial: 16, epoch, 6, iter: 1, curr loss: 0.5155004262924194, avg loss: 0.5155004262924194\n",
      "trial: 16, epoch, 6, iter: 200, curr loss: 0.529468297958374, avg loss: 0.5230495858192444\n",
      "trial: 16, epoch, 7, iter: 1, curr loss: 0.5273066163063049, avg loss: 0.5273066163063049\n",
      "trial: 16, epoch, 7, iter: 200, curr loss: 0.5336751937866211, avg loss: 0.5231511422991753\n",
      "trial: 16, epoch, 8, iter: 1, curr loss: 0.5228637456893921, avg loss: 0.5228637456893921\n",
      "trial: 16, epoch, 8, iter: 200, curr loss: 0.5220513939857483, avg loss: 0.5233349707722664\n",
      "trial: 16, epoch, 9, iter: 1, curr loss: 0.5268813371658325, avg loss: 0.5268813371658325\n",
      "trial: 16, epoch, 9, iter: 200, curr loss: 0.5255019664764404, avg loss: 0.5235638761520386\n",
      "trial: 16, epoch, 10, iter: 1, curr loss: 0.5257970094680786, avg loss: 0.5257970094680786\n",
      "trial: 16, epoch, 10, iter: 200, curr loss: 0.52783203125, avg loss: 0.523413112461567\n",
      "trial: 16, epoch, 11, iter: 1, curr loss: 0.5264827013015747, avg loss: 0.5264827013015747\n",
      "trial: 16, epoch, 11, iter: 200, curr loss: 0.5214486718177795, avg loss: 0.5230744907259941\n",
      "trial: 16, epoch, 12, iter: 1, curr loss: 0.532423734664917, avg loss: 0.532423734664917\n",
      "trial: 16, epoch, 12, iter: 200, curr loss: 0.5298161506652832, avg loss: 0.5234528091549874\n",
      "trial: 16, epoch, 13, iter: 1, curr loss: 0.5186396837234497, avg loss: 0.5186396837234497\n",
      "trial: 16, epoch, 13, iter: 200, curr loss: 0.5214235782623291, avg loss: 0.5235633718967437\n",
      "trial: 16, epoch, 14, iter: 1, curr loss: 0.5315271615982056, avg loss: 0.5315271615982056\n",
      "trial: 16, epoch, 14, iter: 200, curr loss: 0.5264239311218262, avg loss: 0.5235098525881767\n",
      "trial: 16, epoch, 15, iter: 1, curr loss: 0.5283803939819336, avg loss: 0.5283803939819336\n",
      "trial: 16, epoch, 15, iter: 200, curr loss: 0.5304708480834961, avg loss: 0.5231618732213974\n",
      "trial: 16, epoch, 16, iter: 1, curr loss: 0.5311938524246216, avg loss: 0.5311938524246216\n",
      "trial: 16, epoch, 16, iter: 200, curr loss: 0.5259016752243042, avg loss: 0.5229863125085831\n",
      "trial: 16, epoch, 17, iter: 1, curr loss: 0.5306823253631592, avg loss: 0.5306823253631592\n",
      "trial: 16, epoch, 17, iter: 200, curr loss: 0.5339195132255554, avg loss: 0.5228809431195259\n",
      "trial: 16, epoch, 18, iter: 1, curr loss: 0.5244134664535522, avg loss: 0.5244134664535522\n",
      "trial: 16, epoch, 18, iter: 200, curr loss: 0.5213956236839294, avg loss: 0.5235687163472176\n",
      "trial: 16, epoch, 19, iter: 1, curr loss: 0.5309841632843018, avg loss: 0.5309841632843018\n",
      "trial: 16, epoch, 19, iter: 200, curr loss: 0.5213570594787598, avg loss: 0.5233042693138122\n",
      "trial: 16, epoch, 20, iter: 1, curr loss: 0.5311858654022217, avg loss: 0.5311858654022217\n",
      "trial: 16, epoch, 20, iter: 200, curr loss: 0.5378010272979736, avg loss: 0.5231671684980392\n",
      "trial: 16, epoch, 21, iter: 1, curr loss: 0.520245373249054, avg loss: 0.520245373249054\n",
      "trial: 16, epoch, 21, iter: 200, curr loss: 0.5232821106910706, avg loss: 0.5230944907665253\n",
      "trial: 16, epoch, 22, iter: 1, curr loss: 0.5140067338943481, avg loss: 0.5140067338943481\n",
      "trial: 16, epoch, 22, iter: 200, curr loss: 0.5303491353988647, avg loss: 0.5229712116718293\n",
      "trial: 16, epoch, 23, iter: 1, curr loss: 0.5187098979949951, avg loss: 0.5187098979949951\n",
      "trial: 16, epoch, 23, iter: 200, curr loss: 0.526437520980835, avg loss: 0.5225216507911682\n",
      "trial: 16, epoch, 24, iter: 1, curr loss: 0.5277707576751709, avg loss: 0.5277707576751709\n",
      "trial: 16, epoch, 24, iter: 200, curr loss: 0.5293881297111511, avg loss: 0.5240444299578667\n",
      "trial: 16, epoch, 25, iter: 1, curr loss: 0.5266355276107788, avg loss: 0.5266355276107788\n",
      "trial: 16, epoch, 25, iter: 200, curr loss: 0.5245708227157593, avg loss: 0.5233197018504143\n",
      "trial: 16, epoch, 26, iter: 1, curr loss: 0.5222107172012329, avg loss: 0.5222107172012329\n",
      "trial: 16, epoch, 26, iter: 200, curr loss: 0.5229607224464417, avg loss: 0.52295319378376\n",
      "trial: 16, epoch, 27, iter: 1, curr loss: 0.5203856229782104, avg loss: 0.5203856229782104\n",
      "trial: 16, epoch, 27, iter: 200, curr loss: 0.5215528607368469, avg loss: 0.5232607769966126\n",
      "trial: 16, epoch, 28, iter: 1, curr loss: 0.5280668139457703, avg loss: 0.5280668139457703\n",
      "trial: 16, epoch, 28, iter: 200, curr loss: 0.5173404216766357, avg loss: 0.5233737117052079\n",
      "trial: 16, epoch, 29, iter: 1, curr loss: 0.5240566730499268, avg loss: 0.5240566730499268\n",
      "trial: 16, epoch, 29, iter: 200, curr loss: 0.5258390307426453, avg loss: 0.5227428165078163\n",
      "trial: 16, epoch, 30, iter: 1, curr loss: 0.5285224914550781, avg loss: 0.5285224914550781\n",
      "trial: 16, epoch, 30, iter: 200, curr loss: 0.5239907503128052, avg loss: 0.523573340177536\n",
      "trial: 16, epoch, 31, iter: 1, curr loss: 0.5258191823959351, avg loss: 0.5258191823959351\n",
      "trial: 16, epoch, 31, iter: 200, curr loss: 0.5234441757202148, avg loss: 0.5231179347634316\n",
      "trial: 16, epoch, 32, iter: 1, curr loss: 0.5252176523208618, avg loss: 0.5252176523208618\n",
      "trial: 16, epoch, 32, iter: 200, curr loss: 0.5190863013267517, avg loss: 0.5226258674263954\n",
      "trial: 16, epoch, 33, iter: 1, curr loss: 0.5255666971206665, avg loss: 0.5255666971206665\n",
      "trial: 16, epoch, 33, iter: 200, curr loss: 0.5245678424835205, avg loss: 0.5235923007130623\n",
      "trial: 16, epoch, 34, iter: 1, curr loss: 0.5264207124710083, avg loss: 0.5264207124710083\n",
      "trial: 16, epoch, 34, iter: 200, curr loss: 0.5213287472724915, avg loss: 0.5234700962901115\n",
      "trial: 16, epoch, 35, iter: 1, curr loss: 0.5289878845214844, avg loss: 0.5289878845214844\n",
      "trial: 16, epoch, 35, iter: 200, curr loss: 0.5207448601722717, avg loss: 0.5233010348677635\n",
      "trial: 16, epoch, 36, iter: 1, curr loss: 0.5395610332489014, avg loss: 0.5395610332489014\n",
      "trial: 16, epoch, 36, iter: 200, curr loss: 0.5248332023620605, avg loss: 0.5234580966830253\n",
      "trial: 16, epoch, 37, iter: 1, curr loss: 0.5257575511932373, avg loss: 0.5257575511932373\n",
      "trial: 16, epoch, 37, iter: 200, curr loss: 0.5320983529090881, avg loss: 0.5231880041956901\n",
      "trial: 16, epoch, 38, iter: 1, curr loss: 0.5253099203109741, avg loss: 0.5253099203109741\n",
      "trial: 16, epoch, 38, iter: 200, curr loss: 0.5299256443977356, avg loss: 0.5232575550675392\n",
      "trial: 16, epoch, 39, iter: 1, curr loss: 0.5311071872711182, avg loss: 0.5311071872711182\n",
      "trial: 16, epoch, 39, iter: 200, curr loss: 0.5311740040779114, avg loss: 0.5236732855439186\n",
      "trial: 16, epoch, 40, iter: 1, curr loss: 0.5271536707878113, avg loss: 0.5271536707878113\n",
      "trial: 16, epoch, 40, iter: 200, curr loss: 0.5258009433746338, avg loss: 0.5225696849822998\n",
      "trial: 16, epoch, 41, iter: 1, curr loss: 0.5262040495872498, avg loss: 0.5262040495872498\n",
      "trial: 16, epoch, 41, iter: 200, curr loss: 0.5285091400146484, avg loss: 0.5227834829688072\n",
      "trial: 16, epoch, 42, iter: 1, curr loss: 0.5204166769981384, avg loss: 0.5204166769981384\n",
      "trial: 16, epoch, 42, iter: 200, curr loss: 0.5168921947479248, avg loss: 0.5228764781355858\n",
      "trial: 16, epoch, 43, iter: 1, curr loss: 0.5343058109283447, avg loss: 0.5343058109283447\n",
      "trial: 16, epoch, 43, iter: 200, curr loss: 0.532166600227356, avg loss: 0.5233709535002709\n",
      "trial: 16, epoch, 44, iter: 1, curr loss: 0.5294779539108276, avg loss: 0.5294779539108276\n",
      "trial: 16, epoch, 44, iter: 200, curr loss: 0.525928258895874, avg loss: 0.5234708547592163\n",
      "trial: 16, epoch, 45, iter: 1, curr loss: 0.5381536483764648, avg loss: 0.5381536483764648\n",
      "trial: 16, epoch, 45, iter: 200, curr loss: 0.5162329077720642, avg loss: 0.5236744540929794\n",
      "trial: 16, epoch, 46, iter: 1, curr loss: 0.5152437090873718, avg loss: 0.5152437090873718\n",
      "trial: 16, epoch, 46, iter: 200, curr loss: 0.5340738296508789, avg loss: 0.5234934440255166\n",
      "trial: 16, epoch, 47, iter: 1, curr loss: 0.5270976424217224, avg loss: 0.5270976424217224\n",
      "trial: 16, epoch, 47, iter: 200, curr loss: 0.5197930335998535, avg loss: 0.5234448009729386\n",
      "trial: 16, epoch, 48, iter: 1, curr loss: 0.523125410079956, avg loss: 0.523125410079956\n",
      "trial: 16, epoch, 48, iter: 200, curr loss: 0.5330753326416016, avg loss: 0.5235841137170791\n",
      "trial: 16, epoch, 49, iter: 1, curr loss: 0.5250698328018188, avg loss: 0.5250698328018188\n",
      "trial: 16, epoch, 49, iter: 200, curr loss: 0.5298405885696411, avg loss: 0.5232958006858826\n",
      "trial: 16, epoch, 50, iter: 1, curr loss: 0.5200366973876953, avg loss: 0.5200366973876953\n",
      "trial: 16, epoch, 50, iter: 200, curr loss: 0.524802565574646, avg loss: 0.5235696706175804\n",
      "trial: 16, ldr: 0.5597655177116394, dv: 0.5637709498405457, nwj: 0.5637629628181458\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 17, epoch, 1, iter: 1, curr loss: 0.6944618225097656, avg loss: 0.6944618225097656\n",
      "trial: 17, epoch, 1, iter: 200, curr loss: 0.5196225047111511, avg loss: 0.5353692305088044\n",
      "trial: 17, epoch, 2, iter: 1, curr loss: 0.5198278427124023, avg loss: 0.5198278427124023\n",
      "trial: 17, epoch, 2, iter: 200, curr loss: 0.5232135653495789, avg loss: 0.5243426236510277\n",
      "trial: 17, epoch, 3, iter: 1, curr loss: 0.5224478244781494, avg loss: 0.5224478244781494\n",
      "trial: 17, epoch, 3, iter: 200, curr loss: 0.5261406302452087, avg loss: 0.5233967545628547\n",
      "trial: 17, epoch, 4, iter: 1, curr loss: 0.532010555267334, avg loss: 0.532010555267334\n",
      "trial: 17, epoch, 4, iter: 200, curr loss: 0.52115398645401, avg loss: 0.5231236845254899\n",
      "trial: 17, epoch, 5, iter: 1, curr loss: 0.5252098441123962, avg loss: 0.5252098441123962\n",
      "trial: 17, epoch, 5, iter: 200, curr loss: 0.5280773043632507, avg loss: 0.5232120430469513\n",
      "trial: 17, epoch, 6, iter: 1, curr loss: 0.5215034484863281, avg loss: 0.5215034484863281\n",
      "trial: 17, epoch, 6, iter: 200, curr loss: 0.5193747282028198, avg loss: 0.5235329541563988\n",
      "trial: 17, epoch, 7, iter: 1, curr loss: 0.5288543701171875, avg loss: 0.5288543701171875\n",
      "trial: 17, epoch, 7, iter: 200, curr loss: 0.531318187713623, avg loss: 0.5229650828242302\n",
      "trial: 17, epoch, 8, iter: 1, curr loss: 0.5274415016174316, avg loss: 0.5274415016174316\n",
      "trial: 17, epoch, 8, iter: 200, curr loss: 0.5238682627677917, avg loss: 0.5231623861193657\n",
      "trial: 17, epoch, 9, iter: 1, curr loss: 0.5210117101669312, avg loss: 0.5210117101669312\n",
      "trial: 17, epoch, 9, iter: 200, curr loss: 0.5261380076408386, avg loss: 0.5233104288578033\n",
      "trial: 17, epoch, 10, iter: 1, curr loss: 0.5330034494400024, avg loss: 0.5330034494400024\n",
      "trial: 17, epoch, 10, iter: 200, curr loss: 0.5240015983581543, avg loss: 0.5231766977906227\n",
      "trial: 17, epoch, 11, iter: 1, curr loss: 0.5222410559654236, avg loss: 0.5222410559654236\n",
      "trial: 17, epoch, 11, iter: 200, curr loss: 0.5211056470870972, avg loss: 0.5232808539271354\n",
      "trial: 17, epoch, 12, iter: 1, curr loss: 0.5211280584335327, avg loss: 0.5211280584335327\n",
      "trial: 17, epoch, 12, iter: 200, curr loss: 0.5229537487030029, avg loss: 0.523344622850418\n",
      "trial: 17, epoch, 13, iter: 1, curr loss: 0.5229521989822388, avg loss: 0.5229521989822388\n",
      "trial: 17, epoch, 13, iter: 200, curr loss: 0.5127986669540405, avg loss: 0.5231736871600151\n",
      "trial: 17, epoch, 14, iter: 1, curr loss: 0.536512017250061, avg loss: 0.536512017250061\n",
      "trial: 17, epoch, 14, iter: 200, curr loss: 0.5386505722999573, avg loss: 0.5234766209125519\n",
      "trial: 17, epoch, 15, iter: 1, curr loss: 0.5248347520828247, avg loss: 0.5248347520828247\n",
      "trial: 17, epoch, 15, iter: 200, curr loss: 0.5237358808517456, avg loss: 0.5232118532061577\n",
      "trial: 17, epoch, 16, iter: 1, curr loss: 0.5192380547523499, avg loss: 0.5192380547523499\n",
      "trial: 17, epoch, 16, iter: 200, curr loss: 0.5312827825546265, avg loss: 0.5232363376021385\n",
      "trial: 17, epoch, 17, iter: 1, curr loss: 0.5261833071708679, avg loss: 0.5261833071708679\n",
      "trial: 17, epoch, 17, iter: 200, curr loss: 0.5240272879600525, avg loss: 0.5232158136367798\n",
      "trial: 17, epoch, 18, iter: 1, curr loss: 0.5255409479141235, avg loss: 0.5255409479141235\n",
      "trial: 17, epoch, 18, iter: 200, curr loss: 0.5318114757537842, avg loss: 0.5231173545122146\n",
      "trial: 17, epoch, 19, iter: 1, curr loss: 0.5289878249168396, avg loss: 0.5289878249168396\n",
      "trial: 17, epoch, 19, iter: 200, curr loss: 0.5329008102416992, avg loss: 0.5236650723218917\n",
      "trial: 17, epoch, 20, iter: 1, curr loss: 0.5165543556213379, avg loss: 0.5165543556213379\n",
      "trial: 17, epoch, 20, iter: 200, curr loss: 0.5249326825141907, avg loss: 0.5230944380164146\n",
      "trial: 17, epoch, 21, iter: 1, curr loss: 0.5170801877975464, avg loss: 0.5170801877975464\n",
      "trial: 17, epoch, 21, iter: 200, curr loss: 0.5218749046325684, avg loss: 0.522718396782875\n",
      "trial: 17, epoch, 22, iter: 1, curr loss: 0.5271010398864746, avg loss: 0.5271010398864746\n",
      "trial: 17, epoch, 22, iter: 200, curr loss: 0.5305863618850708, avg loss: 0.5230282732844352\n",
      "trial: 17, epoch, 23, iter: 1, curr loss: 0.5298418998718262, avg loss: 0.5298418998718262\n",
      "trial: 17, epoch, 23, iter: 200, curr loss: 0.5288635492324829, avg loss: 0.5232007378339767\n",
      "trial: 17, epoch, 24, iter: 1, curr loss: 0.5266474485397339, avg loss: 0.5266474485397339\n",
      "trial: 17, epoch, 24, iter: 200, curr loss: 0.5303472280502319, avg loss: 0.5234220200777053\n",
      "trial: 17, epoch, 25, iter: 1, curr loss: 0.5294440984725952, avg loss: 0.5294440984725952\n",
      "trial: 17, epoch, 25, iter: 200, curr loss: 0.5353391766548157, avg loss: 0.5237099206447602\n",
      "trial: 17, epoch, 26, iter: 1, curr loss: 0.5244498252868652, avg loss: 0.5244498252868652\n",
      "trial: 17, epoch, 26, iter: 200, curr loss: 0.5230135917663574, avg loss: 0.5235267695784569\n",
      "trial: 17, epoch, 27, iter: 1, curr loss: 0.5265082120895386, avg loss: 0.5265082120895386\n",
      "trial: 17, epoch, 27, iter: 200, curr loss: 0.5335044860839844, avg loss: 0.5232562100887299\n",
      "trial: 17, epoch, 28, iter: 1, curr loss: 0.5218281745910645, avg loss: 0.5218281745910645\n",
      "trial: 17, epoch, 28, iter: 200, curr loss: 0.5414716005325317, avg loss: 0.5232686749100686\n",
      "trial: 17, epoch, 29, iter: 1, curr loss: 0.5283316969871521, avg loss: 0.5283316969871521\n",
      "trial: 17, epoch, 29, iter: 200, curr loss: 0.5213961601257324, avg loss: 0.5232559040188789\n",
      "trial: 17, epoch, 30, iter: 1, curr loss: 0.5185253620147705, avg loss: 0.5185253620147705\n",
      "trial: 17, epoch, 30, iter: 200, curr loss: 0.5358784794807434, avg loss: 0.5230025631189347\n",
      "trial: 17, epoch, 31, iter: 1, curr loss: 0.5249925851821899, avg loss: 0.5249925851821899\n",
      "trial: 17, epoch, 31, iter: 200, curr loss: 0.5243149995803833, avg loss: 0.5231933909654617\n",
      "trial: 17, epoch, 32, iter: 1, curr loss: 0.5373872518539429, avg loss: 0.5373872518539429\n",
      "trial: 17, epoch, 32, iter: 200, curr loss: 0.5196174383163452, avg loss: 0.5230765002965927\n",
      "trial: 17, epoch, 33, iter: 1, curr loss: 0.523544430732727, avg loss: 0.523544430732727\n",
      "trial: 17, epoch, 33, iter: 200, curr loss: 0.5263988971710205, avg loss: 0.5233068388700485\n",
      "trial: 17, epoch, 34, iter: 1, curr loss: 0.5219869613647461, avg loss: 0.5219869613647461\n",
      "trial: 17, epoch, 34, iter: 200, curr loss: 0.5272657871246338, avg loss: 0.5231300923228264\n",
      "trial: 17, epoch, 35, iter: 1, curr loss: 0.5274221897125244, avg loss: 0.5274221897125244\n",
      "trial: 17, epoch, 35, iter: 200, curr loss: 0.5265231132507324, avg loss: 0.5232192349433898\n",
      "trial: 17, epoch, 36, iter: 1, curr loss: 0.5168646574020386, avg loss: 0.5168646574020386\n",
      "trial: 17, epoch, 36, iter: 200, curr loss: 0.5212317109107971, avg loss: 0.5235174325108528\n",
      "trial: 17, epoch, 37, iter: 1, curr loss: 0.5228853821754456, avg loss: 0.5228853821754456\n",
      "trial: 17, epoch, 37, iter: 200, curr loss: 0.5195343494415283, avg loss: 0.5229356762766838\n",
      "trial: 17, epoch, 38, iter: 1, curr loss: 0.5367089509963989, avg loss: 0.5367089509963989\n",
      "trial: 17, epoch, 38, iter: 200, curr loss: 0.5233824253082275, avg loss: 0.5233279505372047\n",
      "trial: 17, epoch, 39, iter: 1, curr loss: 0.5244155526161194, avg loss: 0.5244155526161194\n",
      "trial: 17, epoch, 39, iter: 200, curr loss: 0.5200163722038269, avg loss: 0.523411937057972\n",
      "trial: 17, epoch, 40, iter: 1, curr loss: 0.531958818435669, avg loss: 0.531958818435669\n",
      "trial: 17, epoch, 40, iter: 200, curr loss: 0.5319136381149292, avg loss: 0.5231282529234886\n",
      "trial: 17, epoch, 41, iter: 1, curr loss: 0.507813572883606, avg loss: 0.507813572883606\n",
      "trial: 17, epoch, 41, iter: 200, curr loss: 0.5340386629104614, avg loss: 0.5234469518065452\n",
      "trial: 17, epoch, 42, iter: 1, curr loss: 0.5262477397918701, avg loss: 0.5262477397918701\n",
      "trial: 17, epoch, 42, iter: 200, curr loss: 0.5259677767753601, avg loss: 0.5230590471625328\n",
      "trial: 17, epoch, 43, iter: 1, curr loss: 0.5261999368667603, avg loss: 0.5261999368667603\n",
      "trial: 17, epoch, 43, iter: 200, curr loss: 0.5206989049911499, avg loss: 0.523554193675518\n",
      "trial: 17, epoch, 44, iter: 1, curr loss: 0.5262761116027832, avg loss: 0.5262761116027832\n",
      "trial: 17, epoch, 44, iter: 200, curr loss: 0.5391853451728821, avg loss: 0.5229260462522507\n",
      "trial: 17, epoch, 45, iter: 1, curr loss: 0.5231442451477051, avg loss: 0.5231442451477051\n",
      "trial: 17, epoch, 45, iter: 200, curr loss: 0.5240464806556702, avg loss: 0.5230802616477013\n",
      "trial: 17, epoch, 46, iter: 1, curr loss: 0.5275096893310547, avg loss: 0.5275096893310547\n",
      "trial: 17, epoch, 46, iter: 200, curr loss: 0.5250867009162903, avg loss: 0.5230051398277282\n",
      "trial: 17, epoch, 47, iter: 1, curr loss: 0.5189129114151001, avg loss: 0.5189129114151001\n",
      "trial: 17, epoch, 47, iter: 200, curr loss: 0.535621702671051, avg loss: 0.5229813602566719\n",
      "trial: 17, epoch, 48, iter: 1, curr loss: 0.5235822200775146, avg loss: 0.5235822200775146\n",
      "trial: 17, epoch, 48, iter: 200, curr loss: 0.5254107713699341, avg loss: 0.523211905658245\n",
      "trial: 17, epoch, 49, iter: 1, curr loss: 0.5222429037094116, avg loss: 0.5222429037094116\n",
      "trial: 17, epoch, 49, iter: 200, curr loss: 0.535537600517273, avg loss: 0.5231793347001076\n",
      "trial: 17, epoch, 50, iter: 1, curr loss: 0.5243914127349854, avg loss: 0.5243914127349854\n",
      "trial: 17, epoch, 50, iter: 200, curr loss: 0.5158134698867798, avg loss: 0.5229190072417259\n",
      "trial: 17, ldr: 0.5756392478942871, dv: 0.5638711452484131, nwj: 0.563801646232605\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 18, epoch, 1, iter: 1, curr loss: 0.69379061460495, avg loss: 0.69379061460495\n",
      "trial: 18, epoch, 1, iter: 200, curr loss: 0.5300522446632385, avg loss: 0.5354594391584396\n",
      "trial: 18, epoch, 2, iter: 1, curr loss: 0.5237013697624207, avg loss: 0.5237013697624207\n",
      "trial: 18, epoch, 2, iter: 200, curr loss: 0.5228883028030396, avg loss: 0.5250596916675567\n",
      "trial: 18, epoch, 3, iter: 1, curr loss: 0.5204100608825684, avg loss: 0.5204100608825684\n",
      "trial: 18, epoch, 3, iter: 200, curr loss: 0.515415370464325, avg loss: 0.5235469043254852\n",
      "trial: 18, epoch, 4, iter: 1, curr loss: 0.5314838886260986, avg loss: 0.5314838886260986\n",
      "trial: 18, epoch, 4, iter: 200, curr loss: 0.5283287763595581, avg loss: 0.5236490243673324\n",
      "trial: 18, epoch, 5, iter: 1, curr loss: 0.5258690118789673, avg loss: 0.5258690118789673\n",
      "trial: 18, epoch, 5, iter: 200, curr loss: 0.5261136293411255, avg loss: 0.5235196650028229\n",
      "trial: 18, epoch, 6, iter: 1, curr loss: 0.5323847532272339, avg loss: 0.5323847532272339\n",
      "trial: 18, epoch, 6, iter: 200, curr loss: 0.5290849208831787, avg loss: 0.5236011642217636\n",
      "trial: 18, epoch, 7, iter: 1, curr loss: 0.5313882827758789, avg loss: 0.5313882827758789\n",
      "trial: 18, epoch, 7, iter: 200, curr loss: 0.5224028825759888, avg loss: 0.5230168408155441\n",
      "trial: 18, epoch, 8, iter: 1, curr loss: 0.5209426879882812, avg loss: 0.5209426879882812\n",
      "trial: 18, epoch, 8, iter: 200, curr loss: 0.5191870331764221, avg loss: 0.5234111484885215\n",
      "trial: 18, epoch, 9, iter: 1, curr loss: 0.5312728881835938, avg loss: 0.5312728881835938\n",
      "trial: 18, epoch, 9, iter: 200, curr loss: 0.5246281623840332, avg loss: 0.5233345979452133\n",
      "trial: 18, epoch, 10, iter: 1, curr loss: 0.5256134271621704, avg loss: 0.5256134271621704\n",
      "trial: 18, epoch, 10, iter: 200, curr loss: 0.53513503074646, avg loss: 0.5233502897620201\n",
      "trial: 18, epoch, 11, iter: 1, curr loss: 0.5220104455947876, avg loss: 0.5220104455947876\n",
      "trial: 18, epoch, 11, iter: 200, curr loss: 0.5259103775024414, avg loss: 0.5233454963564873\n",
      "trial: 18, epoch, 12, iter: 1, curr loss: 0.5198276042938232, avg loss: 0.5198276042938232\n",
      "trial: 18, epoch, 12, iter: 200, curr loss: 0.5172672271728516, avg loss: 0.5233169287443161\n",
      "trial: 18, epoch, 13, iter: 1, curr loss: 0.5264856815338135, avg loss: 0.5264856815338135\n",
      "trial: 18, epoch, 13, iter: 200, curr loss: 0.5219312906265259, avg loss: 0.5238618564605713\n",
      "trial: 18, epoch, 14, iter: 1, curr loss: 0.5257824063301086, avg loss: 0.5257824063301086\n",
      "trial: 18, epoch, 14, iter: 200, curr loss: 0.5248831510543823, avg loss: 0.5231964176893235\n",
      "trial: 18, epoch, 15, iter: 1, curr loss: 0.5284291505813599, avg loss: 0.5284291505813599\n",
      "trial: 18, epoch, 15, iter: 200, curr loss: 0.5186964273452759, avg loss: 0.5232377135753632\n",
      "trial: 18, epoch, 16, iter: 1, curr loss: 0.5302002429962158, avg loss: 0.5302002429962158\n",
      "trial: 18, epoch, 16, iter: 200, curr loss: 0.5318281054496765, avg loss: 0.5231304734945297\n",
      "trial: 18, epoch, 17, iter: 1, curr loss: 0.5233941078186035, avg loss: 0.5233941078186035\n",
      "trial: 18, epoch, 17, iter: 200, curr loss: 0.5288076400756836, avg loss: 0.5234347248077392\n",
      "trial: 18, epoch, 18, iter: 1, curr loss: 0.529210090637207, avg loss: 0.529210090637207\n",
      "trial: 18, epoch, 18, iter: 200, curr loss: 0.5291922092437744, avg loss: 0.5235031372308732\n",
      "trial: 18, epoch, 19, iter: 1, curr loss: 0.5202770233154297, avg loss: 0.5202770233154297\n",
      "trial: 18, epoch, 19, iter: 200, curr loss: 0.5204068422317505, avg loss: 0.5230909365415574\n",
      "trial: 18, epoch, 20, iter: 1, curr loss: 0.518585205078125, avg loss: 0.518585205078125\n",
      "trial: 18, epoch, 20, iter: 200, curr loss: 0.5286665558815002, avg loss: 0.5236389777064323\n",
      "trial: 18, epoch, 21, iter: 1, curr loss: 0.5284489393234253, avg loss: 0.5284489393234253\n",
      "trial: 18, epoch, 21, iter: 200, curr loss: 0.5215215682983398, avg loss: 0.523502291738987\n",
      "trial: 18, epoch, 22, iter: 1, curr loss: 0.5358766317367554, avg loss: 0.5358766317367554\n",
      "trial: 18, epoch, 22, iter: 200, curr loss: 0.5289682149887085, avg loss: 0.5234107738733291\n",
      "trial: 18, epoch, 23, iter: 1, curr loss: 0.5254743695259094, avg loss: 0.5254743695259094\n",
      "trial: 18, epoch, 23, iter: 200, curr loss: 0.5221675038337708, avg loss: 0.5229111951589585\n",
      "trial: 18, epoch, 24, iter: 1, curr loss: 0.5286067724227905, avg loss: 0.5286067724227905\n",
      "trial: 18, epoch, 24, iter: 200, curr loss: 0.5282478332519531, avg loss: 0.5233469238877296\n",
      "trial: 18, epoch, 25, iter: 1, curr loss: 0.5385191440582275, avg loss: 0.5385191440582275\n",
      "trial: 18, epoch, 25, iter: 200, curr loss: 0.5276889801025391, avg loss: 0.5231036028265953\n",
      "trial: 18, epoch, 26, iter: 1, curr loss: 0.5272887945175171, avg loss: 0.5272887945175171\n",
      "trial: 18, epoch, 26, iter: 200, curr loss: 0.5239883065223694, avg loss: 0.5227615830302238\n",
      "trial: 18, epoch, 27, iter: 1, curr loss: 0.5224921703338623, avg loss: 0.5224921703338623\n",
      "trial: 18, epoch, 27, iter: 200, curr loss: 0.53325355052948, avg loss: 0.5229198580980301\n",
      "trial: 18, epoch, 28, iter: 1, curr loss: 0.5226712822914124, avg loss: 0.5226712822914124\n",
      "trial: 18, epoch, 28, iter: 200, curr loss: 0.5362173318862915, avg loss: 0.523281766474247\n",
      "trial: 18, epoch, 29, iter: 1, curr loss: 0.5216711163520813, avg loss: 0.5216711163520813\n",
      "trial: 18, epoch, 29, iter: 200, curr loss: 0.5235118865966797, avg loss: 0.5235361701250076\n",
      "trial: 18, epoch, 30, iter: 1, curr loss: 0.5267086625099182, avg loss: 0.5267086625099182\n",
      "trial: 18, epoch, 30, iter: 200, curr loss: 0.5320248603820801, avg loss: 0.5234983360767365\n",
      "trial: 18, epoch, 31, iter: 1, curr loss: 0.5263582468032837, avg loss: 0.5263582468032837\n",
      "trial: 18, epoch, 31, iter: 200, curr loss: 0.5299502611160278, avg loss: 0.5232081106305122\n",
      "trial: 18, epoch, 32, iter: 1, curr loss: 0.5341089963912964, avg loss: 0.5341089963912964\n",
      "trial: 18, epoch, 32, iter: 200, curr loss: 0.5126869678497314, avg loss: 0.5226959884166718\n",
      "trial: 18, epoch, 33, iter: 1, curr loss: 0.5231679677963257, avg loss: 0.5231679677963257\n",
      "trial: 18, epoch, 33, iter: 200, curr loss: 0.5228245258331299, avg loss: 0.5231230318546295\n",
      "trial: 18, epoch, 34, iter: 1, curr loss: 0.5283583402633667, avg loss: 0.5283583402633667\n",
      "trial: 18, epoch, 34, iter: 200, curr loss: 0.5153205990791321, avg loss: 0.5228445985913277\n",
      "trial: 18, epoch, 35, iter: 1, curr loss: 0.530588686466217, avg loss: 0.530588686466217\n",
      "trial: 18, epoch, 35, iter: 200, curr loss: 0.5293846130371094, avg loss: 0.5233185151219368\n",
      "trial: 18, epoch, 36, iter: 1, curr loss: 0.5310312509536743, avg loss: 0.5310312509536743\n",
      "trial: 18, epoch, 36, iter: 200, curr loss: 0.5152384638786316, avg loss: 0.5233387076854705\n",
      "trial: 18, epoch, 37, iter: 1, curr loss: 0.5300920009613037, avg loss: 0.5300920009613037\n",
      "trial: 18, epoch, 37, iter: 200, curr loss: 0.5282099843025208, avg loss: 0.5232958069443703\n",
      "trial: 18, epoch, 38, iter: 1, curr loss: 0.5346754789352417, avg loss: 0.5346754789352417\n",
      "trial: 18, epoch, 38, iter: 200, curr loss: 0.5361555814743042, avg loss: 0.522818631529808\n",
      "trial: 18, epoch, 39, iter: 1, curr loss: 0.5311471223831177, avg loss: 0.5311471223831177\n",
      "trial: 18, epoch, 39, iter: 200, curr loss: 0.521897554397583, avg loss: 0.522946030497551\n",
      "trial: 18, epoch, 40, iter: 1, curr loss: 0.5288307070732117, avg loss: 0.5288307070732117\n",
      "trial: 18, epoch, 40, iter: 200, curr loss: 0.5286464691162109, avg loss: 0.5230308377742767\n",
      "trial: 18, epoch, 41, iter: 1, curr loss: 0.5252296924591064, avg loss: 0.5252296924591064\n",
      "trial: 18, epoch, 41, iter: 200, curr loss: 0.5285198092460632, avg loss: 0.5234254908561706\n",
      "trial: 18, epoch, 42, iter: 1, curr loss: 0.5222166180610657, avg loss: 0.5222166180610657\n",
      "trial: 18, epoch, 42, iter: 200, curr loss: 0.5309951901435852, avg loss: 0.5234523105621338\n",
      "trial: 18, epoch, 43, iter: 1, curr loss: 0.5295025110244751, avg loss: 0.5295025110244751\n",
      "trial: 18, epoch, 43, iter: 200, curr loss: 0.5248444080352783, avg loss: 0.5232895237207412\n",
      "trial: 18, epoch, 44, iter: 1, curr loss: 0.5261960029602051, avg loss: 0.5261960029602051\n",
      "trial: 18, epoch, 44, iter: 200, curr loss: 0.5317944288253784, avg loss: 0.5233903509378434\n",
      "trial: 18, epoch, 45, iter: 1, curr loss: 0.535498857498169, avg loss: 0.535498857498169\n",
      "trial: 18, epoch, 45, iter: 200, curr loss: 0.5305619239807129, avg loss: 0.5234433269500732\n",
      "trial: 18, epoch, 46, iter: 1, curr loss: 0.5259790420532227, avg loss: 0.5259790420532227\n",
      "trial: 18, epoch, 46, iter: 200, curr loss: 0.5148615837097168, avg loss: 0.523565822839737\n",
      "trial: 18, epoch, 47, iter: 1, curr loss: 0.5233488082885742, avg loss: 0.5233488082885742\n",
      "trial: 18, epoch, 47, iter: 200, curr loss: 0.51795494556427, avg loss: 0.5235679370164871\n",
      "trial: 18, epoch, 48, iter: 1, curr loss: 0.5159264206886292, avg loss: 0.5159264206886292\n",
      "trial: 18, epoch, 48, iter: 200, curr loss: 0.523072361946106, avg loss: 0.5227322143316269\n",
      "trial: 18, epoch, 49, iter: 1, curr loss: 0.5274478197097778, avg loss: 0.5274478197097778\n",
      "trial: 18, epoch, 49, iter: 200, curr loss: 0.5169222354888916, avg loss: 0.5230146020650863\n",
      "trial: 18, epoch, 50, iter: 1, curr loss: 0.5252885818481445, avg loss: 0.5252885818481445\n",
      "trial: 18, epoch, 50, iter: 200, curr loss: 0.5252218246459961, avg loss: 0.5233300524950028\n",
      "trial: 18, ldr: 0.5698455572128296, dv: 0.5638680458068848, nwj: 0.5638501644134521\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 19, epoch, 1, iter: 1, curr loss: 0.6927430629730225, avg loss: 0.6927430629730225\n",
      "trial: 19, epoch, 1, iter: 200, curr loss: 0.5292792320251465, avg loss: 0.5350526568293571\n",
      "trial: 19, epoch, 2, iter: 1, curr loss: 0.5252189636230469, avg loss: 0.5252189636230469\n",
      "trial: 19, epoch, 2, iter: 200, curr loss: 0.5203068852424622, avg loss: 0.5241714054346085\n",
      "trial: 19, epoch, 3, iter: 1, curr loss: 0.5247231721878052, avg loss: 0.5247231721878052\n",
      "trial: 19, epoch, 3, iter: 200, curr loss: 0.5210130214691162, avg loss: 0.5238097116351128\n",
      "trial: 19, epoch, 4, iter: 1, curr loss: 0.5235569477081299, avg loss: 0.5235569477081299\n",
      "trial: 19, epoch, 4, iter: 200, curr loss: 0.5209317207336426, avg loss: 0.5236405238509179\n",
      "trial: 19, epoch, 5, iter: 1, curr loss: 0.5326408743858337, avg loss: 0.5326408743858337\n",
      "trial: 19, epoch, 5, iter: 200, curr loss: 0.5201492309570312, avg loss: 0.5234987080097199\n",
      "trial: 19, epoch, 6, iter: 1, curr loss: 0.5239900350570679, avg loss: 0.5239900350570679\n",
      "trial: 19, epoch, 6, iter: 200, curr loss: 0.517335832118988, avg loss: 0.5230890113115311\n",
      "trial: 19, epoch, 7, iter: 1, curr loss: 0.5230587720870972, avg loss: 0.5230587720870972\n",
      "trial: 19, epoch, 7, iter: 200, curr loss: 0.5142005681991577, avg loss: 0.5227280768752098\n",
      "trial: 19, epoch, 8, iter: 1, curr loss: 0.5243080854415894, avg loss: 0.5243080854415894\n",
      "trial: 19, epoch, 8, iter: 200, curr loss: 0.5327415466308594, avg loss: 0.5232742899656295\n",
      "trial: 19, epoch, 9, iter: 1, curr loss: 0.5249841213226318, avg loss: 0.5249841213226318\n",
      "trial: 19, epoch, 9, iter: 200, curr loss: 0.521984338760376, avg loss: 0.5232153806090355\n",
      "trial: 19, epoch, 10, iter: 1, curr loss: 0.5295249819755554, avg loss: 0.5295249819755554\n",
      "trial: 19, epoch, 10, iter: 200, curr loss: 0.5262637138366699, avg loss: 0.5234698292613029\n",
      "trial: 19, epoch, 11, iter: 1, curr loss: 0.5254407525062561, avg loss: 0.5254407525062561\n",
      "trial: 19, epoch, 11, iter: 200, curr loss: 0.5350709557533264, avg loss: 0.5231942313909531\n",
      "trial: 19, epoch, 12, iter: 1, curr loss: 0.5309266448020935, avg loss: 0.5309266448020935\n",
      "trial: 19, epoch, 12, iter: 200, curr loss: 0.5224318504333496, avg loss: 0.5231300303339959\n",
      "trial: 19, epoch, 13, iter: 1, curr loss: 0.527719259262085, avg loss: 0.527719259262085\n",
      "trial: 19, epoch, 13, iter: 200, curr loss: 0.5298136472702026, avg loss: 0.5229171013832092\n",
      "trial: 19, epoch, 14, iter: 1, curr loss: 0.5243960618972778, avg loss: 0.5243960618972778\n",
      "trial: 19, epoch, 14, iter: 200, curr loss: 0.5313596129417419, avg loss: 0.5234583336114883\n",
      "trial: 19, epoch, 15, iter: 1, curr loss: 0.5212958455085754, avg loss: 0.5212958455085754\n",
      "trial: 19, epoch, 15, iter: 200, curr loss: 0.5163512825965881, avg loss: 0.5236530187726021\n",
      "trial: 19, epoch, 16, iter: 1, curr loss: 0.520064115524292, avg loss: 0.520064115524292\n",
      "trial: 19, epoch, 16, iter: 200, curr loss: 0.5253357887268066, avg loss: 0.5235349220037461\n",
      "trial: 19, epoch, 17, iter: 1, curr loss: 0.5271119475364685, avg loss: 0.5271119475364685\n",
      "trial: 19, epoch, 17, iter: 200, curr loss: 0.522957444190979, avg loss: 0.5233490324020386\n",
      "trial: 19, epoch, 18, iter: 1, curr loss: 0.5225868225097656, avg loss: 0.5225868225097656\n",
      "trial: 19, epoch, 18, iter: 200, curr loss: 0.5255706310272217, avg loss: 0.5238065156340599\n",
      "trial: 19, epoch, 19, iter: 1, curr loss: 0.5182350277900696, avg loss: 0.5182350277900696\n",
      "trial: 19, epoch, 19, iter: 200, curr loss: 0.528487503528595, avg loss: 0.523362657725811\n",
      "trial: 19, epoch, 20, iter: 1, curr loss: 0.5254221558570862, avg loss: 0.5254221558570862\n",
      "trial: 19, epoch, 20, iter: 200, curr loss: 0.5228705406188965, avg loss: 0.5228834518790245\n",
      "trial: 19, epoch, 21, iter: 1, curr loss: 0.5210899114608765, avg loss: 0.5210899114608765\n",
      "trial: 19, epoch, 21, iter: 200, curr loss: 0.5191953778266907, avg loss: 0.5234643149375916\n",
      "trial: 19, epoch, 22, iter: 1, curr loss: 0.5330859422683716, avg loss: 0.5330859422683716\n",
      "trial: 19, epoch, 22, iter: 200, curr loss: 0.5189728736877441, avg loss: 0.5229954689741134\n",
      "trial: 19, epoch, 23, iter: 1, curr loss: 0.522916316986084, avg loss: 0.522916316986084\n",
      "trial: 19, epoch, 23, iter: 200, curr loss: 0.5328418016433716, avg loss: 0.5229693940281868\n",
      "trial: 19, epoch, 24, iter: 1, curr loss: 0.5181421041488647, avg loss: 0.5181421041488647\n",
      "trial: 19, epoch, 24, iter: 200, curr loss: 0.5192102193832397, avg loss: 0.5234110364317894\n",
      "trial: 19, epoch, 25, iter: 1, curr loss: 0.5306006073951721, avg loss: 0.5306006073951721\n",
      "trial: 19, epoch, 25, iter: 200, curr loss: 0.5281394124031067, avg loss: 0.523274227976799\n",
      "trial: 19, epoch, 26, iter: 1, curr loss: 0.5254836082458496, avg loss: 0.5254836082458496\n",
      "trial: 19, epoch, 26, iter: 200, curr loss: 0.5350915789604187, avg loss: 0.5232435202598572\n",
      "trial: 19, epoch, 27, iter: 1, curr loss: 0.5227335691452026, avg loss: 0.5227335691452026\n",
      "trial: 19, epoch, 27, iter: 200, curr loss: 0.5295880436897278, avg loss: 0.5231415396928787\n",
      "trial: 19, epoch, 28, iter: 1, curr loss: 0.5182344317436218, avg loss: 0.5182344317436218\n",
      "trial: 19, epoch, 28, iter: 200, curr loss: 0.5192707180976868, avg loss: 0.5233258873224258\n",
      "trial: 19, epoch, 29, iter: 1, curr loss: 0.524544894695282, avg loss: 0.524544894695282\n",
      "trial: 19, epoch, 29, iter: 200, curr loss: 0.526893138885498, avg loss: 0.5233050540089608\n",
      "trial: 19, epoch, 30, iter: 1, curr loss: 0.5204956531524658, avg loss: 0.5204956531524658\n",
      "trial: 19, epoch, 30, iter: 200, curr loss: 0.5365549921989441, avg loss: 0.5228514644503593\n",
      "trial: 19, epoch, 31, iter: 1, curr loss: 0.5266680121421814, avg loss: 0.5266680121421814\n",
      "trial: 19, epoch, 31, iter: 200, curr loss: 0.5224658250808716, avg loss: 0.523186514377594\n",
      "trial: 19, epoch, 32, iter: 1, curr loss: 0.5358049869537354, avg loss: 0.5358049869537354\n",
      "trial: 19, epoch, 32, iter: 200, curr loss: 0.5303570032119751, avg loss: 0.5230601477622986\n",
      "trial: 19, epoch, 33, iter: 1, curr loss: 0.524832546710968, avg loss: 0.524832546710968\n",
      "trial: 19, epoch, 33, iter: 200, curr loss: 0.532326877117157, avg loss: 0.5231449618935585\n",
      "trial: 19, epoch, 34, iter: 1, curr loss: 0.5267724990844727, avg loss: 0.5267724990844727\n",
      "trial: 19, epoch, 34, iter: 200, curr loss: 0.5236129760742188, avg loss: 0.5231863832473755\n",
      "trial: 19, epoch, 35, iter: 1, curr loss: 0.5224819183349609, avg loss: 0.5224819183349609\n",
      "trial: 19, epoch, 35, iter: 200, curr loss: 0.5220208168029785, avg loss: 0.5230657836794853\n",
      "trial: 19, epoch, 36, iter: 1, curr loss: 0.5210866928100586, avg loss: 0.5210866928100586\n",
      "trial: 19, epoch, 36, iter: 200, curr loss: 0.5311221480369568, avg loss: 0.5233057188987732\n",
      "trial: 19, epoch, 37, iter: 1, curr loss: 0.5335050225257874, avg loss: 0.5335050225257874\n",
      "trial: 19, epoch, 37, iter: 200, curr loss: 0.5334844589233398, avg loss: 0.5229824262857438\n",
      "trial: 19, epoch, 38, iter: 1, curr loss: 0.5147453546524048, avg loss: 0.5147453546524048\n",
      "trial: 19, epoch, 38, iter: 200, curr loss: 0.5140599012374878, avg loss: 0.5230813226103783\n",
      "trial: 19, epoch, 39, iter: 1, curr loss: 0.5245169401168823, avg loss: 0.5245169401168823\n",
      "trial: 19, epoch, 39, iter: 200, curr loss: 0.5193344950675964, avg loss: 0.5232717227935791\n",
      "trial: 19, epoch, 40, iter: 1, curr loss: 0.5251052379608154, avg loss: 0.5251052379608154\n",
      "trial: 19, epoch, 40, iter: 200, curr loss: 0.5188187956809998, avg loss: 0.523506860435009\n",
      "trial: 19, epoch, 41, iter: 1, curr loss: 0.5292620658874512, avg loss: 0.5292620658874512\n",
      "trial: 19, epoch, 41, iter: 200, curr loss: 0.5243691205978394, avg loss: 0.5232072800397873\n",
      "trial: 19, epoch, 42, iter: 1, curr loss: 0.5175715684890747, avg loss: 0.5175715684890747\n",
      "trial: 19, epoch, 42, iter: 200, curr loss: 0.525312066078186, avg loss: 0.5227497163414955\n",
      "trial: 19, epoch, 43, iter: 1, curr loss: 0.5268208980560303, avg loss: 0.5268208980560303\n",
      "trial: 19, epoch, 43, iter: 200, curr loss: 0.5242692232131958, avg loss: 0.522885434627533\n",
      "trial: 19, epoch, 44, iter: 1, curr loss: 0.5283399224281311, avg loss: 0.5283399224281311\n",
      "trial: 19, epoch, 44, iter: 200, curr loss: 0.5204546451568604, avg loss: 0.5232070711255074\n",
      "trial: 19, epoch, 45, iter: 1, curr loss: 0.5225247144699097, avg loss: 0.5225247144699097\n",
      "trial: 19, epoch, 45, iter: 200, curr loss: 0.5177409648895264, avg loss: 0.5226696744561196\n",
      "trial: 19, epoch, 46, iter: 1, curr loss: 0.5300189256668091, avg loss: 0.5300189256668091\n",
      "trial: 19, epoch, 46, iter: 200, curr loss: 0.5267936587333679, avg loss: 0.5230012553930282\n",
      "trial: 19, epoch, 47, iter: 1, curr loss: 0.5300558805465698, avg loss: 0.5300558805465698\n",
      "trial: 19, epoch, 47, iter: 200, curr loss: 0.5342414379119873, avg loss: 0.5230570331215858\n",
      "trial: 19, epoch, 48, iter: 1, curr loss: 0.5251829624176025, avg loss: 0.5251829624176025\n",
      "trial: 19, epoch, 48, iter: 200, curr loss: 0.5152922868728638, avg loss: 0.5234685641527176\n",
      "trial: 19, epoch, 49, iter: 1, curr loss: 0.527066707611084, avg loss: 0.527066707611084\n",
      "trial: 19, epoch, 49, iter: 200, curr loss: 0.5247215032577515, avg loss: 0.5231431829929352\n",
      "trial: 19, epoch, 50, iter: 1, curr loss: 0.5214855074882507, avg loss: 0.5214855074882507\n",
      "trial: 19, epoch, 50, iter: 200, curr loss: 0.5217714309692383, avg loss: 0.5232177737355233\n",
      "trial: 19, ldr: 0.5520779490470886, dv: 0.5639712810516357, nwj: 0.5639008283615112\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 20, epoch, 1, iter: 1, curr loss: 0.6933937072753906, avg loss: 0.6933937072753906\n",
      "trial: 20, epoch, 1, iter: 200, curr loss: 0.5268357992172241, avg loss: 0.5341906863451004\n",
      "trial: 20, epoch, 2, iter: 1, curr loss: 0.5331597328186035, avg loss: 0.5331597328186035\n",
      "trial: 20, epoch, 2, iter: 200, curr loss: 0.5327105522155762, avg loss: 0.5248017716407776\n",
      "trial: 20, epoch, 3, iter: 1, curr loss: 0.5186804533004761, avg loss: 0.5186804533004761\n",
      "trial: 20, epoch, 3, iter: 200, curr loss: 0.5258673429489136, avg loss: 0.5233660140633583\n",
      "trial: 20, epoch, 4, iter: 1, curr loss: 0.5322033762931824, avg loss: 0.5322033762931824\n",
      "trial: 20, epoch, 4, iter: 200, curr loss: 0.529381275177002, avg loss: 0.5234543469548225\n",
      "trial: 20, epoch, 5, iter: 1, curr loss: 0.5220352411270142, avg loss: 0.5220352411270142\n",
      "trial: 20, epoch, 5, iter: 200, curr loss: 0.5267752408981323, avg loss: 0.523190072774887\n",
      "trial: 20, epoch, 6, iter: 1, curr loss: 0.5232937335968018, avg loss: 0.5232937335968018\n",
      "trial: 20, epoch, 6, iter: 200, curr loss: 0.5302409529685974, avg loss: 0.5235075679421425\n",
      "trial: 20, epoch, 7, iter: 1, curr loss: 0.5271890163421631, avg loss: 0.5271890163421631\n",
      "trial: 20, epoch, 7, iter: 200, curr loss: 0.5171120166778564, avg loss: 0.522295001745224\n",
      "trial: 20, epoch, 8, iter: 1, curr loss: 0.5263351202011108, avg loss: 0.5263351202011108\n",
      "trial: 20, epoch, 8, iter: 200, curr loss: 0.5334000587463379, avg loss: 0.5238223725557327\n",
      "trial: 20, epoch, 9, iter: 1, curr loss: 0.5204293727874756, avg loss: 0.5204293727874756\n",
      "trial: 20, epoch, 9, iter: 200, curr loss: 0.5327886939048767, avg loss: 0.5233460575342178\n",
      "trial: 20, epoch, 10, iter: 1, curr loss: 0.5194029808044434, avg loss: 0.5194029808044434\n",
      "trial: 20, epoch, 10, iter: 200, curr loss: 0.5368978977203369, avg loss: 0.5228433725237847\n",
      "trial: 20, epoch, 11, iter: 1, curr loss: 0.5273557901382446, avg loss: 0.5273557901382446\n",
      "trial: 20, epoch, 11, iter: 200, curr loss: 0.5217670202255249, avg loss: 0.5230027359724044\n",
      "trial: 20, epoch, 12, iter: 1, curr loss: 0.5424739122390747, avg loss: 0.5424739122390747\n",
      "trial: 20, epoch, 12, iter: 200, curr loss: 0.5251917243003845, avg loss: 0.5233006569743156\n",
      "trial: 20, epoch, 13, iter: 1, curr loss: 0.5275030136108398, avg loss: 0.5275030136108398\n",
      "trial: 20, epoch, 13, iter: 200, curr loss: 0.5334199666976929, avg loss: 0.5234751856327057\n",
      "trial: 20, epoch, 14, iter: 1, curr loss: 0.5263476371765137, avg loss: 0.5263476371765137\n",
      "trial: 20, epoch, 14, iter: 200, curr loss: 0.524927020072937, avg loss: 0.5232907244563103\n",
      "trial: 20, epoch, 15, iter: 1, curr loss: 0.5280835032463074, avg loss: 0.5280835032463074\n",
      "trial: 20, epoch, 15, iter: 200, curr loss: 0.5269700288772583, avg loss: 0.5230367720127106\n",
      "trial: 20, epoch, 16, iter: 1, curr loss: 0.530095100402832, avg loss: 0.530095100402832\n",
      "trial: 20, epoch, 16, iter: 200, curr loss: 0.5287396311759949, avg loss: 0.5231104478240013\n",
      "trial: 20, epoch, 17, iter: 1, curr loss: 0.5249554514884949, avg loss: 0.5249554514884949\n",
      "trial: 20, epoch, 17, iter: 200, curr loss: 0.5219897031784058, avg loss: 0.5236086690425873\n",
      "trial: 20, epoch, 18, iter: 1, curr loss: 0.5275716781616211, avg loss: 0.5275716781616211\n",
      "trial: 20, epoch, 18, iter: 200, curr loss: 0.5221914649009705, avg loss: 0.5232899889349938\n",
      "trial: 20, epoch, 19, iter: 1, curr loss: 0.5296151638031006, avg loss: 0.5296151638031006\n",
      "trial: 20, epoch, 19, iter: 200, curr loss: 0.5266498327255249, avg loss: 0.5238246405124665\n",
      "trial: 20, epoch, 20, iter: 1, curr loss: 0.5262454748153687, avg loss: 0.5262454748153687\n",
      "trial: 20, epoch, 20, iter: 200, curr loss: 0.5296176075935364, avg loss: 0.5236120736598968\n",
      "trial: 20, epoch, 21, iter: 1, curr loss: 0.5232235193252563, avg loss: 0.5232235193252563\n",
      "trial: 20, epoch, 21, iter: 200, curr loss: 0.5121697187423706, avg loss: 0.5232826378941536\n",
      "trial: 20, epoch, 22, iter: 1, curr loss: 0.5291223526000977, avg loss: 0.5291223526000977\n",
      "trial: 20, epoch, 22, iter: 200, curr loss: 0.5286641120910645, avg loss: 0.523451859652996\n",
      "trial: 20, epoch, 23, iter: 1, curr loss: 0.5316497087478638, avg loss: 0.5316497087478638\n",
      "trial: 20, epoch, 23, iter: 200, curr loss: 0.5292874574661255, avg loss: 0.523156191110611\n",
      "trial: 20, epoch, 24, iter: 1, curr loss: 0.5253896713256836, avg loss: 0.5253896713256836\n",
      "trial: 20, epoch, 24, iter: 200, curr loss: 0.517525315284729, avg loss: 0.5232060649991035\n",
      "trial: 20, epoch, 25, iter: 1, curr loss: 0.5345485210418701, avg loss: 0.5345485210418701\n",
      "trial: 20, epoch, 25, iter: 200, curr loss: 0.5267893671989441, avg loss: 0.5232301384210587\n",
      "trial: 20, epoch, 26, iter: 1, curr loss: 0.5242074728012085, avg loss: 0.5242074728012085\n",
      "trial: 20, epoch, 26, iter: 200, curr loss: 0.5227990746498108, avg loss: 0.523322349190712\n",
      "trial: 20, epoch, 27, iter: 1, curr loss: 0.5313910245895386, avg loss: 0.5313910245895386\n",
      "trial: 20, epoch, 27, iter: 200, curr loss: 0.5332008004188538, avg loss: 0.523362478017807\n",
      "trial: 20, epoch, 28, iter: 1, curr loss: 0.5308157205581665, avg loss: 0.5308157205581665\n",
      "trial: 20, epoch, 28, iter: 200, curr loss: 0.525170087814331, avg loss: 0.5230126196146011\n",
      "trial: 20, epoch, 29, iter: 1, curr loss: 0.5196870565414429, avg loss: 0.5196870565414429\n",
      "trial: 20, epoch, 29, iter: 200, curr loss: 0.5194543600082397, avg loss: 0.5227265760302544\n",
      "trial: 20, epoch, 30, iter: 1, curr loss: 0.535545825958252, avg loss: 0.535545825958252\n",
      "trial: 20, epoch, 30, iter: 200, curr loss: 0.5153537392616272, avg loss: 0.5236099353432655\n",
      "trial: 20, epoch, 31, iter: 1, curr loss: 0.5359753370285034, avg loss: 0.5359753370285034\n",
      "trial: 20, epoch, 31, iter: 200, curr loss: 0.5236383676528931, avg loss: 0.5224861532449723\n",
      "trial: 20, epoch, 32, iter: 1, curr loss: 0.5192546248435974, avg loss: 0.5192546248435974\n",
      "trial: 20, epoch, 32, iter: 200, curr loss: 0.5301549434661865, avg loss: 0.5240958359837532\n",
      "trial: 20, epoch, 33, iter: 1, curr loss: 0.5218729972839355, avg loss: 0.5218729972839355\n",
      "trial: 20, epoch, 33, iter: 200, curr loss: 0.5403752326965332, avg loss: 0.523372118473053\n",
      "trial: 20, epoch, 34, iter: 1, curr loss: 0.5296840667724609, avg loss: 0.5296840667724609\n",
      "trial: 20, epoch, 34, iter: 200, curr loss: 0.5217902660369873, avg loss: 0.523245961368084\n",
      "trial: 20, epoch, 35, iter: 1, curr loss: 0.5166798830032349, avg loss: 0.5166798830032349\n",
      "trial: 20, epoch, 35, iter: 200, curr loss: 0.5313740968704224, avg loss: 0.5231633022427559\n",
      "trial: 20, epoch, 36, iter: 1, curr loss: 0.5211983323097229, avg loss: 0.5211983323097229\n",
      "trial: 20, epoch, 36, iter: 200, curr loss: 0.5219458341598511, avg loss: 0.523074412047863\n",
      "trial: 20, epoch, 37, iter: 1, curr loss: 0.5241212844848633, avg loss: 0.5241212844848633\n",
      "trial: 20, epoch, 37, iter: 200, curr loss: 0.5286767482757568, avg loss: 0.5237615972757339\n",
      "trial: 20, epoch, 38, iter: 1, curr loss: 0.5214577913284302, avg loss: 0.5214577913284302\n",
      "trial: 20, epoch, 38, iter: 200, curr loss: 0.5252252221107483, avg loss: 0.5229695808887481\n",
      "trial: 20, epoch, 39, iter: 1, curr loss: 0.5292083621025085, avg loss: 0.5292083621025085\n",
      "trial: 20, epoch, 39, iter: 200, curr loss: 0.5178425908088684, avg loss: 0.5227987825870514\n",
      "trial: 20, epoch, 40, iter: 1, curr loss: 0.5304131507873535, avg loss: 0.5304131507873535\n",
      "trial: 20, epoch, 40, iter: 200, curr loss: 0.5351566672325134, avg loss: 0.522825055718422\n",
      "trial: 20, epoch, 41, iter: 1, curr loss: 0.5155034065246582, avg loss: 0.5155034065246582\n",
      "trial: 20, epoch, 41, iter: 200, curr loss: 0.5222663283348083, avg loss: 0.5233945924043656\n",
      "trial: 20, epoch, 42, iter: 1, curr loss: 0.5246959924697876, avg loss: 0.5246959924697876\n",
      "trial: 20, epoch, 42, iter: 200, curr loss: 0.519750714302063, avg loss: 0.5233724036812782\n",
      "trial: 20, epoch, 43, iter: 1, curr loss: 0.5285578966140747, avg loss: 0.5285578966140747\n",
      "trial: 20, epoch, 43, iter: 200, curr loss: 0.5362139940261841, avg loss: 0.5234815812110901\n",
      "trial: 20, epoch, 44, iter: 1, curr loss: 0.5334935188293457, avg loss: 0.5334935188293457\n",
      "trial: 20, epoch, 44, iter: 200, curr loss: 0.5213332772254944, avg loss: 0.5231661066412926\n",
      "trial: 20, epoch, 45, iter: 1, curr loss: 0.5345544219017029, avg loss: 0.5345544219017029\n",
      "trial: 20, epoch, 45, iter: 200, curr loss: 0.5345965027809143, avg loss: 0.5229820892214775\n",
      "trial: 20, epoch, 46, iter: 1, curr loss: 0.5249882936477661, avg loss: 0.5249882936477661\n",
      "trial: 20, epoch, 46, iter: 200, curr loss: 0.5298649072647095, avg loss: 0.5230703958868981\n",
      "trial: 20, epoch, 47, iter: 1, curr loss: 0.5263746976852417, avg loss: 0.5263746976852417\n",
      "trial: 20, epoch, 47, iter: 200, curr loss: 0.5198900103569031, avg loss: 0.5231028303503991\n",
      "trial: 20, epoch, 48, iter: 1, curr loss: 0.5238672494888306, avg loss: 0.5238672494888306\n",
      "trial: 20, epoch, 48, iter: 200, curr loss: 0.5229408740997314, avg loss: 0.5229954639077187\n",
      "trial: 20, epoch, 49, iter: 1, curr loss: 0.5168868899345398, avg loss: 0.5168868899345398\n",
      "trial: 20, epoch, 49, iter: 200, curr loss: 0.5278415679931641, avg loss: 0.5234139543771744\n",
      "trial: 20, epoch, 50, iter: 1, curr loss: 0.5324420928955078, avg loss: 0.5324420928955078\n",
      "trial: 20, epoch, 50, iter: 200, curr loss: 0.5193995237350464, avg loss: 0.5232365411520005\n",
      "trial: 20, ldr: 0.5710060596466064, dv: 0.5639556646347046, nwj: 0.5639307498931885\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.5674752503633499\n",
      "\tdv: 0.5638414323329926\n",
      "\tnwj: 0.5637658536434174\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 20\n",
    "num_of_inner_iteration = 50\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    print('################################################################')\n",
    "    model, inner_running_loss, inner_running_loss_avg, num_of_joint, num_of_marginal = train_binary_classifier_v2(data, label, num_input_features, hidden_size_arr, lr, num_of_inner_iteration, batch_size, outer_iter, save_avg=200, print_progress=True)\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    curr_ldr, curr_dv, curr_nwj = estimate_mi_for_binary_classification(model, joint_data, num_of_joint, marginal_data, num_of_marginal)\n",
    "    print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "    print('################################################################\\n')\n",
    "    ldr_estimations.append(curr_ldr.item())\n",
    "    dv_estimations.append(curr_dv.item())\n",
    "    nwj_estimations.append(curr_nwj.item())\n",
    "    \n",
    "print('final estimations:\\n\\tldr: {}\\n\\tdv: {}\\n\\tnwj: {}'.format(np.mean(ldr_estimations), np.mean(dv_estimations), np.mean(nwj_estimations)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
