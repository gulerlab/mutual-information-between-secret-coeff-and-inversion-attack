{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T21:59:52.983277901Z",
     "start_time": "2023-11-20T21:59:51.911433451Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lcc.dataset import create_lcc_dataset_k1_t1_scalar\n",
    "\n",
    "from probabilistic_classifier.dataset import create_joint_marginal_dataset\n",
    "from probabilistic_classifier.estimate import estimate_mi_for_binary_classification\n",
    "from probabilistic_classifier.train import train_binary_classifier_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# create the basis dataset\n",
    "prime = 5\n",
    "data_range = 2\n",
    "num_of_samples = 800000\n",
    "weight = 1\n",
    "dataset = create_lcc_dataset_k1_t1_scalar(prime, data_range, num_of_samples, weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:03:09.382696638Z",
     "start_time": "2023-11-20T21:59:52.984392949Z"
    }
   },
   "id": "d52797b0247350ca"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = np.concatenate([dataset[:, :3], dataset[:, 4:]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:03:09.434271202Z",
     "start_time": "2023-11-20T22:03:09.423612896Z"
    }
   },
   "id": "ed2f70bcfd6065fe"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "x_idx, y_idx, z_idx = [0, 1], [3, 4, 5], [2]\n",
    "yz_idx = [2, 3, 4, 5]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_joint_marginal_dataset(dataset, x_idx, yz_idx)\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:03:09.456813729Z",
     "start_time": "2023-11-20T22:03:09.423723410Z"
    }
   },
   "id": "62da61c8fc32e6fa"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(yz_idx)\n",
    "hidden_size_arr = [256, 256, 256]\n",
    "lr = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:03:09.456973323Z",
     "start_time": "2023-11-20T22:03:09.439993393Z"
    }
   },
   "id": "4cb99642d6db7215"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, epoch, 1, iter: 1, curr loss: 0.6964414715766907, avg loss: 0.6964414715766907\n",
      "trial: 1, epoch, 2, iter: 1, curr loss: 0.4438747763633728, avg loss: 0.4438747763633728\n",
      "trial: 1, epoch, 3, iter: 1, curr loss: 0.4465521574020386, avg loss: 0.4465521574020386\n",
      "trial: 1, epoch, 4, iter: 1, curr loss: 0.43235599994659424, avg loss: 0.43235599994659424\n",
      "trial: 1, epoch, 5, iter: 1, curr loss: 0.42525187134742737, avg loss: 0.42525187134742737\n",
      "trial: 1, epoch, 6, iter: 1, curr loss: 0.43201443552970886, avg loss: 0.43201443552970886\n",
      "trial: 1, epoch, 7, iter: 1, curr loss: 0.4363255500793457, avg loss: 0.4363255500793457\n",
      "trial: 1, epoch, 8, iter: 1, curr loss: 0.43732601404190063, avg loss: 0.43732601404190063\n",
      "trial: 1, epoch, 9, iter: 1, curr loss: 0.43077680468559265, avg loss: 0.43077680468559265\n",
      "trial: 1, epoch, 10, iter: 1, curr loss: 0.4282991290092468, avg loss: 0.4282991290092468\n",
      "trial: 1, epoch, 11, iter: 1, curr loss: 0.431566059589386, avg loss: 0.431566059589386\n",
      "trial: 1, epoch, 12, iter: 1, curr loss: 0.42548584938049316, avg loss: 0.42548584938049316\n",
      "trial: 1, epoch, 13, iter: 1, curr loss: 0.4274126887321472, avg loss: 0.4274126887321472\n",
      "trial: 1, epoch, 14, iter: 1, curr loss: 0.4312358796596527, avg loss: 0.4312358796596527\n",
      "trial: 1, epoch, 15, iter: 1, curr loss: 0.4271755516529083, avg loss: 0.4271755516529083\n",
      "trial: 1, epoch, 16, iter: 1, curr loss: 0.4225120544433594, avg loss: 0.4225120544433594\n",
      "trial: 1, epoch, 17, iter: 1, curr loss: 0.4373835027217865, avg loss: 0.4373835027217865\n",
      "trial: 1, epoch, 18, iter: 1, curr loss: 0.420092910528183, avg loss: 0.420092910528183\n",
      "trial: 1, epoch, 19, iter: 1, curr loss: 0.43494945764541626, avg loss: 0.43494945764541626\n",
      "trial: 1, epoch, 20, iter: 1, curr loss: 0.4140017628669739, avg loss: 0.4140017628669739\n",
      "trial: 1, epoch, 21, iter: 1, curr loss: 0.4359070956707001, avg loss: 0.4359070956707001\n",
      "trial: 1, epoch, 22, iter: 1, curr loss: 0.42965006828308105, avg loss: 0.42965006828308105\n",
      "trial: 1, epoch, 23, iter: 1, curr loss: 0.43753018975257874, avg loss: 0.43753018975257874\n",
      "trial: 1, epoch, 24, iter: 1, curr loss: 0.4243190884590149, avg loss: 0.4243190884590149\n",
      "trial: 1, epoch, 25, iter: 1, curr loss: 0.42652562260627747, avg loss: 0.42652562260627747\n",
      "trial: 1, epoch, 26, iter: 1, curr loss: 0.4328707158565521, avg loss: 0.4328707158565521\n",
      "trial: 1, epoch, 27, iter: 1, curr loss: 0.43566447496414185, avg loss: 0.43566447496414185\n",
      "trial: 1, epoch, 28, iter: 1, curr loss: 0.4207123816013336, avg loss: 0.4207123816013336\n",
      "trial: 1, epoch, 29, iter: 1, curr loss: 0.42924273014068604, avg loss: 0.42924273014068604\n",
      "trial: 1, epoch, 30, iter: 1, curr loss: 0.42675715684890747, avg loss: 0.42675715684890747\n",
      "trial: 1, epoch, 31, iter: 1, curr loss: 0.4119061827659607, avg loss: 0.4119061827659607\n",
      "trial: 1, epoch, 32, iter: 1, curr loss: 0.42580586671829224, avg loss: 0.42580586671829224\n",
      "trial: 1, epoch, 33, iter: 1, curr loss: 0.42648953199386597, avg loss: 0.42648953199386597\n",
      "trial: 1, epoch, 34, iter: 1, curr loss: 0.4339193105697632, avg loss: 0.4339193105697632\n",
      "trial: 1, epoch, 35, iter: 1, curr loss: 0.4459027945995331, avg loss: 0.4459027945995331\n",
      "trial: 1, epoch, 36, iter: 1, curr loss: 0.42975783348083496, avg loss: 0.42975783348083496\n",
      "trial: 1, epoch, 37, iter: 1, curr loss: 0.44331908226013184, avg loss: 0.44331908226013184\n",
      "trial: 1, epoch, 38, iter: 1, curr loss: 0.42471984028816223, avg loss: 0.42471984028816223\n",
      "trial: 1, epoch, 39, iter: 1, curr loss: 0.42865243554115295, avg loss: 0.42865243554115295\n",
      "trial: 1, epoch, 40, iter: 1, curr loss: 0.4223310351371765, avg loss: 0.4223310351371765\n",
      "trial: 1, epoch, 41, iter: 1, curr loss: 0.43501928448677063, avg loss: 0.43501928448677063\n",
      "trial: 1, epoch, 42, iter: 1, curr loss: 0.4155816435813904, avg loss: 0.4155816435813904\n",
      "trial: 1, epoch, 43, iter: 1, curr loss: 0.4342474639415741, avg loss: 0.4342474639415741\n",
      "trial: 1, epoch, 44, iter: 1, curr loss: 0.42720162868499756, avg loss: 0.42720162868499756\n",
      "trial: 1, epoch, 45, iter: 1, curr loss: 0.4345470666885376, avg loss: 0.4345470666885376\n",
      "trial: 1, epoch, 46, iter: 1, curr loss: 0.4400639832019806, avg loss: 0.4400639832019806\n",
      "trial: 1, epoch, 47, iter: 1, curr loss: 0.42607828974723816, avg loss: 0.42607828974723816\n",
      "trial: 1, epoch, 48, iter: 1, curr loss: 0.4339701533317566, avg loss: 0.4339701533317566\n",
      "trial: 1, epoch, 49, iter: 1, curr loss: 0.43737125396728516, avg loss: 0.43737125396728516\n",
      "trial: 1, epoch, 50, iter: 1, curr loss: 0.4366943836212158, avg loss: 0.4366943836212158\n",
      "trial: 1, ldr: 0.9652754664421082, dv: 0.9111401438713074, nwj: 0.9096480011940002\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, epoch, 1, iter: 1, curr loss: 0.6958749294281006, avg loss: 0.6958749294281006\n",
      "trial: 2, epoch, 2, iter: 1, curr loss: 0.43807610869407654, avg loss: 0.43807610869407654\n",
      "trial: 2, epoch, 3, iter: 1, curr loss: 0.42174413800239563, avg loss: 0.42174413800239563\n",
      "trial: 2, epoch, 4, iter: 1, curr loss: 0.43063852190971375, avg loss: 0.43063852190971375\n",
      "trial: 2, epoch, 5, iter: 1, curr loss: 0.4227813482284546, avg loss: 0.4227813482284546\n",
      "trial: 2, epoch, 6, iter: 1, curr loss: 0.43583813309669495, avg loss: 0.43583813309669495\n",
      "trial: 2, epoch, 7, iter: 1, curr loss: 0.4326504170894623, avg loss: 0.4326504170894623\n",
      "trial: 2, epoch, 8, iter: 1, curr loss: 0.4274284839630127, avg loss: 0.4274284839630127\n",
      "trial: 2, epoch, 9, iter: 1, curr loss: 0.43041789531707764, avg loss: 0.43041789531707764\n",
      "trial: 2, epoch, 10, iter: 1, curr loss: 0.42608460783958435, avg loss: 0.42608460783958435\n",
      "trial: 2, epoch, 11, iter: 1, curr loss: 0.4390243887901306, avg loss: 0.4390243887901306\n",
      "trial: 2, epoch, 12, iter: 1, curr loss: 0.42607948184013367, avg loss: 0.42607948184013367\n",
      "trial: 2, epoch, 13, iter: 1, curr loss: 0.4398561120033264, avg loss: 0.4398561120033264\n",
      "trial: 2, epoch, 14, iter: 1, curr loss: 0.4340013265609741, avg loss: 0.4340013265609741\n",
      "trial: 2, epoch, 15, iter: 1, curr loss: 0.41972965002059937, avg loss: 0.41972965002059937\n",
      "trial: 2, epoch, 16, iter: 1, curr loss: 0.432015061378479, avg loss: 0.432015061378479\n",
      "trial: 2, epoch, 17, iter: 1, curr loss: 0.4149857759475708, avg loss: 0.4149857759475708\n",
      "trial: 2, epoch, 18, iter: 1, curr loss: 0.4343045949935913, avg loss: 0.4343045949935913\n",
      "trial: 2, epoch, 19, iter: 1, curr loss: 0.433991014957428, avg loss: 0.433991014957428\n",
      "trial: 2, epoch, 20, iter: 1, curr loss: 0.44119301438331604, avg loss: 0.44119301438331604\n",
      "trial: 2, epoch, 21, iter: 1, curr loss: 0.44349390268325806, avg loss: 0.44349390268325806\n",
      "trial: 2, epoch, 22, iter: 1, curr loss: 0.437345415353775, avg loss: 0.437345415353775\n",
      "trial: 2, epoch, 23, iter: 1, curr loss: 0.42948660254478455, avg loss: 0.42948660254478455\n",
      "trial: 2, epoch, 24, iter: 1, curr loss: 0.42609915137290955, avg loss: 0.42609915137290955\n",
      "trial: 2, epoch, 25, iter: 1, curr loss: 0.435089647769928, avg loss: 0.435089647769928\n",
      "trial: 2, epoch, 26, iter: 1, curr loss: 0.42645126581192017, avg loss: 0.42645126581192017\n",
      "trial: 2, epoch, 27, iter: 1, curr loss: 0.4294498860836029, avg loss: 0.4294498860836029\n",
      "trial: 2, epoch, 28, iter: 1, curr loss: 0.4333675503730774, avg loss: 0.4333675503730774\n",
      "trial: 2, epoch, 29, iter: 1, curr loss: 0.44042712450027466, avg loss: 0.44042712450027466\n",
      "trial: 2, epoch, 30, iter: 1, curr loss: 0.42728880047798157, avg loss: 0.42728880047798157\n",
      "trial: 2, epoch, 31, iter: 1, curr loss: 0.43119293451309204, avg loss: 0.43119293451309204\n",
      "trial: 2, epoch, 32, iter: 1, curr loss: 0.4249388873577118, avg loss: 0.4249388873577118\n",
      "trial: 2, epoch, 33, iter: 1, curr loss: 0.4335145354270935, avg loss: 0.4335145354270935\n",
      "trial: 2, epoch, 34, iter: 1, curr loss: 0.42215511202812195, avg loss: 0.42215511202812195\n",
      "trial: 2, epoch, 35, iter: 1, curr loss: 0.433104008436203, avg loss: 0.433104008436203\n",
      "trial: 2, epoch, 36, iter: 1, curr loss: 0.4283193349838257, avg loss: 0.4283193349838257\n",
      "trial: 2, epoch, 37, iter: 1, curr loss: 0.42764848470687866, avg loss: 0.42764848470687866\n",
      "trial: 2, epoch, 38, iter: 1, curr loss: 0.43646240234375, avg loss: 0.43646240234375\n",
      "trial: 2, epoch, 39, iter: 1, curr loss: 0.43309327960014343, avg loss: 0.43309327960014343\n",
      "trial: 2, epoch, 40, iter: 1, curr loss: 0.4186239242553711, avg loss: 0.4186239242553711\n",
      "trial: 2, epoch, 41, iter: 1, curr loss: 0.4465664029121399, avg loss: 0.4465664029121399\n",
      "trial: 2, epoch, 42, iter: 1, curr loss: 0.43908312916755676, avg loss: 0.43908312916755676\n",
      "trial: 2, epoch, 43, iter: 1, curr loss: 0.4350469708442688, avg loss: 0.4350469708442688\n",
      "trial: 2, epoch, 44, iter: 1, curr loss: 0.4331892132759094, avg loss: 0.4331892132759094\n",
      "trial: 2, epoch, 45, iter: 1, curr loss: 0.4335501790046692, avg loss: 0.4335501790046692\n",
      "trial: 2, epoch, 46, iter: 1, curr loss: 0.42822086811065674, avg loss: 0.42822086811065674\n",
      "trial: 2, epoch, 47, iter: 1, curr loss: 0.429809033870697, avg loss: 0.429809033870697\n",
      "trial: 2, epoch, 48, iter: 1, curr loss: 0.4265802502632141, avg loss: 0.4265802502632141\n",
      "trial: 2, epoch, 49, iter: 1, curr loss: 0.4287726581096649, avg loss: 0.4287726581096649\n",
      "trial: 2, epoch, 50, iter: 1, curr loss: 0.43135079741477966, avg loss: 0.43135079741477966\n",
      "trial: 2, ldr: 0.9167444705963135, dv: 0.9126641750335693, nwj: 0.9126558303833008\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, epoch, 1, iter: 1, curr loss: 0.6931319236755371, avg loss: 0.6931319236755371\n",
      "trial: 3, epoch, 2, iter: 1, curr loss: 0.45111435651779175, avg loss: 0.45111435651779175\n",
      "trial: 3, epoch, 3, iter: 1, curr loss: 0.43462419509887695, avg loss: 0.43462419509887695\n",
      "trial: 3, epoch, 4, iter: 1, curr loss: 0.42924341559410095, avg loss: 0.42924341559410095\n",
      "trial: 3, epoch, 5, iter: 1, curr loss: 0.43290799856185913, avg loss: 0.43290799856185913\n",
      "trial: 3, epoch, 6, iter: 1, curr loss: 0.4370992183685303, avg loss: 0.4370992183685303\n",
      "trial: 3, epoch, 7, iter: 1, curr loss: 0.4311460256576538, avg loss: 0.4311460256576538\n",
      "trial: 3, epoch, 8, iter: 1, curr loss: 0.42385560274124146, avg loss: 0.42385560274124146\n",
      "trial: 3, epoch, 9, iter: 1, curr loss: 0.4457956850528717, avg loss: 0.4457956850528717\n",
      "trial: 3, epoch, 10, iter: 1, curr loss: 0.4335256814956665, avg loss: 0.4335256814956665\n",
      "trial: 3, epoch, 11, iter: 1, curr loss: 0.4326191246509552, avg loss: 0.4326191246509552\n",
      "trial: 3, epoch, 12, iter: 1, curr loss: 0.4276207685470581, avg loss: 0.4276207685470581\n",
      "trial: 3, epoch, 13, iter: 1, curr loss: 0.4374069571495056, avg loss: 0.4374069571495056\n",
      "trial: 3, epoch, 14, iter: 1, curr loss: 0.4214751124382019, avg loss: 0.4214751124382019\n",
      "trial: 3, epoch, 15, iter: 1, curr loss: 0.43420183658599854, avg loss: 0.43420183658599854\n",
      "trial: 3, epoch, 16, iter: 1, curr loss: 0.4393905699253082, avg loss: 0.4393905699253082\n",
      "trial: 3, epoch, 17, iter: 1, curr loss: 0.4387762248516083, avg loss: 0.4387762248516083\n",
      "trial: 3, epoch, 18, iter: 1, curr loss: 0.4357921779155731, avg loss: 0.4357921779155731\n",
      "trial: 3, epoch, 19, iter: 1, curr loss: 0.4344538748264313, avg loss: 0.4344538748264313\n",
      "trial: 3, epoch, 20, iter: 1, curr loss: 0.4321380853652954, avg loss: 0.4321380853652954\n",
      "trial: 3, epoch, 21, iter: 1, curr loss: 0.4230296015739441, avg loss: 0.4230296015739441\n",
      "trial: 3, epoch, 22, iter: 1, curr loss: 0.4323643147945404, avg loss: 0.4323643147945404\n",
      "trial: 3, epoch, 23, iter: 1, curr loss: 0.4362172484397888, avg loss: 0.4362172484397888\n",
      "trial: 3, epoch, 24, iter: 1, curr loss: 0.4237588942050934, avg loss: 0.4237588942050934\n",
      "trial: 3, epoch, 25, iter: 1, curr loss: 0.4352377653121948, avg loss: 0.4352377653121948\n",
      "trial: 3, epoch, 26, iter: 1, curr loss: 0.4271107316017151, avg loss: 0.4271107316017151\n",
      "trial: 3, epoch, 27, iter: 1, curr loss: 0.42908430099487305, avg loss: 0.42908430099487305\n",
      "trial: 3, epoch, 28, iter: 1, curr loss: 0.4327666759490967, avg loss: 0.4327666759490967\n",
      "trial: 3, epoch, 29, iter: 1, curr loss: 0.4383429288864136, avg loss: 0.4383429288864136\n",
      "trial: 3, epoch, 30, iter: 1, curr loss: 0.42502227425575256, avg loss: 0.42502227425575256\n",
      "trial: 3, epoch, 31, iter: 1, curr loss: 0.42547059059143066, avg loss: 0.42547059059143066\n",
      "trial: 3, epoch, 32, iter: 1, curr loss: 0.42088058590888977, avg loss: 0.42088058590888977\n",
      "trial: 3, epoch, 33, iter: 1, curr loss: 0.43353402614593506, avg loss: 0.43353402614593506\n",
      "trial: 3, epoch, 34, iter: 1, curr loss: 0.4304202198982239, avg loss: 0.4304202198982239\n",
      "trial: 3, epoch, 35, iter: 1, curr loss: 0.4305839538574219, avg loss: 0.4305839538574219\n",
      "trial: 3, epoch, 36, iter: 1, curr loss: 0.4336789846420288, avg loss: 0.4336789846420288\n",
      "trial: 3, epoch, 37, iter: 1, curr loss: 0.43737339973449707, avg loss: 0.43737339973449707\n",
      "trial: 3, epoch, 38, iter: 1, curr loss: 0.4214852452278137, avg loss: 0.4214852452278137\n",
      "trial: 3, epoch, 39, iter: 1, curr loss: 0.42494308948516846, avg loss: 0.42494308948516846\n",
      "trial: 3, epoch, 40, iter: 1, curr loss: 0.442801833152771, avg loss: 0.442801833152771\n",
      "trial: 3, epoch, 41, iter: 1, curr loss: 0.4344196617603302, avg loss: 0.4344196617603302\n",
      "trial: 3, epoch, 42, iter: 1, curr loss: 0.42932161688804626, avg loss: 0.42932161688804626\n",
      "trial: 3, epoch, 43, iter: 1, curr loss: 0.4338388442993164, avg loss: 0.4338388442993164\n",
      "trial: 3, epoch, 44, iter: 1, curr loss: 0.43654510378837585, avg loss: 0.43654510378837585\n",
      "trial: 3, epoch, 45, iter: 1, curr loss: 0.42399829626083374, avg loss: 0.42399829626083374\n",
      "trial: 3, epoch, 46, iter: 1, curr loss: 0.42321181297302246, avg loss: 0.42321181297302246\n",
      "trial: 3, epoch, 47, iter: 1, curr loss: 0.4281504154205322, avg loss: 0.4281504154205322\n",
      "trial: 3, epoch, 48, iter: 1, curr loss: 0.430133581161499, avg loss: 0.430133581161499\n",
      "trial: 3, epoch, 49, iter: 1, curr loss: 0.42380595207214355, avg loss: 0.42380595207214355\n",
      "trial: 3, epoch, 50, iter: 1, curr loss: 0.42973366379737854, avg loss: 0.42973366379737854\n",
      "trial: 3, ldr: 0.9726763367652893, dv: 0.9102503061294556, nwj: 0.9082606434822083\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, epoch, 1, iter: 1, curr loss: 0.6989659667015076, avg loss: 0.6989659667015076\n",
      "trial: 4, epoch, 2, iter: 1, curr loss: 0.43598631024360657, avg loss: 0.43598631024360657\n",
      "trial: 4, epoch, 3, iter: 1, curr loss: 0.42856210470199585, avg loss: 0.42856210470199585\n",
      "trial: 4, epoch, 4, iter: 1, curr loss: 0.41940927505493164, avg loss: 0.41940927505493164\n",
      "trial: 4, epoch, 5, iter: 1, curr loss: 0.43035757541656494, avg loss: 0.43035757541656494\n",
      "trial: 4, epoch, 6, iter: 1, curr loss: 0.4377461075782776, avg loss: 0.4377461075782776\n",
      "trial: 4, epoch, 7, iter: 1, curr loss: 0.43121984601020813, avg loss: 0.43121984601020813\n",
      "trial: 4, epoch, 8, iter: 1, curr loss: 0.43228989839553833, avg loss: 0.43228989839553833\n",
      "trial: 4, epoch, 9, iter: 1, curr loss: 0.4285040497779846, avg loss: 0.4285040497779846\n",
      "trial: 4, epoch, 10, iter: 1, curr loss: 0.43142449855804443, avg loss: 0.43142449855804443\n",
      "trial: 4, epoch, 11, iter: 1, curr loss: 0.4232005774974823, avg loss: 0.4232005774974823\n",
      "trial: 4, epoch, 12, iter: 1, curr loss: 0.42974111437797546, avg loss: 0.42974111437797546\n",
      "trial: 4, epoch, 13, iter: 1, curr loss: 0.43290817737579346, avg loss: 0.43290817737579346\n",
      "trial: 4, epoch, 14, iter: 1, curr loss: 0.42525458335876465, avg loss: 0.42525458335876465\n",
      "trial: 4, epoch, 15, iter: 1, curr loss: 0.4333178400993347, avg loss: 0.4333178400993347\n",
      "trial: 4, epoch, 16, iter: 1, curr loss: 0.4201831519603729, avg loss: 0.4201831519603729\n",
      "trial: 4, epoch, 17, iter: 1, curr loss: 0.4305639863014221, avg loss: 0.4305639863014221\n",
      "trial: 4, epoch, 18, iter: 1, curr loss: 0.43290913105010986, avg loss: 0.43290913105010986\n",
      "trial: 4, epoch, 19, iter: 1, curr loss: 0.4285293519496918, avg loss: 0.4285293519496918\n",
      "trial: 4, epoch, 20, iter: 1, curr loss: 0.4372561573982239, avg loss: 0.4372561573982239\n",
      "trial: 4, epoch, 21, iter: 1, curr loss: 0.4323464632034302, avg loss: 0.4323464632034302\n",
      "trial: 4, epoch, 22, iter: 1, curr loss: 0.4215584099292755, avg loss: 0.4215584099292755\n",
      "trial: 4, epoch, 23, iter: 1, curr loss: 0.43329137563705444, avg loss: 0.43329137563705444\n",
      "trial: 4, epoch, 24, iter: 1, curr loss: 0.43427109718322754, avg loss: 0.43427109718322754\n",
      "trial: 4, epoch, 25, iter: 1, curr loss: 0.42006516456604004, avg loss: 0.42006516456604004\n",
      "trial: 4, epoch, 26, iter: 1, curr loss: 0.4257029891014099, avg loss: 0.4257029891014099\n",
      "trial: 4, epoch, 27, iter: 1, curr loss: 0.4333082437515259, avg loss: 0.4333082437515259\n",
      "trial: 4, epoch, 28, iter: 1, curr loss: 0.4246505796909332, avg loss: 0.4246505796909332\n",
      "trial: 4, epoch, 29, iter: 1, curr loss: 0.4207504093647003, avg loss: 0.4207504093647003\n",
      "trial: 4, epoch, 30, iter: 1, curr loss: 0.4250233769416809, avg loss: 0.4250233769416809\n",
      "trial: 4, epoch, 31, iter: 1, curr loss: 0.4249553382396698, avg loss: 0.4249553382396698\n",
      "trial: 4, epoch, 32, iter: 1, curr loss: 0.4404340386390686, avg loss: 0.4404340386390686\n",
      "trial: 4, epoch, 33, iter: 1, curr loss: 0.41644325852394104, avg loss: 0.41644325852394104\n",
      "trial: 4, epoch, 34, iter: 1, curr loss: 0.4362506866455078, avg loss: 0.4362506866455078\n",
      "trial: 4, epoch, 35, iter: 1, curr loss: 0.43858814239501953, avg loss: 0.43858814239501953\n",
      "trial: 4, epoch, 36, iter: 1, curr loss: 0.43571314215660095, avg loss: 0.43571314215660095\n",
      "trial: 4, epoch, 37, iter: 1, curr loss: 0.4307090640068054, avg loss: 0.4307090640068054\n",
      "trial: 4, epoch, 38, iter: 1, curr loss: 0.42356306314468384, avg loss: 0.42356306314468384\n",
      "trial: 4, epoch, 39, iter: 1, curr loss: 0.43341854214668274, avg loss: 0.43341854214668274\n",
      "trial: 4, epoch, 40, iter: 1, curr loss: 0.4194604754447937, avg loss: 0.4194604754447937\n",
      "trial: 4, epoch, 41, iter: 1, curr loss: 0.427470862865448, avg loss: 0.427470862865448\n",
      "trial: 4, epoch, 42, iter: 1, curr loss: 0.42895427346229553, avg loss: 0.42895427346229553\n",
      "trial: 4, epoch, 43, iter: 1, curr loss: 0.4256211519241333, avg loss: 0.4256211519241333\n",
      "trial: 4, epoch, 44, iter: 1, curr loss: 0.4270283579826355, avg loss: 0.4270283579826355\n",
      "trial: 4, epoch, 45, iter: 1, curr loss: 0.4225766658782959, avg loss: 0.4225766658782959\n",
      "trial: 4, epoch, 46, iter: 1, curr loss: 0.4266536831855774, avg loss: 0.4266536831855774\n",
      "trial: 4, epoch, 47, iter: 1, curr loss: 0.42276376485824585, avg loss: 0.42276376485824585\n",
      "trial: 4, epoch, 48, iter: 1, curr loss: 0.4262866675853729, avg loss: 0.4262866675853729\n",
      "trial: 4, epoch, 49, iter: 1, curr loss: 0.4326210021972656, avg loss: 0.4326210021972656\n",
      "trial: 4, epoch, 50, iter: 1, curr loss: 0.42630285024642944, avg loss: 0.42630285024642944\n",
      "trial: 4, ldr: 0.9931736588478088, dv: 0.9132509827613831, nwj: 0.9099703431129456\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, epoch, 1, iter: 1, curr loss: 0.693691611289978, avg loss: 0.693691611289978\n",
      "trial: 5, epoch, 2, iter: 1, curr loss: 0.4375762343406677, avg loss: 0.4375762343406677\n",
      "trial: 5, epoch, 3, iter: 1, curr loss: 0.42721015214920044, avg loss: 0.42721015214920044\n",
      "trial: 5, epoch, 4, iter: 1, curr loss: 0.43436673283576965, avg loss: 0.43436673283576965\n",
      "trial: 5, epoch, 5, iter: 1, curr loss: 0.4422035217285156, avg loss: 0.4422035217285156\n",
      "trial: 5, epoch, 6, iter: 1, curr loss: 0.4284663200378418, avg loss: 0.4284663200378418\n",
      "trial: 5, epoch, 7, iter: 1, curr loss: 0.4351545572280884, avg loss: 0.4351545572280884\n",
      "trial: 5, epoch, 8, iter: 1, curr loss: 0.43048277497291565, avg loss: 0.43048277497291565\n",
      "trial: 5, epoch, 9, iter: 1, curr loss: 0.43173909187316895, avg loss: 0.43173909187316895\n",
      "trial: 5, epoch, 10, iter: 1, curr loss: 0.43287181854248047, avg loss: 0.43287181854248047\n",
      "trial: 5, epoch, 11, iter: 1, curr loss: 0.4291446805000305, avg loss: 0.4291446805000305\n",
      "trial: 5, epoch, 12, iter: 1, curr loss: 0.4420126676559448, avg loss: 0.4420126676559448\n",
      "trial: 5, epoch, 13, iter: 1, curr loss: 0.4245612621307373, avg loss: 0.4245612621307373\n",
      "trial: 5, epoch, 14, iter: 1, curr loss: 0.4321569502353668, avg loss: 0.4321569502353668\n",
      "trial: 5, epoch, 15, iter: 1, curr loss: 0.43467506766319275, avg loss: 0.43467506766319275\n",
      "trial: 5, epoch, 16, iter: 1, curr loss: 0.43265581130981445, avg loss: 0.43265581130981445\n",
      "trial: 5, epoch, 17, iter: 1, curr loss: 0.42791008949279785, avg loss: 0.42791008949279785\n",
      "trial: 5, epoch, 18, iter: 1, curr loss: 0.42551684379577637, avg loss: 0.42551684379577637\n",
      "trial: 5, epoch, 19, iter: 1, curr loss: 0.44313955307006836, avg loss: 0.44313955307006836\n",
      "trial: 5, epoch, 20, iter: 1, curr loss: 0.43164336681365967, avg loss: 0.43164336681365967\n",
      "trial: 5, epoch, 21, iter: 1, curr loss: 0.4265557825565338, avg loss: 0.4265557825565338\n",
      "trial: 5, epoch, 22, iter: 1, curr loss: 0.4226038157939911, avg loss: 0.4226038157939911\n",
      "trial: 5, epoch, 23, iter: 1, curr loss: 0.44376063346862793, avg loss: 0.44376063346862793\n",
      "trial: 5, epoch, 24, iter: 1, curr loss: 0.4300280511379242, avg loss: 0.4300280511379242\n",
      "trial: 5, epoch, 25, iter: 1, curr loss: 0.43648213148117065, avg loss: 0.43648213148117065\n",
      "trial: 5, epoch, 26, iter: 1, curr loss: 0.4087485074996948, avg loss: 0.4087485074996948\n",
      "trial: 5, epoch, 27, iter: 1, curr loss: 0.4266960620880127, avg loss: 0.4266960620880127\n",
      "trial: 5, epoch, 28, iter: 1, curr loss: 0.4410710036754608, avg loss: 0.4410710036754608\n",
      "trial: 5, epoch, 29, iter: 1, curr loss: 0.42571380734443665, avg loss: 0.42571380734443665\n",
      "trial: 5, epoch, 30, iter: 1, curr loss: 0.4378240704536438, avg loss: 0.4378240704536438\n",
      "trial: 5, epoch, 31, iter: 1, curr loss: 0.41988080739974976, avg loss: 0.41988080739974976\n",
      "trial: 5, epoch, 32, iter: 1, curr loss: 0.42859750986099243, avg loss: 0.42859750986099243\n",
      "trial: 5, epoch, 33, iter: 1, curr loss: 0.4358851909637451, avg loss: 0.4358851909637451\n",
      "trial: 5, epoch, 34, iter: 1, curr loss: 0.44111499190330505, avg loss: 0.44111499190330505\n",
      "trial: 5, epoch, 35, iter: 1, curr loss: 0.44379881024360657, avg loss: 0.44379881024360657\n",
      "trial: 5, epoch, 36, iter: 1, curr loss: 0.42728593945503235, avg loss: 0.42728593945503235\n",
      "trial: 5, epoch, 37, iter: 1, curr loss: 0.4268677830696106, avg loss: 0.4268677830696106\n",
      "trial: 5, epoch, 38, iter: 1, curr loss: 0.4237367510795593, avg loss: 0.4237367510795593\n",
      "trial: 5, epoch, 39, iter: 1, curr loss: 0.4350660443305969, avg loss: 0.4350660443305969\n",
      "trial: 5, epoch, 40, iter: 1, curr loss: 0.440931499004364, avg loss: 0.440931499004364\n",
      "trial: 5, epoch, 41, iter: 1, curr loss: 0.43019425868988037, avg loss: 0.43019425868988037\n",
      "trial: 5, epoch, 42, iter: 1, curr loss: 0.4235002398490906, avg loss: 0.4235002398490906\n",
      "trial: 5, epoch, 43, iter: 1, curr loss: 0.44189465045928955, avg loss: 0.44189465045928955\n",
      "trial: 5, epoch, 44, iter: 1, curr loss: 0.42030343413352966, avg loss: 0.42030343413352966\n",
      "trial: 5, epoch, 45, iter: 1, curr loss: 0.42910537123680115, avg loss: 0.42910537123680115\n",
      "trial: 5, epoch, 46, iter: 1, curr loss: 0.4412396550178528, avg loss: 0.4412396550178528\n",
      "trial: 5, epoch, 47, iter: 1, curr loss: 0.43243658542633057, avg loss: 0.43243658542633057\n",
      "trial: 5, epoch, 48, iter: 1, curr loss: 0.4327744245529175, avg loss: 0.4327744245529175\n",
      "trial: 5, epoch, 49, iter: 1, curr loss: 0.4318983256816864, avg loss: 0.4318983256816864\n",
      "trial: 5, epoch, 50, iter: 1, curr loss: 0.42115628719329834, avg loss: 0.42115628719329834\n",
      "trial: 5, ldr: 0.9040921926498413, dv: 0.9127949476242065, nwj: 0.9127572178840637\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 6, epoch, 1, iter: 1, curr loss: 0.6982213854789734, avg loss: 0.6982213854789734\n",
      "trial: 6, epoch, 2, iter: 1, curr loss: 0.4373524785041809, avg loss: 0.4373524785041809\n",
      "trial: 6, epoch, 3, iter: 1, curr loss: 0.447961688041687, avg loss: 0.447961688041687\n",
      "trial: 6, epoch, 4, iter: 1, curr loss: 0.4196149706840515, avg loss: 0.4196149706840515\n",
      "trial: 6, epoch, 5, iter: 1, curr loss: 0.44044506549835205, avg loss: 0.44044506549835205\n",
      "trial: 6, epoch, 6, iter: 1, curr loss: 0.4415421187877655, avg loss: 0.4415421187877655\n",
      "trial: 6, epoch, 7, iter: 1, curr loss: 0.43602490425109863, avg loss: 0.43602490425109863\n",
      "trial: 6, epoch, 8, iter: 1, curr loss: 0.4272698760032654, avg loss: 0.4272698760032654\n",
      "trial: 6, epoch, 9, iter: 1, curr loss: 0.4289683401584625, avg loss: 0.4289683401584625\n",
      "trial: 6, epoch, 10, iter: 1, curr loss: 0.4431999921798706, avg loss: 0.4431999921798706\n",
      "trial: 6, epoch, 11, iter: 1, curr loss: 0.43522095680236816, avg loss: 0.43522095680236816\n",
      "trial: 6, epoch, 12, iter: 1, curr loss: 0.4323307275772095, avg loss: 0.4323307275772095\n",
      "trial: 6, epoch, 13, iter: 1, curr loss: 0.43590065836906433, avg loss: 0.43590065836906433\n",
      "trial: 6, epoch, 14, iter: 1, curr loss: 0.4273567795753479, avg loss: 0.4273567795753479\n",
      "trial: 6, epoch, 15, iter: 1, curr loss: 0.4402617812156677, avg loss: 0.4402617812156677\n",
      "trial: 6, epoch, 16, iter: 1, curr loss: 0.4307037591934204, avg loss: 0.4307037591934204\n",
      "trial: 6, epoch, 17, iter: 1, curr loss: 0.43619969487190247, avg loss: 0.43619969487190247\n",
      "trial: 6, epoch, 18, iter: 1, curr loss: 0.42768675088882446, avg loss: 0.42768675088882446\n",
      "trial: 6, epoch, 19, iter: 1, curr loss: 0.43503648042678833, avg loss: 0.43503648042678833\n",
      "trial: 6, epoch, 20, iter: 1, curr loss: 0.4336490333080292, avg loss: 0.4336490333080292\n",
      "trial: 6, epoch, 21, iter: 1, curr loss: 0.4258957505226135, avg loss: 0.4258957505226135\n",
      "trial: 6, epoch, 22, iter: 1, curr loss: 0.4321594834327698, avg loss: 0.4321594834327698\n",
      "trial: 6, epoch, 23, iter: 1, curr loss: 0.43281304836273193, avg loss: 0.43281304836273193\n",
      "trial: 6, epoch, 24, iter: 1, curr loss: 0.4313086271286011, avg loss: 0.4313086271286011\n",
      "trial: 6, epoch, 25, iter: 1, curr loss: 0.43396276235580444, avg loss: 0.43396276235580444\n",
      "trial: 6, epoch, 26, iter: 1, curr loss: 0.4257107079029083, avg loss: 0.4257107079029083\n",
      "trial: 6, epoch, 27, iter: 1, curr loss: 0.43453752994537354, avg loss: 0.43453752994537354\n",
      "trial: 6, epoch, 28, iter: 1, curr loss: 0.42959529161453247, avg loss: 0.42959529161453247\n",
      "trial: 6, epoch, 29, iter: 1, curr loss: 0.42570990324020386, avg loss: 0.42570990324020386\n",
      "trial: 6, epoch, 30, iter: 1, curr loss: 0.42146605253219604, avg loss: 0.42146605253219604\n",
      "trial: 6, epoch, 31, iter: 1, curr loss: 0.43417495489120483, avg loss: 0.43417495489120483\n",
      "trial: 6, epoch, 32, iter: 1, curr loss: 0.4271228313446045, avg loss: 0.4271228313446045\n",
      "trial: 6, epoch, 33, iter: 1, curr loss: 0.42412063479423523, avg loss: 0.42412063479423523\n",
      "trial: 6, epoch, 34, iter: 1, curr loss: 0.4340907037258148, avg loss: 0.4340907037258148\n",
      "trial: 6, epoch, 35, iter: 1, curr loss: 0.4244645833969116, avg loss: 0.4244645833969116\n",
      "trial: 6, epoch, 36, iter: 1, curr loss: 0.4355967044830322, avg loss: 0.4355967044830322\n",
      "trial: 6, epoch, 37, iter: 1, curr loss: 0.4298485815525055, avg loss: 0.4298485815525055\n",
      "trial: 6, epoch, 38, iter: 1, curr loss: 0.42838340997695923, avg loss: 0.42838340997695923\n",
      "trial: 6, epoch, 39, iter: 1, curr loss: 0.43490755558013916, avg loss: 0.43490755558013916\n",
      "trial: 6, epoch, 40, iter: 1, curr loss: 0.4301433265209198, avg loss: 0.4301433265209198\n",
      "trial: 6, epoch, 41, iter: 1, curr loss: 0.4292174279689789, avg loss: 0.4292174279689789\n",
      "trial: 6, epoch, 42, iter: 1, curr loss: 0.4289916753768921, avg loss: 0.4289916753768921\n",
      "trial: 6, epoch, 43, iter: 1, curr loss: 0.4286981225013733, avg loss: 0.4286981225013733\n",
      "trial: 6, epoch, 44, iter: 1, curr loss: 0.4179864823818207, avg loss: 0.4179864823818207\n",
      "trial: 6, epoch, 45, iter: 1, curr loss: 0.4294728636741638, avg loss: 0.4294728636741638\n",
      "trial: 6, epoch, 46, iter: 1, curr loss: 0.4450375735759735, avg loss: 0.4450375735759735\n",
      "trial: 6, epoch, 47, iter: 1, curr loss: 0.4230085611343384, avg loss: 0.4230085611343384\n",
      "trial: 6, epoch, 48, iter: 1, curr loss: 0.42460036277770996, avg loss: 0.42460036277770996\n",
      "trial: 6, epoch, 49, iter: 1, curr loss: 0.42742013931274414, avg loss: 0.42742013931274414\n",
      "trial: 6, epoch, 50, iter: 1, curr loss: 0.429168164730072, avg loss: 0.429168164730072\n",
      "trial: 6, ldr: 0.9211351275444031, dv: 0.9129682779312134, nwj: 0.9129348397254944\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 7, epoch, 1, iter: 1, curr loss: 0.6959981918334961, avg loss: 0.6959981918334961\n",
      "trial: 7, epoch, 2, iter: 1, curr loss: 0.4345319867134094, avg loss: 0.4345319867134094\n",
      "trial: 7, epoch, 3, iter: 1, curr loss: 0.42574653029441833, avg loss: 0.42574653029441833\n",
      "trial: 7, epoch, 4, iter: 1, curr loss: 0.4368073344230652, avg loss: 0.4368073344230652\n",
      "trial: 7, epoch, 5, iter: 1, curr loss: 0.4302108883857727, avg loss: 0.4302108883857727\n",
      "trial: 7, epoch, 6, iter: 1, curr loss: 0.4310451149940491, avg loss: 0.4310451149940491\n",
      "trial: 7, epoch, 7, iter: 1, curr loss: 0.4404580295085907, avg loss: 0.4404580295085907\n",
      "trial: 7, epoch, 8, iter: 1, curr loss: 0.4270184636116028, avg loss: 0.4270184636116028\n",
      "trial: 7, epoch, 9, iter: 1, curr loss: 0.4242236614227295, avg loss: 0.4242236614227295\n",
      "trial: 7, epoch, 10, iter: 1, curr loss: 0.44416314363479614, avg loss: 0.44416314363479614\n",
      "trial: 7, epoch, 11, iter: 1, curr loss: 0.42865508794784546, avg loss: 0.42865508794784546\n",
      "trial: 7, epoch, 12, iter: 1, curr loss: 0.4230714738368988, avg loss: 0.4230714738368988\n",
      "trial: 7, epoch, 13, iter: 1, curr loss: 0.43455904722213745, avg loss: 0.43455904722213745\n",
      "trial: 7, epoch, 14, iter: 1, curr loss: 0.4343951642513275, avg loss: 0.4343951642513275\n",
      "trial: 7, epoch, 15, iter: 1, curr loss: 0.43030399084091187, avg loss: 0.43030399084091187\n",
      "trial: 7, epoch, 16, iter: 1, curr loss: 0.4481238126754761, avg loss: 0.4481238126754761\n",
      "trial: 7, epoch, 17, iter: 1, curr loss: 0.42737895250320435, avg loss: 0.42737895250320435\n",
      "trial: 7, epoch, 18, iter: 1, curr loss: 0.44237375259399414, avg loss: 0.44237375259399414\n",
      "trial: 7, epoch, 19, iter: 1, curr loss: 0.4271591603755951, avg loss: 0.4271591603755951\n",
      "trial: 7, epoch, 20, iter: 1, curr loss: 0.4356781840324402, avg loss: 0.4356781840324402\n",
      "trial: 7, epoch, 21, iter: 1, curr loss: 0.42791905999183655, avg loss: 0.42791905999183655\n",
      "trial: 7, epoch, 22, iter: 1, curr loss: 0.42815959453582764, avg loss: 0.42815959453582764\n",
      "trial: 7, epoch, 23, iter: 1, curr loss: 0.439033567905426, avg loss: 0.439033567905426\n",
      "trial: 7, epoch, 24, iter: 1, curr loss: 0.4312279224395752, avg loss: 0.4312279224395752\n",
      "trial: 7, epoch, 25, iter: 1, curr loss: 0.4380131959915161, avg loss: 0.4380131959915161\n",
      "trial: 7, epoch, 26, iter: 1, curr loss: 0.42437463998794556, avg loss: 0.42437463998794556\n",
      "trial: 7, epoch, 27, iter: 1, curr loss: 0.4340396523475647, avg loss: 0.4340396523475647\n",
      "trial: 7, epoch, 28, iter: 1, curr loss: 0.4244559109210968, avg loss: 0.4244559109210968\n",
      "trial: 7, epoch, 29, iter: 1, curr loss: 0.4364962577819824, avg loss: 0.4364962577819824\n",
      "trial: 7, epoch, 30, iter: 1, curr loss: 0.42200180888175964, avg loss: 0.42200180888175964\n",
      "trial: 7, epoch, 31, iter: 1, curr loss: 0.42910945415496826, avg loss: 0.42910945415496826\n",
      "trial: 7, epoch, 32, iter: 1, curr loss: 0.4367061257362366, avg loss: 0.4367061257362366\n",
      "trial: 7, epoch, 33, iter: 1, curr loss: 0.4434906840324402, avg loss: 0.4434906840324402\n",
      "trial: 7, epoch, 34, iter: 1, curr loss: 0.4418424963951111, avg loss: 0.4418424963951111\n",
      "trial: 7, epoch, 35, iter: 1, curr loss: 0.4358951449394226, avg loss: 0.4358951449394226\n",
      "trial: 7, epoch, 36, iter: 1, curr loss: 0.43313807249069214, avg loss: 0.43313807249069214\n",
      "trial: 7, epoch, 37, iter: 1, curr loss: 0.4399576485157013, avg loss: 0.4399576485157013\n",
      "trial: 7, epoch, 38, iter: 1, curr loss: 0.41461050510406494, avg loss: 0.41461050510406494\n",
      "trial: 7, epoch, 39, iter: 1, curr loss: 0.42871248722076416, avg loss: 0.42871248722076416\n",
      "trial: 7, epoch, 40, iter: 1, curr loss: 0.4230053424835205, avg loss: 0.4230053424835205\n",
      "trial: 7, epoch, 41, iter: 1, curr loss: 0.44247347116470337, avg loss: 0.44247347116470337\n",
      "trial: 7, epoch, 42, iter: 1, curr loss: 0.43227529525756836, avg loss: 0.43227529525756836\n",
      "trial: 7, epoch, 43, iter: 1, curr loss: 0.42133623361587524, avg loss: 0.42133623361587524\n",
      "trial: 7, epoch, 44, iter: 1, curr loss: 0.42900481820106506, avg loss: 0.42900481820106506\n",
      "trial: 7, epoch, 45, iter: 1, curr loss: 0.42277228832244873, avg loss: 0.42277228832244873\n",
      "trial: 7, epoch, 46, iter: 1, curr loss: 0.4414653182029724, avg loss: 0.4414653182029724\n",
      "trial: 7, epoch, 47, iter: 1, curr loss: 0.43461522459983826, avg loss: 0.43461522459983826\n",
      "trial: 7, epoch, 48, iter: 1, curr loss: 0.429164320230484, avg loss: 0.429164320230484\n",
      "trial: 7, epoch, 49, iter: 1, curr loss: 0.41281503438949585, avg loss: 0.41281503438949585\n",
      "trial: 7, epoch, 50, iter: 1, curr loss: 0.4307034909725189, avg loss: 0.4307034909725189\n",
      "trial: 7, ldr: 0.8207160234451294, dv: 0.9125956296920776, nwj: 0.9085010290145874\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 8, epoch, 1, iter: 1, curr loss: 0.6957988739013672, avg loss: 0.6957988739013672\n",
      "trial: 8, epoch, 2, iter: 1, curr loss: 0.44201603531837463, avg loss: 0.44201603531837463\n",
      "trial: 8, epoch, 3, iter: 1, curr loss: 0.44275420904159546, avg loss: 0.44275420904159546\n",
      "trial: 8, epoch, 4, iter: 1, curr loss: 0.44588208198547363, avg loss: 0.44588208198547363\n",
      "trial: 8, epoch, 5, iter: 1, curr loss: 0.44596660137176514, avg loss: 0.44596660137176514\n",
      "trial: 8, epoch, 6, iter: 1, curr loss: 0.4281887412071228, avg loss: 0.4281887412071228\n",
      "trial: 8, epoch, 7, iter: 1, curr loss: 0.43165719509124756, avg loss: 0.43165719509124756\n",
      "trial: 8, epoch, 8, iter: 1, curr loss: 0.4139261841773987, avg loss: 0.4139261841773987\n",
      "trial: 8, epoch, 9, iter: 1, curr loss: 0.4418846666812897, avg loss: 0.4418846666812897\n",
      "trial: 8, epoch, 10, iter: 1, curr loss: 0.4292427897453308, avg loss: 0.4292427897453308\n",
      "trial: 8, epoch, 11, iter: 1, curr loss: 0.4365461468696594, avg loss: 0.4365461468696594\n",
      "trial: 8, epoch, 12, iter: 1, curr loss: 0.43782612681388855, avg loss: 0.43782612681388855\n",
      "trial: 8, epoch, 13, iter: 1, curr loss: 0.42680203914642334, avg loss: 0.42680203914642334\n",
      "trial: 8, epoch, 14, iter: 1, curr loss: 0.4229356348514557, avg loss: 0.4229356348514557\n",
      "trial: 8, epoch, 15, iter: 1, curr loss: 0.4418373703956604, avg loss: 0.4418373703956604\n",
      "trial: 8, epoch, 16, iter: 1, curr loss: 0.4312596917152405, avg loss: 0.4312596917152405\n",
      "trial: 8, epoch, 17, iter: 1, curr loss: 0.437963604927063, avg loss: 0.437963604927063\n",
      "trial: 8, epoch, 18, iter: 1, curr loss: 0.43212077021598816, avg loss: 0.43212077021598816\n",
      "trial: 8, epoch, 19, iter: 1, curr loss: 0.431289404630661, avg loss: 0.431289404630661\n",
      "trial: 8, epoch, 20, iter: 1, curr loss: 0.4307626187801361, avg loss: 0.4307626187801361\n",
      "trial: 8, epoch, 21, iter: 1, curr loss: 0.42560875415802, avg loss: 0.42560875415802\n",
      "trial: 8, epoch, 22, iter: 1, curr loss: 0.4362555742263794, avg loss: 0.4362555742263794\n",
      "trial: 8, epoch, 23, iter: 1, curr loss: 0.41911959648132324, avg loss: 0.41911959648132324\n",
      "trial: 8, epoch, 24, iter: 1, curr loss: 0.4280793070793152, avg loss: 0.4280793070793152\n",
      "trial: 8, epoch, 25, iter: 1, curr loss: 0.431914746761322, avg loss: 0.431914746761322\n",
      "trial: 8, epoch, 26, iter: 1, curr loss: 0.430498331785202, avg loss: 0.430498331785202\n",
      "trial: 8, epoch, 27, iter: 1, curr loss: 0.4218697249889374, avg loss: 0.4218697249889374\n",
      "trial: 8, epoch, 28, iter: 1, curr loss: 0.4323611259460449, avg loss: 0.4323611259460449\n",
      "trial: 8, epoch, 29, iter: 1, curr loss: 0.43228691816329956, avg loss: 0.43228691816329956\n",
      "trial: 8, epoch, 30, iter: 1, curr loss: 0.4309638738632202, avg loss: 0.4309638738632202\n",
      "trial: 8, epoch, 31, iter: 1, curr loss: 0.4391014873981476, avg loss: 0.4391014873981476\n",
      "trial: 8, epoch, 32, iter: 1, curr loss: 0.4325924515724182, avg loss: 0.4325924515724182\n",
      "trial: 8, epoch, 33, iter: 1, curr loss: 0.4286622703075409, avg loss: 0.4286622703075409\n",
      "trial: 8, epoch, 34, iter: 1, curr loss: 0.4257020056247711, avg loss: 0.4257020056247711\n",
      "trial: 8, epoch, 35, iter: 1, curr loss: 0.42844241857528687, avg loss: 0.42844241857528687\n",
      "trial: 8, epoch, 36, iter: 1, curr loss: 0.42439085245132446, avg loss: 0.42439085245132446\n",
      "trial: 8, epoch, 37, iter: 1, curr loss: 0.4398612380027771, avg loss: 0.4398612380027771\n",
      "trial: 8, epoch, 38, iter: 1, curr loss: 0.43976137042045593, avg loss: 0.43976137042045593\n",
      "trial: 8, epoch, 39, iter: 1, curr loss: 0.4429718852043152, avg loss: 0.4429718852043152\n",
      "trial: 8, epoch, 40, iter: 1, curr loss: 0.42921778559684753, avg loss: 0.42921778559684753\n",
      "trial: 8, epoch, 41, iter: 1, curr loss: 0.4240695536136627, avg loss: 0.4240695536136627\n",
      "trial: 8, epoch, 42, iter: 1, curr loss: 0.4292531907558441, avg loss: 0.4292531907558441\n",
      "trial: 8, epoch, 43, iter: 1, curr loss: 0.4385015070438385, avg loss: 0.4385015070438385\n",
      "trial: 8, epoch, 44, iter: 1, curr loss: 0.4297999143600464, avg loss: 0.4297999143600464\n",
      "trial: 8, epoch, 45, iter: 1, curr loss: 0.42837923765182495, avg loss: 0.42837923765182495\n",
      "trial: 8, epoch, 46, iter: 1, curr loss: 0.42751339077949524, avg loss: 0.42751339077949524\n",
      "trial: 8, epoch, 47, iter: 1, curr loss: 0.42435669898986816, avg loss: 0.42435669898986816\n",
      "trial: 8, epoch, 48, iter: 1, curr loss: 0.4219551086425781, avg loss: 0.4219551086425781\n",
      "trial: 8, epoch, 49, iter: 1, curr loss: 0.4357239305973053, avg loss: 0.4357239305973053\n",
      "trial: 8, epoch, 50, iter: 1, curr loss: 0.4325484037399292, avg loss: 0.4325484037399292\n",
      "trial: 8, ldr: 0.9319517016410828, dv: 0.9134129285812378, nwj: 0.9132400155067444\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 9, epoch, 1, iter: 1, curr loss: 0.69420325756073, avg loss: 0.69420325756073\n",
      "trial: 9, epoch, 2, iter: 1, curr loss: 0.43923065066337585, avg loss: 0.43923065066337585\n",
      "trial: 9, epoch, 3, iter: 1, curr loss: 0.42581236362457275, avg loss: 0.42581236362457275\n",
      "trial: 9, epoch, 4, iter: 1, curr loss: 0.438435435295105, avg loss: 0.438435435295105\n",
      "trial: 9, epoch, 5, iter: 1, curr loss: 0.4413212537765503, avg loss: 0.4413212537765503\n",
      "trial: 9, epoch, 6, iter: 1, curr loss: 0.4355064928531647, avg loss: 0.4355064928531647\n",
      "trial: 9, epoch, 7, iter: 1, curr loss: 0.42552852630615234, avg loss: 0.42552852630615234\n",
      "trial: 9, epoch, 8, iter: 1, curr loss: 0.4332457184791565, avg loss: 0.4332457184791565\n",
      "trial: 9, epoch, 9, iter: 1, curr loss: 0.4268958568572998, avg loss: 0.4268958568572998\n",
      "trial: 9, epoch, 10, iter: 1, curr loss: 0.4308580160140991, avg loss: 0.4308580160140991\n",
      "trial: 9, epoch, 11, iter: 1, curr loss: 0.4288429021835327, avg loss: 0.4288429021835327\n",
      "trial: 9, epoch, 12, iter: 1, curr loss: 0.43956664204597473, avg loss: 0.43956664204597473\n",
      "trial: 9, epoch, 13, iter: 1, curr loss: 0.43469297885894775, avg loss: 0.43469297885894775\n",
      "trial: 9, epoch, 14, iter: 1, curr loss: 0.42232364416122437, avg loss: 0.42232364416122437\n",
      "trial: 9, epoch, 15, iter: 1, curr loss: 0.43269485235214233, avg loss: 0.43269485235214233\n",
      "trial: 9, epoch, 16, iter: 1, curr loss: 0.4342348873615265, avg loss: 0.4342348873615265\n",
      "trial: 9, epoch, 17, iter: 1, curr loss: 0.4199821352958679, avg loss: 0.4199821352958679\n",
      "trial: 9, epoch, 18, iter: 1, curr loss: 0.4246600866317749, avg loss: 0.4246600866317749\n",
      "trial: 9, epoch, 19, iter: 1, curr loss: 0.4235023856163025, avg loss: 0.4235023856163025\n",
      "trial: 9, epoch, 20, iter: 1, curr loss: 0.43433815240859985, avg loss: 0.43433815240859985\n",
      "trial: 9, epoch, 21, iter: 1, curr loss: 0.43324506282806396, avg loss: 0.43324506282806396\n",
      "trial: 9, epoch, 22, iter: 1, curr loss: 0.4325173497200012, avg loss: 0.4325173497200012\n",
      "trial: 9, epoch, 23, iter: 1, curr loss: 0.4278944432735443, avg loss: 0.4278944432735443\n",
      "trial: 9, epoch, 24, iter: 1, curr loss: 0.42695051431655884, avg loss: 0.42695051431655884\n",
      "trial: 9, epoch, 25, iter: 1, curr loss: 0.42915207147598267, avg loss: 0.42915207147598267\n",
      "trial: 9, epoch, 26, iter: 1, curr loss: 0.43938347697257996, avg loss: 0.43938347697257996\n",
      "trial: 9, epoch, 27, iter: 1, curr loss: 0.43184733390808105, avg loss: 0.43184733390808105\n",
      "trial: 9, epoch, 28, iter: 1, curr loss: 0.4281160235404968, avg loss: 0.4281160235404968\n",
      "trial: 9, epoch, 29, iter: 1, curr loss: 0.4302603006362915, avg loss: 0.4302603006362915\n",
      "trial: 9, epoch, 30, iter: 1, curr loss: 0.41614601016044617, avg loss: 0.41614601016044617\n",
      "trial: 9, epoch, 31, iter: 1, curr loss: 0.4319601058959961, avg loss: 0.4319601058959961\n",
      "trial: 9, epoch, 32, iter: 1, curr loss: 0.4317288398742676, avg loss: 0.4317288398742676\n",
      "trial: 9, epoch, 33, iter: 1, curr loss: 0.4343956708908081, avg loss: 0.4343956708908081\n",
      "trial: 9, epoch, 34, iter: 1, curr loss: 0.43232813477516174, avg loss: 0.43232813477516174\n",
      "trial: 9, epoch, 35, iter: 1, curr loss: 0.420213520526886, avg loss: 0.420213520526886\n",
      "trial: 9, epoch, 36, iter: 1, curr loss: 0.4215337634086609, avg loss: 0.4215337634086609\n",
      "trial: 9, epoch, 37, iter: 1, curr loss: 0.43404486775398254, avg loss: 0.43404486775398254\n",
      "trial: 9, epoch, 38, iter: 1, curr loss: 0.43369680643081665, avg loss: 0.43369680643081665\n",
      "trial: 9, epoch, 39, iter: 1, curr loss: 0.42617490887641907, avg loss: 0.42617490887641907\n",
      "trial: 9, epoch, 40, iter: 1, curr loss: 0.4266901910305023, avg loss: 0.4266901910305023\n",
      "trial: 9, epoch, 41, iter: 1, curr loss: 0.4354085922241211, avg loss: 0.4354085922241211\n",
      "trial: 9, epoch, 42, iter: 1, curr loss: 0.4249831438064575, avg loss: 0.4249831438064575\n",
      "trial: 9, epoch, 43, iter: 1, curr loss: 0.4309421479701996, avg loss: 0.4309421479701996\n",
      "trial: 9, epoch, 44, iter: 1, curr loss: 0.4240306615829468, avg loss: 0.4240306615829468\n",
      "trial: 9, epoch, 45, iter: 1, curr loss: 0.4326414167881012, avg loss: 0.4326414167881012\n",
      "trial: 9, epoch, 46, iter: 1, curr loss: 0.4336203634738922, avg loss: 0.4336203634738922\n",
      "trial: 9, epoch, 47, iter: 1, curr loss: 0.42175960540771484, avg loss: 0.42175960540771484\n",
      "trial: 9, epoch, 48, iter: 1, curr loss: 0.4241771697998047, avg loss: 0.4241771697998047\n",
      "trial: 9, epoch, 49, iter: 1, curr loss: 0.4357675015926361, avg loss: 0.4357675015926361\n",
      "trial: 9, epoch, 50, iter: 1, curr loss: 0.43906790018081665, avg loss: 0.43906790018081665\n",
      "trial: 9, ldr: 0.9165894389152527, dv: 0.9143224954605103, nwj: 0.9143199324607849\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 10, epoch, 1, iter: 1, curr loss: 0.6951028108596802, avg loss: 0.6951028108596802\n",
      "trial: 10, epoch, 2, iter: 1, curr loss: 0.4385470449924469, avg loss: 0.4385470449924469\n",
      "trial: 10, epoch, 3, iter: 1, curr loss: 0.4330933094024658, avg loss: 0.4330933094024658\n",
      "trial: 10, epoch, 4, iter: 1, curr loss: 0.4419231712818146, avg loss: 0.4419231712818146\n",
      "trial: 10, epoch, 5, iter: 1, curr loss: 0.43726205825805664, avg loss: 0.43726205825805664\n",
      "trial: 10, epoch, 6, iter: 1, curr loss: 0.42664772272109985, avg loss: 0.42664772272109985\n",
      "trial: 10, epoch, 7, iter: 1, curr loss: 0.424765408039093, avg loss: 0.424765408039093\n",
      "trial: 10, epoch, 8, iter: 1, curr loss: 0.4348507523536682, avg loss: 0.4348507523536682\n",
      "trial: 10, epoch, 9, iter: 1, curr loss: 0.43590134382247925, avg loss: 0.43590134382247925\n",
      "trial: 10, epoch, 10, iter: 1, curr loss: 0.4284778833389282, avg loss: 0.4284778833389282\n",
      "trial: 10, epoch, 11, iter: 1, curr loss: 0.4263363182544708, avg loss: 0.4263363182544708\n",
      "trial: 10, epoch, 12, iter: 1, curr loss: 0.431907057762146, avg loss: 0.431907057762146\n",
      "trial: 10, epoch, 13, iter: 1, curr loss: 0.4281420409679413, avg loss: 0.4281420409679413\n",
      "trial: 10, epoch, 14, iter: 1, curr loss: 0.4363892674446106, avg loss: 0.4363892674446106\n",
      "trial: 10, epoch, 15, iter: 1, curr loss: 0.4418928325176239, avg loss: 0.4418928325176239\n",
      "trial: 10, epoch, 16, iter: 1, curr loss: 0.42473506927490234, avg loss: 0.42473506927490234\n",
      "trial: 10, epoch, 17, iter: 1, curr loss: 0.4320470988750458, avg loss: 0.4320470988750458\n",
      "trial: 10, epoch, 18, iter: 1, curr loss: 0.42986738681793213, avg loss: 0.42986738681793213\n",
      "trial: 10, epoch, 19, iter: 1, curr loss: 0.4230012893676758, avg loss: 0.4230012893676758\n",
      "trial: 10, epoch, 20, iter: 1, curr loss: 0.42523011565208435, avg loss: 0.42523011565208435\n",
      "trial: 10, epoch, 21, iter: 1, curr loss: 0.41908520460128784, avg loss: 0.41908520460128784\n",
      "trial: 10, epoch, 22, iter: 1, curr loss: 0.44556745886802673, avg loss: 0.44556745886802673\n",
      "trial: 10, epoch, 23, iter: 1, curr loss: 0.4183727502822876, avg loss: 0.4183727502822876\n",
      "trial: 10, epoch, 24, iter: 1, curr loss: 0.4254913032054901, avg loss: 0.4254913032054901\n",
      "trial: 10, epoch, 25, iter: 1, curr loss: 0.4451296329498291, avg loss: 0.4451296329498291\n",
      "trial: 10, epoch, 26, iter: 1, curr loss: 0.433845192193985, avg loss: 0.433845192193985\n",
      "trial: 10, epoch, 27, iter: 1, curr loss: 0.43497252464294434, avg loss: 0.43497252464294434\n",
      "trial: 10, epoch, 28, iter: 1, curr loss: 0.42785313725471497, avg loss: 0.42785313725471497\n",
      "trial: 10, epoch, 29, iter: 1, curr loss: 0.4376257658004761, avg loss: 0.4376257658004761\n",
      "trial: 10, epoch, 30, iter: 1, curr loss: 0.4395928978919983, avg loss: 0.4395928978919983\n",
      "trial: 10, epoch, 31, iter: 1, curr loss: 0.42617613077163696, avg loss: 0.42617613077163696\n",
      "trial: 10, epoch, 32, iter: 1, curr loss: 0.42200401425361633, avg loss: 0.42200401425361633\n",
      "trial: 10, epoch, 33, iter: 1, curr loss: 0.43094342947006226, avg loss: 0.43094342947006226\n",
      "trial: 10, epoch, 34, iter: 1, curr loss: 0.4252416789531708, avg loss: 0.4252416789531708\n",
      "trial: 10, epoch, 35, iter: 1, curr loss: 0.4450782537460327, avg loss: 0.4450782537460327\n",
      "trial: 10, epoch, 36, iter: 1, curr loss: 0.44452887773513794, avg loss: 0.44452887773513794\n",
      "trial: 10, epoch, 37, iter: 1, curr loss: 0.4317716956138611, avg loss: 0.4317716956138611\n",
      "trial: 10, epoch, 38, iter: 1, curr loss: 0.43032026290893555, avg loss: 0.43032026290893555\n",
      "trial: 10, epoch, 39, iter: 1, curr loss: 0.43321406841278076, avg loss: 0.43321406841278076\n",
      "trial: 10, epoch, 40, iter: 1, curr loss: 0.4347423315048218, avg loss: 0.4347423315048218\n",
      "trial: 10, epoch, 41, iter: 1, curr loss: 0.42785269021987915, avg loss: 0.42785269021987915\n",
      "trial: 10, epoch, 42, iter: 1, curr loss: 0.4276028871536255, avg loss: 0.4276028871536255\n",
      "trial: 10, epoch, 43, iter: 1, curr loss: 0.4303585886955261, avg loss: 0.4303585886955261\n",
      "trial: 10, epoch, 44, iter: 1, curr loss: 0.4468100070953369, avg loss: 0.4468100070953369\n",
      "trial: 10, epoch, 45, iter: 1, curr loss: 0.4229758083820343, avg loss: 0.4229758083820343\n",
      "trial: 10, epoch, 46, iter: 1, curr loss: 0.42982038855552673, avg loss: 0.42982038855552673\n",
      "trial: 10, epoch, 47, iter: 1, curr loss: 0.42852064967155457, avg loss: 0.42852064967155457\n",
      "trial: 10, epoch, 48, iter: 1, curr loss: 0.43067389726638794, avg loss: 0.43067389726638794\n",
      "trial: 10, epoch, 49, iter: 1, curr loss: 0.43896302580833435, avg loss: 0.43896302580833435\n",
      "trial: 10, epoch, 50, iter: 1, curr loss: 0.4341394305229187, avg loss: 0.4341394305229187\n",
      "trial: 10, ldr: 0.8677932620048523, dv: 0.9127852320671082, nwj: 0.9117881059646606\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 11, epoch, 1, iter: 1, curr loss: 0.6960595846176147, avg loss: 0.6960595846176147\n",
      "trial: 11, epoch, 2, iter: 1, curr loss: 0.4351765513420105, avg loss: 0.4351765513420105\n",
      "trial: 11, epoch, 3, iter: 1, curr loss: 0.4304006099700928, avg loss: 0.4304006099700928\n",
      "trial: 11, epoch, 4, iter: 1, curr loss: 0.43849480152130127, avg loss: 0.43849480152130127\n",
      "trial: 11, epoch, 5, iter: 1, curr loss: 0.42643940448760986, avg loss: 0.42643940448760986\n",
      "trial: 11, epoch, 6, iter: 1, curr loss: 0.4179840087890625, avg loss: 0.4179840087890625\n",
      "trial: 11, epoch, 7, iter: 1, curr loss: 0.4354497790336609, avg loss: 0.4354497790336609\n",
      "trial: 11, epoch, 8, iter: 1, curr loss: 0.4486442804336548, avg loss: 0.4486442804336548\n",
      "trial: 11, epoch, 9, iter: 1, curr loss: 0.4315965175628662, avg loss: 0.4315965175628662\n",
      "trial: 11, epoch, 10, iter: 1, curr loss: 0.43313461542129517, avg loss: 0.43313461542129517\n",
      "trial: 11, epoch, 11, iter: 1, curr loss: 0.4272908568382263, avg loss: 0.4272908568382263\n",
      "trial: 11, epoch, 12, iter: 1, curr loss: 0.43279048800468445, avg loss: 0.43279048800468445\n",
      "trial: 11, epoch, 13, iter: 1, curr loss: 0.443909227848053, avg loss: 0.443909227848053\n",
      "trial: 11, epoch, 14, iter: 1, curr loss: 0.4276391863822937, avg loss: 0.4276391863822937\n",
      "trial: 11, epoch, 15, iter: 1, curr loss: 0.42605412006378174, avg loss: 0.42605412006378174\n",
      "trial: 11, epoch, 16, iter: 1, curr loss: 0.4492592513561249, avg loss: 0.4492592513561249\n",
      "trial: 11, epoch, 17, iter: 1, curr loss: 0.4412388205528259, avg loss: 0.4412388205528259\n",
      "trial: 11, epoch, 18, iter: 1, curr loss: 0.4342144727706909, avg loss: 0.4342144727706909\n",
      "trial: 11, epoch, 19, iter: 1, curr loss: 0.4110843539237976, avg loss: 0.4110843539237976\n",
      "trial: 11, epoch, 20, iter: 1, curr loss: 0.42977219820022583, avg loss: 0.42977219820022583\n",
      "trial: 11, epoch, 21, iter: 1, curr loss: 0.4351203441619873, avg loss: 0.4351203441619873\n",
      "trial: 11, epoch, 22, iter: 1, curr loss: 0.42361339926719666, avg loss: 0.42361339926719666\n",
      "trial: 11, epoch, 23, iter: 1, curr loss: 0.4380508363246918, avg loss: 0.4380508363246918\n",
      "trial: 11, epoch, 24, iter: 1, curr loss: 0.4402034282684326, avg loss: 0.4402034282684326\n",
      "trial: 11, epoch, 25, iter: 1, curr loss: 0.4434615969657898, avg loss: 0.4434615969657898\n",
      "trial: 11, epoch, 26, iter: 1, curr loss: 0.4276074171066284, avg loss: 0.4276074171066284\n",
      "trial: 11, epoch, 27, iter: 1, curr loss: 0.43345290422439575, avg loss: 0.43345290422439575\n",
      "trial: 11, epoch, 28, iter: 1, curr loss: 0.4370802640914917, avg loss: 0.4370802640914917\n",
      "trial: 11, epoch, 29, iter: 1, curr loss: 0.4337705969810486, avg loss: 0.4337705969810486\n",
      "trial: 11, epoch, 30, iter: 1, curr loss: 0.4200811982154846, avg loss: 0.4200811982154846\n",
      "trial: 11, epoch, 31, iter: 1, curr loss: 0.4307882785797119, avg loss: 0.4307882785797119\n",
      "trial: 11, epoch, 32, iter: 1, curr loss: 0.44355666637420654, avg loss: 0.44355666637420654\n",
      "trial: 11, epoch, 33, iter: 1, curr loss: 0.4362417161464691, avg loss: 0.4362417161464691\n",
      "trial: 11, epoch, 34, iter: 1, curr loss: 0.4193398356437683, avg loss: 0.4193398356437683\n",
      "trial: 11, epoch, 35, iter: 1, curr loss: 0.4285989999771118, avg loss: 0.4285989999771118\n",
      "trial: 11, epoch, 36, iter: 1, curr loss: 0.4364127516746521, avg loss: 0.4364127516746521\n",
      "trial: 11, epoch, 37, iter: 1, curr loss: 0.42473435401916504, avg loss: 0.42473435401916504\n",
      "trial: 11, epoch, 38, iter: 1, curr loss: 0.42343878746032715, avg loss: 0.42343878746032715\n",
      "trial: 11, epoch, 39, iter: 1, curr loss: 0.43886131048202515, avg loss: 0.43886131048202515\n",
      "trial: 11, epoch, 40, iter: 1, curr loss: 0.4311465919017792, avg loss: 0.4311465919017792\n",
      "trial: 11, epoch, 41, iter: 1, curr loss: 0.42949676513671875, avg loss: 0.42949676513671875\n",
      "trial: 11, epoch, 42, iter: 1, curr loss: 0.43277838826179504, avg loss: 0.43277838826179504\n",
      "trial: 11, epoch, 43, iter: 1, curr loss: 0.43598756194114685, avg loss: 0.43598756194114685\n",
      "trial: 11, epoch, 44, iter: 1, curr loss: 0.4190034568309784, avg loss: 0.4190034568309784\n",
      "trial: 11, epoch, 45, iter: 1, curr loss: 0.4359821081161499, avg loss: 0.4359821081161499\n",
      "trial: 11, epoch, 46, iter: 1, curr loss: 0.4356275796890259, avg loss: 0.4356275796890259\n",
      "trial: 11, epoch, 47, iter: 1, curr loss: 0.43233975768089294, avg loss: 0.43233975768089294\n",
      "trial: 11, epoch, 48, iter: 1, curr loss: 0.4293973743915558, avg loss: 0.4293973743915558\n",
      "trial: 11, epoch, 49, iter: 1, curr loss: 0.43786242604255676, avg loss: 0.43786242604255676\n",
      "trial: 11, epoch, 50, iter: 1, curr loss: 0.43165624141693115, avg loss: 0.43165624141693115\n",
      "trial: 11, ldr: 0.9356139898300171, dv: 0.9130797386169434, nwj: 0.9128239154815674\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 12, epoch, 1, iter: 1, curr loss: 0.6953008770942688, avg loss: 0.6953008770942688\n",
      "trial: 12, epoch, 2, iter: 1, curr loss: 0.44190314412117004, avg loss: 0.44190314412117004\n",
      "trial: 12, epoch, 3, iter: 1, curr loss: 0.4277424216270447, avg loss: 0.4277424216270447\n",
      "trial: 12, epoch, 4, iter: 1, curr loss: 0.4235262870788574, avg loss: 0.4235262870788574\n",
      "trial: 12, epoch, 5, iter: 1, curr loss: 0.4284106492996216, avg loss: 0.4284106492996216\n",
      "trial: 12, epoch, 6, iter: 1, curr loss: 0.42638009786605835, avg loss: 0.42638009786605835\n",
      "trial: 12, epoch, 7, iter: 1, curr loss: 0.4297042489051819, avg loss: 0.4297042489051819\n",
      "trial: 12, epoch, 8, iter: 1, curr loss: 0.4342934489250183, avg loss: 0.4342934489250183\n",
      "trial: 12, epoch, 9, iter: 1, curr loss: 0.42650705575942993, avg loss: 0.42650705575942993\n",
      "trial: 12, epoch, 10, iter: 1, curr loss: 0.43793052434921265, avg loss: 0.43793052434921265\n",
      "trial: 12, epoch, 11, iter: 1, curr loss: 0.43684127926826477, avg loss: 0.43684127926826477\n",
      "trial: 12, epoch, 12, iter: 1, curr loss: 0.42998117208480835, avg loss: 0.42998117208480835\n",
      "trial: 12, epoch, 13, iter: 1, curr loss: 0.4227270483970642, avg loss: 0.4227270483970642\n",
      "trial: 12, epoch, 14, iter: 1, curr loss: 0.439892441034317, avg loss: 0.439892441034317\n",
      "trial: 12, epoch, 15, iter: 1, curr loss: 0.4280658960342407, avg loss: 0.4280658960342407\n",
      "trial: 12, epoch, 16, iter: 1, curr loss: 0.4275442361831665, avg loss: 0.4275442361831665\n",
      "trial: 12, epoch, 17, iter: 1, curr loss: 0.427540123462677, avg loss: 0.427540123462677\n",
      "trial: 12, epoch, 18, iter: 1, curr loss: 0.4369316101074219, avg loss: 0.4369316101074219\n",
      "trial: 12, epoch, 19, iter: 1, curr loss: 0.4355805218219757, avg loss: 0.4355805218219757\n",
      "trial: 12, epoch, 20, iter: 1, curr loss: 0.4301968514919281, avg loss: 0.4301968514919281\n",
      "trial: 12, epoch, 21, iter: 1, curr loss: 0.4298816919326782, avg loss: 0.4298816919326782\n",
      "trial: 12, epoch, 22, iter: 1, curr loss: 0.42821425199508667, avg loss: 0.42821425199508667\n",
      "trial: 12, epoch, 23, iter: 1, curr loss: 0.42870140075683594, avg loss: 0.42870140075683594\n",
      "trial: 12, epoch, 24, iter: 1, curr loss: 0.42229485511779785, avg loss: 0.42229485511779785\n",
      "trial: 12, epoch, 25, iter: 1, curr loss: 0.4224425256252289, avg loss: 0.4224425256252289\n",
      "trial: 12, epoch, 26, iter: 1, curr loss: 0.43237215280532837, avg loss: 0.43237215280532837\n",
      "trial: 12, epoch, 27, iter: 1, curr loss: 0.4186004400253296, avg loss: 0.4186004400253296\n",
      "trial: 12, epoch, 28, iter: 1, curr loss: 0.4327543377876282, avg loss: 0.4327543377876282\n",
      "trial: 12, epoch, 29, iter: 1, curr loss: 0.4202892780303955, avg loss: 0.4202892780303955\n",
      "trial: 12, epoch, 30, iter: 1, curr loss: 0.4308355748653412, avg loss: 0.4308355748653412\n",
      "trial: 12, epoch, 31, iter: 1, curr loss: 0.4301260709762573, avg loss: 0.4301260709762573\n",
      "trial: 12, epoch, 32, iter: 1, curr loss: 0.42931050062179565, avg loss: 0.42931050062179565\n",
      "trial: 12, epoch, 33, iter: 1, curr loss: 0.4223184287548065, avg loss: 0.4223184287548065\n",
      "trial: 12, epoch, 34, iter: 1, curr loss: 0.4290054738521576, avg loss: 0.4290054738521576\n",
      "trial: 12, epoch, 35, iter: 1, curr loss: 0.41883957386016846, avg loss: 0.41883957386016846\n",
      "trial: 12, epoch, 36, iter: 1, curr loss: 0.42661383748054504, avg loss: 0.42661383748054504\n",
      "trial: 12, epoch, 37, iter: 1, curr loss: 0.42776212096214294, avg loss: 0.42776212096214294\n",
      "trial: 12, epoch, 38, iter: 1, curr loss: 0.4294353723526001, avg loss: 0.4294353723526001\n",
      "trial: 12, epoch, 39, iter: 1, curr loss: 0.4381876587867737, avg loss: 0.4381876587867737\n",
      "trial: 12, epoch, 40, iter: 1, curr loss: 0.42492008209228516, avg loss: 0.42492008209228516\n",
      "trial: 12, epoch, 41, iter: 1, curr loss: 0.42439889907836914, avg loss: 0.42439889907836914\n",
      "trial: 12, epoch, 42, iter: 1, curr loss: 0.4342252016067505, avg loss: 0.4342252016067505\n",
      "trial: 12, epoch, 43, iter: 1, curr loss: 0.4350825548171997, avg loss: 0.4350825548171997\n",
      "trial: 12, epoch, 44, iter: 1, curr loss: 0.4411965012550354, avg loss: 0.4411965012550354\n",
      "trial: 12, epoch, 45, iter: 1, curr loss: 0.42468932271003723, avg loss: 0.42468932271003723\n",
      "trial: 12, epoch, 46, iter: 1, curr loss: 0.43916305899620056, avg loss: 0.43916305899620056\n",
      "trial: 12, epoch, 47, iter: 1, curr loss: 0.4395146071910858, avg loss: 0.4395146071910858\n",
      "trial: 12, epoch, 48, iter: 1, curr loss: 0.4235243797302246, avg loss: 0.4235243797302246\n",
      "trial: 12, epoch, 49, iter: 1, curr loss: 0.4297005534172058, avg loss: 0.4297005534172058\n",
      "trial: 12, epoch, 50, iter: 1, curr loss: 0.4148356318473816, avg loss: 0.4148356318473816\n",
      "trial: 12, ldr: 0.8806722164154053, dv: 0.9137526750564575, nwj: 0.9132115244865417\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 13, epoch, 1, iter: 1, curr loss: 0.6949073672294617, avg loss: 0.6949073672294617\n",
      "trial: 13, epoch, 2, iter: 1, curr loss: 0.4332054853439331, avg loss: 0.4332054853439331\n",
      "trial: 13, epoch, 3, iter: 1, curr loss: 0.42782485485076904, avg loss: 0.42782485485076904\n",
      "trial: 13, epoch, 4, iter: 1, curr loss: 0.4297385811805725, avg loss: 0.4297385811805725\n",
      "trial: 13, epoch, 5, iter: 1, curr loss: 0.42817509174346924, avg loss: 0.42817509174346924\n",
      "trial: 13, epoch, 6, iter: 1, curr loss: 0.43668174743652344, avg loss: 0.43668174743652344\n",
      "trial: 13, epoch, 7, iter: 1, curr loss: 0.4267454743385315, avg loss: 0.4267454743385315\n",
      "trial: 13, epoch, 8, iter: 1, curr loss: 0.4273148775100708, avg loss: 0.4273148775100708\n",
      "trial: 13, epoch, 9, iter: 1, curr loss: 0.425367534160614, avg loss: 0.425367534160614\n",
      "trial: 13, epoch, 10, iter: 1, curr loss: 0.44271713495254517, avg loss: 0.44271713495254517\n",
      "trial: 13, epoch, 11, iter: 1, curr loss: 0.4241853952407837, avg loss: 0.4241853952407837\n",
      "trial: 13, epoch, 12, iter: 1, curr loss: 0.4195329248905182, avg loss: 0.4195329248905182\n",
      "trial: 13, epoch, 13, iter: 1, curr loss: 0.4339638352394104, avg loss: 0.4339638352394104\n",
      "trial: 13, epoch, 14, iter: 1, curr loss: 0.43544673919677734, avg loss: 0.43544673919677734\n",
      "trial: 13, epoch, 15, iter: 1, curr loss: 0.4220493733882904, avg loss: 0.4220493733882904\n",
      "trial: 13, epoch, 16, iter: 1, curr loss: 0.4167588949203491, avg loss: 0.4167588949203491\n",
      "trial: 13, epoch, 17, iter: 1, curr loss: 0.43012940883636475, avg loss: 0.43012940883636475\n",
      "trial: 13, epoch, 18, iter: 1, curr loss: 0.4431910216808319, avg loss: 0.4431910216808319\n",
      "trial: 13, epoch, 19, iter: 1, curr loss: 0.4273955225944519, avg loss: 0.4273955225944519\n",
      "trial: 13, epoch, 20, iter: 1, curr loss: 0.4367718994617462, avg loss: 0.4367718994617462\n",
      "trial: 13, epoch, 21, iter: 1, curr loss: 0.4403834342956543, avg loss: 0.4403834342956543\n",
      "trial: 13, epoch, 22, iter: 1, curr loss: 0.42665308713912964, avg loss: 0.42665308713912964\n",
      "trial: 13, epoch, 23, iter: 1, curr loss: 0.44121724367141724, avg loss: 0.44121724367141724\n",
      "trial: 13, epoch, 24, iter: 1, curr loss: 0.42474865913391113, avg loss: 0.42474865913391113\n",
      "trial: 13, epoch, 25, iter: 1, curr loss: 0.42446550726890564, avg loss: 0.42446550726890564\n",
      "trial: 13, epoch, 26, iter: 1, curr loss: 0.42211124300956726, avg loss: 0.42211124300956726\n",
      "trial: 13, epoch, 27, iter: 1, curr loss: 0.44130462408065796, avg loss: 0.44130462408065796\n",
      "trial: 13, epoch, 28, iter: 1, curr loss: 0.42924171686172485, avg loss: 0.42924171686172485\n",
      "trial: 13, epoch, 29, iter: 1, curr loss: 0.43002966046333313, avg loss: 0.43002966046333313\n",
      "trial: 13, epoch, 30, iter: 1, curr loss: 0.44628143310546875, avg loss: 0.44628143310546875\n",
      "trial: 13, epoch, 31, iter: 1, curr loss: 0.4247383773326874, avg loss: 0.4247383773326874\n",
      "trial: 13, epoch, 32, iter: 1, curr loss: 0.4203411042690277, avg loss: 0.4203411042690277\n",
      "trial: 13, epoch, 33, iter: 1, curr loss: 0.4257339537143707, avg loss: 0.4257339537143707\n",
      "trial: 13, epoch, 34, iter: 1, curr loss: 0.4434867203235626, avg loss: 0.4434867203235626\n",
      "trial: 13, epoch, 35, iter: 1, curr loss: 0.41970038414001465, avg loss: 0.41970038414001465\n",
      "trial: 13, epoch, 36, iter: 1, curr loss: 0.42837777733802795, avg loss: 0.42837777733802795\n",
      "trial: 13, epoch, 37, iter: 1, curr loss: 0.43233025074005127, avg loss: 0.43233025074005127\n",
      "trial: 13, epoch, 38, iter: 1, curr loss: 0.4285063147544861, avg loss: 0.4285063147544861\n",
      "trial: 13, epoch, 39, iter: 1, curr loss: 0.4401710629463196, avg loss: 0.4401710629463196\n",
      "trial: 13, epoch, 40, iter: 1, curr loss: 0.4326210021972656, avg loss: 0.4326210021972656\n",
      "trial: 13, epoch, 41, iter: 1, curr loss: 0.426565945148468, avg loss: 0.426565945148468\n",
      "trial: 13, epoch, 42, iter: 1, curr loss: 0.42872345447540283, avg loss: 0.42872345447540283\n",
      "trial: 13, epoch, 43, iter: 1, curr loss: 0.44384774565696716, avg loss: 0.44384774565696716\n",
      "trial: 13, epoch, 44, iter: 1, curr loss: 0.43345457315444946, avg loss: 0.43345457315444946\n",
      "trial: 13, epoch, 45, iter: 1, curr loss: 0.44066089391708374, avg loss: 0.44066089391708374\n",
      "trial: 13, epoch, 46, iter: 1, curr loss: 0.42654648423194885, avg loss: 0.42654648423194885\n",
      "trial: 13, epoch, 47, iter: 1, curr loss: 0.4272997975349426, avg loss: 0.4272997975349426\n",
      "trial: 13, epoch, 48, iter: 1, curr loss: 0.42776623368263245, avg loss: 0.42776623368263245\n",
      "trial: 13, epoch, 49, iter: 1, curr loss: 0.428161084651947, avg loss: 0.428161084651947\n",
      "trial: 13, epoch, 50, iter: 1, curr loss: 0.4178102910518646, avg loss: 0.4178102910518646\n",
      "trial: 13, ldr: 0.9250063896179199, dv: 0.9104605913162231, nwj: 0.9103542566299438\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 14, epoch, 1, iter: 1, curr loss: 0.6998915672302246, avg loss: 0.6998915672302246\n",
      "trial: 14, epoch, 2, iter: 1, curr loss: 0.4392644166946411, avg loss: 0.4392644166946411\n",
      "trial: 14, epoch, 3, iter: 1, curr loss: 0.4311787784099579, avg loss: 0.4311787784099579\n",
      "trial: 14, epoch, 4, iter: 1, curr loss: 0.42647987604141235, avg loss: 0.42647987604141235\n",
      "trial: 14, epoch, 5, iter: 1, curr loss: 0.4292415380477905, avg loss: 0.4292415380477905\n",
      "trial: 14, epoch, 6, iter: 1, curr loss: 0.4405475854873657, avg loss: 0.4405475854873657\n",
      "trial: 14, epoch, 7, iter: 1, curr loss: 0.42838427424430847, avg loss: 0.42838427424430847\n",
      "trial: 14, epoch, 8, iter: 1, curr loss: 0.4258502125740051, avg loss: 0.4258502125740051\n",
      "trial: 14, epoch, 9, iter: 1, curr loss: 0.43217167258262634, avg loss: 0.43217167258262634\n",
      "trial: 14, epoch, 10, iter: 1, curr loss: 0.43261802196502686, avg loss: 0.43261802196502686\n",
      "trial: 14, epoch, 11, iter: 1, curr loss: 0.42409491539001465, avg loss: 0.42409491539001465\n",
      "trial: 14, epoch, 12, iter: 1, curr loss: 0.43476760387420654, avg loss: 0.43476760387420654\n",
      "trial: 14, epoch, 13, iter: 1, curr loss: 0.43302831053733826, avg loss: 0.43302831053733826\n",
      "trial: 14, epoch, 14, iter: 1, curr loss: 0.4261816143989563, avg loss: 0.4261816143989563\n",
      "trial: 14, epoch, 15, iter: 1, curr loss: 0.43498387932777405, avg loss: 0.43498387932777405\n",
      "trial: 14, epoch, 16, iter: 1, curr loss: 0.4268763065338135, avg loss: 0.4268763065338135\n",
      "trial: 14, epoch, 17, iter: 1, curr loss: 0.4432814121246338, avg loss: 0.4432814121246338\n",
      "trial: 14, epoch, 18, iter: 1, curr loss: 0.42627236247062683, avg loss: 0.42627236247062683\n",
      "trial: 14, epoch, 19, iter: 1, curr loss: 0.4324486255645752, avg loss: 0.4324486255645752\n",
      "trial: 14, epoch, 20, iter: 1, curr loss: 0.4255722165107727, avg loss: 0.4255722165107727\n",
      "trial: 14, epoch, 21, iter: 1, curr loss: 0.436189204454422, avg loss: 0.436189204454422\n",
      "trial: 14, epoch, 22, iter: 1, curr loss: 0.4275463819503784, avg loss: 0.4275463819503784\n",
      "trial: 14, epoch, 23, iter: 1, curr loss: 0.4383513927459717, avg loss: 0.4383513927459717\n",
      "trial: 14, epoch, 24, iter: 1, curr loss: 0.4251498579978943, avg loss: 0.4251498579978943\n",
      "trial: 14, epoch, 25, iter: 1, curr loss: 0.44351959228515625, avg loss: 0.44351959228515625\n",
      "trial: 14, epoch, 26, iter: 1, curr loss: 0.433368444442749, avg loss: 0.433368444442749\n",
      "trial: 14, epoch, 27, iter: 1, curr loss: 0.4349069893360138, avg loss: 0.4349069893360138\n",
      "trial: 14, epoch, 28, iter: 1, curr loss: 0.43623650074005127, avg loss: 0.43623650074005127\n",
      "trial: 14, epoch, 29, iter: 1, curr loss: 0.4374070167541504, avg loss: 0.4374070167541504\n",
      "trial: 14, epoch, 30, iter: 1, curr loss: 0.41625750064849854, avg loss: 0.41625750064849854\n",
      "trial: 14, epoch, 31, iter: 1, curr loss: 0.42952221632003784, avg loss: 0.42952221632003784\n",
      "trial: 14, epoch, 32, iter: 1, curr loss: 0.4318527579307556, avg loss: 0.4318527579307556\n",
      "trial: 14, epoch, 33, iter: 1, curr loss: 0.4288746118545532, avg loss: 0.4288746118545532\n",
      "trial: 14, epoch, 34, iter: 1, curr loss: 0.42796292901039124, avg loss: 0.42796292901039124\n",
      "trial: 14, epoch, 35, iter: 1, curr loss: 0.4334836006164551, avg loss: 0.4334836006164551\n",
      "trial: 14, epoch, 36, iter: 1, curr loss: 0.4392845034599304, avg loss: 0.4392845034599304\n",
      "trial: 14, epoch, 37, iter: 1, curr loss: 0.42494097352027893, avg loss: 0.42494097352027893\n",
      "trial: 14, epoch, 38, iter: 1, curr loss: 0.4191085994243622, avg loss: 0.4191085994243622\n",
      "trial: 14, epoch, 39, iter: 1, curr loss: 0.42435240745544434, avg loss: 0.42435240745544434\n",
      "trial: 14, epoch, 40, iter: 1, curr loss: 0.4354850649833679, avg loss: 0.4354850649833679\n",
      "trial: 14, epoch, 41, iter: 1, curr loss: 0.4138072729110718, avg loss: 0.4138072729110718\n",
      "trial: 14, epoch, 42, iter: 1, curr loss: 0.43253839015960693, avg loss: 0.43253839015960693\n",
      "trial: 14, epoch, 43, iter: 1, curr loss: 0.4370238482952118, avg loss: 0.4370238482952118\n",
      "trial: 14, epoch, 44, iter: 1, curr loss: 0.4274011552333832, avg loss: 0.4274011552333832\n",
      "trial: 14, epoch, 45, iter: 1, curr loss: 0.44167035818099976, avg loss: 0.44167035818099976\n",
      "trial: 14, epoch, 46, iter: 1, curr loss: 0.43188607692718506, avg loss: 0.43188607692718506\n",
      "trial: 14, epoch, 47, iter: 1, curr loss: 0.4263722598552704, avg loss: 0.4263722598552704\n",
      "trial: 14, epoch, 48, iter: 1, curr loss: 0.43258994817733765, avg loss: 0.43258994817733765\n",
      "trial: 14, epoch, 49, iter: 1, curr loss: 0.43575361371040344, avg loss: 0.43575361371040344\n",
      "trial: 14, epoch, 50, iter: 1, curr loss: 0.4370870292186737, avg loss: 0.4370870292186737\n",
      "trial: 14, ldr: 0.8549706935882568, dv: 0.9113224744796753, nwj: 0.9097641110420227\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 15, epoch, 1, iter: 1, curr loss: 0.7019398212432861, avg loss: 0.7019398212432861\n",
      "trial: 15, epoch, 2, iter: 1, curr loss: 0.4419020414352417, avg loss: 0.4419020414352417\n",
      "trial: 15, epoch, 3, iter: 1, curr loss: 0.443037748336792, avg loss: 0.443037748336792\n",
      "trial: 15, epoch, 4, iter: 1, curr loss: 0.4233545660972595, avg loss: 0.4233545660972595\n",
      "trial: 15, epoch, 5, iter: 1, curr loss: 0.44179320335388184, avg loss: 0.44179320335388184\n",
      "trial: 15, epoch, 6, iter: 1, curr loss: 0.4323602616786957, avg loss: 0.4323602616786957\n",
      "trial: 15, epoch, 7, iter: 1, curr loss: 0.4405539631843567, avg loss: 0.4405539631843567\n",
      "trial: 15, epoch, 8, iter: 1, curr loss: 0.4371911883354187, avg loss: 0.4371911883354187\n",
      "trial: 15, epoch, 9, iter: 1, curr loss: 0.43172866106033325, avg loss: 0.43172866106033325\n",
      "trial: 15, epoch, 10, iter: 1, curr loss: 0.4297451972961426, avg loss: 0.4297451972961426\n",
      "trial: 15, epoch, 11, iter: 1, curr loss: 0.4494996666908264, avg loss: 0.4494996666908264\n",
      "trial: 15, epoch, 12, iter: 1, curr loss: 0.43622344732284546, avg loss: 0.43622344732284546\n",
      "trial: 15, epoch, 13, iter: 1, curr loss: 0.42958176136016846, avg loss: 0.42958176136016846\n",
      "trial: 15, epoch, 14, iter: 1, curr loss: 0.425666481256485, avg loss: 0.425666481256485\n",
      "trial: 15, epoch, 15, iter: 1, curr loss: 0.43287718296051025, avg loss: 0.43287718296051025\n",
      "trial: 15, epoch, 16, iter: 1, curr loss: 0.42842212319374084, avg loss: 0.42842212319374084\n",
      "trial: 15, epoch, 17, iter: 1, curr loss: 0.43958914279937744, avg loss: 0.43958914279937744\n",
      "trial: 15, epoch, 18, iter: 1, curr loss: 0.4184355139732361, avg loss: 0.4184355139732361\n",
      "trial: 15, epoch, 19, iter: 1, curr loss: 0.43123775720596313, avg loss: 0.43123775720596313\n",
      "trial: 15, epoch, 20, iter: 1, curr loss: 0.4328896701335907, avg loss: 0.4328896701335907\n",
      "trial: 15, epoch, 21, iter: 1, curr loss: 0.4309336245059967, avg loss: 0.4309336245059967\n",
      "trial: 15, epoch, 22, iter: 1, curr loss: 0.42754191160202026, avg loss: 0.42754191160202026\n",
      "trial: 15, epoch, 23, iter: 1, curr loss: 0.4288454055786133, avg loss: 0.4288454055786133\n",
      "trial: 15, epoch, 24, iter: 1, curr loss: 0.44697141647338867, avg loss: 0.44697141647338867\n",
      "trial: 15, epoch, 25, iter: 1, curr loss: 0.43695324659347534, avg loss: 0.43695324659347534\n",
      "trial: 15, epoch, 26, iter: 1, curr loss: 0.42000922560691833, avg loss: 0.42000922560691833\n",
      "trial: 15, epoch, 27, iter: 1, curr loss: 0.4248294532299042, avg loss: 0.4248294532299042\n",
      "trial: 15, epoch, 28, iter: 1, curr loss: 0.4220355153083801, avg loss: 0.4220355153083801\n",
      "trial: 15, epoch, 29, iter: 1, curr loss: 0.4332515299320221, avg loss: 0.4332515299320221\n",
      "trial: 15, epoch, 30, iter: 1, curr loss: 0.41289299726486206, avg loss: 0.41289299726486206\n",
      "trial: 15, epoch, 31, iter: 1, curr loss: 0.42647409439086914, avg loss: 0.42647409439086914\n",
      "trial: 15, epoch, 32, iter: 1, curr loss: 0.43158918619155884, avg loss: 0.43158918619155884\n",
      "trial: 15, epoch, 33, iter: 1, curr loss: 0.42183491587638855, avg loss: 0.42183491587638855\n",
      "trial: 15, epoch, 34, iter: 1, curr loss: 0.42157840728759766, avg loss: 0.42157840728759766\n",
      "trial: 15, epoch, 35, iter: 1, curr loss: 0.42672568559646606, avg loss: 0.42672568559646606\n",
      "trial: 15, epoch, 36, iter: 1, curr loss: 0.4292425811290741, avg loss: 0.4292425811290741\n",
      "trial: 15, epoch, 37, iter: 1, curr loss: 0.42828643321990967, avg loss: 0.42828643321990967\n",
      "trial: 15, epoch, 38, iter: 1, curr loss: 0.4317086935043335, avg loss: 0.4317086935043335\n",
      "trial: 15, epoch, 39, iter: 1, curr loss: 0.43456682562828064, avg loss: 0.43456682562828064\n",
      "trial: 15, epoch, 40, iter: 1, curr loss: 0.43041810393333435, avg loss: 0.43041810393333435\n",
      "trial: 15, epoch, 41, iter: 1, curr loss: 0.44335609674453735, avg loss: 0.44335609674453735\n",
      "trial: 15, epoch, 42, iter: 1, curr loss: 0.4369432330131531, avg loss: 0.4369432330131531\n",
      "trial: 15, epoch, 43, iter: 1, curr loss: 0.43372654914855957, avg loss: 0.43372654914855957\n",
      "trial: 15, epoch, 44, iter: 1, curr loss: 0.42466825246810913, avg loss: 0.42466825246810913\n",
      "trial: 15, epoch, 45, iter: 1, curr loss: 0.4340318441390991, avg loss: 0.4340318441390991\n",
      "trial: 15, epoch, 46, iter: 1, curr loss: 0.410885751247406, avg loss: 0.410885751247406\n",
      "trial: 15, epoch, 47, iter: 1, curr loss: 0.42361947894096375, avg loss: 0.42361947894096375\n",
      "trial: 15, epoch, 48, iter: 1, curr loss: 0.4404247999191284, avg loss: 0.4404247999191284\n",
      "trial: 15, epoch, 49, iter: 1, curr loss: 0.43412357568740845, avg loss: 0.43412357568740845\n",
      "trial: 15, epoch, 50, iter: 1, curr loss: 0.4216383695602417, avg loss: 0.4216383695602417\n",
      "trial: 15, ldr: 0.9805867671966553, dv: 0.9113979935646057, nwj: 0.9089483022689819\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 16, epoch, 1, iter: 1, curr loss: 0.6943572759628296, avg loss: 0.6943572759628296\n",
      "trial: 16, epoch, 2, iter: 1, curr loss: 0.4386107623577118, avg loss: 0.4386107623577118\n",
      "trial: 16, epoch, 3, iter: 1, curr loss: 0.4381980001926422, avg loss: 0.4381980001926422\n",
      "trial: 16, epoch, 4, iter: 1, curr loss: 0.4198053181171417, avg loss: 0.4198053181171417\n",
      "trial: 16, epoch, 5, iter: 1, curr loss: 0.43103641271591187, avg loss: 0.43103641271591187\n",
      "trial: 16, epoch, 6, iter: 1, curr loss: 0.4348244071006775, avg loss: 0.4348244071006775\n",
      "trial: 16, epoch, 7, iter: 1, curr loss: 0.4363938271999359, avg loss: 0.4363938271999359\n",
      "trial: 16, epoch, 8, iter: 1, curr loss: 0.4306643009185791, avg loss: 0.4306643009185791\n",
      "trial: 16, epoch, 9, iter: 1, curr loss: 0.4226731061935425, avg loss: 0.4226731061935425\n",
      "trial: 16, epoch, 10, iter: 1, curr loss: 0.44032785296440125, avg loss: 0.44032785296440125\n",
      "trial: 16, epoch, 11, iter: 1, curr loss: 0.44710099697113037, avg loss: 0.44710099697113037\n",
      "trial: 16, epoch, 12, iter: 1, curr loss: 0.4301501214504242, avg loss: 0.4301501214504242\n",
      "trial: 16, epoch, 13, iter: 1, curr loss: 0.4321235418319702, avg loss: 0.4321235418319702\n",
      "trial: 16, epoch, 14, iter: 1, curr loss: 0.4446253776550293, avg loss: 0.4446253776550293\n",
      "trial: 16, epoch, 15, iter: 1, curr loss: 0.4342939257621765, avg loss: 0.4342939257621765\n",
      "trial: 16, epoch, 16, iter: 1, curr loss: 0.4272870719432831, avg loss: 0.4272870719432831\n",
      "trial: 16, epoch, 17, iter: 1, curr loss: 0.43473508954048157, avg loss: 0.43473508954048157\n",
      "trial: 16, epoch, 18, iter: 1, curr loss: 0.4256522059440613, avg loss: 0.4256522059440613\n",
      "trial: 16, epoch, 19, iter: 1, curr loss: 0.4296586513519287, avg loss: 0.4296586513519287\n",
      "trial: 16, epoch, 20, iter: 1, curr loss: 0.43787074089050293, avg loss: 0.43787074089050293\n",
      "trial: 16, epoch, 21, iter: 1, curr loss: 0.4424706995487213, avg loss: 0.4424706995487213\n",
      "trial: 16, epoch, 22, iter: 1, curr loss: 0.43455183506011963, avg loss: 0.43455183506011963\n",
      "trial: 16, epoch, 23, iter: 1, curr loss: 0.4232105612754822, avg loss: 0.4232105612754822\n",
      "trial: 16, epoch, 24, iter: 1, curr loss: 0.43365567922592163, avg loss: 0.43365567922592163\n",
      "trial: 16, epoch, 25, iter: 1, curr loss: 0.44216808676719666, avg loss: 0.44216808676719666\n",
      "trial: 16, epoch, 26, iter: 1, curr loss: 0.4272690713405609, avg loss: 0.4272690713405609\n",
      "trial: 16, epoch, 27, iter: 1, curr loss: 0.42053788900375366, avg loss: 0.42053788900375366\n",
      "trial: 16, epoch, 28, iter: 1, curr loss: 0.44483575224876404, avg loss: 0.44483575224876404\n",
      "trial: 16, epoch, 29, iter: 1, curr loss: 0.4258568584918976, avg loss: 0.4258568584918976\n",
      "trial: 16, epoch, 30, iter: 1, curr loss: 0.43319135904312134, avg loss: 0.43319135904312134\n",
      "trial: 16, epoch, 31, iter: 1, curr loss: 0.4231147766113281, avg loss: 0.4231147766113281\n",
      "trial: 16, epoch, 32, iter: 1, curr loss: 0.42155954241752625, avg loss: 0.42155954241752625\n",
      "trial: 16, epoch, 33, iter: 1, curr loss: 0.4166806936264038, avg loss: 0.4166806936264038\n",
      "trial: 16, epoch, 34, iter: 1, curr loss: 0.43003517389297485, avg loss: 0.43003517389297485\n",
      "trial: 16, epoch, 35, iter: 1, curr loss: 0.43002787232398987, avg loss: 0.43002787232398987\n",
      "trial: 16, epoch, 36, iter: 1, curr loss: 0.4238545298576355, avg loss: 0.4238545298576355\n",
      "trial: 16, epoch, 37, iter: 1, curr loss: 0.4170495271682739, avg loss: 0.4170495271682739\n",
      "trial: 16, epoch, 38, iter: 1, curr loss: 0.4223095178604126, avg loss: 0.4223095178604126\n",
      "trial: 16, epoch, 39, iter: 1, curr loss: 0.41516026854515076, avg loss: 0.41516026854515076\n",
      "trial: 16, epoch, 40, iter: 1, curr loss: 0.4189738631248474, avg loss: 0.4189738631248474\n",
      "trial: 16, epoch, 41, iter: 1, curr loss: 0.4203183948993683, avg loss: 0.4203183948993683\n",
      "trial: 16, epoch, 42, iter: 1, curr loss: 0.4340996742248535, avg loss: 0.4340996742248535\n",
      "trial: 16, epoch, 43, iter: 1, curr loss: 0.42675745487213135, avg loss: 0.42675745487213135\n",
      "trial: 16, epoch, 44, iter: 1, curr loss: 0.4429335594177246, avg loss: 0.4429335594177246\n",
      "trial: 16, epoch, 45, iter: 1, curr loss: 0.42966413497924805, avg loss: 0.42966413497924805\n",
      "trial: 16, epoch, 46, iter: 1, curr loss: 0.42365580797195435, avg loss: 0.42365580797195435\n",
      "trial: 16, epoch, 47, iter: 1, curr loss: 0.44262295961380005, avg loss: 0.44262295961380005\n",
      "trial: 16, epoch, 48, iter: 1, curr loss: 0.42236512899398804, avg loss: 0.42236512899398804\n",
      "trial: 16, epoch, 49, iter: 1, curr loss: 0.42348039150238037, avg loss: 0.42348039150238037\n",
      "trial: 16, epoch, 50, iter: 1, curr loss: 0.4285004138946533, avg loss: 0.4285004138946533\n",
      "trial: 16, ldr: 0.87396639585495, dv: 0.9140167832374573, nwj: 0.9132253527641296\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 17, epoch, 1, iter: 1, curr loss: 0.6945630311965942, avg loss: 0.6945630311965942\n",
      "trial: 17, epoch, 2, iter: 1, curr loss: 0.4268893599510193, avg loss: 0.4268893599510193\n",
      "trial: 17, epoch, 3, iter: 1, curr loss: 0.4385668635368347, avg loss: 0.4385668635368347\n",
      "trial: 17, epoch, 4, iter: 1, curr loss: 0.4246496558189392, avg loss: 0.4246496558189392\n",
      "trial: 17, epoch, 5, iter: 1, curr loss: 0.43465760350227356, avg loss: 0.43465760350227356\n",
      "trial: 17, epoch, 6, iter: 1, curr loss: 0.443462073802948, avg loss: 0.443462073802948\n",
      "trial: 17, epoch, 7, iter: 1, curr loss: 0.4233357906341553, avg loss: 0.4233357906341553\n",
      "trial: 17, epoch, 8, iter: 1, curr loss: 0.4314979016780853, avg loss: 0.4314979016780853\n",
      "trial: 17, epoch, 9, iter: 1, curr loss: 0.44388604164123535, avg loss: 0.44388604164123535\n",
      "trial: 17, epoch, 10, iter: 1, curr loss: 0.4314604103565216, avg loss: 0.4314604103565216\n",
      "trial: 17, epoch, 11, iter: 1, curr loss: 0.430508017539978, avg loss: 0.430508017539978\n",
      "trial: 17, epoch, 12, iter: 1, curr loss: 0.43737906217575073, avg loss: 0.43737906217575073\n",
      "trial: 17, epoch, 13, iter: 1, curr loss: 0.4211549162864685, avg loss: 0.4211549162864685\n",
      "trial: 17, epoch, 14, iter: 1, curr loss: 0.4219643175601959, avg loss: 0.4219643175601959\n",
      "trial: 17, epoch, 15, iter: 1, curr loss: 0.43885666131973267, avg loss: 0.43885666131973267\n",
      "trial: 17, epoch, 16, iter: 1, curr loss: 0.43103647232055664, avg loss: 0.43103647232055664\n",
      "trial: 17, epoch, 17, iter: 1, curr loss: 0.4303269684314728, avg loss: 0.4303269684314728\n",
      "trial: 17, epoch, 18, iter: 1, curr loss: 0.4287721812725067, avg loss: 0.4287721812725067\n",
      "trial: 17, epoch, 19, iter: 1, curr loss: 0.4405125677585602, avg loss: 0.4405125677585602\n",
      "trial: 17, epoch, 20, iter: 1, curr loss: 0.41482722759246826, avg loss: 0.41482722759246826\n",
      "trial: 17, epoch, 21, iter: 1, curr loss: 0.4231363534927368, avg loss: 0.4231363534927368\n",
      "trial: 17, epoch, 22, iter: 1, curr loss: 0.43304136395454407, avg loss: 0.43304136395454407\n",
      "trial: 17, epoch, 23, iter: 1, curr loss: 0.4349033832550049, avg loss: 0.4349033832550049\n",
      "trial: 17, epoch, 24, iter: 1, curr loss: 0.4274168312549591, avg loss: 0.4274168312549591\n",
      "trial: 17, epoch, 25, iter: 1, curr loss: 0.4288898706436157, avg loss: 0.4288898706436157\n",
      "trial: 17, epoch, 26, iter: 1, curr loss: 0.43267443776130676, avg loss: 0.43267443776130676\n",
      "trial: 17, epoch, 27, iter: 1, curr loss: 0.4253125488758087, avg loss: 0.4253125488758087\n",
      "trial: 17, epoch, 28, iter: 1, curr loss: 0.4314931035041809, avg loss: 0.4314931035041809\n",
      "trial: 17, epoch, 29, iter: 1, curr loss: 0.43456700444221497, avg loss: 0.43456700444221497\n",
      "trial: 17, epoch, 30, iter: 1, curr loss: 0.4233264923095703, avg loss: 0.4233264923095703\n",
      "trial: 17, epoch, 31, iter: 1, curr loss: 0.43011000752449036, avg loss: 0.43011000752449036\n",
      "trial: 17, epoch, 32, iter: 1, curr loss: 0.4350283145904541, avg loss: 0.4350283145904541\n",
      "trial: 17, epoch, 33, iter: 1, curr loss: 0.4268772006034851, avg loss: 0.4268772006034851\n",
      "trial: 17, epoch, 34, iter: 1, curr loss: 0.4263155162334442, avg loss: 0.4263155162334442\n",
      "trial: 17, epoch, 35, iter: 1, curr loss: 0.43138349056243896, avg loss: 0.43138349056243896\n",
      "trial: 17, epoch, 36, iter: 1, curr loss: 0.42919498682022095, avg loss: 0.42919498682022095\n",
      "trial: 17, epoch, 37, iter: 1, curr loss: 0.4352111220359802, avg loss: 0.4352111220359802\n",
      "trial: 17, epoch, 38, iter: 1, curr loss: 0.4234299063682556, avg loss: 0.4234299063682556\n",
      "trial: 17, epoch, 39, iter: 1, curr loss: 0.44093358516693115, avg loss: 0.44093358516693115\n",
      "trial: 17, epoch, 40, iter: 1, curr loss: 0.4407714605331421, avg loss: 0.4407714605331421\n",
      "trial: 17, epoch, 41, iter: 1, curr loss: 0.43537941575050354, avg loss: 0.43537941575050354\n",
      "trial: 17, epoch, 42, iter: 1, curr loss: 0.4243450462818146, avg loss: 0.4243450462818146\n",
      "trial: 17, epoch, 43, iter: 1, curr loss: 0.42875194549560547, avg loss: 0.42875194549560547\n",
      "trial: 17, epoch, 44, iter: 1, curr loss: 0.4298878312110901, avg loss: 0.4298878312110901\n",
      "trial: 17, epoch, 45, iter: 1, curr loss: 0.43043243885040283, avg loss: 0.43043243885040283\n",
      "trial: 17, epoch, 46, iter: 1, curr loss: 0.41955822706222534, avg loss: 0.41955822706222534\n",
      "trial: 17, epoch, 47, iter: 1, curr loss: 0.433713436126709, avg loss: 0.433713436126709\n",
      "trial: 17, epoch, 48, iter: 1, curr loss: 0.43433982133865356, avg loss: 0.43433982133865356\n",
      "trial: 17, epoch, 49, iter: 1, curr loss: 0.43052852153778076, avg loss: 0.43052852153778076\n",
      "trial: 17, epoch, 50, iter: 1, curr loss: 0.4309573173522949, avg loss: 0.4309573173522949\n",
      "trial: 17, ldr: 0.8708968162536621, dv: 0.9116845726966858, nwj: 0.9108639359474182\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 18, epoch, 1, iter: 1, curr loss: 0.6954737305641174, avg loss: 0.6954737305641174\n",
      "trial: 18, epoch, 2, iter: 1, curr loss: 0.4457021951675415, avg loss: 0.4457021951675415\n",
      "trial: 18, epoch, 3, iter: 1, curr loss: 0.43417757749557495, avg loss: 0.43417757749557495\n",
      "trial: 18, epoch, 4, iter: 1, curr loss: 0.43611007928848267, avg loss: 0.43611007928848267\n",
      "trial: 18, epoch, 5, iter: 1, curr loss: 0.4359161853790283, avg loss: 0.4359161853790283\n",
      "trial: 18, epoch, 6, iter: 1, curr loss: 0.4302927255630493, avg loss: 0.4302927255630493\n",
      "trial: 18, epoch, 7, iter: 1, curr loss: 0.43230533599853516, avg loss: 0.43230533599853516\n",
      "trial: 18, epoch, 8, iter: 1, curr loss: 0.42527663707733154, avg loss: 0.42527663707733154\n",
      "trial: 18, epoch, 9, iter: 1, curr loss: 0.43854427337646484, avg loss: 0.43854427337646484\n",
      "trial: 18, epoch, 10, iter: 1, curr loss: 0.4339737892150879, avg loss: 0.4339737892150879\n",
      "trial: 18, epoch, 11, iter: 1, curr loss: 0.4309654235839844, avg loss: 0.4309654235839844\n",
      "trial: 18, epoch, 12, iter: 1, curr loss: 0.4196300506591797, avg loss: 0.4196300506591797\n",
      "trial: 18, epoch, 13, iter: 1, curr loss: 0.4278416633605957, avg loss: 0.4278416633605957\n",
      "trial: 18, epoch, 14, iter: 1, curr loss: 0.4285280108451843, avg loss: 0.4285280108451843\n",
      "trial: 18, epoch, 15, iter: 1, curr loss: 0.4415801763534546, avg loss: 0.4415801763534546\n",
      "trial: 18, epoch, 16, iter: 1, curr loss: 0.42514920234680176, avg loss: 0.42514920234680176\n",
      "trial: 18, epoch, 17, iter: 1, curr loss: 0.4338962435722351, avg loss: 0.4338962435722351\n",
      "trial: 18, epoch, 18, iter: 1, curr loss: 0.42242658138275146, avg loss: 0.42242658138275146\n",
      "trial: 18, epoch, 19, iter: 1, curr loss: 0.44060570001602173, avg loss: 0.44060570001602173\n",
      "trial: 18, epoch, 20, iter: 1, curr loss: 0.4260784983634949, avg loss: 0.4260784983634949\n",
      "trial: 18, epoch, 21, iter: 1, curr loss: 0.4378536343574524, avg loss: 0.4378536343574524\n",
      "trial: 18, epoch, 22, iter: 1, curr loss: 0.44276612997055054, avg loss: 0.44276612997055054\n",
      "trial: 18, epoch, 23, iter: 1, curr loss: 0.42456454038619995, avg loss: 0.42456454038619995\n",
      "trial: 18, epoch, 24, iter: 1, curr loss: 0.4278385639190674, avg loss: 0.4278385639190674\n",
      "trial: 18, epoch, 25, iter: 1, curr loss: 0.4314388930797577, avg loss: 0.4314388930797577\n",
      "trial: 18, epoch, 26, iter: 1, curr loss: 0.4266442656517029, avg loss: 0.4266442656517029\n",
      "trial: 18, epoch, 27, iter: 1, curr loss: 0.43764322996139526, avg loss: 0.43764322996139526\n",
      "trial: 18, epoch, 28, iter: 1, curr loss: 0.4269743859767914, avg loss: 0.4269743859767914\n",
      "trial: 18, epoch, 29, iter: 1, curr loss: 0.42835569381713867, avg loss: 0.42835569381713867\n",
      "trial: 18, epoch, 30, iter: 1, curr loss: 0.43083420395851135, avg loss: 0.43083420395851135\n",
      "trial: 18, epoch, 31, iter: 1, curr loss: 0.43836766481399536, avg loss: 0.43836766481399536\n",
      "trial: 18, epoch, 32, iter: 1, curr loss: 0.42675259709358215, avg loss: 0.42675259709358215\n",
      "trial: 18, epoch, 33, iter: 1, curr loss: 0.4308720827102661, avg loss: 0.4308720827102661\n",
      "trial: 18, epoch, 34, iter: 1, curr loss: 0.4286518692970276, avg loss: 0.4286518692970276\n",
      "trial: 18, epoch, 35, iter: 1, curr loss: 0.43287670612335205, avg loss: 0.43287670612335205\n",
      "trial: 18, epoch, 36, iter: 1, curr loss: 0.43197208642959595, avg loss: 0.43197208642959595\n",
      "trial: 18, epoch, 37, iter: 1, curr loss: 0.4302634000778198, avg loss: 0.4302634000778198\n",
      "trial: 18, epoch, 38, iter: 1, curr loss: 0.42574313282966614, avg loss: 0.42574313282966614\n",
      "trial: 18, epoch, 39, iter: 1, curr loss: 0.4236699938774109, avg loss: 0.4236699938774109\n",
      "trial: 18, epoch, 40, iter: 1, curr loss: 0.4282488524913788, avg loss: 0.4282488524913788\n",
      "trial: 18, epoch, 41, iter: 1, curr loss: 0.42140716314315796, avg loss: 0.42140716314315796\n",
      "trial: 18, epoch, 42, iter: 1, curr loss: 0.4434451460838318, avg loss: 0.4434451460838318\n",
      "trial: 18, epoch, 43, iter: 1, curr loss: 0.4334948658943176, avg loss: 0.4334948658943176\n",
      "trial: 18, epoch, 44, iter: 1, curr loss: 0.425072580575943, avg loss: 0.425072580575943\n",
      "trial: 18, epoch, 45, iter: 1, curr loss: 0.41889381408691406, avg loss: 0.41889381408691406\n",
      "trial: 18, epoch, 46, iter: 1, curr loss: 0.42008256912231445, avg loss: 0.42008256912231445\n",
      "trial: 18, epoch, 47, iter: 1, curr loss: 0.43246594071388245, avg loss: 0.43246594071388245\n",
      "trial: 18, epoch, 48, iter: 1, curr loss: 0.4296954870223999, avg loss: 0.4296954870223999\n",
      "trial: 18, epoch, 49, iter: 1, curr loss: 0.43708494305610657, avg loss: 0.43708494305610657\n",
      "trial: 18, epoch, 50, iter: 1, curr loss: 0.416738897562027, avg loss: 0.416738897562027\n",
      "trial: 18, ldr: 0.9075956344604492, dv: 0.9141661524772644, nwj: 0.9141446352005005\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 19, epoch, 1, iter: 1, curr loss: 0.6947696208953857, avg loss: 0.6947696208953857\n",
      "trial: 19, epoch, 2, iter: 1, curr loss: 0.44474005699157715, avg loss: 0.44474005699157715\n",
      "trial: 19, epoch, 3, iter: 1, curr loss: 0.4385327696800232, avg loss: 0.4385327696800232\n",
      "trial: 19, epoch, 4, iter: 1, curr loss: 0.4262593984603882, avg loss: 0.4262593984603882\n",
      "trial: 19, epoch, 5, iter: 1, curr loss: 0.4518766403198242, avg loss: 0.4518766403198242\n",
      "trial: 19, epoch, 6, iter: 1, curr loss: 0.41584545373916626, avg loss: 0.41584545373916626\n",
      "trial: 19, epoch, 7, iter: 1, curr loss: 0.4231012761592865, avg loss: 0.4231012761592865\n",
      "trial: 19, epoch, 8, iter: 1, curr loss: 0.43762484192848206, avg loss: 0.43762484192848206\n",
      "trial: 19, epoch, 9, iter: 1, curr loss: 0.43400439620018005, avg loss: 0.43400439620018005\n",
      "trial: 19, epoch, 10, iter: 1, curr loss: 0.43820202350616455, avg loss: 0.43820202350616455\n",
      "trial: 19, epoch, 11, iter: 1, curr loss: 0.4402247667312622, avg loss: 0.4402247667312622\n",
      "trial: 19, epoch, 12, iter: 1, curr loss: 0.4392714500427246, avg loss: 0.4392714500427246\n",
      "trial: 19, epoch, 13, iter: 1, curr loss: 0.4212155044078827, avg loss: 0.4212155044078827\n",
      "trial: 19, epoch, 14, iter: 1, curr loss: 0.4344225227832794, avg loss: 0.4344225227832794\n",
      "trial: 19, epoch, 15, iter: 1, curr loss: 0.43794673681259155, avg loss: 0.43794673681259155\n",
      "trial: 19, epoch, 16, iter: 1, curr loss: 0.43197619915008545, avg loss: 0.43197619915008545\n",
      "trial: 19, epoch, 17, iter: 1, curr loss: 0.4325120449066162, avg loss: 0.4325120449066162\n",
      "trial: 19, epoch, 18, iter: 1, curr loss: 0.4260292947292328, avg loss: 0.4260292947292328\n",
      "trial: 19, epoch, 19, iter: 1, curr loss: 0.43340978026390076, avg loss: 0.43340978026390076\n",
      "trial: 19, epoch, 20, iter: 1, curr loss: 0.42590951919555664, avg loss: 0.42590951919555664\n",
      "trial: 19, epoch, 21, iter: 1, curr loss: 0.42933815717697144, avg loss: 0.42933815717697144\n",
      "trial: 19, epoch, 22, iter: 1, curr loss: 0.4272807240486145, avg loss: 0.4272807240486145\n",
      "trial: 19, epoch, 23, iter: 1, curr loss: 0.43191930651664734, avg loss: 0.43191930651664734\n",
      "trial: 19, epoch, 24, iter: 1, curr loss: 0.4343252182006836, avg loss: 0.4343252182006836\n",
      "trial: 19, epoch, 25, iter: 1, curr loss: 0.4325993061065674, avg loss: 0.4325993061065674\n",
      "trial: 19, epoch, 26, iter: 1, curr loss: 0.44103774428367615, avg loss: 0.44103774428367615\n",
      "trial: 19, epoch, 27, iter: 1, curr loss: 0.43246278166770935, avg loss: 0.43246278166770935\n",
      "trial: 19, epoch, 28, iter: 1, curr loss: 0.42572999000549316, avg loss: 0.42572999000549316\n",
      "trial: 19, epoch, 29, iter: 1, curr loss: 0.4177677631378174, avg loss: 0.4177677631378174\n",
      "trial: 19, epoch, 30, iter: 1, curr loss: 0.4353491961956024, avg loss: 0.4353491961956024\n",
      "trial: 19, epoch, 31, iter: 1, curr loss: 0.4391505718231201, avg loss: 0.4391505718231201\n",
      "trial: 19, epoch, 32, iter: 1, curr loss: 0.43362846970558167, avg loss: 0.43362846970558167\n",
      "trial: 19, epoch, 33, iter: 1, curr loss: 0.4311051666736603, avg loss: 0.4311051666736603\n",
      "trial: 19, epoch, 34, iter: 1, curr loss: 0.42606937885284424, avg loss: 0.42606937885284424\n",
      "trial: 19, epoch, 35, iter: 1, curr loss: 0.43232184648513794, avg loss: 0.43232184648513794\n",
      "trial: 19, epoch, 36, iter: 1, curr loss: 0.4375239908695221, avg loss: 0.4375239908695221\n",
      "trial: 19, epoch, 37, iter: 1, curr loss: 0.430654376745224, avg loss: 0.430654376745224\n",
      "trial: 19, epoch, 38, iter: 1, curr loss: 0.44081807136535645, avg loss: 0.44081807136535645\n",
      "trial: 19, epoch, 39, iter: 1, curr loss: 0.42200925946235657, avg loss: 0.42200925946235657\n",
      "trial: 19, epoch, 40, iter: 1, curr loss: 0.4341813027858734, avg loss: 0.4341813027858734\n",
      "trial: 19, epoch, 41, iter: 1, curr loss: 0.42911678552627563, avg loss: 0.42911678552627563\n",
      "trial: 19, epoch, 42, iter: 1, curr loss: 0.4264231324195862, avg loss: 0.4264231324195862\n",
      "trial: 19, epoch, 43, iter: 1, curr loss: 0.4258873462677002, avg loss: 0.4258873462677002\n",
      "trial: 19, epoch, 44, iter: 1, curr loss: 0.43516185879707336, avg loss: 0.43516185879707336\n",
      "trial: 19, epoch, 45, iter: 1, curr loss: 0.4354674816131592, avg loss: 0.4354674816131592\n",
      "trial: 19, epoch, 46, iter: 1, curr loss: 0.4330829381942749, avg loss: 0.4330829381942749\n",
      "trial: 19, epoch, 47, iter: 1, curr loss: 0.42186862230300903, avg loss: 0.42186862230300903\n",
      "trial: 19, epoch, 48, iter: 1, curr loss: 0.43039441108703613, avg loss: 0.43039441108703613\n",
      "trial: 19, epoch, 49, iter: 1, curr loss: 0.4316175580024719, avg loss: 0.4316175580024719\n",
      "trial: 19, epoch, 50, iter: 1, curr loss: 0.42115694284439087, avg loss: 0.42115694284439087\n",
      "trial: 19, ldr: 0.8688345551490784, dv: 0.9103372693061829, nwj: 0.9094878435134888\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 20, epoch, 1, iter: 1, curr loss: 0.6941291689872742, avg loss: 0.6941291689872742\n",
      "trial: 20, epoch, 2, iter: 1, curr loss: 0.43760716915130615, avg loss: 0.43760716915130615\n",
      "trial: 20, epoch, 3, iter: 1, curr loss: 0.4339914619922638, avg loss: 0.4339914619922638\n",
      "trial: 20, epoch, 4, iter: 1, curr loss: 0.4260282516479492, avg loss: 0.4260282516479492\n",
      "trial: 20, epoch, 5, iter: 1, curr loss: 0.4255237579345703, avg loss: 0.4255237579345703\n",
      "trial: 20, epoch, 6, iter: 1, curr loss: 0.4212765097618103, avg loss: 0.4212765097618103\n",
      "trial: 20, epoch, 7, iter: 1, curr loss: 0.4194866418838501, avg loss: 0.4194866418838501\n",
      "trial: 20, epoch, 8, iter: 1, curr loss: 0.4376590847969055, avg loss: 0.4376590847969055\n",
      "trial: 20, epoch, 9, iter: 1, curr loss: 0.4325018525123596, avg loss: 0.4325018525123596\n",
      "trial: 20, epoch, 10, iter: 1, curr loss: 0.4303109645843506, avg loss: 0.4303109645843506\n",
      "trial: 20, epoch, 11, iter: 1, curr loss: 0.4410400986671448, avg loss: 0.4410400986671448\n",
      "trial: 20, epoch, 12, iter: 1, curr loss: 0.4261583685874939, avg loss: 0.4261583685874939\n",
      "trial: 20, epoch, 13, iter: 1, curr loss: 0.43330439925193787, avg loss: 0.43330439925193787\n",
      "trial: 20, epoch, 14, iter: 1, curr loss: 0.43272697925567627, avg loss: 0.43272697925567627\n",
      "trial: 20, epoch, 15, iter: 1, curr loss: 0.4236147999763489, avg loss: 0.4236147999763489\n",
      "trial: 20, epoch, 16, iter: 1, curr loss: 0.4336438775062561, avg loss: 0.4336438775062561\n",
      "trial: 20, epoch, 17, iter: 1, curr loss: 0.4254381060600281, avg loss: 0.4254381060600281\n",
      "trial: 20, epoch, 18, iter: 1, curr loss: 0.4252144396305084, avg loss: 0.4252144396305084\n",
      "trial: 20, epoch, 19, iter: 1, curr loss: 0.43438851833343506, avg loss: 0.43438851833343506\n",
      "trial: 20, epoch, 20, iter: 1, curr loss: 0.4288845658302307, avg loss: 0.4288845658302307\n",
      "trial: 20, epoch, 21, iter: 1, curr loss: 0.4279448986053467, avg loss: 0.4279448986053467\n",
      "trial: 20, epoch, 22, iter: 1, curr loss: 0.4272565245628357, avg loss: 0.4272565245628357\n",
      "trial: 20, epoch, 23, iter: 1, curr loss: 0.42951929569244385, avg loss: 0.42951929569244385\n",
      "trial: 20, epoch, 24, iter: 1, curr loss: 0.43975144624710083, avg loss: 0.43975144624710083\n",
      "trial: 20, epoch, 25, iter: 1, curr loss: 0.43135833740234375, avg loss: 0.43135833740234375\n",
      "trial: 20, epoch, 26, iter: 1, curr loss: 0.43111205101013184, avg loss: 0.43111205101013184\n",
      "trial: 20, epoch, 27, iter: 1, curr loss: 0.4323751926422119, avg loss: 0.4323751926422119\n",
      "trial: 20, epoch, 28, iter: 1, curr loss: 0.4220713973045349, avg loss: 0.4220713973045349\n",
      "trial: 20, epoch, 29, iter: 1, curr loss: 0.42497119307518005, avg loss: 0.42497119307518005\n",
      "trial: 20, epoch, 30, iter: 1, curr loss: 0.4377036392688751, avg loss: 0.4377036392688751\n",
      "trial: 20, epoch, 31, iter: 1, curr loss: 0.41844773292541504, avg loss: 0.41844773292541504\n",
      "trial: 20, epoch, 32, iter: 1, curr loss: 0.425039678812027, avg loss: 0.425039678812027\n",
      "trial: 20, epoch, 33, iter: 1, curr loss: 0.4256514310836792, avg loss: 0.4256514310836792\n",
      "trial: 20, epoch, 34, iter: 1, curr loss: 0.44179821014404297, avg loss: 0.44179821014404297\n",
      "trial: 20, epoch, 35, iter: 1, curr loss: 0.4218714237213135, avg loss: 0.4218714237213135\n",
      "trial: 20, epoch, 36, iter: 1, curr loss: 0.42259618639945984, avg loss: 0.42259618639945984\n",
      "trial: 20, epoch, 37, iter: 1, curr loss: 0.4296385943889618, avg loss: 0.4296385943889618\n",
      "trial: 20, epoch, 38, iter: 1, curr loss: 0.43253591656684875, avg loss: 0.43253591656684875\n",
      "trial: 20, epoch, 39, iter: 1, curr loss: 0.4360786974430084, avg loss: 0.4360786974430084\n",
      "trial: 20, epoch, 40, iter: 1, curr loss: 0.4333893656730652, avg loss: 0.4333893656730652\n",
      "trial: 20, epoch, 41, iter: 1, curr loss: 0.4308120608329773, avg loss: 0.4308120608329773\n",
      "trial: 20, epoch, 42, iter: 1, curr loss: 0.443659245967865, avg loss: 0.443659245967865\n",
      "trial: 20, epoch, 43, iter: 1, curr loss: 0.43345391750335693, avg loss: 0.43345391750335693\n",
      "trial: 20, epoch, 44, iter: 1, curr loss: 0.42575332522392273, avg loss: 0.42575332522392273\n",
      "trial: 20, epoch, 45, iter: 1, curr loss: 0.43271687626838684, avg loss: 0.43271687626838684\n",
      "trial: 20, epoch, 46, iter: 1, curr loss: 0.43142592906951904, avg loss: 0.43142592906951904\n",
      "trial: 20, epoch, 47, iter: 1, curr loss: 0.4310946464538574, avg loss: 0.4310946464538574\n",
      "trial: 20, epoch, 48, iter: 1, curr loss: 0.42297255992889404, avg loss: 0.42297255992889404\n",
      "trial: 20, epoch, 49, iter: 1, curr loss: 0.42726245522499084, avg loss: 0.42726245522499084\n",
      "trial: 20, epoch, 50, iter: 1, curr loss: 0.417104035615921, avg loss: 0.417104035615921\n",
      "trial: 20, ldr: 0.9101152420043945, dv: 0.9091218709945679, nwj: 0.9091213941574097\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.9109203189611434\n",
      "\tdv: 0.9122762620449066\n",
      "\tnwj: 0.9113010615110397\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 20\n",
    "num_of_inner_iteration = 50\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    print('################################################################')\n",
    "    model, inner_running_loss, inner_running_loss_avg, num_of_joint, num_of_marginal = train_binary_classifier_v2(data, label, num_input_features, hidden_size_arr, lr, num_of_inner_iteration, batch_size, outer_iter, save_avg=200, print_progress=True)\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    curr_ldr, curr_dv, curr_nwj = estimate_mi_for_binary_classification(model, joint_data, num_of_joint, marginal_data, num_of_marginal)\n",
    "    print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "    print('################################################################\\n')\n",
    "    ldr_estimations.append(curr_ldr.item())\n",
    "    dv_estimations.append(curr_dv.item())\n",
    "    nwj_estimations.append(curr_nwj.item())\n",
    "    \n",
    "print('final estimations:\\n\\tldr: {}\\n\\tdv: {}\\n\\tnwj: {}'.format(np.mean(ldr_estimations), np.mean(dv_estimations), np.mean(nwj_estimations)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:05:23.367433119Z",
     "start_time": "2023-11-20T22:03:09.443560651Z"
    }
   },
   "id": "146b880bcd657c43"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# create the joint and marginal datasets\n",
    "x_idx, y_idx, z_idx = [0, 1], [3, 4, 5], [2]\n",
    "yz_idx = [2, 3, 4, 5]\n",
    "dataset = dataset[:, :3]\n",
    "joint_data, joint_label, marginal_data, marginal_label = create_joint_marginal_dataset(dataset, x_idx, z_idx)\n",
    "data, label = np.concatenate([joint_data, marginal_data]), np.concatenate([joint_label, marginal_label])\n",
    "randomize_idx = np.random.permutation(np.arange(2 * num_of_samples))\n",
    "data, label = data[randomize_idx], label[randomize_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:53:31.150979635Z",
     "start_time": "2023-11-20T22:53:31.103753037Z"
    }
   },
   "id": "e71923f51216c14b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_input_features = len(x_idx) + len(z_idx)\n",
    "hidden_size_arr = [256, 256, 256]\n",
    "lr = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:53:33.956464597Z",
     "start_time": "2023-11-20T22:53:33.954298715Z"
    }
   },
   "id": "ba58c3711e6fa58d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "trial: 1, epoch, 1, iter: 1, curr loss: 0.693889856338501, avg loss: 0.693889856338501\n",
      "trial: 1, epoch, 2, iter: 1, curr loss: 0.5279072523117065, avg loss: 0.5279072523117065\n",
      "trial: 1, epoch, 3, iter: 1, curr loss: 0.5308347940444946, avg loss: 0.5308347940444946\n",
      "trial: 1, epoch, 4, iter: 1, curr loss: 0.5243828296661377, avg loss: 0.5243828296661377\n",
      "trial: 1, epoch, 5, iter: 1, curr loss: 0.530073881149292, avg loss: 0.530073881149292\n",
      "trial: 1, epoch, 6, iter: 1, curr loss: 0.519391655921936, avg loss: 0.519391655921936\n",
      "trial: 1, epoch, 7, iter: 1, curr loss: 0.5324214696884155, avg loss: 0.5324214696884155\n",
      "trial: 1, epoch, 8, iter: 1, curr loss: 0.5272299647331238, avg loss: 0.5272299647331238\n",
      "trial: 1, epoch, 9, iter: 1, curr loss: 0.5247963666915894, avg loss: 0.5247963666915894\n",
      "trial: 1, epoch, 10, iter: 1, curr loss: 0.5254008173942566, avg loss: 0.5254008173942566\n",
      "trial: 1, epoch, 11, iter: 1, curr loss: 0.5268428921699524, avg loss: 0.5268428921699524\n",
      "trial: 1, epoch, 12, iter: 1, curr loss: 0.5159443020820618, avg loss: 0.5159443020820618\n",
      "trial: 1, epoch, 13, iter: 1, curr loss: 0.5221922397613525, avg loss: 0.5221922397613525\n",
      "trial: 1, epoch, 14, iter: 1, curr loss: 0.5266257524490356, avg loss: 0.5266257524490356\n",
      "trial: 1, epoch, 15, iter: 1, curr loss: 0.5187190771102905, avg loss: 0.5187190771102905\n",
      "trial: 1, epoch, 16, iter: 1, curr loss: 0.524398922920227, avg loss: 0.524398922920227\n",
      "trial: 1, epoch, 17, iter: 1, curr loss: 0.5246134400367737, avg loss: 0.5246134400367737\n",
      "trial: 1, epoch, 18, iter: 1, curr loss: 0.5286601781845093, avg loss: 0.5286601781845093\n",
      "trial: 1, epoch, 19, iter: 1, curr loss: 0.5219025611877441, avg loss: 0.5219025611877441\n",
      "trial: 1, epoch, 20, iter: 1, curr loss: 0.5322045683860779, avg loss: 0.5322045683860779\n",
      "trial: 1, epoch, 21, iter: 1, curr loss: 0.5316528081893921, avg loss: 0.5316528081893921\n",
      "trial: 1, epoch, 22, iter: 1, curr loss: 0.5267789363861084, avg loss: 0.5267789363861084\n",
      "trial: 1, epoch, 23, iter: 1, curr loss: 0.5299220085144043, avg loss: 0.5299220085144043\n",
      "trial: 1, epoch, 24, iter: 1, curr loss: 0.5244392156600952, avg loss: 0.5244392156600952\n",
      "trial: 1, epoch, 25, iter: 1, curr loss: 0.525219202041626, avg loss: 0.525219202041626\n",
      "trial: 1, epoch, 26, iter: 1, curr loss: 0.5230073928833008, avg loss: 0.5230073928833008\n",
      "trial: 1, epoch, 27, iter: 1, curr loss: 0.5394927263259888, avg loss: 0.5394927263259888\n",
      "trial: 1, epoch, 28, iter: 1, curr loss: 0.5248463749885559, avg loss: 0.5248463749885559\n",
      "trial: 1, epoch, 29, iter: 1, curr loss: 0.5181558132171631, avg loss: 0.5181558132171631\n",
      "trial: 1, epoch, 30, iter: 1, curr loss: 0.5188664197921753, avg loss: 0.5188664197921753\n",
      "trial: 1, epoch, 31, iter: 1, curr loss: 0.5316234827041626, avg loss: 0.5316234827041626\n",
      "trial: 1, epoch, 32, iter: 1, curr loss: 0.5302014350891113, avg loss: 0.5302014350891113\n",
      "trial: 1, epoch, 33, iter: 1, curr loss: 0.521296501159668, avg loss: 0.521296501159668\n",
      "trial: 1, epoch, 34, iter: 1, curr loss: 0.5105429291725159, avg loss: 0.5105429291725159\n",
      "trial: 1, epoch, 35, iter: 1, curr loss: 0.5354013442993164, avg loss: 0.5354013442993164\n",
      "trial: 1, epoch, 36, iter: 1, curr loss: 0.5303999781608582, avg loss: 0.5303999781608582\n",
      "trial: 1, epoch, 37, iter: 1, curr loss: 0.527414083480835, avg loss: 0.527414083480835\n",
      "trial: 1, epoch, 38, iter: 1, curr loss: 0.5293383598327637, avg loss: 0.5293383598327637\n",
      "trial: 1, epoch, 39, iter: 1, curr loss: 0.5216504335403442, avg loss: 0.5216504335403442\n",
      "trial: 1, epoch, 40, iter: 1, curr loss: 0.5277916193008423, avg loss: 0.5277916193008423\n",
      "trial: 1, epoch, 41, iter: 1, curr loss: 0.52330082654953, avg loss: 0.52330082654953\n",
      "trial: 1, epoch, 42, iter: 1, curr loss: 0.5362831354141235, avg loss: 0.5362831354141235\n",
      "trial: 1, epoch, 43, iter: 1, curr loss: 0.5262922048568726, avg loss: 0.5262922048568726\n",
      "trial: 1, epoch, 44, iter: 1, curr loss: 0.5317249894142151, avg loss: 0.5317249894142151\n",
      "trial: 1, epoch, 45, iter: 1, curr loss: 0.5307703018188477, avg loss: 0.5307703018188477\n",
      "trial: 1, epoch, 46, iter: 1, curr loss: 0.5300150513648987, avg loss: 0.5300150513648987\n",
      "trial: 1, epoch, 47, iter: 1, curr loss: 0.5303453803062439, avg loss: 0.5303453803062439\n",
      "trial: 1, epoch, 48, iter: 1, curr loss: 0.5197722911834717, avg loss: 0.5197722911834717\n",
      "trial: 1, epoch, 49, iter: 1, curr loss: 0.5183242559432983, avg loss: 0.5183242559432983\n",
      "trial: 1, epoch, 50, iter: 1, curr loss: 0.5264089107513428, avg loss: 0.5264089107513428\n",
      "trial: 1, ldr: 0.5490577220916748, dv: 0.566160261631012, nwj: 0.56601482629776\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 2, epoch, 1, iter: 1, curr loss: 0.6935088634490967, avg loss: 0.6935088634490967\n",
      "trial: 2, epoch, 2, iter: 1, curr loss: 0.527551531791687, avg loss: 0.527551531791687\n",
      "trial: 2, epoch, 3, iter: 1, curr loss: 0.5208398699760437, avg loss: 0.5208398699760437\n",
      "trial: 2, epoch, 4, iter: 1, curr loss: 0.528114914894104, avg loss: 0.528114914894104\n",
      "trial: 2, epoch, 5, iter: 1, curr loss: 0.5271999835968018, avg loss: 0.5271999835968018\n",
      "trial: 2, epoch, 6, iter: 1, curr loss: 0.5243936777114868, avg loss: 0.5243936777114868\n",
      "trial: 2, epoch, 7, iter: 1, curr loss: 0.5339339971542358, avg loss: 0.5339339971542358\n",
      "trial: 2, epoch, 8, iter: 1, curr loss: 0.5288431644439697, avg loss: 0.5288431644439697\n",
      "trial: 2, epoch, 9, iter: 1, curr loss: 0.5251890420913696, avg loss: 0.5251890420913696\n",
      "trial: 2, epoch, 10, iter: 1, curr loss: 0.516395092010498, avg loss: 0.516395092010498\n",
      "trial: 2, epoch, 11, iter: 1, curr loss: 0.5184143781661987, avg loss: 0.5184143781661987\n",
      "trial: 2, epoch, 12, iter: 1, curr loss: 0.5324375629425049, avg loss: 0.5324375629425049\n",
      "trial: 2, epoch, 13, iter: 1, curr loss: 0.51900315284729, avg loss: 0.51900315284729\n",
      "trial: 2, epoch, 14, iter: 1, curr loss: 0.5369774103164673, avg loss: 0.5369774103164673\n",
      "trial: 2, epoch, 15, iter: 1, curr loss: 0.5280236005783081, avg loss: 0.5280236005783081\n",
      "trial: 2, epoch, 16, iter: 1, curr loss: 0.5283086895942688, avg loss: 0.5283086895942688\n",
      "trial: 2, epoch, 17, iter: 1, curr loss: 0.5271779298782349, avg loss: 0.5271779298782349\n",
      "trial: 2, epoch, 18, iter: 1, curr loss: 0.5194720029830933, avg loss: 0.5194720029830933\n",
      "trial: 2, epoch, 19, iter: 1, curr loss: 0.5158476829528809, avg loss: 0.5158476829528809\n",
      "trial: 2, epoch, 20, iter: 1, curr loss: 0.5160050988197327, avg loss: 0.5160050988197327\n",
      "trial: 2, epoch, 21, iter: 1, curr loss: 0.5313363671302795, avg loss: 0.5313363671302795\n",
      "trial: 2, epoch, 22, iter: 1, curr loss: 0.5167937278747559, avg loss: 0.5167937278747559\n",
      "trial: 2, epoch, 23, iter: 1, curr loss: 0.5260847806930542, avg loss: 0.5260847806930542\n",
      "trial: 2, epoch, 24, iter: 1, curr loss: 0.5256744623184204, avg loss: 0.5256744623184204\n",
      "trial: 2, epoch, 25, iter: 1, curr loss: 0.5232796669006348, avg loss: 0.5232796669006348\n",
      "trial: 2, epoch, 26, iter: 1, curr loss: 0.5190558433532715, avg loss: 0.5190558433532715\n",
      "trial: 2, epoch, 27, iter: 1, curr loss: 0.5229166150093079, avg loss: 0.5229166150093079\n",
      "trial: 2, epoch, 28, iter: 1, curr loss: 0.5340062379837036, avg loss: 0.5340062379837036\n",
      "trial: 2, epoch, 29, iter: 1, curr loss: 0.5242683291435242, avg loss: 0.5242683291435242\n",
      "trial: 2, epoch, 30, iter: 1, curr loss: 0.5287232398986816, avg loss: 0.5287232398986816\n",
      "trial: 2, epoch, 31, iter: 1, curr loss: 0.5282556414604187, avg loss: 0.5282556414604187\n",
      "trial: 2, epoch, 32, iter: 1, curr loss: 0.5360798835754395, avg loss: 0.5360798835754395\n",
      "trial: 2, epoch, 33, iter: 1, curr loss: 0.5232155323028564, avg loss: 0.5232155323028564\n",
      "trial: 2, epoch, 34, iter: 1, curr loss: 0.523842453956604, avg loss: 0.523842453956604\n",
      "trial: 2, epoch, 35, iter: 1, curr loss: 0.5329000949859619, avg loss: 0.5329000949859619\n",
      "trial: 2, epoch, 36, iter: 1, curr loss: 0.5239546895027161, avg loss: 0.5239546895027161\n",
      "trial: 2, epoch, 37, iter: 1, curr loss: 0.5306743383407593, avg loss: 0.5306743383407593\n",
      "trial: 2, epoch, 38, iter: 1, curr loss: 0.5235702395439148, avg loss: 0.5235702395439148\n",
      "trial: 2, epoch, 39, iter: 1, curr loss: 0.5213908553123474, avg loss: 0.5213908553123474\n",
      "trial: 2, epoch, 40, iter: 1, curr loss: 0.5173797607421875, avg loss: 0.5173797607421875\n",
      "trial: 2, epoch, 41, iter: 1, curr loss: 0.5302930474281311, avg loss: 0.5302930474281311\n",
      "trial: 2, epoch, 42, iter: 1, curr loss: 0.52082359790802, avg loss: 0.52082359790802\n",
      "trial: 2, epoch, 43, iter: 1, curr loss: 0.5315662622451782, avg loss: 0.5315662622451782\n",
      "trial: 2, epoch, 44, iter: 1, curr loss: 0.531093955039978, avg loss: 0.531093955039978\n",
      "trial: 2, epoch, 45, iter: 1, curr loss: 0.5275764465332031, avg loss: 0.5275764465332031\n",
      "trial: 2, epoch, 46, iter: 1, curr loss: 0.529544472694397, avg loss: 0.529544472694397\n",
      "trial: 2, epoch, 47, iter: 1, curr loss: 0.524592399597168, avg loss: 0.524592399597168\n",
      "trial: 2, epoch, 48, iter: 1, curr loss: 0.5236798524856567, avg loss: 0.5236798524856567\n",
      "trial: 2, epoch, 49, iter: 1, curr loss: 0.5303797125816345, avg loss: 0.5303797125816345\n",
      "trial: 2, epoch, 50, iter: 1, curr loss: 0.5219976902008057, avg loss: 0.5219976902008057\n",
      "trial: 2, ldr: 0.5284045934677124, dv: 0.5659411549568176, nwj: 0.5652453899383545\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 3, epoch, 1, iter: 1, curr loss: 0.6935515999794006, avg loss: 0.6935515999794006\n",
      "trial: 3, epoch, 2, iter: 1, curr loss: 0.5274573564529419, avg loss: 0.5274573564529419\n",
      "trial: 3, epoch, 3, iter: 1, curr loss: 0.5267087817192078, avg loss: 0.5267087817192078\n",
      "trial: 3, epoch, 4, iter: 1, curr loss: 0.5335354208946228, avg loss: 0.5335354208946228\n",
      "trial: 3, epoch, 5, iter: 1, curr loss: 0.5280054807662964, avg loss: 0.5280054807662964\n",
      "trial: 3, epoch, 6, iter: 1, curr loss: 0.5345520377159119, avg loss: 0.5345520377159119\n",
      "trial: 3, epoch, 7, iter: 1, curr loss: 0.5278489589691162, avg loss: 0.5278489589691162\n",
      "trial: 3, epoch, 8, iter: 1, curr loss: 0.5308332443237305, avg loss: 0.5308332443237305\n",
      "trial: 3, epoch, 9, iter: 1, curr loss: 0.5313252806663513, avg loss: 0.5313252806663513\n",
      "trial: 3, epoch, 10, iter: 1, curr loss: 0.5213333964347839, avg loss: 0.5213333964347839\n",
      "trial: 3, epoch, 11, iter: 1, curr loss: 0.5268323421478271, avg loss: 0.5268323421478271\n",
      "trial: 3, epoch, 12, iter: 1, curr loss: 0.5221914649009705, avg loss: 0.5221914649009705\n",
      "trial: 3, epoch, 13, iter: 1, curr loss: 0.5241296291351318, avg loss: 0.5241296291351318\n",
      "trial: 3, epoch, 14, iter: 1, curr loss: 0.5367711186408997, avg loss: 0.5367711186408997\n",
      "trial: 3, epoch, 15, iter: 1, curr loss: 0.5272180438041687, avg loss: 0.5272180438041687\n",
      "trial: 3, epoch, 16, iter: 1, curr loss: 0.5278448462486267, avg loss: 0.5278448462486267\n",
      "trial: 3, epoch, 17, iter: 1, curr loss: 0.5232073068618774, avg loss: 0.5232073068618774\n",
      "trial: 3, epoch, 18, iter: 1, curr loss: 0.5267913341522217, avg loss: 0.5267913341522217\n",
      "trial: 3, epoch, 19, iter: 1, curr loss: 0.5336726903915405, avg loss: 0.5336726903915405\n",
      "trial: 3, epoch, 20, iter: 1, curr loss: 0.5364606380462646, avg loss: 0.5364606380462646\n",
      "trial: 3, epoch, 21, iter: 1, curr loss: 0.5166294574737549, avg loss: 0.5166294574737549\n",
      "trial: 3, epoch, 22, iter: 1, curr loss: 0.5356279611587524, avg loss: 0.5356279611587524\n",
      "trial: 3, epoch, 23, iter: 1, curr loss: 0.5186001658439636, avg loss: 0.5186001658439636\n",
      "trial: 3, epoch, 24, iter: 1, curr loss: 0.5241190195083618, avg loss: 0.5241190195083618\n",
      "trial: 3, epoch, 25, iter: 1, curr loss: 0.5235110521316528, avg loss: 0.5235110521316528\n",
      "trial: 3, epoch, 26, iter: 1, curr loss: 0.5174276828765869, avg loss: 0.5174276828765869\n",
      "trial: 3, epoch, 27, iter: 1, curr loss: 0.5306157469749451, avg loss: 0.5306157469749451\n",
      "trial: 3, epoch, 28, iter: 1, curr loss: 0.5297404527664185, avg loss: 0.5297404527664185\n",
      "trial: 3, epoch, 29, iter: 1, curr loss: 0.5253591537475586, avg loss: 0.5253591537475586\n",
      "trial: 3, epoch, 30, iter: 1, curr loss: 0.5336635112762451, avg loss: 0.5336635112762451\n",
      "trial: 3, epoch, 31, iter: 1, curr loss: 0.5346453189849854, avg loss: 0.5346453189849854\n",
      "trial: 3, epoch, 32, iter: 1, curr loss: 0.5247882604598999, avg loss: 0.5247882604598999\n",
      "trial: 3, epoch, 33, iter: 1, curr loss: 0.5263651609420776, avg loss: 0.5263651609420776\n",
      "trial: 3, epoch, 34, iter: 1, curr loss: 0.5284881591796875, avg loss: 0.5284881591796875\n",
      "trial: 3, epoch, 35, iter: 1, curr loss: 0.523379921913147, avg loss: 0.523379921913147\n",
      "trial: 3, epoch, 36, iter: 1, curr loss: 0.5220414996147156, avg loss: 0.5220414996147156\n",
      "trial: 3, epoch, 37, iter: 1, curr loss: 0.5201857089996338, avg loss: 0.5201857089996338\n",
      "trial: 3, epoch, 38, iter: 1, curr loss: 0.5329287648200989, avg loss: 0.5329287648200989\n",
      "trial: 3, epoch, 39, iter: 1, curr loss: 0.5248974561691284, avg loss: 0.5248974561691284\n",
      "trial: 3, epoch, 40, iter: 1, curr loss: 0.5287352204322815, avg loss: 0.5287352204322815\n",
      "trial: 3, epoch, 41, iter: 1, curr loss: 0.517926037311554, avg loss: 0.517926037311554\n",
      "trial: 3, epoch, 42, iter: 1, curr loss: 0.5318105220794678, avg loss: 0.5318105220794678\n",
      "trial: 3, epoch, 43, iter: 1, curr loss: 0.5244784951210022, avg loss: 0.5244784951210022\n",
      "trial: 3, epoch, 44, iter: 1, curr loss: 0.5227726101875305, avg loss: 0.5227726101875305\n",
      "trial: 3, epoch, 45, iter: 1, curr loss: 0.5174713730812073, avg loss: 0.5174713730812073\n",
      "trial: 3, epoch, 46, iter: 1, curr loss: 0.5362621545791626, avg loss: 0.5362621545791626\n",
      "trial: 3, epoch, 47, iter: 1, curr loss: 0.5265525579452515, avg loss: 0.5265525579452515\n",
      "trial: 3, epoch, 48, iter: 1, curr loss: 0.5206656455993652, avg loss: 0.5206656455993652\n",
      "trial: 3, epoch, 49, iter: 1, curr loss: 0.5199068784713745, avg loss: 0.5199068784713745\n",
      "trial: 3, epoch, 50, iter: 1, curr loss: 0.5155454874038696, avg loss: 0.5155454874038696\n",
      "trial: 3, ldr: 0.5584819316864014, dv: 0.5630174875259399, nwj: 0.5630072355270386\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 4, epoch, 1, iter: 1, curr loss: 0.6945855617523193, avg loss: 0.6945855617523193\n",
      "trial: 4, epoch, 2, iter: 1, curr loss: 0.5343254208564758, avg loss: 0.5343254208564758\n",
      "trial: 4, epoch, 3, iter: 1, curr loss: 0.5382225513458252, avg loss: 0.5382225513458252\n",
      "trial: 4, epoch, 4, iter: 1, curr loss: 0.5273656845092773, avg loss: 0.5273656845092773\n",
      "trial: 4, epoch, 5, iter: 1, curr loss: 0.5250194668769836, avg loss: 0.5250194668769836\n",
      "trial: 4, epoch, 6, iter: 1, curr loss: 0.5170859098434448, avg loss: 0.5170859098434448\n",
      "trial: 4, epoch, 7, iter: 1, curr loss: 0.5288302898406982, avg loss: 0.5288302898406982\n",
      "trial: 4, epoch, 8, iter: 1, curr loss: 0.5261257886886597, avg loss: 0.5261257886886597\n",
      "trial: 4, epoch, 9, iter: 1, curr loss: 0.5242355465888977, avg loss: 0.5242355465888977\n",
      "trial: 4, epoch, 10, iter: 1, curr loss: 0.5137298107147217, avg loss: 0.5137298107147217\n",
      "trial: 4, epoch, 11, iter: 1, curr loss: 0.5271865725517273, avg loss: 0.5271865725517273\n",
      "trial: 4, epoch, 12, iter: 1, curr loss: 0.527014434337616, avg loss: 0.527014434337616\n",
      "trial: 4, epoch, 13, iter: 1, curr loss: 0.5327408313751221, avg loss: 0.5327408313751221\n",
      "trial: 4, epoch, 14, iter: 1, curr loss: 0.5182408094406128, avg loss: 0.5182408094406128\n",
      "trial: 4, epoch, 15, iter: 1, curr loss: 0.537399411201477, avg loss: 0.537399411201477\n",
      "trial: 4, epoch, 16, iter: 1, curr loss: 0.5253629684448242, avg loss: 0.5253629684448242\n",
      "trial: 4, epoch, 17, iter: 1, curr loss: 0.5289797186851501, avg loss: 0.5289797186851501\n",
      "trial: 4, epoch, 18, iter: 1, curr loss: 0.5288466215133667, avg loss: 0.5288466215133667\n",
      "trial: 4, epoch, 19, iter: 1, curr loss: 0.5304630398750305, avg loss: 0.5304630398750305\n",
      "trial: 4, epoch, 20, iter: 1, curr loss: 0.5199218988418579, avg loss: 0.5199218988418579\n",
      "trial: 4, epoch, 21, iter: 1, curr loss: 0.5221884250640869, avg loss: 0.5221884250640869\n",
      "trial: 4, epoch, 22, iter: 1, curr loss: 0.5386104583740234, avg loss: 0.5386104583740234\n",
      "trial: 4, epoch, 23, iter: 1, curr loss: 0.5258797407150269, avg loss: 0.5258797407150269\n",
      "trial: 4, epoch, 24, iter: 1, curr loss: 0.5274620056152344, avg loss: 0.5274620056152344\n",
      "trial: 4, epoch, 25, iter: 1, curr loss: 0.5273362398147583, avg loss: 0.5273362398147583\n",
      "trial: 4, epoch, 26, iter: 1, curr loss: 0.5268890857696533, avg loss: 0.5268890857696533\n",
      "trial: 4, epoch, 27, iter: 1, curr loss: 0.5259366035461426, avg loss: 0.5259366035461426\n",
      "trial: 4, epoch, 28, iter: 1, curr loss: 0.526374340057373, avg loss: 0.526374340057373\n",
      "trial: 4, epoch, 29, iter: 1, curr loss: 0.5379729270935059, avg loss: 0.5379729270935059\n",
      "trial: 4, epoch, 30, iter: 1, curr loss: 0.5176025629043579, avg loss: 0.5176025629043579\n",
      "trial: 4, epoch, 31, iter: 1, curr loss: 0.5112884640693665, avg loss: 0.5112884640693665\n",
      "trial: 4, epoch, 32, iter: 1, curr loss: 0.5205904245376587, avg loss: 0.5205904245376587\n",
      "trial: 4, epoch, 33, iter: 1, curr loss: 0.5251139402389526, avg loss: 0.5251139402389526\n",
      "trial: 4, epoch, 34, iter: 1, curr loss: 0.5257047414779663, avg loss: 0.5257047414779663\n",
      "trial: 4, epoch, 35, iter: 1, curr loss: 0.5244492888450623, avg loss: 0.5244492888450623\n",
      "trial: 4, epoch, 36, iter: 1, curr loss: 0.5240721702575684, avg loss: 0.5240721702575684\n",
      "trial: 4, epoch, 37, iter: 1, curr loss: 0.5363324284553528, avg loss: 0.5363324284553528\n",
      "trial: 4, epoch, 38, iter: 1, curr loss: 0.5118693113327026, avg loss: 0.5118693113327026\n",
      "trial: 4, epoch, 39, iter: 1, curr loss: 0.5194592475891113, avg loss: 0.5194592475891113\n",
      "trial: 4, epoch, 40, iter: 1, curr loss: 0.5317102670669556, avg loss: 0.5317102670669556\n",
      "trial: 4, epoch, 41, iter: 1, curr loss: 0.5285854339599609, avg loss: 0.5285854339599609\n",
      "trial: 4, epoch, 42, iter: 1, curr loss: 0.5193823575973511, avg loss: 0.5193823575973511\n",
      "trial: 4, epoch, 43, iter: 1, curr loss: 0.5279426574707031, avg loss: 0.5279426574707031\n",
      "trial: 4, epoch, 44, iter: 1, curr loss: 0.5213222503662109, avg loss: 0.5213222503662109\n",
      "trial: 4, epoch, 45, iter: 1, curr loss: 0.5187998414039612, avg loss: 0.5187998414039612\n",
      "trial: 4, epoch, 46, iter: 1, curr loss: 0.5301644802093506, avg loss: 0.5301644802093506\n",
      "trial: 4, epoch, 47, iter: 1, curr loss: 0.5217635631561279, avg loss: 0.5217635631561279\n",
      "trial: 4, epoch, 48, iter: 1, curr loss: 0.5216621160507202, avg loss: 0.5216621160507202\n",
      "trial: 4, epoch, 49, iter: 1, curr loss: 0.5267724990844727, avg loss: 0.5267724990844727\n",
      "trial: 4, epoch, 50, iter: 1, curr loss: 0.5203739404678345, avg loss: 0.5203739404678345\n",
      "trial: 4, ldr: 0.6227550506591797, dv: 0.5658659338951111, nwj: 0.5642166137695312\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 5, epoch, 1, iter: 1, curr loss: 0.6921516060829163, avg loss: 0.6921516060829163\n",
      "trial: 5, epoch, 2, iter: 1, curr loss: 0.5343258380889893, avg loss: 0.5343258380889893\n",
      "trial: 5, epoch, 3, iter: 1, curr loss: 0.5200453400611877, avg loss: 0.5200453400611877\n",
      "trial: 5, epoch, 4, iter: 1, curr loss: 0.5270571112632751, avg loss: 0.5270571112632751\n",
      "trial: 5, epoch, 5, iter: 1, curr loss: 0.5296041965484619, avg loss: 0.5296041965484619\n",
      "trial: 5, epoch, 6, iter: 1, curr loss: 0.5304582118988037, avg loss: 0.5304582118988037\n",
      "trial: 5, epoch, 7, iter: 1, curr loss: 0.523118257522583, avg loss: 0.523118257522583\n",
      "trial: 5, epoch, 8, iter: 1, curr loss: 0.5300532579421997, avg loss: 0.5300532579421997\n",
      "trial: 5, epoch, 9, iter: 1, curr loss: 0.5251290798187256, avg loss: 0.5251290798187256\n",
      "trial: 5, epoch, 10, iter: 1, curr loss: 0.5226455926895142, avg loss: 0.5226455926895142\n",
      "trial: 5, epoch, 11, iter: 1, curr loss: 0.5345392227172852, avg loss: 0.5345392227172852\n",
      "trial: 5, epoch, 12, iter: 1, curr loss: 0.5270131826400757, avg loss: 0.5270131826400757\n",
      "trial: 5, epoch, 13, iter: 1, curr loss: 0.5348438024520874, avg loss: 0.5348438024520874\n",
      "trial: 5, epoch, 14, iter: 1, curr loss: 0.5264736413955688, avg loss: 0.5264736413955688\n",
      "trial: 5, epoch, 15, iter: 1, curr loss: 0.5322744250297546, avg loss: 0.5322744250297546\n",
      "trial: 5, epoch, 16, iter: 1, curr loss: 0.5369281768798828, avg loss: 0.5369281768798828\n",
      "trial: 5, epoch, 17, iter: 1, curr loss: 0.5243256092071533, avg loss: 0.5243256092071533\n",
      "trial: 5, epoch, 18, iter: 1, curr loss: 0.524913489818573, avg loss: 0.524913489818573\n",
      "trial: 5, epoch, 19, iter: 1, curr loss: 0.5345889329910278, avg loss: 0.5345889329910278\n",
      "trial: 5, epoch, 20, iter: 1, curr loss: 0.5260293483734131, avg loss: 0.5260293483734131\n",
      "trial: 5, epoch, 21, iter: 1, curr loss: 0.5232152938842773, avg loss: 0.5232152938842773\n",
      "trial: 5, epoch, 22, iter: 1, curr loss: 0.534877359867096, avg loss: 0.534877359867096\n",
      "trial: 5, epoch, 23, iter: 1, curr loss: 0.5183645486831665, avg loss: 0.5183645486831665\n",
      "trial: 5, epoch, 24, iter: 1, curr loss: 0.5360763669013977, avg loss: 0.5360763669013977\n",
      "trial: 5, epoch, 25, iter: 1, curr loss: 0.5274357199668884, avg loss: 0.5274357199668884\n",
      "trial: 5, epoch, 26, iter: 1, curr loss: 0.5244516730308533, avg loss: 0.5244516730308533\n",
      "trial: 5, epoch, 27, iter: 1, curr loss: 0.5283159613609314, avg loss: 0.5283159613609314\n",
      "trial: 5, epoch, 28, iter: 1, curr loss: 0.5259866714477539, avg loss: 0.5259866714477539\n",
      "trial: 5, epoch, 29, iter: 1, curr loss: 0.5201772451400757, avg loss: 0.5201772451400757\n",
      "trial: 5, epoch, 30, iter: 1, curr loss: 0.533372163772583, avg loss: 0.533372163772583\n",
      "trial: 5, epoch, 31, iter: 1, curr loss: 0.526631772518158, avg loss: 0.526631772518158\n",
      "trial: 5, epoch, 32, iter: 1, curr loss: 0.522629976272583, avg loss: 0.522629976272583\n",
      "trial: 5, epoch, 33, iter: 1, curr loss: 0.5231934785842896, avg loss: 0.5231934785842896\n",
      "trial: 5, epoch, 34, iter: 1, curr loss: 0.5207279920578003, avg loss: 0.5207279920578003\n",
      "trial: 5, epoch, 35, iter: 1, curr loss: 0.5331539511680603, avg loss: 0.5331539511680603\n",
      "trial: 5, epoch, 36, iter: 1, curr loss: 0.521270751953125, avg loss: 0.521270751953125\n",
      "trial: 5, epoch, 37, iter: 1, curr loss: 0.5266040563583374, avg loss: 0.5266040563583374\n",
      "trial: 5, epoch, 38, iter: 1, curr loss: 0.5329602956771851, avg loss: 0.5329602956771851\n",
      "trial: 5, epoch, 39, iter: 1, curr loss: 0.5140309929847717, avg loss: 0.5140309929847717\n",
      "trial: 5, epoch, 40, iter: 1, curr loss: 0.5266174077987671, avg loss: 0.5266174077987671\n",
      "trial: 5, epoch, 41, iter: 1, curr loss: 0.525693416595459, avg loss: 0.525693416595459\n",
      "trial: 5, epoch, 42, iter: 1, curr loss: 0.5134061574935913, avg loss: 0.5134061574935913\n",
      "trial: 5, epoch, 43, iter: 1, curr loss: 0.5222256183624268, avg loss: 0.5222256183624268\n",
      "trial: 5, epoch, 44, iter: 1, curr loss: 0.5248568058013916, avg loss: 0.5248568058013916\n",
      "trial: 5, epoch, 45, iter: 1, curr loss: 0.5314600467681885, avg loss: 0.5314600467681885\n",
      "trial: 5, epoch, 46, iter: 1, curr loss: 0.5154561996459961, avg loss: 0.5154561996459961\n",
      "trial: 5, epoch, 47, iter: 1, curr loss: 0.5187028050422668, avg loss: 0.5187028050422668\n",
      "trial: 5, epoch, 48, iter: 1, curr loss: 0.5227388143539429, avg loss: 0.5227388143539429\n",
      "trial: 5, epoch, 49, iter: 1, curr loss: 0.5353133082389832, avg loss: 0.5353133082389832\n",
      "trial: 5, epoch, 50, iter: 1, curr loss: 0.5210455656051636, avg loss: 0.5210455656051636\n",
      "trial: 5, ldr: 0.5379879474639893, dv: 0.5653667449951172, nwj: 0.5649953484535217\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 6, epoch, 1, iter: 1, curr loss: 0.697655439376831, avg loss: 0.697655439376831\n",
      "trial: 6, epoch, 2, iter: 1, curr loss: 0.5235099196434021, avg loss: 0.5235099196434021\n",
      "trial: 6, epoch, 3, iter: 1, curr loss: 0.5335493683815002, avg loss: 0.5335493683815002\n",
      "trial: 6, epoch, 4, iter: 1, curr loss: 0.5248309373855591, avg loss: 0.5248309373855591\n",
      "trial: 6, epoch, 5, iter: 1, curr loss: 0.5168408155441284, avg loss: 0.5168408155441284\n",
      "trial: 6, epoch, 6, iter: 1, curr loss: 0.5380923748016357, avg loss: 0.5380923748016357\n",
      "trial: 6, epoch, 7, iter: 1, curr loss: 0.520012378692627, avg loss: 0.520012378692627\n",
      "trial: 6, epoch, 8, iter: 1, curr loss: 0.5241191387176514, avg loss: 0.5241191387176514\n",
      "trial: 6, epoch, 9, iter: 1, curr loss: 0.5403961539268494, avg loss: 0.5403961539268494\n",
      "trial: 6, epoch, 10, iter: 1, curr loss: 0.5281038880348206, avg loss: 0.5281038880348206\n",
      "trial: 6, epoch, 11, iter: 1, curr loss: 0.5204817056655884, avg loss: 0.5204817056655884\n",
      "trial: 6, epoch, 12, iter: 1, curr loss: 0.5312528610229492, avg loss: 0.5312528610229492\n",
      "trial: 6, epoch, 13, iter: 1, curr loss: 0.5277321338653564, avg loss: 0.5277321338653564\n",
      "trial: 6, epoch, 14, iter: 1, curr loss: 0.5241517424583435, avg loss: 0.5241517424583435\n",
      "trial: 6, epoch, 15, iter: 1, curr loss: 0.5108397603034973, avg loss: 0.5108397603034973\n",
      "trial: 6, epoch, 16, iter: 1, curr loss: 0.5305909514427185, avg loss: 0.5305909514427185\n",
      "trial: 6, epoch, 17, iter: 1, curr loss: 0.5227973461151123, avg loss: 0.5227973461151123\n",
      "trial: 6, epoch, 18, iter: 1, curr loss: 0.5255748629570007, avg loss: 0.5255748629570007\n",
      "trial: 6, epoch, 19, iter: 1, curr loss: 0.5280839204788208, avg loss: 0.5280839204788208\n",
      "trial: 6, epoch, 20, iter: 1, curr loss: 0.530515193939209, avg loss: 0.530515193939209\n",
      "trial: 6, epoch, 21, iter: 1, curr loss: 0.5187493562698364, avg loss: 0.5187493562698364\n",
      "trial: 6, epoch, 22, iter: 1, curr loss: 0.5200703144073486, avg loss: 0.5200703144073486\n",
      "trial: 6, epoch, 23, iter: 1, curr loss: 0.5266212224960327, avg loss: 0.5266212224960327\n",
      "trial: 6, epoch, 24, iter: 1, curr loss: 0.5247694849967957, avg loss: 0.5247694849967957\n",
      "trial: 6, epoch, 25, iter: 1, curr loss: 0.5153816938400269, avg loss: 0.5153816938400269\n",
      "trial: 6, epoch, 26, iter: 1, curr loss: 0.5262784957885742, avg loss: 0.5262784957885742\n",
      "trial: 6, epoch, 27, iter: 1, curr loss: 0.5214147567749023, avg loss: 0.5214147567749023\n",
      "trial: 6, epoch, 28, iter: 1, curr loss: 0.5161601305007935, avg loss: 0.5161601305007935\n",
      "trial: 6, epoch, 29, iter: 1, curr loss: 0.5260378122329712, avg loss: 0.5260378122329712\n",
      "trial: 6, epoch, 30, iter: 1, curr loss: 0.5308794975280762, avg loss: 0.5308794975280762\n",
      "trial: 6, epoch, 31, iter: 1, curr loss: 0.5182287693023682, avg loss: 0.5182287693023682\n",
      "trial: 6, epoch, 32, iter: 1, curr loss: 0.5222110748291016, avg loss: 0.5222110748291016\n",
      "trial: 6, epoch, 33, iter: 1, curr loss: 0.5283793807029724, avg loss: 0.5283793807029724\n",
      "trial: 6, epoch, 34, iter: 1, curr loss: 0.5226151943206787, avg loss: 0.5226151943206787\n",
      "trial: 6, epoch, 35, iter: 1, curr loss: 0.5212990045547485, avg loss: 0.5212990045547485\n",
      "trial: 6, epoch, 36, iter: 1, curr loss: 0.5237410068511963, avg loss: 0.5237410068511963\n",
      "trial: 6, epoch, 37, iter: 1, curr loss: 0.5225142240524292, avg loss: 0.5225142240524292\n",
      "trial: 6, epoch, 38, iter: 1, curr loss: 0.5320169925689697, avg loss: 0.5320169925689697\n",
      "trial: 6, epoch, 39, iter: 1, curr loss: 0.5252788066864014, avg loss: 0.5252788066864014\n",
      "trial: 6, epoch, 40, iter: 1, curr loss: 0.5202434659004211, avg loss: 0.5202434659004211\n",
      "trial: 6, epoch, 41, iter: 1, curr loss: 0.5289242267608643, avg loss: 0.5289242267608643\n",
      "trial: 6, epoch, 42, iter: 1, curr loss: 0.5298519134521484, avg loss: 0.5298519134521484\n",
      "trial: 6, epoch, 43, iter: 1, curr loss: 0.5277010202407837, avg loss: 0.5277010202407837\n",
      "trial: 6, epoch, 44, iter: 1, curr loss: 0.5226292610168457, avg loss: 0.5226292610168457\n",
      "trial: 6, epoch, 45, iter: 1, curr loss: 0.5178667306900024, avg loss: 0.5178667306900024\n",
      "trial: 6, epoch, 46, iter: 1, curr loss: 0.5196158289909363, avg loss: 0.5196158289909363\n",
      "trial: 6, epoch, 47, iter: 1, curr loss: 0.5251970291137695, avg loss: 0.5251970291137695\n",
      "trial: 6, epoch, 48, iter: 1, curr loss: 0.5288699269294739, avg loss: 0.5288699269294739\n",
      "trial: 6, epoch, 49, iter: 1, curr loss: 0.5279232859611511, avg loss: 0.5279232859611511\n",
      "trial: 6, epoch, 50, iter: 1, curr loss: 0.5265641212463379, avg loss: 0.5265641212463379\n",
      "trial: 6, ldr: 0.5489303469657898, dv: 0.5661395788192749, nwj: 0.5659923553466797\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 7, epoch, 1, iter: 1, curr loss: 0.695770263671875, avg loss: 0.695770263671875\n",
      "trial: 7, epoch, 2, iter: 1, curr loss: 0.5274640321731567, avg loss: 0.5274640321731567\n",
      "trial: 7, epoch, 3, iter: 1, curr loss: 0.524742603302002, avg loss: 0.524742603302002\n",
      "trial: 7, epoch, 4, iter: 1, curr loss: 0.52949059009552, avg loss: 0.52949059009552\n",
      "trial: 7, epoch, 5, iter: 1, curr loss: 0.5234309434890747, avg loss: 0.5234309434890747\n",
      "trial: 7, epoch, 6, iter: 1, curr loss: 0.5154206156730652, avg loss: 0.5154206156730652\n",
      "trial: 7, epoch, 7, iter: 1, curr loss: 0.5179126262664795, avg loss: 0.5179126262664795\n",
      "trial: 7, epoch, 8, iter: 1, curr loss: 0.5342075824737549, avg loss: 0.5342075824737549\n",
      "trial: 7, epoch, 9, iter: 1, curr loss: 0.5194742679595947, avg loss: 0.5194742679595947\n",
      "trial: 7, epoch, 10, iter: 1, curr loss: 0.5336916446685791, avg loss: 0.5336916446685791\n",
      "trial: 7, epoch, 11, iter: 1, curr loss: 0.5233759880065918, avg loss: 0.5233759880065918\n",
      "trial: 7, epoch, 12, iter: 1, curr loss: 0.5267471671104431, avg loss: 0.5267471671104431\n",
      "trial: 7, epoch, 13, iter: 1, curr loss: 0.5213510990142822, avg loss: 0.5213510990142822\n",
      "trial: 7, epoch, 14, iter: 1, curr loss: 0.5354578495025635, avg loss: 0.5354578495025635\n",
      "trial: 7, epoch, 15, iter: 1, curr loss: 0.5288373827934265, avg loss: 0.5288373827934265\n",
      "trial: 7, epoch, 16, iter: 1, curr loss: 0.5198080539703369, avg loss: 0.5198080539703369\n",
      "trial: 7, epoch, 17, iter: 1, curr loss: 0.5270956158638, avg loss: 0.5270956158638\n",
      "trial: 7, epoch, 18, iter: 1, curr loss: 0.5223751068115234, avg loss: 0.5223751068115234\n",
      "trial: 7, epoch, 19, iter: 1, curr loss: 0.5173981785774231, avg loss: 0.5173981785774231\n",
      "trial: 7, epoch, 20, iter: 1, curr loss: 0.5366935729980469, avg loss: 0.5366935729980469\n",
      "trial: 7, epoch, 21, iter: 1, curr loss: 0.5267832279205322, avg loss: 0.5267832279205322\n",
      "trial: 7, epoch, 22, iter: 1, curr loss: 0.5296536087989807, avg loss: 0.5296536087989807\n",
      "trial: 7, epoch, 23, iter: 1, curr loss: 0.5199626684188843, avg loss: 0.5199626684188843\n",
      "trial: 7, epoch, 24, iter: 1, curr loss: 0.5319917798042297, avg loss: 0.5319917798042297\n",
      "trial: 7, epoch, 25, iter: 1, curr loss: 0.519455075263977, avg loss: 0.519455075263977\n",
      "trial: 7, epoch, 26, iter: 1, curr loss: 0.5235092639923096, avg loss: 0.5235092639923096\n",
      "trial: 7, epoch, 27, iter: 1, curr loss: 0.5294051766395569, avg loss: 0.5294051766395569\n",
      "trial: 7, epoch, 28, iter: 1, curr loss: 0.5345526933670044, avg loss: 0.5345526933670044\n",
      "trial: 7, epoch, 29, iter: 1, curr loss: 0.5250686407089233, avg loss: 0.5250686407089233\n",
      "trial: 7, epoch, 30, iter: 1, curr loss: 0.5146242380142212, avg loss: 0.5146242380142212\n",
      "trial: 7, epoch, 31, iter: 1, curr loss: 0.5266506671905518, avg loss: 0.5266506671905518\n",
      "trial: 7, epoch, 32, iter: 1, curr loss: 0.5295940041542053, avg loss: 0.5295940041542053\n",
      "trial: 7, epoch, 33, iter: 1, curr loss: 0.5361813306808472, avg loss: 0.5361813306808472\n",
      "trial: 7, epoch, 34, iter: 1, curr loss: 0.5223041772842407, avg loss: 0.5223041772842407\n",
      "trial: 7, epoch, 35, iter: 1, curr loss: 0.5373164415359497, avg loss: 0.5373164415359497\n",
      "trial: 7, epoch, 36, iter: 1, curr loss: 0.526563286781311, avg loss: 0.526563286781311\n",
      "trial: 7, epoch, 37, iter: 1, curr loss: 0.5230931043624878, avg loss: 0.5230931043624878\n",
      "trial: 7, epoch, 38, iter: 1, curr loss: 0.5295759439468384, avg loss: 0.5295759439468384\n",
      "trial: 7, epoch, 39, iter: 1, curr loss: 0.528760552406311, avg loss: 0.528760552406311\n",
      "trial: 7, epoch, 40, iter: 1, curr loss: 0.5282037258148193, avg loss: 0.5282037258148193\n",
      "trial: 7, epoch, 41, iter: 1, curr loss: 0.5313515067100525, avg loss: 0.5313515067100525\n",
      "trial: 7, epoch, 42, iter: 1, curr loss: 0.5269931554794312, avg loss: 0.5269931554794312\n",
      "trial: 7, epoch, 43, iter: 1, curr loss: 0.5218750238418579, avg loss: 0.5218750238418579\n",
      "trial: 7, epoch, 44, iter: 1, curr loss: 0.5210505723953247, avg loss: 0.5210505723953247\n",
      "trial: 7, epoch, 45, iter: 1, curr loss: 0.5260850191116333, avg loss: 0.5260850191116333\n",
      "trial: 7, epoch, 46, iter: 1, curr loss: 0.5227068662643433, avg loss: 0.5227068662643433\n",
      "trial: 7, epoch, 47, iter: 1, curr loss: 0.5308135747909546, avg loss: 0.5308135747909546\n",
      "trial: 7, epoch, 48, iter: 1, curr loss: 0.5271327495574951, avg loss: 0.5271327495574951\n",
      "trial: 7, epoch, 49, iter: 1, curr loss: 0.5169004201889038, avg loss: 0.5169004201889038\n",
      "trial: 7, epoch, 50, iter: 1, curr loss: 0.5321038365364075, avg loss: 0.5321038365364075\n",
      "trial: 7, ldr: 0.6046969294548035, dv: 0.5615337491035461, nwj: 0.5605886578559875\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 8, epoch, 1, iter: 1, curr loss: 0.6933055520057678, avg loss: 0.6933055520057678\n",
      "trial: 8, epoch, 2, iter: 1, curr loss: 0.5257664322853088, avg loss: 0.5257664322853088\n",
      "trial: 8, epoch, 3, iter: 1, curr loss: 0.5227164030075073, avg loss: 0.5227164030075073\n",
      "trial: 8, epoch, 4, iter: 1, curr loss: 0.5277987122535706, avg loss: 0.5277987122535706\n",
      "trial: 8, epoch, 5, iter: 1, curr loss: 0.5304492712020874, avg loss: 0.5304492712020874\n",
      "trial: 8, epoch, 6, iter: 1, curr loss: 0.5347695350646973, avg loss: 0.5347695350646973\n",
      "trial: 8, epoch, 7, iter: 1, curr loss: 0.5447168350219727, avg loss: 0.5447168350219727\n",
      "trial: 8, epoch, 8, iter: 1, curr loss: 0.5225661993026733, avg loss: 0.5225661993026733\n",
      "trial: 8, epoch, 9, iter: 1, curr loss: 0.5243802070617676, avg loss: 0.5243802070617676\n",
      "trial: 8, epoch, 10, iter: 1, curr loss: 0.5338042974472046, avg loss: 0.5338042974472046\n",
      "trial: 8, epoch, 11, iter: 1, curr loss: 0.5352005362510681, avg loss: 0.5352005362510681\n",
      "trial: 8, epoch, 12, iter: 1, curr loss: 0.5324699878692627, avg loss: 0.5324699878692627\n",
      "trial: 8, epoch, 13, iter: 1, curr loss: 0.5279808044433594, avg loss: 0.5279808044433594\n",
      "trial: 8, epoch, 14, iter: 1, curr loss: 0.5281164646148682, avg loss: 0.5281164646148682\n",
      "trial: 8, epoch, 15, iter: 1, curr loss: 0.5285122394561768, avg loss: 0.5285122394561768\n",
      "trial: 8, epoch, 16, iter: 1, curr loss: 0.5263803005218506, avg loss: 0.5263803005218506\n",
      "trial: 8, epoch, 17, iter: 1, curr loss: 0.5101412534713745, avg loss: 0.5101412534713745\n",
      "trial: 8, epoch, 18, iter: 1, curr loss: 0.518240749835968, avg loss: 0.518240749835968\n",
      "trial: 8, epoch, 19, iter: 1, curr loss: 0.5169066190719604, avg loss: 0.5169066190719604\n",
      "trial: 8, epoch, 20, iter: 1, curr loss: 0.5181775093078613, avg loss: 0.5181775093078613\n",
      "trial: 8, epoch, 21, iter: 1, curr loss: 0.5297681093215942, avg loss: 0.5297681093215942\n",
      "trial: 8, epoch, 22, iter: 1, curr loss: 0.5245944261550903, avg loss: 0.5245944261550903\n",
      "trial: 8, epoch, 23, iter: 1, curr loss: 0.5258723497390747, avg loss: 0.5258723497390747\n",
      "trial: 8, epoch, 24, iter: 1, curr loss: 0.5296506881713867, avg loss: 0.5296506881713867\n",
      "trial: 8, epoch, 25, iter: 1, curr loss: 0.5246789455413818, avg loss: 0.5246789455413818\n",
      "trial: 8, epoch, 26, iter: 1, curr loss: 0.5258475542068481, avg loss: 0.5258475542068481\n",
      "trial: 8, epoch, 27, iter: 1, curr loss: 0.5267965793609619, avg loss: 0.5267965793609619\n",
      "trial: 8, epoch, 28, iter: 1, curr loss: 0.524705171585083, avg loss: 0.524705171585083\n",
      "trial: 8, epoch, 29, iter: 1, curr loss: 0.5244013667106628, avg loss: 0.5244013667106628\n",
      "trial: 8, epoch, 30, iter: 1, curr loss: 0.534101128578186, avg loss: 0.534101128578186\n",
      "trial: 8, epoch, 31, iter: 1, curr loss: 0.5324519872665405, avg loss: 0.5324519872665405\n",
      "trial: 8, epoch, 32, iter: 1, curr loss: 0.5283214449882507, avg loss: 0.5283214449882507\n",
      "trial: 8, epoch, 33, iter: 1, curr loss: 0.5281257629394531, avg loss: 0.5281257629394531\n",
      "trial: 8, epoch, 34, iter: 1, curr loss: 0.5180283188819885, avg loss: 0.5180283188819885\n",
      "trial: 8, epoch, 35, iter: 1, curr loss: 0.5234123468399048, avg loss: 0.5234123468399048\n",
      "trial: 8, epoch, 36, iter: 1, curr loss: 0.5275265574455261, avg loss: 0.5275265574455261\n",
      "trial: 8, epoch, 37, iter: 1, curr loss: 0.5269140005111694, avg loss: 0.5269140005111694\n",
      "trial: 8, epoch, 38, iter: 1, curr loss: 0.5238805413246155, avg loss: 0.5238805413246155\n",
      "trial: 8, epoch, 39, iter: 1, curr loss: 0.5333035588264465, avg loss: 0.5333035588264465\n",
      "trial: 8, epoch, 40, iter: 1, curr loss: 0.5305278301239014, avg loss: 0.5305278301239014\n",
      "trial: 8, epoch, 41, iter: 1, curr loss: 0.5194944143295288, avg loss: 0.5194944143295288\n",
      "trial: 8, epoch, 42, iter: 1, curr loss: 0.5287760496139526, avg loss: 0.5287760496139526\n",
      "trial: 8, epoch, 43, iter: 1, curr loss: 0.5283375978469849, avg loss: 0.5283375978469849\n",
      "trial: 8, epoch, 44, iter: 1, curr loss: 0.5167934894561768, avg loss: 0.5167934894561768\n",
      "trial: 8, epoch, 45, iter: 1, curr loss: 0.5203603506088257, avg loss: 0.5203603506088257\n",
      "trial: 8, epoch, 46, iter: 1, curr loss: 0.5219588875770569, avg loss: 0.5219588875770569\n",
      "trial: 8, epoch, 47, iter: 1, curr loss: 0.5147777795791626, avg loss: 0.5147777795791626\n",
      "trial: 8, epoch, 48, iter: 1, curr loss: 0.5267374515533447, avg loss: 0.5267374515533447\n",
      "trial: 8, epoch, 49, iter: 1, curr loss: 0.5285277366638184, avg loss: 0.5285277366638184\n",
      "trial: 8, epoch, 50, iter: 1, curr loss: 0.5325697660446167, avg loss: 0.5325697660446167\n",
      "trial: 8, ldr: 0.5856092572212219, dv: 0.566003143787384, nwj: 0.5658096671104431\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 9, epoch, 1, iter: 1, curr loss: 0.6946771144866943, avg loss: 0.6946771144866943\n",
      "trial: 9, epoch, 2, iter: 1, curr loss: 0.5310970544815063, avg loss: 0.5310970544815063\n",
      "trial: 9, epoch, 3, iter: 1, curr loss: 0.5215455293655396, avg loss: 0.5215455293655396\n",
      "trial: 9, epoch, 4, iter: 1, curr loss: 0.5316426753997803, avg loss: 0.5316426753997803\n",
      "trial: 9, epoch, 5, iter: 1, curr loss: 0.5279923677444458, avg loss: 0.5279923677444458\n",
      "trial: 9, epoch, 6, iter: 1, curr loss: 0.526085376739502, avg loss: 0.526085376739502\n",
      "trial: 9, epoch, 7, iter: 1, curr loss: 0.5250164270401001, avg loss: 0.5250164270401001\n",
      "trial: 9, epoch, 8, iter: 1, curr loss: 0.5228893160820007, avg loss: 0.5228893160820007\n",
      "trial: 9, epoch, 9, iter: 1, curr loss: 0.5167049169540405, avg loss: 0.5167049169540405\n",
      "trial: 9, epoch, 10, iter: 1, curr loss: 0.5214306116104126, avg loss: 0.5214306116104126\n",
      "trial: 9, epoch, 11, iter: 1, curr loss: 0.5197724103927612, avg loss: 0.5197724103927612\n",
      "trial: 9, epoch, 12, iter: 1, curr loss: 0.5227483510971069, avg loss: 0.5227483510971069\n",
      "trial: 9, epoch, 13, iter: 1, curr loss: 0.526820957660675, avg loss: 0.526820957660675\n",
      "trial: 9, epoch, 14, iter: 1, curr loss: 0.5277119874954224, avg loss: 0.5277119874954224\n",
      "trial: 9, epoch, 15, iter: 1, curr loss: 0.533444881439209, avg loss: 0.533444881439209\n",
      "trial: 9, epoch, 16, iter: 1, curr loss: 0.5207433700561523, avg loss: 0.5207433700561523\n",
      "trial: 9, epoch, 17, iter: 1, curr loss: 0.5275317430496216, avg loss: 0.5275317430496216\n",
      "trial: 9, epoch, 18, iter: 1, curr loss: 0.5242392420768738, avg loss: 0.5242392420768738\n",
      "trial: 9, epoch, 19, iter: 1, curr loss: 0.5233170390129089, avg loss: 0.5233170390129089\n",
      "trial: 9, epoch, 20, iter: 1, curr loss: 0.5246030688285828, avg loss: 0.5246030688285828\n",
      "trial: 9, epoch, 21, iter: 1, curr loss: 0.5226691961288452, avg loss: 0.5226691961288452\n",
      "trial: 9, epoch, 22, iter: 1, curr loss: 0.5238324999809265, avg loss: 0.5238324999809265\n",
      "trial: 9, epoch, 23, iter: 1, curr loss: 0.5181726217269897, avg loss: 0.5181726217269897\n",
      "trial: 9, epoch, 24, iter: 1, curr loss: 0.5294101238250732, avg loss: 0.5294101238250732\n",
      "trial: 9, epoch, 25, iter: 1, curr loss: 0.5266432762145996, avg loss: 0.5266432762145996\n",
      "trial: 9, epoch, 26, iter: 1, curr loss: 0.5220470428466797, avg loss: 0.5220470428466797\n",
      "trial: 9, epoch, 27, iter: 1, curr loss: 0.5307398438453674, avg loss: 0.5307398438453674\n",
      "trial: 9, epoch, 28, iter: 1, curr loss: 0.5205535292625427, avg loss: 0.5205535292625427\n",
      "trial: 9, epoch, 29, iter: 1, curr loss: 0.5252397060394287, avg loss: 0.5252397060394287\n",
      "trial: 9, epoch, 30, iter: 1, curr loss: 0.5339798331260681, avg loss: 0.5339798331260681\n",
      "trial: 9, epoch, 31, iter: 1, curr loss: 0.5339677929878235, avg loss: 0.5339677929878235\n",
      "trial: 9, epoch, 32, iter: 1, curr loss: 0.525267481803894, avg loss: 0.525267481803894\n",
      "trial: 9, epoch, 33, iter: 1, curr loss: 0.5256727933883667, avg loss: 0.5256727933883667\n",
      "trial: 9, epoch, 34, iter: 1, curr loss: 0.5305291414260864, avg loss: 0.5305291414260864\n",
      "trial: 9, epoch, 35, iter: 1, curr loss: 0.5201382637023926, avg loss: 0.5201382637023926\n",
      "trial: 9, epoch, 36, iter: 1, curr loss: 0.5198628306388855, avg loss: 0.5198628306388855\n",
      "trial: 9, epoch, 37, iter: 1, curr loss: 0.5295636653900146, avg loss: 0.5295636653900146\n",
      "trial: 9, epoch, 38, iter: 1, curr loss: 0.5189570188522339, avg loss: 0.5189570188522339\n",
      "trial: 9, epoch, 39, iter: 1, curr loss: 0.5227186679840088, avg loss: 0.5227186679840088\n",
      "trial: 9, epoch, 40, iter: 1, curr loss: 0.5245159864425659, avg loss: 0.5245159864425659\n",
      "trial: 9, epoch, 41, iter: 1, curr loss: 0.5270013809204102, avg loss: 0.5270013809204102\n",
      "trial: 9, epoch, 42, iter: 1, curr loss: 0.5254226326942444, avg loss: 0.5254226326942444\n",
      "trial: 9, epoch, 43, iter: 1, curr loss: 0.5271427631378174, avg loss: 0.5271427631378174\n",
      "trial: 9, epoch, 44, iter: 1, curr loss: 0.5240554213523865, avg loss: 0.5240554213523865\n",
      "trial: 9, epoch, 45, iter: 1, curr loss: 0.5366016626358032, avg loss: 0.5366016626358032\n",
      "trial: 9, epoch, 46, iter: 1, curr loss: 0.5203593969345093, avg loss: 0.5203593969345093\n",
      "trial: 9, epoch, 47, iter: 1, curr loss: 0.526114821434021, avg loss: 0.526114821434021\n",
      "trial: 9, epoch, 48, iter: 1, curr loss: 0.5261554718017578, avg loss: 0.5261554718017578\n",
      "trial: 9, epoch, 49, iter: 1, curr loss: 0.5305299758911133, avg loss: 0.5305299758911133\n",
      "trial: 9, epoch, 50, iter: 1, curr loss: 0.5284311771392822, avg loss: 0.5284311771392822\n",
      "trial: 9, ldr: 0.5876080989837646, dv: 0.566027820110321, nwj: 0.5657932758331299\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 10, epoch, 1, iter: 1, curr loss: 0.6962870359420776, avg loss: 0.6962870359420776\n",
      "trial: 10, epoch, 2, iter: 1, curr loss: 0.5230539441108704, avg loss: 0.5230539441108704\n",
      "trial: 10, epoch, 3, iter: 1, curr loss: 0.5200514793395996, avg loss: 0.5200514793395996\n",
      "trial: 10, epoch, 4, iter: 1, curr loss: 0.5162549018859863, avg loss: 0.5162549018859863\n",
      "trial: 10, epoch, 5, iter: 1, curr loss: 0.5416151285171509, avg loss: 0.5416151285171509\n",
      "trial: 10, epoch, 6, iter: 1, curr loss: 0.5314577221870422, avg loss: 0.5314577221870422\n",
      "trial: 10, epoch, 7, iter: 1, curr loss: 0.530569314956665, avg loss: 0.530569314956665\n",
      "trial: 10, epoch, 8, iter: 1, curr loss: 0.5293914675712585, avg loss: 0.5293914675712585\n",
      "trial: 10, epoch, 9, iter: 1, curr loss: 0.5258201360702515, avg loss: 0.5258201360702515\n",
      "trial: 10, epoch, 10, iter: 1, curr loss: 0.5219857692718506, avg loss: 0.5219857692718506\n",
      "trial: 10, epoch, 11, iter: 1, curr loss: 0.5222967863082886, avg loss: 0.5222967863082886\n",
      "trial: 10, epoch, 12, iter: 1, curr loss: 0.5304872989654541, avg loss: 0.5304872989654541\n",
      "trial: 10, epoch, 13, iter: 1, curr loss: 0.5199019908905029, avg loss: 0.5199019908905029\n",
      "trial: 10, epoch, 14, iter: 1, curr loss: 0.5225338935852051, avg loss: 0.5225338935852051\n",
      "trial: 10, epoch, 15, iter: 1, curr loss: 0.5263404846191406, avg loss: 0.5263404846191406\n",
      "trial: 10, epoch, 16, iter: 1, curr loss: 0.5159543752670288, avg loss: 0.5159543752670288\n",
      "trial: 10, epoch, 17, iter: 1, curr loss: 0.51334148645401, avg loss: 0.51334148645401\n",
      "trial: 10, epoch, 18, iter: 1, curr loss: 0.5211359858512878, avg loss: 0.5211359858512878\n",
      "trial: 10, epoch, 19, iter: 1, curr loss: 0.5310574769973755, avg loss: 0.5310574769973755\n",
      "trial: 10, epoch, 20, iter: 1, curr loss: 0.5265522003173828, avg loss: 0.5265522003173828\n",
      "trial: 10, epoch, 21, iter: 1, curr loss: 0.5285038948059082, avg loss: 0.5285038948059082\n",
      "trial: 10, epoch, 22, iter: 1, curr loss: 0.534487247467041, avg loss: 0.534487247467041\n",
      "trial: 10, epoch, 23, iter: 1, curr loss: 0.5276045203208923, avg loss: 0.5276045203208923\n",
      "trial: 10, epoch, 24, iter: 1, curr loss: 0.5201722979545593, avg loss: 0.5201722979545593\n",
      "trial: 10, epoch, 25, iter: 1, curr loss: 0.5151509642601013, avg loss: 0.5151509642601013\n",
      "trial: 10, epoch, 26, iter: 1, curr loss: 0.5282403230667114, avg loss: 0.5282403230667114\n",
      "trial: 10, epoch, 27, iter: 1, curr loss: 0.5276005268096924, avg loss: 0.5276005268096924\n",
      "trial: 10, epoch, 28, iter: 1, curr loss: 0.5117745399475098, avg loss: 0.5117745399475098\n",
      "trial: 10, epoch, 29, iter: 1, curr loss: 0.5256995558738708, avg loss: 0.5256995558738708\n",
      "trial: 10, epoch, 30, iter: 1, curr loss: 0.5204858779907227, avg loss: 0.5204858779907227\n",
      "trial: 10, epoch, 31, iter: 1, curr loss: 0.5219310522079468, avg loss: 0.5219310522079468\n",
      "trial: 10, epoch, 32, iter: 1, curr loss: 0.5370447635650635, avg loss: 0.5370447635650635\n",
      "trial: 10, epoch, 33, iter: 1, curr loss: 0.5298579335212708, avg loss: 0.5298579335212708\n",
      "trial: 10, epoch, 34, iter: 1, curr loss: 0.5219312906265259, avg loss: 0.5219312906265259\n",
      "trial: 10, epoch, 35, iter: 1, curr loss: 0.5251193046569824, avg loss: 0.5251193046569824\n",
      "trial: 10, epoch, 36, iter: 1, curr loss: 0.5187674760818481, avg loss: 0.5187674760818481\n",
      "trial: 10, epoch, 37, iter: 1, curr loss: 0.5258071422576904, avg loss: 0.5258071422576904\n",
      "trial: 10, epoch, 38, iter: 1, curr loss: 0.5305792093276978, avg loss: 0.5305792093276978\n",
      "trial: 10, epoch, 39, iter: 1, curr loss: 0.5387784242630005, avg loss: 0.5387784242630005\n",
      "trial: 10, epoch, 40, iter: 1, curr loss: 0.5261670351028442, avg loss: 0.5261670351028442\n",
      "trial: 10, epoch, 41, iter: 1, curr loss: 0.5169482827186584, avg loss: 0.5169482827186584\n",
      "trial: 10, epoch, 42, iter: 1, curr loss: 0.5271877646446228, avg loss: 0.5271877646446228\n",
      "trial: 10, epoch, 43, iter: 1, curr loss: 0.5185957551002502, avg loss: 0.5185957551002502\n",
      "trial: 10, epoch, 44, iter: 1, curr loss: 0.518179178237915, avg loss: 0.518179178237915\n",
      "trial: 10, epoch, 45, iter: 1, curr loss: 0.5239135026931763, avg loss: 0.5239135026931763\n",
      "trial: 10, epoch, 46, iter: 1, curr loss: 0.5295366644859314, avg loss: 0.5295366644859314\n",
      "trial: 10, epoch, 47, iter: 1, curr loss: 0.522618293762207, avg loss: 0.522618293762207\n",
      "trial: 10, epoch, 48, iter: 1, curr loss: 0.5325777530670166, avg loss: 0.5325777530670166\n",
      "trial: 10, epoch, 49, iter: 1, curr loss: 0.5265789031982422, avg loss: 0.5265789031982422\n",
      "trial: 10, epoch, 50, iter: 1, curr loss: 0.5198101997375488, avg loss: 0.5198101997375488\n",
      "trial: 10, ldr: 0.5899323225021362, dv: 0.566256582736969, nwj: 0.5659741163253784\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 11, epoch, 1, iter: 1, curr loss: 0.6918616890907288, avg loss: 0.6918616890907288\n",
      "trial: 11, epoch, 2, iter: 1, curr loss: 0.5265924334526062, avg loss: 0.5265924334526062\n",
      "trial: 11, epoch, 3, iter: 1, curr loss: 0.5215973854064941, avg loss: 0.5215973854064941\n",
      "trial: 11, epoch, 4, iter: 1, curr loss: 0.530270516872406, avg loss: 0.530270516872406\n",
      "trial: 11, epoch, 5, iter: 1, curr loss: 0.5272359848022461, avg loss: 0.5272359848022461\n",
      "trial: 11, epoch, 6, iter: 1, curr loss: 0.5315289497375488, avg loss: 0.5315289497375488\n",
      "trial: 11, epoch, 7, iter: 1, curr loss: 0.5264750123023987, avg loss: 0.5264750123023987\n",
      "trial: 11, epoch, 8, iter: 1, curr loss: 0.533809244632721, avg loss: 0.533809244632721\n",
      "trial: 11, epoch, 9, iter: 1, curr loss: 0.5260556936264038, avg loss: 0.5260556936264038\n",
      "trial: 11, epoch, 10, iter: 1, curr loss: 0.5199424624443054, avg loss: 0.5199424624443054\n",
      "trial: 11, epoch, 11, iter: 1, curr loss: 0.5239064693450928, avg loss: 0.5239064693450928\n",
      "trial: 11, epoch, 12, iter: 1, curr loss: 0.5093564391136169, avg loss: 0.5093564391136169\n",
      "trial: 11, epoch, 13, iter: 1, curr loss: 0.5358663201332092, avg loss: 0.5358663201332092\n",
      "trial: 11, epoch, 14, iter: 1, curr loss: 0.527888834476471, avg loss: 0.527888834476471\n",
      "trial: 11, epoch, 15, iter: 1, curr loss: 0.5271956920623779, avg loss: 0.5271956920623779\n",
      "trial: 11, epoch, 16, iter: 1, curr loss: 0.534379243850708, avg loss: 0.534379243850708\n",
      "trial: 11, epoch, 17, iter: 1, curr loss: 0.5166388750076294, avg loss: 0.5166388750076294\n",
      "trial: 11, epoch, 18, iter: 1, curr loss: 0.5232915878295898, avg loss: 0.5232915878295898\n",
      "trial: 11, epoch, 19, iter: 1, curr loss: 0.5356540083885193, avg loss: 0.5356540083885193\n",
      "trial: 11, epoch, 20, iter: 1, curr loss: 0.5355544686317444, avg loss: 0.5355544686317444\n",
      "trial: 11, epoch, 21, iter: 1, curr loss: 0.5219365954399109, avg loss: 0.5219365954399109\n",
      "trial: 11, epoch, 22, iter: 1, curr loss: 0.5214189887046814, avg loss: 0.5214189887046814\n",
      "trial: 11, epoch, 23, iter: 1, curr loss: 0.5258133411407471, avg loss: 0.5258133411407471\n",
      "trial: 11, epoch, 24, iter: 1, curr loss: 0.5283331274986267, avg loss: 0.5283331274986267\n",
      "trial: 11, epoch, 25, iter: 1, curr loss: 0.5299193263053894, avg loss: 0.5299193263053894\n",
      "trial: 11, epoch, 26, iter: 1, curr loss: 0.5227709412574768, avg loss: 0.5227709412574768\n",
      "trial: 11, epoch, 27, iter: 1, curr loss: 0.5395311117172241, avg loss: 0.5395311117172241\n",
      "trial: 11, epoch, 28, iter: 1, curr loss: 0.5150231122970581, avg loss: 0.5150231122970581\n",
      "trial: 11, epoch, 29, iter: 1, curr loss: 0.5270912647247314, avg loss: 0.5270912647247314\n",
      "trial: 11, epoch, 30, iter: 1, curr loss: 0.5202123522758484, avg loss: 0.5202123522758484\n",
      "trial: 11, epoch, 31, iter: 1, curr loss: 0.5239726305007935, avg loss: 0.5239726305007935\n",
      "trial: 11, epoch, 32, iter: 1, curr loss: 0.5215227007865906, avg loss: 0.5215227007865906\n",
      "trial: 11, epoch, 33, iter: 1, curr loss: 0.5372793674468994, avg loss: 0.5372793674468994\n",
      "trial: 11, epoch, 34, iter: 1, curr loss: 0.5248044729232788, avg loss: 0.5248044729232788\n",
      "trial: 11, epoch, 35, iter: 1, curr loss: 0.5254402160644531, avg loss: 0.5254402160644531\n",
      "trial: 11, epoch, 36, iter: 1, curr loss: 0.5314396619796753, avg loss: 0.5314396619796753\n",
      "trial: 11, epoch, 37, iter: 1, curr loss: 0.5251842141151428, avg loss: 0.5251842141151428\n",
      "trial: 11, epoch, 38, iter: 1, curr loss: 0.5292931199073792, avg loss: 0.5292931199073792\n",
      "trial: 11, epoch, 39, iter: 1, curr loss: 0.5234566330909729, avg loss: 0.5234566330909729\n",
      "trial: 11, epoch, 40, iter: 1, curr loss: 0.525650143623352, avg loss: 0.525650143623352\n",
      "trial: 11, epoch, 41, iter: 1, curr loss: 0.5250310897827148, avg loss: 0.5250310897827148\n",
      "trial: 11, epoch, 42, iter: 1, curr loss: 0.5201826095581055, avg loss: 0.5201826095581055\n",
      "trial: 11, epoch, 43, iter: 1, curr loss: 0.5272840261459351, avg loss: 0.5272840261459351\n",
      "trial: 11, epoch, 44, iter: 1, curr loss: 0.5328153371810913, avg loss: 0.5328153371810913\n",
      "trial: 11, epoch, 45, iter: 1, curr loss: 0.5212734341621399, avg loss: 0.5212734341621399\n",
      "trial: 11, epoch, 46, iter: 1, curr loss: 0.5305265188217163, avg loss: 0.5305265188217163\n",
      "trial: 11, epoch, 47, iter: 1, curr loss: 0.5236847400665283, avg loss: 0.5236847400665283\n",
      "trial: 11, epoch, 48, iter: 1, curr loss: 0.5230365991592407, avg loss: 0.5230365991592407\n",
      "trial: 11, epoch, 49, iter: 1, curr loss: 0.5321477651596069, avg loss: 0.5321477651596069\n",
      "trial: 11, epoch, 50, iter: 1, curr loss: 0.5302844047546387, avg loss: 0.5302844047546387\n",
      "trial: 11, ldr: 0.6225920915603638, dv: 0.5649231672286987, nwj: 0.5632278919219971\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 12, epoch, 1, iter: 1, curr loss: 0.6942365765571594, avg loss: 0.6942365765571594\n",
      "trial: 12, epoch, 2, iter: 1, curr loss: 0.5108828544616699, avg loss: 0.5108828544616699\n",
      "trial: 12, epoch, 3, iter: 1, curr loss: 0.5278500318527222, avg loss: 0.5278500318527222\n",
      "trial: 12, epoch, 4, iter: 1, curr loss: 0.5178191065788269, avg loss: 0.5178191065788269\n",
      "trial: 12, epoch, 5, iter: 1, curr loss: 0.5240660905838013, avg loss: 0.5240660905838013\n",
      "trial: 12, epoch, 6, iter: 1, curr loss: 0.51802659034729, avg loss: 0.51802659034729\n",
      "trial: 12, epoch, 7, iter: 1, curr loss: 0.5287289023399353, avg loss: 0.5287289023399353\n",
      "trial: 12, epoch, 8, iter: 1, curr loss: 0.5293496251106262, avg loss: 0.5293496251106262\n",
      "trial: 12, epoch, 9, iter: 1, curr loss: 0.5336506962776184, avg loss: 0.5336506962776184\n",
      "trial: 12, epoch, 10, iter: 1, curr loss: 0.529662013053894, avg loss: 0.529662013053894\n",
      "trial: 12, epoch, 11, iter: 1, curr loss: 0.534841001033783, avg loss: 0.534841001033783\n",
      "trial: 12, epoch, 12, iter: 1, curr loss: 0.525895893573761, avg loss: 0.525895893573761\n",
      "trial: 12, epoch, 13, iter: 1, curr loss: 0.5207975506782532, avg loss: 0.5207975506782532\n",
      "trial: 12, epoch, 14, iter: 1, curr loss: 0.5348889827728271, avg loss: 0.5348889827728271\n",
      "trial: 12, epoch, 15, iter: 1, curr loss: 0.5246831774711609, avg loss: 0.5246831774711609\n",
      "trial: 12, epoch, 16, iter: 1, curr loss: 0.5218594074249268, avg loss: 0.5218594074249268\n",
      "trial: 12, epoch, 17, iter: 1, curr loss: 0.5274115204811096, avg loss: 0.5274115204811096\n",
      "trial: 12, epoch, 18, iter: 1, curr loss: 0.5239430665969849, avg loss: 0.5239430665969849\n",
      "trial: 12, epoch, 19, iter: 1, curr loss: 0.5231015682220459, avg loss: 0.5231015682220459\n",
      "trial: 12, epoch, 20, iter: 1, curr loss: 0.530776858329773, avg loss: 0.530776858329773\n",
      "trial: 12, epoch, 21, iter: 1, curr loss: 0.5203977823257446, avg loss: 0.5203977823257446\n",
      "trial: 12, epoch, 22, iter: 1, curr loss: 0.5353610515594482, avg loss: 0.5353610515594482\n",
      "trial: 12, epoch, 23, iter: 1, curr loss: 0.5191672444343567, avg loss: 0.5191672444343567\n",
      "trial: 12, epoch, 24, iter: 1, curr loss: 0.529200553894043, avg loss: 0.529200553894043\n",
      "trial: 12, epoch, 25, iter: 1, curr loss: 0.5256675481796265, avg loss: 0.5256675481796265\n",
      "trial: 12, epoch, 26, iter: 1, curr loss: 0.5292366147041321, avg loss: 0.5292366147041321\n",
      "trial: 12, epoch, 27, iter: 1, curr loss: 0.5245993733406067, avg loss: 0.5245993733406067\n",
      "trial: 12, epoch, 28, iter: 1, curr loss: 0.5219559669494629, avg loss: 0.5219559669494629\n",
      "trial: 12, epoch, 29, iter: 1, curr loss: 0.5307419896125793, avg loss: 0.5307419896125793\n",
      "trial: 12, epoch, 30, iter: 1, curr loss: 0.520093560218811, avg loss: 0.520093560218811\n",
      "trial: 12, epoch, 31, iter: 1, curr loss: 0.5315015316009521, avg loss: 0.5315015316009521\n",
      "trial: 12, epoch, 32, iter: 1, curr loss: 0.5260134339332581, avg loss: 0.5260134339332581\n",
      "trial: 12, epoch, 33, iter: 1, curr loss: 0.5277048349380493, avg loss: 0.5277048349380493\n",
      "trial: 12, epoch, 34, iter: 1, curr loss: 0.5233699083328247, avg loss: 0.5233699083328247\n",
      "trial: 12, epoch, 35, iter: 1, curr loss: 0.5217275619506836, avg loss: 0.5217275619506836\n",
      "trial: 12, epoch, 36, iter: 1, curr loss: 0.5310468077659607, avg loss: 0.5310468077659607\n",
      "trial: 12, epoch, 37, iter: 1, curr loss: 0.5327457785606384, avg loss: 0.5327457785606384\n",
      "trial: 12, epoch, 38, iter: 1, curr loss: 0.528770387172699, avg loss: 0.528770387172699\n",
      "trial: 12, epoch, 39, iter: 1, curr loss: 0.5238685011863708, avg loss: 0.5238685011863708\n",
      "trial: 12, epoch, 40, iter: 1, curr loss: 0.5260804295539856, avg loss: 0.5260804295539856\n",
      "trial: 12, epoch, 41, iter: 1, curr loss: 0.5254525542259216, avg loss: 0.5254525542259216\n",
      "trial: 12, epoch, 42, iter: 1, curr loss: 0.5176765322685242, avg loss: 0.5176765322685242\n",
      "trial: 12, epoch, 43, iter: 1, curr loss: 0.5290319919586182, avg loss: 0.5290319919586182\n",
      "trial: 12, epoch, 44, iter: 1, curr loss: 0.5222505331039429, avg loss: 0.5222505331039429\n",
      "trial: 12, epoch, 45, iter: 1, curr loss: 0.518944263458252, avg loss: 0.518944263458252\n",
      "trial: 12, epoch, 46, iter: 1, curr loss: 0.5345085859298706, avg loss: 0.5345085859298706\n",
      "trial: 12, epoch, 47, iter: 1, curr loss: 0.523198664188385, avg loss: 0.523198664188385\n",
      "trial: 12, epoch, 48, iter: 1, curr loss: 0.5296821594238281, avg loss: 0.5296821594238281\n",
      "trial: 12, epoch, 49, iter: 1, curr loss: 0.5211324691772461, avg loss: 0.5211324691772461\n",
      "trial: 12, epoch, 50, iter: 1, curr loss: 0.5221463441848755, avg loss: 0.5221463441848755\n",
      "trial: 12, ldr: 0.5105904340744019, dv: 0.5662893056869507, nwj: 0.564766526222229\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 13, epoch, 1, iter: 1, curr loss: 0.6942662000656128, avg loss: 0.6942662000656128\n",
      "trial: 13, epoch, 2, iter: 1, curr loss: 0.5183412432670593, avg loss: 0.5183412432670593\n",
      "trial: 13, epoch, 3, iter: 1, curr loss: 0.5208233594894409, avg loss: 0.5208233594894409\n",
      "trial: 13, epoch, 4, iter: 1, curr loss: 0.5063346028327942, avg loss: 0.5063346028327942\n",
      "trial: 13, epoch, 5, iter: 1, curr loss: 0.5169178247451782, avg loss: 0.5169178247451782\n",
      "trial: 13, epoch, 6, iter: 1, curr loss: 0.5306235551834106, avg loss: 0.5306235551834106\n",
      "trial: 13, epoch, 7, iter: 1, curr loss: 0.5166325569152832, avg loss: 0.5166325569152832\n",
      "trial: 13, epoch, 8, iter: 1, curr loss: 0.5325005054473877, avg loss: 0.5325005054473877\n",
      "trial: 13, epoch, 9, iter: 1, curr loss: 0.5196245908737183, avg loss: 0.5196245908737183\n",
      "trial: 13, epoch, 10, iter: 1, curr loss: 0.5317256450653076, avg loss: 0.5317256450653076\n",
      "trial: 13, epoch, 11, iter: 1, curr loss: 0.5356556177139282, avg loss: 0.5356556177139282\n",
      "trial: 13, epoch, 12, iter: 1, curr loss: 0.5272692441940308, avg loss: 0.5272692441940308\n",
      "trial: 13, epoch, 13, iter: 1, curr loss: 0.5299150943756104, avg loss: 0.5299150943756104\n",
      "trial: 13, epoch, 14, iter: 1, curr loss: 0.5307035446166992, avg loss: 0.5307035446166992\n",
      "trial: 13, epoch, 15, iter: 1, curr loss: 0.525206446647644, avg loss: 0.525206446647644\n",
      "trial: 13, epoch, 16, iter: 1, curr loss: 0.525266170501709, avg loss: 0.525266170501709\n",
      "trial: 13, epoch, 17, iter: 1, curr loss: 0.5203701853752136, avg loss: 0.5203701853752136\n",
      "trial: 13, epoch, 18, iter: 1, curr loss: 0.5279227495193481, avg loss: 0.5279227495193481\n",
      "trial: 13, epoch, 19, iter: 1, curr loss: 0.5190846920013428, avg loss: 0.5190846920013428\n",
      "trial: 13, epoch, 20, iter: 1, curr loss: 0.5113725066184998, avg loss: 0.5113725066184998\n",
      "trial: 13, epoch, 21, iter: 1, curr loss: 0.5364031791687012, avg loss: 0.5364031791687012\n",
      "trial: 13, epoch, 22, iter: 1, curr loss: 0.523672878742218, avg loss: 0.523672878742218\n",
      "trial: 13, epoch, 23, iter: 1, curr loss: 0.5267350077629089, avg loss: 0.5267350077629089\n",
      "trial: 13, epoch, 24, iter: 1, curr loss: 0.5284332633018494, avg loss: 0.5284332633018494\n",
      "trial: 13, epoch, 25, iter: 1, curr loss: 0.5250189900398254, avg loss: 0.5250189900398254\n",
      "trial: 13, epoch, 26, iter: 1, curr loss: 0.519098162651062, avg loss: 0.519098162651062\n",
      "trial: 13, epoch, 27, iter: 1, curr loss: 0.5330885648727417, avg loss: 0.5330885648727417\n",
      "trial: 13, epoch, 28, iter: 1, curr loss: 0.5185832977294922, avg loss: 0.5185832977294922\n",
      "trial: 13, epoch, 29, iter: 1, curr loss: 0.5310593843460083, avg loss: 0.5310593843460083\n",
      "trial: 13, epoch, 30, iter: 1, curr loss: 0.518994927406311, avg loss: 0.518994927406311\n",
      "trial: 13, epoch, 31, iter: 1, curr loss: 0.5303393006324768, avg loss: 0.5303393006324768\n",
      "trial: 13, epoch, 32, iter: 1, curr loss: 0.5274066925048828, avg loss: 0.5274066925048828\n",
      "trial: 13, epoch, 33, iter: 1, curr loss: 0.5358355045318604, avg loss: 0.5358355045318604\n",
      "trial: 13, epoch, 34, iter: 1, curr loss: 0.5231108665466309, avg loss: 0.5231108665466309\n",
      "trial: 13, epoch, 35, iter: 1, curr loss: 0.514380693435669, avg loss: 0.514380693435669\n",
      "trial: 13, epoch, 36, iter: 1, curr loss: 0.5187926888465881, avg loss: 0.5187926888465881\n",
      "trial: 13, epoch, 37, iter: 1, curr loss: 0.5227115154266357, avg loss: 0.5227115154266357\n",
      "trial: 13, epoch, 38, iter: 1, curr loss: 0.5298986434936523, avg loss: 0.5298986434936523\n",
      "trial: 13, epoch, 39, iter: 1, curr loss: 0.5145494937896729, avg loss: 0.5145494937896729\n",
      "trial: 13, epoch, 40, iter: 1, curr loss: 0.5279867053031921, avg loss: 0.5279867053031921\n",
      "trial: 13, epoch, 41, iter: 1, curr loss: 0.5218138098716736, avg loss: 0.5218138098716736\n",
      "trial: 13, epoch, 42, iter: 1, curr loss: 0.5180484056472778, avg loss: 0.5180484056472778\n",
      "trial: 13, epoch, 43, iter: 1, curr loss: 0.5278128981590271, avg loss: 0.5278128981590271\n",
      "trial: 13, epoch, 44, iter: 1, curr loss: 0.5164867639541626, avg loss: 0.5164867639541626\n",
      "trial: 13, epoch, 45, iter: 1, curr loss: 0.5199226140975952, avg loss: 0.5199226140975952\n",
      "trial: 13, epoch, 46, iter: 1, curr loss: 0.5335484743118286, avg loss: 0.5335484743118286\n",
      "trial: 13, epoch, 47, iter: 1, curr loss: 0.5341798067092896, avg loss: 0.5341798067092896\n",
      "trial: 13, epoch, 48, iter: 1, curr loss: 0.5261596441268921, avg loss: 0.5261596441268921\n",
      "trial: 13, epoch, 49, iter: 1, curr loss: 0.5235186815261841, avg loss: 0.5235186815261841\n",
      "trial: 13, epoch, 50, iter: 1, curr loss: 0.5196505784988403, avg loss: 0.5196505784988403\n",
      "trial: 13, ldr: 0.5469186902046204, dv: 0.5660009384155273, nwj: 0.565820038318634\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 14, epoch, 1, iter: 1, curr loss: 0.695554256439209, avg loss: 0.695554256439209\n",
      "trial: 14, epoch, 2, iter: 1, curr loss: 0.5236254334449768, avg loss: 0.5236254334449768\n",
      "trial: 14, epoch, 3, iter: 1, curr loss: 0.525395393371582, avg loss: 0.525395393371582\n",
      "trial: 14, epoch, 4, iter: 1, curr loss: 0.5270703434944153, avg loss: 0.5270703434944153\n",
      "trial: 14, epoch, 5, iter: 1, curr loss: 0.5266739130020142, avg loss: 0.5266739130020142\n",
      "trial: 14, epoch, 6, iter: 1, curr loss: 0.5321177840232849, avg loss: 0.5321177840232849\n",
      "trial: 14, epoch, 7, iter: 1, curr loss: 0.5226854681968689, avg loss: 0.5226854681968689\n",
      "trial: 14, epoch, 8, iter: 1, curr loss: 0.5387847423553467, avg loss: 0.5387847423553467\n",
      "trial: 14, epoch, 9, iter: 1, curr loss: 0.5312840938568115, avg loss: 0.5312840938568115\n",
      "trial: 14, epoch, 10, iter: 1, curr loss: 0.5308976173400879, avg loss: 0.5308976173400879\n",
      "trial: 14, epoch, 11, iter: 1, curr loss: 0.5178898572921753, avg loss: 0.5178898572921753\n",
      "trial: 14, epoch, 12, iter: 1, curr loss: 0.5314040184020996, avg loss: 0.5314040184020996\n",
      "trial: 14, epoch, 13, iter: 1, curr loss: 0.5268921256065369, avg loss: 0.5268921256065369\n",
      "trial: 14, epoch, 14, iter: 1, curr loss: 0.5338218212127686, avg loss: 0.5338218212127686\n",
      "trial: 14, epoch, 15, iter: 1, curr loss: 0.5289827585220337, avg loss: 0.5289827585220337\n",
      "trial: 14, epoch, 16, iter: 1, curr loss: 0.5252964496612549, avg loss: 0.5252964496612549\n",
      "trial: 14, epoch, 17, iter: 1, curr loss: 0.5279517769813538, avg loss: 0.5279517769813538\n",
      "trial: 14, epoch, 18, iter: 1, curr loss: 0.5257979035377502, avg loss: 0.5257979035377502\n",
      "trial: 14, epoch, 19, iter: 1, curr loss: 0.5188801288604736, avg loss: 0.5188801288604736\n",
      "trial: 14, epoch, 20, iter: 1, curr loss: 0.5271844863891602, avg loss: 0.5271844863891602\n",
      "trial: 14, epoch, 21, iter: 1, curr loss: 0.5249297618865967, avg loss: 0.5249297618865967\n",
      "trial: 14, epoch, 22, iter: 1, curr loss: 0.5219987630844116, avg loss: 0.5219987630844116\n",
      "trial: 14, epoch, 23, iter: 1, curr loss: 0.529065728187561, avg loss: 0.529065728187561\n",
      "trial: 14, epoch, 24, iter: 1, curr loss: 0.5312740802764893, avg loss: 0.5312740802764893\n",
      "trial: 14, epoch, 25, iter: 1, curr loss: 0.5265257358551025, avg loss: 0.5265257358551025\n",
      "trial: 14, epoch, 26, iter: 1, curr loss: 0.5323331952095032, avg loss: 0.5323331952095032\n",
      "trial: 14, epoch, 27, iter: 1, curr loss: 0.5262178778648376, avg loss: 0.5262178778648376\n",
      "trial: 14, epoch, 28, iter: 1, curr loss: 0.5367885828018188, avg loss: 0.5367885828018188\n",
      "trial: 14, epoch, 29, iter: 1, curr loss: 0.528872013092041, avg loss: 0.528872013092041\n",
      "trial: 14, epoch, 30, iter: 1, curr loss: 0.5237874388694763, avg loss: 0.5237874388694763\n",
      "trial: 14, epoch, 31, iter: 1, curr loss: 0.5274399518966675, avg loss: 0.5274399518966675\n",
      "trial: 14, epoch, 32, iter: 1, curr loss: 0.5173790454864502, avg loss: 0.5173790454864502\n",
      "trial: 14, epoch, 33, iter: 1, curr loss: 0.5325793027877808, avg loss: 0.5325793027877808\n",
      "trial: 14, epoch, 34, iter: 1, curr loss: 0.5263394713401794, avg loss: 0.5263394713401794\n",
      "trial: 14, epoch, 35, iter: 1, curr loss: 0.5332010388374329, avg loss: 0.5332010388374329\n",
      "trial: 14, epoch, 36, iter: 1, curr loss: 0.5297341346740723, avg loss: 0.5297341346740723\n",
      "trial: 14, epoch, 37, iter: 1, curr loss: 0.5196995735168457, avg loss: 0.5196995735168457\n",
      "trial: 14, epoch, 38, iter: 1, curr loss: 0.5161411762237549, avg loss: 0.5161411762237549\n",
      "trial: 14, epoch, 39, iter: 1, curr loss: 0.5365167856216431, avg loss: 0.5365167856216431\n",
      "trial: 14, epoch, 40, iter: 1, curr loss: 0.5377501249313354, avg loss: 0.5377501249313354\n",
      "trial: 14, epoch, 41, iter: 1, curr loss: 0.526878297328949, avg loss: 0.526878297328949\n",
      "trial: 14, epoch, 42, iter: 1, curr loss: 0.5265397429466248, avg loss: 0.5265397429466248\n",
      "trial: 14, epoch, 43, iter: 1, curr loss: 0.5225720405578613, avg loss: 0.5225720405578613\n",
      "trial: 14, epoch, 44, iter: 1, curr loss: 0.5319303274154663, avg loss: 0.5319303274154663\n",
      "trial: 14, epoch, 45, iter: 1, curr loss: 0.5370700359344482, avg loss: 0.5370700359344482\n",
      "trial: 14, epoch, 46, iter: 1, curr loss: 0.5310026407241821, avg loss: 0.5310026407241821\n",
      "trial: 14, epoch, 47, iter: 1, curr loss: 0.5280838012695312, avg loss: 0.5280838012695312\n",
      "trial: 14, epoch, 48, iter: 1, curr loss: 0.5348019599914551, avg loss: 0.5348019599914551\n",
      "trial: 14, epoch, 49, iter: 1, curr loss: 0.5139702558517456, avg loss: 0.5139702558517456\n",
      "trial: 14, epoch, 50, iter: 1, curr loss: 0.5258648991584778, avg loss: 0.5258648991584778\n",
      "trial: 14, ldr: 0.5492645502090454, dv: 0.5657184720039368, nwj: 0.5655838251113892\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 15, epoch, 1, iter: 1, curr loss: 0.6917780637741089, avg loss: 0.6917780637741089\n",
      "trial: 15, epoch, 2, iter: 1, curr loss: 0.5187983512878418, avg loss: 0.5187983512878418\n",
      "trial: 15, epoch, 3, iter: 1, curr loss: 0.5260599851608276, avg loss: 0.5260599851608276\n",
      "trial: 15, epoch, 4, iter: 1, curr loss: 0.5194164514541626, avg loss: 0.5194164514541626\n",
      "trial: 15, epoch, 5, iter: 1, curr loss: 0.5224093198776245, avg loss: 0.5224093198776245\n",
      "trial: 15, epoch, 6, iter: 1, curr loss: 0.5255863070487976, avg loss: 0.5255863070487976\n",
      "trial: 15, epoch, 7, iter: 1, curr loss: 0.5312620997428894, avg loss: 0.5312620997428894\n",
      "trial: 15, epoch, 8, iter: 1, curr loss: 0.5274749398231506, avg loss: 0.5274749398231506\n",
      "trial: 15, epoch, 9, iter: 1, curr loss: 0.5329633951187134, avg loss: 0.5329633951187134\n",
      "trial: 15, epoch, 10, iter: 1, curr loss: 0.5296492576599121, avg loss: 0.5296492576599121\n",
      "trial: 15, epoch, 11, iter: 1, curr loss: 0.5279603600502014, avg loss: 0.5279603600502014\n",
      "trial: 15, epoch, 12, iter: 1, curr loss: 0.5252401828765869, avg loss: 0.5252401828765869\n",
      "trial: 15, epoch, 13, iter: 1, curr loss: 0.52687668800354, avg loss: 0.52687668800354\n",
      "trial: 15, epoch, 14, iter: 1, curr loss: 0.5225842595100403, avg loss: 0.5225842595100403\n",
      "trial: 15, epoch, 15, iter: 1, curr loss: 0.5259796380996704, avg loss: 0.5259796380996704\n",
      "trial: 15, epoch, 16, iter: 1, curr loss: 0.5127090215682983, avg loss: 0.5127090215682983\n",
      "trial: 15, epoch, 17, iter: 1, curr loss: 0.5194119215011597, avg loss: 0.5194119215011597\n",
      "trial: 15, epoch, 18, iter: 1, curr loss: 0.5232577323913574, avg loss: 0.5232577323913574\n",
      "trial: 15, epoch, 19, iter: 1, curr loss: 0.5249989032745361, avg loss: 0.5249989032745361\n",
      "trial: 15, epoch, 20, iter: 1, curr loss: 0.5296174883842468, avg loss: 0.5296174883842468\n",
      "trial: 15, epoch, 21, iter: 1, curr loss: 0.5281886458396912, avg loss: 0.5281886458396912\n",
      "trial: 15, epoch, 22, iter: 1, curr loss: 0.528100848197937, avg loss: 0.528100848197937\n",
      "trial: 15, epoch, 23, iter: 1, curr loss: 0.5359094142913818, avg loss: 0.5359094142913818\n",
      "trial: 15, epoch, 24, iter: 1, curr loss: 0.520724892616272, avg loss: 0.520724892616272\n",
      "trial: 15, epoch, 25, iter: 1, curr loss: 0.5260015726089478, avg loss: 0.5260015726089478\n",
      "trial: 15, epoch, 26, iter: 1, curr loss: 0.5201902389526367, avg loss: 0.5201902389526367\n",
      "trial: 15, epoch, 27, iter: 1, curr loss: 0.5327388048171997, avg loss: 0.5327388048171997\n",
      "trial: 15, epoch, 28, iter: 1, curr loss: 0.5173633098602295, avg loss: 0.5173633098602295\n",
      "trial: 15, epoch, 29, iter: 1, curr loss: 0.5239326357841492, avg loss: 0.5239326357841492\n",
      "trial: 15, epoch, 30, iter: 1, curr loss: 0.5292593240737915, avg loss: 0.5292593240737915\n",
      "trial: 15, epoch, 31, iter: 1, curr loss: 0.5210376977920532, avg loss: 0.5210376977920532\n",
      "trial: 15, epoch, 32, iter: 1, curr loss: 0.5274976491928101, avg loss: 0.5274976491928101\n",
      "trial: 15, epoch, 33, iter: 1, curr loss: 0.5194920301437378, avg loss: 0.5194920301437378\n",
      "trial: 15, epoch, 34, iter: 1, curr loss: 0.5299216508865356, avg loss: 0.5299216508865356\n",
      "trial: 15, epoch, 35, iter: 1, curr loss: 0.5267497301101685, avg loss: 0.5267497301101685\n",
      "trial: 15, epoch, 36, iter: 1, curr loss: 0.5218992233276367, avg loss: 0.5218992233276367\n",
      "trial: 15, epoch, 37, iter: 1, curr loss: 0.5210481286048889, avg loss: 0.5210481286048889\n",
      "trial: 15, epoch, 38, iter: 1, curr loss: 0.5300912857055664, avg loss: 0.5300912857055664\n",
      "trial: 15, epoch, 39, iter: 1, curr loss: 0.5269432067871094, avg loss: 0.5269432067871094\n",
      "trial: 15, epoch, 40, iter: 1, curr loss: 0.5267707109451294, avg loss: 0.5267707109451294\n",
      "trial: 15, epoch, 41, iter: 1, curr loss: 0.5277557969093323, avg loss: 0.5277557969093323\n",
      "trial: 15, epoch, 42, iter: 1, curr loss: 0.5210340023040771, avg loss: 0.5210340023040771\n",
      "trial: 15, epoch, 43, iter: 1, curr loss: 0.5252823829650879, avg loss: 0.5252823829650879\n",
      "trial: 15, epoch, 44, iter: 1, curr loss: 0.5288835167884827, avg loss: 0.5288835167884827\n",
      "trial: 15, epoch, 45, iter: 1, curr loss: 0.5404276847839355, avg loss: 0.5404276847839355\n",
      "trial: 15, epoch, 46, iter: 1, curr loss: 0.5270545482635498, avg loss: 0.5270545482635498\n",
      "trial: 15, epoch, 47, iter: 1, curr loss: 0.5331202745437622, avg loss: 0.5331202745437622\n",
      "trial: 15, epoch, 48, iter: 1, curr loss: 0.5152960419654846, avg loss: 0.5152960419654846\n",
      "trial: 15, epoch, 49, iter: 1, curr loss: 0.527539849281311, avg loss: 0.527539849281311\n",
      "trial: 15, epoch, 50, iter: 1, curr loss: 0.5223381519317627, avg loss: 0.5223381519317627\n",
      "trial: 15, ldr: 0.5272085070610046, dv: 0.5655627846717834, nwj: 0.5648365616798401\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 16, epoch, 1, iter: 1, curr loss: 0.6940171122550964, avg loss: 0.6940171122550964\n",
      "trial: 16, epoch, 2, iter: 1, curr loss: 0.5185068845748901, avg loss: 0.5185068845748901\n",
      "trial: 16, epoch, 3, iter: 1, curr loss: 0.5199465155601501, avg loss: 0.5199465155601501\n",
      "trial: 16, epoch, 4, iter: 1, curr loss: 0.528327226638794, avg loss: 0.528327226638794\n",
      "trial: 16, epoch, 5, iter: 1, curr loss: 0.5266175270080566, avg loss: 0.5266175270080566\n",
      "trial: 16, epoch, 6, iter: 1, curr loss: 0.5209795236587524, avg loss: 0.5209795236587524\n",
      "trial: 16, epoch, 7, iter: 1, curr loss: 0.530992865562439, avg loss: 0.530992865562439\n",
      "trial: 16, epoch, 8, iter: 1, curr loss: 0.5230234861373901, avg loss: 0.5230234861373901\n",
      "trial: 16, epoch, 9, iter: 1, curr loss: 0.5256755352020264, avg loss: 0.5256755352020264\n",
      "trial: 16, epoch, 10, iter: 1, curr loss: 0.5288868546485901, avg loss: 0.5288868546485901\n",
      "trial: 16, epoch, 11, iter: 1, curr loss: 0.5199803113937378, avg loss: 0.5199803113937378\n",
      "trial: 16, epoch, 12, iter: 1, curr loss: 0.5242577791213989, avg loss: 0.5242577791213989\n",
      "trial: 16, epoch, 13, iter: 1, curr loss: 0.5259082913398743, avg loss: 0.5259082913398743\n",
      "trial: 16, epoch, 14, iter: 1, curr loss: 0.5343855619430542, avg loss: 0.5343855619430542\n",
      "trial: 16, epoch, 15, iter: 1, curr loss: 0.5327578783035278, avg loss: 0.5327578783035278\n",
      "trial: 16, epoch, 16, iter: 1, curr loss: 0.5280562043190002, avg loss: 0.5280562043190002\n",
      "trial: 16, epoch, 17, iter: 1, curr loss: 0.5252225399017334, avg loss: 0.5252225399017334\n",
      "trial: 16, epoch, 18, iter: 1, curr loss: 0.5207269191741943, avg loss: 0.5207269191741943\n",
      "trial: 16, epoch, 19, iter: 1, curr loss: 0.5186798572540283, avg loss: 0.5186798572540283\n",
      "trial: 16, epoch, 20, iter: 1, curr loss: 0.5353407859802246, avg loss: 0.5353407859802246\n",
      "trial: 16, epoch, 21, iter: 1, curr loss: 0.5295661687850952, avg loss: 0.5295661687850952\n",
      "trial: 16, epoch, 22, iter: 1, curr loss: 0.5234700441360474, avg loss: 0.5234700441360474\n",
      "trial: 16, epoch, 23, iter: 1, curr loss: 0.5176651477813721, avg loss: 0.5176651477813721\n",
      "trial: 16, epoch, 24, iter: 1, curr loss: 0.5298058986663818, avg loss: 0.5298058986663818\n",
      "trial: 16, epoch, 25, iter: 1, curr loss: 0.5300499200820923, avg loss: 0.5300499200820923\n",
      "trial: 16, epoch, 26, iter: 1, curr loss: 0.5252306461334229, avg loss: 0.5252306461334229\n",
      "trial: 16, epoch, 27, iter: 1, curr loss: 0.5289583206176758, avg loss: 0.5289583206176758\n",
      "trial: 16, epoch, 28, iter: 1, curr loss: 0.5197551250457764, avg loss: 0.5197551250457764\n",
      "trial: 16, epoch, 29, iter: 1, curr loss: 0.5252529382705688, avg loss: 0.5252529382705688\n",
      "trial: 16, epoch, 30, iter: 1, curr loss: 0.5298581123352051, avg loss: 0.5298581123352051\n",
      "trial: 16, epoch, 31, iter: 1, curr loss: 0.5222897529602051, avg loss: 0.5222897529602051\n",
      "trial: 16, epoch, 32, iter: 1, curr loss: 0.5337146520614624, avg loss: 0.5337146520614624\n",
      "trial: 16, epoch, 33, iter: 1, curr loss: 0.5220160484313965, avg loss: 0.5220160484313965\n",
      "trial: 16, epoch, 34, iter: 1, curr loss: 0.5197985172271729, avg loss: 0.5197985172271729\n",
      "trial: 16, epoch, 35, iter: 1, curr loss: 0.5309478044509888, avg loss: 0.5309478044509888\n",
      "trial: 16, epoch, 36, iter: 1, curr loss: 0.5212404727935791, avg loss: 0.5212404727935791\n",
      "trial: 16, epoch, 37, iter: 1, curr loss: 0.5187503099441528, avg loss: 0.5187503099441528\n",
      "trial: 16, epoch, 38, iter: 1, curr loss: 0.5219376087188721, avg loss: 0.5219376087188721\n",
      "trial: 16, epoch, 39, iter: 1, curr loss: 0.5314226150512695, avg loss: 0.5314226150512695\n",
      "trial: 16, epoch, 40, iter: 1, curr loss: 0.5376622676849365, avg loss: 0.5376622676849365\n",
      "trial: 16, epoch, 41, iter: 1, curr loss: 0.5284526348114014, avg loss: 0.5284526348114014\n",
      "trial: 16, epoch, 42, iter: 1, curr loss: 0.5334008932113647, avg loss: 0.5334008932113647\n",
      "trial: 16, epoch, 43, iter: 1, curr loss: 0.5178312063217163, avg loss: 0.5178312063217163\n",
      "trial: 16, epoch, 44, iter: 1, curr loss: 0.5278416872024536, avg loss: 0.5278416872024536\n",
      "trial: 16, epoch, 45, iter: 1, curr loss: 0.5319264531135559, avg loss: 0.5319264531135559\n",
      "trial: 16, epoch, 46, iter: 1, curr loss: 0.5298577547073364, avg loss: 0.5298577547073364\n",
      "trial: 16, epoch, 47, iter: 1, curr loss: 0.5151568651199341, avg loss: 0.5151568651199341\n",
      "trial: 16, epoch, 48, iter: 1, curr loss: 0.5193694233894348, avg loss: 0.5193694233894348\n",
      "trial: 16, epoch, 49, iter: 1, curr loss: 0.5216896533966064, avg loss: 0.5216896533966064\n",
      "trial: 16, epoch, 50, iter: 1, curr loss: 0.5253918170928955, avg loss: 0.5253918170928955\n",
      "trial: 16, ldr: 0.5858607888221741, dv: 0.5660631060600281, nwj: 0.5658658146858215\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 17, epoch, 1, iter: 1, curr loss: 0.6932250261306763, avg loss: 0.6932250261306763\n",
      "trial: 17, epoch, 2, iter: 1, curr loss: 0.5208015441894531, avg loss: 0.5208015441894531\n",
      "trial: 17, epoch, 3, iter: 1, curr loss: 0.5222799777984619, avg loss: 0.5222799777984619\n",
      "trial: 17, epoch, 4, iter: 1, curr loss: 0.5248314738273621, avg loss: 0.5248314738273621\n",
      "trial: 17, epoch, 5, iter: 1, curr loss: 0.5256272554397583, avg loss: 0.5256272554397583\n",
      "trial: 17, epoch, 6, iter: 1, curr loss: 0.5225001573562622, avg loss: 0.5225001573562622\n",
      "trial: 17, epoch, 7, iter: 1, curr loss: 0.5271650552749634, avg loss: 0.5271650552749634\n",
      "trial: 17, epoch, 8, iter: 1, curr loss: 0.5273631811141968, avg loss: 0.5273631811141968\n",
      "trial: 17, epoch, 9, iter: 1, curr loss: 0.5253027677536011, avg loss: 0.5253027677536011\n",
      "trial: 17, epoch, 10, iter: 1, curr loss: 0.5259788036346436, avg loss: 0.5259788036346436\n",
      "trial: 17, epoch, 11, iter: 1, curr loss: 0.5222655534744263, avg loss: 0.5222655534744263\n",
      "trial: 17, epoch, 12, iter: 1, curr loss: 0.5342062711715698, avg loss: 0.5342062711715698\n",
      "trial: 17, epoch, 13, iter: 1, curr loss: 0.5319883823394775, avg loss: 0.5319883823394775\n",
      "trial: 17, epoch, 14, iter: 1, curr loss: 0.5316088199615479, avg loss: 0.5316088199615479\n",
      "trial: 17, epoch, 15, iter: 1, curr loss: 0.5194665789604187, avg loss: 0.5194665789604187\n",
      "trial: 17, epoch, 16, iter: 1, curr loss: 0.5292944312095642, avg loss: 0.5292944312095642\n",
      "trial: 17, epoch, 17, iter: 1, curr loss: 0.5152517557144165, avg loss: 0.5152517557144165\n",
      "trial: 17, epoch, 18, iter: 1, curr loss: 0.5238643288612366, avg loss: 0.5238643288612366\n",
      "trial: 17, epoch, 19, iter: 1, curr loss: 0.5307683348655701, avg loss: 0.5307683348655701\n",
      "trial: 17, epoch, 20, iter: 1, curr loss: 0.5292547345161438, avg loss: 0.5292547345161438\n",
      "trial: 17, epoch, 21, iter: 1, curr loss: 0.523033082485199, avg loss: 0.523033082485199\n",
      "trial: 17, epoch, 22, iter: 1, curr loss: 0.5332071185112, avg loss: 0.5332071185112\n",
      "trial: 17, epoch, 23, iter: 1, curr loss: 0.5248321294784546, avg loss: 0.5248321294784546\n",
      "trial: 17, epoch, 24, iter: 1, curr loss: 0.5194751024246216, avg loss: 0.5194751024246216\n",
      "trial: 17, epoch, 25, iter: 1, curr loss: 0.5273613333702087, avg loss: 0.5273613333702087\n",
      "trial: 17, epoch, 26, iter: 1, curr loss: 0.5209382772445679, avg loss: 0.5209382772445679\n",
      "trial: 17, epoch, 27, iter: 1, curr loss: 0.531030535697937, avg loss: 0.531030535697937\n",
      "trial: 17, epoch, 28, iter: 1, curr loss: 0.5187046527862549, avg loss: 0.5187046527862549\n",
      "trial: 17, epoch, 29, iter: 1, curr loss: 0.5270600914955139, avg loss: 0.5270600914955139\n",
      "trial: 17, epoch, 30, iter: 1, curr loss: 0.5325664281845093, avg loss: 0.5325664281845093\n",
      "trial: 17, epoch, 31, iter: 1, curr loss: 0.5309844017028809, avg loss: 0.5309844017028809\n",
      "trial: 17, epoch, 32, iter: 1, curr loss: 0.5244323015213013, avg loss: 0.5244323015213013\n",
      "trial: 17, epoch, 33, iter: 1, curr loss: 0.5214227437973022, avg loss: 0.5214227437973022\n",
      "trial: 17, epoch, 34, iter: 1, curr loss: 0.5286345481872559, avg loss: 0.5286345481872559\n",
      "trial: 17, epoch, 35, iter: 1, curr loss: 0.5220156311988831, avg loss: 0.5220156311988831\n",
      "trial: 17, epoch, 36, iter: 1, curr loss: 0.5199863314628601, avg loss: 0.5199863314628601\n",
      "trial: 17, epoch, 37, iter: 1, curr loss: 0.5289660692214966, avg loss: 0.5289660692214966\n",
      "trial: 17, epoch, 38, iter: 1, curr loss: 0.5227369070053101, avg loss: 0.5227369070053101\n",
      "trial: 17, epoch, 39, iter: 1, curr loss: 0.5306668281555176, avg loss: 0.5306668281555176\n",
      "trial: 17, epoch, 40, iter: 1, curr loss: 0.5202146768569946, avg loss: 0.5202146768569946\n",
      "trial: 17, epoch, 41, iter: 1, curr loss: 0.5296071767807007, avg loss: 0.5296071767807007\n",
      "trial: 17, epoch, 42, iter: 1, curr loss: 0.5213220715522766, avg loss: 0.5213220715522766\n",
      "trial: 17, epoch, 43, iter: 1, curr loss: 0.5167432427406311, avg loss: 0.5167432427406311\n",
      "trial: 17, epoch, 44, iter: 1, curr loss: 0.5257299542427063, avg loss: 0.5257299542427063\n",
      "trial: 17, epoch, 45, iter: 1, curr loss: 0.521285355091095, avg loss: 0.521285355091095\n",
      "trial: 17, epoch, 46, iter: 1, curr loss: 0.5229171514511108, avg loss: 0.5229171514511108\n",
      "trial: 17, epoch, 47, iter: 1, curr loss: 0.528929591178894, avg loss: 0.528929591178894\n",
      "trial: 17, epoch, 48, iter: 1, curr loss: 0.5218949317932129, avg loss: 0.5218949317932129\n",
      "trial: 17, epoch, 49, iter: 1, curr loss: 0.5228176116943359, avg loss: 0.5228176116943359\n",
      "trial: 17, epoch, 50, iter: 1, curr loss: 0.5310218334197998, avg loss: 0.5310218334197998\n",
      "trial: 17, ldr: 0.5490015149116516, dv: 0.565538227558136, nwj: 0.5654022693634033\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 18, epoch, 1, iter: 1, curr loss: 0.6948432326316833, avg loss: 0.6948432326316833\n",
      "trial: 18, epoch, 2, iter: 1, curr loss: 0.5266760587692261, avg loss: 0.5266760587692261\n",
      "trial: 18, epoch, 3, iter: 1, curr loss: 0.5242300033569336, avg loss: 0.5242300033569336\n",
      "trial: 18, epoch, 4, iter: 1, curr loss: 0.5195446014404297, avg loss: 0.5195446014404297\n",
      "trial: 18, epoch, 5, iter: 1, curr loss: 0.5335999727249146, avg loss: 0.5335999727249146\n",
      "trial: 18, epoch, 6, iter: 1, curr loss: 0.5252586603164673, avg loss: 0.5252586603164673\n",
      "trial: 18, epoch, 7, iter: 1, curr loss: 0.5267412066459656, avg loss: 0.5267412066459656\n",
      "trial: 18, epoch, 8, iter: 1, curr loss: 0.5203920602798462, avg loss: 0.5203920602798462\n",
      "trial: 18, epoch, 9, iter: 1, curr loss: 0.5296564102172852, avg loss: 0.5296564102172852\n",
      "trial: 18, epoch, 10, iter: 1, curr loss: 0.5261616706848145, avg loss: 0.5261616706848145\n",
      "trial: 18, epoch, 11, iter: 1, curr loss: 0.5319201946258545, avg loss: 0.5319201946258545\n",
      "trial: 18, epoch, 12, iter: 1, curr loss: 0.5203613042831421, avg loss: 0.5203613042831421\n",
      "trial: 18, epoch, 13, iter: 1, curr loss: 0.5243280529975891, avg loss: 0.5243280529975891\n",
      "trial: 18, epoch, 14, iter: 1, curr loss: 0.5232997536659241, avg loss: 0.5232997536659241\n",
      "trial: 18, epoch, 15, iter: 1, curr loss: 0.5242170691490173, avg loss: 0.5242170691490173\n",
      "trial: 18, epoch, 16, iter: 1, curr loss: 0.5294004678726196, avg loss: 0.5294004678726196\n",
      "trial: 18, epoch, 17, iter: 1, curr loss: 0.5369454622268677, avg loss: 0.5369454622268677\n",
      "trial: 18, epoch, 18, iter: 1, curr loss: 0.5231931805610657, avg loss: 0.5231931805610657\n",
      "trial: 18, epoch, 19, iter: 1, curr loss: 0.5342426300048828, avg loss: 0.5342426300048828\n",
      "trial: 18, epoch, 20, iter: 1, curr loss: 0.5168418288230896, avg loss: 0.5168418288230896\n",
      "trial: 18, epoch, 21, iter: 1, curr loss: 0.5194679498672485, avg loss: 0.5194679498672485\n",
      "trial: 18, epoch, 22, iter: 1, curr loss: 0.527561366558075, avg loss: 0.527561366558075\n",
      "trial: 18, epoch, 23, iter: 1, curr loss: 0.513640284538269, avg loss: 0.513640284538269\n",
      "trial: 18, epoch, 24, iter: 1, curr loss: 0.5184069871902466, avg loss: 0.5184069871902466\n",
      "trial: 18, epoch, 25, iter: 1, curr loss: 0.527694821357727, avg loss: 0.527694821357727\n",
      "trial: 18, epoch, 26, iter: 1, curr loss: 0.5215485095977783, avg loss: 0.5215485095977783\n",
      "trial: 18, epoch, 27, iter: 1, curr loss: 0.5335371494293213, avg loss: 0.5335371494293213\n",
      "trial: 18, epoch, 28, iter: 1, curr loss: 0.5224105715751648, avg loss: 0.5224105715751648\n",
      "trial: 18, epoch, 29, iter: 1, curr loss: 0.5265625715255737, avg loss: 0.5265625715255737\n",
      "trial: 18, epoch, 30, iter: 1, curr loss: 0.525336742401123, avg loss: 0.525336742401123\n",
      "trial: 18, epoch, 31, iter: 1, curr loss: 0.5447027683258057, avg loss: 0.5447027683258057\n",
      "trial: 18, epoch, 32, iter: 1, curr loss: 0.5327111482620239, avg loss: 0.5327111482620239\n",
      "trial: 18, epoch, 33, iter: 1, curr loss: 0.5220268964767456, avg loss: 0.5220268964767456\n",
      "trial: 18, epoch, 34, iter: 1, curr loss: 0.5381665229797363, avg loss: 0.5381665229797363\n",
      "trial: 18, epoch, 35, iter: 1, curr loss: 0.522637128829956, avg loss: 0.522637128829956\n",
      "trial: 18, epoch, 36, iter: 1, curr loss: 0.521272599697113, avg loss: 0.521272599697113\n",
      "trial: 18, epoch, 37, iter: 1, curr loss: 0.5226789116859436, avg loss: 0.5226789116859436\n",
      "trial: 18, epoch, 38, iter: 1, curr loss: 0.524303674697876, avg loss: 0.524303674697876\n",
      "trial: 18, epoch, 39, iter: 1, curr loss: 0.5253933668136597, avg loss: 0.5253933668136597\n",
      "trial: 18, epoch, 40, iter: 1, curr loss: 0.5230065584182739, avg loss: 0.5230065584182739\n",
      "trial: 18, epoch, 41, iter: 1, curr loss: 0.5242961645126343, avg loss: 0.5242961645126343\n",
      "trial: 18, epoch, 42, iter: 1, curr loss: 0.525388777256012, avg loss: 0.525388777256012\n",
      "trial: 18, epoch, 43, iter: 1, curr loss: 0.5350393652915955, avg loss: 0.5350393652915955\n",
      "trial: 18, epoch, 44, iter: 1, curr loss: 0.5237921476364136, avg loss: 0.5237921476364136\n",
      "trial: 18, epoch, 45, iter: 1, curr loss: 0.5372291207313538, avg loss: 0.5372291207313538\n",
      "trial: 18, epoch, 46, iter: 1, curr loss: 0.5271028280258179, avg loss: 0.5271028280258179\n",
      "trial: 18, epoch, 47, iter: 1, curr loss: 0.5286583304405212, avg loss: 0.5286583304405212\n",
      "trial: 18, epoch, 48, iter: 1, curr loss: 0.5251988768577576, avg loss: 0.5251988768577576\n",
      "trial: 18, epoch, 49, iter: 1, curr loss: 0.5324591398239136, avg loss: 0.5324591398239136\n",
      "trial: 18, epoch, 50, iter: 1, curr loss: 0.5343164205551147, avg loss: 0.5343164205551147\n",
      "trial: 18, ldr: 0.5602697134017944, dv: 0.5659439563751221, nwj: 0.5659278631210327\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 19, epoch, 1, iter: 1, curr loss: 0.6943068504333496, avg loss: 0.6943068504333496\n",
      "trial: 19, epoch, 2, iter: 1, curr loss: 0.5279391407966614, avg loss: 0.5279391407966614\n",
      "trial: 19, epoch, 3, iter: 1, curr loss: 0.5250974297523499, avg loss: 0.5250974297523499\n",
      "trial: 19, epoch, 4, iter: 1, curr loss: 0.5291814804077148, avg loss: 0.5291814804077148\n",
      "trial: 19, epoch, 5, iter: 1, curr loss: 0.527992844581604, avg loss: 0.527992844581604\n",
      "trial: 19, epoch, 6, iter: 1, curr loss: 0.5346480011940002, avg loss: 0.5346480011940002\n",
      "trial: 19, epoch, 7, iter: 1, curr loss: 0.5245859622955322, avg loss: 0.5245859622955322\n",
      "trial: 19, epoch, 8, iter: 1, curr loss: 0.5237755179405212, avg loss: 0.5237755179405212\n",
      "trial: 19, epoch, 9, iter: 1, curr loss: 0.5183548331260681, avg loss: 0.5183548331260681\n",
      "trial: 19, epoch, 10, iter: 1, curr loss: 0.533027172088623, avg loss: 0.533027172088623\n",
      "trial: 19, epoch, 11, iter: 1, curr loss: 0.5201568603515625, avg loss: 0.5201568603515625\n",
      "trial: 19, epoch, 12, iter: 1, curr loss: 0.5280091166496277, avg loss: 0.5280091166496277\n",
      "trial: 19, epoch, 13, iter: 1, curr loss: 0.5259501934051514, avg loss: 0.5259501934051514\n",
      "trial: 19, epoch, 14, iter: 1, curr loss: 0.5199917554855347, avg loss: 0.5199917554855347\n",
      "trial: 19, epoch, 15, iter: 1, curr loss: 0.5330747365951538, avg loss: 0.5330747365951538\n",
      "trial: 19, epoch, 16, iter: 1, curr loss: 0.5264427661895752, avg loss: 0.5264427661895752\n",
      "trial: 19, epoch, 17, iter: 1, curr loss: 0.5212041139602661, avg loss: 0.5212041139602661\n",
      "trial: 19, epoch, 18, iter: 1, curr loss: 0.5237040519714355, avg loss: 0.5237040519714355\n",
      "trial: 19, epoch, 19, iter: 1, curr loss: 0.5293421745300293, avg loss: 0.5293421745300293\n",
      "trial: 19, epoch, 20, iter: 1, curr loss: 0.5273081064224243, avg loss: 0.5273081064224243\n",
      "trial: 19, epoch, 21, iter: 1, curr loss: 0.5328118801116943, avg loss: 0.5328118801116943\n",
      "trial: 19, epoch, 22, iter: 1, curr loss: 0.5208231210708618, avg loss: 0.5208231210708618\n",
      "trial: 19, epoch, 23, iter: 1, curr loss: 0.5351837873458862, avg loss: 0.5351837873458862\n",
      "trial: 19, epoch, 24, iter: 1, curr loss: 0.535305380821228, avg loss: 0.535305380821228\n",
      "trial: 19, epoch, 25, iter: 1, curr loss: 0.5290486812591553, avg loss: 0.5290486812591553\n",
      "trial: 19, epoch, 26, iter: 1, curr loss: 0.5268548130989075, avg loss: 0.5268548130989075\n",
      "trial: 19, epoch, 27, iter: 1, curr loss: 0.5216938257217407, avg loss: 0.5216938257217407\n",
      "trial: 19, epoch, 28, iter: 1, curr loss: 0.5315859317779541, avg loss: 0.5315859317779541\n",
      "trial: 19, epoch, 29, iter: 1, curr loss: 0.5222835540771484, avg loss: 0.5222835540771484\n",
      "trial: 19, epoch, 30, iter: 1, curr loss: 0.5224381685256958, avg loss: 0.5224381685256958\n",
      "trial: 19, epoch, 31, iter: 1, curr loss: 0.5304346680641174, avg loss: 0.5304346680641174\n",
      "trial: 19, epoch, 32, iter: 1, curr loss: 0.5246303081512451, avg loss: 0.5246303081512451\n",
      "trial: 19, epoch, 33, iter: 1, curr loss: 0.5247674584388733, avg loss: 0.5247674584388733\n",
      "trial: 19, epoch, 34, iter: 1, curr loss: 0.5197089910507202, avg loss: 0.5197089910507202\n",
      "trial: 19, epoch, 35, iter: 1, curr loss: 0.5362645983695984, avg loss: 0.5362645983695984\n",
      "trial: 19, epoch, 36, iter: 1, curr loss: 0.521655797958374, avg loss: 0.521655797958374\n",
      "trial: 19, epoch, 37, iter: 1, curr loss: 0.5242674350738525, avg loss: 0.5242674350738525\n",
      "trial: 19, epoch, 38, iter: 1, curr loss: 0.5320284366607666, avg loss: 0.5320284366607666\n",
      "trial: 19, epoch, 39, iter: 1, curr loss: 0.5200859904289246, avg loss: 0.5200859904289246\n",
      "trial: 19, epoch, 40, iter: 1, curr loss: 0.5174487829208374, avg loss: 0.5174487829208374\n",
      "trial: 19, epoch, 41, iter: 1, curr loss: 0.5294167995452881, avg loss: 0.5294167995452881\n",
      "trial: 19, epoch, 42, iter: 1, curr loss: 0.5214799642562866, avg loss: 0.5214799642562866\n",
      "trial: 19, epoch, 43, iter: 1, curr loss: 0.5242769718170166, avg loss: 0.5242769718170166\n",
      "trial: 19, epoch, 44, iter: 1, curr loss: 0.5244314074516296, avg loss: 0.5244314074516296\n",
      "trial: 19, epoch, 45, iter: 1, curr loss: 0.5284132361412048, avg loss: 0.5284132361412048\n",
      "trial: 19, epoch, 46, iter: 1, curr loss: 0.5223333835601807, avg loss: 0.5223333835601807\n",
      "trial: 19, epoch, 47, iter: 1, curr loss: 0.529639482498169, avg loss: 0.529639482498169\n",
      "trial: 19, epoch, 48, iter: 1, curr loss: 0.5266238451004028, avg loss: 0.5266238451004028\n",
      "trial: 19, epoch, 49, iter: 1, curr loss: 0.5309864282608032, avg loss: 0.5309864282608032\n",
      "trial: 19, epoch, 50, iter: 1, curr loss: 0.5247385501861572, avg loss: 0.5247385501861572\n",
      "trial: 19, ldr: 0.5873798727989197, dv: 0.5657252669334412, nwj: 0.5654891133308411\n",
      "################################################################\n",
      "\n",
      "################################################################\n",
      "trial: 20, epoch, 1, iter: 1, curr loss: 0.6942602396011353, avg loss: 0.6942602396011353\n",
      "trial: 20, epoch, 2, iter: 1, curr loss: 0.5321441888809204, avg loss: 0.5321441888809204\n",
      "trial: 20, epoch, 3, iter: 1, curr loss: 0.5215752124786377, avg loss: 0.5215752124786377\n",
      "trial: 20, epoch, 4, iter: 1, curr loss: 0.5265011191368103, avg loss: 0.5265011191368103\n",
      "trial: 20, epoch, 5, iter: 1, curr loss: 0.5238926410675049, avg loss: 0.5238926410675049\n",
      "trial: 20, epoch, 6, iter: 1, curr loss: 0.5240578651428223, avg loss: 0.5240578651428223\n",
      "trial: 20, epoch, 7, iter: 1, curr loss: 0.5314651131629944, avg loss: 0.5314651131629944\n",
      "trial: 20, epoch, 8, iter: 1, curr loss: 0.5247116088867188, avg loss: 0.5247116088867188\n",
      "trial: 20, epoch, 9, iter: 1, curr loss: 0.5283292531967163, avg loss: 0.5283292531967163\n",
      "trial: 20, epoch, 10, iter: 1, curr loss: 0.5068444609642029, avg loss: 0.5068444609642029\n",
      "trial: 20, epoch, 11, iter: 1, curr loss: 0.5300175547599792, avg loss: 0.5300175547599792\n",
      "trial: 20, epoch, 12, iter: 1, curr loss: 0.5224778652191162, avg loss: 0.5224778652191162\n",
      "trial: 20, epoch, 13, iter: 1, curr loss: 0.5266908407211304, avg loss: 0.5266908407211304\n",
      "trial: 20, epoch, 14, iter: 1, curr loss: 0.5216662883758545, avg loss: 0.5216662883758545\n",
      "trial: 20, epoch, 15, iter: 1, curr loss: 0.5233408212661743, avg loss: 0.5233408212661743\n",
      "trial: 20, epoch, 16, iter: 1, curr loss: 0.5226552486419678, avg loss: 0.5226552486419678\n",
      "trial: 20, epoch, 17, iter: 1, curr loss: 0.5240253210067749, avg loss: 0.5240253210067749\n",
      "trial: 20, epoch, 18, iter: 1, curr loss: 0.5240679979324341, avg loss: 0.5240679979324341\n",
      "trial: 20, epoch, 19, iter: 1, curr loss: 0.5259493589401245, avg loss: 0.5259493589401245\n",
      "trial: 20, epoch, 20, iter: 1, curr loss: 0.5235254764556885, avg loss: 0.5235254764556885\n",
      "trial: 20, epoch, 21, iter: 1, curr loss: 0.5117312669754028, avg loss: 0.5117312669754028\n",
      "trial: 20, epoch, 22, iter: 1, curr loss: 0.5152328014373779, avg loss: 0.5152328014373779\n",
      "trial: 20, epoch, 23, iter: 1, curr loss: 0.5279987454414368, avg loss: 0.5279987454414368\n",
      "trial: 20, epoch, 24, iter: 1, curr loss: 0.5324720740318298, avg loss: 0.5324720740318298\n",
      "trial: 20, epoch, 25, iter: 1, curr loss: 0.5241210460662842, avg loss: 0.5241210460662842\n",
      "trial: 20, epoch, 26, iter: 1, curr loss: 0.534760057926178, avg loss: 0.534760057926178\n",
      "trial: 20, epoch, 27, iter: 1, curr loss: 0.5274112224578857, avg loss: 0.5274112224578857\n",
      "trial: 20, epoch, 28, iter: 1, curr loss: 0.532561182975769, avg loss: 0.532561182975769\n",
      "trial: 20, epoch, 29, iter: 1, curr loss: 0.5321658849716187, avg loss: 0.5321658849716187\n",
      "trial: 20, epoch, 30, iter: 1, curr loss: 0.5161454677581787, avg loss: 0.5161454677581787\n",
      "trial: 20, epoch, 31, iter: 1, curr loss: 0.5217452049255371, avg loss: 0.5217452049255371\n",
      "trial: 20, epoch, 32, iter: 1, curr loss: 0.5251476764678955, avg loss: 0.5251476764678955\n",
      "trial: 20, epoch, 33, iter: 1, curr loss: 0.5263795852661133, avg loss: 0.5263795852661133\n",
      "trial: 20, epoch, 34, iter: 1, curr loss: 0.5235271453857422, avg loss: 0.5235271453857422\n",
      "trial: 20, epoch, 35, iter: 1, curr loss: 0.5291123390197754, avg loss: 0.5291123390197754\n",
      "trial: 20, epoch, 36, iter: 1, curr loss: 0.5252305269241333, avg loss: 0.5252305269241333\n",
      "trial: 20, epoch, 37, iter: 1, curr loss: 0.5226199626922607, avg loss: 0.5226199626922607\n",
      "trial: 20, epoch, 38, iter: 1, curr loss: 0.5206032991409302, avg loss: 0.5206032991409302\n",
      "trial: 20, epoch, 39, iter: 1, curr loss: 0.5233085751533508, avg loss: 0.5233085751533508\n",
      "trial: 20, epoch, 40, iter: 1, curr loss: 0.5229455232620239, avg loss: 0.5229455232620239\n",
      "trial: 20, epoch, 41, iter: 1, curr loss: 0.5320231914520264, avg loss: 0.5320231914520264\n",
      "trial: 20, epoch, 42, iter: 1, curr loss: 0.5314054489135742, avg loss: 0.5314054489135742\n",
      "trial: 20, epoch, 43, iter: 1, curr loss: 0.511930525302887, avg loss: 0.511930525302887\n",
      "trial: 20, epoch, 44, iter: 1, curr loss: 0.5228182673454285, avg loss: 0.5228182673454285\n",
      "trial: 20, epoch, 45, iter: 1, curr loss: 0.5198057889938354, avg loss: 0.5198057889938354\n",
      "trial: 20, epoch, 46, iter: 1, curr loss: 0.529862642288208, avg loss: 0.529862642288208\n",
      "trial: 20, epoch, 47, iter: 1, curr loss: 0.5254268050193787, avg loss: 0.5254268050193787\n",
      "trial: 20, epoch, 48, iter: 1, curr loss: 0.5113999247550964, avg loss: 0.5113999247550964\n",
      "trial: 20, epoch, 49, iter: 1, curr loss: 0.532688319683075, avg loss: 0.532688319683075\n",
      "trial: 20, epoch, 50, iter: 1, curr loss: 0.5318416953086853, avg loss: 0.5318416953086853\n",
      "trial: 20, ldr: 0.534949779510498, dv: 0.5661852359771729, nwj: 0.5657024383544922\n",
      "################################################################\n",
      "\n",
      "final estimations:\n",
      "\tldr: 0.5643750071525574\n",
      "\tdv: 0.5655131459236145\n",
      "\tnwj: 0.5650129914283752\n"
     ]
    }
   ],
   "source": [
    "num_of_outer_iteration = 20\n",
    "num_of_inner_iteration = 50\n",
    "batch_size = 4096\n",
    "\n",
    "# iterate over many times\n",
    "outer_running_loss = []\n",
    "outer_running_loss_avg = []\n",
    "ldr_estimations = []\n",
    "dv_estimations = []\n",
    "nwj_estimations = []\n",
    "\n",
    "for outer_iter in range(num_of_outer_iteration):\n",
    "    print('################################################################')\n",
    "    model, inner_running_loss, inner_running_loss_avg, num_of_joint, num_of_marginal = train_binary_classifier_v2(data, label, num_input_features, hidden_size_arr, lr, num_of_inner_iteration, batch_size, outer_iter, save_avg=200, print_progress=True)\n",
    "    outer_running_loss.append(inner_running_loss)\n",
    "    outer_running_loss_avg.append(inner_running_loss_avg)\n",
    "    \n",
    "    ## estimate cmi\n",
    "    curr_ldr, curr_dv, curr_nwj = estimate_mi_for_binary_classification(model, joint_data, num_of_joint, marginal_data, num_of_marginal)\n",
    "    print('trial: {}, ldr: {}, dv: {}, nwj: {}'.format(outer_iter + 1, curr_ldr.item(), curr_dv.item(), curr_nwj.item()))\n",
    "    print('################################################################\\n')\n",
    "    ldr_estimations.append(curr_ldr.item())\n",
    "    dv_estimations.append(curr_dv.item())\n",
    "    nwj_estimations.append(curr_nwj.item())\n",
    "    \n",
    "print('final estimations:\\n\\tldr: {}\\n\\tdv: {}\\n\\tnwj: {}'.format(np.mean(ldr_estimations), np.mean(dv_estimations), np.mean(nwj_estimations)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:55:40.973467077Z",
     "start_time": "2023-11-20T22:53:35.898004419Z"
    }
   },
   "id": "fbdf107dc1fdd5ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
