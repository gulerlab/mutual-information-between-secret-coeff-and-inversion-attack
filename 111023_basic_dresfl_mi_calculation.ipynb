{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DReS-FL Experiment \n",
    "\n",
    "- K = 1\n",
    "- T = 1\n",
    "- input dimension = 1 -> scalar\n",
    "- linear regression\n",
    "- w = 1\n",
    "- finite field size = 5\n",
    "- inputs are selected from {0, 1}\n",
    "- y = x\n",
    "- the gradient is supposed to be revealed at the end of each training round\n",
    "\n",
    "Basically, our objective function is $l = (y - xw)^2$ and our gradient is $g = -2(xy - x^2w)$ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b3c4298b0e65eb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lcc.polynomials import LCCPoly, InterpolatedPoly\n",
    "from mutual_information.estimators.neural.benchmark import neural_estimator_benchmark\n",
    "from lcc.domain import create_lcc_gradient_domain_basic_setup\n",
    "from mutual_information.exhaustive_search_mutual_information import calculate_mutual_information_domain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:34:30.284959734Z",
     "start_time": "2023-11-13T20:34:29.216335928Z"
    }
   },
   "id": "5ecd3014be47b957"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "prime = 5\n",
    "data_range = 2\n",
    "para_param = 1 # K\n",
    "priv_param = 1 # T\n",
    "\n",
    "num_of_samples = 10000\n",
    "beta_arr = [0, 1]\n",
    "alpha_arr = [2, 3, 4] # number of clients = 3\n",
    "weight = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:34:30.285318263Z",
     "start_time": "2023-11-13T20:34:30.284603911Z"
    }
   },
   "id": "cea634fe6a81f53"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_encoded_dataset(encoded_data_pol, encoded_label_pol, alpha):\n",
    "    encoded_dataset = np.empty((len(encoded_data_pol), 2)) \n",
    "    for idx, (data_pol, label_pol) in enumerate(zip(encoded_data_pol, encoded_label_pol)):\n",
    "        encoded_dataset[idx][0] = data_pol(alpha)\n",
    "        encoded_dataset[idx][1] = label_pol(alpha)\n",
    "    return encoded_dataset\n",
    "\n",
    "def calculate_gradient(encoded_dataset, curr_weight, p):\n",
    "    encoded_data = encoded_dataset[:, 0].reshape(-1, 1)\n",
    "    encoded_label = encoded_dataset[:, 1].reshape(-1, 1)\n",
    "    \n",
    "    gradient = (encoded_label - encoded_data @ curr_weight) % p\n",
    "    gradient = (encoded_data.T @ gradient) % p\n",
    "    gradient = (-2 * gradient) % p\n",
    "    return gradient\n",
    "\n",
    "def calculate_gradient_samplewise(encoded_dataset, curr_weight, p):\n",
    "    # g = -2(xy - x^2w)\n",
    "    gradient = np.empty(encoded_dataset.shape[0])\n",
    "    for idx, encoded_sample in enumerate(encoded_dataset):\n",
    "        data, label = encoded_sample[0], encoded_sample[1]\n",
    "        gradient[idx] = (label - data * curr_weight) % p\n",
    "        gradient[idx] = (data * gradient[idx]) % p\n",
    "        gradient[idx] = (-2 * gradient[idx]) % p\n",
    "    gradient = gradient.astype(int)\n",
    "    return gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:57:16.180910265Z",
     "start_time": "2023-11-13T19:57:16.179645394Z"
    }
   },
   "id": "2d6a184396caa636"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "secret_data = np.random.randint(low=0, high=2, size=(num_of_samples, 1))\n",
    "secret_label = secret_data\n",
    "encoded_secret_data_pol = [LCCPoly(beta_arr, [x[0]], para_param, priv_param, prime) for x in secret_data]\n",
    "encoded_secret_label_pol = [LCCPoly(beta_arr, [x[0]], para_param, priv_param, prime) for x in secret_label]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:57:23.922385697Z",
     "start_time": "2023-11-13T19:57:16.952749513Z"
    }
   },
   "id": "705f968c5d9b62fc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# client 0\n",
    "client_0_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[0])\n",
    "client_0_encoded_gradient = calculate_gradient_samplewise(client_0_encoded_data, weight, prime)\n",
    "\n",
    "# client 1\n",
    "client_1_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[1])\n",
    "client_1_encoded_gradient = calculate_gradient_samplewise(client_1_encoded_data, weight, prime)\n",
    "\n",
    "# client 2\n",
    "client_2_encoded_data = create_encoded_dataset(encoded_secret_data_pol, encoded_secret_label_pol, alpha_arr[2])\n",
    "client_2_encoded_gradient = calculate_gradient_samplewise(client_2_encoded_data, weight, prime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:57:24.080154043Z",
     "start_time": "2023-11-13T19:57:23.927649214Z"
    }
   },
   "id": "ac2d268532e1f34a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "revealed_poly_arr = [] \n",
    "revealed_gradients = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_random = np.empty((client_0_encoded_gradient.shape[0], 1))\n",
    "revealed_poly_constructed_coeff = np.empty((client_0_encoded_gradient.shape[0], 2 * para_param + 1))\n",
    "for gradient_idx in range(client_0_encoded_gradient.shape[0]):\n",
    "    revealed_poly = InterpolatedPoly([int(client_0_encoded_gradient[gradient_idx]), int(client_1_encoded_gradient[gradient_idx]), int(client_2_encoded_gradient[gradient_idx])], alpha_arr, prime)\n",
    "    revealed_gradients[gradient_idx][0] = revealed_poly(beta_arr[0])\n",
    "    revealed_random[gradient_idx][0] = revealed_poly(beta_arr[1])\n",
    "    revealed_poly_constructed_coeff[gradient_idx] = revealed_poly.coefficients\n",
    "    revealed_poly_arr.append(revealed_poly)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:57:28.138146606Z",
     "start_time": "2023-11-13T19:57:24.083826992Z"
    }
   },
   "id": "a77a29cfacc3050a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# create dataset\n",
    "resulting_dataset = np.concatenate([secret_data, secret_label, revealed_gradients, revealed_random, revealed_poly_constructed_coeff], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:57:28.138294094Z",
     "start_time": "2023-11-13T19:57:28.136118606Z"
    }
   },
   "id": "4566e622a38e75c5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▎                                               | 1000/10000 [01:41<15:13,  9.85step/s, test=0.69, train=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▌                                             | 1250/10000 [00:04<00:33, 259.51step/s, test=0.71, train=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                                  | 750/10000 [01:12<14:58, 10.30step/s, test=0.69, train=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                                  | 750/10000 [01:12<14:52, 10.37step/s, test=0.69, train=0.70]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_all, results_all = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 2:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:01:40.816855615Z",
     "start_time": "2023-11-13T19:57:28.138084283Z"
    }
   },
   "id": "4e4d497917e37ba1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████▌                                          | 2000/10000 [04:27<17:51,  7.47step/s, test=0.69, train=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donker Varadhan estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▌                                             | 1250/10000 [00:04<00:32, 265.71step/s, test=0.71, train=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINE estimator: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                                  | 750/10000 [01:38<20:18,  7.59step/s, test=0.69, train=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▎                                               | 1000/10000 [02:16<20:32,  7.30step/s, test=0.69, train=0.70]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWJ estimator: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators_revealed_gradient, results_revealed_gradient = neural_estimator_benchmark(resulting_dataset[:, :2], resulting_dataset[:, 2].reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:10:09.301302132Z",
     "start_time": "2023-11-13T20:01:40.818141924Z"
    }
   },
   "id": "f4987aa6326c8320"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100/12500\n",
      "iteration 200/12500\n",
      "iteration 300/12500\n",
      "iteration 400/12500\n",
      "iteration 500/12500\n",
      "iteration 600/12500\n",
      "iteration 700/12500\n",
      "iteration 800/12500\n",
      "iteration 900/12500\n",
      "iteration 1000/12500\n",
      "iteration 1100/12500\n",
      "iteration 1200/12500\n",
      "iteration 1300/12500\n",
      "iteration 1400/12500\n",
      "iteration 1500/12500\n",
      "iteration 1600/12500\n",
      "iteration 1700/12500\n",
      "iteration 1800/12500\n",
      "iteration 1900/12500\n",
      "iteration 2000/12500\n",
      "iteration 2100/12500\n",
      "iteration 2200/12500\n",
      "iteration 2300/12500\n",
      "iteration 2400/12500\n",
      "iteration 2500/12500\n",
      "iteration 2600/12500\n",
      "iteration 2700/12500\n",
      "iteration 2800/12500\n",
      "iteration 2900/12500\n",
      "iteration 3000/12500\n",
      "iteration 3100/12500\n",
      "iteration 3200/12500\n",
      "iteration 3300/12500\n",
      "iteration 3400/12500\n",
      "iteration 3500/12500\n",
      "iteration 3600/12500\n",
      "iteration 3700/12500\n",
      "iteration 3800/12500\n",
      "iteration 3900/12500\n",
      "iteration 4000/12500\n",
      "iteration 4100/12500\n",
      "iteration 4200/12500\n",
      "iteration 4300/12500\n",
      "iteration 4400/12500\n",
      "iteration 4500/12500\n",
      "iteration 4600/12500\n",
      "iteration 4700/12500\n",
      "iteration 4800/12500\n",
      "iteration 4900/12500\n",
      "iteration 5000/12500\n",
      "iteration 5100/12500\n",
      "iteration 5200/12500\n",
      "iteration 5300/12500\n",
      "iteration 5400/12500\n",
      "iteration 5500/12500\n",
      "iteration 5600/12500\n",
      "iteration 5700/12500\n",
      "iteration 5800/12500\n",
      "iteration 5900/12500\n",
      "iteration 6000/12500\n",
      "iteration 6100/12500\n",
      "iteration 6200/12500\n",
      "iteration 6300/12500\n",
      "iteration 6400/12500\n",
      "iteration 6500/12500\n",
      "iteration 6600/12500\n",
      "iteration 6700/12500\n",
      "iteration 6800/12500\n",
      "iteration 6900/12500\n",
      "iteration 7000/12500\n",
      "iteration 7100/12500\n",
      "iteration 7200/12500\n",
      "iteration 7300/12500\n",
      "iteration 7400/12500\n",
      "iteration 7500/12500\n",
      "iteration 7600/12500\n",
      "iteration 7700/12500\n",
      "iteration 7800/12500\n",
      "iteration 7900/12500\n",
      "iteration 8000/12500\n",
      "iteration 8100/12500\n",
      "iteration 8200/12500\n",
      "iteration 8300/12500\n",
      "iteration 8400/12500\n",
      "iteration 8500/12500\n",
      "iteration 8600/12500\n",
      "iteration 8700/12500\n",
      "iteration 8800/12500\n",
      "iteration 8900/12500\n",
      "iteration 9000/12500\n",
      "iteration 9100/12500\n",
      "iteration 9200/12500\n",
      "iteration 9300/12500\n",
      "iteration 9400/12500\n",
      "iteration 9500/12500\n",
      "iteration 9600/12500\n",
      "iteration 9700/12500\n",
      "iteration 9800/12500\n",
      "iteration 9900/12500\n",
      "iteration 10000/12500\n",
      "iteration 10100/12500\n",
      "iteration 10200/12500\n",
      "iteration 10300/12500\n",
      "iteration 10400/12500\n",
      "iteration 10500/12500\n",
      "iteration 10600/12500\n",
      "iteration 10700/12500\n",
      "iteration 10800/12500\n",
      "iteration 10900/12500\n",
      "iteration 11000/12500\n",
      "iteration 11100/12500\n",
      "iteration 11200/12500\n",
      "iteration 11300/12500\n",
      "iteration 11400/12500\n",
      "iteration 11500/12500\n",
      "iteration 11600/12500\n",
      "iteration 11700/12500\n",
      "iteration 11800/12500\n",
      "iteration 11900/12500\n",
      "iteration 12000/12500\n",
      "iteration 12100/12500\n",
      "iteration 12200/12500\n",
      "iteration 12300/12500\n",
      "iteration 12400/12500\n",
      "iteration 12500/12500\n",
      "0.6931471805599452 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "basic_experiment_domain = create_lcc_gradient_domain_basic_setup(data_range, beta_arr, alpha_arr, weight, prime)\n",
    "all_coeff_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4, 5, 6, 7, 8], [data_range, data_range], [prime, prime, prime, prime, prime])\n",
    "revealed_gradient_mi = calculate_mutual_information_domain(basic_experiment_domain, [0, 2], [4], [data_range, data_range], [prime])\n",
    "print(all_coeff_mi, revealed_gradient_mi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:36:01.128748005Z",
     "start_time": "2023-11-13T20:35:57.386813161Z"
    }
   },
   "id": "e5c2fec600e08573"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
